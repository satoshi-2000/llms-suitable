[
{
"QuestionId": "76378346",
"QuestionTitle": "How to modify a regular expression to validate a text box with letters and numbers only, excluding certain characters like !@#$%^&*+=",
"QuestionBody": "Regular Expression for text box validation. I need to validate textbox. conditions like below\n\ncan enter numbers and letters.\nneed to avoid these characters !@#$%^&*+=\n\nCurrently i am using below regular expression. but it is not working.\n <input type=\"text\" pattern=\"^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$\" />\ncan u help me to find correct regular expression\n",
"AnswerId": "76378431",
"AnswerBody": "The regulation expression you are currently using is for validate email addresses.\nSo you have to use a regular expression to validate textboxes, make it only contain letters and numbers and avoid the characters (!@#$%^&*+=).\n^[a-zA-Z0-9]+$\n\nThis will match any strings that is a letter or a number. It will not match any strings that any characters !@#$%^&*+=.\n\n\n<input type=\"text\" pattern=\"^[a-zA-Z0-9]+$\" />\n\n\n\nHope this will help. Thank you!\nRefer to this link if you need more clarifications https://laasyasettyblog.hashnode.dev/validating-username-using-regex\nImproving my answer with the question u asked,\n\n\n<!DOCTYPE html>\n<html>\n<head>\n<title>Test Pattern</title>\n</head>\n<body>\n<input type=\"text\" id=\"input\" pattern='^[a-zA-Z0-9./|()?~<>\":;]+$' />\n<button onclick=\"validate()\">Validate</button>\n<script>\nfunction validate() {\n var input = document.getElementById(\"input\").value;\n var pattern = /[a-zA-Z0-9./|()?~<>\":;]+/;\n if (pattern.test(input)) {\n  alert(\"Valid\");\n } else {\n  alert(\"Invalid\");\n }\n}\n</script>\n</body>\n</html>\n\n\n\n"
},
{
"QuestionId": "76378408",
"QuestionTitle": "How can i add new key and value in a existing list",
"QuestionBody": "I'm trying to create a blind auction. So basically it will ask for your name and then your bid. After that, it will ask if there are any bidders, if yes it will ask you the name and the bid price. But after you said yes the terminal will be cleaned. So that the other bidder can't see how much the other person bid, if I run print on the [data_base] it can't print more than two keys and value.\nHere is the output:\nWhat is your name?: Gael\nWhat is your bid: $560\nAre there any other bidders? Type 'yes or 'no'.\nyes\n\n\\[({'Gael': \\['560'\\]},)\\]\nWhat is your name?: Mikey\nWhat is your bid: $350\nAre there any other bidders? Type 'yes or 'no'.\nyes\n\n\\[({'Mikey': \\['350'\\]},)\\]\nWhat is your name?: Josh\nWhat is your bid: $298\nAre there any other bidders? Type 'yes or 'no'.\nno\n\nHere is the final output:\n[({'Mikey': ['350']},), ({'Josh': ['298']},)]\nGael's name and his bid are missing.\nHere is the code:\nimport os\n\nwhile True:\nname = input(\"What is your name?: \")\nbid = input(\"What is your bid: $\")\n\n    other_user = input(\"Are there any other bidders? Type 'yes or 'no'.\\n\")\n    \n    if other_user == 'yes':\n         os.system('cls')\n         data_base = [\n    \n             ]\n    def new_user(name, bid):\n        brandnew_user = {\n            name: [bid]\n            \n            },\n        \n        data_base.append(brandnew_user)\n        \n    new_user(name, bid)\n    print(data_base)\n    \n    \n    if other_user == 'no':\n        break\n\nThank you!!\nI was expecting that Gael's name and bid will be recorded. But it did not, it only recorded, Mikey and Josh.\n",
"AnswerId": "76378435",
"AnswerBody": "Here's a better way to organize things.  Also, I'm not sure why you are creating a list of tuples of dictionaries.  Why not just make data_base a dictionary and store the new entries as keys?\nimport os\n\ndata_base = []\nwhile True:\n    name = input(\"What is your name?: \")\n    bid = input(\"What is your bid: $\")\n\n    data_base.append( {name: [bid]} )\n    print(data_base)\n\n    other_user = input(\"Are there any other bidders? Type 'yes or 'no'.\\n\")\n    if other_user == 'no':\n        break\n\nHere's what I'm talking about:\nimport os\n\ndata_base = {}\nwhile True:\n    name = input(\"What is your name?: \")\n    bid = input(\"What is your bid: $\")\n\n    data_base[name] = [bid]\n    print(data_base)\n\n    other_user = input(\"Are there any other bidders? Type 'yes or 'no'.\\n\")\n    if other_user == 'no':\n        break\n\n"
},
{
"QuestionId": "76378340",
"QuestionTitle": "How to repeat video with start and end time in Android Studio?",
"QuestionBody": "I'm getting error in Android Studio on second \"cannot resolve symbol second\" how to fix it so that it loops from 358 to 331 in this example?\npackage com.example.myapp;\n\nimport androidx.annotation.NonNull;\nimport androidx.appcompat.app.AppCompatActivity;\n\nimport android.content.Intent;\nimport android.os.Bundle;\nimport android.view.View;\nimport android.widget.RelativeLayout;\n\nimport com.pierfrancescosoffritti.androidyoutubeplayer.core.player.YouTubePlayer;\nimport com.pierfrancescosoffritti.androidyoutubeplayer.core.player.listeners.AbstractYouTubePlayerListener;\nimport com.pierfrancescosoffritti.androidyoutubeplayer.core.player.views.YouTubePlayerView;\n\npublic class FingerStretching extends AppCompatActivity {\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_finger_stretching);\n\n        YouTubePlayerView youTubePlayerView = findViewById(R.id.youtube_player_view);\n        getLifecycle().addObserver(youTubePlayerView);\n\n        youTubePlayerView.addYouTubePlayerListener(new AbstractYouTubePlayerListener() {\n            String videoId = \"mSZWSQSSEjE\";\n            @Override\n            public void onReady(@NonNull YouTubePlayer youTubePlayer) {\n                youTubePlayer.loadVideo(videoId, 331);\n            }\n            \n            public void onCurrentSecond(@NonNull YouTubePlayer youTubePlayer) {\n                if(second == 358) youTubePlayer.seekTo(331);\n            }\n        });\n\n\n\n    }\n}\n\ntried creating local variable second\n",
"AnswerId": "76378439",
"AnswerBody": "According to the source code, the signature of onCurrentSecond is\noverride fun onCurrentSecond(youTubePlayer: YouTubePlayer, second: Float)\n\nYou are not overriding it. It should be\n@Override\npublic void onCurrentSecond(@NonNull YouTubePlayer youTubePlayer, float second) {\n    if(second >= 358) youTubePlayer.seekTo(331);\n}\n\nSuch kind of error is easily avoidable if you make use of the auto complete feature in the IDE. Typing onC within the AbstractYouTubePlayerListener should give you auto complete option for onCurrentSecond, selecting it should automatically write the override function for you with correct signature.\n"
},
{
"QuestionId": "76378344",
"QuestionTitle": "how to use react function in codepen?",
"QuestionBody": "How to use React functions in CodePen?\nI wrote a react function in CodePem to test React hooks, however it constantly keeps reporting errors: Uncaught ReferenceError: require is not defined.\nMy Code:\nimport {useState, useEffect,useRef } from 'react';\n\nfunction Test() {\n  const [count, setCount] = useState(0);\n  const prevRef = useRef();\n  \n  useEffect(() => {\n    // const ref = useRef();\n    console.log('ref----', prevRef.current);\n    prevRef.current = count;\n  })\n  \n  return (\n    <div>\n      <div onClick={() => setCount(count+1)}>+1</div>\n      <div>{`count: ${count}`}</div>\n      <div>{`precount: ${prevRef.current}`}</div>\n    </div>\n  )\n}\n\nReactDOM.render(<Test />, document.getElementById(\"app\"));\n\n\n",
"AnswerId": "76378496",
"AnswerBody": "You can add a package by adjusting the settings in your Pen.\nTake a look at the following image for reference:\n\nBy doing so, it will automatically generate the necessary import statement:\nimport React, { useState, useEffect, useRef } from 'https://esm.sh/react@18.2.0';\nimport ReactDOM from 'https://esm.sh/react-dom@18.2.0';\n\nTo help you understand this process, I've created a sample code on CodePen. You can refer to this example to implement it yourself.\nHere is the codepen link to the sample code: https://codepen.io/camel2243/pen/ExdBRar\n"
},
{
"QuestionId": "76378323",
"QuestionTitle": "Search Customers that are part of the logged on User's Business?",
"QuestionBody": "The code I currently have is this, in my views.py I can't figure out how to set up my search function. All other functions work.\nmodels.py\nclass User(AbstractUser):\n    \"\"\"User can be Employee or Customer\"\"\"\n\nclass Business(models.Model):\n    business = models.CharField(max_length=50)\n\nclass BusinessOwner(models.Model):\n    user = models.OneToOneField(User, on_delete=models.CASCADE, null=True )\n    business = models.ForeignKey(Business, on_delete=models.CASCADE, null=True)\n\nclass Customer(models.Model):\n    \"\"\" Customer-specific information \"\"\"\n    user = models.OneToOneField(User, on_delete=models.CASCADE, null=True )\n    business = models.ForeignKey(Business, on_delete=models.CASCADE, null=True)\n\nclass Employee(models.Model):\n    \"\"\" Employee-specific information \"\"\"\n    user = models.OneToOneField(User, on_delete=models.CASCADE, null=True)\n    business = models.ForeignKey(Business,  on_delete=models.CASCADE, null=True, blank=True)`\n\nforms.py\nclass UserForm(UserCreationForm):\n    class Meta:\n        model = User\n        fields = ( \"username\", \"email\", \"password1\", \"password2\", \"first_name\", \"last_name\", )\n\n\nclass BusinessOwnerForm(forms.ModelForm):\n. . . no fields\nclass EmployeeForm(forms.ModelForm):\n. . . no fields\n\nclass CustomerForm(forms.ModelForm):\n. . . no fields\n\nclass BusinessForm(forms.ModelForm):\n    class Meta:\n        model = Business\n        fields = ( \"business\",  )\n\nviews.py (user creation process)\ndef searchUsers(request):\n    qs_owned_businesses = BusinessOwner.objects.filter(user = request.user).values('business_id')\n    qs_biz_customers = Customer.objects.filter(business_id__in=qs_owned_businesses)\n    if request.method == \"GET\":\n        query = request.GET.get('search')\n        if query == '':\n            query = 'None'\n    results = User.objects.filter(username__icontains=query, id__in=qs_biz_customers)\n    return render(request, 'search_users.html', {'query': query, 'results': results})\n    \n    \n\n\n#example of hows employees and customers are created in my views:\ndef employeeCreation(request):\n    \"\"\"Creates an Employee\"\"\"\n    if request.method == \"POST\":\n        employee_form = EmployeeForm(request.POST)\n        user_creation_form = UserForm(request.POST)\n        if (user_creation_form.is_valid() and employee_form.is_valid()):\n            employee_form.instance.business = request.user.businessowner.business\n            new_user = user_creation_form.save(commit=False)\n            employee_form.instance.user = new_user\n            user_creation_form.save()\n            employee_form.save()\n            messages.success(request, \"You Have Created An Employee\" )\n            return redirect(\"user-homepage\")\n        else:\n            messages.error(request, \"Try creating an Employee Again something went wrong.\")\n    employee_form = EmployeeForm()\n    user_creation_form = UserForm()\n    return render (request, \"registration/employee_creation.html\", \n        context={\"user_creation_form\": user_creation_form, \n                \"employee_form\": employee_form,\n                    })\n\n\ndef customerCreation(request):\n. . . functions is exactly the same as employee creation just for a customer. The Business owner's business is used as a starting point to build employees off of. I didn't incldue that view because it's not necessary for this and stack overflow limits how much code I put here.\n\n\nsearch_users.html\n\n\n{% if results %}\n you Searched for {{ query }}  . . \n    {% for x in results %}\n        {{ x }}<p></p>\n    {% endfor %}\n\n{%endif %}```\nI have tried using Q, icontain ,.filter() and django-filter, but this is a tricky search criteria that I can't get to work.\nnavbar search feature:\n       <form action=\"{% url 'search-users' %}\" class=\"form-inline\" method=\"get\">\n      <div class=\"form-group mx-sm-3 mb-2\">\n      <label for=\"\" class=\"sr-only\">search</label>\n      <input name=\"search\" type=\"\" class=\"form-control\" id=\"\" placeholder=\"Keyword\">\n      </div>\n     <button type=\"submit\" class=\"btn btn-success btn-lg mb-2\">Search</button>\n</form>```\n\n",
"AnswerId": "76378505",
"AnswerBody": "Let's break this down into tasks. I'm using values() to limit the request to what we're interested in, as I can then use that result to filter further.\n#First you want to get all the businesses the logged in user owns\n#(Currently they can only own one, so you could use get rather than filter,\n#but you might change that later and this approach will still work)\nqs_owned_businesses = BusinessOwner.objects.filter(user = request.user).values('business_id')\n\n#next you want to get all the customers of those businesses\nqs_biz_customers = Customer.objects.filter(business_id__in= qs_owned_businesses).values('user_id')\n\n#finally you want to filter those customers further based on your form field\n#remember, the icontains criteria needs to refer to a field\n#here we're looking at username, but you might use last_name or something else.\nresults = User.objects.filter(username__icontains=query, id__in=qs_biz_customers)\n\nresults should now be a list of users you can cycle through in your template to show names, usernames etc.\n"
},
{
"QuestionId": "76378468",
"QuestionTitle": "Remove remote commits on the branch in GitHub",
"QuestionBody": "ALL,\nI made a local branch in my fork a long time ago and pushed some changes to it. I then submitted a PR which was passed the CI build.\nNow after some time I came back to the same machine I produced the PR but for some reason I didn't check which branch I was on and made couple of commits on the old branch and pushed them therefore screwing up the PR (it was not yet merged, due to the lack of the test code).\nNow what I'd like to do is go to Github Web interface, remove those commits, but keep them locally, because I can just generate a patch on my local machine, remove those commits, switch to the new branch and apply the patch to it.\nOr maybe even there is a better solution?\nSo how do I solve this mess?\nKeep in mind - I intend to finish the PR with the test, but those are 2 completely unrelated things.\nTIA!!\nEDIT:\nEverythig worked fine and my old branch on the original laptop is back to normal and the PR is now good.\nHowever, in order to put the unit test I had to go to a different machine and do a git pull. For some unknown reason after that the git tree on that machine becomes clogged with everything including the bad commit.\nI was able to revoke bad commits with git reset --hard N, but I fear that the same happen when I try to test my unit test on all platforms/different laptops which means my changes will be lost and I will need to redo them again for the UT on all different machines.\nCan you help me here as well?\nTIA!!\n",
"AnswerId": "76378523",
"AnswerBody": "After some thought, my original answer is more complicated than strictly necessary, but I'll leave it below.\nThe easiest way to get your original branch back to its old state and keep the new commits is to create a new branch then reset the old branch and force push. It looks like this:\ngit checkout old-branch\ngit branch new-branch\ngit reset --hard <hash of commit you want to keep in old-branch>\ngit push -f\n\nAlternatively you can use\ngit reset --hard HEAD~n\n\nwhere n is the number of commits you want to remove from the old branch.\nNow you can do whatever you wish with the new branch, such as rebase it onto main. This might not be entirely necessary. If for example, your PR is merged, you will need to pull those changes into the new branch anyway before making the second PR. However, if you want to make a 2nd PR before the 1st is merged, then it is better to keep them separate until one of them is merged.\nTLDR\nThe easiest way to fix a remote repository is to first make the changes locally and then push, possibly force push, to GitHub or other remote.\nDetails\nYou can do this all locally first, then push to GitHub to fix the PR. First, you should create a new branch and git cherry-pick the commits that you want to keep but remove from the other branch.\nStart by getting the hashes of the commits you want:\ngit checkout old-branch\ngit log --oneline --graph\n\nCopy the commit hashes for the commits you want to move. Then do\ngit checkout -b new-branch main\n\nand for each of the hashes you copied:\ngit cherry-pick <hash>\n\nAlternatively, you can do this more easily with git rebase. You only need the hash of the oldest commit you want to keep:\ngit checkout -b new-branch old-branch\ngit rebase --onto main <hash of oldest commit>~\n\nNow go back to your old branch and get rid of all the commits you no longer want:\ngit checkout old-branch\ngit reset --hard <hash of the first commit you want to keep on this branch>\n\nFinally force push:\ngit push -f\n\nThis will automatically update the PR back to its original state, if you used the correct hash for the git reset command.\n"
},
{
"QuestionId": "76378419",
"QuestionTitle": "How to use async properly to get chrome.storage?",
"QuestionBody": "I am creating a google chrome extension. On the popup, I am displaying a leaderboard. However, I am new to JavaScript so I don't know how to properly use async. I am using chrome.storage to get stored scores to display on the leaderboard, then sending them from background.js to score.js. My issue is that, since chrome.storage.get happens asynchronously, my findScores method does not wait for chrome.storage.get to finish before incorrectly returning a default empty score.\nHere is my code:\nbackground.js\nchrome.runtime.onMessage.addListener(\n    function(request, sender, sendResponse) {\n      console.log(sender.tab ?\n                  \"from a content script:\" + sender.tab.url :\n                  \"from the extension\");\n      if (request.type === \"request\") {\n        var scoresVar = findScores(request.table, \"All\");\n        console.log(\"Sending response \" + scoresVar);\n        sendResponse({scores: scoresVar})\n      } \n      else if (request.type === \"score\") {\n        saveScore(request.website, request.score, request.tab);\n        sendResponse(\"Finished adding score \" + request.score);\n      }\n    }\n);\n\nfunction findScores(table, website) {\n    const categories = table.split(\"-\");\n    if (categories.includes(\"personal\")) {\n        chrome.storage.sync.get([website], function(response) {\n            if (!(typeof response[website] === 'undefined')) {\n                console.log(\"Found \" + response[website]);\n                return response[website];\n            }\n        });\n    } else if (categories.includes(\"global\")){\n        // TODO: Add global leaderboards\n        return [\"-\"];\n    }\n    console.log(\"Didn't find, on default\");\n    return [\"-\"];\n}\n\npopup.js\nasync function requestScores(tableID) {\n  var url = \"All\"\n  if (tableID.includes(\"current\")) {\n    var url = await getCurrentTab();\n  }\n  console.log(\"Sending message to load scores to \" + url);\n  (async () => {\n    const response = await chrome.runtime.sendMessage({type: \"request\", request: \"load scores\", table: tableID, tab: url});\n    console.log(\"Received: \" + response);\n    // add scores to HTML DOM\n    });\n  })();\n}\n\n\nMy console messages reveal that I first return a default score, which is sent to popup.js. I have tried throwing async keywords in front of functions (as well as \"await\" in front of variables like scoresVar = await findScores(request.table, \"All\") but it just caused more issues, where findScores still returned a default value, but background.j instead sent an undefined promise.\nHow can I fix my code?\n",
"AnswerId": "76378558",
"AnswerBody": "It is simpler to work with Promises and async/await instead of callbacks. chrome.storage.sync.get returns a Promise if you do not pass a callback.\nasync function findScores(table, website) {\n    // ...\n    if (categories.includes(\"personal\")) {\n        const response = await chrome.storage.sync.get([website]);\n        if (response[website] !== undefined) {\n            console.log(\"Found \" + response[website]);\n            return response[website];\n        }\n    }\n    // ...\n}\n// ...\nchrome.runtime.onMessage.addListener(function(request, sender, sendResponse) {\n    // ...\n    findScores(request.table, \"All\").then(scores => {\n        console.log(\"Sending response \" + scores);\n        sendResponse({scores});\n    });\n    return true; // keep the messaging channel open for sendResponse\n});\n\nNote that the callback of onMessage should return a literal true value (documentation) in order to keep the internal messaging channel open so that sendResponse can work asynchronously.\n"
},
{
"QuestionId": "76383950",
"QuestionTitle": "How do I change the focus of the text field on Submit?",
"QuestionBody": "I have a text field and it has an onSubmit method, inside which I check for validation and then focus on another field, but for some reason the focus does not work\nonSubmitted: (value) {\n        //print(\"ga test\");\n\n        if (!widget.validator?.call(value)) {\n          setState(() {\n            showError = true;\n          });\n        }\n        if (widget.nextFocus != null) {\n          FocusScope.of(context).requestFocus(widget.nextFocus);\n        }\n\n      },\n\n",
"AnswerId": "76384028",
"AnswerBody": "I did so and it worked\nif (widget.validator != null) {\n          setState(() {\n            showError = !widget.validator?.call(value);\n          });\n        }\n        if (widget.nextFocus != null) {\n          FocusScope.of(context).requestFocus(widget.nextFocus);\n        }\n\n"
},
{
"QuestionId": "76380624",
"QuestionTitle": "Testng test are ignored after upgrading to Sprint Boot 3 and maven-surefire-plugin 3.1.0",
"QuestionBody": "I have an application that was executing TestNG tests perfectly with maven, for example, when using a mvn clean install command.\nCurrently I have updated the application to start using Spring Boot 3.1.0, and now the tests are completely ignored. No tests are executed.\nI am using a classic testng.xml file defined on the maven-surefire-plugin:\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-surefire-plugin</artifactId>\n                <version>${maven-surefire-plugin.version}</version>\n                <configuration>\n                    <suiteXmlFiles>\n                        <suiteXmlFile>src/test/resources/testng.xml</suiteXmlFile>\n                    </suiteXmlFiles>\n                </configuration>\n            </plugin>\n\nAll solutions I have found are related about the java classes ending on *Test.java but this is not applied as I am using the testng suite file. And before the update, the tests are working fine.\nWhat has been changed into Spring Boot 3 to skip my tests?\n",
"AnswerId": "76380646",
"AnswerBody": "Ok, I have found the \"issue\". Seems that the new versions of maven-surefire-plugin needs to include a surefire-testng extra plugin for executing it:\n           <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-surefire-plugin</artifactId>\n                <version>3.1.0</version>\n                <configuration>\n                    <suiteXmlFiles>\n                        <suiteXmlFile>src/test/resources/testng.xml</suiteXmlFile>\n                    </suiteXmlFiles>\n                </configuration>\n                <dependencies>\n                    <dependency>\n                        <groupId>org.apache.maven.surefire</groupId>\n                        <artifactId>surefire-testng</artifactId>\n                        <version>3.1.0</version>\n                    </dependency>\n                </dependencies>\n            </plugin>\n\nAfter including the dependency on the plugin, now is working fine.\n"
},
{
"QuestionId": "76380600",
"QuestionTitle": "Terragrunt - make dynamic group optional",
"QuestionBody": "I'm using Okta provider to create okta_app_oauth and okta_app_group_assignments. My module looks like:\nresource \"okta_app_oauth\" \"app\" {\n\n  label                      = var.label\n  type                       = var.type\n  grant_types                = var.grant_types\n  redirect_uris              = var.type != \"service\" ? var.redirect_uris : null\n  response_types             = var.response_types\n  login_mode                 = var.login_mode\n  login_uri                  = var.login_uri\n  post_logout_redirect_uris  = var.post_logout_redirect_uris\n  consent_method             = var.consent_method\n  token_endpoint_auth_method = var.token_endpoint_auth_method\n  pkce_required              = var.token_endpoint_auth_method == \"none\" ? true : var.pkce_required\n  lifecycle {\n    ignore_changes = [\n      client_basic_secret, groups\n    ]\n  }\n}\n\nresource \"okta_app_group_assignments\" \"app\" {\n  app_id = okta_app_oauth.app.id\n  dynamic \"group\" {\n    for_each = var.app_groups\n    content {\n      id       = group.value[\"id\"]\n      priority = group.value[\"priority\"]\n    }\n  }\n}\n\nAnd it works when I assign groups to application, but when I don't want to assign groups, I get error:\n│ Error: Invalid index\n│ \n│   on main.tf line 26, in resource \"okta_app_group_assignments\" \"app\":\n│   26:       id       = group.value[\"id\"]\n│     ├────────────────\n│     │ group.value is empty map of dynamic\n│ \n│ The given key does not identify an element in this collection value.\n\n\nin addition, my app_groups variable looks like:\nvariable \"app_groups\" {\n  description = \"Groups assigned to app\"\n  type        = list(map(any))\n  default     = [{}]\n}\n\nI was trying to use lookup(group, \"priority\", null), but it wasn't resolving my problem. Can somebody help me with solving this?\n",
"AnswerId": "76380785",
"AnswerBody": "You can make the block optional as follows:\n  dynamic \"group\" {\n    for_each = length(var.app_groups) > 0 : var.app_groups : []\n    content {\n      id       = group.value[\"id\"]\n      priority = group.value[\"priority\"]\n    }\n  }\n\nalso your default value for app_groups should be:\nvariable \"app_groups\" {\n  description = \"Groups assigned to app\"\n  type        = list(map(any))\n  default     = []\n}\n\n"
},
{
"QuestionId": "76378487",
"QuestionTitle": "Group by and select rows based on if value combinations exist",
"QuestionBody": "I have a table PetsTable:\n\n\n\n\nId\nType\nkey\nvalue\n\n\n\n\n1\n\"Cat\"\n10\n5\n\n\n1\n\"Cat\"\n9\n2\n\n\n2\n\"dog\"\n10\n5\n\n\n1\n\"Cat\"\n8\n4\n\n\n1\n\"Cat\"\n6\n3\n\n\n2\n\"dog\"\n8\n4\n\n\n2\n\"dog\"\n6\n3\n\n\n3\n\"Cat\"\n13\n5\n\n\n3\n\"Cat\"\n10\n0\n\n\n3\n\"Cat\"\n8\n0\n\n\n\n\nHow to insert this data into a new table MyPets from PetsTable with these conditions:\n\nGroup by Id\nOnly select rows when in the group exists (key = 10 and value = 5) and (key = 8 and value = 4) and (key = 6 and value = 3)\nIf exists key = 9, then mark hasFee = 1 else hasFee = 0\n\nFinal table should look like:\n\n\n\n\nId\nType\nhasFee\n\n\n\n\n1\n\"Cat\"\n1\n\n\n2\n\"dog\"\n0\n\n\n\n",
"AnswerId": "76378586",
"AnswerBody": "One approach is to use window functions to evaluate your conditions, which you can then apply as conditions using a CTE.\nThis creates the data you desire, its then trivial to insert into a table of your choice.\ncreate table Test (Id int, [Type] varchar(3), [Key] int, [Value] int);\n\ninsert into Test (Id, [Type], [Key], [Value])\nvalues\n(1, 'Cat', 10, 5),\n(1, 'Cat', 9,  2),\n(2, 'Dog', 10, 5),\n(1, 'Cat', 8,  4),\n(1, 'Cat', 6,  3),\n(2, 'Dog', 8,  4),\n(2, 'Dog', 6,  3),\n(3, 'Cat', 13, 5),\n(3, 'Cat', 10, 0),\n(3, 'Cat', 8,  0);\n\nwith cte as (\n  select *\n    , sum(case when [Key] = 10 and [Value] = 5 then 1 else 0 end) over (partition by Id) Cond1\n    , sum(case when [Key] = 8 and [Value] = 4 then 1 else 0 end) over (partition by Id) Cond2\n    , sum(case when [Key] = 6 and [Value] = 3 then 1 else 0 end) over (partition by Id) Cond3\n    , sum(case when [Key] = 9 then 1 else 0 end) over (partition by Id) HasFee\n  from Test\n)\nselect Id, [Type], HasFee\nfrom cte\nwhere Cond1 = 1 and Cond2 = 1 and Cond3 = 1\ngroup by Id, [Type], HasFee;\n\nReturns:\n\n\n\n\nId\nType\nHasFee\n\n\n\n\n1\nCat\n1\n\n\n2\nDog\n0\n\n\n\n\nNote: If you provide your sample data in this format (DDL+DML) you make it much easier for people to assist.\ndb<>fiddle\n"
},
{
"QuestionId": "76380579",
"QuestionTitle": "How to store multiple commands in a bash variable (similar to cat otherscript.sh)",
"QuestionBody": "For work I'm needing to connect to test nodes and establish a vnc connection so you can see the desktop remotely. It's a manual process with a bunch of commands that need to be executed in order. Perfect for automation using a bash script. The problem is that some commands need to be executed on the remote node after an ssh connection is established.\nCurrently I've got it working like this, where startVNC is a seperate bash file which stores the commands that need to be executed on the remote node after an ssh connection is established.\ncat startVNC | sed -e \"s/\\$scaling/$scaling/\" -e \"s/\\$address/$address/\" -e \"s/\\$display/$display/\" | ssh -X maintain@$host\n\nFor my question the contents of startVNC don't really matter, just that multiple commands can be executed in order. It could be:\necho \"hello\"\nsleep 1\necho \"world\"\n\nWhile for personal use this solution is fine, I find it a bit of a bother that this needs to be done using two separate bash files. If I want to share this file (which I do) it'd be better if it was just one file. My question is, is it possible to mimic the output from cat in some way using a variable?\n",
"AnswerId": "76380826",
"AnswerBody": "Well, you could do:\na=\"echo 'hello'\\nsleep 2\\necho world\\n\"\necho -e $a\n#  output-> echo 'hello'\n#  output-> sleep 2\n#  output-> echo world\necho -e $a | bash\n#  output-> hello\n#  waiting 2 secs\n#  output-> world\n\nThe -e in echo enables the interpretation of the \\n.\n"
},
{
"QuestionId": "76383957",
"QuestionTitle": "How to set ID header in Spring Integration Kafka Message?",
"QuestionBody": "I have a demo Spring Integration project which is receiving Kafka messages, aggregating them, and then releasing them. I'm trying to add JdbcMessageStore to the project. The problem is that it failing with error:\nCaused by: java.lang.IllegalArgumentException: Cannot store messages without an ID header\n    at org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.15.RELEASE.jar:5.2.15.RELEASE]\n    at org.springframework.integration.jdbc.store.JdbcMessageStore.addMessage(JdbcMessageStore.java:314) ~[spring-integration-jdbc-5.3.8.RELEASE.jar:5.3.8.RELEASE]\n\nAfter debugging I found that it requires the UUID header id in this message. But the problem is that I can't manually set the Kafka header id - it is forbidden (the same as timestamp header) - I tried to do this in Kafka producer in different project.\nIf I'm using IDEA plugin named Big Data Tools and send a message from there I'm able to set id header but it is received by my project as an array of bytes and it is failing with error\nIllegalArgumentException Incorrect type specified for header 'id'. Expected [UUID] but actual type is [B]\n\nI can't find any solution on how to resolve this issue. I need to set somehow this id header to be able to store messages in the database.\nThanks in advance\n",
"AnswerId": "76384041",
"AnswerBody": "The KafkaMessageDrivenChannelAdapter has an option:\n/**\n * Set the message converter to use with a record-based consumer.\n * @param messageConverter the converter.\n */\npublic void setRecordMessageConverter(RecordMessageConverter messageConverter) {\n\nWhere you can set a MessagingMessageConverter with:\n/**\n * Generate {@link Message} {@code ids} for produced messages. If set to {@code false},\n * will try to use a default value. By default set to {@code false}.\n * @param generateMessageId true if a message id should be generated\n */\npublic void setGenerateMessageId(boolean generateMessageId) {\n    this.generateMessageId = generateMessageId;\n}\n\n/**\n * Generate {@code timestamp} for produced messages. If set to {@code false}, -1 is\n * used instead. By default set to {@code false}.\n * @param generateTimestamp true if a timestamp should be generated\n */\npublic void setGenerateTimestamp(boolean generateTimestamp) {\n    this.generateTimestamp = generateTimestamp;\n}\n\nset to true.\nThis way the Message created from a ConsumerRecord will have respective id and timestamp headers.\nYou also simply can have a \"dummy\" transformer to return incoming payload and the framework will create a new Message where those headers are generated.\n"
},
{
"QuestionId": "76383902",
"QuestionTitle": "Concatenate onto Next Row",
"QuestionBody": "I have some SQL that does some manipulation to the data i.e. filling in empty columns.\nSELECT *,\n    ModifiedLineData = CASE\n        WHEN Column2 = '' AND LineData NOT LIKE ',,,0,,,,0'\n            THEN CONCAT(STUFF(LineData, CHARINDEX(',', LineData, CHARINDEX(',', LineData) + 1), 0, '\"No PO Number\"'), ',\"\"')\n        ELSE CONCAT(LineData, ',\"\"')\n    END\nFROM (\n    SELECT\n        *,\n        Column2 = CONVERT(XML, '<s>' + REPLACE((SELECT ISNULL(LineData, '') FOR XML PATH('')), ',', '</s><s>') + '</s>').value('/s[2]', 'varchar(100)')\n    FROM [dbo].[Temp_Raw_Data]\n    WHERE LineData NOT LIKE ',,,0,,,,0'\n) AS Subquery\n\nNow lets say this returns\n\n\n\n\nFileName\nLineNumber\nLineData\nColumn2\nModifiedLineData\n\n\n\n\nfile1\n4\n1232,,\"product-1\", 1,0\n\n1232,NA,\"product-1\", 1,0\n\n\nfile2\n7\n\"failed\"\nNULL\n\"failed\"\n\n\nfile3\n8\n1235,,\"product-2\", 1,0\n\n1235,NA,\"product-2\", 1,0\n\n\n\n\nHow can I modify this query so that if Column2 is NULL then it would concatenate the LineData onto the next row (ModifiedLineData) else just concatenate a ,\"\" and then remove that NULL result (if possible else it doesnt matter) so that my result would look like:\n\n\n\n\nFileName\nLineNumber\nLineData\nColumn2\nModifiedLineData\n\n\n\n\nfile1\n4\n1232,,\"product-1\", 1,0\n\n1232,NA,\"product-1\", 1,0,\"\"\n\n\nfile3\n8\n1235,,\"product-2\", 1,0\n\n1235,NA,\"product-2\", 1,0,\"failed\"\n\n\n\n\nI tried playing around with LEAD() but couldn't get it how i wanted.\nNote: Two null rows are not possible to be together. This is due to the nature of the data. The next row should simply be the next available row when selecting all rows as they are imported one by 1.\nUpdated Query that isn't concatenating:\nSELECT * \n  FROM (SELECT FileName, LineNumber, LineData, Column2, \n               CASE WHEN LAG(Column2) OVER(ORDER BY LineNumber) IS NULL\n                    THEN CONCAT_WS(', ',\n                                ModifiedLineData, \n                                LAG(ModifiedLineData) OVER(ORDER BY LineNumber))\n                    ELSE ModifiedLineData\n               END AS ModifiedLineData\n        FROM (\n        SELECT *,\n            ModifiedLineData = CASE\n                WHEN Column2 = '' AND LineData NOT LIKE ',,,0,,,,0'\n                    THEN CONCAT(STUFF(LineData, CHARINDEX(',', LineData, CHARINDEX(',', LineData) + 1), 0, '\"No PO Number\"'), '')\n                ELSE CONCAT(LineData, '')\n            END\n        FROM (\n            SELECT *,\n                Column2 = CONVERT(XML, '<s>' + REPLACE((SELECT ISNULL(LineData, '') FOR XML PATH('')), ',', '</s><s>') + '</s>').value('/s[2]', 'varchar(100)')\n            FROM [backstreet_WMS_Optimizer].[dbo].[Temp_GoodsIn_Raw_Data]\n            WHERE LineData NOT LIKE ',,,0,,,,0'\n        ) AS Subquery\n    ) AS cte\n) AS Subquery\nWHERE Column2 IS NOT NULL\norder by FileName, LineNumber\n\n",
"AnswerId": "76384109",
"AnswerBody": "Given that you can't have consecutive NULL values, using LEAD/LAG should be suitable for this task. Without knowledge of your original data, we can work on your query and add on top two subqueries, last of which is optional:\n\nthe inner adds the information needed to the record successive to \"Column2=NULL\" records\nthe outer removes records having those null values\n\nSELECT * \n  FROM (SELECT FileName, LineNumber, LineData, Column2, \n               CASE WHEN LAG(Column2) OVER(ORDER BY LineNumber) IS NULL\n                    THEN CONCAT_WS(', ',\n                                ModifiedLineData, \n                                LAG(ModifiedLineData) OVER(ORDER BY LineNumber))\n                    ELSE ModifiedLineData\n               END AS ModifiedLineData\n        FROM <your query>) cte\nWHERE Column2 IS NOT NULL \n\nOutput:\n\n\n\n\nFileName\nLineNumber\nLineData\nColumn2\nModifiedLineData\n\n\n\n\nfile1\n4\n1232,,\"product-1\", 1,0\n\n1232,NA,\"product-1\", 1,0\n\n\nfile3\n8\n1235,,\"product-2\", 1,0\n\n1235,NA,\"product-2\", 1,0\"failed\"\n\n\n\n\nCheck the demo here.\n"
},
{
"QuestionId": "76378480",
"QuestionTitle": "How do I get my main content to take up the rest of the space left over after the header and footer?",
"QuestionBody": "I'm working through The Odin Project and I'm having trouble making my main content take up the rest of the space of the browser.\nRight now it looks like this:\n\nThe 1px solid red border is as far as the main content goes. I have tried this but it's not allowing for a fixed header and footer. I have also tried some other flex solutions. Those are commented out in the code.\nAm I just doing this whole thing wrong? Is there a standard way that I don't know about?\nindex.html:\n<body>\n    <div class=\"header\">\n        <h1>\n            MY AWESOME WEBSITE\n        </h1>\n    </div>\n\n    <div class=\"main-content\">\n        <div class=\"sidebar\">\n            <ul>\n                <li><a href=\"#\">⭐ - link one</a></li>\n                <li><a href=\"#\">🦸🏽‍♂️ - link two</a></li>\n                <li><a href=\"#\">🖌️ - link three</a></li>\n                <li><a href=\"#\">👌🏽 - link four</a></li>\n            </ul>\n        </div>\n        <div class=\"content\">\n            <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Tempora, eveniet? Dolorem\n                dignissimos\n                maiores non delectus possimus dolor nulla repudiandae vitae provident quae, obcaecati ipsam unde impedit\n                corrupti veritatis minima porro?</div>\n            <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Quasi quaerat qui iure ipsam\n                maiores\n                velit tempora, deleniti nesciunt fuga suscipit alias vero rem, corporis officia totam saepe excepturi\n                odit\n                ea.\n            </div>\n            <div class=\"card\">Lorem ipsum dolor sit amet consectetur, adipisicing elit. Nobis illo ex quas, commodi\n                eligendi\n                aliquam ut, dolor, atque aliquid iure nulla. Laudantium optio accusantium quaerat fugiat, natus officia\n                esse\n                autem?</div>\n            <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus nihil impedit eius\n                amet\n                adipisci dolorum vel nostrum sit excepturi corporis tenetur cum, dolore incidunt blanditiis. Unde earum\n                minima\n                laboriosam eos!</div>\n            <div class=\"card\">Lorem ipsum dolor sit amet consectetur, adipisicing elit. Nobis illo ex quas, commodi\n                eligendi\n                aliquam ut, dolor, atque aliquid iure nulla. Laudantium optio accusantium quaerat fugiat, natus officia\n                esse\n                autem?</div>\n            <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus nihil impedit eius\n                amet\n                adipisci dolorum vel nostrum sit excepturi corporis tenetur cum, dolore incidunt blanditiis. Unde earum\n                minima\n                laboriosam eos!</div>\n        </div>\n    </div>\n\n    <div class=\"footer\">\n        The Odin Project ❤️\n    </div>\n</body>\n\n</html>\n\nstyle-07.css:\n:root{\n    --header-height: 72px;\n}\nbody {\n    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\n    margin: 0;\n    min-height: 100vh;\n    height: 100%;\n}\n\n.main-content{\n    display: flex;\n    height: 100%; /* If I use px units it will force the main content to go down but I know that is not ideal. */\n    padding-top: var(--header-height); \n    flex-direction: row;\n    border: 1px solid red;\n    /* Things I have tried from other answers*/\n    /* flex: 1 1 auto; */\n    /* height: calc(100% - var(--header-height)); */\n}\n\n.sidebar{\n    flex-shrink: 0;\n}\n\n.content {\n    padding: 32px;\n    display: flex;\n    flex-wrap: wrap;\n}\n\n.card {\n    width: 300px;\n    padding: 16px;\n    margin: 16px;\n}\n\n.header {\n    position: fixed;\n    top: 0;\n    left: 0;\n    right: 0;\n    display: flex;\n    align-items: center;\n    height: var(--header-height);\n    background: darkmagenta;\n    color: white;\n    padding: 0px 15px;\n}\n\nh1 {\n    font-weight: 1000;\n}\n\n.footer {\n    height: var(--header-height);\n    background: #eee;\n    color: darkmagenta;\n    position: fixed;\n    bottom: 0;\n    left: 0;\n    right: 0;\n    width: 100%;\n    height: 5%;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n}\n\n.sidebar {\n    width: 300px;\n    background: royalblue;\n    box-sizing: border-box;\n    padding: 16px;\n}\n\n.card {\n    border: 1px solid #eee;\n    box-shadow: 2px 4px 16px rgba(0, 0, 0, .06);\n    border-radius: 4px;\n}\n\nul{\n    list-style-type: none;\n    margin: 0;\n    padding: 0;\n}\n\na {\n    text-decoration: none;\n    color: white;\n    font-size: 24px;\n}\n\nli{\n    margin-bottom: 16px;\n}\n\n",
"AnswerId": "76378588",
"AnswerBody": "You can use flex diplay on body instead of using instead of fixed on header and footer and make the body display flex with column direction, then for main-content all you need is to set flex: 1 and remove padding top, flex: 1 will make sure that main-content take any remaining space in the parent. Set the body height to height: 100vh and overflow: hidden, for man-content, set overflow: auto.\nAdditionally, To make sidebar sticky when scrolling,  I added position: relative; to main-content and position: sticky; to the sidebar.\nTo force header and footer heights and prevent them to be squeezed by the flex position, use min-height instead of height as I modified in the code.\nTry to view the run code in full page, if you have any further questions, comment below.\n\n\n:root {\n  --header-height: 72px;\n}\n\nbody {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\n  margin: 0;\n  height: 100vh;\n  overflow:hidden;\n  \n  display: flex; \n  flex-direction: column;\n}\n\n.main-content {\n  flex: 1;\n  display: flex;\n  overflow-y: auto;\n  /* If I use px units it will force the main content to go down but I know that is not ideal. */\n  flex-direction: row;\n  border: 1px solid red;\n  /* Things I have tried from other answers*/\n  /* flex: 1 1 auto; */\n  /* height: calc(100% - var(--header-height)); */\n  \n  position: relative;\n}\n\n\n\n.content {\n  padding: 32px;\n  display: flex;\n  flex-wrap: wrap;\n}\n\n.card {\n  width: 300px;\n  padding: 16px;\n  margin: 16px;\n}\n\n.header {\n\n \n  display: flex;\n  align-items: center;\n  min-height: var(--header-height);\n  background: darkmagenta;\n  color: white;\n  padding: 0px 15px;\n}\n\nh1 {\n  font-weight: 1000;\n}\n\n.footer {\n  min-height: var(--header-height);\n  background: #eee;\n  color: darkmagenta;\n \n  width: 100%;\n  height: 5%;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n\n.sidebar {\n  width: 300px;\n  background: royalblue;\n  box-sizing: border-box;\n  padding: 16px;\n  \n  position: sticky;\n  top: 0;\n  \n  white-space: nowrap;\n  min-height: 250px;\n}\n\n.card {\n  border: 1px solid #eee;\n  box-shadow: 2px 4px 16px rgba(0, 0, 0, .06);\n  border-radius: 4px;\n}\n\nul {\n  list-style-type: none;\n  margin: 0;\n  padding: 0;\n}\n\na {\n  text-decoration: none;\n  color: white;\n  font-size: 24px;\n}\n\nli {\n  margin-bottom: 16px;\n}\n<body>\n  <div class=\"header\">\n    <h1>\n      MY AWESOME WEBSITE\n    </h1>\n  </div>\n\n  <div class=\"main-content\">\n    <div class=\"sidebar\">\n      <ul>\n        <li><a href=\"#\">⭐ - link one</a></li>\n        <li><a href=\"#\">🦸🏽‍♂️ - link two</a></li>\n        <li><a href=\"#\">🖌️ - link three</a></li>\n        <li><a href=\"#\">👌🏽 - link four</a></li>\n      </ul>\n    </div>\n    <div class=\"content\">\n      <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Tempora, eveniet? Dolorem dignissimos maiores non delectus possimus dolor nulla repudiandae vitae provident quae, obcaecati ipsam unde impedit corrupti veritatis minima porro?</div>\n      <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Quasi quaerat qui iure ipsam maiores velit tempora, deleniti nesciunt fuga suscipit alias vero rem, corporis officia totam saepe excepturi odit ea.\n      </div>\n      <div class=\"card\">Lorem ipsum dolor sit amet consectetur, adipisicing elit. Nobis illo ex quas, commodi eligendi aliquam ut, dolor, atque aliquid iure nulla. Laudantium optio accusantium quaerat fugiat, natus officia esse autem?\n      </div>\n      <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus nihil impedit eius amet adipisci dolorum vel nostrum sit excepturi corporis tenetur cum, dolore incidunt blanditiis. Unde earum minima laboriosam eos!</div>\n      <div class=\"card\">Lorem ipsum dolor sit amet consectetur, adipisicing elit. Nobis illo ex quas, commodi eligendi aliquam ut, dolor, atque aliquid iure nulla. Laudantium optio accusantium quaerat fugiat, natus officia esse autem?\n      </div>\n      <div class=\"card\">Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus nihil impedit eius amet adipisci dolorum vel nostrum sit excepturi corporis tenetur cum, dolore incidunt blanditiis. Unde earum minima laboriosam eos!</div>\n    </div>\n  </div>\n\n  <div class=\"footer\">\n    The Odin Project ❤️\n  </div>\n</body>\n\n</html>\n\n\n\n"
},
{
"QuestionId": "76384080",
"QuestionTitle": "Can't initialize variables inside of when statement in Kotlin",
"QuestionBody": "For whatever reason, my Kotlin program won't initialize variables assigned inside a when statement. Here's the code:\nimport kotlin.random.Random\nimport kotlin.random.nextInt\n\nval mood: String\n\nwhen(Random.nextInt(1..2)) {\n    1 -> {\n        mood = \"loud\"\n        println(\"$mood\")\n    }\n    2 -> {\n        mood = \"quiet\"\n        println(\"$mood\")\n    }\n}\n\nprintln(\"$mood\")\n\nThe lines inside the when statement are printed, but when I run the last line, I get a \"Variable 'mood' must be initialized\" error.\nI don't know what I could possibly be doing wrong here...\n",
"AnswerId": "76384128",
"AnswerBody": "In Kotlin, variables declared with the val keyword must be initialized at the point of declaration or in the constructor of the class. In your code, the mood variable is declared without an initial value, and you are trying to assign values to it inside the when statement. However, the compiler is unable to determine if either of the branches will be executed at runtime, so it doesn't consider the variable as fully initialized.\nTo fix this issue, you can either declare the mood variable as a var instead of a val or assign an initial value to it when declaring it. Here's an updated version of your code using a var:\nimport kotlin.random.Random\nimport kotlin.random.nextInt\nvar mood: String\n\nwhen (Random.nextInt(1..2)) {\n    1 -> {\n        mood = \"loud\"\n        println(\"$mood\")\n    }\n    2 -> {\n        mood = \"quiet\"\n        println(\"$mood\")\n    }\n}\n\nprintln(\"$mood\")\n\nBy using a var instead of a val, you indicate that the variable can be reassigned later. Since the mood variable is assigned within both branches of the when statement, the compiler no longer complains about it being uninitialized.\nNote that the order of the when branches should cover all possible cases, otherwise you might encounter a \"when expression must be exhaustive\" warning. In your case, the range of nextInt is 1 to 2, so the two branches should be sufficient.\n"
},
{
"QuestionId": "76380728",
"QuestionTitle": "Flutter Deep Link Firebase in iOS",
"QuestionBody": "My deep link works fine on Android and transfers information to the app, but it doesn't work on iOS\nFirebase Link\nhttps://dvzpl.com\n\nmy short link\nhttps://dvzpl.com/6BG2\n\nmy domain\nhttps://dovizpanel.com/\n\nmy associated domain\n<dict>\n    <key>aps-environment</key>\n    <string>development</string>\n    <key>com.apple.developer.associated-domains</key>\n    <array>\n        <string>webcredentials:dvzpl.com</string>\n        <string>applinks:dvzpl.com</string>\n    </array>\n</dict>\n\nhow to fix ?\nWhen I open the short link in the browser, it goes into the app but does not transfer the data in ios , android working not problams\n<key>FirebaseDynamicLinksCustomDomains</key>\n<array>\n    <string>https://dovizpanel.com/blog</string>\n    <string>https://dovizpanel.com/exchanger</string>\n    <string>https://dovizpanel.com/link</string>\n</array>\n\n",
"AnswerId": "76380908",
"AnswerBody": "If you are using a custom domain for firebase dynamic links follow the instructions below:\nIn your Xcode project's Info.plist file, create a key called FirebaseDynamicLinksCustomDomains and set it to your app's Dynamic Links URL prefixes. For example:\n<key>FirebaseDynamicLinksCustomDomains</key>\n<array>\n  <string>https://dvzpl.com</string>\n</array>\n\nYou can find more details directly in the Firebase documentation.\n"
},
{
"QuestionId": "76384218",
"QuestionTitle": "How to toggle/display content individually in ReactJS",
"QuestionBody": "my question is how can I toggle/display the \"Some text\" content on onClick individually?.\nI can use different function and state for every div an it is working but I know this is not the correct way to do it .\nCan you help me with this guys? Thanks\nThis is my code\nfunction App() {\n  const [loaded, setLoaded] = useState(true);\n  const [show, setShow] = useState(false);\n\n  const handleShow = () => {\n    setShow(!show);\n  };\n\n  return (\n    <div className={styles.App}>\n      {loaded && (\n        <div className={styles.cards_container}>\n          <div className={styles.card_container} onClick={handleShow}>\n            <h3>Title</h3>\n            {show && (\n              <div>\n                <p>Some text</p>\n              </div>\n            )}\n          </div>\n          <div className={styles.card_container} onClick={handleShow}>\n            <h3>Title</h3>\n            {show && (\n              <div>\n                <p>Some text</p>\n              </div>\n            )}\n          </div>\n          <div className={styles.card_container} onClick={handleShow}>\n            <h3>Title</h3>\n            {show && (\n              <div>\n                <p>Some text</p>\n              </div>\n            )}\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n\n",
"AnswerId": "76384269",
"AnswerBody": "You could create a custom component for your card that handles the state for each card:\nfunction Card() {\n    const [show, setShow] = useState(false);\n\n    const handleShow = () => {\n      setShow(state => !state);\n    };\n\n    return <div className={styles.card_container} onClick={handleShow}>\n      <h3>Title</h3>\n\n      {show && (\n          <div>\n            <p>Some text</p>\n          </div>\n      )}\n    </div>\n}\n\nAnd use it in your app:\nfunction App() {\n  const [loaded, setLoaded] = useState(true);\n\n  return (\n    <div className={styles.App}>\n      {loaded && (\n        <div className={styles.cards_container}>\n          <Card />\n          <Card />\n          <Card />\n        </div>\n      )}\n    </div>\n  );\n}\n\n"
},
{
"QuestionId": "76383839",
"QuestionTitle": "Revoking permission to install plugins?",
"QuestionBody": "The following query was used as part of a security audit to identify users with access to install/uninstall server plugins at the database level.\nSELECT user, host FROM mysql.db WHERE db = 'mysql' and (insert_priv='y') or (delete_priv='y') or (insert_priv='y' and delete_priv='y');\n\nI need to revoke that permission from the users that are listed.  Is there a specific privilege I revoke to do this? If so, I can't find it.  Or would I simply UPDATE the insert_priv and delete_priv fields directly in the mysql.db table?  I'm not a DBA but the closest thing we have at the moment.\n",
"AnswerId": "76384284",
"AnswerBody": "You are able to install plugins when you have INSERT permissions on the mysql.plugin table, see INSTALL PLUGIN:\n\nTo use INSTALL PLUGIN, you must have the INSERT privilege for the mysql.plugin table.\n\nSo when you have database wide INSERT permissions on the (internal administrative) database mysql, then you can install plugins.\nThe same goes for the UNINSTALL PLUGIN statement, see UNINSTALL PLUGIN\n\nTo use UNINSTALL PLUGIN, you must have the DELETE privilege for the mysql.plugin table.\n\nRemove the insert_priv and delete_priv privileges for the mysql database, your \"normal\" MySQL user accounts shouldn't be able to write in this database anyway.\n"
},
{
"QuestionId": "76378670",
"QuestionTitle": "pandas dataframe query not working with where",
"QuestionBody": "I am new to pandas, I have this data frame:\ndf['educ1']\nwhich gives\n1        4\n2        3\n3        3\n4        4\n5        1\n        ..\n28461    3\n28462    2\n28463    3\n28464    2\n28465    4\nName: educ1, Length: 28465, dtype: int64\n\nwhen I try querying with\ndt=df[df.educ1 > 1]\n\nIt's working fine returning multiple rows, but when I try\ncollege_grad_mask=(df.educ1 > 1)\ndf.where(college_grad_mask).dropna().head()\n\nIt gives 0 rows, I wonder what is wrong here?\n",
"AnswerId": "76378715",
"AnswerBody": "You likely have NaNs in many columns, try to subset:\ndf.where(college_grad_mask).dropna(subset=['educ1']).head()\n\nOr better:\ndf[college_grad_mask].head()\n\n"
},
{
"QuestionId": "76378383",
"QuestionTitle": "Problem when scoring new data -- tidymodels",
"QuestionBody": "I'm learning tidymodels. The following code runs nicely:\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Draw a random sample of 2000 to try the models\n\nset.seed(1234)\n\ndiamonds <- diamonds %>%    \n  sample_n(2000)\n  \ndiamonds_split <- initial_split(diamonds, prop = 0.80, strata=\"price\")\n\ndiamonds_train <- training(diamonds_split)\ndiamonds_test <- testing(diamonds_split)\n\nfolds <- rsample::vfold_cv(diamonds_train, v = 10, strata=\"price\")\n\nmetric <- metric_set(rmse,rsq,mae)\n\n# Model KNN \n\nknn_spec <-\n  nearest_neighbor(\n    mode = \"regression\", \n    neighbors = tune(\"k\"),\n    engine = \"kknn\"\n  ) \n\nknn_rec <-\n  recipe(price ~ ., data = diamonds_train) %>%\n  step_log(all_outcomes()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors())\n\nknn_wflow <- \n  workflow() %>% \n  add_model(knn_spec) %>%\n  add_recipe(knn_rec)\n\nknn_grid = expand.grid(k=c(1,5,10,30))\n\nknn_res <- \n  tune_grid(\n    knn_wflow,\n    resamples = folds,\n    metrics = metric,\n    grid = knn_grid\n  )\n\ncollect_metrics(knn_res)\nautoplot(knn_res)\n\nshow_best(knn_res,metric=\"rmse\")\n\n# Best KNN \n\nbest_knn_spec <-\n  nearest_neighbor(\n    mode = \"regression\", \n    neighbors = 10,\n    engine = \"kknn\"\n  ) \n\nbest_knn_wflow <- \n  workflow() %>% \n  add_model(best_knn_spec) %>%\n  add_recipe(knn_rec)\n\nbest_knn_fit <- last_fit(best_knn_wflow, diamonds_split)\n\ncollect_metrics(best_knn_fit)\n\n\nBut when I try to fit the best model on the training set and applying it to the test set I run into problems. The following two lines give me the error : \"Error in step_log():\n! The following required column is missing from new_data in step 'log_mUSAb': price.\nRun rlang::last_trace() to see where the error occurred.\"\n# Predict Manually\n\nf1 = fit(best_knn_wflow,diamonds_train)\np1 = predict(f1,new_data=diamonds_test)\n\n",
"AnswerId": "76378734",
"AnswerBody": "This problem is related to log transform outcome variable in tidymodels workflow\nFor log transformations to the outcome, we strongly recommend that those transformation be done before you pass them to the recipe(). This is because you are not guaranteed to have an outcome when predicting (which is what happens when you last_fit() a workflow) on new data. And the recipe fails.\nYou are seeing this here as when you predict on a workflow() object, it only passes the predictors, as it is all that it needs. Hence why you see this error.\nSince log transformations isn't a learned transformation you can safely do it before.\ndiamonds_train$price <- log(diamonds_train$price)\n\nif (!is.null(diamonds_test$price)) {\n  diamonds_test$price <- log(diamonds_test$price)\n}\n\n"
},
{
"QuestionId": "76380693",
"QuestionTitle": "How to name a term created in the formula when calling `lm()`?",
"QuestionBody": "Is it possible to name a term created in a formula? This is the scenario:\nCreate a toy dataset:\nset.seed(67253)\nn <- 100\nx <- sample(c(\"A\", \"B\", \"C\"), size = n, replace = TRUE)\ny <- sapply(x, switch, A = 0, B = 2, C = 1) + rnorm(n, 2)\ndat <- data.frame(x, y)\nhead(dat)\n#>   x         y\n#> 1 B 4.5014474\n#> 2 C 4.0252796\n#> 3 C 2.4958761\n#> 4 C 0.6725571\n#> 5 B 4.3364206\n#> 6 C 3.9798909\n\nFit a regression model:\nout <- lm(y ~ x, dat)\nsummary(out)\n#> \n#> Call:\n#> lm(formula = y ~ x, data = dat)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -2.07296 -0.52161 -0.03713  0.53898  2.12497 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   2.1138     0.1726  12.244  < 2e-16 ***\n#> xB            1.6772     0.2306   7.274 9.04e-11 ***\n#> xC            0.5413     0.2350   2.303   0.0234 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.9297 on 97 degrees of freedom\n#> Multiple R-squared:  0.3703, Adjusted R-squared:  0.3573 \n#> F-statistic: 28.52 on 2 and 97 DF,  p-value: 1.808e-10\n\nFit the model again, but use \"C\" as the reference group:\nout2 <- lm(y ~ relevel(factor(x), ref = \"C\"), dat)\nsummary(out2)\n#> \n#> Call:\n#> lm(formula = y ~ relevel(factor(x), ref = \"C\"), data = dat)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -2.07296 -0.52161 -0.03713  0.53898  2.12497 \n#> \n#> Coefficients:\n#>                                Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)                      2.6551     0.1594  16.653  < 2e-16 ***\n#> relevel(factor(x), ref = \"C\")A  -0.5413     0.2350  -2.303   0.0234 *  \n#> relevel(factor(x), ref = \"C\")B   1.1359     0.2209   5.143 1.41e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.9297 on 97 degrees of freedom\n#> Multiple R-squared:  0.3703, Adjusted R-squared:  0.3573 \n#> F-statistic: 28.52 on 2 and 97 DF,  p-value: 1.808e-10\n\nThe variable, x, was re-leveled in the second call to lm(). This is done in the formula and so the name of this term is relevel(factor(x), ref = \"C\").\nCertainly, we can create the term before calling lm(), e.g.:\ndat$x2 <- relevel(factor(x), ref = \"C\")\nout3 <- lm(y ~ x2, dat)\nsummary(out3)\n#> \n#> Call:\n#> lm(formula = y ~ x2, data = dat)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -2.07296 -0.52161 -0.03713  0.53898  2.12497 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   2.6551     0.1594  16.653  < 2e-16 ***\n#> x2A          -0.5413     0.2350  -2.303   0.0234 *  \n#> x2B           1.1359     0.2209   5.143 1.41e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.9297 on 97 degrees of freedom\n#> Multiple R-squared:  0.3703, Adjusted R-squared:  0.3573 \n#> F-statistic: 28.52 on 2 and 97 DF,  p-value: 1.808e-10\n\nHowever, can I create a term and name it in the formula? If yes, how?\n",
"AnswerId": "76380922",
"AnswerBody": "adapted from the info in this comment : Rename model terms in lm object for forecasting\nset.seed(67253)\nn <- 100\nx <- sample(c(\"A\", \"B\", \"C\"), size = n, replace = TRUE)\ny <- sapply(x, switch, A = 0, B = 2, C = 1) + rnorm(n, 2)\ndat <- data.frame(x, y)\n\nout <- lm(y ~ x, dat)\nsummary(out)\n\nout2 <- lm(y ~ x2, transform(dat,\n                             x2=relevel(factor(x), ref = \"C\")))\nsummary(out2)\n\n"
},
{
"QuestionId": "76378708",
"QuestionTitle": "Translating Stata to R yields different results",
"QuestionBody": "I am trying to translate a Stata code from a paper into R.\nThe Stata code looks like this:\ng tau = year - temp2 if temp2 > temp3 & (bod<. | do<. | lnfcoli<.)\n\nMy R translation looks like this:\ndata <- data %>%\n  mutate(tau = if_else((temp2 > temp3) & \n                         (is.na(bod) | is.na(do) | is.na(lnfcoli)), \n                       year - temp2,\n                       NA_integer_))\n\nThe problem is that when I run each code I get different results.\nThis is the result I get when I run the code in Stata:\n1   Year |  temp2  |  temp3 | bod | do  | lnfcoli | tau |\n2   1986 |  1995   |  1986  | 3.2 | 7.2 | 2.1.    |  -9 |\n\nThis is the result I get when I run the code in R:\n1   Year |  temp2  |  temp3 | bod | do  | lnfcoli | tau |\n2   1986 |  1995   |  1986  | 3.2 | 7.2 | 2.1.    |  NA |\n\nDo you know what might be wrong with my R code or what should I modify to get the same output?\n",
"AnswerId": "76378750",
"AnswerBody": "None of bod, do or lnfcoli are missing (NA), so your logic returns FALSE and returns NA_integer_ (false= in the if_else). Stata treats . or missing values as positive infinity, so that check is actually looking for not missing.\nSo the equivalent in R/dplyr is probably:\ndata %>%\n    mutate(\n        tau = if_else(\n        (temp2 > temp3) & (!(is.na(bod) | is.na(do) | is.na(lnfcoli))),\n        year-temp2,\n        NA_integer_\n        )\n    )\n\n#  year temp2 temp3 bod  do lnfcoli tau\n#1 1986  1995  1986 3.2 7.2     2.1  -9\n\n"
},
{
"QuestionId": "76383859",
"QuestionTitle": "Why sometimes local class cannot access constexpr variables defined in function scope",
"QuestionBody": "This c++ code cannot compile:\n#include <iostream>\n\nint main()\n{\n    constexpr int kInt = 123;\n    struct LocalClass {\n        void func(){\n            const int b = std::max(kInt, 12); \n            //                     ^~~~  \n            // error: use of local variable with automatic storage from containing function\n            std::cout << b;\n        }\n    };\n    LocalClass a;\n    a.func();\n    return 0;\n}\n\nBut this works:\n#include <iostream>\n#include <vector>\n\nint main()\n{\n    constexpr int kInt = 123;\n    struct LocalClass {\n        void func(){\n            const int b = std::max((int)kInt, 12); // added an extra conversion \"(int)\"\n            std::cout << b;\n            const int c = kInt; // this is also ok\n            std::cout << c;\n            const auto d = std::vector{kInt}; // also works\n            std::cout << d[0];\n        }\n    };\n    LocalClass a;\n    a.func();\n    return 0;\n}\n\nTested under C++17 and C++20, same behaviour.\n",
"AnswerId": "76384297",
"AnswerBody": "1. odr-using local entities from nested function scopes\nNote that kInt still has automatic storage duration - so it is a local entity as per:\n\n6.1 Preamble [basic.pre]\n(7) A local entity is a variable with automatic storage duration, [...]\n\n\nIn general local entities cannot be odr-used from nested function definitions (as in your LocalClass example)\nThis is given by:\n\n6.3 One-definition rule [basic.def.odr]\n(10) A local entity is odr-usable in a scope if:\n[...]\n(10.2) for each intervening scope between the point at which the entity is introduced and the scope (where *this is considered to be introduced within the innermost enclosing class or non-lambda function definition scope), either:\n\nthe intervening scope is a block scope, or\nthe intervening scope is the function parameter scope of a lambda-expression that has a simple-capture naming the entity or has a capture-default, and the block scope of the lambda-expression is also an intervening scope.\n\nIf a local entity is odr-used in a scope in which it is not odr-usable, the program is ill-formed.\n\nSo the only times you can odr-use a local variable within a nested scope are nested block scopes and lambdas which capture the local variable.\ni.e.:\nvoid foobar() {\n    int x = 0;\n\n    {\n        // OK: x is odr-usable here because there is only an intervening block scope\n        std::cout << x << std::endl;\n    }\n\n    // OK: x is odr-usable here because it is captured by the lambda\n    auto l = [&]() { std::cout << x << std::endl; };\n\n    // NOT OK: There is an intervening function definition scope\n    struct K {\n      int bar() { return x; }\n    };\n}\n\n11.6 Local class declarations [class.local] contains a few examples of what is and is not allowed, if you're interested.\n\nSo if use of kInt constitutes an odr-use, your program is automatically ill-formed.\n2. Is naming kInt always an odr-use?\nIn general naming a variable constitutes an odr-use of that variable:\n\n6.3 One-definition rule [basic.def.odr]\n(5) A variable is named by an expression if the expression is an id-expression that denotes it. A variable x that is named by a potentially-evaluated expression E is odr-used by E unless [...]\n\nBut because kInt is a constant expression the special exception (5.2) could apply:\n\n6.3 One-definition rule [basic.def.odr]\n(5.2) x is a variable of non-reference type that is usable in constant expressions and has no mutable subobjects, and E is an element of the set of potential results of an expression of non-volatile-qualified non-class type to which the lvalue-to-rvalue conversion is applied, or\n\nSo naming kInt is not deemed an odr-use as long as it ...\n\nis of non-reference type (✓)\nis usable in constant expressions (✓)\ndoes not contain mutable members (✓)\n\nand the expression that contains kInt ...\n\nmust produce a non-volatile-qualified non-class type (✓)\nmust apply the lvalue-to-rvalue conversion (?)\n\nSo we pass almost all the checks for the naming of kInt to not be an odr-use, and therefore be well-formed.\nThe only condition that is not always true in your example is the lvalue-to-rvalue conversion that must happen.\nIf the lvalue-to-rvalue conversion does not happen (i.e. no temporary is introduced), then your program is ill-formed - if it does happen then it is well-formed.\n// lvalue-to-rvalue conversion will be applied to kInt:\n// (well-formed)\nconst int c = kInt;  \nstd::vector v{kInt}; // vector constructor takes a std::size_t\n\n// lvalue-to-rvalue conversion will NOT be applied to kInt:\n// (it is passed by reference to std::max)\n// (ill-formed)\nstd::max(kInt, 12); // std::max takes arguments by const reference (!)\n\nThis is also the reason why std::max((int)kInt, 12); is well-formed - the explicit cast introduces a temporary variable due to the lvalue-to-rvalue conversion being applied.\n"
},
{
"QuestionId": "76380850",
"QuestionTitle": "How do I keep and append placeholder text into the selected value in React Select?",
"QuestionBody": "Let's say I have a React Select with a placeholder ('Selected Value: '), and I want to keep the placeholder and append it into the selected value so that it looks something like ('Selected Value: 1'). Is there any way to do it?\nimport Select from \"react-select\";\n\nexport default function App() {\n  const options = [\n    { value: 1, label: 1 },\n    { value: 2, label: 2 },\n    { value: 3, label: 3 },\n    { value: 4, label: 4 }\n  ];\n  const placeholder = \"Selected Value: \";\n  return (\n    <div className=\"App\">\n      <Select options={options} placeholder={placeholder} />\n    </div>\n  );\n}\n\ncodesandbox: https://codesandbox.io/s/brave-chatterjee-pjol2d?file=/src/App.js:23-385\nEDIT: Sorry, forget to mention, I do not want the placeholder to directly be in the labels of the options\n",
"AnswerId": "76380929",
"AnswerBody": "you can accept my answer\nimport Select from \"react-select\";\nimport { useState } from \"react\";\n\nexport default function App() {\n  const [selectBoxValue, setSelectBoxValue] = useState('')\n  const options = [\n    { value: 1, label: 1 },\n    { value: 2, label: 2 },\n    { value: 3, label: 3 },\n    { value: 4, label: 4 }\n  ];\n  const placeholder = `Selected Value: ${selectBoxValue}`;\n  return (\n    <div className=\"App\">\n      <Select \n      options={options} \n      placeholder={placeholder} \n      value={placeholder}\n      onChange={(event) => setSelectBoxValue(event.value)} />\n    </div>\n  );\n}\n\n"
},
{
"QuestionId": "76380934",
"QuestionTitle": "Method not allowed, flask, python",
"QuestionBody": "Installed FlareSolverr in docker.\ncURL work correctly and return the correct response.\ncurl -L -X POST 'http://localhost:8191/v1' -H 'Content-Type: application/json' --data-raw '{\n  \"cmd\": \"request.get\",\n  \"url\":\"http://google.com\",\n  \"maxTimeout\": 60000\n}'\n\nbut when using from python + flask I get an error - 405 Method is not allowed\ndef get_parsed_page(url, delay=0.5):\ndata = {\n    \"cmd\": \"request.get\",\n    \"url\": url,\n    \"maxTimeout\": 60000\n}\nheaders = {\"Content-Type\": \"application/json\"}\ntime.sleep(delay)\nprint(requests.get(\"***:8191/v1\", headers=headers, data=data))\nreturn BeautifulSoup(requests.get(\"***:8191/v1\", headers=headers, data=data).text, 'lxml')\n\n",
"AnswerId": "76380982",
"AnswerBody": "you are using a GET request in your python code. It should be a POST request. Use requests.post\n"
},
{
"QuestionId": "76378592",
"QuestionTitle": "Can't not write three value in 1 line",
"QuestionBody": "I was having this problem about last week in this code\na = int(input())\nb = int(input())\nc = int(input())\nprint(min(a+b,b+c,c+a))\n\n\nso when I enter three input like this: 2 5 6 (three interger in 1 line)\nIt show me a error:\n\nFile \"c:\\Users\\Administrator\\Documents\\Code\\Python\\baitap(LQDOJ)\\EZMIN.py\", line 1, in <module>\n    a = int(input())\nValueError: invalid literal for int() with base 10: '2 5 6' \n\nand I see that it only identify 'a' but not identify 'b' , 'c' so can you show me how to fix it or are there other ways to write it in 1 line?\n",
"AnswerId": "76378760",
"AnswerBody": "Method 1\nThe error you're encountering is because you're trying to convert the entire string '2 5 6' into an integer using the int() function. However, the int() function expects a single integer value, not a string containing multiple numbers.\ncode:\na = int(input())\nb = int(input())\nc = int(input())\n\nx = a + b\ny = b + c\nz = c + a\n\nmin_value = x\nif y < min_value:\n    min_value = y\nif z < min_value:\n    min_value = z\n\nprint(\"The minimum value is:\", min_value)\n\nyou'll be prompted to enter the values for a, b, and c separately, and the code will correctly calculate and display the minimum value among the three sums.\nMethod 2\nUsing This one is more optimize solution\ninput_values = input()\ninput_list = list(map(int, input_values.split()))\n\nmin_value = min(input_list[0] + input_list[1], input_list[1] + input_list[2], input_list[2] + input_list[0])\n\nprint(\"The minimum value is:\", min_value)\n\n\nThe split() method splits the input string at spaces, creating a list of string elements.\nThe map() function applies the int() function to each element of the split list, converting them into integers.\nlist() is used to convert the resulting map object into a list of integers.\nThe resulting list is stored in input_list for further calculations.\n\n"
},
{
"QuestionId": "76383945",
"QuestionTitle": "Typescript type extension",
"QuestionBody": "I try to define a custom interfaces like this :\nexport interface IAPIRequest<B extends any, P extends any, Q extends any>\n{\n  body: B;\n  params: P;\n  query: Q;\n}\n\nThis type is supposed to be extended in a lot of other types for each request mu API is supposed to handle.\nFor example :\nexport interface ILoginRequest extends IAPIRequest<{ email: string; password: string; }>, undefined, undefined> {}\n\nIt works a little but everytime I use this interface, I must provide all the properties even if they are undefined.\nExample:\nconst login = async ({ body }: ILoginRequest) => \n{\n  ...\n}\n\nconst response = await login({ body: { email: 'mail@test.com', password: 'verystrongpassword' }, params: undefined, query: undefined });\n\nIt doesn't work if I don't provide the undefined properties.\nHow can I define an abstract type for IAPIRequest that would avoid me from providing undefined values ?\nPS : I've tried this as well\nexport interface IAPIRequest<B extends any, P extends any, Q extends any>\n{\n  body?: B;\n  params?: P;\n  query?: Q;\n}\n\nEven for IAPIRequest<B, P, Q> where none of B, P, or Q allow undefined, I still get that the properties might be undefined\n",
"AnswerId": "76384326",
"AnswerBody": "TypeScript doesn't automatically treat properties that accept undefined to be optional (although the converse, treating optional properties as accepting undefined, is true, unless you've enabled --exactOptionalPropertyTypes).  There is a longstanding open feature request for this at microsoft/TypeScript#12400 (the title is about optional function parameters, not object properties, but the issue seems to have expanded to include object properties also).  Nothing has been implemented there, although the discussion describes various workarounds.\nLet's define our own workaround; a utility type UndefinedIsOptional<T> that produces a version of T such that any property accepting undefined is optional.  It could look like this:\ntype UndefinedIsOptional<T extends object> = (Partial<T> &\n    { [K in keyof T as undefined extends T[K] ? never : K]: T[K] }\n) extends infer U ? { [K in keyof U]: U[K] } : never\n\nThat's a combination of Partial<T> which turns all properties optional, and a key remapped type that suppresses all undefined-accepting properties.  The intersection of those is essentially what you want (an intersection of an optional prop and a required prop is a required prop) but I use a technique described at How can I see the full expanded contract of a Typescript type? to display the type in a more palatable manner.\nThen we can define your type as\ntype IAPIRequest<B, P, Q> = UndefinedIsOptional<{\n    body: B;\n    params: P;\n    query: Q;\n}>\n\nand note that this must be a type alias and not an interface because the compiler needs to know exactly which properties will appear (and apparently their optional-ness) to be an interface.  This won't matter much with your example code but you should be aware of it.\nLet's test it out:\ntype ILR = IAPIRequest<{ email: string; password: string; }, undefined, undefined>\n/* type ILR = {\n    body: {\n        email: string;\n        password: string;\n    };\n    params?: undefined;\n    query?: undefined;\n} */\n\nThat looks like what you wanted, so you can define your ILoginRequest interface:\ninterface ILoginRequest extends IAPIRequest<\n    { email: string; password: string; }, undefined, undefined> {\n}\n\nAlso, let's just look at what happens when the property includes undefined but is not only undefined:\ntype Other = IAPIRequest<{ a: string } | undefined, number | undefined, { b: number }>;\n/* type Other = {\n    body?: {\n        a: string;\n    } | undefined;\n    params?: number | undefined;\n    query: {\n        b: number;\n    };\n} */\n\nHere body and params are optional because undefined is possible, but query is not because undefined is impossible.\nPlayground link to code\n"
},
{
"QuestionId": "76380868",
"QuestionTitle": "How to configure the Quarkus Mailer extension to allow dynamic 'from' email addresses based on user?",
"QuestionBody": "This Quarkus mailer guide requires that the sending email is preconfigured in property file: quarkus.mailer.from=YOUREMAIL@gmail.com. However, my use case for email includes unique originator email based on user. Using the provided method looks something like:\npublic void sendEmail(EmailSender emailSender) {\n\n    // Send to each recipient\n    emailMessageRepository.findByEmailSenderId(emailSender.getId())\n        .forEach(emailMessage ->\n                mailer.send(\n                    Mail.withText(emailMessage.getEmail(),\n                    emailSender.getSubject(),\n                    emailSender.getMessage())\n            );\n    );\n}\n\nHow can I include the sender's email address (i.e. 'from') when the Mail.withText() method only provides for recipient email?\n",
"AnswerId": "76380985",
"AnswerBody": "The documention showcases how to use multimailer (Multiple From Addresses)\nquarkus.mailer.from=your-from-address@gmail.com \nquarkus.mailer.host=smtp.gmail.com\n\nquarkus.mailer.aws.from=your-from-address@gmail.com \nquarkus.mailer.aws.host=${ses.smtp}\nquarkus.mailer.aws.port=587\n\nquarkus.mailer.sendgrid.from=your-from-address@gmail.com \nquarkus.mailer.sendgrid.host=${sendgrid.smtp-host}\nquarkus.mailer.sendgrid.port=465\n\nSo you would write:\nquarkus.mailer.from=default@gmail.com \n\nquarkus.mailer.aws.from=your_aws@gmail.com \n\nquarkus.mailer.sendgrid.from=your_sendgrid@gmail.com \n\nThen you would inject them as shown below and use them based on whom you want to send with:\n@Inject\n@MailerName(\"aws\") \nMailer mailer;\n\n\n@Inject\n@MailerName(\"sendgrid\") \nMailer mailer;\n\naws and sendgrid at the names between quarkus.mailer.xxx.from\nhttps://quarkus.io/guides/mailer-reference#multiple-mailer-configurations\n\n\nThe Quarkus Mailer is implemented on top of the Vert.x Mail Client,\nproviding an asynchronous and non-blocking way to send emails.\n\nIf you need fine control on how the mail is sent, for instance if you need to retrieve the message ids, you can inject the underlying client, and use it directly:\n@Inject MailClient client;\n\nThen use it:\nMailMessage message = new MailMessage();\nmessage.setFrom(\"user@example.com (Example User)\");\nmessage.setTo(\"recipient@example.org\");\nmessage.setCc(\"Another User <another@example.net>\");\nmessage.setText(\"this is the plain message text\");\nmessage.setHtml(\"this is html text <a href=\\\"http://vertx.io\\\">vertx.io</a>\");\n\nTo send using MailClient:\nmailClient.sendMail(message)\n  .onSuccess(System.out::println)\n  .onFailure(Throwable::printStackTrace);\n\nhttps://quarkus.io/guides/mailer-reference#using-the-underlying-vert-x-mail-client\nhttps://vertx.io/docs/vertx-mail-client/java/\n"
},
{
"QuestionId": "76380847",
"QuestionTitle": "Why Drop trait is only executed at the end of the scope, instead of after the last use?",
"QuestionBody": "This is a question from rust onomicon # lifetime\nThe first example can compile, as x is a reference and the compiler can infer its lifetime as minimal as the last use here :println!(), so x is dropped after this line.\nlet mut data = vec![1, 2, 3];\nlet x = &data[0];\nprintln!(\"{}\", x);\n// This is OK, x is no longer needed\ndata.push(4);\n\nBut the case is different when x is a struct implemented Drop trait.\n#[derive(Debug)]\nstruct X<'a>(&'a i32);\n\nimpl Drop for X<'_> {\n    fn drop(&mut self) {}\n}\n\nlet mut data = vec![1, 2, 3];\nlet x = X(&data[0]);\nprintln!(\"{:?}\", x);\ndata.push(4);\n// Here, the destructor is run and therefore this'll fail to compile.\n\nThe onomicon says in this case, drop() is only executed at the very end of a scope, so x keeps valid until the last line.\nBut why the compiler cannot minimize the lifetime of x to the last use? And is applying drop() just after the last use has some nontrivial side effects when x is implemented Drop trait?\n",
"AnswerId": "76380988",
"AnswerBody": "The primary reason is that it was once defined to be like that, and now changing it isn't possible any more because it wouldn't be backwards-compatible and might break stuff.\nYour code is easily fixable by introducing a nested scope, though, which is (to my understanding) best practice in those situations:\n#[derive(Debug)]\nstruct X<'a>(&'a i32);\n\nimpl Drop for X<'_> {\n    fn drop(&mut self) {}\n}\n\nfn main() {\n    let mut data = vec![1, 2, 3];\n    {\n        let x = X(&data[0]);\n        println!(\"{:?}\", x);\n    }\n    data.push(4);\n}\n\nX(1)\n\nAlternatively, you could drop it manually:\n#[derive(Debug)]\nstruct X<'a>(&'a i32);\n\nimpl Drop for X<'_> {\n    fn drop(&mut self) {}\n}\n\nfn main() {\n    let mut data = vec![1, 2, 3];\n\n    let x = X(&data[0]);\n    println!(\"{:?}\", x);\n    drop(x);\n\n    data.push(4);\n}\n\nX(1)\n\n"
},
{
"QuestionId": "76384211",
"QuestionTitle": "When it's necessary to create a custom spring boot starter rather than create a new microservice?",
"QuestionBody": "I've a microservice architecture, and need some common logic.\nWhen it's necessary to create a custom spring boot starter rather than create a new microservice?\n",
"AnswerId": "76384348",
"AnswerBody": "In my experience, creating a new microservice from the ground up is generally due to preventing any monoliths occurring. Microservices should generally have one job and then do it well. You don't want to muddy up the implementation and purpose of your microservice by adding unrelated operations.\nThere are many design patterns for the \"types\" you could be creating but I won't go into too much detail there. Overall, based on what business purpose you are solving you can select your design and begin development. Different designs should be separated and not combined into monolithic styles. Here is a good article showcasing design options: https://www.openlegacy.com/blog/microservices-architecture-patterns/\nIf you find your self having to re-create multiple microservice serving different use cases you can always utilize a tool such as yeoman to speed up creating these new projects. You can build a generator that will give you a working template so you don't have to spend the time re developing from the ground up each time you need a different service.\nHere is a guide that I wrote recently on creating your own yeoman generator: https://medium.com/@dylanlamott/building-a-yeoman-generator-line-by-line-6966debb39a3\n"
},
{
"QuestionId": "76378628",
"QuestionTitle": "How to fix 'int' object has no attribute 'astype' error when sending WhatsApp messages to large number of contacts using Python and pandas?",
"QuestionBody": "AttributeError: 'int' object has no attribute 'astype' in automatic WhatsApp message sender script\n\nThe following is an automated WhatsApp message sender script I partially developed. I tried the following script and it worked fine with an excel with 5 numbers in it. However, I tried upscaling it to 1700+ numbers, and I get the following traceback:\nTraceback (most recent call last):\n  File \"c:\\Users\\MSI\\Desktop\\AutoSenderPY\\main.py\", line 9, in <module>\n    cellphone = data.loc[i,'Cellphone'].astype(str)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'int' object has no attribute 'astype'*\n\nThe script is the following:\nimport pandas as pd\nimport webbrowser as web\nimport pyautogui as pg\nimport time\n\ndata = pd.read_excel(\"book1.xlsx\", sheet_name='sheet1')\n\nfor i in range(len(data)):\n    cellphone = data.loc[i,'Cellphone'].astype(str) \n    \n    message = \"Test Message\"\n    \n    web.open(\"https://web.whatsapp.com/send?phone=\" + cellphone + \"&text=\" + message)\n    \n    time.sleep(5.5)           \n    pg.click(1230,964)      \n    time.sleep(1)            \n    pg.press('enter')       \n    time.sleep(2)         \n    pg.hotkey('ctrl', 'w') \n    time.sleep(1)\n\nWhy is that happening, and how can I get it working for those 1700+ numbers?\n",
"AnswerId": "76378769",
"AnswerBody": "Try using -\ncellphone = str(data.loc[i,'Cellphone'])\n\nI think loc returns a single element of type \"numpy.int64\", calling the \"str\" should be enough.\n"
},
{
"QuestionId": "76378370",
"QuestionTitle": "SQL How to return record ID's not included in table 2 from table 1 based off of user ID in table 2",
"QuestionBody": "I have two tables, one has course name and course ID. The second table has the ID of the students and the course ID they have taken. I need to find all the class ID’s of the classes a student hasn’t taken. For example, in table 2 student 03 has taken classes 01 and 02 but not 03 and 04 from table one. The course ID’s 03 and 04 from table one are what I need to return (all the classes student 03 hasn't taken). I've tried numerous queries and the last one I tried is:\nSELECT table1.* FROM table1\nLEFT JOIN table2\nON\n    table1.course_ID = table2.course_ID\nWHERE\n    table2.course_ID IS NULL\nAND \n    table2.user_ID != 3\n\nAppreciate your help!\ntable 1\n\n\n\n\ncourse_ID\ncourseName\n\n\n\n\n01\nmath\n\n\n02\nEnglish\n\n\n03\nart\n\n\n04\nmusic\n\n\n\n\ntable 2\n\n\n\n\ncert_Id\ncourse_ID\nuser_ID\n\n\n\n\n01\n01\n03\n\n\n02\n02\n03\n\n\n\n",
"AnswerId": "76378800",
"AnswerBody": "As per your current requirement below query will work\n    SELECT * FROM table1 t1 \n    WHERE course_ID \n    NOT IN (SELECT course_ID FROM table2 WHERE user_ID =3)\n\nIf you have more records in table2 and if you need to populate more than one student's details then you have to use other logic\nIf you want to modify your query then use as below\n    SELECT table1.* FROM table1 \n         LEFT JOIN table2 ON table1.course_ID = table2.course_ID \n         AND table2.user_ID = 3 \n    WHERE table2.course_ID IS NULL\n\n"
},
{
"QuestionId": "76380967",
"QuestionTitle": "Why is SQL Server Pivot being case sensitive on TabTypeId instead of treating it as the actual column name?",
"QuestionBody": "In T-Sql I am parsing JSON and using PIVOT.\nSelect * from (select [key],convert(varchar,[value])[value] \nfrom openjson ('{\"Name\":\"tew\",\"TabTypeId\":9,\"Type\":3}'))A\n    pivot(max(value) for [key] in ([Name],tabTypeId,[Type]))b\n\nIt is not treating tabTypeId as equal to TabTypeId. I am getting NULL for tabTypeId.\nIf I use TabTypeId I get the value 9.\nWhy is it happening?\n",
"AnswerId": "76381059",
"AnswerBody": "It's not PIVOT that is case sensitive, it's the data returned from OPENJSON that is. If you check the data returned from it, you'll see that the column key is a binary collation:\nSELECT name, system_type_name, collation_name\nFROM sys.dm_exec_describe_first_result_set(N'SELECT [key], CONVERT(varchar, [value]) AS [value] FROM OPENJSON(''{\"Name\":\"tew\",\"TabTypeId\":9,\"Type\":3}'');',NULL,NULL)\n\n\n\n\n\nname\nsystem_type_name\ncollation_name\n\n\n\n\nkey\nnvarchar(4000)\nLatin1_General_BIN2\n\n\nvalue\nvarchar(30)\nSQL_Latin1_General_CP1_CI_AS\n\n\n\n\nFor binary collations the actual bytes of the characters must match. As such N'tabTypeId' and N'TabTypeId' are not equal as N'T' and N't' have the binary values 0x5400 and 0x7400.\nThough I am unsure why you are using PIVOT at all; just define your columns in your OPENJSON call:\nSELECT name, --Columns are intentionally demonstrating non-case sensitivity\n       tabTypeId,\n       type\nFROM OPENJSON('{\"Name\":\"tew\",\"TabTypeId\":9,\"Type\":3}')\n        WITH (Name varchar(3),\n              TabTypeId int,\n              Type int);\n\nNote that in the WITH clause of OPENJSON the column names are still case sensitive. tabTypeId int would also yield NULL. If you \"had\" to have a column called tabTypeId defined prior to the SELECT you would use tabTypeId int '$.TabTypeId' instead.\n"
},
{
"QuestionId": "76384091",
"QuestionTitle": "PSQL / SQL: Is it possible to further optimize this query with requiring write access to the database?",
"QuestionBody": "I have a query here that uses four subqueries inside a single CTE, and each subquery is scanning every row of another CTE for each row in itself. I would think that this is very inefficient.\nAre there any SQL optimizations that I can implement now that the proof of concept is finished?\nI don't have write access to the database, so optimizations would be required within the select clause.\nWITH datetable AS (\n    SELECT generate_series(\n        DATE_TRUNC('week', (SELECT MIN(created_at) FROM org_accounts.deleted_users)),\n        DATE_TRUNC('week', now()),\n        '1 week'::INTERVAL\n    )::DATE AS week_start\n), all_users AS (\n    SELECT\n        id,\n        registered_at,\n        NULL AS deleted_at\n    FROM org_accounts.users\n    WHERE status = 'active'\n        AND org_accounts.__user_is_qa(id) <> 'Y'\n        AND email NOT LIKE '%@org%'\n    \n    UNION ALL\n    \n    SELECT\n        id,\n        created_at AS registered_at,\n        deleted_at\n    FROM org_accounts.deleted_users\n    WHERE deleter_id = id\n        AND email NOT LIKE '%@org%'\n), weekly_activity AS (\n    SELECT\n        DATE_TRUNC('week', date)::DATE AS week_start,\n        COUNT(DISTINCT user_id) AS weekly_active_users\n    FROM (\n      SELECT user_id, date\n      FROM org_storage_extra.stats_user_daily_counters \n      WHERE type in ('created_file', 'created_folder', 'created_secure_fetch')\n      \n      UNION ALL\n      \n      SELECT user_id, date\n      FROM ipfs_pinning_facility.stats_user_daily_counters\n      WHERE type <> 'shares_viewed_by_others'\n      ) activity_ids_dates\n    WHERE EXISTS(SELECT 1 from all_users WHERE id = user_id)\n    GROUP BY week_start\n), preprocessed AS (\n    SELECT\n        week_start,\n        (\n            SELECT COUNT(DISTINCT id)\n            FROM all_users\n            WHERE registered_at < week_start\n                AND (deleted_at IS NULL OR deleted_at > week_start)\n        ) AS actual_users,\n        (\n            SELECT COUNT(DISTINCT id)\n            FROM all_users\n            WHERE deleted_at < week_start + '1 week'::INTERVAL\n        ) AS cumulative_churned_users,\n        (\n            SELECT COUNT(DISTINCT id)\n            FROM all_users\n            WHERE registered_at >= week_start\n                AND registered_at < week_start + '1 week'::INTERVAL\n        ) AS weekly_new_users,\n        (\n            SELECT COUNT(DISTINCT id)\n            FROM all_users\n            WHERE deleted_at >= week_start\n                AND deleted_at < week_start + '1 week'::INTERVAL\n        ) AS weekly_churned_users,\n        COALESCE(weekly_active_users, 0) AS weekly_active_users\n    FROM datetable dt\n    LEFT JOIN weekly_activity USING (week_start)\n    ORDER BY week_start DESC\n)\nSELECT\n    week_start AS for_week_of, \n    actual_users + cumulative_churned_users AS cumulative_users,\n    cumulative_churned_users,\n    cumulative_churned_users::FLOAT / NULLIF((actual_users + cumulative_churned_users)::FLOAT, 0) AS cumulated_churn_rate,\n    actual_users,\n    weekly_new_users,\n    weekly_churned_users,\n    weekly_active_users,\n    weekly_churned_users::FLOAT / NULLIF(actual_users::FLOAT, 0) AS weekly_churn_rate \nFROM preprocessed;\n\nResults of query analysis:\nQUERY PLAN\nSubquery Scan on preprocessed  (cost=40875.45..7501783.95 rows=1000 width=68) (actual time=1553.471..13613.116 rows=231 loops=1)\n  Output: preprocessed.week_start, (preprocessed.actual_users + preprocessed.cumulative_churned_users), preprocessed.cumulative_churned_users, ((preprocessed.cumulative_churned_users)::double precision / NULLIF(((preprocessed.actual_users + preprocessed.cumulative_churned_users))::double precision, '0'::double precision)), preprocessed.actual_users, preprocessed.weekly_new_users, preprocessed.weekly_churned_users, preprocessed.weekly_active_users, ((preprocessed.weekly_churned_users)::double precision / NULLIF((preprocessed.actual_users)::double precision, '0'::double precision))\n  Buffers: shared hit=287734 read=1964, temp read=274840 written=873\n  CTE all_users\n    ->  Append  (cost=0.00..30953.99 rows=70293 width=32) (actual time=0.099..1313.372 rows=71228 loops=1)\n          Buffers: shared hit=285995 read=1964\n          ->  Seq Scan on org_accounts.users  (cost=0.00..27912.65 rows=70009 width=32) (actual time=0.099..1289.469 rows=70007 loops=1)\n                Output: users.id, users.registered_at, NULL::timestamp with time zone\n                Filter: ((users.email !~~ '%@mailinator%'::text) AND (users.email !~~ '%@org%'::text) AND (users.email !~~ '%testaccnt%'::text) AND (users.status = 'active'::text) AND ((org_accounts.__user_is_qa(users.id))::text <> 'Y'::text))\n                Rows Removed by Filter: 9933\n                Buffers: shared hit=285269 read=1964\n          ->  Seq Scan on org_accounts.deleted_users  (cost=0.00..1986.94 rows=284 width=32) (actual time=0.014..14.267 rows=1221 loops=1)\n                Output: deleted_users.id, deleted_users.created_at, deleted_users.deleted_at\n                Filter: ((deleted_users.email !~~ '%@mailinator%'::text) AND (deleted_users.email !~~ '%@org%'::text) AND (deleted_users.email !~~ '%testaccnt%'::text) AND (deleted_users.deleter_id = deleted_users.id))\n                Rows Removed by Filter: 61826\n                Buffers: shared hit=726\n  ->  Merge Left Join  (cost=9921.47..7470794.97 rows=1000 width=44) (actual time=1553.467..13612.496 rows=231 loops=1)\n        Output: (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date), (SubPlan 2), (SubPlan 3), (SubPlan 4), (SubPlan 5), COALESCE(weekly_activity.weekly_active_users, '0'::bigint)\n        Inner Unique: true\n        Merge Cond: ((((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date) = weekly_activity.week_start)\n        Buffers: shared hit=287734 read=1964, temp read=274840 written=873\n        ->  Sort  (cost=1601.45..1603.95 rows=1000 width=4) (actual time=10.108..10.250 rows=231 loops=1)\n              Output: (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date)\n              Sort Key: (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date) DESC\n              Sort Method: quicksort  Memory: 35kB\n              Buffers: shared hit=726\n              ->  Result  (cost=1514.10..1541.62 rows=1000 width=4) (actual time=9.986..10.069 rows=231 loops=1)\n                    Output: ((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date\n                    Buffers: shared hit=726\n                    InitPlan 6 (returns $5)\n                      ->  Aggregate  (cost=1514.09..1514.10 rows=1 width=8) (actual time=9.974..9.975 rows=1 loops=1)\n                            Output: min(deleted_users_1.created_at)\n                            Buffers: shared hit=726\n                            ->  Seq Scan on org_accounts.deleted_users deleted_users_1  (cost=0.00..1356.47 rows=63047 width=8) (actual time=0.006..4.332 rows=63047 loops=1)\n                                  Output: deleted_users_1.id, deleted_users_1.email, deleted_users_1.created_at, deleted_users_1.deleter_id, deleted_users_1.deleted_at, deleted_users_1.registration_app\n                                  Buffers: shared hit=726\n                    ->  ProjectSet  (cost=0.00..5.03 rows=1000 width=8) (actual time=9.984..10.030 rows=231 loops=1)\n                          Output: generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)\n                          Buffers: shared hit=726\n                          ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.001 rows=1 loops=1)\n        ->  Sort  (cost=8320.02..8320.52 rows=200 width=12) (actual time=1475.315..1475.418 rows=159 loops=1)\n              Output: weekly_activity.weekly_active_users, weekly_activity.week_start\n              Sort Key: weekly_activity.week_start DESC\n              Sort Method: quicksort  Memory: 32kB\n              Buffers: shared hit=287008 read=1964, temp read=412 written=872\n              ->  Subquery Scan on weekly_activity  (cost=8050.90..8312.37 rows=200 width=12) (actual time=1466.686..1475.279 rows=159 loops=1)\n                    Output: weekly_activity.weekly_active_users, weekly_activity.week_start\n                    Buffers: shared hit=287008 read=1964, temp read=412 written=872\n                    ->  GroupAggregate  (cost=8050.90..8310.37 rows=200 width=12) (actual time=1466.685..1475.254 rows=159 loops=1)\n                          Output: ((date_trunc('week'::text, (\"*SELECT* 1\".date)::timestamp with time zone))::date), count(DISTINCT \"*SELECT* 1\".user_id)\n                          Group Key: ((date_trunc('week'::text, (\"*SELECT* 1\".date)::timestamp with time zone))::date)\n                          Buffers: shared hit=287008 read=1964, temp read=412 written=872\n                          ->  Sort  (cost=8050.90..8136.22 rows=34130 width=20) (actual time=1466.668..1468.872 rows=23005 loops=1)\n                                Output: ((date_trunc('week'::text, (\"*SELECT* 1\".date)::timestamp with time zone))::date), \"*SELECT* 1\".user_id\n                                Sort Key: ((date_trunc('week'::text, (\"*SELECT* 1\".date)::timestamp with time zone))::date)\n                                Sort Method: quicksort  Memory: 2566kB\n                                Buffers: shared hit=287008 read=1964, temp read=412 written=872\n                                ->  Hash Join  (cost=1586.09..5481.12 rows=34130 width=20) (actual time=1411.350..1462.022 rows=23005 loops=1)\n                                      Output: (date_trunc('week'::text, (\"*SELECT* 1\".date)::timestamp with time zone))::date, \"*SELECT* 1\".user_id\n                                      Inner Unique: true\n                                      Hash Cond: (\"*SELECT* 1\".user_id = all_users.id)\n                                      Buffers: shared hit=287008 read=1964, temp read=412 written=872\n                                      ->  Append  (cost=0.00..3080.17 rows=68261 width=20) (actual time=0.010..25.441 rows=68179 loops=1)\n                                            Buffers: shared hit=1013\n                                            ->  Subquery Scan on \"*SELECT* 1\"  (cost=0.00..1018.43 rows=21568 width=20) (actual time=0.008..7.895 rows=21532 loops=1)\n                                                  Output: \"*SELECT* 1\".date, \"*SELECT* 1\".user_id\n                                                  Buffers: shared hit=372\n                                                  ->  Seq Scan on org_storage_extra.stats_user_daily_counters  (cost=0.00..802.75 rows=21568 width=20) (actual time=0.008..5.910 rows=21532 loops=1)\n                                                        Output: stats_user_daily_counters.user_id, stats_user_daily_counters.date\n                                                        Filter: (stats_user_daily_counters.type = ANY ('{created_file,created_folder,created_secure_fetch}'::text[]))\n                                                        Rows Removed by Filter: 9795\n                                                        Buffers: shared hit=372\n                                            ->  Subquery Scan on \"*SELECT* 2\"  (cost=0.00..1720.44 rows=46693 width=20) (actual time=0.009..12.460 rows=46647 loops=1)\n                                                  Output: \"*SELECT* 2\".date, \"*SELECT* 2\".user_id\n                                                  Buffers: shared hit=641\n                                                  ->  Seq Scan on ipfs_pinning_facility.stats_user_daily_counters stats_user_daily_counters_1  (cost=0.00..1253.51 rows=46693 width=20) (actual time=0.009..8.209 rows=46647 loops=1)\n                                                        Output: stats_user_daily_counters_1.user_id, stats_user_daily_counters_1.date\n                                                        Filter: (stats_user_daily_counters_1.type <> 'shares_viewed_by_others'::text)\n                                                        Rows Removed by Filter: 2354\n                                                        Buffers: shared hit=641\n                                      ->  Hash  (cost=1583.59..1583.59 rows=200 width=16) (actual time=1411.250..1411.251 rows=71228 loops=1)\n                                            Output: all_users.id\n                                            Buckets: 131072 (originally 1024)  Batches: 2 (originally 1)  Memory Usage: 3073kB\n                                            Buffers: shared hit=285995 read=1964, temp read=100 written=717\n                                            ->  HashAggregate  (cost=1581.59..1583.59 rows=200 width=16) (actual time=1383.986..1398.270 rows=71228 loops=1)\n                                                  Output: all_users.id\n                                                  Group Key: all_users.id\n                                                  Batches: 5  Memory Usage: 4161kB  Disk Usage: 1544kB\n                                                  Buffers: shared hit=285995 read=1964, temp read=100 written=560\n                                                  ->  CTE Scan on all_users  (cost=0.00..1405.86 rows=70293 width=16) (actual time=0.102..1351.241 rows=71228 loops=1)\n                                                        Output: all_users.id\n                                                        Buffers: shared hit=285995 read=1964, temp written=296\n        SubPlan 2\n          ->  Aggregate  (cost=1777.05..1777.06 rows=1 width=8) (actual time=20.197..20.197 rows=1 loops=231)\n                Output: count(DISTINCT all_users_1.id)\n                Buffers: temp read=68607 written=1\n                ->  CTE Scan on all_users all_users_1  (cost=0.00..1757.33 rows=7888 width=16) (actual time=0.883..10.874 rows=27239 loops=231)\n                      Output: all_users_1.id, all_users_1.registered_at, all_users_1.deleted_at\n                      Filter: ((all_users_1.registered_at < (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date)) AND ((all_users_1.deleted_at IS NULL) OR (all_users_1.deleted_at > (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date))))\n                      Rows Removed by Filter: 43989\n                      Buffers: temp read=68607 written=1\n        SubPlan 3\n          ->  Aggregate  (cost=1815.90..1815.91 rows=1 width=8) (actual time=11.215..11.215 rows=1 loops=231)\n                Output: count(DISTINCT all_users_2.id)\n                Buffers: temp read=68607\n                ->  CTE Scan on all_users all_users_2  (cost=0.00..1757.33 rows=23431 width=16) (actual time=11.009..11.150 rows=231 loops=231)\n                      Output: all_users_2.id, all_users_2.registered_at, all_users_2.deleted_at\n                      Filter: (all_users_2.deleted_at < ((((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date) + '7 days'::interval))\n                      Rows Removed by Filter: 70997\n                      Buffers: temp read=68607\n        SubPlan 4\n          ->  Aggregate  (cost=1933.94..1933.95 rows=1 width=8) (actual time=14.515..14.515 rows=1 loops=231)\n                Output: count(DISTINCT all_users_3.id)\n                Buffers: temp read=68607\n                ->  CTE Scan on all_users all_users_3  (cost=0.00..1933.06 rows=351 width=16) (actual time=2.264..14.424 rows=308 loops=231)\n                      Output: all_users_3.id, all_users_3.registered_at, all_users_3.deleted_at\n                      Filter: ((all_users_3.registered_at >= (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date)) AND (all_users_3.registered_at < ((((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date) + '7 days'::interval)))\n                      Rows Removed by Filter: 70920\n                      Buffers: temp read=68607\n        SubPlan 5\n          ->  Aggregate  (cost=1933.94..1933.95 rows=1 width=8) (actual time=6.556..6.556 rows=1 loops=231)\n                Output: count(DISTINCT all_users_4.id)\n                Buffers: temp read=68607\n                ->  CTE Scan on all_users all_users_4  (cost=0.00..1933.06 rows=351 width=16) (actual time=6.441..6.547 rows=5 loops=231)\n                      Output: all_users_4.id, all_users_4.registered_at, all_users_4.deleted_at\n                      Filter: ((all_users_4.deleted_at >= (((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date)) AND (all_users_4.deleted_at < ((((generate_series(date_trunc('week'::text, $5), date_trunc('week'::text, now()), '7 days'::interval)))::date) + '7 days'::interval)))\n                      Rows Removed by Filter: 71223\n                      Buffers: temp read=68607\nPlanning Time: 0.612 ms\nExecution Time: 13615.054 ms\n\n",
"AnswerId": "76384360",
"AnswerBody": "An obvious optimization is to eliminate redundant table scans. There isn't any need in preprocessed to query from all_users more than once. The following query uses COUNT with FILTER to gather the same statistics:\nWITH datetable AS (SELECT GENERATE_SERIES(\n                            DATE_TRUNC('week', (SELECT MIN(created_at) FROM org_accounts.deleted_users)),\n                            DATE_TRUNC('week', NOW()),\n                            '1 week'::INTERVAL\n                            )::DATE AS week_start),\n     all_users AS (SELECT id,\n                          registered_at,\n                          NULL AS deleted_at\n                     FROM org_accounts.users\n                     WHERE status = 'active'\n                       AND org_accounts.__user_is_qa(id) <> 'Y'\n                       AND email NOT LIKE '%@org%'\n                   UNION ALL\n                   SELECT id,\n                          created_at AS registered_at,\n                          deleted_at\n                     FROM org_accounts.deleted_users\n                     WHERE deleter_id = id\n                       AND email NOT LIKE '%@org%'),\n     weekly_activity AS (SELECT DATE_TRUNC('week', date)::DATE AS week_start,\n                                COUNT(DISTINCT user_id)        AS weekly_active_users\n                           FROM (SELECT user_id, date\n                                   FROM org_storage_extra.stats_user_daily_counters\n                                   WHERE type IN ('created_file', 'created_folder', 'created_secure_fetch')\n                                 UNION ALL\n                                 SELECT user_id, date\n                                   FROM ipfs_pinning_facility.stats_user_daily_counters\n                                   WHERE type <> 'shares_viewed_by_others') activity_ids_dates\n                           WHERE EXISTS(SELECT 1 FROM all_users WHERE id = user_id)\n                           GROUP BY week_start),\n     preprocessed AS (SELECT week_start,\n                             us.actual_users,\n                             us.cumulative_churned_users,\n                             us.weekly_new_users,\n                             us.weekly_churned_users,\n                             COALESCE(weekly_active_users, 0) AS weekly_active_users\n                        FROM datetable dt\n                          CROSS JOIN LATERAL (SELECT\n                                                 COUNT(DISTINCT u.id) FILTER (WHERE u.registered_at < dt.week_start AND\n                                                                                    (u.deleted_at IS NULL OR u.deleted_at > dt.week_start)) AS actual_users,\n                                                 COUNT(DISTINCT u.id)\n                                                 FILTER (WHERE u.deleted_at < dt.week_start + '1 week'::INTERVAL)                           AS cumulative_churned_users,\n                                                 COUNT(DISTINCT u.id)\n                                                 FILTER (WHERE u.registered_at >= dt.week_start AND u.registered_at <\n                                                                                                    dt.week_start +\n                                                                                                    '1 week'::INTERVAL)                     AS weekly_new_users,\n                                                 COUNT(DISTINCT u.id)\n                                                 FILTER (WHERE u.deleted_at >= dt.week_start AND u.deleted_at <\n                                                                                                 dt.week_start +\n                                                                                                 '1 week'::INTERVAL)                        AS weekly_churned_users\n                                               FROM all_users u\n                                               WHERE u.registered_at < dt.week_start + '1 week'::INTERVAL\n                                                  OR (u.deleted_at >= dt.week_start AND\n                                                      u.deleted_at < dt.week_start + '1 week'::INTERVAL)) us\n                          LEFT JOIN weekly_activity\n                                    USING (week_start)\n  ORDER BY week_start DESC)\nSELECT week_start                                                   AS for_week_of,\n       actual_users + cumulative_churned_users                      AS cumulative_users,\n       cumulative_churned_users,\n       cumulative_churned_users::FLOAT /\n       NULLIF((actual_users + cumulative_churned_users)::FLOAT, 0)  AS cumulated_churn_rate,\n       actual_users,\n       weekly_new_users,\n       weekly_churned_users,\n       weekly_active_users,\n       weekly_churned_users::FLOAT / NULLIF(actual_users::FLOAT, 0) AS weekly_churn_rate\n  FROM preprocessed;\n\nThere are probably other optimizations possible, but this one was immediately evident.\n"
},
{
"QuestionId": "76378322",
"QuestionTitle": "How can I convert an int to a generic type containing complex128 in Go?",
"QuestionBody": "I cannot work out how to convert an int to a generic type containing complex128. Here is an example which doesn't compile unless the complex128 is commented out:\npackage main\n\nimport \"fmt\"\n\ntype val interface {\n    int64 | float64 | complex128\n}\n\nfunc f[V val](a, b V) (c V) {\n    q := calc()\n    return a * b * V(q)\n}\n\nfunc calc() int {\n    // lengthy calculation that returns an int\n    return 1\n}\n\nfunc main() {\n    fmt.Printf(\"%v\\n\", f(int64(1), int64(2)))\n}\n\nThis is simplified from a much larger calculation. I've tried using a switch but every syntax I have attempted seems to meet resistance of one kind or another.\nHow can I multiply a and b with an integer?\nI have tried using a switch on the type of the return variable such as any(c).(type) but for example if I have case complex128: then it refuses to allow the complex builtin since it doesn't return a V.\nWithout the complex128 the above will compile.\n",
"AnswerId": "76378801",
"AnswerBody": "This one works but it needs to list every type in the switch statement:\nfunc f[V val](a, b V) (c V) {\n    q := calc()\n\n    var temp any\n    switch any(c).(type) {\n    case complex128:\n        temp = complex(float64(q), 0)\n    case int64:\n        temp = int64(q)\n    default:\n        temp = float64(q)\n    }\n    return a * b * (temp.(V))\n}\n\n"
},
{
"QuestionId": "76378721",
"QuestionTitle": "Hide 'Display Cart' button in WooCommerce mini cart widget",
"QuestionBody": "enter image description here\nin wordpress and woocommerce Plugin\nis there anyway to hide \"Display Cart\" button in wordpress mini card widget ?\ni can hide \"checkout\" button individually but it seems theres no Special Css Class Fot \"Display Card\" buttun. ?!?!\n",
"AnswerId": "76378829",
"AnswerBody": "you can try this\n \nadd_action( 'woocommerce_widget_shopping_cart_buttons', 'bbloomer_remove_view_cart_minicart', 1 );\n \nfunction bbloomer_remove_view_cart_minicart() {\n   remove_action( 'woocommerce_widget_shopping_cart_buttons', 'woocommerce_widget_shopping_cart_button_view_cart', 10 );\n}\n\nOR\n.widget .woocommerce-mini-cart__buttons a:not(.checkout) {\ndisplay: none;\n}\n\n"
},
{
"QuestionId": "76378661",
"QuestionTitle": "The fastest way to convert a UInt64 hex string to a UInt32 value preserving as many leading digits as possible, i.e. truncation",
"QuestionBody": "I'm looking for the fastest way to parse a hex string representing a ulong into a uint keeping as many leading digits as a uint can handle and discarding the rest. For example,\nstring hex = \"0xab54a9a1df8a0edb\";  // 12345678991234567899\nShould output: uint result = 1234567899;\nI can do this by simply parsing the hex into a ulong, getting the digits using ToString and then just taking as many of them as would fit into uint without overflowing but I need something much faster. Thanks. C# code preferred but any would do.\n",
"AnswerId": "76378944",
"AnswerBody": "For decimal truncation, all the high bits of the hex digit affect the low 9 or 10 decimal digits, so you need to convert the whole thing.  Is there an algorithm to convert massive hex string to bytes stream QUICKLY? asm/C/C++ has C++ with SSE intrinsics.  I commented there with some possible improvements to that, and to https://github.com/zbjornson/fast-hex .  This could be especially good if you're using SIMD to find numeric literals in larger buffers, so you might have the hex string in a SIMD register already.  (Not sure if SIMDJSON does that.)\nHex-string to 64-bit integer is something SIMD certainly can speed up, e.g. do something to map each digit to a 0-15 integer, combine pairs of bytes to pack nibbles (e.g. with x86 pmaddubsw), then shuffle those 8-bit chunks to the bottom of a register.  (e.g. packuswb or pshufb).  x86 at least has efficient SIMD to GP-integer movq rax, xmm0, although the ARM equivalent is slow on some ARM CPUs.\n(Getting a speedup from SIMD for ASCII hex -> uint is much easier if your strings are fixed-length, and probably if you don't need to check for invalid characters that aren't hex digits.)\n\nDecimal truncation of u64 (C# ulong) to fit in u32 (C# uint)\nModulo by a power of 10 truncates to some number of decimal digits.\n(uint)(x % 10000000000) works for some numbers, but 10000000000 (1e10 = one followed by 10 zeros) is larger than 2^32-1. Consider an input like 0x2540be3ff (9999999999).  We'd get (uint)9999999999 producing 1410065407 = 0x540be3ff (keeping the low 32 bits of that 34-bit number.)\nSo perhaps try modulo 1e10, but if it's too big for u32 then modulo 1e9.\n  ulong tendigit = x % 10000000000;  // 1e10\n  uint truncated = tendigit <= (ulong)0xffffffff ? tendigit : (x % 1000000000);  // % 1e9 keeps 9 decimal digits\n\nIf this isn't correct C# syntax or the literals need some decoration to make them ulong (like C 10000000000uLL for good measure), please let me know.\nIt's probably at least as efficient to just modulo the original number two different ways than to try to get the leading decimal digit of x % 1e10 and subtract it or whatever.  The asm is going to need two 64-bit multiplicative inverse constants, and starting from the original number again keeps critical-path latency shorter for out-of-order exec if branch prediction predicts that it needs to calculate the nine-digit truncation.\n\nBinary truncation\n@Matthew Whited deleted his answer (due to a bug in the decimal truncation part), but his binary truncation part based on substrings of the original hex input could perhaps be more efficient in some cases than doing the full conversion and then casting to a narrower type or masking with AND.\n\nIf you want the last 8 bytes of the hex string\nuint.Parse(hex[^8..],NumberStyles.HexNumber)\n\nIf you want the first 8 bytes\nuint.Parse(hex[2..10], NumberStyles.HexNumber);\n\n\n"
},
{
"QuestionId": "76384304",
"QuestionTitle": "How to backup a full project of firebase",
"QuestionBody": "I am faced a problem. I have a project which is in firebase. I have used there firebase Authenticate, Firebase realtime database, Firebase function and some more. Now I have changed my decision. I want to make my own server where I will set up and manage everything.\nSo that I want to backup my project to move all data to other framework like spring boot project.\nIn this situation how can I get the whole project? User Auth data, Firebase Realtime database, Firestore etc.\n",
"AnswerId": "76384361",
"AnswerBody": "You'll have to write code or use the CLI to query all of the data you want, and write it to a place you want.  Firebase does not provide a tool to do all this automatically for an entire project. You will need to deal with each product's data separately.\nYou can use the Firebase Admin SDK or the Firebase CLI to access data from the products you listed.\nSee also:\n\nIs it possible to backup Firebase DB?\nhttps://firebase.google.com/docs/firestore/manage-data/export-import\nhttps://firebase.google.com/docs/cli/auth\n\n"
},
{
"QuestionId": "76378577",
"QuestionTitle": "Why does ruby recognise a method outside of a class, but not inside?",
"QuestionBody": "I am trying to build a simple language translating program. I imported the 'language_converter' gem to aid with this goal. I wrote the following code:\nrequire 'language_converter'\n\nclass Translator\n    def initialize\n        @to = 'ja';  \n        @from = 'en';   \n    end\n\n    def translate text\n        lc(text, @to,@from)\n    end\nend\n\n#puts lc('welcome to Japan!', 'ja','en');\n \nt = Translator.new\n\np t.translate('welcome to Japan!');\n\nThis code results in the error: undefined method 'lc' for #<Translator:0x0000000101167a90 @to=\"ja\", @from=\"en\"> (NoMethodError)\nHowever, when i uncomment the code on line 15, ruby can access the lc method and return some japanese. Does anyone know why the method is 'defined' outside of the class but not inside?\nEdit: the language-converter gem is not my own. also, I cannot find the source code on its homepage.\nI have also tried adding two semicolons before the lc method like so: ::lc(text, @to,@from). This results in the error: syntax error, unexpected local variable or method, expecting constant\n",
"AnswerId": "76378945",
"AnswerBody": "The gem is more than 10 years old and only has one method. And that method is implemented as a class method.\nYou are properly better off with just rewriting that method in your application with a modern Ruby syntax and proper error handling.\nFor reference, this it how lib/language_converter.rb in the gem looks like:\nrequire 'net/http'\nrequire 'rubygems'\nrequire \"uri\"\nrequire 'json'\n\nclass UnSupportedLanguage < RuntimeError\n\n  def initialize(message='')\n    @msg = \"not supported.\"\n  end\nend\n\n\n  def self.lc( text, to, from='en' )\n\n    begin\n\n      uri = URI.parse(\"http://mymemory.translated.net/api/get\")\n\n      response = Net::HTTP.post_form(uri, {\"q\" => text,\"langpair\"=>\"#{from.to_s.downcase}|#{to.to_s.downcase}\", \"per_page\" => \"50\"})\n\n      json_response_body = JSON.parse( response.body )\n\n      if json_response_body['responseStatus'] == 200\n        json_response_body['responseData']['translatedText']\n      else\n        puts json_response_body['responseDetails']\n        raise StandardError, response['responseDetails']\n      end\n    rescue UnSupportedLanguage\n      raise UnSupportedLanguage.new\n    rescue => err_msg\n      puts \"#{err_msg}\"\n    end\n\n  end\n\n"
},
{
"QuestionId": "76384270",
"QuestionTitle": "How to override parent's styles in css?",
"QuestionBody": "In this example, I want the purple rectangle to change its opacity to 100% regardless of the value of the parent. I tried using all: unset/initial and !important but it doesn't seem to work.\n\n\n.rect {\n    width: 500px;\n    height: 600px;\n    margin-top: 200px;\n    margin-left: 300px;\n    background-color: black;\n    /* this V */\n    opacity: 37%;\n    z-index: -1;\n}\n\n.rect1 {\n    all: unset;\n    position: absolute;\n    z-index: 10;\n    width: 259px;\n    height: 300px;\n    margin-top: 500px;\n    margin-left: 50px;\n    background-color: purple;\n    /* to this V */\n    opacity: 100% !important;\n}\n<div class=\"rect\">\n  <div class=\"rect1\"></div>\n</div>\n\n\n\n",
"AnswerId": "76384365",
"AnswerBody": "So like Haworth pointed out, using opacity on the element itself brings all children under the influence of the pixelshading used to make the opacity effect.\nIf you want to get the same effect while retaining your html structure I'd recommend a different approach for the same result using RGBA or hex with an alpha channel on the background-color property directly. See example below.\n\n\nbody {\n  height: 100%;\n  width: 100%;\n  background: url(https://picsum.photos/800) no-repeat;\n  background-size: cover;\n}\n\n.rect {\n    width: 500px;\n    height: 600px;\n    margin-top: 200px;\n    margin-left: 300px;\n    background-color: rgba(0,0,0,.37);\n    /* this V\n    opacity: 37%;*/\n    z-index: -1;\n}\n\n.rect1 {\n    position: absolute;\n    z-index: 10;\n    width: 259px;\n    height: 300px;\n    margin-top: 500px;\n    margin-left: 50px;\n    background-color: purple;\n    /* to this V */\n    opacity: 100% !important;\n}\n<div class=\"rect\">\n  <div class=\"rect1\"></div>\n</div>\n\n\n\n"
},
{
"QuestionId": "76378347",
"QuestionTitle": "How to generate a log file of the windows prompt when I run a bat file",
"QuestionBody": "I'm running a bat file in windows. I'm trying to generate a log file of all the output that appears in the command prompt, to have as a document.\nNote, Not a log file of the contents of the bat file but of the command prompt that it outputs.\nHow would I do this? Thanks\n",
"AnswerId": "76378974",
"AnswerBody": "Redirecting to output is done by using > or appending to file using >>\nfor batch-file, we typically call them.\n(call script.cmd)2>&1>\"logfile.log\"\n\nor append\n(call script.cmd)2>&1>>\"logfile.log\"\n\nNote, 2>&1 2>&1 is redirecting the stderr stream 2 to the stdout stream 1, it is important here, seeing as you said you want to log all of the output results to logfile.\nSo that should also give the clue that you can in fact redirect success (stdout) results to one file and failures (stderr) to another, i.e\n(call script.cmd) 1>\"Output.log\" 2>\"Errors.log\"\n\nNote, some commands and executables sends everything to the stdout stream and nothing to stderr, example ping.exe.\n"
},
{
"QuestionId": "76384255",
"QuestionTitle": "calculate an object property based on the value of another property of the same object",
"QuestionBody": "I need to find out the value of \"name\" inside on the obj object. How can I find it without function invocation?\nI wanna use just obj.isActive not obj.isActive()\nlet obj = {\n  name: \"X Æ A-12 Musk\",\n  isActive: function () {\n    return this.name.length > 4;\n  },\n};\n\n// and after a while I need to check if is active:\n\nconsole.log(obj);\n\n// { \n//   name: 'X Æ A-12 Musk',\n//   isActive: [Function: isActive]  <--------- NOT COOL ! \n// }\n\n\n\nIf use an IFEE:\nlet obj = {\n  name: \"X Æ A-12 Musk\",\n  isActive: (function () {\n    return this.name.length > 4;\n  })(),\n};\n\nI get:\nreturn this.name.length > 4;\n                ^\nTypeError: Cannot read properties of undefined (reading 'length') \n\n",
"AnswerId": "76384399",
"AnswerBody": "If you do not want to have to call isActive as a function, you can use a getter.\n\n\nconst obj = {\n  name: \"X Æ A-12 Musk\",\n  get isActive () {\n    return this.name.length > 4;\n  },\n};\n\nconsole.log(obj.isActive);\n\n\n\n"
},
{
"QuestionId": "76384220",
"QuestionTitle": "Code to format JSON data and append hardcoded data to create a flat .txt file",
"QuestionBody": "Source Data::\njson_data = [{\"studentid\": 1, \"name\": \"ABC\", \"subjects\": [\"Python\", \"Data Structures\"]},\n             {\"studentid\": 2, \"name\": \"PQR\", \"subjects\": [\"Java\", \"Operating System\"]}]\n\nHardcoded_Val1 = 10\nHardcoded_Val2 = 20\nHardcoded_Val3 = str(datetime.datetime.now())\n\nNeed to create a flat .txt file with the below data.\nID,DEPT,\"studentid|name|subjects\",execution_dt\n10,20,\"1|ABC|Python,Data Structures\",2023-06-01\n10,20,\"2|PQR|Java,Operating System\",2023-06-01\n\nI am very new in python. Have already tried to figure it out to achieve it but couldn't. Your help will be much appreciated.\nimport datetime\nimport pandas as pd\nimport json\n\n\njson_data = [{\"studentid\": 1, \"name\": \"ABC\", \"subjects\": [\"Python\", \"Data Structures\"]},\n             {\"studentid\": 2, \"name\": \"PQR\", \"subjects\": [\"Java\", \"Operating System\"]}]\n\nHardcoded_Val1 = 10\nHardcoded_Val2 = 20\nHardcoded_Val3 = str(datetime.datetime.now())\n\nprofile = str(Hardcoded_Val1) + ',' + str(Hardcoded_Val2) + ',\"' + str(json_data) + '\",' + Hardcoded_Val3\n        \nprint(profile)\n#data = json.dumps(profile, indent=True)\n#print(data)\ndata_list = []\nfor data_info in profile:\n   data_list.append(data_info.replace(\", '\", '|'))\ndata_df = pd.DataFrame(data=data_list)\ndata_df.to_csv(r'E:\\DataLake\\api_fetched_sample_output.txt', sep='|', index=False, encoding='utf-8')\n\n\n",
"AnswerId": "76384400",
"AnswerBody": "I would bypass using pandas for this and just build the string manually primarily using a list comprehension and join().\nimport datetime\nimport csv\n\nHardcoded_Val1 = 10\nHardcoded_Val2 = 20\nHardcoded_Val3 = str(datetime.date.today())\njson_data = [\n    {\"studentid\": 1, \"name\": \"ABC\", \"subjects\": [\"Python\", \"Data Structures\"]},\n    {\"studentid\": 2, \"name\": \"PQR\", \"subjects\": [\"Java\", \"Operating System\"]}\n]\n\ncsv_data = []\nfor row in json_data:\n    keys = \"|\".join(row.keys())\n    values = \"|\".join([\n        \",\".join(value) if isinstance(value, list) else str(value)\n        for value in row.values()\n    ])\n    csv_data.append(dict([\n        (\"ID\", Hardcoded_Val1),\n        (\"DEPT\", Hardcoded_Val2),\n        (keys, values),\n        (\"execution_dt\", Hardcoded_Val3)\n    ]))\n\nwith open(\"out.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as file_out:\n    writer = csv.DictWriter(file_out, fieldnames=list(csv_data[0].keys()))\n    writer.writeheader()\n    writer.writerows(csv_data)\n\nThis will produce a file with the following contents:\nID,DEPT,studentid|name|subjects,execution_dt\n10,20,\"1|ABC|Python,Data Structures\",2023-06-02\n10,20,\"2|PQR|Java,Operating System\",2023-06-02\n\n"
},
{
"QuestionId": "76380911",
"QuestionTitle": "Expect function Parameter to be Key of Object with Dynamic Properties",
"QuestionBody": "Im making an application multi Language.\nI want to build typing as strict and simpel as possible. My Code is the following:\n//=== Inside my Hook: ===//\ninterface ITranslation {\n   [key:string]:[string, string]\n}\n\nconst useTranslator = (translations:ITranslation) => {\n   const language = useLanguage() // just getting the language setting from another hook\n\n   const translate = (key:keyof typeof translations) => {\n      // mapping and returning the right translation\n   }\n\n   return translate;\n}\n\n\n//=== Inside the component: ===//\nconst translation:ITranlation = {\n   \"something in english\": [ \"something in german\", \"something in spanish\" ],\n   \"anotherthing in english\": [\"anotherthing in german\", \"anotherthing in spanish\"]\n}\n\nconst translate = useTranslation(translation)\n\nreturn(\n   <Text>{translate(\"something in english\")}</Text>\n)\n\n\nWhat i want to achieve:\n\nWhen passing the translation Object, with Dynamic Keys to the Hook: useTranslation(translations), there should be a typecheck validating, that both languages are provided (any property has an Array with 2 Strings)\n\nWhen using the translate function (inside the Text component) typescript should bring an error, if a key is not matching the Dynamic Keys inside the translations object. So this should throw an error: tranlate(\"not a key in object\")\n\n\nBut i can't get it to work properly. I can either set the translations object as const, but then there is no typecheck when passing the object to the Hook.\nOr i set it as shown above with translation:ITranslation but then there is no typechecking for the parameter in the ´translate´ function inside the component.\nIs it possible to achive that? (If yes, how?)\nThanks in advance!\n",
"AnswerId": "76381092",
"AnswerBody": "This solution will work only for Typescript >= 4.9 since it uses the satisfies operator introduced in the 4.9.\nAdding as const is the approach we will go with, and satisfies will allow us to type-check it.\nconst translation = {\n  'something in english': ['something in german', 'something in spanish'],\n  'anotherthing in english': ['anotherthing in german', 'anotherthing in spanish'],\n} as const satisfies ITranslation;\n\nSince we added as const the values in the ITranslation will be readonly [string, string], thus we have to update the ITranslation to the following:\ninterface ITranslation {\n  [key: string]: readonly [string, string];\n}\n\nNext, we need to add a generic parameter to useTranslator so it works over the specific instance of ITranslation.  The same goes for the translate function. It should accept the generic parameter for the key of ITranslation and return the value for that specific key:\nconst useTranslator = <T extends ITranslation>(translations: T) => {\n  const language = useLanguage(); // just getting the language setting from another hook\n\n  const translate = <K extends keyof T>(key: K): T[K][number] => {\n    // return retrieved value\n  };\n\n  return translate;\n};\n\nSince it is not asked in the question translate will return a union of the translations for the specific key, which is achieved by T[K][number]\nUsage:\nconst Component = () => {\n  const translate = useTranslator(translation);\n  \n  // \"something in german\" | \"something in spanish\"\n  const case1 = translate('something in english');\n\n  // \"anotherthing in german\" | \"anotherthing in spanish\"\n  const case2 = translate( 'anotherthing in english');\n\n  return null;\n};\n\nplayground\n"
},
{
"QuestionId": "76381023",
"QuestionTitle": "jquery above and below screen sizes",
"QuestionBody": "I have added a script for showing a div before different divs in different screen size. This is the code I used:\njQuery(function($){ \njQuery(document).ready(function(){\n    jQuery(window).on('resize', function(){\n        if(jQuery(window).width() <= 1024){\n            jQuery( \".checkout.woocommerce-checkout .woocommerce-shipping-fields__wrapper\" ).insertBefore( \".checkout.woocommerce-checkout .flux-step.flux-step--2 .flux-checkout__shipping-table\" );\n        }\n        else if(jQuery(window).width() >= 1025){\n            jQuery( \".checkout.woocommerce-checkout .woocommerce-shipping-fields__wrapper\" ).insertBefore( \".checkout.woocommerce-checkout .flux-checkout__content-right #order_review\" );\n        }\n    }); \n}); \n});\n\nBut the code is not working when I open the site. It only works if I resize the screen. May be due to the resize function is used.\nCan anyone please guide me how to make it so that it'll show the 2 conditions even without resizing the screen and one'll work above 1024px and another below 1024px.\nTIA\n",
"AnswerId": "76381114",
"AnswerBody": "Just put your code in a function and call it on the document ready:\n\n\n$(function(){\n  \n  resize();\n  \n  $(window).on('resize', resize);\n\n  function resize(){\n    $( \".checkout.woocommerce-checkout .woocommerce-shipping-fields__wrapper\" )\n      .insertBefore(\n        $(window).width() <= 1024 ? \n        \".checkout.woocommerce-checkout .flux-step.flux-step--2 .flux-checkout__shipping-table\" : \n        \".checkout.woocommerce-checkout .flux-checkout__content-right #order_review\"\n      );\n   }\n   \n}); \n\n\n\n"
},
{
"QuestionId": "76378620",
"QuestionTitle": "How is arbitrary distributed for Int? Why is it limited by so small values?",
"QuestionBody": "I am trying to compare the QuickCheck library to the SmallCheck one. In SmallCheck I can reach particular value manipulating depth parameter. In QuickCheck:\n>a<-generate (replicateM 10000 arbitrary) :: IO [Int]\n>length a\n10000\n>maximum a\n30\n\nand my question then is: why are 10,000 \"random\" (\"arbitrary\") integers limited by 30?! I expected to see more \"widely\" distributed values within the range 0..10,000, maybe the maximum value close to 5,000.\n",
"AnswerId": "76378997",
"AnswerBody": "The documentation contains a clue:\n\nThe size passed to the generator is always 30\n\nBy default QuickCheck works by starting with 'easy' or 'small' inputs to see if it can find counterexamples with those. Only if it finds no problems with the small inputs does it gradually widen the range of generated input. The size value (which runs implicitly throughout everything that QuickCheck does) is the value that controls this behaviour.\nWhen you run QuickCheck (e.g. with quickCheck) it automatically increases the size as it goes.\nYou're not really supposed to use the generate function directly, but if you do, you can resize it:\nghci> b <- generate (replicateM 10000 (resize 60 arbitrary)) :: IO [Int]\nghci> maximum b\n60\n\nThat said, how are you supposed to use QuickCheck? The documentation describes quickCheck along with a multitude of variations you can use to evaluate properties.\nPersonally, I integrate my QuickCheck properties with a unit testing framework with testProperty. You can see examples here: Property-based testing is not the same as partition testing.\n"
},
{
"QuestionId": "76384387",
"QuestionTitle": "How can I resolve the TypeScript error 'Function lacks ending return statement and return type does not include 'undefined'' in my code?",
"QuestionBody": "I have the following simple function (make) that calls the handle function and is supposed to retry a number of times whenever that function throws. If the retries are exhausted, the make function should throw the error.\nconst handle = async (): Promise<string> => 'hi';\n\nconst make = async (): Promise<string> => {\n  const MAX_RETRIES = 2;\n  for (let idx = 0; idx <= MAX_RETRIES; idx++) {\n    try {\n      return await handle();\n    } catch (err) {\n      if (idx < MAX_RETRIES) {\n        continue;\n      } else {\n        throw err;\n      }\n    }\n  }\n};\n\nI'm using TypeScript, which is complaining because the return type doesn't include undefined:\n\nFunction lacks ending return statement and return type does not include 'undefined'.\n\nFor reference, this is the TS Playground for the code above.\nI'm looking for guidance on how to handle the return type for the function.\nNote that:\n\nI don't want to change my tsconfigs (currently set to strict)\nI don't want to modify the return type to Promise<string | undefined>\n\nMy understanding is that the make function can only either return a string (inside the try block) or throw an error once the retries have been exhausted. If that's the case then where does the undefined that TS is asking for comes from? Am I missing something?\n",
"AnswerId": "76384457",
"AnswerBody": "\nMy understanding is that the make function can only either return a string (inside the try block) or throw an error once the retries have been exhausted.\n\nI'm fairly sure you're right, but TypeScript can't quite follow logic that complex, so it (incorrectly, I think) sees a path through the function that doesn't do an explicit return and so implicitly returns undefined (wrapped in a promise).\nYou can solve it in a few ways:\n\nAdd a return \"\"; at the end with a comment noting it'll never happen. (Blech.)\nAdd a throw new Error(\"Logic error, this will never be reached.\"); at the end.\nRewrite the function to make the final attempt more obviously a return-or-throw situation by using < instead of <= and then repeating the return await handle(); at the end. (Not great to have to repeat it, but it's very simple.)\n\nI don't think #1 or #2 need examples, but here's what #3 might look like:\nconst make = async (): Promise<string> => {\n    const MAX_RETRIES = 2;\n    for (let idx = 0; idx < MAX_RETRIES; idx++) {\n        try {\n            return await handle();\n        } catch (err) {\n            continue; // I guess technically we don't need this, since\n                      // the loop doesn't do anything else\n        }\n    }\n    return await handle();\n};\n\nFor me, #2 is the winner (or jcalz's rewrite), but any of them will make TypeScript happy, it's really a style choice.\n"
},
{
"QuestionId": "76384356",
"QuestionTitle": "How can i get all the metrics where two label have same values using promql?",
"QuestionBody": "I am new to promql. So not sure if promql supports my requirement or not.\nmax_over_time(cbnode_systemstats_cpu_utilization_rate{instance=\"a\",node=\"a\"}[6h])\n\nThis above query gives me result  of max cpu utilization in past 6 hr for instance a single instnace a.\nHowever I want a query which fetches all metrics for all the instances where instance and node has same value. Something similar to below:\nmax_over_time(cbnode_systemstats_cpu_utilization_rate{instance = node}[6h])\n\n",
"AnswerId": "76384460",
"AnswerBody": "There is no easy elegant way to do that.\nBut you can utilize label_replace, logic of label matching for binary operations and a pinch of ingenuity.\nlabel_replace(cbnode_systemstats_cpu_utilization_rate{}, \"pseudoid\", \"$1\", \"instance\", \"(.*)\")\n == label_replace(cbnode_systemstats_cpu_utilization_rate{}, \"pseudoid\", \"$1\", \"node\", \"(.*)\")\n\nHere we add to LHS metric new label called pseudoid with value of instance, and same for RHS, but with value of node.\nResult will be returned only if all labels are the same, and in turn it will mean that instance == pseudoid == node.\nDemo of similar query can be seen here.\nNotice that since it is not the instant vector selector, you'll need to use subquery syntax to pass it into max_over_time.\nYou resulting query should look like this:\nmax_over_time(\n (\n   label_replace(cbnode_systemstats_cpu_utilization_rate{}, \"pseudoid\", \"$1\", \"instance\", \"(.*)\")\n     == label_replace(cbnode_systemstats_cpu_utilization_rate{}, \"pseudoid\", \"$1\", \"node\", \"(.*)\")\n )[6h:]\n)\n\n"
},
{
"QuestionId": "76381015",
"QuestionTitle": "How to Save data to the Database using Laravel 8?",
"QuestionBody": "This is ItemManufactureController file\nclass ItemManufactureController extends Controller\n{\n    public function index(){\n\n        return view('item_manufacture');\n    }\n    // Save category data into the database\n    public function store(Request $request){\n\n        $newManufacture = new ItemManufacture;\n        $newManufacture->name = $request->input('txtManufactureName');\n        $newManufacture->status = $request->input('status', 'available');\n\n        dd($newManufacture);\n\n        $newManufacture->save();\n        return redirect('/item_manufacture');\n\n    }\n}\n\nThis is item_manufacture.blade.php file\n{{--this page add to layout   --}}\n@extends('layout.layout_01')\n\n{{--identity the content form the layout--}}\n@section('content')\n\n    <div class=\"container\">\n        <div class=\"row\">\n            <div class=\"col-md-4\"></div>\n\n            <div class=\"col-md-4\">\n                <div class=\"card\">\n                    <h5 class=\"card-header\">Add Item Manufacture Details</h5>\n                    <div class=\"card-body\">\n\n                        <div class=\"input-field p-3\">\n                            <label for=\"txtManufactureName\">Manufacture Name :</label>\n                            <div class=\"col-sm-8 p-2\">\n                                <input type=\"text\" placeholder=\"Item Name\" name=\"txtManufactureName\" id=\"txtManufactureName\">\n                            </div>\n                        </div>\n\n                        <div class=\"input-field p-3\">\n\n                            <div class=\"col-sm-8 p-2\">\n\n                            </div>\n                        </div>\n\n                        <a href=\"/save_manufacture\" class=\"btn btn-primary mb-2\" id=\"btnAdd\">ADD</a>\n                    </div>\n                </div>\n            </div>\n\n            <div class=\"col-md-4\"></div>\n        </div>\n\n    </div>\n\n@endsection\n\nThis is route file\n\n//save manufacture\nRoute::get('/save_manufacture', [ItemManufactureController::class, 'store'])->name('saveManufacture');\nRoute::get('/item_manufacture', function (){\n    return view('pages.item_manufacture');\n});\n\nThis is Model file\nclass ItemManufacture extends Model\n{\n    use HasFactory;\n//    public $timestamps=false;\n    protected $connection = 'mysql';\n    protected $primaryKey = 'id';\n    protected $table = 'item_manufacture';\n    protected $fillable = [\n        'name',\n        'status'];\n}\n\nwhen add data into the form and click \"ADD\" button array comes null value\nI used Laravel 8 framework, when I add data into the input field of the item_manufacture form, data will not pass the array. If there any error of my code, Please correct it.\nHow to save data and get values from the input fields using Laravel framework?\n",
"AnswerId": "76381115",
"AnswerBody": "Please make your route as post since you're storing the data and change your route in chaining name() method as saveManufacture.store\nRoute::post('/save_manufacture', [ItemManufactureController::class, 'store'])->name('saveManufacture.store');\n\nAnd in your blade file wrap your inputs inside form tag and set named route in your action.\nAnd then replace a tag (anchor tag) with input type submit since we have added action in our form tag. so your blade file will look this.\n{{--this page add to layout   --}}\n@extends('layout.layout_01')\n\n{{--identity the content form the layout--}}\n@section('content')\n    <div class=\"container\">\n        <div class=\"row\">\n            <div class=\"col-md-4\"></div>\n            <div class=\"col-md-4\">\n                <div class=\"card\">\n                    <h5 class=\"card-header\">Add Item Manufacture Details</h5>\n                    <div class=\"card-body\">\n                        <form action=\"{{ route('saveManufacture.store') }}\" method=\"post\">\n                        <div class=\"input-field p-3\">\n                            <label for=\"txtManufactureName\">Manufacture Name :</label>\n                            <div class=\"col-sm-8 p-2\">\n                                <input type=\"text\" placeholder=\"Item Name\" name=\"txtManufactureName\" id=\"txtManufactureName\">\n                            </div>\n                        </div>\n                        <div class=\"input-field p-3\">\n                            <div class=\"col-sm-8 p-2\">\n                            </div>\n                        </div>\n                        <input type=\"submit\" class=\"btn btn-primary mb-2\" id=\"btnAdd\" value=\"ADD\">\n                        </form>\n                    </div>\n                </div>\n            </div>\n            <div class=\"col-md-4\"></div>\n        </div>\n    </div>\n@endsection\n\nNow you'll able to get the request param in your store() function, please try to debug dd($request->post());\n"
},
{
"QuestionId": "76378362",
"QuestionTitle": "Prevent webpack from auto-incrementing project version",
"QuestionBody": "I am working with a chrome extension which uses webpack to build.\nTo build I use this : cross-env NODE_ENV=production yarn webpack -c webpack.config.js --mode production\nwebpack.config.js\nconst HTMLPlugin = require('html-webpack-plugin');\nconst CopyPlugin = require('copy-webpack-plugin');\nconst path = require('path');\nconst UglifyJSPlugin = require('uglifyjs-webpack-plugin');\nconst BrowserExtensionPlugin = require(\"extension-build-webpack-plugin\");\n\nmodule.exports = {\n  entry: {\n    options: './src/options.tsx',\n    popup: './src/popup.tsx',\n    content: './src/content.tsx',\n    background: './src/background.tsx',\n  },\n  output: {\n    filename: '[name].js',\n    path: path.resolve(__dirname, 'build'),\n  },\n  resolve: {\n    extensions: ['.js', '.jsx', '.ts', '.tsx', '.css'],\n    modules: [path.resolve(__dirname, 'src'), 'node_modules'],\n    alias: {\n      react: 'preact/compat',\n      'react-dom': 'preact/compat',\n    },\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.(tsx|jsx|ts|js)x?$/,\n        exclude: /node_modules/,\n        use: [\n          {\n            loader: 'babel-loader',\n            options: {\n              presets: [\n                \"@babel/preset-env\",\n                \"@babel/preset-react\",\n                \"@babel/preset-typescript\",\n              ],\n            },\n          },\n        ],\n      },\n      {\n        test: /\\.svg$/,\n        use: ['@svgr/webpack'],\n      },\n    ],\n  },\n  plugins: [\n    new HTMLPlugin({\n      chunks: ['options'],\n      filename: 'options.html',\n      title: 'Options page title',\n    }),\n    new HTMLPlugin({\n      chunks: ['popup'],\n      filename: 'popup.html',\n    }),\n    new CopyPlugin([\n      { from: './src/_locales/', to: './_locales' },\n      { from: './src/assets', to: './assets' },\n      { from: './src/manifest.json', to: './manifest.json' },\n    ]),\n    new BrowserExtensionPlugin({devMode: false, name: \"build/chromium.zip\", directory: \"src\", updateType: \"minor\"}),\n  ],\n  optimization: {\n    minimizer: [\n      new UglifyJSPlugin({\n        uglifyOptions: {\n          compress: {\n            drop_console: true,\n            drop_debugger: true,\n          }\n        }\n      })\n    ]\n  },\n  mode: 'production',\n  stats: 'minimal',\n  performance: {\n    hints: false,\n    maxEntrypointSize: 512000,\n    maxAssetSize: 512000\n  }\n};\n\n\nmanifest.json:\n{\n    \"manifest_version\": 3,\n    \"name\": \"__MSG_appName__\",\n    \"description\": \"__MSG_appDesc__\",\n    \"default_locale\": \"en\",\n    \"version\": \"0.1.0\",\n    ....\n    ....\n}\n\nIf I run cross-env NODE_ENV=production yarn webpack -c webpack.config.js --mode production again it increments the version from  0.1.0 to   0.2.0 automatically not just in build folder but in src folder as well. How can I prevent this auto increment functionality.\nI suspect it's due to one of the webpack plugins I am using.\n",
"AnswerId": "76378998",
"AnswerBody": "This is caused by extension-build-webpack-plugin which you really shouldn't have struggled to find, as there's a total of 4 plugins there to look at.\nNo, it does not offer any method of avoiding version bumps. You can only configure if you want it to bump the major or minor version number, defaulting to minor.\nIt's a really weird library to be using, it gets few downloads and is unmaintained. There's probably better alternatives out there.\n"
},
{
"QuestionId": "76384281",
"QuestionTitle": "Javascript: run specific parts of strings through a function",
"QuestionBody": "I want to parse some data that's in a string format. Anything enclosed in parenthesis in the string to parse should be replaced with itself run through a function. This is what I want:\nfunction foo(str) {\n    return parseInt(str) + 1; // Example function, not actually what the function will be\n}\n\nfunction parse(str) {\n    // everything in str that is enclosed in parenthesis should be replaced with itself ran through foo();\n\n    // Example\n    // Input: \"My name is foo and I am (0) year old.\"\n    // Output: \"My name is foo and I am 1 year old.\"\n    // \"(0)\" has been replaced with the result of foo(\"0\")\n}\n\nI have thought up a couple bad workarounds, but I want something more robust. For example:\nfunction parse(str) {\n    // Input: \"My name is foo and I am (0) year old.\"\n    str = str.replaceAll(\"(\", \"${foo('\");\n    str = str.replaceAll(\")\", \"')}\");\n    str = \"`\" + str + \"`\"\n    // Here str will be \"`My name is foo and I am ${foo(0)} year old.`\"\n    // And I can use eval() or something to treat it like I've typed that\n}\n\nThis, however, is kind of a bad way of doing it.\nEDIT: I tested it, it works, but it is quite vulnerable.\nI can't think of anything else and I'm not very good with RegEx. (although I'd accept a solution using it)\n",
"AnswerId": "76384463",
"AnswerBody": "Here's what I would do. I would match the string with a RegEx that would match anything inside parenthesis in the string. With that, I would then use str.replaceAll() to replace the matched string with the result of the foo() function.\nconst regex = /\\((\\d*)\\)/gm;\n\nfunction foo(str) {\n    return parseInt(str) + 1;\n}\n\nfunction parse(str) {\n  \n  // Loop all match the regex find in the string\n  let m;\n  while ((m = regex.exec(str)) !== null) {\n    \n    // This is necessary to avoid infinite loops with zero-width matches\n    if (m.index === regex.lastIndex) {\n        regex.lastIndex++;\n    }\n    \n    // Replace all instance of the match with the operation of the match\n    str = str.replaceAll(m[0], foo(m[1]))\n  }\n  return str;\n}\n\nlet p = parse('My name is foo and I am (0) year old and I want (54) apples');\n\n// The result will be: My name is foo and I am 1 year old and I want 55 apples\n\nWith that, you won't need to use eval() as it potentially pose a risk for your application.\nI hope that would work for you. If I missed anything, tell me, I will edit my answer.\n"
},
{
"QuestionId": "76381105",
"QuestionTitle": "Find unique date from existing dataframe and make a new CSV with corresponding column values",
"QuestionBody": "I have a time series every which looks like this :\n\n\n\n\nTime\nVolume every minute\n\n\n\n\n2023-05-25T00:00:00Z\n284\n\n\n2023-05-25T00:01:00Z\n421\n\n\n.\n.\n\n\n.\n.\n\n\n2023-05-27T23:58:00Z\n894\n\n\n2023-05-27T23:59:00Z\n357\n\n\n\n\nI have to make new CSV by iterating Time column finding unique date and making new columns with corresponding values of volume every minute. For example desired output:\n\n\n\n\nDate\nmin1\nmin2\n...\nmin1440\n\n\n\n\n2023-05-25\n284\n421\n...\n578\n\n\n2023-05-26\n512\n645\n...\n114\n\n\n2023-05-27\n894\n357\n...\n765\n\n\n\n\ni am able to fetch unique dates but after that i am clueless. please find my sample codes:\nimport pandas as pd\n\ntrain_data = pd.read_csv('date25to30.csv')\n\nprint(pd.to_datetime(train_data['time']).dt.date.unique())\n\n",
"AnswerId": "76381147",
"AnswerBody": "First add parameter parse_dates to read_csv for convert Time column to datetimes:\ntrain_data = pd.read_csv('date25to30.csv', parse_dates=['Time'])\n\nThen create minutes by converting HH:MM:SS to timedeltas by to_timedelta and Series.dt.total_seconds, divide 60 and add 1 because python count from 0:\nminutes = (pd.to_timedelta(train_data['Time'].dt.strftime('%H:%M:%S'))\n             .dt.total_seconds()\n             .div(60)\n             .astype(int)\n             .add(1))\n\nLast pass to DataFrame.pivot_table with DataFrame.add_prefix:\ndf = (train_data.pivot_table(index=train_data['Time'].dt.date,\n                             columns=minutes,\n                             values='Volume',\n                             aggfunc='sum').add_prefix('min'))\nprint (df)\nTime         min1   min2  min1439  min1440\nTime                                      \n2023-05-25  284.0  421.0      NaN      NaN\n2023-05-27    NaN    NaN    894.0    357.0\n\n"
},
{
"QuestionId": "76378633",
"QuestionTitle": "Cannot properly hide the appbar title on scroll in flutter",
"QuestionBody": "I want to hide the AppBar on scroll. The search icon is hidden properly and also the opacity decreases on scroll. But for the title, it is not working.\nimport 'package:flutter/material.dart';\nimport 'package:vet_mobile/screens/chat.dart';\nimport 'package:vet_mobile/screens/logot.dart';\n\nclass HomeScreen extends StatelessWidget {\n  const HomeScreen({Key? key}) : super(key: key);\n\n  @override\n  Widget build(BuildContext context) {\n    return DefaultTabController(\n      length: 3,\n      child: Scaffold(\n        body: NestedScrollView(\n          headerSliverBuilder: (BuildContext context, bool innerBoxIsScrolled) {\n            return <Widget>[\n              SliverAppBar(\n                title: Row(\n                  mainAxisAlignment: MainAxisAlignment.spaceBetween,\n                  children: [\n                    Text(\n                      'WhatsApp',\n                      style: TextStyle(\n                        color: Theme.of(context).textTheme.bodyLarge!.color,\n                      ),\n                    ),\n                    IconButton(\n                      onPressed: () {},\n                      icon: Icon(\n                        Icons.search,\n                        color: Theme.of(context).textTheme.bodyLarge!.color,\n                      ),\n                    ),\n                  ],\n                ),\n                pinned: true,\n                floating: true,\n                elevation: 5,\n                bottom: TabBar(\n                  indicatorSize: TabBarIndicatorSize.tab,\n                  indicatorWeight: 4,\n                  indicatorColor: Theme.of(context).textTheme.bodyLarge!.color,\n                  labelStyle:\n                      TextStyle(fontSize: 13, fontWeight: FontWeight.w600),\n                  labelColor: Theme.of(context).textTheme.bodyLarge!.color,\n                  unselectedLabelColor:\n                      Theme.of(context).textTheme.bodySmall!.color,\n                  dividerColor: Colors.transparent,\n                  tabs: const [\n                    Tab(text: 'CHATS'),\n                    Tab(text: 'STATUS'),\n                    Tab(text: 'CALLS'),\n                  ],\n                ),\n              ),\n            ];\n          },\n          body: const TabBarView(\n            children: [\n              Center(child: LogoutScreen()),\n              Center(child: ChatScreen()),\n              Center(child: Text('Patient')),\n            ],\n          ),\n        ),\n      ),\n    );\n  }\n}\n\n\n\nAs we can see the opacity of the search button decreases slowly as I scroll down but not for the title.\nI tried using the preferred height, animation controller, but it messed up more.\n",
"AnswerId": "76379006",
"AnswerBody": "Seems that this effect does not work when you set a custom style. Remove the fixed style setting from here:\nText(\n  'PawCare',\n  // remove this\n  /*style: TextStyle(\n    color: Theme.of(context).textTheme.bodyLarge!.color,\n  ),*/\n),\n\nTo set the style of the title text, use the titleTextStyle configuration of SliverAppBar:\nSliverAppBar(\n  titleTextStyle: TextStyle(\n   color: Theme.of(context).textTheme.bodyLarge!.color),\n...\n\n"
},
{
"QuestionId": "76378657",
"QuestionTitle": "Haskell: cache result of a function in pattern matching",
"QuestionBody": "I have the following algebraic data type:\ndata Tree a = Empty | Node a (Tree a) (Tree a)\n  deriving (Show, Eq)\n\nAlso, I have\ndata Step = StepL | StepR\n  deriving (Show, Eq)\n\nNow, I need a function search that takes\n\na root of the tree\na target value t\n... and it must return a path of type [Step] leading to a node with value t. Also, if t is not present in the tree, search must return Nothing. Finally, the input is guaranteed to have the target value at most once.\n\nMy best effort, as of now, is:\nsearchHelper :: Eq a => a -> Tree a -> [Step] -> Maybe [Step]\nsearchHelper _ Empty _ = Nothing\nsearchHelper targetValue (Node nodeValue leftChild rightChild) stepsSoFar = \n  if targetValue == nodeValue then Just stepsSoFar \n  else if searchHelper targetValue leftChild (stepsSoFar ++ [StepL]) /= Nothing then searchHelper targetValue leftChild (stepsSoFar ++ [StepL])\n  else if searchHelper targetValue rightChild (stepsSoFar ++ [StepR]) /= Nothing then searchHelper targetValue rightChild (stepsSoFar ++ [StepR])\n  else Nothing\n\nsearch :: Eq a => a -> Tree a -> Maybe [Step]\nsearch targetValue root = searchHelper targetValue root []\n\nAs you can see, I call the searchHelper too often (else if searchHelper targetValue leftChild (stepsSoFar ++ [StepL]) /= Nothing then searchHelper targetValue leftChild (stepsSoFar ++ [StepL])). I need a machinery that would allow me to cache the results of searchHelper calls and use them\nin if ... then ... else.\nQ: How can I do it?\n",
"AnswerId": "76379177",
"AnswerBody": "The use of the word cache confused me, but if I understand the question correctly, the real problem is the repeated use of the same expression. That could certainly become a readability and maintainability issue in a larger code base, so is worthwhile addressing.\nFrom the context this looks like a 'toy problem'. There's nothing wrong with that - I play with plenty of those myself to learn new stuff. The reason I mention it, though, is that from this and other clues I gather that you're still a Haskell beginner. Again: nothing wrong with that, but it just means that I'm going to skip some of the slightly more advanced Haskell stuff.\nChecking for Nothing or Just like in the OP is rarely idiomatic Haskell. Instead you'd use pattern-matching or (more commonly) some of the higher-level APIs for working with Maybe (such as Functor, Applicative, Monad, etc.).\nThat said, I gather that this isn't quite what you need right now. In order to cut down on the duplication of expressions, you can use let..in syntax in Haskell:\nsearchHelper :: Eq a => a -> Tree a -> [Step] -> Maybe [Step]\nsearchHelper _ Empty _ = Nothing\nsearchHelper targetValue (Node nodeValue leftChild rightChild) stepsSoFar = \n  if targetValue == nodeValue then Just stepsSoFar\n  else\n    let l = searchHelper targetValue leftChild (stepsSoFar ++ [StepL])\n    in if l /= Nothing then l\n  else\n    let r = searchHelper targetValue rightChild (stepsSoFar ++ [StepR])\n    in if r /= Nothing then r\n  else Nothing\n\nThis enables you to 'declare' 'variables' l and r and reuse them.\nAs my lengthy preamble suggests, this still isn't idiomatic Haskell, but I hope it adresses the immediate question.\n"
},
{
"QuestionId": "76383893",
"QuestionTitle": "Implement MultiKeyDict class in Python with alias() method for creating aliases. Existing code fails when original key is deleted. Need fix",
"QuestionBody": "Python OOP problem\nMultiKeyDict class, which is almost identical to the dict class. Creating an instance of MultiKeyDict class should be similar to creating an instance of dict class:\nmultikeydict1 = MultiKeyDict(x=1, y=2, z=3)\nmultikeydict2 = MultiKeyDict([('x', 1), ('y', 2), ('z', 3)])\n\nprint(multikeydict1['x']) # 1\nprint(multikeydict2['z']) # 3\n\nA feature of the MultiKeyDict class should be the alias() method, which should allow aliases to be given to existing keys. The reference to the created alias should not differ from the reference to the original key, that is, the value has two keys (or more if there are several aliases) when the alias is created:\nmultikeydict = MultiKeyDict(x=100, y=[10, 20])\n\nmultikeydict.alias('x', 'z') # add key 'x' alias 'z'\nmultikeydict.alias('x', 't') # add alias 't' to key 'x'\nprint(multikeydict['z']) # 100\nmultikeydict['t'] += 1\nprint(multikeydict['x']) # 101\n\nmultikeydict.alias('y', 'z') # now 'z' becomes an alias of the key 'y'\nmultikeydict['z'] += [30]\nprint(multikeydict['y']) # [10, 20, 30]\n\nThe value must remain available by alias even if the original key was removed:\nmultikeydict = MultiKeyDict(x=100)\n\nmultikeydict.alias('x', 'z')\ndel multikeydict['x']\nprint(multikeydict['z']) # 100\n\nKeys must take precedence over aliases. If some key and alias are the same, then all operations when accessing them must be performed with the key:\nmultikeydict = MultiKeyDict(x=100, y=[10, 20])\n\nmultikeydict.alias('x', 'y')\nprint(multikeydict['y']) # [10, 20]\n\nI can't implement such a feature, please give me ideas how it can be done!!!\nmultikeydict = MultiKeyDict(x=100)\n\nmultikeydict.alias('x', 'z')\ndel multikeydict['x']\nprint(multikeydict['z']) # 100\n\nmy code does not work with this test\nmultikeydict = MultiKeyDict(x=100)\n\nmultikeydict.alias('x', 'z')\ndel multikeydict['x']\nprint(multikeydict['z']) #100 \n\nclass MultiKeyDict(dict):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.aliases = {}\n\n    def alias(self, key, alias):\n        self.aliases[alias] = key\n\n    def __getitem__(self, key):\n        if key in self.aliases:\n            key = self.aliases[key]\n        return super().__getitem__(key)\n\n    def __setitem__(self, key, value):\n        if key in self.aliases:\n            key = self.aliases[key]\n        super().__setitem__(key, value)\n    \n    def __delitem__(self, key):\n        if key in self.aliases:\n            del self.aliases[key]\n        super().__delitem__(key)\n\n\nmultikeydict = MultiKeyDict(x=100, y=[10, 20])\n\nmultikeydict.alias('x', 'z')\nmultikeydict.alias('x', 't')\nprint(multikeydict['z'])\nmultikeydict['t'] += 1\nprint(multikeydict['x'])\n\nmultikeydict.alias('y', 'z')\nmultikeydict['z'] += [30]\nprint(multikeydict['y'])\n\n",
"AnswerId": "76384507",
"AnswerBody": "Some remarks:\n\nAs the specification says that keys should have precedence over aliases (when both exist), you should first test key membership on self before looking in aliases. Your methods first check for membership in aliases...\n\nAs a value must continue to exist when a key is deleted for which there are still alias(es), I would suggest storing the values wrapped in a list (that just has that value as only member). This way you can reference that list in an alias entry. When the key is deleted, the alias will still have the reference to the list and can still act on it.\n\n\nHere is how that could look:\nclass MultiKeyDict(dict):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.aliases = {}\n        # wrap each value in a list of size 1:\n        for key, value in self.items():\n            super().__setitem__(key, [value])\n            \n    def alias(self, key, alias):\n        self.aliases[alias] = super().__getitem__(key)\n\n    def __getitem__(self, key):\n        if key in self:\n            return super().__getitem__(key)[0]\n        return self.aliases[key][0]\n\n    def __setitem__(self, key, value):\n        if key in self:\n            super().__getitem__(key)[0] = value\n        elif key in self.aliases:\n            self.aliases[key][0] = value\n        else:\n            super().__setitem__(key, [value])\n\n    def __delitem__(self, key):\n        if key in self:\n            return super().__delitem__(key)\n        del self.aliases[key]\n\n"
},
{
"QuestionId": "76381091",
"QuestionTitle": "Narrow down literal unions based on previously used values",
"QuestionBody": "The scenario is the following:\ntype Option = 'a' | 'b' | 'c' | 'd'\n\ntype Question = {\n  message: string;\n  options: Option[];\n  default: Option // here's the issue\n}\n\nI want the default prop to be the one of the options used inside question.options. For example:\nconst q1: Question = {\n  message: 'first question',\n  options: ['a', 'b'],\n  default: 'a'\n}\n\nconst q2: Question = {\n  message: 'second question',\n  options: ['c', 'd'],\n  default: 'a' // I want this to give an error because 'a' is not in 'c' | 'd'\n}\n\nHow can I achieve this?\n",
"AnswerId": "76381163",
"AnswerBody": "It can be done just by using Question; however, it will be a complex type that will cause a horrible time for the compiler since it grows at the speed of power of two, and if you have more options (more than 10), the compiler will reach its limits and won't compile.\nInstead, I would suggest adjusting Question to accept the Option[] as a generic parameter and assign the type of the elements of that generic parameter to default:\ntype Question<T extends Option[]> = {\n  message: string;\n  options: T;\n  default: T[number];\n};\n\nLastly, we will need a generic function that would create a question for us:\nconst createQuestion = <T extends Option[]>(question: Question<T>) => question;\n\nUsage:\nconst q1 = createQuestion({\n  message: \"first question\",\n  options: [\"a\", \"b\"],\n  default: \"a\",\n});\n\nconst q2 = createQuestion({\n  message: \"second question\",\n  options: [\"c\", \"d\"],\n  default: \"a\", // Expected error\n});\n\nplayground\n"
},
{
"QuestionId": "76378693",
"QuestionTitle": "How to create a transparent Material 3 NavigationBar in Flutter?",
"QuestionBody": "I want to make my NavigationBar transparent. I have tried extendBody: true on Scafold with surfaceTintColor=Colors.transparent to the NavigationBar widget, but nothing changed.\n",
"AnswerId": "76379413",
"AnswerBody": "According to the document, SurfaceTintColor is the color of the surface tint overlay applied to the app bar's background color to indicate elevation.\nIf you want to make the AppBar transparent, just use the property backgroundColor instead.\nScaffold(\n      extendBody: true,\n      backgroundColor: Colors.white,\n      appBar: AppBar(\n        backgroundColor: Colors.transparent, // To make appBar transparent\n        \n        /// This is not necessary. You can play around \n        /// to see surfaceTintColor when the AppBar is transaprent\n        surfaceTintColor: Colors.redAccent,\n        elevation: 3,\n        title: Text(widget.title),\n      ),\n),\n\nIt is also applied to NavigationBar\nbottomNavigationBar: NavigationBar(\n        surfaceTintColor: Colors.amber, // not neccessary\n        backgroundColor: Colors.transparent,\n        destinations: [\n          Icon(Icons.book, color: Colors.blue,),\n          Icon(Icons.map, color: Colors.blue,),\n        ],\n      ),\n\n"
},
{
"QuestionId": "76378332",
"QuestionTitle": "How to use tableone to change table percentage by row?",
"QuestionBody": "I am use library(tableone) to make my descriptive statistics for multiple variables\nThis is my code:\nlibrary(tableone)\n\nmyVars <- c(\"class\", \"age\", \"Sex\", \"bmi\", \"bmi_category\",\n            \"drink_freq\", \"smoke_yn\", \"edu_dummy\")\n\ncatVars <- c(\"class\", \"Sex\", \"bmi_category\",\n             \"drink_freq\", \"smoke_yn\", \"edu_dummy\")\n\ntab1_inf <- CreateTableOne(vars = myVars, strata = \"NEWDI\",\n                             data = TKA_table1, factorVars = catVars)\n\na1 <- print(tab1_inf, exact = \"NEWDI\", showAllLevels = TRUE)\n\nThis it default for percentage, and I want change it format like this(example):\n\nI checked its description and found no options to set.\nhttps://rdrr.io/cran/tableone/man/print.TableOne.html\nHow can I do it?\n",
"AnswerId": "76379520",
"AnswerBody": "With some clever getting-your-hands dirty, you can manipulate the percentages in the TableOne object. This uses an example dataset called pbc from survival package.\nlibrary(tableone)\nlibrary(survival)\ndata(pbc)\n\n## Make categorical variables factors\nvarsToFactor <- c(\"status\",\"trt\",\"ascites\",\"hepato\",\"spiders\",\"edema\",\"stage\")\npbc[varsToFactor] <- lapply(pbc[varsToFactor], factor)\n\n## Create a variable list\nvars <- c(\"time\",\"status\",\"age\",\"sex\",\"ascites\",\"hepato\",\n          \"spiders\",\"edema\",\"bili\",\"chol\",\"albumin\",\n          \"copper\",\"alk.phos\",\"ast\",\"trig\",\"platelet\",\n          \"protime\",\"stage\")\n\n## Create Table 1 stratified by trt\ntableOne <- CreateTableOne(vars = vars, strata = c(\"trt\"), data = pbc)\n\ntableOne\n\nBefore\n                      Stratified by trt\n                       1                 2                 p      test\n  n                        158               154                      \n  time (mean (SD))     2015.62 (1094.12) 1996.86 (1155.93)  0.883     \n  status (%)                                                0.894     \n     0                      83 (52.5)         85 (55.2)               \n     1                      10 ( 6.3)          9 ( 5.8)               \n     2                      65 (41.1)         60 (39.0)               \n  age (mean (SD))        51.42 (11.01)     48.58 (9.96)     0.018     \n  sex = f (%)              137 (86.7)        139 (90.3)     0.421     \n  ascites = 1 (%)           14 ( 8.9)         10 ( 6.5)     0.567     \n  hepato = 1 (%)            73 (46.2)         87 (56.5)     0.088     \n  spiders = 1 (%)           45 (28.5)         45 (29.2)     0.985 \n...\n\nYou should try to adapt the following code for your own data format:\nfor (i in 1:length(table1)) {\n    sum = tableOne$CatTable[[1]][[i]]$freq + tableOne$CatTable[[2]][[i]]$freq\n    tableOne$CatTable[[1]][[i]]$percent = tableOne$CatTable[[1]][[i]]$freq / sum\n    tableOne$CatTable[[2]][[i]]$percent = tableOne$CatTable[[2]][[i]]$freq / sum\n  }\n}\n\ntableOne\n\nAfter\n                      Stratified by trt\n                       1                 2                 p      test\n  n                        158               154                      \n  time (mean (SD))     2015.62 (1094.12) 1996.86 (1155.93)  0.883     \n  status (%)                                                0.894     \n     0                      83 (0.5)          85 (0.5)                \n     1                      10 (0.5)           9 (0.5)                \n     2                      65 (0.5)          60 (0.5)                \n  age (mean (SD))        51.42 (11.01)     48.58 (9.96)     0.018     \n  sex = f (%)              137 (0.5)         139 (0.5)      0.421     \n  ascites = 1 (%)           14 (0.6)          10 (0.4)      0.567     \n  hepato = 1 (%)            73 (0.5)          87 (0.5)      0.088     \n  spiders = 1 (%)           45 (0.5)          45 (0.5)      0.985   \n\n"
},
{
"QuestionId": "76384509",
"QuestionTitle": "Altair: showing the value of the current point in the tooltip",
"QuestionBody": "In the code below, we have a dataset that can be read as: \"two cooks cook1, cook2 are doing a competition. They have to make four dishes, each time with two given ingredients ingredient1, ingredient2. A jury has scored the dishes and the grades are stored in _score.\nI want to use Altair to show a graph where the x-axis is each dish (1, 2, 3, 4) and the y-axis contains the scores of the two cooks separately. This currently works but the main issue is that on hover, the tooltip does not include the score of the current point that is being hovered.\nimport altair as alt\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    \"ingredient1\": [\"potato\", \"onion\", \"carrot\", \"beet\"],\n    \"ingredient2\": [\"tomato\", \"pepper\", \"zucchini\", \"lettuce\"],\n    \"dish\": [1, 2, 3, 4],\n    \"cook1\": [\"cook1 dish1\", \"cook1 dish2\", \"cook1 dish3\", \"cook1 dish4\"],\n    \"cook1_score\": [0.4, 0.3, 0.7, 0.9],\n    \"cook2\": [\"cook2 dish1\", \"cook2 dish2\", \"cook2 dish3\", \"cook2 dish4\"],\n    \"cook2_score\": [0.6, 0.2, 0.5, 0.6],\n})\n\n\nvalue_vars = [c for c in df.columns if c.endswith(\"_score\")]\ncook_names = [c.replace(\"_score\", \"\") for c in value_vars]\nid_vars = [\"dish\", \"ingredient1\", \"ingredient2\",] + cook_names\ndf_melt = df.melt(id_vars=id_vars, value_vars=value_vars,\n                  var_name=\"cook\", value_name=\"score\")\n\nchart = alt.Chart(df_melt).mark_circle().encode(\n    x=alt.X(\"dish:O\", title=\"Dish number\"),\n    y=alt.Y(\"score:Q\", title=\"Score\"),\n    color=\"cook:N\",\n    tooltip=id_vars\n)\n\nchart.show()\n\n\nI tried explicitly adding the score columns to the tooltip:\n    tooltip=id_vars+value_vars\n\nBut that yields the following error:\n\nValueError: cook1_score encoding field is specified without a type; the type cannot be inferred because it does not match any column in the data.\n\nSo how can I get altair to also show the score of (only) the currently hovered element?\n",
"AnswerId": "76384598",
"AnswerBody": "cook1_score is not a column in df_melt, which is why you see the error. Setting tooltip=id_vars+['score'] will work.\n"
},
{
"QuestionId": "76384490",
"QuestionTitle": "Flutter: Inconsistent column padding on Buttons between Android and Windows",
"QuestionBody": "I have created a simple material app in flutter with:\nflutter create --platforms=android,windows columntest\nWhen I run the program on Android and Windows, I get some kind of padding between the ElevatedButtons on Android, but not on Windows. Do you know where this comes from and how I can make the design consistent?\nThe behavior seems to occur only with buttons (TextButton, OutlinedButton, ElevatedButton).\nI have also tested this with container (with border), there it does not occur.\nHere the code from the small app:\nimport 'package:flutter/material.dart';\n\nvoid main() {\n  runApp(const MyApp());\n}\n\nclass MyApp extends StatelessWidget {\n  const MyApp({super.key});\n\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      title: 'Flutter Demo',\n      home: Scaffold(\n        body: Center(\n          child: Column(\n            crossAxisAlignment: CrossAxisAlignment.center,\n            mainAxisAlignment: MainAxisAlignment.center,\n            children: [\n              ElevatedButton(child: const Text(\"Foobar1\"), onPressed: () {}),\n              ElevatedButton(child: const Text(\"Foobar2\"), onPressed: () {}),\n            ],\n          ),\n        ),\n      ),\n    );\n  }\n}\n\n\nHere is a screenshot at runtime:\n\nHere my flutter version:\n$ flutter --version\nFlutter 3.10.0 • channel stable • https://github.com/flutter/flutter.git\nFramework • revision 84a1e904f4 (3 weeks ago) • 2023-05-09 07:41:44 -0700\nEngine • revision d44b5a94c9\nTools • Dart 3.0.0 • DevTools 2.23.1\n\nMy Android Emulator is an: Pixel_3a_API_33_x86_64\nBut the behaviour also occurs on my physical Pixel 6 (with android UpsideDownCake)\nI look forward to your responses.\nbest regards\nMichael\n",
"AnswerId": "76384624",
"AnswerBody": "So, this implementation is done by flutter.\nThis is behaviour is because of the ThemeData.materialTapTargetSize parameter for the MaterialApp.\nThis feature decides what should be touchable dimensions of Material Button, in your case ElevatedButton.\nYou have 2 potential solutions\n\nChange padding from ElevatedButton like below\n\n    ElevatedButton(\n              onPressed: () {},\n              style: const ButtonStyle(padding: MaterialStatePropertyAll(EdgeInsets.zero)),\n              child: const Icon(Icons.abc),\n            ),\n\n\nChange value from material app\n\n    MaterialApp(\n      title: 'Flutter Demo',\n      theme: ThemeData(\n        primarySwatch: Colors.blue,\n        materialTapTargetSize: MaterialTapTargetSize.shrinkWrap),\n      home: CupertinoPickerExample(),\n    )\n\nReference :  https://stackoverflow.com/a/67580951\n"
},
{
"QuestionId": "76378581",
"QuestionTitle": "Perl Mojolicious: Passing arguments to a code ref",
"QuestionBody": "In my Mojolicious Controller, I have:\nmy @promise;\nforeach my $code (\\&doit1, \\&doit2,) {\n    my $prom = Mojo::Promise->new;\n    Mojo::IOLoop->subprocess(\n    sub {\n        my $r = $code->(\"Hello\");\n        return $r;\n    },\n    sub {\n        my ($subprocess, $err, @res) = @_;\n        return $prom->reject($err) if $err;\n        $prom->resolve(@res);\n    },\n    );\n    push @promise, $prom;\n}\n\nMojo::Promise\n    ->all(@promise)\n    ->then(\n    sub {\n    my ($result1, $result2) = map {$_->[0]} @_;\n    });\n\nThis works, and I can pass arguments (e.g. Hello) to my sub.\nNow I converted doti1() and doit2() as helpers. So the code looks like:\nforeach my $code (sub {$self->myhelper->doit1(\"Goodbye\")},\n                  sub {$self->myhelper->doit2(\"Good night\")},\n    ) {\n    my $prom = Mojo::Promise->new;\n    Mojo::IOLoop->subprocess(\n    sub {\n        my $r = $code->(\"Hello\"); # this is ignored?\n        return $r;\n    },\n    sub {\n        my ($subprocess, $err, @res) = @_;\n        return $prom->reject($err) if $err;\n        $prom->resolve(@res);\n    },\n    );\n    push @promise, $prom;\n}\n\nHow can I continue to pass the same set of arguments inside the loop (e.g. Hello), without having to specify them in each code ref (i.e. avoid Goodbye & Good night)? I like the idea of passing the same arguments for each code ref: $code->(\"Hello\")\n",
"AnswerId": "76379917",
"AnswerBody": "\nNow I converted doti1() and doit2() as helpers. So the code looks like:\n\nforeach my $code (sub {$self->myhelper->doit1(\"Goodbye\")},\n                  sub {$self->myhelper->doit2(\"Good night\")},\n    ) {\n    #....\n}\n\nYes but you are calling the helpers from another anonymous sub,\n\nHow can I continue to pass the same set of arguments inside the loop (e.g. Hello), without having to specify them in each code ref\n\nso to recover the argument and pass it on the the helper, you just do:\nforeach my $code (sub {my $arg = shift; $self->myhelper->doit1($arg)},\n                  sub {my $arg = shift; $self->myhelper->doit2($arg)},\n) {...}\n\nor more generally as @Dada pointed out in the comments:\nforeach my $code (sub {$self->myhelper->doit1(@_)},\n                  sub {$self->myhelper->doit2(@_)},\n) {...}\n\n"
},
{
"QuestionId": "76378589",
"QuestionTitle": "How can I parse the certificate information output from the security command in Mac?",
"QuestionBody": "I need to retrieve the attributes of a certificate that is stored in the keychain on my Mac from the command line. I can collect them manually from the Keychain Access app, but I want to do that with a script.\n\nI used the security command to get a certificate and \"grep\" to inspect the \"subject\" section:\nsecurity find-certificate -c \"Apple Development\" login.keychain | grep \"subj\"\n\nand then got the following output (some omitted by \"...\").\n\"subj\"<blob>=0x3081943...553  \"0\\201\\2241\\0320\\03...02US\"\n\nIn the output above, what format is the data following \"subj\"<blob>= and how can I parse it? I found that decoding the first half of the hexadecimal sequence(0x30...) with UTF-8 yields the second half of the string (0\\201...), but I don't know what 0\\201\\2241\\... means. I have tried other character codes, but they just give me garbled characters.\n",
"AnswerId": "76381943",
"AnswerBody": "As for the format, the certificates are stored in DER/PEM format, which is a representation of ASN.1 encoded data. What you see in the output is the hexadecimal representation of the ASN.1 binary data. The blob indicates that the value or attribute is stored as binary data.\nAs for exporting (for certificates), I would highly recommend combining security with openssl as follows:\nsecurity find certificate -p -c \"Apple Development\" login.keychain | openssl x509 -noout -subject\n\nThe -p option in the security command exports the found certificate in PEM format, which is something openssl can use. You can then pipe the PEM data into the openssl command, where one can easily extract the subject using the -subject option.\nYou can check out both the man page of security and the man page of openssl x509.\n"
},
{
"QuestionId": "76384082",
"QuestionTitle": "error messages fitting a non-linear exponential model between two variables",
"QuestionBody": "I have two variables that I'm trying to model the relationship between and extract the residuals. The relationship between the two variables is clearly a non-linear exponential relationship. I've tried a few different approaches with nls, but I keep getting different error messages.\n\n# dataset\ndf <- structure(list(y = c(464208.56, 334962.43, 361295.68, 426535.68, 258843.93, 272855.46, \n   166322.72, 244695.28, 227003.03, 190728.4, 156025.45, 72594.24, 56911.4, 175328.95, 161199.76, \n   152520.77, 190610.57, 60734.34, 31620.9, 74518.86, 45524.49, 2950.58, 2986.38, 15961.77, 12484.05, \n   6828.41, 2511.72, 1656.12, 5271.4, 7550.66, 3357.71, 3620.43, 3699.85, 3337.56, 4106.55, 3526.66, \n   2996.79, 1649.89, 4561.64, 1724.25, 3877.2, 4426.69, 8557.61, 6021.61, 6074.17, 4072.77, 4032.95, \n   5280.16, 7127.22), \n   x = c(39.23, 38.89, 38.63, 38.44, 38.32, 38.27, 38.3, 38.4, 38.56, 38.79, 39.06, 39.36, 39.68, \n   40.01, 40.34, 40.68, 41.05, 41.46, 41.93, 42.48, 43.14, 43.92, 44.84, 45.9, 47.1, 48.4, 49.78, \n   51.2, 52.62, 54.01, 55.31, 56.52, 57.6, 58.54, 59.33, 59.98, 60.46, 60.78, 60.94, 60.92, 60.71, \n   60.3, 59.69, 58.87, 57.86, 56.67, 55.33, 53.87, 52.33)), \n   row.names = c(NA, -49L), \n   class = c(\"tbl_df\", \"tbl\", \"data.frame\"), \n   na.action = structure(c(`1` = 1L, `51` = 51L), \n   class = \"omit\"))\n\n# initial model\nm <- nls(y ~  a * exp(r * x), \n         start = list(a = 0.5, r = -0.2), \n         data = df)\nError in nls(y ~ a * exp(r * x), start = list(a = 0.5, r = -0.2), data = df,  : singular gradient\n\n# add term for alg\nm <- nls(y ~  a * exp(r * x), \n         start = list(a = 0.5, r = -0.2), \n         data = df,\n         alg = \"plinear\")\nError in nls(y ~ a * exp(r * x), start = list(a = 0.5, r = -0.2), data = df,  : \n  step factor 0.000488281 reduced below 'minFactor' of 0.000976562\n\n",
"AnswerId": "76384628",
"AnswerBody": "log-Gaussian GLM\nAs @Gregor Thomas suggests you could linearize your problem (fit a log-linear regression), at the cost of changing the error model.  (Basic model diagnostics, i.e. a scale-location plot, suggest that this would be a much better statistical model!) However, you can do this efficiently without changing the error structure by fitting a log-link Gaussian GLM:\nm1 <- glm(y ~ x, family = gaussian(link = \"log\"), data = df)\n\nThe model is y ~ Normal(exp(b0 + b1*x), s), so a = exp(b0), r = b1.\nI tried using list(a=exp(coef(m1)[1]), r=coef(m1)[2]) as starting values, but even this was too finicky for nls().\nThere are two ways to get nls to work.\nshifted exponential\nAs @GregorThomas suggests, shifting the x-axis to x=38 also works fine (given a sensible starting value):\nm <- nls(y ~  a * exp(r * (x-38)), \n         start = list(a = 3e5, r = -0.35), \n         data = df)\n\nprovide nls with a gradient\nThe deriv function will generate a function with the right structure for nls (returns the objective function, with a \".grad\" attribute giving a vector of derivatives) if you ask it nicely. (I'm also using the exponentiated intercept from the log-Gaussian GLM as a starting value ...)\nf <- deriv( ~ a*exp(r*x), c(\"a\", \"r\"), function.arg = c(\"x\", \"a\", \"r\"))\nm2 <- nls(y ~  f(x, a, r),\n         start = list(a = exp(coef(m1)[1]), r = -0.35),\n         data = df)\n\nWe can plot these to compare the predictions (visually identical):\npar(las = 1, bty = \"l\")\nxvec <- seq(38, 60, length = 101)\nplot(y ~ x, df)\nlines(xvec, predict(m1, newdata = data.frame(x=xvec), type = \"response\"),\n      col = 2)\nlines(xvec, predict(m, newdata = data.frame(x=xvec)), col = 4,  lty = 2)\nlines(xvec, predict(m2, newdata = data.frame(x=xvec)), col = 5,  lty = 2)\n\n\nWith a little bit of extra work (exponentiating the intercept for the Gaussian GLM, shifting the x-origin back to zero for the nls fit) we can compare the coefficients (only equal up to a tolerance of 2e-4 but that should be good enough, right?)\na1 <- exp(coef(m1)[[1]])\na2 <- coef(m)[[1]]*exp(-38*coef(m)[[2]])\nall.equal(c(a = a1, r = coef(m)[[2]]),\n          c(a = a2, r = coef(m1)[[2]]), tolerance = 1e-4)\nall.equal(c(a = a1, r = coef(m)[[2]]),\n          coef(m2), tolerance = 2e-4)\n\n"
},
{
"QuestionId": "76382271",
"QuestionTitle": "Function call as a parameter inside insert values statement",
"QuestionBody": "I'm trying to insert the data inside a forall loop. For this case, I cannot use a temporary variable and set result of the function beforehand.\nThe function just maps a number to a string:\ncreate or replace function GetInvoiceStatus(status number)\n    return nvarchar2\nas\nbegin\n    case status\n        when 0 then return 'New';\n        when 200 then return 'Sent';\n        when 300 then return 'Accepted';\n        end case;\n\n    return '';\nend; \n\nwhen I call this function like:\nselect GetInvoiceStatus(200) from dual;\n\nI get the appropriate result.\nHowever, when I try to insert the data I get errors.\nThe forall insert:\nforall i in 1.. INVOICE_DATA.COUNT\ninsert into \"InvoiceAudit\"\n(\"PropertyName\", \"OldValue\", \"NewValue\" (\n            VALUES ('Status', (GetInvoiceStatus(invoice_data(i).status)),\n                    ((GetInvoiceStatus((select \"Status\" from \"Invoice\" where \"InvoiceId\" = invoice_data(i).invoiceId)))));\n\nHowever, I get the following error:\n\n[2023-06-01 15:02:57] [65000][6592] [2023-06-01 15:02:57]     ORA-06592:\nCASE not found while executing CASE statement [2023-06-01 15:02:57]\nORA-06512: at \"PUBLIC.GETINVOICESTATUS\", line 9 [2023-06-01 15:02:57]\nORA-06512: at \"PUBLIC.INVOICESSP\", line 63 [2023-06-01 15:02:57]\nPosition: 5\n\nI have double checked, and the results from invoice_data(i).Status and the other select value are both valid parameters (and have their cases covered) and return appropriate string when called outside the stored procedure.\nIs the syntax somewhere wrong?\nI would like to remain using forall if at all possible because it is much faster than a regular for loop.\n",
"AnswerId": "76382378",
"AnswerBody": "This error means that the parameter value (status) is not one of the cases in the case expression (which are 0, 200, 300).\nIf you executed this code select GetInvoiceStatus(555) as dd from dual you will get the same error. So, add ELSE clause like this:\ncreate or replace function GetInvoiceStatus(status number)\n    return nvarchar2\nas\nbegin\n    case status\n        when 0 then return 'New';\n        when 200 then return 'Sent';\n        when 300 then return 'Accepted';\n        else return '';\n    end case;\nend; \n\n"
},
{
"QuestionId": "76384531",
"QuestionTitle": "pivot returning blank instead of 0 google sheet",
"QuestionBody": "I have a spreadsheet where I have an importrange and vlookup to another file where its looking up to a pivot table. Some data is blank in the pivot table and when I lookup in the formula, I have a result of blank even though I have set it to return to 0 by iferror.\nHere's my formula:\n=iferror(VLOOKUP(A5,importrange(\"12PaJfEC7Q7gOcCx2zlMHG3YybQuk1TSsNjZDw26qFRg\",\"Converted Pivot!A:E\"),3,false),0)\n",
"AnswerId": "76384635",
"AnswerBody": "You may try:\n=let(Σ,ifna(vlookup(A5,importrange(\"12PaJfEC7Q7gOcCx2zlMHG3YybQuk1TSsNjZDw26qFRg\",\"Converted Pivot!A:E\"),3,),\"no_match_found\"),\n       if(Σ=\"\",0,Σ))\n\n\nblank_value will now be shown as 0 & a non-match output error will be prompted with no_match_found\n\n"
},
{
"QuestionId": "76380577",
"QuestionTitle": "Make an element not scroll horizontally",
"QuestionBody": "I am trying to  make a layout with:\n\nA header (gray block in the snippet)\nA body (lime borrder)\nMain body content ( blocks with red border)\n\nIf you scroll horizontally, then the header should not scroll, it should be full width and stay in view. If you scroll vertically, then the header should scroll off the page as usual. The height of the header is dynamic, and fits the content within it (this SO answer works with a fixed height)..\nThe <main> element is allowed to be wider than the viewport, but the header is always the viewport width.\nThe reason I dont add max-width: 100%; overflow-x: auto on the <main> element (like this SO answer, is because then the horizontal scroll appears at the bottom of the element, and then say one is reading the first block, and you wish to scroll horizontally, you have to scroll to the bottom of the main element to see the horizontal scroll bar, scroll to the side, then scroll back up. I wish to have the horizontal scroll bar always present if main is wider than the view port.\nI have tried position: sticky/fixed on the header but could not get it to work.\nI would prefer not to use JavaScript if possible.\n\n\nheader {\n  padding: 32px;\n  background: gray;\n  width: 100%;\n}\nmain {\n  border: 2px solid lime;\n  min-width: 100%;\n}\ndiv {\n  height: 200px;\n  width: 120%; /* make it overflow horizontally */\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  border: 2px solid red;\n}\n<header>The Header should not scroll horizntally<br>(is dynamic height)</header>\n<main>\n  <div>content 1</div>\n  <div>content 2</div>\n  <div>content 3</div>\n  <div>content 4</div>\n  <div>content 5</div>\n  <div>content 6</div>\n</main>\n\n\n\n",
"AnswerId": "76381169",
"AnswerBody": "What I have done here is make header sticky to the left part of the screen. Its parent element must be aware of size of your content to allow header to move. So I set body min-width to min-content and same with main so it can transfer its children's size to body.\nYou also may notice I used box-sizing: border-box; in the header, its so padding size is taken into account when element size is calculated(100vw in this case). You don´t want to use % on header width because it won´t have room to slide.\nAlso div sizes must not be dependent on parent size, so you can´t use % here either.\n\n\nbody{\n  min-width: min-content;\n}\n\nheader {\n  box-sizing: border-box;\n  position: sticky;\n  left: 0;\n  padding: 32px;\n  background: gray;\n  width: 100vw;\n}\nmain {\n  min-width: min-content;\n  border: 2px solid lime;\n}\ndiv {\n  height: 200px;\n  width: 120vw; /* make it overflow horizontally */\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  border: 2px solid red;\n}\n<body>\n\n<header>The Header should not scroll horizntally<br>(is dynamic height)</header>\n<main>\n  <div>content 1</div>\n  <div>content 2</div>\n  <div>content 3</div>\n  <div>content 4</div>\n  <div>content 5</div>\n  <div>content 6</div>\n</main>\n</body>\n\n\n\n"
},
{
"QuestionId": "76382239",
"QuestionTitle": "\"Unused CSS selector\" when using a SASS themify mixin with Svelte and Vite:",
"QuestionBody": "I'm trying to create a small web application using Svelte.\nOne of the requirements is to be able to change the application \"theme\" on demand, for example - dark theme, light theme, high contrast, and so on.\nI've been using an online mixin snippet to help me with that -\nhttps://medium.com/@dmitriy.borodiy/easy-color-theming-with-scss-bc38fd5734d1\nHowever, this doesn't work consistently, and I often get errors like:\n[vite-plugin-svelte] /path/to/svelte/component.svelte:61:0 Unused CSS selector \"main.default-theme div.some.element.identification\"\neven tho the selector is used and is receiving it's non-themed attributes.\nInside a themes.scss file:\n@mixin themify($themes) {\n\n    @each $theme,\n    $map in $themes {\n        main.#{$theme}-theme & {\n            $theme-map: () !global;\n\n            @each $key,\n            $submap in $map {\n                $value: map-get(map-get($themes, $theme), '#{$key}');\n                $theme-map: map-merge($theme-map, ($key: $value)) !global;\n            }\n\n            @content;\n            $theme-map: null !global;\n        }\n    }\n}\n\n@function themed($key) {\n    @return map-get($theme-map, $key);\n}\n\n$themes: (\n    default: (\n        strokeColor: green,\n        fillColor: red,\n    ),\n);\n\nand inside another scss file that is importing themes.scss:\ndiv.some.element.identification {\n    some-non-themed-attribute: some-value;\n\n    @include themify($themes) {\n        stroke: themed('strokeColor');\n        fill: themed('fillColor');\n    }\n}\n\nnow the punchline - when using this methodology, some elements are receiving their appropriate themed attributes, and others dont.\nI am also seeing the following error:\n[vite-plugin-svelte] /path/to/svelte/component.svelte:61:0 Unused CSS selector \"main.default-theme div.some.element.identification\"\nthe issue doesn't seem to be in the css selectors - since the elements that dont receive the themed attributes, still receive the other non-themed attributes in the same css clause.\nTwo final observations -\n\nWhen I'm building the project (using vite build), I can see that the css asset file being created doesn't include the css selectors that are missing their themed attributes.\nWhen i'm using the devtools to locate the supposedly unused selectors (whose themed attributes are not present), they can be found - despite the error message.\n\nI've been trying different way to solve this issue and nothing works consistently.\nThank you in advance for your help!\n",
"AnswerId": "76382400",
"AnswerBody": "You could try checking these different items:\n\nIf you use svelte-preprocess, try to add scss: { prependData: `@import 'src/styles/theme.scss';` } or whatever the path to your theme is, to the config object.\nIf it still does not work, maybe try to swap svelte-preprocess with vite-preprocess\nDisable any potential css purge plugin\n\n"
},
{
"QuestionId": "76384567",
"QuestionTitle": "Is it faster to use push_back(x) or using an index (capacity)?",
"QuestionBody": "I learned 2 ways of inserting elements into a vector.\nAnd I've been wondering which way is faster since I'm working with time limits.\nMethod 1:\nint n;\ncin>>n;\nvector<int> v(n);\nfor(int i = 0;i<n;i++){\n  cin>>v[i];\n}\n\nMethod 2:\nint n;\ncin>>n;\nvector<int> v;\nfor(int i = 0;i<n;i++){\n  int x;\n  cin>>x;\n  v.push_back(x);\n}\n\nIf you have a better method to suggest, it'd be appreciated!\n",
"AnswerId": "76384661",
"AnswerBody": "Both have issues:\nYou should be using reserve(n)\nint n;\ncin >>  n;\nvector<int> v;\nv.reserve(n);\nfor(int i = 0; i < n; ++i){\n    int x;\n    cin >> x;\n    v.emplace_back(x);\n}\n\nIn the first version: Setting size.\nHere you have the issue that you are constructing all the elements in the array. Now for integers this may be insignificant. But if we extend this to non integer types that have a constructor that needs to be called for each element and then you are using the assignment operator to copy over them.\nThe second option: push_back\nHere you run into the risk of the underlying storage being reallocated (potentially multiple times). Each time you re-allocate you need to copy the data from the old storage to the new storage.\nAgain this hurts for integers but really hurts for types with constructors and destructors.\nPrefer: emplace_back()\nRather than pushing where you need a fully constructed object. You can use emplace_back and pass in the objects used to construct the object. This allows the vector to construct the object in place. If you have simple integers or classes with effecient move semantics then not an issue but worth it as a general habit.\n"
},
{
"QuestionId": "76382402",
"QuestionTitle": "Background video in Node.js 13",
"QuestionBody": "I am trying to set up a gif as a background,I get does it not work:\nIn the code Import GridMatrix and extract the src from it, then I use the video tag to try to render it on fullscreen.\nimport React from 'react';\nimport GridMatrix from '../assets/gridMatrix.gif';\n\nfunction Home() {\n\n    return (\n        <div>\n            <video\n                className=\"matrix-bg fixed top-0 left-0 w-full h-full z-[-1] object-cover\"\n                autoPlay\n                loop\n                muted\n            >\n                <source\n                    src={GridMatrix.src}\n                    type=\"video/gif\"\n                />\n            </video>\n            <main className=\"container mx-auto py-10 px-4 flex flex-col items-center justify-center\">\n                <h1 className=\"text-4xl font-bold mb-8 text-white text-center\">\n                    UNS Demo\n                </h1>\n                <button className=\"bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-4 rounded\">\n                    Login\n                </button>\n\n            </main>\n        </div>\n    );\n}\n\nexport default Home;\n\n\n",
"AnswerId": "76382476",
"AnswerBody": "GIF files are not video files and the MIME type for them is image/gif. The <video> tag will not render them.\nYou can embed images using <img src={GridMatrix.src} /> or set it as a background-image with CSS on an element.\nNowadays, websites often embed what they call 'GIFs' that are actually video files, but notice that those are often .webm or .mp4 files, both being video formats, thus compatible with <video>.\n"
},
{
"QuestionId": "76380888",
"QuestionTitle": "Convert XML File with nested hierarchy placed in Azure Data lake to CSV using C# Azure Function",
"QuestionBody": "I have the following xml file with the below structure to convert to csv using Azure function C#. The XML file is located in Azure Data Lake location. The structure of the file is as follows.\n<root id=\"1\" created_date=\"01/01/2023\" asof_date=\"01/01/2023\">\n    <level1>\n        <data1>sdfs</data1>\n        <data2>true</data2>\n        <level2 rec=\"4\">\n            <level_record>\n                <groupid>1</groupid>\n                <groupname>somegroup</groupname>\n                <groupdate>01/01/2023</groudate>\n                <groupvalue>5</groupvalue>\n                <groupkey>ag55</groupkey>\n            </level_record>  \n            <level_record>\n                <groupid>2</groupid>\n                <groupname>somegroup1</groupname>\n                <groupdate>02/01/2023</groudate>\n                <groupvalue>6</groupvalue>\n                <groupkey>ag56</groupkey>\n            </level_record> \n       </level2> \n    </level1>\n</root> \n\nHow do i read the file from Azure data lake and convert it as a csv file?\n",
"AnswerId": "76381205",
"AnswerBody": "Here is the example of Azure Function in C# that reads an XML file from Azure Data Lake Storage and converts it to a CSV file\nusing Microsoft.Azure.Functions.Worker;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Azure.Storage;\nusing Microsoft.Azure.Storage.Auth;\nusing Microsoft.Azure.Storage.Blob;\nusing System.IO;\nusing System.Xml.Linq;\n\nnamespace YourNamespace\n{\n    public static class ConvertXmlToCsvFunction\n    {\n        [Function(\"ConvertXmlToCsvFunction\")]\n        public static void Run([BlobTrigger(\"your-container/{name}\", Connection = \"AzureWebJobsStorage\")] Stream xmlStream, string name, FunctionContext context)\n        {\n            var logger = context.GetLogger(\"ConvertXmlToCsvFunction\");\n            logger.LogInformation($\"Processing file: {name}\");\n\n            try\n            {\n                // Read the XML file content\n                string xmlContent;\n                using (StreamReader reader = new StreamReader(xmlStream))\n                {\n                    xmlContent = reader.ReadToEnd();\n                }\n\n                // Parse the XML content\n                XDocument xDoc = XDocument.Parse(xmlContent);\n\n                // Extract data and convert to CSV format\n                XElement rootElement = xDoc.Element(\"root\");\n                XElement level1Element = rootElement.Element(\"level1\");\n                XElement level2Element = level1Element.Element(\"level2\");\n\n                // Create the CSV header\n                string csv = \"groupid,groupname,groupdate,groupvalue,groupkey\" + \"\\n\";\n\n                // Iterate over level_record elements and extract data\n                foreach (XElement recordElement in level2Element.Elements(\"level_record\"))\n                {\n                    string groupid = recordElement.Element(\"groupid\").Value;\n                    string groupname = recordElement.Element(\"groupname\").Value;\n                    string groupdate = recordElement.Element(\"groupdate\").Value;\n                    string groupvalue = recordElement.Element(\"groupvalue\").Value;\n                    string groupkey = recordElement.Element(\"groupkey\").Value;\n\n                    // Append the CSV row\n                    csv += $\"{groupid},{groupname},{groupdate},{groupvalue},{groupkey}\" + \"\\n\";\n                }\n\n                // Save the CSV content to a file\n                string csvFileName = Path.ChangeExtension(name, \"csv\");\n                string csvFilePath = Path.Combine(Path.GetTempPath(), csvFileName);\n                File.WriteAllText(csvFilePath, csv);\n\n                logger.LogInformation($\"CSV file created: {csvFilePath}\");\n            }\n            catch (Exception ex)\n            {\n                logger.LogError($\"An error occurred: {ex.Message}\");\n                throw;\n            }\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76380899",
"QuestionTitle": "How can we stop vuetify 3 v-combobox from adding new items if the validation checks fail?",
"QuestionBody": "I have tried using the validation-on, rules props, they are able to validate and give me error messages but the new items are still getting appended to the state. Is there any way to change this behaviour so that every time there is a validation error it don't append the item to the state?\nParentComponent.vue\n...\n <MultiSelect\n    v-model=\"form.tags\"\n    label=\"Select Tags\"\n    :items=\"tags\"\n    item-title=\"name\"\n    item-value=\"id\"\n  />\n...\n\nMultiselectComponent.vue\n<template>\n    <v-combobox \n        multiple \n    chips \n        closable-chips \n        clearable \n        :return-object=\"false\"\n        variant=\"outlined\"\n    />\n</template>\n\nWhat I want\nBasically I don't want user to add tags that starts with a number or are all numbers\n\ne.g. 123, 2VueJs, 456890, 68yjkk etc.\n\n",
"AnswerId": "76381218",
"AnswerBody": "Validation is used to show error messages to the user and prevent the form from being submitted. But if you remove invalid values immediately, there is no error message and the values are always going to be valid.\nSo instead of validation, you can just filter the values coming out of the component. Just replace the v-model with the underlying :modelValue and @update:modelValue and pipe the values through a filter:\n<v-combobox\n  :model-value=\"values\"\n  @update:model-value=\"values = filterInvalid($event)\"\n  ...\n/>\n\nYou can also use the filter on the input of :modelValue to filter any invalid values coming in, depending on if there are preset values and how to deal with them if they are invalid.\nHere it is in a snippet:\n\n\nconst { createApp, ref } = Vue;\nconst { createVuetify } = Vuetify\nconst vuetify = createVuetify()\nconst app = {\n  setup(){\n    return {\n      values: ref([12, '12n','n']),\n      filterInvalid: (inputValues) => inputValues.filter(value => typeof value === 'string' && isNaN(value[0]))\n    }\n  }\n\n}\ncreateApp(app).use(vuetify).mount('#app')\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/npm/vuetify@3/dist/vuetify.min.css\" />\n<link href=\"https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css\" rel=\"stylesheet\">\n<div id=\"app\">\n  <v-app>\n    <v-main class=\"pa-8\">\n    \n      <v-combobox\n        :model-value=\"filterInvalid(values)\"\n        @update:model-value=\"values = filterInvalid($event)\"\n        multiple\n        chips\n        closable-chips\n        clearable\n        variant=\"outlined\"\n      ></v-combobox>\n      \n      <div>Values: {{values}}</div>\n      \n      </v-main>\n  </v-app>\n</div>\n<script src=\"https://unpkg.com/vue@3/dist/vue.global.prod.js\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/vuetify@3/dist/vuetify.min.js\"></script>\n\n\n\nNote however that removing values automatically can feel like a bug to users. You might be better off with the validation approach after all.\n"
},
{
"QuestionId": "76382472",
"QuestionTitle": "I tried Simple Jolt transformation but its not working",
"QuestionBody": "I want to convert this data using jolt, I tried but it showing null as result\nInput :\n{\n  \"employer\": [\n    {\n      \"id\": \"98\",\n      \"place_id\": \"7871\",\n      \"name\": \"Iti-ha-cho\"\n    }\n  ]\n}\n\nExpected Output :\n{\n  \"id\" : \"98\",\n  \"place_id\" : \"7871\",\n  \"name\" : \"Iti-ha-cho\"\n}\n\nJolt Spec I tried but didnt work :\n{\n  \"operation\": \"shift\",\n  \"spec\": {\n    \"employer\": {\n      \"id\": \"[&1].&\",\n      \"place_id\": \"place_id\",\n      \"name\": \"name\"\n    }\n  }\n}\n\n",
"AnswerId": "76382541",
"AnswerBody": "While the current issue is due to missing square bracket nesting the spec, you don't need to specify those long stuff, just the following spec will suffice\n[\n  {\n    \"operation\": \"shift\",\n    \"spec\": {\n      \"employer\": {\n        \"*\": \"\"\n      }\n    }\n  }\n]\n\nas you only want to extract the sub-content of the employer array.\n"
},
{
"QuestionId": "76382467",
"QuestionTitle": "form with 2 int inputs where one always has to be lower and one always has to higher",
"QuestionBody": "I think its's pretty clear in my code what I am trying to do. basically I'm trying to use the max and min parameter from the input to make it so that they can never cross each other. This doesn't work of course, I am using react and am using usestate to set the values whenever the form is submitted and pass these variables into my database fetch. I feel like using 2 states one for the temporary value of the input and one to pass the submitted value to the fetch is not a good way of solving this.\nconst [ LowestPrice, setLowestPrice ] = useState(0)\nconst [ HighestPrice, setHighestPrice ] = useState(500)\n\nuseEffect(() =>{\nconst getProps = async () => {\nconst { data, count, error } = await backbase.from('products_2')\n      .select('*', { count: 'exact' })\n      .gte('price', LowestPrice)\n      .lt('price', HighestPrice)\n      .range(indexOfFirstItem, indexOfLastItem - 1)\n}}, [LowestPrice, HighestPrice])\n\nconst handleSubmit = (e) => {\n    e.preventDefault()\n\n    setLowestPrice(document.getElementById(\"lowest_price\")?.value)\n    setHighestPrice(document.getElementById(\"highest_price\")?.value)\n  }\n\n<form onSubmit={handleSubmit}>\n        <label htmlFor=\"lowest_price\">minimum price</label>\n        <input\n          type=\"number\"\n          id=\"lowest_price\"\n          defaultValue={LowestPrice}\n          min={0}\n          max={document.getElementById(\"highest_price\")?.value}\n        />\n        <label htmlFor=\"highest_price\">maximum price</label>\n        <input\n          type=\"number\"\n          id=\"highest_price\"\n          defaultValue={HighestPrice}\n          min={document.getElementById(\"lowest_price\")?.value}\n          max={500}\n        />\n        <button type=\"submit\">apply filters</button>\n      </form>\n\nI left out unessential parts of the code to make it easier to read. It's the min and max in the form that are the most relevant.\n",
"AnswerId": "76382555",
"AnswerBody": "Firstly, don't use getElementById to listen to changes. React triggers a re-render on components when their value changes. In order to retain the value, we use useState. Secondly, you can use OnChange to compare between both values in state before deciding whether or not to discard the new value. Try something like this;\nconst [lowestPrice, setLowestPrice] = useState(0);\nconst [highestPrice, setHighestPrice] = useState(1);\n\nreturn (\n<form onSubmit={handleSubmit}>\n    <label htmlFor=\"lowest_price\">minimum price</label>\n    <input\n      onChange={e => e.target.value <= highestPrice && setLowestPrice(e.target.value)} value={lowestPrice}\n      type=\"number\"\n      id=\"lowest_price\"\n      defaultValue={lowestPrice}\n      value={lowestPrice}\n      min={0}\n      max={highestPrice}\n    />\n    <label htmlFor=\"highest_price\">maximum price</label>\n    <input\n      onChange={e => e.target.value > lowestPrice && setHighestPrice(e.target.value)}\n      type=\"number\"\n      id=\"highest_price\"\n      defaultValue={highestPrice}\n      value={highestPrice}\n      min={lowestPrice}\n      max={500}\n    />\n    <button type=\"submit\">apply filters</button>\n  </form>\n)\n\n"
},
{
"QuestionId": "76384489",
"QuestionTitle": "Postgresql Need a query that gives me all the parents that don't have child with a specific status value",
"QuestionBody": "This is the parent table named route\n\n\n\n\nid\nstart_day\nend_day\n\n\n\n\n1\n2023/05/01\n2023/05/07\n\n\n2\n2023/05/01\n2023/05/07\n\n\n3\n2023/05/01\n2023/05/07\n\n\n4\n2023/05/01\n2023/05/07\n\n\n5\n2023/05/01\n2023/05/07\n\n\n\n\nChild table named route_detail\n\n\n\n\nid\nroute_id\nvisit_status\npoint_of_delivery_plant_name\npoint_of_delivery_plant_number\n\n\n\n\n1\n1\n5\nCROP SOLUTIONS S.A.\n563\n\n\n2\n1\n5\nCROP SOLUTIONS S.A.\n563\n\n\n3\n1\n5\nCROP SOLUTIONS S.A.\n563\n\n\n4\n2\n0\nSAMA S.A.\n781\n\n\n5\n3\n0\nWALTER SAMA HARMS\n732\n\n\n6\n4\n5\nAGROSER S.A.\n242\n\n\n7\n4\n5\nAGROSER S.A.\n242\n\n\n8\n5\n5\nAGROFERTIL S.A\n287\n\n\n9\n5\n5\nAGROFERTIL S.A\n287\n\n\n10\n5\n5\nAGROFERTIL S.A\n287\n\n\n\n\nand a third child table named event, for each record route_detail there is 1 event. This is child to route_detail\n\n\n\n\nid\nroute_detail_id\nevent_type\nevent_description\n\n\n\n\n50\n1\n1\nstart visit\n\n\n51\n2\n2\nrecurrent form\n\n\n52\n3\n3\nend visit\n\n\n53\n4\n1\nstart visit\n\n\n54\n5\n1\nstart visit\n\n\n55\n6\n1\nstart visit\n\n\n56\n7\n2\nrecurrent form\n\n\n57\n8\n1\nstart visit\n\n\n58\n9\n2\nrecurrent form\n\n\n59\n10\n4\nharvest advance\n\n\n\n\nWhat I'm trying to do is to get all the routes with visit_status = 5 and that don't have events with event_type = 3(end visit)\nBut I can't manage to get that result\nI tried something like this after some research but the queries would still return routes with route_details with the event_type = 3 on them\nSELECT r.id,\n       r.start_day,\n       r.end_day,\n       de.point_of_delivery_plant_name,\n       de.point_of_delivery_plant_number,\n       de.visit_status\nFROM route r\nJOIN route_detail de ON de.route_id = r.id\nWHERE NOT EXISTS (SELECT 1 \n                  FROM route ro \n                  JOIN route_detail rd ON rd.route_id = ro.id \n                  JOIN event ev ON ev.route_detail_id = rd.id \n                  WHERE rd.route_id = r.id \n                    AND ev.event_type_id !=7 \n                    AND rd.visit_status = '5' \n                    AND rd.id = de.id)\n   AND de.visit_status = '5'\nGROUP BY 1,2,3,4,5,6\nORDER BY r.id DESC;\n\nThis is how my results should look like, since only routes 4 and 5 have visit_status = '5' and their route_details don't have event_type =3\nNote: I didn't make the tables\n\n\n\n\nid\nstart_day\nend_day\n\n\n\n\n4\n2023/05/01\n2023/05/07\n\n\n5\n2023/05/01\n2023/05/07\n\n\n\n",
"AnswerId": "76384691",
"AnswerBody": "If you want to do it with the EXISTS expression, you can use:\n\none EXISTS to check the existence of route_detail.visit_status = 5\none EXISTS to check the non-existence of event.event_type = 3 when route_detail.visit_status = 5\n\nSELECT r.*\nFROM route r\nWHERE EXISTS(SELECT 1\n             FROM route_detail rd\n             WHERE r.id = rd.route_id\n               AND rd.visit_status = 5 )\n  AND NOT EXISTS(SELECT 1 \n                 FROM       route_detail rd\n                 INNER JOIN \"event\"      e\n                         ON rd.id = e.route_detail_id\n                 WHERE r.id = rd.route_id\n                   AND e.event_type = 3)\n\nOutput:\n\n\n\n\nid\nstart_day\nend_day\n\n\n\n\n4\n2023-05-01T00:00:00.000Z\n2023-05-07T00:00:00.000Z\n\n\n5\n2023-05-01T00:00:00.000Z\n2023-05-07T00:00:00.000Z\n\n\n\n\nCheck the demo here.\n"
},
{
"QuestionId": "76381164",
"QuestionTitle": "Sum cells by colors based on other colum cells",
"QuestionBody": "I wanna sum cells that have the same color. I know there are some VBA functions to do that. But my problem is kinda specific. I want to sum cells values from a single column, based on cells colors on another column.\nI add an example and the code I used. I got the \"#VALUE\" error on the line where I try to access the Interior property.\n\nFunction SumByColor(CellColor As Range, rRange As Range)\n Dim cSum As Double\n Dim ColIndex As Integer\n Dim compatedCell As Range  \n Debug.Print (\"sumbycolor called\")\n\n ColIndex = CellColor.Interior.ColorIndex\n\n For Each cl In rRange\n  comparedCell = Worksheets(\"HA\").Cells(cl.Row, 1)\n  Debug.Print (comparedCell.Interior.ColorIndex) #nothing printed\n\n  If comparedCell.Interior.ColorIndex = ColIndex Then\n   cSum = WorksheetFunction.Sum(cl, cSum)\n  End If\n  Next cl\n\n SumByColor = cSum\n\nEnd Function\n\nThx for your help.\n",
"AnswerId": "76381242",
"AnswerBody": "You should dim all your variables.\n  Dim cl As Range, comparedCell As Range\n  For Each cl In rRange\n    Set comparedCell = Worksheets(\"HA\").Cells(cl.Row, 1)\n    Debug.Print (comparedCell.Interior.ColorIndex) 'nothing printed\n\n    If comparedCell.Interior.ColorIndex = ColIndex Then\n         cSum = WorksheetFunction.Sum(cl, cSum)\n    End If\n  Next cl\n\nAs comparedCell is a Range-object you have to use Set.\n"
},
{
"QuestionId": "76382489",
"QuestionTitle": "How to delete constructors and operators using inheritance in c++?",
"QuestionBody": "Suppose I have two classes, no_copy and no_move which are base classes. From which any class can derive from and hence have their constructors and operators modified.\nAs the name suggests, no_copy will literally just do the following; (commented out what it should do)\nclass base : no_copy\n{\n    /*\n       base(const base&)=delete;\n       base& operator=(const base&)=delete;\n    */\n};\n\nAnd the same for no_move,\nclass base : no_move\n{\n    /*\n       base(base&&)=delete;\n       base& operator=(base&&)=delete;\n    */\n};\n\nThese classes (no_copy & no_move) make it so that the class that derives from it should not be copyable or moveable.\nRight now I am just using a macro to do this;\n// For classes without a qualified name\n#define __NO_COPY__(__class__) __class__::__class__(const __class__&)=delete; __class__& __class__::operator=(const __class__&)=delete;\n\n// For classes with qualified names\n#define __NO_COPY_LIB__(__qualified_name__,__class__) __qualified_name__::__class__(const __class__&)=delete; __class__& __qualified_name__::operator=(const __class__&)=delete;\n\nAnd the same technique for not moving.\n\nEDIT:\nExamples of the macros;\nsuppose a class as such;\nnamespace wrapper\n{\n   class my_class {};\n\n   __NO_COPY__(my_class);\n}\n__NO_COPY_LIB__(::wrapper::my_class,my_class);\n\n\nThe macros work just fine, but it doesn't look pretty. Moreover they are not easy to refactor as these macros can be anywhere in the definition or implementation.\nA syntax like the following would mean that all of this in right there in the definition of the class and can be changed or modified very easily;\nclass base : public attributes<no_copy,no_move> {};\n\nThe attributes struct is just defined as;\ntemplate <typename... _BCs/*Base Classes*/>\nstruct attibutes : public _BCs... {};\n\nNow obviously the syntax of inheriting doesn't matter that much. All I want it to be able to define where the class can be copied,moved or not. Also, if there is a method other than inheritance which could work please do suggest it.\nAs all I am looking for is the method that is easily refactorable.\n\nI have tried finding solutions online about how to overload constructors. But so far I have not found anything about deleting them and hence I am doubting if it is even possible to delete constructors or operators using inheritance.\nAny help would be greatly appreciated.\n",
"AnswerId": "76382575",
"AnswerBody": "Special member functions delegate to the corresponding functions of their subobjects (bases and members) and will be defaulted as deleted if that delegation finds a deleted or inaccessible function.\n\nhttps://timsong-cpp.github.io/cppwp/n4868/class.ctor#class.copy.ctor-10\nhttps://timsong-cpp.github.io/cppwp/n4868/class.copy.assign#7\n\nAlthough you could use a non-static member for this, using a base class is better because it enables the \"Empty Base Optimization\", not costing anything.\nstruct no_copy\n{\nprotected:\n    no_copy() = default;\n    no_copy(const no_copy&) = delete;\n    no_copy& operator=(const no_copy&) = delete;\n};\n\nclass important_class : no_copy {};\n\npre-C++11 version:\nclass no_copy // members default to \"private\"\n{\n    no_copy(const no_copy&); // no definition needed\n    no_copy& operator=(const no_copy&); // no definition needed\nprotected:\n    no_copy() {}\n};\n\nThis won't stop the derived class from defining a user-provided special member that explicitly avoids calling the base class version, but if you do that it shows intent to make the derived class actually be copyable/whatever after all.\n"
},
{
"QuestionId": "76384393",
"QuestionTitle": "Nest.js empty Body for form data",
"QuestionBody": "I have a simple controller, in this controller I have this endpoint\n@Post('/temp')\nasync asdf(\n  @Body() form: Record<string, string>,\n  @Res({ passthrough: true }) response: Response,\n) {\n  this.logger.debug(JSON.stringify(form));\n  await response.json({ ok: true, form: JSON.stringify(form) });\n}\n\nWhen I try to POST some form data on it, using cURL or the browser, the object form is empty.\nExample:\ncurl -X POST http://localhost:4000/mycontroller/temp -H \"Content-Type: application/x-www-form-urlencoded\" -d \"param1=value1&param2=value2\"\n\nResults in\n\n{\"ok\":true,\"form\":\"{}\"}\n\nOther controllers work; I can't see any difference between my controller and the endpoint to others.\nWhat I'm doing wrong or missing?\n",
"AnswerId": "76384692",
"AnswerBody": "If you're using form data you need to implement a form data parser, like busboy or multer. Nest integrates with multer and express already via the FileInterceptor and its variants. This will force multer to parse the request. If you don't use any files, just the form data format, I believe there is a NoFileInterceptor or similar.\n\nLooks like there is no NoFileInterceptor. You could use AnyFileInterceptor instead and ignore the req.files, just be aware it could end up having your server taken down if a really nasty set of files comes in for multer to parse\n"
},
{
"QuestionId": "76381056",
"QuestionTitle": "How to construct a graph using a list of tuples in python in networkX?",
"QuestionBody": "I am trying to make a graph from a list of tuples stored in a variable. I found G.add_edges_from(e) for making graph using list of tuples. but the problem is that this does not work and when i try to for example print the graph it returns None. I appreciate answers that solve my problem. I use the code below to make the graph:\nimport networkx as nx\n\ne = [(1,2),(1,3),(2,3)]\nG = nx.Graph()\ng1 = G.add_edges_from(e)\nprint(g1)\n\n\nUpdate:\nI testes this code but again give None when trying to print:\ne = [[(1,2),(1,3),(2,3)],[(10,20),(10,30),(20,30)]]\ngraph_list = []\nfor i in e:\n    graph_list.append(nx.Graph().add_edges_from(i))\n\nprint(graph_list[0].nodes)\n\n\n",
"AnswerId": "76381247",
"AnswerBody": "Let's break it down shall we?\nYou assigned a list of edges in e, then you made a graph with G.\nHowever, your issue is you're trying to assign g1 to what the method add_edges_from returns (which is None).\nWhat you actually want is something like this:\nimport networkx as nx\n\ne = [(1,2),(1,3),(2,3)]\nG = nx.Graph()\nG.add_edges_from(e)\nprint(G)\n\nSince the add_edges_from method returns None it is working as intended, you should try printing your original graph instead. I hope this helps and clarifies things for you!\nEdit:\nIf you insist on just using the list of tuples, you can just do away with variables. Use lists to store graph objects instead, keep storing them in a loop as such:\ne = [[(1,2),(1,3),(2,3)],[(10,20),(10,30),(20,30)]]\ngraph_list = []\nfor i in e:\n    G = nx.Graph()\n    G.add_edges_from(i)\n    graph_list.append(G)\n\nprint(graph_list[0].nodes)\nprint(graph_list[1].nodes)\n\nThen you can use indices to get each specific graph you make (which would be stored separately in the list)\nOr you might want to start dumping each graph in a json file ([answered here] (Method to export networkx graph to json graph file?))\nWhich can solve your RAM issue\n"
},
{
"QuestionId": "76381127",
"QuestionTitle": "Why is strtol() returning 0x7fffffff instead of the expected 0xAABBCCDD?",
"QuestionBody": "// msvc 17.3.5\n// sizeof (long) : 4\n#include <stdlib.h>\nint main(){\n    long i = 0xAABBCCDD;// 0x AABBCCDD in debugger window\n\n    char number[] = \"AABBCCDD EEFF\";\n    char* p;\n    long var = strtol ( number, &p, 16 );// 0x 7FFF FFFF\n    perror ( \"?:\" ); // ?:: Result too large\n}\n\nI tried char number[] = \"AABBCC EEFF\"; and it works fine.\nI expect 0xAABBCCDD inside var instead 0x7fffffff.\nWhat is wrong?\n",
"AnswerId": "76381250",
"AnswerBody": "From the C Standard (7.22.1.4 The strtol, strtoll, strtoul, and strtoull functions)\n\n8 The strtol, strtoll, strtoul, and strtoull functions\nreturn the converted value, if any. If no conversion could be\nperformed, zero is returned. If the correct value is outside the range\nof representable values, LONG_MIN, LONG_MAX, LLONG_MIN,\nLLONG_MAX, ULONG_MAX, or ULLONG_MAX is returned (according to the return type and sign of the value, if any), and the value of\nthe macro ERANGE is stored in errno.\n\nThe positive hexadecimal constant 0xAABBCCDD can not be represented in an object of the signed type long int provided that sizeof( long int ) is equal to 4.\nFor example try this demonstration program\n#include <stddef.h>\n#include <stdio.h>\n\nint main( void )\n{\n    printf( \"%#X\\n\", LONG_MAX );\n}\n\nThe program output is\n0X7FFFFFFF\n\nNote: as in this case sizeof( long ) is equal to sizeof( unsigned int ) and the value is representable in an object of the type unsigned int there is used the conversion specifier X. Otherwise you need to include header <inttypes.h> and to use a macro as for example PRIX32.\nAs you can see LONG_MAX (the maximum positive value that can be stored in an object of the type long int)  is less than the positive hexadecimal constant 0xAABBCCDD.\nInstead of using the function strtol use function strtoul\nunsigned long var = strtoul ( number, &p, 16 );\n\nOr if you want to deal with signed integers then use function strtoll.\n"
},
{
"QuestionId": "76383877",
"QuestionTitle": "How to find out which package depends on \"futures\" in requirements.txt",
"QuestionBody": "I have defined many pip packages in a requirements.txt, but I have not define the \"futures\" package:\n...\nfuture == 0.18.3\nsix == 1.16.0\njoblib == 1.2.0\n...\n\nAnd then download all packages with the following command on Ubuntu 22.04:\npip3.9 download -r \"/home/requirements.txt\"\n\nThe above command exited with the following error:\n...\n...\nCollecting widgetsnbextension~=4.0.7\n  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 3.9 MB/s eta 0:00:00\nCollecting branca>=0.5.0\n  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\nCollecting traittypes<3,>=0.2.1\n  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\nCollecting xyzservices>=2021.8.1\n  Downloading xyzservices-2023.5.0-py3-none-any.whl (56 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 KB 1.3 MB/s eta 0:00:00\nCollecting futures\n  Downloading futures-3.0.5.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... error\n  error: subprocess-exited-with-error\n  \n  × python setup.py egg_info did not run successfully.\n  │ exit code: 1\n  ╰─> [25 lines of output]\n      Traceback (most recent call last):\n        File \"<string>\", line 2, in <module>\n        File \"<pip-setuptools-caller>\", line 14, in <module>\n        File \"/python39/lib/python3.9/site-packages/setuptools/__init__.py\", line 18, in <module>\n          from setuptools.dist import Distribution\n        File \"/python39/lib/python3.9/site-packages/setuptools/dist.py\", line 32, in <module>\n          from setuptools.extern.more_itertools import unique_everseen\n        File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n        File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n        File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\n        File \"<frozen importlib._bootstrap>\", line 565, in module_from_spec\n        File \"/python39/lib/python3.9/site-packages/setuptools/extern/__init__.py\", line 52, in create_module\n          return self.load_module(spec.name)\n        File \"/python39/lib/python3.9/site-packages/setuptools/extern/__init__.py\", line 37, in load_module\n          __import__(extant)\n        File \"/python39/lib/python3.9/site-packages/setuptools/_vendor/more_itertools/__init__.py\", line 1, in <module>\n          from .more import *  # noqa\n        File \"/python39/lib/python3.9/site-packages/setuptools/_vendor/more_itertools/more.py\", line 5, in <module>\n          from concurrent.futures import ThreadPoolExecutor\n        File \"/tmp/pip-download-jelw4tc2/futures/concurrent/futures/__init__.py\", line 8, in <module>\n          from concurrent.futures._base import (FIRST_COMPLETED,\n        File \"/tmp/pip-download-jelw4tc2/futures/concurrent/futures/_base.py\", line 357\n          raise type(self._exception), self._exception, self._traceback\n                                     ^\n      SyntaxError: invalid syntax\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: metadata-generation-failed\n\n× Encountered error while generating package metadata.\n╰─> futures\n\nnote: This is an issue with the package mentioned above, not pip.\nhint: See above for details.\n\nHow to find out which package depends on the \"futures\" from the \"requirements.txt\"?\nHere is the dummy code:\n# find_out_depends --requirement-file \"/home/requirements.txt\" --find-depends \"futures\"\n\nIs there any \"find_out_depends\" command for accepting requirements.txt as argument and then print out the whole dependencies tree?\n",
"AnswerId": "76384741",
"AnswerBody": "Create a fresh Python 3.9 venv and install your requirements without dependencies:\npython3.9 -m pip install --no-deps requirements.txt\n\nThen run the pip check CLI:\npython3.9 -m pip check\n\nIt will complain that some package(s) have unmet dependencies, and you should find futures somewhere in there. Not to be confused with future, which is cross-compat.\n"
},
{
"QuestionId": "76384647",
"QuestionTitle": "Grouping Semesters into Academic Years generalization",
"QuestionBody": "I have about a specific section of my code. The loop inputs semester files, computes new columns and outputs a data set with the new variables. The loop works beautifully, however making the Acad_Year variable is stagnant, I am looking for a way to make it more flexible so that I won't need to go in and re-write the case_when statement every time there is a new dataset. Sample data is available.  Thank you in advance!\n{r setup}\n\nrequire(\"knitr\")\n setwd(\"~/Downloads/Stack Overflow/\")\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(writexl)\n\nPhGrad <- rbind(PhGrad_08, PhGrad_SP_23) %>% \n  filter(!BannerID== \"\")\n\nd <- tibble(\n  filename = list.files(), \n  Sem = gsub(\".*(Fall|Spring|Summer).*\", \"//1\", filename), \n  Year = gsub(\".*(//d{2}).*\", \"//1\", filename), \n  grp = gsub(\".*(ASPH|ID).*\", \"//1\", filename)) %>% \n  pivot_wider(names_from = \"grp\", values_from=\"filename\")\n\nres <- vector(mode=\"list\", length=nrow(d))\nnames(res) <- paste(d$Sem, d$Year, sep=\"_\")\n\nfor(i in seq_along(res)){\n  ASPH <- rio::import(d$ASPH[i])\n  ID <- rio::import(d$ID[i])\n  \nres[[i]] <- bind_rows(ASPH, ID) %>%\n    distinct(ID, Program, .keep_all = T) %>% \n    rowwise() %>% \n    mutate(racecount= sum(c_across(`Race-Am Ind`:`Race- Caucasian`)== \"Y\", na.rm=T)) %>% \n    ungroup() %>% \n    mutate(racecode= case_when(Citizenship %in% list(\"NN\", \"NV\") ~ \"foreign_national\",\n                               `Race- Hispanic`== \"Y\" ~ \"hispanic_latino\", \n                                racecount >1 ~ \"two_or_more_races\",\n                               `Race-Am Ind`== \"Y\"  ~ \"american_indian_alaskan_native\",\n                               `Race- Asian`== \"Y\"  ~ \"asian\",\n                               `Race-Afr Amer`== \"Y\"  ~ \"black_african_american\",\n                               `Race- Hawaiian` == \"Y\"  ~ \"native_hawaiian_pacific_islander\",\n                               `Race- Caucasian`== \"Y\" ~ \"white\",\n                               `Race-Not Rept`== \"Y\" ~ \"race_unknown\",\n                               TRUE~ \"race_unknown\"),\n           gender_long= case_when(Gender== \"F\"~ \"Female\",\n                                  Gender== \"M\"~ \"Male\",\n                                  Gender== \"N\"~ \"Other\",\n                                  TRUE~ \"other\"),\n           DEPT= case_when(Program %in% list(\"3GPH363AMS\", \"3GPH363AMSP\", \"3GPH378AMCD\", \"3GPH378AMS\", \"3GPH379APHD\")~ \"COMD\",\n                           Program %in% list(\"3GPH593AMPH\", \"3GPH593AMS\", \"3GPH593APHD\", \"3GPH569ACGS\")~ \"ENHS\",\n                           Program %in% list(\"3GPH596AMS\", \"3GPH596AMSPH\", \"3GPH596APHD\",\"3GPH594AMPH\", \"3GPH594AMS\", \"3GPH594AMSPH\", \"3GPH594APHD\", \"3GPH586APBAC\")~ \"EPID/BIOS\", \n                           Program %in% list(\"3GPH331AMS\",\"3GPH331APHD\",\"3GPH334AMS\",\"3GPH335ADPT\", \"3GPH377AMS\", \"3GPH388AMS\", \"3GPH588AMPH\", \"3GPHJ331MS\", \"3UPH331ABS\")~ \"EXSC\",\n                           Program %in% list(\"3GPH568APBAC\",\"3GPH592ACGS\",\"3GPH592AMPH\", \"3GPH592APHD\", \"3GPH576ACGS\", \"3GPH121ACGS\", \"3GID635ACGS\")~ \"HPEB\",\n                           Program %in% list(\"3GPH591AMPH\", \"3GPH591APHD\", \"3GPH597AMHA\",\"3GPH591ADPH\")~ \"HSPM\",\n                           TRUE~ \"Missing\"), \n           degree_delivery_type= case_when(`First Concentration`== \"R999\" | `Second Concentration`== \"R999\" ~ \"Distance-based\",\n                                           `First Concentration`== \"3853\" | `Second Concentration`== \"3853\" ~ \"Executive\", \n                                           TRUE~ \"Campus-based\"),\n # FTE_compute= case_when(Level== \"GR\" & `Course Hours`<9 ~ round(`Course Hours`/9, #digits=2),\n #                                  Level== \"GR\" & `Course Hours`>=9~ 1,\n #                                 Level== \"UG\" & `Course Hours`<12~ round(`Course Hours`/12, \n #digits=2),\n #                                  Level== \"UG\" & `Course Hours`>=12 ~ 1),\n #          Full_Part_Status=case_when((Level== \"GR\" & `Course Hours` <9)| (Level== \"UG\" & \n #`Course Hours`<12)~\"parttime_status\",\n #                                      (Level==\"GR\" & `Course Hours`>=9)|(Level== \"UG\" & `Course \n #Hours`>=12)~\"fulltime_status\",\n #                                       TRUE~ \"other\"),\n           Sem_Year= paste0(d$Sem[i],\"_\",d$Year[i]),\n           StudentCount= 1,\n      Acad_Year= case_when(Sem_Year %in% list(\"Fall_18\", \"Spring_19\", \"Summer_19\")~ \"AY2018-19\",\n                                 Sem_Year %in% list(\"Fall_19\", \"Spring_20\", \"Summer_20\")~ \"AY2019-20\",\n                                 Sem_Year %in% list(\"Fall_20\", \"Spring_21\", \"Summer_21\")~ \"AY2020-21\",\n                                 Sem_Year %in% list(\"Fall_21\", \"Spring_22\", \"Summer_22\")~ \"AY2021-22\",\n                                 Sem_Year %in% list(\"Fall_22\", \"Spring_23\")~ \"AY2022-23\"),\n      Deg_group = case_when(Degree %in% list(\"DPT\", \"PHD\", \"DPH\")~ \"Doctorate\",\n                            Degree %in% list(\"MSP\", \"MCD\", \"MPH\", \"MHA\", \"MS\",\"MSPH\")~ \"Masters\",\n                            Degree %in% list(\"CGS\", \"PBACC\")~ \"Certificate\")) %>% \n    left_join(., PhGrad %>% mutate_at(vars(BannerID), ~as.character(.)), by= c(\"ID\"=\"BannerID\", \"DEPT\"), unmatched= \"drop\", relationship= \"many-to-many\") %>% \n  mutate(New_Deg= case_when(is.na(Degree.y)== T~ Degree.x,\n                     is.na(Degree.y)== F~ Degree.y,\n                          TRUE~ \"Error\")) %>% \n  select(-c(ApplicationID:StudentStatus))\n}\n\n",
"AnswerId": "76384769",
"AnswerBody": "library(dplyr)\ndata.frame(Sem_Year = c(\"Fall_21\", \"Spring_22\", \"Summer_22\",\n                        \"Fall_31\", \"Spring_32\", \"Summer_32\")) %>%\n  \n  tidyr::separate(Sem_Year, c(\"Sem\",\"Yr\"), convert = TRUE, remove = FALSE) %>%\n  mutate(AY_end = Yr + if_else(Sem == \"Fall\", 1, 0),\n         Acad_Year = paste0(\"AY20\", AY_end - 1, \"-\", AY_end)) %>%\n  select(-c(Sem, Yr, AY_end))\n\nResult (Reminder: update in 2099)\n   Sem_Year Acad_Year\n1   Fall_21 AY2021-22\n2 Spring_22 AY2021-22\n3 Summer_22 AY2021-22\n4   Fall_31 AY2031-32\n5 Spring_32 AY2031-32\n6 Summer_32 AY2031-32\n\n"
},
{
"QuestionId": "76381002",
"QuestionTitle": "Is this a race condition in go",
"QuestionBody": "func main() {\n    m := map[string]int{\n        \"foo\": 42,\n        \"bar\": 1337,\n    }\n\n    go func() {\n        time.Sleep(1 * time.Second)\n        tmp := map[string]int{\n            \"foo\": 44,\n            \"bar\": 1339,\n        }\n\n        m = tmp\n    }()\n\n    for {\n        val := m[\"foo\"]\n        fmt.Println(val)\n    }\n}\n\nI saw this in many packages.\nWhy this is not considered as a race condition?\ngo run -race . giving no error.\n",
"AnswerId": "76381254",
"AnswerBody": "As pointed out by @Volker, this is a data race. And since there is only one write, it's hard to be detected. Here is a modified demo to make it easy to trigger the data race error:\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    m := map[string]int{\n        \"foo\": 42,\n        \"bar\": 1337,\n    }\n\n    done := make(chan any)\n\n    go func() {\n        for i := 0; i < 100; i++ {\n            time.Sleep(time.Microsecond)\n            tmp := map[string]int{\n                \"foo\": 44,\n                \"bar\": 1339,\n            }\n\n            m = tmp\n        }\n\n        close(done)\n    }()\n\n    for {\n        select {\n        case <-done:\n            return\n        default:\n            val := m[\"foo\"]\n            fmt.Println(val)\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76382398",
"QuestionTitle": "Condition to filter records with \"in\" and \"and\" operators",
"QuestionBody": "\n\n\n\nID\nname\nisSearchable\n\n\n\n\n1\nfoo\ntrue\n\n\n2\nbar\ntrue\n\n\n3\nzar\nfalse\n\n\n\n\nI've got some ids and I need to filter records where they have isSearchable = true.\nThis query give as result ID = 1 because is searchable, but I would to apply the filter isSearchable to the entire result, not row-by-row.\nSELECT *\nFROM my_table\nWHERE id IN (1, 3)\n  AND isSearchable = true\n\nSo in this case I'm expecting no-results because both records should be in first isSearchable and after that, filter the ids.\nI've tried experimenting with sub-query etc but the in operator (or the or operator) but I'm not able to accomplish the result.\nMaybe is something really simple, but I've no ideas on how to solve.\nThanks for your help.\n",
"AnswerId": "76382590",
"AnswerBody": "One approach using a window function:\nSELECT ID \nFROM (SELECT ID,\n             MIN(isSearchable::INT) OVER() AS minSearchable\n      FROM my_table\n      WHERE id IN (1,3)) cte \nWHERE minSearchable = 1\n\nCheck the demo here.\n"
},
{
"QuestionId": "76382293",
"QuestionTitle": "Converting Bash Option String to Unix Environment Variable Name using vscode snippet Transformation",
"QuestionBody": "I am working on a bash script snippet for the sheller extension where I need to convert a Bash option string entered by the user into a valid Unix environment variable name. For example, the user may enter an option string like \"-my-option-name\" or \"--another_option=\", and I need to transform it into a valid environment variable name like \"MY_OPTION_NAME\" or \"ANOTHER_OPTION\".\nTo clarify my requirements and provide a clear understanding of the desired transformation, I have created a JavaScript example on JSFiddle. You can find it here. The example showcases a table of different input strings and their expected output after the transformation.\nThe javascript function handling the transformation used in the fiddle.\nfunction stripCapitalizeAndSnake(inputString) {\n  const regex = /^-+(.*?)(?:=)?$/;\n  const result = inputString.replace(regex, (_, selectedString) => {\n    const transformedString = selectedString.replace(/-/g, '_');\n    return transformedString.toUpperCase();\n  });\n  return result;\n}\n\nI am seeking guidance or preferably code examples on how to implement this transformation using snippet transforms in Visual Studio Code snippets.\n\nThank you in advance for your assistance, especially if you have experience or knowledge about the vscode, code snippets and transformations!\n\nHere is a simplified version of a snippet, which I hope someone can modify for the expected result.\nCurrent snippet\n{\n    \"OPTION TO ENVIRONMENT\": {\n        \"prefix\": \"option to environment\",\n        \"body\": [\n            \"#!/usr/bin/env bash\",\n            \"\",\n            \"OPTION=\\\"${1:--quiet-mode}\\\"\",\n            \"\",\n            \"echo \\\"Option        :\\\\${OPTION}\\\"\",\n            \"echo \\\"Variable name :${1/^(\\\\-+)([^=]+)(=)?$/${2:/upcase}/}\\\"\"\n        ],\n        \"description\": \"Convert bash option to a valid shell environment variable\"\n    }\n}\n\nCurrent Result\nWhen triggering the snippet, and leaving the default value as is the Variable name is correct except for the fact that \"-\" is not replaced with \"_\" which is my problem.\n\"QUIET-MODE\" needs to be transformed to \"QUIET_MODE\".\n#!/usr/bin/env bash\n\nOPTION=\"--quiet-mode\"\n\necho \"Option        :${OPTION}\"\necho \"Variable name :QUIET-MODE\"\n\nI have been trying to do this for a while now, so I ask you, do you know how to do this?\nPs.\nDo you know of a better documentation about transformations, other than is mentioned here?\n",
"AnswerId": "76382615",
"AnswerBody": "use the extension Hypersnips\nyou can add JavaScript to the snippet\n\nIt can be done with VSC standard snippets\n\ncapture possible starting - characters, ignore in result\ncapture all till - or =, UPCASE that group\ncapture possible -, substitute with _\ncapture possible =, ignore in result\n\napply these rules global/repeatedly\n{\n  \"OPTION TO ENVIRONMENT\": {\n    \"prefix\": \"option to environment\",\n    \"body\": [\n        \"#!/usr/bin/env bash\",\n        \"\",\n        \"OPTION=\\\"${1:--quiet-mode}\\\"\",\n        \"\",\n        \"echo \\\"Option        :\\\\${OPTION}\\\"\",\n        \"echo \\\"Variable name :${1/(^-+)?([^-=]+)(-?)(=?)/${2:/upcase}${3:+_}/g}\\\"\"\n    ],\n    \"description\": \"Convert bash option to a valid shell environment variable\"\n}\n\n"
},
{
"QuestionId": "76381019",
"QuestionTitle": "How can I create a dynamic list in Terraform that combines a list of strings with a list of maps?",
"QuestionBody": "Merge list with another list of map in terraform\nWe have a list listA and a list of map, mapA as below\nlistA = [\"cluster-0\",\"cluster-1\"]\n\n\nmapA = [\n{\n  auto_upgrade       = false\n  disk_size_gb       = 100\n  disk_type          = \"pd-standard\"\n  node_pool_labels            = {\n    agentpool = \"np-1\"\n  }\n},\n{\n  auto_upgrade       = false\n  disk_size_gb       = 50\n  disk_type          = \"pd-balanced\"\n  node_pool_labels            = {\n    agentpool = \"np-2\"\n  }\n},\n{\n auto_upgrade                = false\n disk_size_gb                = 100\n disk_type                   = \"pd-standard\"\n node_pool_labels            = {\n    agentpool = \"np-3\"\n }\n}\n]\n\n\nI am trying to create a new list which should look like\nlistB = [\n\"cluster-0\" = [{\n  auto_upgrade       = false\n  disk_size_gb       = 100\n  disk_type          = \"pd-standard\"\n  node_pool_labels   = {\n      agentpool = \"np-1\"\n   }\n },\n {\n  auto_upgrade       = false\n  disk_size_gb       = 50\n  disk_type          = \"pd-balanced\"\n  node_pool_labels   = {\n      agentpool = \"np-2\"\n   }\n },\n {\n  auto_upgrade                = false\n  disk_size_gb                = 100\n  disk_type                   = \"pd-standard\"\n  node_pool_labels            = {\n      agentpool = \"np-3\"\n  }\n}], \n\n\"cluster-1\"= [{\n  auto_upgrade       = false\n  disk_size_gb       = 100\n  disk_type          = \"pd-standard\"\n  node_pool_labels   = {\n      agentpool = \"np-1\"\n   }\n },\n {\n  auto_upgrade       = false\n  disk_size_gb       = 50\n  disk_type          = \"pd-balanced\"\n  node_pool_labels   = {\n      agentpool = \"np-2\"\n   }\n },\n {\n  auto_upgrade                = false\n  disk_size_gb                = 100\n  disk_type                   = \"pd-standard\"\n  node_pool_labels            = {\n      agentpool = \"np-3\"\n  }\n}]\n] \n\nI have tried zipmap which works when listA has two elements and mapA has got two elements like only np-1, np-2 but fails when we add np-3. Trying to make this dynamic listB.\n",
"AnswerId": "76381291",
"AnswerBody": "You can use:\nlistB = [{for idx, value in local.listA: value => local.mapA }]\n\nso iterate over listA to create a new list where the elements are a dict of which the key is the original element in listA, and the value mapA.\n"
},
{
"QuestionId": "76382245",
"QuestionTitle": "UA_Client_Service_read only yields empty responses",
"QuestionBody": "I am trying to create a small program in C which will poll a frame of data over a opc/ua connection using the open62541 library and the forward it to a kafka server.\nEverything works fine when fetching the values from the nodes separately but I would like to use a UA_ReadRequest for that. The problem is that I am only receiving empty responses.\nThe opc/ua server is coded with in python using the freeopc package.\nThis is the function that tries tu use a UA_ReadResponse to fetch a several values for specified nodeIDs:\nvoid retrieveOPCData(void)\n{\n    UA_ReadRequest request;\n    UA_ReadRequest_init(&request);\n    UA_ReadValueId ids[nodeCount];\n    \n    for (int i = 0; i < nodeCount; i++)\n    {\n        UA_ReadValueId_init(&ids[i]);\n        ids[i].attributeId = UA_ATTRIBUTEID_VALUE;\n        ids[i].nodeId = nodesToRead[i];\n    }\n\n    request.nodesToRead = ids;\n\n    for (int i = 0; i < nodeCount; i++)\n    {\n        UA_LOG_INFO(UA_Log_Stdout, UA_LOGCATEGORY_USERLAND, \"ID%i: %s, %i\", i,\n            request.nodesToRead[i].nodeId.identifier.string.data,\n            request.nodesToRead[i].nodeId.namespaceIndex);\n    }\n\n    UA_ReadResponse response = UA_Client_Service_read(client, request);\n\n    UA_LOG_INFO(UA_Log_Stdout, UA_LOGCATEGORY_USERLAND, \"Status: %i\",\n        response.responseHeader.serviceResult);\n    UA_LOG_INFO(UA_Log_Stdout, UA_LOGCATEGORY_USERLAND, \"Responses: %li\", response.resultsSize);\n}\n\nThe result value is UA_STATUSCODE_GOOD but the number of responses is 0. It works fine when fetching the values one after the other like this:\nvoid readNodeAtIndex(int index)\n{\n    if (index >= nodeCount)\n    {\n        UA_LOG_INFO(UA_Log_Stdout, UA_LOGCATEGORY_USERLAND, \"Index out of Range\");\n        return;\n    }\n\n    UA_Variant variant;\n    UA_Variant_init(&variant);\n\n    const UA_NodeId nodeId = nodesToRead[index];\n\n    UA_StatusCode retval = UA_Client_readValueAttribute(client, nodeId, &variant);\n\n    if (retval == UA_STATUSCODE_GOOD && UA_Variant_hasScalarType(&variant,\n        &UA_TYPES[UA_TYPES_DOUBLE]))\n    {\n        UA_Double value = *(UA_Double*)variant.data;\n\n        UA_LOG_INFO(UA_Log_Stdout, UA_LOGCATEGORY_USERLAND, \"Double-Value: %f\", value);\n    }\n    else if (retval == UA_STATUSCODE_GOOD && UA_Variant_hasScalarType(&variant,\n        &UA_TYPES[UA_TYPES_BOOLEAN]))\n    {\n        UA_Boolean value = *(UA_Boolean*)variant.data;\n\n        UA_LOG_INFO(UA_Log_Stdout, UA_LOGCATEGORY_USERLAND, \"Boolean-Value: %i\", value);\n    }\n    \n\n    UA_Variant_clear(&variant);\n}\n\nThe opc/ua server is setup like this:\nserver = Server()\nspace_url = \"opc.tcp://localhost:61032\"\nserver.set_endpoint(space_url)\nserver.set_security_policy([ua.SecurityPolicyType.NoSecurity])\nnode = server.get_objects_node()\n\n",
"AnswerId": "76382626",
"AnswerBody": "You need to set nodesToReadSize:\n    UA_ReadRequest request;\n    UA_ReadRequest_init(&request);\n    UA_ReadValueId ids[nodeCount];\n    \n    for (int i = 0; i < nodeCount; i++)\n    {\n        UA_ReadValueId_init(&ids[i]);\n        ids[i].attributeId = UA_ATTRIBUTEID_VALUE;\n        ids[i].nodeId = nodesToRead[i];\n    }\n    request.nodesToReadSize = nodeCount;\n    request.nodesToRead = ids;\n\n"
},
{
"QuestionId": "76384502",
"QuestionTitle": "React Ts trying to create guarded routed but getting an error",
"QuestionBody": "Hi I tried creating guards for my routes but I am getting this error:\n[Error] Error: [GuardedRoute] is not a <Route> component. All component children of <Routes> must be a <Route> or <React.Fragment>\n\nThis is my code:\nGuardedRoute.tsx-\nimport { Route, Navigate } from 'react-router-dom';\nimport { useUserInfo } from '../context/UserContext';\n\nexport const GuardedRoute = ({ path, element: Element, ...rest }: any) => {\n  const { userInfo } = useUserInfo();\n\n  if (userInfo.id !== '') {\n    return <Route path={path} element={Element} {...rest} />;\n  } else {\n    return <Navigate to=\"/\" replace />;\n  }\n};\n\n\nApp.tsx\n <BrowserRouter>\n                <Nav></Nav>\n                <div className=\"w-[100vw] fixed top-[50px] z-[100] flex flex-col\">\n                {\n                  ErrorMessages.map((message,index)=>(\n                      <div className=\"w-[300px] h-[50px] mt-[10px] mx-auto bg-red-600/90 rounded-md grid place-content-center\" key={index}>\n                        <p className=\"font-bold text-gray-200 text-center\">{message}</p>\n                      </div>\n                  ))\n                }\n                </div>\n                  <Routes>\n                    <Route path=\"/\" element={<Home />} />\n                    <GuardedRoute path=\"/profile/:select?\" element={<Profile />} />\n                    <GuardedRoute path=\"/checkout\" element={<CheckOut />}/>\n                    <Route path=\"/register\" element={<Register />} />\n                    <Route path=\"/login\" element={<Login />} />\n                    <Route path=\"/browse\" element={<Browse />} />\n                    <Route path=\"/product/:id\" element={<Product />} />\n                    <Route path=\"/404\"  element={<PageNotFound />}/>\n                    <Route path=\"*\"  element={<Navigate to=\"/404\" />}/>\n                  </Routes>\n                </BrowserRouter>\n\nDoes anyone have a solution for this error? thanks.\n",
"AnswerId": "76384779",
"AnswerBody": "It is better to put all the private routes inside Authguard instead of providing Authguard to each component. you can customize the auth, like if there is cookie exists of particular user, then auth is true, otherwise false.\nimport { Outlet, Navigate } from 'react-router-dom';\n\nconst Authguard = () => {\n\n    let auth = false;\n    return(\n        auth ? <Outlet/> : <Navigate to=\"/\"/>\n    )\n}\n\nexport default Authguard\n\nNow you Routes will be like, e.g in App.tsx\n  function App(){\n    return(\n     <Routes>\n          <Route path=\"/\" element={<Login />} />\n    \n           <Route element={<Authguard />}> \n               <Route path=\"/register\" element={<Register />} />\n               <Route path=\"/home\" element={<Home />} />\n          </Route>\n     </Routes>)\n    }\n\nThis shows your Register and Home components are private, and Login component is public.\n"
},
{
"QuestionId": "76381166",
"QuestionTitle": "Object reference not set to an instance of an object, Unity",
"QuestionBody": "So when enemy is spawned i try to init him here enemy.Init(); but had error Object reference not set to an instance of an object. But here Debug.Log(enemy._enemyHealth); i get number of enemy health. How i can Init my enemy from here if enemy has class 'Usual Enemy' and it extends from this class 'Enemy' and i wiil have more enemy child cllases?\nI vave class Enemy\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing UnityEngine.AI;\n\npublic abstract class Enemy : MonoBehaviour\n{\n\n    private GameObject _player;\n    private Animator _animator;\n    private Rigidbody _rigidbody;\n    private bool _isSpawned;\n    private const int _enemySpavnTime = 5;\n    [SerializeField] public float _enemyHealth;\n    [SerializeField] protected float _rotationSpeed = 10f;\n    [SerializeField] protected float _moveSpeed;\n    [SerializeField] protected float _damage;\n    [SerializeField] protected DamageBox _damageBox;\n    [SerializeField] protected TriggerBox _triggerBox;\n    private EnemyCondition _enemyCondition = EnemyCondition.Dead;\n    \n    private enum EnemyCondition \n    {\n        Spawn,\n        Run,\n        Attack,\n        Dead\n    }\n\n\n    void Start()\n    {\n        _rigidbody = GetComponent<Rigidbody>();\n        _animator = GetComponent<Animator>();\n        _player = GameObject.FindWithTag(\"Hero\");\n        _damageBox.HeroHited += enemyAttack;\n        _triggerBox.HeroInAttackRange += enemyGetAngry;\n        _triggerBox.HeroOutAttackRange += enemyGetChill;\n    }\n\n    void Update()\n    {   \n        if (_player != null) \n        {\n            if (_enemyCondition == EnemyCondition.Run)\n            {\n                EnemyPlayerRotation(_player);\n\n            } else if (_enemyCondition == EnemyCondition.Attack)\n            {\n                EnemyPlayerRotation(_player);\n            }\n        }\n        \n    }\n\n    void FixedUpdate() {\n        if (_enemyCondition == EnemyCondition.Run)\n        {\n            EnemyPlayerFollow();\n        }   \n    }\n\n    public virtual void Init() {\n        enemySpawn();\n    }\n\n    protected virtual void EnemyPlayerFollow() {\n        Vector3 direction = transform.TransformDirection(new Vector3(0, 0, 1));\n        _rigidbody.velocity = direction * _moveSpeed;\n    }\n\n    protected virtual void EnemyPlayerRotation(GameObject target) {\n        Vector3 direction = (target.transform.position - transform.position).normalized;\n        Quaternion lookRotation = Quaternion.LookRotation(new Vector3(direction.x, 0, direction.z));\n        transform.rotation = Quaternion.Slerp(transform.rotation, lookRotation, Time.deltaTime * _rotationSpeed);\n     }\n\n    public virtual void EnemyDamage(float damage)\n    {\n        _enemyHealth -= damage;\n        if (_enemyHealth <= 0) {\n            PoolManager.Instanse.Despawn(gameObject);\n        }\n    }\n\n    public virtual void enemySpawned() {\n        _enemyCondition = EnemyCondition.Run;\n        _rigidbody.isKinematic = false;\n        _animator.SetTrigger(\"Run\");\n        StopCoroutine(SpawnMoveUp());\n        Debug.Log(\"enemySpawned\");\n    }\n\n    protected virtual void enemyAttack(Hero trigger) \n    {   \n        if (_enemyCondition == EnemyCondition.Attack) {\n            trigger.HeroDamage(_damage);\n        }\n    }\n\n    protected virtual void enemyGetAngry() {\n        _enemyCondition = EnemyCondition.Attack;\n        _animator.SetTrigger(\"Attack\");\n    }\n\n    protected virtual void enemyGetChill() {\n        _enemyCondition = EnemyCondition.Run;\n        _animator.SetTrigger(\"Run\");\n    }\n\n    protected virtual void enemySpawn() {\n        _animator.SetTrigger(\"Spawn\");\n        _animator.speed = 0.0f;\n        StartCoroutine(SpawnMoveUp());\n    }\n\n    IEnumerator SpawnMoveUp()\n    {  \n        float spawnStage = 0.0f;\n        Vector3 startPoint = transform.position;\n        while(spawnStage <= 1.0f) {\n            transform.position = Vector3.Slerp(startPoint, new Vector3(transform.position.x, 0, transform.position.z), spawnStage);\n            spawnStage += Time.deltaTime/_enemySpavnTime;\n            yield return null;\n        }\n        _animator.speed = 1.0f;\n        \n    }\n    \n}\n\nAnd I have class that spawns enemies\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\n\npublic class EnemiesSpawner : MonoBehaviour\n{\n    [SerializeField] private Levels[] _levelsList;\n    private List<GameObject> _enemiesQueue = new List<GameObject>();\n    private List<GameObject> _levelEnemiesList = new List<GameObject>();\n    private List<int> _levelEnemiesCount = new List<int>();\n\n    private bool _isBossSpawned = false;\n    // private int _currentLevel = PlayerPrefs.GetInt(\"currentLevel\") - 1;\n    private int _currentLevelNumber = 0;\n    private float _reloadPause = 0;\n    private int currentEnemiesListPos = 0;\n    private int allEnemiesCount = 0;\n\n    private float _reloadTime;\n    private float _spawnRadius;\n    private float _spawnOfsetRadius = 2f;\n\n    [SerializeField] private GameObject _boss;\n    [SerializeField] private GameObject _spawnPoint;\n\n    void Start() {\n        Levels currentLevelObj = _levelsList[_currentLevelNumber];\n        _levelEnemiesCount.AddRange(currentLevelObj.enemiesCount.ToArray());\n        _levelEnemiesList = currentLevelObj.enemiesPrefabs;\n        _spawnRadius = currentLevelObj.spawnRadius;\n        _reloadTime = currentLevelObj.spawnReload;\n\n        foreach(int num in _levelEnemiesCount) {\n            allEnemiesCount += num;\n        }\n\n        while(_enemiesQueue.Count < allEnemiesCount){\n            int randomIndex = Random.Range(0, _levelEnemiesCount.Count);\n            if (_levelEnemiesCount[randomIndex] == 0) {\n                continue;\n            } else {\n                _enemiesQueue.Add(_levelEnemiesList[randomIndex]);\n                _levelEnemiesCount[randomIndex] --;\n            }\n        }\n    }\n\n    public void SetPlayerForSpawn (GameObject player) {\n        _spawnPoint = player;\n    }\n\n    void Update ()\n    {           \n        if (_spawnPoint != null){\n            SpawnEnemies();\n        }\n        \n    }\n\n    public void SpawnEnemies() \n    {\n        _reloadPause += Time.deltaTime;\n        if (_reloadPause >= _reloadTime && currentEnemiesListPos < allEnemiesCount) {\n            GameObject go = PoolManager.Instanse.Spawn(_enemiesQueue[currentEnemiesListPos],new Vector3((Random.value < 0.5f) ? Random.Range(_spawnPoint.transform.position.x + _spawnOfsetRadius, _spawnPoint.transform.position.x + _spawnRadius) : Random.Range(_spawnPoint.transform.position.x - _spawnOfsetRadius, _spawnPoint.transform.position.x - _spawnRadius), -5, (Random.value < 0.5f) ? Random.Range(_spawnPoint.transform.position.z + _spawnOfsetRadius, _spawnPoint.transform.position.z + _spawnRadius) : Random.Range(_spawnPoint.transform.position.z - _spawnOfsetRadius, _spawnPoint.transform.position.z - _spawnRadius)), Quaternion.identity);\n            Enemy enemy = go.GetComponent<Enemy>();\n            Debug.Log(enemy._enemyHealth);\n            enemy.Init();\n            _reloadPause = 0;\n            currentEnemiesListPos ++;\n        } else if (currentEnemiesListPos == allEnemiesCount && _isBossSpawned == true) {\n            Instantiate(_boss,new Vector3(0,0,0), Quaternion.identity);\n            _isBossSpawned = true;\n        }\n        \n    }\n}\n\nSo when enemy is spawned i try to init him here enemy.Init(); but had error Object reference not set to an instance of an object. But here Debug.Log(enemy._enemyHealth); i get number of enemy health. How i can Init my enemy from here if enemy has class 'Usual Enemy' and it extends from this class 'Enemy' and i wiil have more enemy child cllases?\n",
"AnswerId": "76381309",
"AnswerBody": "The problem is not about \"enemy\" object. It is not null. If you look at the last reference on your call stack, you see that it is \"_animator\" field.\nIt's probably because you call the \"Init\" function before the \"enemy\" object's \"Start\" method called by Unity engine.\n"
},
{
"QuestionId": "76382285",
"QuestionTitle": "Kotlin Error 'unresolved reference' appears when trying to run Java Code from a Kotlin file",
"QuestionBody": "Referencing Problem when Java Class is used in Kotlin. There is the Java class Base32Decoder.java and code from this class is used in the Kotlin file hello.kt.\nWhen I try to run Java code through a Kotlin file, an error occurs because of no reference could be established to the Java class Base32Decoder.\nError message:\n\nhello.kt:4:25: error: unresolved reference: Base32Decoder\n\nBase32Decoder Java class can't resolve the reference to it. Since this class is used inside the Kotlin file, the reference needs to work.\nCode\nfun main(args: Array<String>){\n    val Base32Decoder = Base32Decoder()\n   val rectangleArea: String = Base32Decoder.base32Decode(\"JBSWY3DPFQQFO33SNRSCC===\")\n   println(\"inside the Kotlin codes:\" + rectangleArea)\n}\n\nHow can I reference Java classes when I want to use Java code in Kotlin files?\n",
"AnswerId": "76382653",
"AnswerBody": "The code must be accessible for Kotlin. This means you have to compile (If you compile code in terminal: javac SampleFile.java The Base32Decoder.java file to generate the Base32Decoder.class.\nNow generate the JAR-file with a link to the Kotlin file in command line:\njar cf app.jar Base32Decoder.class hello.kt\n\nNow since you use kotlinc you can execute the code in command line like this:\nkotlinc -classpath app.jar -script hello.kt\n\nNow your code should run fine. The problem is that Kotlin didn't have access to the Base32Decoder.java class.\n"
},
{
"QuestionId": "76380938",
"QuestionTitle": "Azure blob storage returns Unauthorized with SAS generated URL",
"QuestionBody": "I am trying to generate a URL where users can access a file that is in a blob storage container on Azure. The blob storage container is heavily restricted by IP address, and then the service I'm building will manage requests and generate a URL where users can access the file directly. Here is the code used to generate the URL (I think the code itself is probably fine).\nCloudBlobContainer container = BlobStorage.GetContainer(_accountStatementEmailConfig.BlobStorageContainerName);\nCloudBlockBlob blob = container.GetBlockBlobReference(document.StoragePath);\n\nif (!blob.Exists())\n{\n    return NotFound();\n}\n\nTimeSpan sasExpiryTime = TimeSpan.FromMinutes(_apiConfig.PresignedURLExpiryInMinutes);\n\nSharedAccessBlobPermissions permissions = SharedAccessBlobPermissions.Read;\n\nstring sasToken = blob.GetSharedAccessSignature(new SharedAccessBlobPolicy\n{\n    Permissions = permissions,\n    SharedAccessExpiryTime = DateTime.UtcNow.Add(sasExpiryTime)\n}, new SharedAccessBlobHeaders(), _apiConfig.SharedAccessSignaturePermissionsPolicyName);\n\nstring documentUrl = $\"{blob.Uri.AbsoluteUri}{sasToken}\";\n\nThe code generates the URL fine, but when a user goes to the URL they receive the following error:\n<Error>\n    <Code>AuthorizationFailure</Code>\n    <Message>\n        This request is not authorized to perform this operation. RequestId:92d7ca35-501e-0016-2a65-973659000000 Time:2023-06-01T08:43:35.2439678Z\n    </Message>\n</Error>\n\nIt was perhaps my incorrect assumption about SAS that the token would allow me to bypass the IP restrictions since I am generating the URL from a whitelisted IP. Am I taking the incorrect approach, or is there something minor I am overlooking?\n",
"AnswerId": "76381339",
"AnswerBody": "As Gaurav Mantri pointed out in comments, the issue is my understanding of how Azure handles permissions since all of my previous experience is from AWS.\nIn Azure the storage account and the containers have separate access levels. Can achieve similar functionality to AWS's private + presignedURL option by setting the Storage Account to public, and each of the individual containers to private. Then using the generated SAS URL to access the file.\n"
},
{
"QuestionId": "76384686",
"QuestionTitle": "Lag of every nth element",
"QuestionBody": "I have data frame as :\ndf <- data.frame( date =seq(from = as.Date(\"2000-01-01\"), \n                              to =  as.Date(\"2005-01-01\"),'month'))\n\n\ndf <-  df %>% mutate(cumsum = seq(1, length.out = length(date)))\n\nI want to create a new column, which is the sum of the value in cumsum and every 12th value (one year back).\nEDIT:\nI like both your answers! Actually I just found a problem for the solution for me (sorry my explanation was not quite clear.) Your approach gives me the sum of the value now and one year befor. But I do have seveal years and would need the cumsum of all overervation in previous years (so sum(x, lag(x,12), lag(x,24), lag (x,36)). I tried smth. like (rep(lag(cumsu, 12), nrow(df)/12). May you can help. Thanks!\n",
"AnswerId": "76384798",
"AnswerBody": "The literal approach is to use lag, and if you are assured of perfectly-spaced data, then @Jamie's answer is the most direct and simplest approach.\nHowever, if there is a chance that you don't have all intermediate months, this could lag incorrectly. One way to guard against this is to self-join with the previous date.\ndf2 <- df[-20,] # just to impose some missingness\nlibrary(lubridate) # %m+%\ndf2 %>%\n  mutate(\n    # this is the more direct route, but with missingness it glitches\n    rolling_12 = cumsum + lag(cumsum, n = 12),\n    lastyear = date %m+% years(-1)\n  ) %>%\n  left_join(df2, by = c(\"lastyear\" = \"date\"), suffix = c(\"\", \"_12\")) %>%\n  mutate(cumsum_12 = cumsum + cumsum_12) %>%\n  select(-lastyear)\n#          date cumsum rolling_12 cumsum_12\n# 1  2000-01-01      1         NA        NA\n# 2  2000-02-01      2         NA        NA\n# 3  2000-03-01      3         NA        NA\n# 4  2000-04-01      4         NA        NA\n# 5  2000-05-01      5         NA        NA\n# 6  2000-06-01      6         NA        NA\n# 7  2000-07-01      7         NA        NA\n# 8  2000-08-01      8         NA        NA\n# 9  2000-09-01      9         NA        NA\n# 10 2000-10-01     10         NA        NA\n# 11 2000-11-01     11         NA        NA\n# 12 2000-12-01     12         NA        NA\n# 13 2001-01-01     13         14        14\n# 14 2001-02-01     14         16        16\n# 15 2001-03-01     15         18        18\n# 16 2001-04-01     16         20        20\n# 17 2001-05-01     17         22        22\n# 18 2001-06-01     18         24        24\n# 19 2001-07-01     19         26        26\n# 20 2001-09-01     21         29        30  <-- this is where rolling_12 goes wrong\n# 21 2001-10-01     22         31        32\n# 22 2001-11-01     23         33        34\n# 23 2001-12-01     24         35        36\n# 24 2002-01-01     25         37        38\n# 25 2002-02-01     26         39        40\n# 26 2002-03-01     27         41        42\n# 27 2002-04-01     28         43        44\n# 28 2002-05-01     29         45        46\n# 29 2002-06-01     30         47        48\n# 30 2002-07-01     31         49        50\n# 31 2002-08-01     32         51        NA\n# 32 2002-09-01     33         54        54\n# 33 2002-10-01     34         56        56\n# 34 2002-11-01     35         58        58\n# 35 2002-12-01     36         60        60\n# 36 2003-01-01     37         62        62\n# 37 2003-02-01     38         64        64\n# 38 2003-03-01     39         66        66\n# 39 2003-04-01     40         68        68\n# 40 2003-05-01     41         70        70\n# 41 2003-06-01     42         72        72\n# 42 2003-07-01     43         74        74\n# 43 2003-08-01     44         76        76\n# 44 2003-09-01     45         78        78\n# 45 2003-10-01     46         80        80\n# 46 2003-11-01     47         82        82\n# 47 2003-12-01     48         84        84\n# 48 2004-01-01     49         86        86\n# 49 2004-02-01     50         88        88\n# 50 2004-03-01     51         90        90\n# 51 2004-04-01     52         92        92\n# 52 2004-05-01     53         94        94\n# 53 2004-06-01     54         96        96\n# 54 2004-07-01     55         98        98\n# 55 2004-08-01     56        100       100\n# 56 2004-09-01     57        102       102\n# 57 2004-10-01     58        104       104\n# 58 2004-11-01     59        106       106\n# 59 2004-12-01     60        108       108\n# 60 2005-01-01     61        110       110\n\n"
},
{
"QuestionId": "76382357",
"QuestionTitle": "How to do integer arithmetic in Makefile prerequisites?",
"QuestionBody": "I have a file <n>.x and <n-1>.y and I want to create a dependency in my Makefile.\nManually I can write each case as follows:\n2.x : 1.y\n3.x : 2.y\n4.x : 3.y\n...\n\nNow I would like to be able to write this more generically:\n%.x : <???>.y\n\nGnu Make doesn't seem to have integer arithmetic on its own and shell expansions ($$(( )), $(shell ) don't seem to work for prerequisites.\nIs there a way do this in the Makefile itself or should I use an external script that can generate these dependencies and let the Makefile include them?\nEdit: My specific case is dealing with files containing financial transactions. Each file (e.g. 2023.journal) represents transactions for a specific year and includes an opening statement (e.g. 2023_opening.journal), which is based on the closing statement of the year before that. This create a dependency between 2023_opening.journal and 2022.journal.\n",
"AnswerId": "76382656",
"AnswerBody": "With GNU make:\n.SECONDEXPANSION:\n%.x: $$(shell expr $$* + 1).y\n\nAll rules after the .SECONDEXPANSION special target have their list of prerequisites (and only that) processed twice by make: a first time, as everything else, when make parses the Makefile, plus a second time when make needs to check the prerequisites of a target. Contrary to the first phase, during the second phase the automatic variables are defined.\nSo, after the first phase the rule becomes:\n%.x: $(shell expr $* + 1).y\n\n$* is the make automatic variable that expands as the stem in pattern rules. In your case it is the part that matches the %.\nAnd then, when make needs the list of prerequisites for 1.x, the rule is processed again, $(shell expr $* + 1).y is expanded, and becomes (step by step):\n\n1.x: $(shell expr 1 + 1).y # $* --> 1\n1.x: 2.y                   # $(shell expr 1 + 1) --> 2\n\n"
},
{
"QuestionId": "76380520",
"QuestionTitle": "How can I add multiple non-consecutive cells to Name Manager in Excel using Python?",
"QuestionBody": "I am trying to add multiple cells, which are not always consecutive, in only one Name in Excel Name Manager using Python. You can see an example of what I want to do in the attached screenshot.\n\nI have tried the Python libraries openpyxl and XlsxWriter, but both libraries can only define a specific cell or a specific range.\nExamples\n\nopenpyxl\n\nspecific_cell = DefinedName('specific_cell', attr_text='Sheet1!$C$8')\nspecific_range = DefinedName('specific_range', attr_text='Sheet1!$C$8:$J$13')\n\n\nXlsxWriter\n\nworkbook.define_name('specific_cell', '=Sheet1!$G$1')\nworkbook.define_name('specific_range', '=Sheet1!$G$1:$H$10')\n\nIs there any way to add to Name Manager something more complicated than the above?\nBased on the attached screenshot something like\nworkbook.define_name('complex_range','=Sheet1!$B$3:$E$8;Sheet1!$B$12:$C$16;Sheet1!$B$19;Sheet1!$H$12:$I$16')\n\n",
"AnswerId": "76381361",
"AnswerBody": "These will work for each module, the common factor being comma rather than semi-colon?\n\nXlsxwriter:\nworkbook.define_name(\"test\", \"=Sheet1!$B$3:$E$8,Sheet1!$B$12:$C$16,Sheet1!$H$12:$I$16,Sheet1!$B$19\") \n\nXlwings:\nworkbook.names.add(name=\"test\", refers_to=\"=Sheet1!$B$3:$E$8,Sheet1!$B$12:$C$16,Sheet1!$H$12:$I$16,Sheet1!$B$19\") \n\nOpenpyxl:\nworkbook.defined_names.add(DefinedName(\"test\", attr_text=\"Sheet1!$B$3:$E$8,Sheet1!$B$12:$C$16,Sheet1!$H$12:$I$16,Sheet1!$B$19\"))\n\n"
},
{
"QuestionId": "76382439",
"QuestionTitle": "How to fix Multer middleware when it fails to create upload folder and change filename?",
"QuestionBody": "i am trying to upload pdf to server using nodejs and multer but there is a problem.\na send a file from ejs templet and it must be saved at disk on folder named upload and file name changed to specific name .\nbut what happen that Multer middleware does not work no folder created no filename changed\nThere are parts of code .\nejs file\n <form enctype=\"multipart/form-data\">\n        <input type=\"text\" placeholder=\"Book Name\" id=\"name\" />\n        <input type=\"text\" placeholder=\"Author \" id=\"author\" />\n        <input type=\"text\" placeholder=\"Buy link\" id=\"link\" />\n        <input type=\"text\" placeholder=\"Book description\" id=\"desc\" />\n        <input type=\"file\" name=\"pdf\" id=\"pdf\" placeholder=\"upload file\" />\n        <button type=\"submit\">Add</button>\n      </form>\n<script>\n      // const multer = import(\"multer\");\n      // const upload = multer({ dest: \"./public/data/uploads/\" });\n      let form = document.querySelector(\"form\");\n      form.addEventListener(\"submit\", async (e) => {\n        let bookName = document.getElementById(\"name\").value;\n        let bookAuthor = document.getElementById(\"author\").value;\n        let bookLink = document.getElementById(\"link\").value;\n        let bookDesc = document.getElementById(\"desc\").value;\n        let pdf = document.getElementById(\"myfile\").files[0].name;\n        e.preventDefault();\n        try {\n          const res = await fetch(\"/addBooks\", {\n            method: \"POST\",\n            body: JSON.stringify({\n              bookName,\n              bookAuthor,\n              bookDesc,\n              bookLink,\n              pdf,\n            }),\n            headers: { \"Content-Type\": \"application/json\" },\n          });\n</script>\n\n\nmiddleware:\nonst storage = multer.diskStorage({\n  destination: function (req, file, cb) {\n    cb(null, \"upload\");\n  },\n  filename: function (req, file, cb) {\n    cb(null, Date.now() + \"-\" + file.originalname);\n    console.log(destination, filename);\n  },\n});\nconst upload = multer({ storage });\n\nroute.post(\"/addBooks\", upload.single(\"pdf\"), addBook);\n\n\npost func\nlet addBook = async (req, res) => {\n  console.log(\"reqbody >> \", req.body);\n  let { bookName, bookAuthor, bookDesc, bookLink, pdf } = req.body;\n  try {\n    let _book = await books.create({\n      name: bookName,\n      author: bookAuthor,\n      description: bookDesc,\n      buyLink: bookLink,\n      pdf:pdf,\n    });\n    if (_book) {\n      res.status(200).send({ msg: \"success\" });\n    }\n  } catch (error) {\n    logger.error(\"system crashed try again \");\n    res.status(400).send({ msg: \"Wrong\" });\n  }\n};\n\n",
"AnswerId": "76382678",
"AnswerBody": "When sending a file, you must send it in the form, and the information comes in req.file, not in req.body\n"
},
{
"QuestionId": "76381321",
"QuestionTitle": "How do I make the label text of an element bold in javascript?",
"QuestionBody": "My HTML :\n<div id=\"PDF\">\n    <input type=\"checkbox\" id=\"pdf\" name=\"pdf\" value=\"pdf\">\n    <label for=\"pdf\">PDF</label>\n</div>\n\nMy JS :\ndocument.addEventListener('change',function(event){\n    if(event.target.id == \"pdf\"){\n        if(event.target.checked == true){\n            event.target.label.style.fontWeight = \"bold\";\n        }\n        else{\n            event.target.label.style.fontWeight = \"normal\";\n        }\n    }\n});\n\nTo my utter dismay, when I execute the code, I am greeted with this error:\n\nUncaught TypeError: Cannot read properties of undefined (reading\n'style')\n\nHow do I fix this issue?\n",
"AnswerId": "76381368",
"AnswerBody": "There are two main issues here. Firstly, the event target has no attribute of label. You should just select the label explicitly and change the styles. Secondly, I would recommend adding the event listener to only the #pdf div rather than the whole document. This way, you won't need to check for the ID and the event listener won't be fired on every change. For example:\ndocument.getElementById(\"pdf\").addEventListener(\"click\", event => {\n  const label = document.querySelector(\"label[for=pdf]\");\n  if(event.target.checked == true){\n    label.style.fontWeight = \"bold\";\n  }\n  else{\n    label.style.fontWeight = \"normal\";\n  }\n})\n\n"
},
{
"QuestionId": "76384755",
"QuestionTitle": "Oracle SQL Case with Null",
"QuestionBody": "I have a simple query that is taking an input from a bind variable.\nCREATE TABLE \"FRUITS\" \n(   \"FRUIT_NAME\" VARCHAR2(100), \n\"COLOR\" VARCHAR2(100)\n) ;\n\ninsert into fruits (fruit_name, color)\nvalues ('Banana', 'Yellow')\ninsert into fruits (fruit_name, color)\nvalues ('Lemon', '')\ninsert into fruits (fruit_name, color)\nvalues ('Apple', 'Red')\n\nSELECT * FROM FRUITS\nWHERE\nCOLOR =     case\n            when :P1_ITEM is null then null\n            else :P1_ITEM\n            end\n\nIf the input is 'Yellow' the result would be 'Banana' (when 'Red' then 'Apple'). However, if the input happens to be null the result is 'no data found'.\nHow can this be avoided knowing that null is not a null value?\nIf the input is null on color then how can I return the null color row? meaning 'Lemon' + null\nThanks\n",
"AnswerId": "76384803",
"AnswerBody": "Something like this might be one option:\nSELECT * FROM FRUITS\nWHERE\nnvl(COLOR, 'x') = case\n                    when :P1_ITEM is null then 'x'\n                    else :P1_ITEM\n                  end;\n\n"
},
{
"QuestionId": "76380594",
"QuestionTitle": "A local object disappeared in ABAP from $TMP package",
"QuestionBody": "There was a local report in the $TMP that is \"disappeared\" somehow. I did not delete it, but can't see it in SE80 anymore.\nWhat could be the reason?\nSomebody else has deleted it. The system has been resetted somehow to an older backup state. Are any other reasons possible?\nIs there a possibility to see in the traces what has happened or are there any other (better) tracking possibilities?\nUnfortunately I don't know what was the exact name of the disappeared report, but I know the beginning of its name (like Z_ABCD_...)\n",
"AnswerId": "76381374",
"AnswerBody": "You cannot restore or track local objects if they were deleted. There could  be any reason from that you have mentioned. Better ask collegues / basic team if they made some changes.\nTry to look up the table TADIR (Directory of Repository Objects) to check which local development objects exist. Use SE16 / SE16N transaction with condition DEVCLASS = $TMP, additionally AUTHOR to include only objects from specific user, OBJ_NAME = Z_ABCD* to restrict the program name.\nYou can also check the table REPOSRC (Report Source Code), where reports source code in RAWSTRING (DATA field) is stored. Filter on PROGNAME, CNAM (username) to check if the source sode is available on the system (there are also several views avaiable for this table, TRDIR, D010SINF).\nIf the program were assigned to a package / transport and deleted, than you could find it in TADIR with a deletion flag DELFLAG = X, and also in the table E071 with OBJFUNC = D in case of a transport assignment. Local objects just get deleted from the repository tables.\n"
},
{
"QuestionId": "76382531",
"QuestionTitle": "Cannot convert value of type 'Image' to expected argument type 'String'",
"QuestionBody": "I make a category included image scroll butI can't put my variable named tabBarItemName name into image, it keeps giving error like this : Cannot convert value of type 'Image' to expected argument type 'String'\nstruct ContentView: View {\n        @State var currentTab: Int = 0\n        var body: some View {\n            ZStack(alignment:.top) {\n                        TabView(selection:self.$currentTab){\n                            Image1View().tag(0)\n                            Image2View().tag(1)\n                            Image3View().tag(2)\n                        }\n                        .tabViewStyle(.page(indexDisplayMode: .never))\n                        .edgesIgnoringSafeArea(.all)\n                        .padding(.top,76)\n                        CategoryScroll(currentTab: self.$currentTab)\n                    }   \n       }\n    }\n\n    struct CategoryScroll:  View {\n        var tabBarOptions: [Image] = [Image(\"bim\")]\n        @Binding var currentTab : Int\n        var body: some View {\n              ScrollView(.horizontal){\n                  HStack(spacing:20){\n                      ForEach(Array(zip(self.tabBarOptions.indices, self.tabBarOptions)),\n                              id:\\.0,\n                              content: {\n                          index, name in\n                          CategoryView(currentTab: self.$currentTab, tab: index, tabBarItemName: name)\n              })\n            }\n        }.padding(7)\n        .background(Color.white)\n    }\n\n    struct CategoryView: View {\n        @Binding var currentTab: Int\n        var tab : Int\n        var tabBarItemName: Image\n        var body: some View{\n            Button{\n                self.currentTab = tab\n            } label: {\n                VStack{\n                    Image(tabBarItemName) // I'm trying to make changes right here\n                        .frame(width: 12, height: 12)\n                        .padding(.leading, 65)\n    \n                    if currentTab == tab {\n                        Color.init( red: 0.965, green: 0.224, blue: 0.49)\n                            .frame(height: 2)\n                            .padding(.leading,65)\n                    } else {\n                        Color.clear.frame(height: 6)\n                    }\n                }\n                .animation(.spring(), value: self.currentTab)\n                \n            }\n           .buttonStyle(.plain)\n        }\n      }\n    }\n\nI would be very happy if you could help me with this.\n",
"AnswerId": "76382683",
"AnswerBody": "Change\nvar tabBarOptions: [Image] = [Image(\"bim\")]\n\nto\nvar tabBarOptions: [String] = [\"bim\"]\n\nAnd change\nvar tabBarItemName: Image\n\nto\nvar tabBarItemName: String\n\nThe issue:\nImage(tabBarItemName) is expecting a String, not an Image\n"
},
{
"QuestionId": "76380711",
"QuestionTitle": "express js error handler(s) get ignored after first one",
"QuestionBody": "I have an express js app with some routes and a protected route that matches all the calls to an endpoint that starts with /app. after that i add generic error handler to the app like so:\n\napp.use(\"/app\", authenticate);\n\n// app.post(\"/new_user\", validate({body: schema}), route_handler);\n// more routes etc. \n\napp.use((error: TypeError | ValidationError, req: Request, res: Response, next: NextFunction) => {\n        console.log(\"CHECK FOR VALIDATION ERROR\");\n        if(error instanceof ValidationError) {\n            console.log(\"VALIDATION ERROR FOUND\")\n            res.status(403).send(error);\n        } else {\n            console.log(\"NO VALIDATION ERROR\")\n            next();\n        }\n    });\n\n    app.use((error: TypeError | AuthError, req: Request, res: Response, next: NextFunction) => {\n        console.log(\"CHECK FOR AUTH ERROR\");\n        if(error instanceof AuthError) {\n            console.log(\"AUTH ERROR FOUND\");\n            res.status(403).send({msg: \"Authentication failed\"});\n        } else {\n            console.log(\"NO AUTH ERROR\")\n            next();\n        }\n    });\n\n    app.use((error: Error, req: Request, res: Response, next: NextFunction) => {\n        console.log(\"CHECK GENERIC ERROR\");\n        if(error) {\n            res.status(500).send({msg: \"Some generic error happend\"});\n        } else {\n            next();\n        }\n    });\n\n    app.use((req: Request, res: Response, next: NextFunction) => {\n        console.log(\"ROUTE NOT FOUND\");\n        res.status(404).send({\n            msg: \"this endpoint was not found\",\n        });\n\n        next();\n    });\n\nWhen i do a request to for example the following endpoint: https://localhost/app/ and throw a AuthError on purpose in this endpoint the only console.log()'s i ever see are:\nCHECK FOR VALIDATION ERROR\nNO VALIDATION ERROR\nROUTE NOT FOUND\nBut i think i should see the following:\nCHECK FOR VALIDATION ERROR\nNO VALIDATION ERROR\nCHECK FOR AUTH ERROR\nAUTH ERROR FOUND\nWhy is my Auth error middleware never called??\n",
"AnswerId": "76381383",
"AnswerBody": "You need to pass error to the other error middleware when you call next like this:\napp.use((error: TypeError | AuthError, req: Request, res: Response, next: NextFunction) => {\n        console.log(\"CHECK FOR AUTH ERROR\");\n        if(error instanceof AuthError) {\n            console.log(\"AUTH ERROR FOUND\");\n            res.status(403).send({msg: \"Authentication failed\"});\n        } else {\n            console.log(\"NO AUTH ERROR\")\n            next(error);\n        }\n    });\n\nWithout it, the normal middleware will get called.\n"
},
{
"QuestionId": "76383987",
"QuestionTitle": "Notification Manager getSystemService() call not working",
"QuestionBody": "I am following this tutorial on creating notifications\nHowever, I cannot seem to do the following:\nNotificationManager notificationManager = getSystemService(NotificationManager.class);\n\nBecause my Android studio reports the error:\nRequired Type: Context\nProvided: Class <android.app.NotificationManager>\nreason: Class<NotificationManager> is not compatible with Context\n\nPlease let me know how to resolve this issue.\n",
"AnswerId": "76384806",
"AnswerBody": "I found this was my solution:\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n"
},
{
"QuestionId": "76382344",
"QuestionTitle": "Can an f77 subroutine be called from C?",
"QuestionBody": "In modern Fortran, we can call a subroutine from C by using C binding. E.g. The Fortran subroutine will look like this\nsubroutine my_routine(...) bind (C, name=\"my_routine\")\n\nHowever, if the fortran subroutine is an old f77 subroutine, this binding is presumably not an available solution. What would be the best alternative?\n",
"AnswerId": "76382710",
"AnswerBody": "\nHowever, if the fortran subroutine is an old f77 subroutine, this binding is presumably not an available solution.\n\nIt depends.  Modern Fortran is largely backwards compatible with Fortran 77.  Your F77 subroutine will not come with a bind attribute, but if you're willing to add one and compile it with a modern Fortran compiler then chances are pretty good that it will work just as you expect of code originally written for a newer Fortran version.\nOn the other hand, what C interop brings to Fortran is standardization, not a new capability.  People have been calling Fortran routines from C almost as long as people have been using C.\nThe issue here is that the specifics are system and compiler dependent.  If you don't rely on C interop, then you will need to accommodate your Fortran compiler's name-mangling and argument-passing conventions to successfully call Fortran-compiled functions from C code.  These vary.  There used to be a fair amount of tools and documentation for such activity.  I imagine it's harder to find these days, but much of it should still work.\n\nWhat would be the best alternative?\n\nThat depends on your specific constraints.  If you're up for modifying the Fortran source and compiling with a modern compiler then I'd at least start with adding a bind attribute to the function, and see how that plays out.\n"
},
{
"QuestionId": "76382433",
"QuestionTitle": "How can I make an adaptive list to check against another adaptive list?",
"QuestionBody": "I apologize from the start as I am not allowed to share the workbook I am working on (it has confidential information from work) but I will do my best to explain what is happening and what my issue is.\nI have two sheets, \"Tracker\" and \"Reviewers\". In the tracker names are recorded in column L and their submission is recorded in column M. Everything runs on a serial code in column A so there are blank cells between names. Some people have multiple submissions so their names show multiple times in column L. In the reviewers sheet, I have:\n=UNIQUE(FILTER(Tracker!L4:L4999,Tracker!L4:L4999<>0))\n\nIn cell A2 to pull all the names of people who have a submission. This works flawlessly and adapts to include any new people. Then in cell B2 I have written:\n=SUMPRODUCT(IF(ISBLANK(FILTER(Tracker!$L$4:$M$4999,Tracker!$L$4:$L$4999=Reviewers!A2#))=TRUE,1,0))\n\nThe idea here was to get a count of how many \"submissions\" people have without actually writing anything. It is filtering the list of names and submissions by name in the list we just created, checking if their \"submission\" is a blank cell, then adding them up. Issue is that it works when I filter by cell A2 but not when I filter by the function that spills out of cell A2 (A2#). I need it to be adaptive so if new names are added it can make the list longer, hence why I cannot just pull the cells down the list (A2, A3, A4,...). How would you go about getting a check of how many are blank like this?\nAs an example, Tracker could have:\n\n\n\n\nName\nSubmission\n\n\n\n\nJim\nIdea\n\n\nBob\nIdea\n\n\nPam\n\n\n\nSam\nIdea\n\n\nJim\n\n\n\nBob\nIdea\n\n\nJim\n\n\n\nPam\nIdea\n\n\n\n\nAnd Reviewers should return:\n\n\n\n\nName\n#Blank\n\n\n\n\nJim\n2\n\n\nBob\n0\n\n\nPam\n1\n\n\nSam\n0\n\n\n\n\nI hope this makes sense and I hope you can help me edit the equation in cell B2 of the Reviewers sheet to be adaptive and spill the results.\n",
"AnswerId": "76382759",
"AnswerBody": "=LET(d,DROP(FILTER(A:B,A:A<>\"\"),1),\n     n,INDEX(d,,1),\n     s,INDEX(d,,2),\n     u,UNIQUE(n),\n     m,MMULT(--(TOROW(n)=u),--(s=\"\")),\nHSTACK(u,m))\n\nChange the filter range (and maybe the lines to drop) and the index numbers to your situation.\n\nI think this would work in your case:\n=LET(d,DROP(FILTER(Tracker!$L$4:$M$4999,Tracker!$M$4:$M$4999<>\"\"),1),\n     n,INDEX(d,,1),\n     s,INDEX(d,,2),\n     u,UNIQUE(n),\n     m,MMULT(--(TOROW(n)=u),--(s=\"\")),\nHSTACK(u,m))\n\n"
},
{
"QuestionId": "76382452",
"QuestionTitle": "How to show the data of the list outside of the area of ListView Builder in Flutter?",
"QuestionBody": "Is it technically impossible to show the data outside of the list? I searched through the internet but I couldn't get any answers at all smh -_-\nI wanted to display the value of data rows of the list besides of the section ListViewBuilder.\nOutput:\n\n[ ListView Builder  Screen ]\n\n\nName: You, Age: 20 Name: Him, Age: 20\n\nAn Output photo there.\nenter image description here\nString name = userList[index].name;\nint? age = userList[index].age;\n\nclass _Passenger extends State<Passenger> {\n  TextEditingController nameController = TextEditingController();\n  TextEditingController ageController = TextEditingController();\n  int currentIndex = 0;\n\n  final form = GlobalKey<FormState>();\n  bool update = false;\n  final User user = User(name: \"\", age: int.tryParse(''));\n  List<User> userList = [\n    User(name: \"You\", age: 20),\n    User(name: \"Him\", age: 20),\n  ];\n  String text = '';\n  int? number = int.tryParse('');\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp( debugShowCheckedModeBanner: false,\n    home: Scaffold(\n        body: Column(children: <Widget>[\n      Column(\n          children: <Widget>[\n            Container(\n              height: 550,\n              decoration: BoxDecoration(border: Border.all(color: Colors.black)),\n              child: ListView.builder(\n                  itemCount: userList.length,\n                  itemBuilder: (context, index) {\n                    String name = userList[index].name;\n                    int? age = userList[index].age;\n\n                    return SizedBox(\n                      width: 20,\n                      child: Card(\n                          color: Colors.grey,\n                          child: Padding(\n                              padding: const EdgeInsets.all(2.0),\n                              child: ListTile(\n                                title: Text( \"Name: $name    Age: $age\"),\n                              ))),\n                    );\n                  }),\n            ),\n          ],\n        ),\n      Container( child: Text(\"Display the data here, How?\") ),\n      //Add Button\n      Container(\n          width: 150,\n          height: 50,\n          margin: const EdgeInsets.all(10),\n          child: ElevatedButton(\n            onPressed: () {\n              showDialog(\n                  context: context,\n                  builder: (context) => SimpleDialog(children: [\n                        TextField(\n                          decoration: const InputDecoration(labelText: 'Name'),\n                          onChanged: (value) {\n                            setState(() {\n                              text = value;\n                            });\n                          },\n                        ),\n                        TextField(\n                          keyboardType: TextInputType.number,\n                          decoration: const InputDecoration(labelText: 'Age'),\n                          onChanged: (value) {\n                            setState(() {\n                              number = int.parse(value);\n                            });\n                          },\n                        ),\n                        ElevatedButton(\n                            onPressed: () {\n                              setState(() {\n                                userList.add(User(name: text, age: number));\n                              });\n                            },\n                            child: const Text('Add'))\n                      ]));\n            },\n            child: const Text(\"Add\"),\n          )),\n    ])));\n  }\n}\n\nclass User {\n  String name;\n  int? age;\n  User({\n    required this.name,\n    this.age,\n  });\n}\n\n",
"AnswerId": "76382772",
"AnswerBody": "So... if it's the same list, just add this :\nInstead :\n   Container( child: Text(\"Display the data here, How?\") )\n\nDo :\n          SingleChildScrollView(\n            scrollDirection: Axis.horizontal,\n            child: Row(\n              mainAxisAlignment: MainAxisAlignment.center,\n              children: userList\n                  .map((user) => Text(\"Name: ${user.name}, Age: ${user.age} \"))\n                  .toList(),\n            ),\n          ),\n\nI added a SingleChildScrollView with horizontal scroll to avoid problems\nTo send the list of users to another page, just do :\nNavigator.push(\n  context,\n  MaterialPageRoute(\n    settings: const RouteSettings(name: \"no-route\"),\n    builder: (context) => OtherPage(userList: userList),\n  ),\n);\n\n\nclass OtherPage extends StatelessWidget {\n  final List<User> userList;\n\n  const OtherPage({\n    required this.userList,\n    Key? key,\n  }) : super(key: key);\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      body: Column(\n                mainAxisAlignment: MainAxisAlignment.center,\n                children: userList\n                    .map(\n                        (user) => Text(\"Name: ${user.name}, Age: ${user.age} \"))\n                    .toList(),\n              ),\n    );\n  }\n}\n\n\n"
},
{
"QuestionId": "76380806",
"QuestionTitle": "Firebase Cloud Functions V2: The request was not authorized to invoke this service",
"QuestionBody": "I'm attempting to call a callable cloud function (which is already deployed) from a client app and getting this error on the GCP logs:\n{\nhttpRequest: {9}\ninsertId: \"647865c20002422d2d32b259\"\nlabels: {1}\nlogName: \"projects/faker-app-flutter-firebase-dev/logs/run.googleapis.com%2Frequests\"\nreceiveTimestamp: \"2023-06-01T09:32:50.154902339Z\"\nresource: {2}\nseverity: \"WARNING\"\nspanId: \"11982344486849947204\"\ntextPayload: \"The request was not authorized to invoke this service. Read more at https://cloud.google.com/run/docs/securing/authenticating Additional troubleshooting documentation can be found at: https://cloud.google.com/run/docs/troubleshooting#401\"\ntimestamp: \"2023-06-01T09:32:50.138090Z\"\ntrace: \"projects/faker-app-flutter-firebase-dev/traces/ddcb5a4df500af085b7a7f6f89a72ace\"\ntraceSampled: true\n}\n\n\nThe same function works correctly from the Firebase Local Emulator, so I assume this is a permissions issue related to IAM and service accounts (I still don't understand too well how IAM works).\nHere is my code:\nimport * as admin from \"firebase-admin\"\nimport * as functions from \"firebase-functions/v2\"\nimport * as logger from \"firebase-functions/logger\";\n\n// https://github.com/firebase/firebase-tools/issues/1532\nif (admin.apps.length === 0) {\n  admin.initializeApp()\n}\n\nexport const deleteAllUserJobs = functions.https.onCall(async (context: functions.https.CallableRequest) => {\n  const uid = context.auth?.uid\n  if (uid === undefined) {\n    throw new functions.https.HttpsError(\"unauthenticated\", \"You need to be authenticated to perform this action\")\n  }\n  const firestore = admin.firestore()\n  const collectionRef = firestore.collection(`/users/${uid}/jobs`)\n  const collection = await collectionRef.get()\n  logger.debug(`Deleting ${collection.docs.length} docs at \"/users/${uid}/jobs\"`)\n  // transaction version\n  await firestore.runTransaction(async (transaction) => {\n      for (const doc of collection.docs) {\n          transaction.delete(firestore.doc(`/users/${uid}/jobs/${doc.id}`))\n      }\n  })\n\n  logger.debug(`Deleted ${collection.docs.length} docs at \"/users/${uid}/jobs\"`)\n  return {\"success\": true}\n})\n\nThe function was deployed with firebase deploy --only functions, and I made sure the client app calls this function when the user is already authorized.\nAccording to the docs:\n\nIf you encounter permissions errors when deploying functions, make sure that the appropriate IAM roles are assigned to the user running the deployment commands.\n\nThe docs also link to this page, which says:\n\nCloud Functions for Firebase permissions\nFor a list and descriptions of Cloud Functions permissions, refer to\nthe IAM documentation.\nBe aware that the deployment of functions requires a specific\nconfiguration of permissions that aren't included in the standard\nFirebase predefined roles. To deploy functions, use one of the\nfollowing options:\nDelegate the deployment of functions to a project Owner.\n\nIf you're deploying only non-HTTP functions, then a project Editor can deploy your functions.\n\nDelegate deployment of functions to a project member who has the following two roles:\n    Cloud Functions Admin role (roles/cloudfunctions.admin)\n    Service Account User role (roles/iam.serviceAccountUser)\n\nA project Owner can assign these roles to a project member using the Google Cloud Console or gcloud CLI. For detailed steps and\n\nsecurity implications for this role configuration, refer to the IAM\ndocumentation.\n\nBut like I said, I can successfully deploy the function. It's when I try to execute it that I get an error log.\nIn summary, what I'm trying to do is quite basic:\n\nwrite a callable cloud function\ndeploy it\ncall it from the client app\n\nWhen the function runs, it fails with the error above.\nAny advice? Do I need to set a specific IAM role?\n",
"AnswerId": "76381408",
"AnswerBody": "Open https://console.cloud.google.com/iam-admin/<project_name>, find the service account you are using in your firebase project and add the Rol \"Cloud Functions Invoker\".\n\nIs like Admin, Editor or Viewer roles are about manipulating the function on GCP (don't allow you to use it) and Invoker allows that account to invoke the function.\n"
},
{
"QuestionId": "76384708",
"QuestionTitle": "How to set document quality while ingesting document into MarkLogic through PutMarkLogic NiFi processor?",
"QuestionBody": "I'm using NiFi 1.21.0 and nifi-marklogic-nar-1.9.1.6.\nI have been using PutMarkLogic 1.9.1.6 processor to ingest documents to MarkLogic-db for more than 2 years. Recently witnessed that the processor doesn't support adding document-quality (PFB the processor image).\n\nSo I have created a new issue against marklogic/nifi project.\n",
"AnswerId": "76384807",
"AnswerBody": "This enhancement was fixed as part of https://github.com/marklogic/nifi/pull/121. Therefore use nifi-marklogic-nar-1.15.3.1 or later version to set document-quality. I'm currently using PutMarkLogic 1.16.3.2 and I can now see a provision to add Quality.\n\n"
},
{
"QuestionId": "76381224",
"QuestionTitle": "Loop through rows of a table on outlook and change (Text To Display) to an ascending number per each row",
"QuestionBody": "I have used the below code to Loop through selection on outlook and convert into Hyperlinks and change Text To Display Link.\nit works but it adds the the ascending number incrementally to all cells like this picture:\n\nMy need is to add the ascending number per each row like this picture:\n\nIn advance, great thanks for all your help.\nSub Hyperlink_Outlook()\n\n  Dim wDoc As Word.Document, rngSel As Word.Selection, cel As Cell, i As Long\n  \n  Set wDoc = Application.ActiveInspector.WordEditor\n  Set rngSel = wDoc.Windows(1).Selection\n    \n  If Not rngSel Is Nothing And rngSel.Information(wdWithInTable) Then\n    If rngSel.Range.Cells.Count > 0 Then\n       For Each cel In rngSel.Cells\n         If Len(cel.Range.Text) > 10 Then\n           i = i + 1\n            wDoc.Hyperlinks.Add cel.Range, _\n             Address:=Left(cel.Range.Text, Len(cel.Range.Text) - 1), _\n             TextToDisplay:=\"Attachment \" & i\n         End If\n       Next\n    End If\n  End If\n  \nEnd Sub\n\n",
"AnswerId": "76381430",
"AnswerBody": "Try looping through rows first (the following is not tested):\nSub Hyperlink_Outlook()\n\n  Dim wDoc As Word.Document, rngSel As Word.Selection, cel As Cell, i As Long\n  Dim r As Variant\n  \n  Set wDoc = Application.ActiveInspector.WordEditor\n  Set rngSel = wDoc.Windows(1).Selection\n    \n  If Not rngSel Is Nothing And rngSel.Information(wdWithInTable) Then\n    If rngSel.Range.Cells.Count > 0 Then\n      For Each r In rngSel.Rows\n        i = 0 ' reset i here\n        For Each cel In r.Cells\n          If Len(cel.Range.Text) > 10 Then\n            i = i + 1\n             wDoc.Hyperlinks.Add cel.Range, _\n              Address:=Left(cel.Range.Text, Len(cel.Range.Text) - 1), _\n              TextToDisplay:=\"Attachment \" & i\n          End If\n        Next cel\n      Next r\n    End If\n  End If\n  \nEnd Sub\n\n"
},
{
"QuestionId": "76382642",
"QuestionTitle": "Resampling Rows minute wise not working in for Even Minutes in Python DataFrame",
"QuestionBody": "I have df which has 5 columns. A column named date which has minute-wise data of a few days but the data start at 9:15 and ends at 15:29. And then there are four other columns which are named first, max, min, and last which have numerical numbers in them.\nI wrote a code that uses x mins as a variable. It resamples the rows and gives rows of x minutes.\nThe first of resampled will be the 'first' of first row. \nThe 'last' of resampled will be the 'last' of the last row. \nThe max of resampled will be the highest of all the rows of the max column. \nThe low of resampled will be low of all the rows for the low column.\nAnd the date will have datetime of x minutes intervals.\nMy problem is for some minutes the code is working perfectly. But for other minutes I am getting the wrong time as the first row.\nInstead of resampled data starting from 9:15. It starts with some other minute.\nCode:\ndef resample_df(df, x_minutes = '15T'):\n    \n    df.set_index('date', inplace=True)\n\n    resampled_df = df.resample(x_minutes).agg({\n        'first': 'first',\n        'max': 'max',\n        'min': 'min',\n        'last': 'last'\n    })\n\n    resampled_df.reset_index(inplace=True)\n\n    return resampled_df\n\nInput:\n    date                   first    max         min         last\n0   2023-06-01 09:15:00 0.014657    0.966861    0.556195    0.903073\n1   2023-06-01 09:16:00 0.255174    0.607714    0.845804    0.039933\n2   2023-06-01 09:17:00 0.956839    0.881803    0.876322    0.552568\n\nOutput: when x_minutes = '6T'\n    date                   first    max         min         last\n0   2023-06-01 09:12:00 0.014657    0.966861    0.556195    0.552568\n1   2023-06-01 09:18:00 0.437867    0.988005    0.162957    0.897419\n2   2023-06-01 09:24:00 0.296486    0.370957    0.013994    0.108506\n\nThe data shows 9:12 but I don't have 9:12. Why is it giving me the wrong data?\nNote: It works prefectly when minutes entered are odd. e.g. x_minutes = '15T'\nCode to create a dummy df:\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\n# Define the number of days for which data is generated\nnum_days = 5\n\n# Define the start and end times for each day\nstart_time = datetime.strptime('09:15', '%H:%M').time()\nend_time = datetime.strptime('15:30', '%H:%M').time()\n\n# Create a list of all the timestamps for the specified days\ntimestamps = []\ncurrent_date = datetime.now().replace(hour=start_time.hour, minute=start_time.minute, second=0, microsecond=0)\nend_date = current_date + timedelta(days=num_days)\nwhile current_date < end_date:\n    current_time = current_date.time()\n    if start_time <= current_time <= end_time:\n        timestamps.append(current_date)\n    current_date += timedelta(minutes=1)\n\n# Generate random data for each column\ndata = {\n    'date': timestamps,\n    'first': [random.random() for _ in range(len(timestamps))],\n    'max': [random.random() for _ in range(len(timestamps))],\n    'min': [random.random() for _ in range(len(timestamps))],\n    'last': [random.random() for _ in range(len(timestamps))]\n}\n\n# Create the DataFrame\ndf = pd.DataFrame(data)\n\n# Display the resulting DataFrame\ndisplay(df)\n\n",
"AnswerId": "76382822",
"AnswerBody": "Use:\nresampled_df = df.resample(x_minutes, origin = 'start').agg({\n    'first': 'first',\n    'max': 'max',\n    'min': 'min',\n    'last': 'last'\n})\n\n"
},
{
"QuestionId": "76384685",
"QuestionTitle": "SwiftUI Toggle how to distinguish changing value by UI action vs changing programatically",
"QuestionBody": "If i have a toggle, which updates its state from external async load but also by user intput, how can i differentiate those two? eg. to perform a special action on user action\n    Group {\n        Toggle(isOn: $on) {\n            EmptyView()\n        }\n    }\n    .onChange(of: on) { newValue in\n        was \"on\" changed by user or onAppear async update?\n    }\n    .onAppear {\n        async update on\n    }\n\nPS: this is mostly for macOS, and there the tapGesture on Toggle doesn't work\n",
"AnswerId": "76384818",
"AnswerBody": "If you want a side effect for use the user actions, you can use a custom wrapper Binding:\nstruct ContentView: View {\n    @State private var on: Bool = false\n    \n    var userManagedOn: Binding<Bool> {\n        .init {\n            return on\n        } set: { newValue in\n            print(\"Side effect\")\n            on = newValue\n        }\n    }\n    \n    var body: some View {\n        VStack {\n            Group {\n                Toggle(isOn: userManagedOn) {\n                    EmptyView()\n                }\n            }\n        }\n        .padding()\n        .onAppear {\n            Task { @MainActor in\n                try? await Task.sleep(nanoseconds: NSEC_PER_SEC)\n                on.toggle()\n            }\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76380987",
"QuestionTitle": "How can I change the color of an icon when a checkbox is checked using Tailwind?",
"QuestionBody": "<input type=\"checkbox\" id=\"darkmode-toggle\" class=\"peer invisible h-0 w-0\" />\n<label for=\"darkmode-toggle\" class=\"btn-toggle group\">\n    <svg class=\"icon absolute\">\n        <use href=\"../../assets/icons/spirit.svg#sun\" />\n    </svg>\n    <svg class=\"icon absolute  group-[peer-checked]:fill-secondary-dark-300\">\n        <use href=\"../../assets/icons/spirit.svg#moon\" />\n    </svg>\n</label>\n\nIn the given HTML code (using Tailwind CSS), I want to change the color of the icon when the associated input checkbox is checked.\nThe attempted selector used is group-[peer-checked]:fill-secondary-dark-300. However, the desired icon color change is not happening.\nHow can I achieve the desired result of changing the color of the icon when the input checkbox is checked using the provided selector?\nThis is what I want to achieve with this selector:\n\ngroup (select the parent \"label\")\n\n[peer-checked] (when the sibling of the label \"input\" is checked)\n\nfill-secondary-dark-300: change the icon color.\n\n\n",
"AnswerId": "76381434",
"AnswerBody": "You could consider using group-[.peer:checked+&]::\n\n\ntailwind.config = {\n  theme: {\n    extend: {\n      colors: {\n        'secondary-dark-300': 'red',\n      },\n    },\n  },\n};\n<script src=\"https://cdn.tailwindcss.com\"></script>\n\n<input type=\"checkbox\" id=\"darkmode-toggle\" class=\"peer invisible h-0 w-0\" />\n<label for=\"darkmode-toggle\" class=\"btn-toggle group\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"currentColor\" class=\"w-6 h-6\">\n    <path d=\"M12 2.25a.75.75 0 01.75.75v2.25a.75.75 0 01-1.5 0V3a.75.75 0 01.75-.75zM7.5 12a4.5 4.5 0 119 0 4.5 4.5 0 01-9 0zM18.894 6.166a.75.75 0 00-1.06-1.06l-1.591 1.59a.75.75 0 101.06 1.061l1.591-1.59zM21.75 12a.75.75 0 01-.75.75h-2.25a.75.75 0 010-1.5H21a.75.75 0 01.75.75zM17.834 18.894a.75.75 0 001.06-1.06l-1.59-1.591a.75.75 0 10-1.061 1.06l1.59 1.591zM12 18a.75.75 0 01.75.75V21a.75.75 0 01-1.5 0v-2.25A.75.75 0 0112 18zM7.758 17.303a.75.75 0 00-1.061-1.06l-1.591 1.59a.75.75 0 001.06 1.061l1.591-1.59zM6 12a.75.75 0 01-.75.75H3a.75.75 0 010-1.5h2.25A.75.75 0 016 12zM6.697 7.757a.75.75 0 001.06-1.06l-1.59-1.591a.75.75 0 00-1.061 1.06l1.59 1.591z\" />\n  </svg>\n \n  <svg class=\"w-6 h-6 group-[.peer:checked+&]:fill-secondary-dark-300\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"currentColor\">\n    <path fill-rule=\"evenodd\" d=\"M9.528 1.718a.75.75 0 01.162.819A8.97 8.97 0 009 6a9 9 0 009 9 8.97 8.97 0 003.463-.69.75.75 0 01.981.98 10.503 10.503 0 01-9.694 6.46c-5.799 0-10.5-4.701-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 01.818.162z\" clip-rule=\"evenodd\" />\n  </svg>\n</label>\n\n\n\n"
},
{
"QuestionId": "76380618",
"QuestionTitle": "Javascript - alert problem with onblur and focus-visible Firefox/Chrome",
"QuestionBody": "In onblur I need to call alert(), but this doesn't work in Chrome and Firefox. Sess https://jsfiddle.net/mimomade/5sur482w/1/\nIn Firefox :focus-visible stays after leaving the 2nd and 4th input field and is not removed.\nIn Chrome I can't leave the 2nd input field. Although the 1st doesn't has any problem.\n",
"AnswerId": "76381442",
"AnswerBody": "At the very bottom is the code with both bugs fixed. You're initial JavaScript looks like this:\n// Has different bugs in Firefox and Chrome.\nfunction blurring(el) {\n  console.log(el.id + ' pre  alert');\n  alert('blurring ' + el.id);\n  console.log(el.id + ' post alert');\n}\n\nIn Firefox, your apparent bug actually masks a bug similar to what you're encountering in Chrome. When the alert is removed, the code has the intended behavior, so alert and the event are interacting in a weird way. In this specific case, to get around this, we can just wait for the event to finish by wrapping the function in a zero-millisecond timeout.\n// Has a similar bug in both browsers.\nfunction blurring(el) {\n  console.log(el.id + ' pre  alert');\n  setTimeout(function () {\n    alert('blurring ' + el.id);\n    console.log(el.id + ' post alert');\n  }, 0);\n}\n\nIn Chrome, your bug appears to be caused by the blur event emitting each time the alert box is closed. Luckily, because we wait for the events to finish, the active element should be the element newly selected input instead of whatever the browser set it to. This means checking ensuring el and document.activeElement are different is sufficient to fix this bug.\n// addresses both bugs.\nfunction blurring(el) {\n  console.log(el.id + ' pre  alert');\n  setTimeout(function () {\n    if (document.activeElement !== el) {\n      alert('blurring ' + el.id);\n      console.log(el.id + ' post alert');\n    }\n  }, 0);\n}\n\n"
},
{
"QuestionId": "76382726",
"QuestionTitle": "How to type NextJS router.query.id as string?",
"QuestionBody": "I'm pretty new to TypeScript, as well as using the T3 stack (React Query / Tanstack Query).  I'm trying to type companyId as string, so that I don't have to type companyId as string every time I use it later on it in the code, but I can't figure out how to best to that or what the best practice is with this stack... I'm used to plain old JavaScript and useEffects to do API calls (and probably writing worse code).\nNote:  the following code exists at /pages/companies/[id].tsx\nThe following is my first attempt, but I get a  \"Rendered more hooks than during the previous render\" error at \"const { data: company} ...\", which makes sense:\nconst CompanyPage: NextPage = () => {\n  const router = useRouter()\n\n  const companyId = router.query.id\n  if (!companyId || Array.isArray(companyId)) return <div>Loading...</div> // have to check for Array.isArray because of NextJS/Typescript bug\n\n  const { data: company } = api.companies.getSingleById.useQuery({companyId: companyId});\n  if (!company ) return <div>Loading...</div>\n\n  ...\n  return (...)\n\nI tried doing the following, but I was not allowed because the type for companyId from router.query.id is string | string[] | undefined.\nconst CompanyPage: NextPage = () => {\n  const router = useRouter()\n\n  const companyId: string = router.query.id // Type 'string | string[] | undefined' is not assignable to type 'string'\n\n  const { data: company } = api.companies.getSingleById.useQuery({companyId: companyId});\n  if (!company ) return <div>Loading...</div>\n\n  ...\n  return (...)\n\nUPDATE:\nI changed it to the following now, which seems to work, but it doesn't feel quite right it's the correct way to do things.  (With this method, I only have to write companyId as string once, which is fine.)\nconst CompanyPage: NextPage = () => {\n  const router = useRouter()\n\n  const companyId = router.query.id\n  const { data: company } = api.companies.getSingleById.useQuery({companyId: companyId as string});\n\n  if (!companyId || Array.isArray(companyId)) return <div>Loading...</div> // have to check for Array.isArray because of NextJS/Typescript bug\n  if (!company ) return <div>Loading...</div>\n\n  ...\n  return (...)\n\nANSWER:\nThank you to Fabio for the accepted answer.\nI'm destructuring router.query into multiple variables on other routes, so this is an example of doing that based on the accepted answer:\nconst { companyId, locationId } = useMemo(() => ({\n  companyId: router.query?.companyId?.toString() ?? \"\",\n  locationId: router.query?.locationId?.toString() ?? \"\",\n}), [router.query?.companyId, router.query?.locationId]);\n\n",
"AnswerId": "76382845",
"AnswerBody": "You can use optional chaining and nullish coalescing in combination with the query params' toString() method, heres an example based on your code snippet:\nconst CompanyPage: NextPage = () => {\n  const router = useRouter();\n\n  // this result will be of type string\n  const companyId = useMemo(() => {\n    return router.query?.id?.toString?.() ?? \"\";\n  }, [router.query?.id]);\n\n  const { data: company } = api.companies.getSingleById.useQuery({\n    companyId: companyId,\n  });\n\n  if (!company) return <div>Loading...</div>;\n\n  return; // ...\n};\n\nThe reason why the query parameters are of type string | string[] is because if you had a catch-all segment each of the url parts will be split by / and presented to you as an array.\nExample\nIf you had the route /some-segment/[...href] and the URL would be /some-segment/200/my-post following would apply:\n\nThe contents of the href query variable would be [\"200\", \"my-post\"]\nCalling href?.toString?.() would return you /some-segment/200/my-post.\n\n"
},
{
"QuestionId": "76384713",
"QuestionTitle": "Tried to use state variable inside another state variable, but it didn't work as expected it to, Why ? (in ReactJS using function component)",
"QuestionBody": "I was trying to use a state variables value inside another state variable, but when the other sub state variable was updated outside, its updated value didn't get reflected in parent state variable, why did this happened? can I not use state variable inside another state variable or is there any specific way to use it?\nCan anyone explain this please?\nconst [noOfPersonstForRoom, setNoOfPersonsForRoom] = useState([2]);\n\nconst [ageOfPerson1ForRoom, setAgeOfPerson1ForRoom] = useState([0]);\nconst [ageOfPerson2ForRoom, setAgeOfPerson2ForRoom] = useState([0]);\n\n    const [rooms, setRooms] = useState([\n    {\n        roomNo: 1,\n        noOfPersons: noOfPersonsForRoom[0], \n                    ageOfPerson1: ageOfPerson1ForRoom[0],\n                    ageOfPerson2: ageOfPerson2ForRoom[0]\n        \n\n        \n    },\n]);\n\nThis is code of what I tried, with some changes.\nTo change sub state variable, I used following function, and it was called on onChange() of an input field:\nconst changeNoOfPersonsForRoom = (e, index) => {\n        let newNoOfPersonsForRoom = e.target.value;\n        setNoOfPersonsForRoom([\n            ...noOfPersonsForRoom.slice(0, index),\n            e.target.value,\n            ...noOfPersonsForRoom.slice(index + 1),\n        ]);\n\n",
"AnswerId": "76384822",
"AnswerBody": "Could you add how you update your state(s)?\nBut in general, states are not bound or connected to each other.\nIf you change one state, it won't update any other state.\nconst [rooms, setRooms] = useState([\n    {\n        roomNo: 1,\n        noOfPersons: noOfPersonsForRoom[0], \n        ageOfPerson1: ageOfPerson1ForRoom[0],\n        ageOfPerson2: ageOfPerson2ForRoom[0]\n    },\n\nGiven your example, you just set the initial state of rooms with the values of your previous states. Nothing more. If you need to update several states, you have to update each of them separately.\n"
},
{
"QuestionId": "76382432",
"QuestionTitle": "What is the best way to check for consecutive missing values in a data column in R and exclude them based on a related column value?",
"QuestionBody": "I am trying to write code in R for a dataset to check if DAYS column have consecutive numbers and print out the missing DAYS number, in such a way that, if the count of missing consecutive numbers between two rows of the DAYS column equals to that count+1 in the corresponding last row of the PERIOD column, exclude it from the output. For example, consider the two rows in DAYS column 163 and 165, where the count of missing number is 1. But in this case, the last row (where DAYS is 165) has PERIOD value of 2, that is (count+1). So, exclude this missing value (164) from the output. However if you look at DAYS 170 and 172,y you can see 172 has PERIOD value of 1 (not 2 or count+1). So, show this output (171).\nHere is the first 28 rows of the dataset.\nDAYS PERIOD\n146 1\n147 1\n148 1\n149 1\n150 1\n151 1\n152 1\n153 1\n154 1\n155 1\n156 1\n157 1\n158 1\n159 1\n160 1\n161 1\n162 1\n163 1\n165 2\n166 1\n167 1\n168 1\n169 1\n170 1\n172 1\n173 1\n174 1\n175 1\n\n\n\n\nI tried\nFirst, created a sequence of expected DAYS values\nexpected_days <- seq(min(hs$DAYS), max(hs$DAYS))\nThen, find the missing DAYS values\nmissing_days <- setdiff(expected_days, hs$DAYS)\nHow to do the next bit?\n",
"AnswerId": "76382854",
"AnswerBody": "I've managed to do this using tidyverse tools:\nSet up example data\nI've tweaked your data slightly to show that the solution can handle longer runs of missing days.\nlibrary(vroom)\nlibrary(dplyr)\nlibrary(tidyr)\n\ntest <-\n  vroom(\n    I(\n\"days period\n161 1\n162 1\n163 1\n166 3\n167 1\n168 1\n169 1\n170 1\n172 1\n\"),\ncol_types = c(\"ii\"))\n\n\nAdd 'empty' days explicitly to data frame\nall_days <- min(test[[\"days\"]]):max(test[[\"days\"]])\n\nframe <- tibble(days = all_days)\n\ntest <-\n  right_join(test, frame, by = \"days\") |> \n  arrange(days)\n\ntest\n#> # A tibble: 12 × 2\n#>     days period\n#>    <int>  <int>\n#>  1   161      1\n#>  2   162      1\n#>  3   163      1\n#>  4   164     NA\n#>  5   165     NA\n#>  6   166      3\n#>  7   167      1\n#>  8   168      1\n#>  9   169      1\n#> 10   170      1\n#> 11   171     NA\n#> 12   172      1\n\nFind the number of consecutive missing days\ntest <- \n  mutate(test,\n         no_na = xor(is.na(period), is.na(lag(period))),\n          missingness_group = cumsum(no_na)) |> \n  select(-no_na)\n\ntest <- \n  group_by(test, missingness_group) |> \n  mutate(missing_days = \n           case_when(\n             all(is.na(period)) ~ n(),\n             TRUE               ~ 0)) |> \n  ungroup() |> \n  select(-missingness_group)\n\ntest\n#> # A tibble: 12 × 3\n#>     days period missing_days\n#>    <int>  <int>        <dbl>\n#>  1   161      1            0\n#>  2   162      1            0\n#>  3   163      1            0\n#>  4   164     NA            2\n#>  5   165     NA            2\n#>  6   166      3            0\n#>  7   167      1            0\n#>  8   168      1            0\n#>  9   169      1            0\n#> 10   170      1            0\n#> 11   171     NA            1\n#> 12   172      1            0\n\nRemove rows where days are all accounted for\ntest <- mutate(test, extra_days = period - 1)\n\ntest <- fill(test, extra_days, .direction = \"up\")\n\ntest <-\n  filter(test, !is.na(period) | missing_days > extra_days) |> \n  select(days, period)\n\ntest\n#> # A tibble: 10 × 2\n#>     days period\n#>    <int>  <int>\n#>  1   161      1\n#>  2   162      1\n#>  3   163      1\n#>  4   166      3\n#>  5   167      1\n#>  6   168      1\n#>  7   169      1\n#>  8   170      1\n#>  9   171     NA\n#> 10   172      1\n\nCreated on 2023-06-01 with reprex v2.0.2\n"
},
{
"QuestionId": "76380830",
"QuestionTitle": "Spring Boot Wrong date returned",
"QuestionBody": "I have an entity Person\n@Entity\n@Data\npublic class Person {\n\n  @Temporal(TemporalType.DATE)\n  private Calendar dob;\n}\n\nAnd some dao classes\n@Data\npublic class PersonResponse {\n\n  @JsonFormat(pattern = \"yyyy-MM-dd\")\n  private Calendar dob;\n}\n\n@Data\npublic class PersonRequest{\n  @DateTimeFormat(pattern = \"yyyy-MM-dd\")\n  private Calendar dob;\n}\n\nWhen storing values it works perfectly. Example if I send \"2000-01-01\" it's stored as is in the database \"2000-01-01\". But When I try to return it I get \"1999-12-31\".\nNow it's clear that is a Timezone Problem but I don't know how to fix it.\nMy explanation for the cause\nThe user timezone is GMT+1 so it is some how retrieved as \"2000-01-01T00:00:00.000 +01:00\", then parsed to UTC \"1999-12-31T23:00:00.000 +00:00\" to finally be returned as \"1999-12-31\".\nBut why? And how can I prevent this knowing that users timezones can change (so adding the time offset manually of 1 hour won't work).\nI tried also changing type from Calendar to java.util.Date and java.sql.Date... but no result.\nSimilar questions where asked before like this one but I still couldn't understand how to fix it\n",
"AnswerId": "76381444",
"AnswerBody": "If Applicable try to switch from class Calendar to LocalDate. LocalDate does not take time zone into consideration. This should resolve your issue (and simplify your code). Also, for formatting the LocalDate with Json see the answer to this question: Spring Data JPA - ZonedDateTime format for json serialization\n"
},
{
"QuestionId": "76384705",
"QuestionTitle": "Python: Fix missing import with a monkey patch",
"QuestionBody": "I am trying to monkey patch a missing import. The old_invoke() still does not get the import.\nIn case it is relevant, MyClass is a gdb.Command.\n(gdb) pi\n>>> import mymodule\n>>> old_invoke = mymodule.MyClass.invoke\n>>> def new_invoke(self, *k, **kw):\n...   print(\"New invoke\")\n...   import getopt\n...   old_invoke(self, *k, **kw)\n...\n>>> mymodule.MyClass.invoke = new_invoke\n>>>\n(gdb) my_gdb_command\nNew invoke\nPython Exception <class 'NameError'> name 'getopt' is not defined:\nError occurred in Python: name 'getopt' is not defined\n\nAlso, in case it is relevant, the initial files and sourcing looks something like this:\nmymodule.py:\nimport gdb\nclass MyClass(gdb.Command):\n   ...\n\n   def invoke(self, arg, from_tty):\n      options, remainder = getopt.getopt(args, 'p:s:t:o:')\n      ...\n\nMyClass()\n\nmyothermodule.py:\nimport mymodule\n...\n\nSourcing the above\n(gdb) source myothermodule.py\n\n",
"AnswerId": "76384834",
"AnswerBody": "old_invoke is trying to reference mymodule's getopt, which doesn't exist. You need:\n>>> import mymodule\n>>> old_invoke = mymodule.MyClass.invoke\n>>> def new_invoke(self, *k, **kw):\n...   print(\"New invoke\")\n...   import getopt\n...   \n...   # here\n...   mymodule.getopt = getopt\n...   \n...   old_invoke(self, *k, **kw)\n...\n>>> mymodule.MyClass.invoke = new_invoke\n\nBut, realistically, you should just have an import getopt in mymodule:\n# mymodule.py\nimport getopt\n...\n\nThen your function is simply:\n>>> import mymodule\n>>> old_invoke = mymodule.MyClass.invoke\n>>> def new_invoke(self, *k, **kw):\n...   print(\"New invoke\")\n...   old_invoke(self, *k, **kw)\n...\n>>> mymodule.MyClass.invoke = new_invoke\n\nAddendum\nAs another note, using import in a function isn't generally recommended. Unless you are only calling this function once (and even then, why?), every time you call the function you are attempting to load a module, which at best will always do a check against sys.modules when you probably don't have to.\nHave the import getopt at the top of the script:\nimport getopt\nimport mymodule\n\nmymodule.getopt = getopt\n\nWhich is where you'd probably expect this to be anyways\n"
},
{
"QuestionId": "76382691",
"QuestionTitle": "Adding a volume in dockerfile",
"QuestionBody": "I am trying to create an image of Windows with additional things. My question is whether it is possible to include a specific volume when creating the container. For example, I would like to do:\ndocker run --name container -v shared:c:\\shared -it mcr.microsoft.com/windows/servercore:20H2-amd64 powershell\nThere I am accessing the shared volume, but I want to do this in the dockerfile as a command.\nI want something like this after running the container:\n\nThank you for the help\nI tried to use the VOLUME command but I don't know if I am doing it right or it's not for what I am trying.\n",
"AnswerId": "76382862",
"AnswerBody": "Using VOLUME in dockerfile does not mount the volume during build, this only specifies a target where a directory can be mounted during container runtime (anonymous volume).\nBecause image build and container run can happen on different machines, so having VOLUME source defined in dockerfile (buid time) does not make sense.\n"
},
{
"QuestionId": "76381353",
"QuestionTitle": "How to change cursor size in PyQt5?",
"QuestionBody": "I want to implement brush cursor like in most image editors when cursor is a circle that change its size according to brush size. I've read the docs and found only setShape method, but no setSize. Is it possible in Qt to change cursor size?\n",
"AnswerId": "76381491",
"AnswerBody": "pixmap = QPixmap(\"image.png\")  # Replace with the path to your custom cursor image, brush in your case\npixmap = pixmap.scaled(30, 30)  # Set the desired size\ncursor = QCursor(pixmap)\nself.setCursor(cursor)\n\nyou can change the size and the \"form\" of your cursor in PyQt5 by creating a pixmap and then assigning in to your cursor\n"
},
{
"QuestionId": "76384330",
"QuestionTitle": "subprocess.run command with non-utf-8 characters (UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbb)",
"QuestionBody": "Encoding honestly continues to confuse me, so hopefully this isn't a totally daft question.\nI have a python script that calls metaflac to compare the flac fingerprints in a file to the flac fingerprints of a file. Recently I came across files with » (https://bytetool.web.app/en/ascii/code/0xbb/) in the file name. This failed with how I was dealing with the file name strings, so I'm trying to work around that. My first thought was that I needed to deal with this as bytes objects. But when I do that and then call subprocess.run, I get a UnicodeDecodeError\nHere's the snippet of code that is give me errors:\ndef test():\n    directory = b'<redacted>'\n    ffp_open = open(directory + b'<redacted>.ffp','rb')\n    ffp_lines = ffp_open.readlines()\n    print(ffp_lines)\n    for line in ffp_lines:\n        if not line.startswith(b';') and b':' in line:\n            txt = line.split(b':')\n\n            ffp_cmd = b'/usr/bin/metaflac --show-md5sum \\'' + directory + b'/' + txt[0]+ b'\\''\n            print(ffp_cmd)\n            get_ffp_process = subprocess.run(ffp_cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True,shell=True)\n\nWith that, I get the following output (shortened to make more sense):\n[b'01 - Intro.flac:eee7ca01db887168ce8312e7a3bdf8d6\\r\\n', b'04 - Song title \\xbb Other Song \\xbb.flac:98d2d03f47790d234052c6c9a2ca5cfd\\r\\n']\nb\"/usr/bin/metaflac --show-md5sum '<redacted>/01 - Intro.flac'\"\nb\"/usr/bin/metaflac --show-md5sum '<redacted>/04 - Song title \\xbb Other Song \\xbb.flac'\"\n\n    get_ffp_process = subprocess.run(ffp_cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True,shell=True)\n  File \"<redacted>/python/lib/python3.9/subprocess.py\", line 507, in run\n    stdout, stderr = process.communicate(input, timeout=timeout)\n  File \"<redacted>/python/lib/python3.9/subprocess.py\", line 1134, in communicate\n    stdout, stderr = self._communicate(input, endtime, timeout)\n  File \"<redacted>/python/lib/python3.9/subprocess.py\", line 2021, in _communicate\n    stderr = self._translate_newlines(stderr,\n  File \"<redacted>/python/lib/python3.9/subprocess.py\", line 1011, in _translate_newlines\n    data = data.decode(encoding, errors)\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xbb in position 85: invalid start byte\n\nIf I run this directly on the command line it works just fine (using tabs to fill in the file name):\nmetaflac --show-md5sum 04\\ -\\ Song\\ title\\ »\\ Other Song\\ ».flac \n98d2d03f47790d234052c6c9a2ca5cfd\n\nThe FFP file, through nano, looks like this:\n01 - Intro.flac:eee7ca01db887168ce8312e7a3bdf8d6\n04 - Song title � Other Song �.flac:98d2d03f47790d234052c6c9a2ca5cfd\n\nI have no control over the file names, so I'm trying to be as flexible as possible to handle them, which is why I thought a bytes object would be best. I'd appreciate any direction. Thanks!\n",
"AnswerId": "76384840",
"AnswerBody": "I believe coding of \"latin1\" or \"cp1252\" will do decode that successfully. Also, it is easier to deal with strings than with bytes, so here is my suggestion:\nimport pathlib\nimport subprocess\n\ndirectory = pathlib.Path(\"/tmp\")\n\nwith open(directory / \"data.ffp\", \"r\", encoding=\"latin1\") as stream:\n    for line in stream:\n        if line.startswith(\";\"):\n            continue\n        if \":\" not in line:\n            continue\n\n        file_name, expected_md5sum = line.strip().split(\":\")\n        print(f\"{name=}\")\n        print(f\"{expected_md5sum=}\")\n        command = [\n            \"/usr/bin/metaflac\",\n            \"--show-md5sum\",\n            str(directory / file_name)\n        ]\n        print(f\"{command=}\")\n\n        # Now you can run the command. I assume that the command will return a MD5 sum back.\n        completed_process = subprocess.run(\n            command,\n            encoding=\"latin1\",\n            capture_output=True,\n        )\n\n        # Now, completed_process.stdout will hold the output\n        # as a string, not bytes.\n\nHere is a sample output:\nname='04 - Song title » Other Song ».flac'\nexpected_md5sum='eee7ca01db887168ce8312e7a3bdf8d6\\n'\ncommand=['/usr/bin/metaflac', '--show-md5sum', '/tmp/01 - Intro.flac']\nname='04 - Song title » Other Song ».flac'\nexpected_md5sum='98d2d03f47790d234052c6c9a2ca5cfd\\n'\ncommand=['/usr/bin/metaflac', '--show-md5sum', '/tmp/04 - Song title » Other Song ».flac']\n\nSince my system does not have the metaflac command, I cannot test it. Please forgive any error that come up. If an error found, please post in the comment and I will try to fix it.\n"
},
{
"QuestionId": "76382379",
"QuestionTitle": "Optimize data for t.test to avoid \"data are essentially constant\" error",
"QuestionBody": "There are several StackOverflow posts about situation where t.test() in R produce an error saying \"data are essentially constant\", this is due to that there is not enough difference between the groups (there is no variation) to run the t.test(). (Correct me if there is something else)\nI'm in this situation, and I would like to fix this buy altering my data the way the statistical features of the data don't change drastically, so the t-test stays correct. I was wondering what if I add some very little variation to the data (e.g. change 0.301029995663981 to 0.301029995663990), or what else can I do?\nFor example, this is my data:\n# Create the data frame\ndata <- data.frame(Date = c(\"2021.08\",\"2021.08\",\"2021.09\",\"2021.09\",\"2021.09\",\"2021.10\",\"2021.10\",\"2021.10\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.12\",\"2021.12\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.09\",\"2022.09\",\"2022.10\",\"2022.10\",\"2022.10\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.12\",\"2022.12\",\"2022.12\",\"2022.12\",\"2023.01\",\"2023.01\",\"2023.01\",\"2023.01\",\"2021.08\",\"2021.08\",\"2021.09\",\"2021.09\",\"2021.09\",\"2021.10\",\"2021.10\",\"2021.10\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.12\",\"2021.12\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.09\",\"2022.09\",\"2022.09\",\"2022.09\",\"2022.10\",\"2022.10\",\"2022.10\",\"2022.10\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.12\",\"2022.12\",\"2022.12\",\"2022.12\",\"2023.01\",\"2023.01\",\"2023.01\",\"2023.01\"),\nSpecies = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\"),\nSite = c(\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n\"Something\",\"Something\",\"Something\",\"Something\"),\nMean = c(\"0.301029995663981\",\"1.07918124604762\",\"0.698970004336019\",\"1.23044892137827\",\"1.53147891704226\",\"1.41497334797082\",\"1.7160033436348\",\n         \"0.698970004336019\",\"1.39794000867204\",\"1\",\"0.301029995663981\",\"0.301029995663981\",\"0.477121254719662\",\"0.301029995663981\",\"0.301029995663981\",\n         \"0.301029995663981\",\"0.477121254719662\",\"0.301029995663981\",\"0.301029995663981\",\"0.845098040014257\",\"0.301029995663981\",\"0.301029995663981\",\n         \"0.477121254719662\",\"0.698970004336019\",\"1.23044892137827\",\"1.41497334797082\",\"1.95904139232109\",\"1.5910646070265\",\"1.53147891704226\",\n         \"1.14612803567824\",\"1.57978359661681\",\"1.34242268082221\",\"0.778151250383644\",\"0.301029995663981\",\"0.301029995663981\",\"0.477121254719662\",\n         \"0.301029995663981\",\"1.20411998265592\",\"0.845098040014257\",\"1.17609125905568\",\"1.20411998265592\",\"0.698970004336019\",\"0.301029995663981\",\n         \"0.698970004336019\",\"0.698970004336019\",\"0.903089986991944\",\"1.14612803567824\",\"0.301029995663981\",\"0.602059991327962\",\"0.301029995663981\",\n         \"0.845098040014257\",\"0.698970004336019\",\"0.698970004336019\",\"0.301029995663981\",\"0.698970004336019\",\"0.301029995663981\",\"0.301029995663981\",\n         \"0.301029995663981\",\"0.477121254719662\",\"0.301029995663981\",\"0.301029995663981\",\"0.301029995663981\",\"0.301029995663981\",\"0.301029995663981\",\n         \"0.602059991327962\",\"0.301029995663981\",\"0.845098040014257\",\"1.92941892571429\",\"1.27875360095283\",\"0.698970004336019\",\"1.38021124171161\",\n         \"1.20411998265592\",\"1.38021124171161\",\"1.14612803567824\",\"1\",\"1.07918124604762\",\"1.17609125905568\",\"0.845098040014257\",\"0.698970004336019\",\n         \"0.778151250383644\",\"0.301029995663981\",\"0.845098040014257\",\"1.64345267648619\",\"1.46239799789896\",\"1.34242268082221\",\"1.34242268082221\",\n         \"0.778151250383644\"))\n\nAfter, I set the factors:\n# Set factors\nstr(data)\ndata$Date<-as.factor(data$Date)\ndata$Site<-as.factor(data$Site)\ndata$Species<-as.factor(data$Species)\ndata$Mean<-as.numeric(data$Mean)\nstr(data)\n\nWhen I try t.test():\ncompare_means(Mean ~ Species, data = data, group.b = \"Date\", method = \"t.test\")\n\nThis is the error:\nError in `mutate()`:\nℹ In argument: `p = purrr::map(...)`.\nCaused by error in `purrr::map()`:\nℹ In index: 5.\nℹ With name: Date.2021.12.\nCaused by error in `t.test.default()`:\n! data are essentially constant\nRun `rlang::last_trace()` to see where the error occurred.\n\nSimilarly, when I use this in ggplot:\nggplot(data, aes(x = Date, y = Mean, fill=Species)) +\n  geom_boxplot()+\n  stat_compare_means(data=data,method=\"t.test\", label = \"p.signif\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\nWarning message:\nComputation failed in `stat_compare_means()`\nCaused by error in `mutate()`:\nℹ In argument: `p = purrr::map(...)`.\nCaused by error in `purrr::map()`:\nℹ In index: 5.\nℹ With name: x.5.\nCaused by error in `t.test.default()`:\n! data are essentially constant \n\nWhat is the best solution, which keeps the data still usable in t-test?\n",
"AnswerId": "76382881",
"AnswerBody": "Finding the sd of Mean for each Date-Species combination and then filtering out any Dates where any sd is 0 will do the trick.  You could even just pipe the filtered data to compare_means():\nlibrary(dplyr)\nlibrary(ggpubr)\ndata <- data.frame(Date = c(\"2021.08\",\"2021.08\",\"2021.09\",\"2021.09\",\"2021.09\",\"2021.10\",\"2021.10\",\"2021.10\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.12\",\"2021.12\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.09\",\"2022.09\",\"2022.10\",\"2022.10\",\"2022.10\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.12\",\"2022.12\",\"2022.12\",\"2022.12\",\"2023.01\",\"2023.01\",\"2023.01\",\"2023.01\",\"2021.08\",\"2021.08\",\"2021.09\",\"2021.09\",\"2021.09\",\"2021.10\",\"2021.10\",\"2021.10\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.11\",\"2021.12\",\"2021.12\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.01\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.08\",\"2022.09\",\"2022.09\",\"2022.09\",\"2022.09\",\"2022.10\",\"2022.10\",\"2022.10\",\"2022.10\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.11\",\"2022.12\",\"2022.12\",\"2022.12\",\"2022.12\",\"2023.01\",\"2023.01\",\"2023.01\",\"2023.01\"),\n                   Species = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                               \"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                               \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\"),\n                   Site = c(\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\"Something\",\n                            \"Something\",\"Something\",\"Something\",\"Something\"),\n                   Mean = c(\"0.301029995663981\",\"1.07918124604762\",\"0.698970004336019\",\"1.23044892137827\",\"1.53147891704226\",\"1.41497334797082\",\"1.7160033436348\",\n                            \"0.698970004336019\",\"1.39794000867204\",\"1\",\"0.301029995663981\",\"0.301029995663981\",\"0.477121254719662\",\"0.301029995663981\",\"0.301029995663981\",\n                            \"0.301029995663981\",\"0.477121254719662\",\"0.301029995663981\",\"0.301029995663981\",\"0.845098040014257\",\"0.301029995663981\",\"0.301029995663981\",\n                            \"0.477121254719662\",\"0.698970004336019\",\"1.23044892137827\",\"1.41497334797082\",\"1.95904139232109\",\"1.5910646070265\",\"1.53147891704226\",\n                            \"1.14612803567824\",\"1.57978359661681\",\"1.34242268082221\",\"0.778151250383644\",\"0.301029995663981\",\"0.301029995663981\",\"0.477121254719662\",\n                            \"0.301029995663981\",\"1.20411998265592\",\"0.845098040014257\",\"1.17609125905568\",\"1.20411998265592\",\"0.698970004336019\",\"0.301029995663981\",\n                            \"0.698970004336019\",\"0.698970004336019\",\"0.903089986991944\",\"1.14612803567824\",\"0.301029995663981\",\"0.602059991327962\",\"0.301029995663981\",\n                            \"0.845098040014257\",\"0.698970004336019\",\"0.698970004336019\",\"0.301029995663981\",\"0.698970004336019\",\"0.301029995663981\",\"0.301029995663981\",\n                            \"0.301029995663981\",\"0.477121254719662\",\"0.301029995663981\",\"0.301029995663981\",\"0.301029995663981\",\"0.301029995663981\",\"0.301029995663981\",\n                            \"0.602059991327962\",\"0.301029995663981\",\"0.845098040014257\",\"1.92941892571429\",\"1.27875360095283\",\"0.698970004336019\",\"1.38021124171161\",\n                            \"1.20411998265592\",\"1.38021124171161\",\"1.14612803567824\",\"1\",\"1.07918124604762\",\"1.17609125905568\",\"0.845098040014257\",\"0.698970004336019\",\n                            \"0.778151250383644\",\"0.301029995663981\",\"0.845098040014257\",\"1.64345267648619\",\"1.46239799789896\",\"1.34242268082221\",\"1.34242268082221\",\n                            \"0.778151250383644\"))\n\ndata$Date<-as.factor(data$Date)\ndata$Site<-as.factor(data$Site)\ndata$Species<-as.factor(data$Species)\ndata$Mean<-as.numeric(data$Mean)\n\ndata %>% \n  group_by(Date, Species) %>% \n  mutate(s = sd(Mean)) %>% \n  group_by(Date) %>%\n  filter(!any(s == 0)) %>% \n  compare_means(Mean ~ Species, data = ., group.b = \"Date\", method = \"t.test\")\n#> # A tibble: 11 × 9\n#>    Date    .y.   group1 group2      p p.adj p.format p.signif method\n#>    <fct>   <chr> <chr>  <chr>   <dbl> <dbl> <chr>    <chr>    <chr> \n#>  1 2021.08 Mean  A      B      0.718   1    0.718    ns       T-test\n#>  2 2021.09 Mean  A      B      0.451   1    0.451    ns       T-test\n#>  3 2021.10 Mean  A      B      0.0889  0.89 0.089    ns       T-test\n#>  4 2021.11 Mean  A      B      0.850   1    0.850    ns       T-test\n#>  5 2022.01 Mean  A      B      1       1    1.000    ns       T-test\n#>  6 2022.08 Mean  A      B      0.234   1    0.234    ns       T-test\n#>  7 2022.09 Mean  A      B      0.670   1    0.670    ns       T-test\n#>  8 2022.10 Mean  A      B      0.0707  0.78 0.071    ns       T-test\n#>  9 2022.11 Mean  A      B      0.783   1    0.783    ns       T-test\n#> 10 2022.12 Mean  A      B      0.399   1    0.399    ns       T-test\n#> 11 2023.01 Mean  A      B      0.255   1    0.255    ns       T-test\n\nCreated on 2023-06-01 with reprex v2.0.2\n"
},
{
"QuestionId": "76384487",
"QuestionTitle": "Trying to run simple code that writes a dataframe as a csv file using spark and Java. java.lang.NoClassDefFoundError: org/apache/spark/sql/Dataset",
"QuestionBody": "Here is my simple code:\npackage org.example;\n\nimport org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Row;\nimport org.apache.spark.sql.RowFactory;\nimport org.apache.spark.sql.SparkSession;\nimport org.apache.spark.sql.types.DataTypes;\nimport org.apache.spark.sql.types.StructField;\nimport org.apache.spark.sql.types.StructType;\n\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class Main {\n    public static void writeOutput(Dataset<Row> df, String outputPath) {\n        df.write()\n                .option(\"header\", \"true\")\n                .option(\"delimiter\", \"\\t\")\n                .csv(outputPath);\n    }\n    public static void main(String[] args) {\n\n        // Create a SparkSession\n        SparkSession spark = SparkSession.builder()\n                .appName(\"DataFrameWriter\")\n                .getOrCreate();\n\n        // Create a DataFrame (assuming df is already defined)\n        List<Row> data = Arrays.asList(\n                RowFactory.create(\"John\", 25, \"New York\"),\n                RowFactory.create(\"Alice\", 30, \"San Francisco\"),\n                RowFactory.create(\"Bob\", 35, \"Chicago\")\n        );\n\n        StructType schema = DataTypes.createStructType(new StructField[] {\n                DataTypes.createStructField(\"name\", DataTypes.StringType, true),\n                DataTypes.createStructField(\"age\", DataTypes.IntegerType, true),\n                DataTypes.createStructField(\"city\", DataTypes.StringType, true)\n        });\n\n        Dataset<Row> df = spark.createDataFrame(data, schema);\n\n        // Specify the output path\n        String outputPath = \"src/main/java/output\";\n\n        // Call the writeOutput method\n        writeOutput(df, outputPath);\n\n        // Stop the SparkSession\n        spark.stop();\n    }\n}\n\nHere is my build.gradle file:\nplugins {\n    id 'java'\n}\n\ngroup = 'org.example'\nversion = '1.0-SNAPSHOT'\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    compileOnly 'org.apache.spark:spark-sql_2.12:3.2.0'\n    implementation 'org.apache.spark:spark-core_2.12:3.2.0'\n\n\n    testImplementation platform('org.junit:junit-bom:5.9.1')\n    testImplementation 'org.junit.jupiter:junit-jupiter'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\nAnd errors:\nTask :Main.main() FAILED\nError: Unable to initialize main class org.example.Main\nCaused by: java.lang.NoClassDefFoundError: org/apache/spark/sql/Dataset\n\nFAILURE: Build failed with an exception.\n\n* What went wrong:\nExecution failed for task ':Main.main()'.\n> Process 'command '/Library/Java/JavaVirtualMachines/jdk-11.0.11.jdk/Contents/Home/bin/java'' finished with non-zero exit value 1\n\njava -version:\njava version \"11.0.19\" 2023-04-18 LTS\nJava(TM) SE Runtime Environment 18.9 (build 11.0.19+9-LTS-224)\nJava HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.19+9-LTS-224, mixed mode)\n\nscala -version:\nScala code runner version 3.3.0 -- Copyright 2002-2023, LAMP/EPFL\n\nSpark: version 3.4.0\nUsing Scala version 2.12.17 (OpenJDK 64-Bit Server VM, Java 17.0.7)\nCould you tell me what could be wrong? Pretty simple code, just can't figure out what to check. I've already tried reinstalling everything.\n",
"AnswerId": "76384848",
"AnswerBody": "Avoid using compileOnly directive for dependencies which implementation will be needed during runtime as stated on Gradle's Java library plugin user guide https://docs.gradle.org/current/userguide/java_library_plugin.html and blog https://blog.gradle.org/introducing-compile-only-dependencies\n"
},
{
"QuestionId": "76380747",
"QuestionTitle": "Give same width to items vertically positioned",
"QuestionBody": "I have two items positioned vertically, and I'd like the narrower one is as wide as the wider one.\nMy code looks like\n<div class=\"flex flex-col items-end\">\n  <div>This should take all the space</div>\n  <div class=\"flex flex-row gap-x-4\">\n    <div> this is the first element</div>\n    <div> this is the second element</div>\n  </div>\n</div>\n\nand produce\n\nHowever, I would like the result to be\n\nitems-end is needed because the items are displayed on the right side of the page.\nI have tried to mess with positioning, but I cannot achieve the final result I'm looking for.\nCan anyone give me a hand on this?\n",
"AnswerId": "76381513",
"AnswerBody": "You could shrink-wrap the container and then right align it:\n\n\n<script src=\"https://cdn.tailwindcss.com\"></script>\n\n<div class=\"flex flex-col w-max ml-auto\">\n  <div>This should take all the space</div>\n  <div class=\"flex flex-row gap-x-4\">\n    <div> this is the first element</div>\n    <div> this is the second element</div>\n  </div>\n</div>\n\n\n\nYou could also use a grid layout with one grid column track sized to max-content and then align the grid column track to the right:\n\n\n<script src=\"https://cdn.tailwindcss.com\"></script>\n\n<div class=\"grid grid-cols-[max-content] justify-end\">\n  <div>This should take all the space</div>\n  <div class=\"flex flex-row gap-x-4\">\n    <div> this is the first element</div>\n    <div> this is the second element</div>\n  </div>\n</div>\n\n\n\n"
},
{
"QuestionId": "76382807",
"QuestionTitle": "Is there a better way to publish messages using Pusher Channels' batch event?",
"QuestionBody": "I'm trying to send messages to my users from my server using Pusher Channels. My api receives a list of users and the message needs to be sent to all the users in the list. I can't group these users into a single channel and an individual channel has to be used for each user. This makes my api slow as the list of users can have a size of anything between 1 and 10000 (possibly more in the future), and pusher batch events can only accept a Event list of size 10.\n\nI'm using .net 6 for my api\n\nI've tried using batch events to try and improve performance; my code looks something like this,\nvar events = new List<Event>();\n// count can be anything between 1 and 10000\nfor (int i = 1; i <= count; i++)\n{\n    // creating a sample list of events\n    events.Add(new Event\n    {\n        Channel = string.Format(\"batch-channel-{0}\", i),\n        EventName = \"batch-event\",\n        Data = new\n        {\n            Channel = string.Format(\"batch-channel-{0}\", i),\n            Event = \"batch-event\",\n            Message = string.Format(\"{0} - sample message\", i)\n        {\n    });\n}\nvar result = new List<HttpStatusCode>();\nint chunkSize = 10;\nint totalChunks = (int)Math.Ceiling((double)events.Length / chunkSize);\nfor (int i = 0; i < totalChunks; i++)\n{\n    var eventsChunk = events.Skip(i * chunkSize).Take(chunkSize).ToArray();\n    // publishing event lists of size 10\n    var chunkResult = await pusher.TriggerAsync(eventsChunk);\n    result.Add(chunkResult.StatusCode);\n}\n\nI tested this code with a Event list of size 10000 and it takes around 6 minutes to complete execution. I want to know if there is anything I'm missing and if I can somehow improve performance.\nAny help is appreciated. Thank you.\n",
"AnswerId": "76382905",
"AnswerBody": "If you are sending the same event to multiple channels then you can use the standard trigger endpoint but specify a list of the channels that you are broadcasting to. For example:\nusing PusherServer;\n\nvar options = new PusherOptions();\noptions.Cluster = \"APP_CLUSTER\";\nvar pusher = new Pusher(\"APP_ID\", \"APP_KEY\", \"APP_SECRET\", options);\n\nITriggerResult result = await pusher.TriggerAsync(\n  new string[]{\"my-channel-1\", \"my-channel-2\", \"my-channel-3\"},\n  \"my-event\",\n  new { message: \"hello world\" });\n\nThis would trigger the event to the three specified channels. You can specify up to 100 channels in a single publish.\nIf you are sending a different event to each channel then the batch event endpoint you have mentioned would be the way forward. In this case you might look at multi-threading to or similar to be able to handle multiple batch triggers at the same time, rather than sequentially.\nSource - https://pusher.com/docs/channels/server_api/http-api/#example-publish-an-event-on-multiple-channels\n"
},
{
"QuestionId": "76384790",
"QuestionTitle": "Pandas Webscraping Errors",
"QuestionBody": "I'm currently trying to webscrape websites for tables using pandas and I get this error for one of the links.\nHere's a snippet of what causes the crash:\nimport pandas as pd\nwebsite_df = pd.read_html(\"https://ballotpedia.org/Roger_Wicker\")\nprint(website_df)\n\nBelow is the error I get, does anyone know how to fix this?\nTraceback (most recent call last):\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 700, in _next_line\n    line = self._check_comments([self.data[self.pos]])[0]\nIndexError: list index out of range\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 385, in _infer_columns\n    line = self._next_line()\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 713, in _next_line\n    raise StopIteration\nStopIteration\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\legislators-current.py\", line 15, in <module>\n    website_df = pd.read_html(\"https://ballotpedia.org/Roger_Wicker\")\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 1205, in read_html\n    return _parse(\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 1011, in _parse\n    df = _data_to_frame(data=table, **kwargs)\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 890, in _data_to_frame\n    with TextParser(body, header=header, **kwargs) as tp:\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1876, in TextParser\n    return TextFileReader(*args, **kwds)\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1753, in _make_engine\n    return mapping[engine](f, **self.options)\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 122, in __init__\n    ) = self._infer_columns()\n  File \"C:\\Users\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 395, in _infer_columns\n    raise ValueError(\nValueError: Passed header=[1,2], len of 2, but only 2 lines in file\n\n",
"AnswerId": "76384880",
"AnswerBody": "Set header=0. You're going to get a lot of dataframes, but you can parse them to get what you need.\nwebsite_df = pd.read_html(\"https://ballotpedia.org/Roger_Wicker\", header=0)\n\n"
},
{
"QuestionId": "76381459",
"QuestionTitle": "Adding tolerations to fluentbit pod and making it persistent",
"QuestionBody": "I am using fluentbit as a pod deployment where I am creating many fluentbit pods which are attached to azure blob containers. Since multiple pods exist I tried adding tolerations as I did on daemonset deployment but it did not work and failed. Also every time I delete and start the pods reinvests all the the again. Please advise on fixing these issues.\napiVersion: v1\nkind: Pod\nmetadata:\n  name: deployment \nspec:\n  volumes:\n    - name: config_map_name\n      configMap:\n        name: config_map_name\n    - name: pvc_name\n      persistentVolumeClaim:\n        claimName: pvc_name       \n  containers:\n    - name: fluentbit-logger\n      image: fluent/fluent-bit:2.1.3\n      env:\n        - name: FLUENTBIT_USER\n          valueFrom:\n            secretKeyRef:\n              name: fluentbit-secret\n              key: user\n        - name: FLUENTBIT_PWD\n          valueFrom:\n            secretKeyRef:\n              name: fluentbit-secret\n              key: pwd              \n      resources:\n        requests:\n          memory: \"32Mi\"\n          cpu: \"50m\"\n        limits:\n          memory: \"64Mi\"\n          cpu: \"100m\"\n      securityContext:\n        runAsUser: 0\n        privileged: true\n      volumeMounts:\n        - name: config_map_name\n          mountPath: \"/fluent-bit/etc\"\n        - name: pvc_name\n          mountPath: mount_path  \n      tolerations: \n      - key: \"dedicated\"\n        operator: \"Equal\"\n        value: \"sgelk\"\n        effect: \"NoSchedule\"\n\n      - key: \"dedicated\"\n        operator: \"Equal\"\n        value: \"kafka\"\n        effect: \"NoSchedule\"               \n\nGetting the error as below\nerror: error validating \"/tmp/fluentbit-deploy.yaml\": error validating data: ValidationError(Pod.spec.containers[0]): unknown field \"tolerations\" in io.k8s.api.core.v1.Container; if you choose to ignore these errors, turn validation off with --validate=false\n\n",
"AnswerId": "76381521",
"AnswerBody": "The tolerations attribute needs to be set on the pod, but you are attempting to set it on a container (that's why you see the error \"unknown field \"tolerations\" in io.k8s.api.core.v1.Container\"). You would need to write:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: deployment\nspec:\n  volumes:\n    - name: config_map_name\n      configMap:\n        name: config_map_name\n    - name: pvc_name\n      persistentVolumeClaim:\n        claimName: pvc_name\n  containers:\n    - name: fluentbit-logger\n      image: fluent/fluent-bit:2.1.3\n      env:\n        - name: FLUENTBIT_USER\n          valueFrom:\n            secretKeyRef:\n              name: fluentbit-secret\n              key: user\n        - name: FLUENTBIT_PWD\n          valueFrom:\n            secretKeyRef:\n              name: fluentbit-secret\n              key: pwd\n      resources:\n        requests:\n          memory: \"32Mi\"\n          cpu: \"50m\"\n        limits:\n          memory: \"64Mi\"\n          cpu: \"100m\"\n      securityContext:\n        runAsUser: 0\n        privileged: true\n      volumeMounts:\n        - name: config_map_name\n          mountPath: \"/fluent-bit/etc\"\n        - name: pvc_name\n          mountPath: mount_path\n  tolerations:\n  - key: \"dedicated\"\n    operator: \"Equal\"\n    value: \"sgelk\"\n    effect: \"NoSchedule\"\n\n  - key: \"dedicated\"\n    operator: \"Equal\"\n    value: \"kafka\"\n    effect: \"NoSchedule\"\n\n"
},
{
"QuestionId": "76382480",
"QuestionTitle": "Ansible - starting a task after cpu load is below 2.0",
"QuestionBody": "I am trying to create a playbook where I want to perform a simple debug task after cpu load is below 2.0.\nI have this so far in cpu-load.yml:\n---\n- name: Check CPU load and wait\n  hosts: localhost\n  gather_facts: yes\n  \n  tasks:\n    - name: Check cpu load\n      shell: uptime | awk -F 'load average:' '{print $2}' | awk -F ', ' '{print $1}'\n      register: cpu_load\n      \n    - name: Wait until cpu load is bellow 2.0\n      wait_for:\n        timeout: 300\n        delay: 10\n        shell: Do something here\n        msg: \"cpu load is bellow 2.0\"\n      \n    - name: Continue jobs\n      debug:\n        msg: \"CPU load is bellow 2.0. Continue!!!\"\n\nNow I am not sure how to make the task wait for the cpu load to go bellow 2.0. Can you guys help?\n",
"AnswerId": "76382917",
"AnswerBody": "You need to put an until loop around your \"check cpu load\" task:\n- hosts: localhost\n  gather_facts: false\n  tasks:\n    - name: Check cpu load\n      shell: uptime | awk -F 'load average:' '{print $2}' | awk -F ', ' '{print $1}'\n      register: cpu_load\n      until: cpu_load.stdout|float < 2.0\n      retries: 300\n      delay: 1\n\n    - name: Some other task\n      debug:\n        msg: hello world\n\nThis will wait up to five minutes (300 retries with a 1-second delay) for the load average to drop below 2.0.\n\nThere are probably better ways to get the current 1-minute CPU load; reading from /proc/loadavg may be easiest:\n- hosts: localhost\n  gather_facts: false\n  tasks:\n    - name: Check cpu load\n      command: cat /proc/loadavg\n      register: cpu_load\n      until: cpu_load.stdout.split()|first|float < 2.0\n      retries: 300\n      delay: 1\n\n    - name: Some other task\n      debug:\n        msg: hello world\n\n"
},
{
"QuestionId": "76382514",
"QuestionTitle": "How can I use Webpack to load a separate JS file in Shopware 6 and improve web performance?",
"QuestionBody": "How to load a separate JS file in Shopware 6 using webpack?\nWhat?\nI'm trying to load a separate javascript file next to the all.js file by using WebPack.\nWhy?\nThe all.js file can get really big and you're loading unnecessary javascript on a page. So by using code splitting (which should be possible since WebPack is implemented in Shopware 6) and dynamic imports you could stop loading unnecessary javascript.\nWhat I've tried\nI've added a webpack.config.js file inside the root of my theme plugin like so:\nmodule.exports = {\n\n    entry: {\n        main: './src/main.js', \n        separateFile: './src/js/separate.js'\n    },\n\n    output: {\n        filename: '[name].js'\n    },\n\n    optimization: {\n        splitChunks: {\n            chunks: 'all',\n        },\n    },\n};\n\nAfter running bin/build-storefront.sh there is no separate JS file added in the public folder.\nI'm also trying to dynamically load this JS file in src/Resources/app/storefront/src/main.js but this results in a 404 since the separate file doesn't exist.\n",
"AnswerId": "76382923",
"AnswerBody": "This will not work since all pre-compiled assets of plugins are collected in the ThemeCompiler and concatenated into one single script. This is done  in PHP since node is not a requirement for production environments.\nYou could try to add separate scripts as additional custom assets, but you would still have to extend the template to add the corresponding script tags manually.\n"
},
{
"QuestionId": "76384679",
"QuestionTitle": "Chunked xarray: load only 1 cell in memory efficiently",
"QuestionBody": "Context:\nI have a datacube with 3 variables (3D arrays, dims:time,y,x). The datacube is too big to fit in memory so I chunk it with xarray/dask. I want to apply a function to every cell in x,y of every variable in my datacube.\nProblem:\nMy method takes a long time to load only one cell (1 minute) and I have to do that 112200 times. I use a for loop with dataset.variable.isel(x=i, y=j).values to load a single 1D array from my variables. Is there a better way to do that ? Also, knowing my dataset is chunked, is there a way to do that in parallel for all the chunks at once ?\nCode example:\n# Setup\nimport xarray as xr\nimport numpy as np\n\n# Create the dimensions\nx = np.linspace(0, 99, 100)\ny = np.linspace(0, 349, 350)\ntime = np.linspace(0, 299, 300)\n\n# Create the dataset\nxrds= xr.Dataset()\n\n# Add the dimensions to the dataset\nxrds['time'] = time\nxrds['y'] = y\nxrds['x'] = x\n\n\n\n# Create the random data variables with chunking\nchunksize = (10, 100, 100)  # Chunk size for the variables\ndata_var1 = np.random.rand(len(time), len(y), len(x))\ndata_var2 = np.random.rand(len(time), len(y), len(x))\ndata_var3 = np.random.rand(len(time), len(y), len(x))\n\nxrds['data_var1'] = (('time', 'y', 'x'), data_var1, {'chunks': chunksize})\nxrds['data_var2'] = (('time', 'y', 'x'), data_var2, {'chunks': chunksize})\nxrds['data_var3'] = (('time', 'y', 'x'), data_var3, {'chunks': chunksize})\n\n#### ---- My Attempt ---- ####\n\n# Iterate through all the variables in my dataset\nfor var_name, var_data in xrds.data_vars.items():\n\n    # if variable is 3D\n    if var_data.shape == (xrds.dims['time'], xrds.dims['y'], xrds.dims['x']):\n\n        # Iterate through every cell of the variable along the x and y axis only\n        for i in range(xrds.dims['y']):\n            for j in range(xrds.dims['x']):\n\n                # Load a single 1D cell into memory (len(cell) = len(time))\n                print(xrds.v.isel(y=i,x=j).values)\n\n",
"AnswerId": "76384898",
"AnswerBody": "I find that explicitly iterating over the xarray is faster than isel(), by about 10%.\nExample:\n    for var_name, var_data in xrds.data_vars.items():\n\n        # if variable is 3D\n        if var_data.shape == (xrds.dims['time'], xrds.dims['y'], xrds.dims['x']):\n\n            # Iterate through every cell of the variable along the x and y axis only\n            for i_array in xrds['data_var1'].transpose('x', 'y', 'time'):\n                x_coordinate = i_array.x.item()\n                for cell in i_array.transpose('y', 'time'):\n                    y_coordinate = cell.y.item()\n                    # Do something with cell\n\nThis takes 17.38s, versus 20.47s for the original.\nPS: The line chunksize = (10, 100, 100) seems very suspicious to me. It seems like if you want to load an array corresponding to the entire time axis at once, the chunks should be set so that this doesn't require looking at multiple chunks. It seems like chunksize = (len(time), 100, 100) would be more efficient. However, I benchmarked this both ways and it doesn't make a difference for this data size. May make a difference on your larger problem.\n"
},
{
"QuestionId": "76381460",
"QuestionTitle": "How to change colors when using scale_fill_discrete in R?",
"QuestionBody": "I have the data below:\ntime=c(200,218,237,237,237,237,237,246,246,246,257,257,257,272,272,272,294,294,294)\nlocation=c(\"A\",\"A\",\"D\",\"C\",\"A\",\"B\",\"B\",\"D\",\"C\",\"B\",\"D\",\"C\",\"B\",\"D\",\"C\",\"B\",\"D\",\"C\",\"B\")\nvalue=c(0,774,0,0,2178,0,2178,0,1494,2644,1326,1504,4188,3558,1385,5013,12860,829,3483)\ndataA=data.frame(time,location,value)\n\nand I made a graph.\nggplot(data=dataA, aes(x=time, y=value))+\n  geom_area(aes(group=location, fill=location), position=\"stack\", linetype=1, size=0.5 ,colour=\"black\") +\n  scale_fill_discrete(breaks=c(\"A\",\"B\",\"C\",\"D\"), labels=c(\"Main_town\",\"B\",\"C\",\"D\"))+\n  theme_classic(base_size=18, base_family=\"serif\")+\n  theme(legend.position=\"right\",\n        axis.line=element_line(linewidth=0.5, colour=\"black\"))+\nwindows(width=5.5, height=5)\n\nI changed one of the legend label from A to main_town using scale_fill_discrete(). Then color is automatically generated.\n\nI want to change this color according to my preference. When I add a code, scale_fill_manual(values=c(\"darkblue\",\"darkred\",\"khaki4\",\"darkgreen\"))+ the below message shows up and the graph is before I changed legend label.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\nHow can I change colors when using scale_fill_discrete()? I want to change colors to \"darkblue\",\"darkred\",\"khaki4\",\"darkgreen\"\nCould you please let me know how to do that? Or do you let me know simply how to change legend labels maintaining colors I want?\nAlways many thanks!!!\n",
"AnswerId": "76381528",
"AnswerBody": "I think you need scale_fill_discrete(type = c(...)).\nlibrary(ggplot2)\n\nggplot(data=dataA, aes(x=time, y=value))+\n  geom_area(aes(group=location, fill=location), position=\"stack\", linetype=1, size=0.5 ,colour=\"black\") +\n  scale_fill_discrete(breaks=c(\"A\",\"B\",\"C\",\"D\"), labels=c(\"Main_town\",\"B\",\"C\",\"D\"),\n                      type=c(\"darkblue\",\"darkred\",\"khaki4\",\"darkgreen\"))+\n  theme_classic(base_size=18, base_family=\"serif\")+\n  theme(legend.position=\"right\",\n        axis.line=element_line(linewidth=0.5, colour=\"black\"))\n\n\n"
},
{
"QuestionId": "76381485",
"QuestionTitle": "C# IQueryable .Union reset sorting",
"QuestionBody": "I have the following code:\nvar expressions = new List<IQueryable<Container>>();\n\nvar containers1 = containers\n    .Where(x => EF.Functions.Like(x.ContainerReference1, $\"%{message.SearchValue}%\")\n             || EF.Functions.Like(x.ContainerReference2, $\"%{message.SearchValue}%\"))\n    .OrderBy(x => x.ContainerReference1)\n    .ThenBy(x => x.ContainerReference2)\n    .ThenByDescending(x => x.DateUpdated);\nexpressions.Add(containers1);\n\nvar containers2 = containers\n                  .Where(x => EF.Functions.Like(x.Description, $\"%{message.SearchValue}%\"))\n                  .OrderBy(x => x.Description)\n                  .ThenByDescending(x => x.DateUpdated);\nexpressions.Add(containers2);\n\nvar containers3 = containers.Where(x => x.ContactEmails\n                            .OrderBy(y => y.Email)\n                            .ThenBy(y => y.DisplayName)\n                            .Any(y => EF.Functions.Like(y.Email, $\"%{message.SearchValue}%\")\n                                 || EF.Functions.Like(y.DisplayName, $\"%{message.SearchValue}%\")))\n                            .OrderByDescending(x => x.DateUpdated);\nexpressions.Add(containers3);\n\nvar containers4 = containers\n                            .Where(x => EF.Functions.Like(x.Keywords, $\"%{message.SearchValue}%\"))\n                            .OrderBy(x => x.Keywords)\n                            .ThenByDescending(x => x.DateUpdated);\nexpressions.Add(containers4);\n\ncontainers = expressions.Aggregate((acc, i) => acc.Union(i));\n\nBut after .Union operation sorting is reset.\nHow can I prevent resetting of sorting?\n",
"AnswerId": "76381539",
"AnswerBody": "Union operator does not preserve the order of the elements. You need to dynamically construct the sorting logic based on the presence of data\nvar expressions = new List<IQueryable<Container>>();\nvar sortingExpressions = new List<Func<IQueryable<Container>, IOrderedQueryable<Container>>>();\n\nvar containers1 = containers\n        .Where(x => EF.Functions.Like(x.ContainerReference1, $\"%{message.SearchValue}%\")\n                || EF.Functions.Like(x.ContainerReference2, $\"%{message.SearchValue}%\"));\nif (containers1.Any())\n{\n    var containers1Sorting = new Func<IQueryable<Container>, IOrderedQueryable<Container>>(x => x\n        .OrderBy(y => y.ContainerReference1)\n        .ThenBy(y => y.ContainerReference2)\n        .ThenByDescending(y => y.DateUpdated));\n\n    expressions.Add(containers1);\n    sortingExpressions.Add(containers1Sorting);\n}\n\nvar containers2 = containers\n          .Where(x => EF.Functions.Like(x.Description, $\"%{message.SearchValue}%\"));\nif (containers2.Any())\n{\n    var containers2Sorting = new Func<IQueryable<Container>, IOrderedQueryable<Container>>(x => x\n        .OrderBy(y => y.Description)\n        .ThenByDescending(y => y.DateUpdated));\n\n    expressions.Add(containers2);\n    sortingExpressions.Add(containers2Sorting);\n}\n\nvar containers3 = containers\n        .Where(x => x.ContactEmails\n            .Any(y => EF.Functions.Like(y.Email, $\"%{message.SearchValue}%\")\n                || EF.Functions.Like(y.DisplayName, $\"%{message.SearchValue}%\")));\nif (containers3.Any())\n{\n    var containers3Sorting = new Func<IQueryable<Container>, IOrderedQueryable<Container>>(x => x\n        .OrderBy(y => y.ContactEmails.OrderBy(z => z.Email).ThenBy(z => z.DisplayName))\n        .OrderByDescending(x => x.DateUpdated));\n\n    expressions.Add(containers3);\n    sortingExpressions.Add(containers3Sorting);\n}\n\nvar containers4 = containers\n      .Where(x => EF.Functions.Like(x.Keywords, $\"%{message.SearchValue}%\"));\nif (containers4.Any())\n{\n    var containers4Sorting = new Func<IQueryable<Container>, IOrderedQueryable<Container>>(x => x\n        .OrderBy(y => y.Keywords)\n        .ThenByDescending(y => y.DateUpdated));\n\n    expressions.Add(containers4);\n    sortingExpressions.Add(containers4Sorting);\n}\n\nvar mergedContainers = expressions.Aggregate((acc, i) => acc.Union(i));\n\nif (sortingExpressions.Any())\n{\n    var mergedSorting = sortingExpressions\n        .Aggregate((acc, next) => q => next(acc(q)));\n\n    containers = mergedSorting(mergedContainers);\n}\nelse\n{\n    containers = mergedContainers.OrderByDescending(x => x.DateUpdated);\n}\n\n"
},
{
"QuestionId": "76381526",
"QuestionTitle": "How can I use Python to increment 'tokenId' values in a .json file?",
"QuestionBody": "I have a .json file but I got the tokenId numbering wrong. I need to increase all values of \"tokenId\" by 1 number\n[\n    {\n        \"Background\": \"Red\",\n        \"Body\": \"Tunn\",\n        \"Hat\": \"Bambu\",\n        \"Outfit\": \"Pirate\",\n        \"Expression\": \"Sad\",\n        \"Accessory\": \"Rifle\",\n        \"tokenId\": 0\n    },\n    {\n        \"Background\": \"Lilac\",\n        \"Body\": \"Tunn\",\n        \"Hat\": \"Bicorn\",\n        \"Outfit\": \"Pirate\",\n        \"Expression\": \"Angry\",\n        \"Accessory\": \"Balloons\",\n        \"tokenId\": 1\n    },\n\n          ...\n    \n    {\n        \"Background\": \"Green\",\n        \"Body\": \"Tunn\",\n        \"Hat\": \"Bicorn\",\n        \"Outfit\": \"Pirate\",\n        \"Expression\": \"Sad\",\n        \"Accessory\": \"Balloons\",\n        \"tokenId\": 3000\n    },\n\n\nis it possible to do this with python? i created this .json file with python.\nI tried this code, but I get an error\nimport json\n\nwith open('traits.json') as f:\n    data = json.load(f)\n\nfor item in data['tokenId']:\n    item['tokenId'] = item['tokenId'].replace([int('+1')])\n\nwith open('new_data.json', 'w') as f:\n    json.dump(data, f)\n\nTypeError: list indices must be integers or slices, not str\n\nThank you!\n",
"AnswerId": "76381562",
"AnswerBody": "To increase the values of the \"tokenId\" field in your JSON file by 1, you can modify your code as follows:\nimport json\n\nwith open('traits.json') as f:\n    data = json.load(f)\n\nfor item in data:\n    item['tokenId'] += 1\n\nwith open('new_data.json', 'w') as f:\n    json.dump(data, f)\n\nIn your original code, you were trying to access data['tokenId'] as if it was a list, but it is actually a dictionary. Instead, you need to iterate over the list data and update the \"tokenId\" field of each item. By using item['tokenId'] += 1, you increment the value of \"tokenId\" by 1.\nFinally, the modified data is saved to a new JSON file named \"new_data.json\" using json.dump(data, f).\nAfter running this code, the \"new_data.json\" file will contain the updated \"tokenId\" values with an increment of 1.\n"
},
{
"QuestionId": "76382811",
"QuestionTitle": "Update input values into elements only JS",
"QuestionBody": "I have created an index file so that the information entered here is added to the created element\nthis is for a review section\nthe index.html file is here, and includes the CSS and js\n\n\n    let name = document.querySelector('.name').value;\n    let message = document.querySelector('.message').value;\n    let btn = document.getElementById('button');\n    let div = document.querySelector('.items')\n\n    btn.addEventListener('click', ()=>{\n        let item = document.createElement('div')\n        let inner = `\n                <h3>${name}</h3>\n                <p>${message}</p>\n                `\n        item.className = \"message-item\"        \n        item.innerHTML = inner        \n        div.append(item)\n    });\n html, body{\n            padding: 0;\n            margin: 0;\n        }\n        .msg{\n            padding: 2em;\n            margin: 2em;\n            border-radius: 2vh;\n            height: 70vh;\n            display: flex;\n            align-items: center;\n            justify-content: left;\n            flex-direction: column;\n            background-color: #1e90ff;\n        }\n        .items{\n            height: 65vh;\n            overflow: scroll;\n            color: white;\n            width: 100%;\n            overflow-x: hidden;\n            margin: 10px;\n        }\n        input{\n            padding: 10px;\n            border: none;\n            border-radius: 8px;\n            outline: none;\n            font-size: 1em;\n        }\n        #button{\n            padding: 10px 20px;\n            border-radius: 8px;\n            border: none;\n            font-size: 1em;\n        }\n        .button{\n            padding: 10px 20px;\n            border-radius: 8px;\n            border: none;\n            font-size: 1em;\n        }\n        .message-item{\n            background-color: black;\n            padding: 1em;\n            border-radius: 8px;\n            margin: 3px;\n        }\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title></title>\n\n</head>\n<body>\n    <div class=\"msg\">\n        <div class=\"items\"></div>\n        <div class=\"input\">\n                <input type=\"text\" class=\"name\" placeholder=\"Name\">\n                <input type=\"text\" class=\"message\" placeholder=\"Message\">\n                <button id=\"button\">Submit</button>\n                <button type=\"reset\">Reset</button>\n        </div>\n    </div>\n</body>\n\n</html>\n\n\n\nSo I am expecting it to append the elements which have different values\nexample once i enter the **name **\"harry\" and **message **as \"this is the message\"\nand then i reset and enter another **name **and **message **then the newly created element should display the newly entered **name **and message\n",
"AnswerId": "76382942",
"AnswerBody": "Your name variable should be a pointer to the element, not the value.\nAlso, you should clear the input after adding.\n\n\nconst\n  name = document.querySelector('.name'),\n  message = document.querySelector('.message'),\n  btn = document.getElementById('button'),\n  div = document.querySelector('.items');\n\nconst handleAdd = (e) => {\n  div.insertAdjacentHTML('beforeend', `\n    <div class=\"message-item\">\n      <h3>${name.value}</h3>\n      <p>${message.value}</p>\n    </div>\n  `);\n  name.value = '';    // Clear name\n  message.value = ''; // Clear message\n};\n\nbtn.addEventListener('click', handleAdd);\nhtml,\nbody {\n  padding: 0;\n  margin: 0;\n}\n\n.msg {\n  padding: 2em;\n  margin: 2em;\n  border-radius: 2vh;\n  height: 70vh;\n  display: flex;\n  align-items: center;\n  justify-content: left;\n  flex-direction: column;\n  background-color: #1e90ff;\n}\n\n.items {\n  height: 65vh;\n  overflow: scroll;\n  color: white;\n  width: 100%;\n  overflow-x: hidden;\n  margin: 10px;\n}\n\ninput {\n  padding: 10px;\n  border: none;\n  border-radius: 8px;\n  outline: none;\n  font-size: 1em;\n}\n\n#button {\n  padding: 10px 20px;\n  border-radius: 8px;\n  border: none;\n  font-size: 1em;\n}\n\n.button {\n  padding: 10px 20px;\n  border-radius: 8px;\n  border: none;\n  font-size: 1em;\n}\n\n.message-item {\n  background-color: black;\n  padding: 1em;\n  border-radius: 8px;\n  margin: 3px;\n}\n<div class=\"msg\">\n  <div class=\"items\"></div>\n  <div class=\"input\">\n    <input type=\"text\" class=\"name\" placeholder=\"Name\">\n    <input type=\"text\" class=\"message\" placeholder=\"Message\">\n    <button id=\"button\">Submit</button>\n    <button type=\"reset\">Reset</button>\n  </div>\n</div>\n\n\n\nA better approach\nA better example would be to use a form. This way you can take advantage of built-in form validation, submission, and resetting.\nFor example, you can call elements by their name and you have the added bonus of Enter key support.\n\nEnter a name\nPress Tab\nEnter a message\nPress Enter\n\nThe item is added\nThe form is cleared\nFocus is sent to the name\n\n\n\n\n\nconst handleAdd = (e) => {\n  e.preventDefault(); // Prevent page from navigating\n  const\n    form = e.target,\n    formElements = form.elements,\n    parent = form.closest('.msg'),\n    items = parent.querySelector('.items');\n  items.insertAdjacentHTML('beforeend', `\n    <div class=\"message-item\">\n      <h3>${formElements.name.value}</h3>\n      <p>${formElements.message.value}</p>\n    </div>\n  `);\n  formElements.name.value = '';    // Clear name\n  formElements.message.value = ''; // Clear message\n  formElements.name.focus();\n};\n\ndocument.forms.namedItem('new-msg')\n  .addEventListener('submit', handleAdd);\nhtml,\nbody {\n  padding: 0;\n  margin: 0;\n}\n\n.msg {\n  padding: 2em;\n  margin: 2em;\n  border-radius: 2vh;\n  height: 70vh;\n  display: flex;\n  align-items: center;\n  justify-content: left;\n  flex-direction: column;\n  background-color: #1e90ff;\n}\n\n.items {\n  height: 65vh;\n  overflow: scroll;\n  color: white;\n  width: 100%;\n  overflow-x: hidden;\n  margin: 10px;\n}\n\ninput {\n  padding: 10px;\n  border: none;\n  border-radius: 8px;\n  outline: none;\n  font-size: 1em;\n}\n\n.form-btn {\n  padding: 10px 20px;\n  border-radius: 8px;\n  border: none;\n  font-size: 1em;\n}\n\n.message-item {\n  background-color: black;\n  padding: 1em;\n  border-radius: 8px;\n  margin: 3px;\n}\n<div class=\"msg\">\n  <div class=\"items\"></div>\n  <form id=\"new-msg\" autocomplete=\"off\">\n    <input type=\"text\" name=\"name\" placeholder=\"Name\" required>\n    <input type=\"text\" name=\"message\" placeholder=\"Message\">\n    <button type=\"submit\" class=\"form-btn\">Submit</button>\n    <button type=\"reset\" class=\"form-btn\">Reset</button>\n  </form>\n</div>\n\n\n\n\nLocalStorage\nHere is an example of local storage. The main idea here is how to store and restore the state of the messages.\nconst MESSAGES_KEY = \"messages\";\n\nconst main = () => {\n  // Restore all messages\n  const messageContainer = document.querySelector(\".items\");\n  __retrieveAllMessages().forEach((message) => {\n    insertMessage(message, messageContainer);\n  });\n  // Add event listener\n  document.forms.namedItem(\"new-msg\").addEventListener(\"submit\", handleAdd);\n};\n\nconst saveMessage = (message) => {\n  __saveAllMessages(__retrieveAllMessages().concat(message));\n};\n\nconst insertMessage = (message, container) => {\n  container.insertAdjacentHTML(\"beforeend\", messageToHtml(message));\n};\n\nconst messageToHtml = ({ name, message }) => `\n  <div class=\"message-item\">\n    <h3>${name}</h3>\n    <p>${message}</p>\n  </div>\n`;\n\nconst handleAdd = (e) => {\n  e.preventDefault(); // Prevent page from navigating\n  const form = e.target,\n    message = {\n      name: form.elements.name.value,\n      message: form.elements.message.value,\n    };\n  saveMessage(message);\n  insertMessage(message, form.closest(\".msg\").querySelector(\".items\"));\n  form.elements.name.value = \"\"; // Clear name\n  form.elements.message.value = \"\"; // Clear message\n  form.elements.name.focus();\n};\n\nconst __retrieveAllMessages = () => {\n  return JSON.parse(localStorage.getItem(MESSAGES_KEY) ?? \"[]\");\n};\n\nconst __saveAllMessages = (messages = []) => {\n  return localStorage.setItem(MESSAGES_KEY, JSON.stringify(messages));\n};\n\nmain();\n\n"
},
{
"QuestionId": "76381469",
"QuestionTitle": "How to extract data from xml in NodeJS?",
"QuestionBody": "I have the following xml:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n    <wfs:FeatureCollection xmlns:wfs=\"http://www.opengis.net/wfs/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.opengis.net/wfs/2.0 http://www.wfs.nrw.de/aaa-suite/schema/ogc/wfs/2.0/wfs.xsd\" timeStamp=\"2023-06-01T13:31:53.444+02:00\" numberReturned=\"0\" numberMatched=\"9359426\"/>\n\nHow can I extract the value of numberMatched using an xml parser like fast-xml-parser in NodeJS?\n",
"AnswerId": "76381565",
"AnswerBody": "You need to set ignoreAttributes option to false\nimport { XMLParser } from \"fast-xml-parser\";\n\nconst XMLdata = `<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<wfs:FeatureCollection xmlns:wfs=\"http://www.opengis.net/wfs/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.opengis.net/wfs/2.0 http://www.wfs.nrw.de/aaa-suite/schema/ogc/wfs/2.0/wfs.xsd\" timeStamp=\"2023-06-01T13:31:53.444+02:00\" numberReturned=\"0\" numberMatched=\"9359426\"/>`;\n\nconst parser = new XMLParser({\n  ignoreAttributes: false,\n  attributeNamePrefix: \"\"\n});\nlet jObj = parser.parse(XMLdata);\n\nconsole.log(jObj[\"wfs:FeatureCollection\"].numberMatched);\n\n\n"
},
{
"QuestionId": "76384843",
"QuestionTitle": "How can I update my UI after a coroutine is completed in Kotlin for Android?",
"QuestionBody": "I use Retrofit and Coroutines to fetch a list of languages from an API. My ViewModel loads the list of languages whenever it is created. I want to load this list into a spinner, but whenever I update the spinner data, the data in the ViewModel hasn't completely loaded.\nHere my viewmodel class to load data from an api\nclass TranslateViewModel : ViewModel() {\n    var langToCode = HashMap<String, String>()\n    var codeToLang = HashMap<String, String>()\n    private val translateRepository = TranslateRepository()\n\n    init {\n        viewModelScope.launch {\n            val langList = try {\n                translateRepository.getLangList()\n            } catch (e: IOException) {\n                Log.e(TAG, \"IOException\", e)\n                return@launch\n            } catch (e: HttpException) {\n                Log.e(TAG, \"HTTPException\", e)\n                return@launch\n            }\n            if (langList.isSuccessful && langList.body() != null) {\n                codeToLang = langList.body()!!.langList\n                langToCode = codeToLang.map { (key, value) ->\n                    value to key\n                }.toMap() as HashMap<String, String>\n            } else {\n                Log.d(TAG, \"Get lang list failure\")\n            }\n        }\n    }\n}\n\nI want to load my list of languages into my spinner but my viewmodel is taking too long to load the data, so the langList variable is alway empty.\noverride fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        super.onViewCreated(view, savedInstanceState)\n\n        viewBinding.apply {\n            sourceLanguage.apply {\n                val langList = viewModel.langToCode.keys.toList()\n                val arrayAdapter = ArrayAdapter (\n                    context,\n                    android.R.layout.simple_spinner_item,\n                    langList\n                ).also { it.setDropDownViewResource(\n                     android.R.layout.simple_spinner_dropdown_item\n                )\n                }\n                this.adapter = arrayAdapter\n        }\n}\n\nI want to know how to update my UI immediately after my coroutine has finished loading data. I appreciate all of your help, and please forgive me for my poor English skills.\n",
"AnswerId": "76384912",
"AnswerBody": "In Your case update your viewmodel as below-\nclass TranslateViewModel : ViewModel() {\n    private val _langList = MutableLiveData<List<String>>()\n    val langList: LiveData<List<String>> get() = _langList\n    \n    init {\n        viewModelScope.launch {\n            if (langList.isSuccessful && langList.body() != null) {\n                codeToLang = langList.body()!!.langList\n                langToCode = codeToLang.map { (key, value) ->\n                    value to key\n                }.toMap() as HashMap<String, String>\n                _langList.value = langToCode.keys.toList() // Update the LiveData value\n            } else {\n                Log.d(TAG, \"Get lang list failure\")\n            }\n        }\n    }\n}\n\nIn your UI code to observe the LiveData and update the spinner as below-\nviewModel.langList.observe(viewLifecycleOwner, { langList ->\n            val arrayAdapter = ArrayAdapter(\n                context,\n                android.R.layout.simple_spinner_item,\n                langList\n            ).also { it.setDropDownViewResource(\n                 android.R.layout.simple_spinner_dropdown_item\n            )\n            }\n            sourceLanguage.adapter = arrayAdapter\n        })\n\nFollow this link for more detail - https://developer.android.com/topic/libraries/architecture/livedata\n"
},
{
"QuestionId": "76382497",
"QuestionTitle": "How to make a forever loop in JS not freeze",
"QuestionBody": "I'm working on a block based programming language based of of Google's Blockly. I need to make a block that loops the contents forever, for making games.\nI tried a while (true) loop but it froze. Is there any way to make a forever loop that won't freeze and will let other scripts run?\nThanks!\n",
"AnswerId": "76382988",
"AnswerBody": "check setTimeout() : https://developer.mozilla.org/en-US/docs/Web/API/setTimeout\nSomething like that to loop indefinitely without blocking the main thread (you should probably design a way to break the loop at some point) :\nfunction doSomeStuff() {\n  // do some stuff…\n  setTimeout(() => {\n    doSomeStuff();\n  }, 1000);\n}\n\n"
},
{
"QuestionId": "76384804",
"QuestionTitle": "What is the correct syntax to classify ages into groups using IF statements in Google Sheets?",
"QuestionBody": "[Why am i getting \"formula parse error\" when I try to classify the ages (column H) into groups using the following formula? And is there a better way? Thanks for your assistance:\n=IF (H19<20, “0-19”, IF ((H19>=20 AND H19<40), “20-39”, IF ((H19>=40 AND H19<60), “40-59”, IF ((H19>=60 AND H19<70), “60-69”, IF (H19>=70, \">= 70\", “WRONG”)))))\nI was expecting to output the Age column into strings based on my category definitions.\n",
"AnswerId": "76384938",
"AnswerBody": "The portions that you have formatted as (H19>=20 AND H19<40) should be changed to AND(H19>=20, H19<40). Your final formula should then be:\n=IF(H19<20, “0-19”,\n  IF(AND(H19>=20, H19<40), “20-39”,\n  IF(AND(H19>=40, H19<60), “40-59”,\n  IF(AND(H19>=60, H19<70), “60-69”,\n  IF(H19>=70, \">= 70\", “WRONG”)))))\n\nAlternatively:\n=IFS(OR(NOT(ISNUMBER(H19)),H19<0), \"WRONG\",\n  H19<20, \"0-19\",\n  AND(H19>=20, H19<40), \"20-39\",\n  AND(H19>=40, H19<60), \"40-59\",\n  AND(H19>=60, H19<70), \"60-69\",\n  H19>=70, \">= 70\")\n\n"
},
{
"QuestionId": "76381508",
"QuestionTitle": "Masking a pandas column based on another column with slightly different values",
"QuestionBody": "So what I have is two Pandas dataframes in Python with a large number of xyz-coordinates. One of them will be used to mask/remove some coordinates in the other one, but the problem is that the coordinates are very slightly different so that I cannot simply remove duplicates. As an example, let's say they look like this:\ndf1 = pd.DataFrame(data=None, columns=['x', 'y', 'z'])\ndf1.x = [104245, 252355, 547364, 135152]\ndf1.y = [842714, 135812, 425328, 124912]\ndf1.z = [125125, 547574, 364343, 346372]\n\ndf2 = pd.DataFrame(data=None, columns=['x', 'y', 'z'])\ndf2.x = [104230, 547298]\ndf2.y = [842498, 424989]\ndf2.z = [124976, 364001]\n\nWhat I then want is for the first and second xyz-rows in df2 to remove the first and third row in df1. My idea was to create new columns with rounded values, compare those, and remove based on those. It would look something like this:\ndf1['id'] = np.linspace(0,len(df1)-1,len(df1))\ndf2['id'] = np.linspace(0,len(df2)-1,len(df2))\n\ndf3 = df1.round({'x': -3, 'y': -3, 'z': -3})\ndf4 = df2.round({'x': -3, 'y': -3, 'z': -3})\n\ndf5 = df3.merge(df4, on=['x', 'y', 'z'], how='inner')\ndf6 = df1[~df1.index.isin(df5.id_x)]\n\nThis works fine to remove some of the values, but often they round to different places. I was hoping with help if there is a better method to mask those values which are simply closest in all three coordinates. Maybe that it finds the closest xyz-pair between df1 and df2 and masks those pairs. If anyone has any ideas I would really appreciate it!\n",
"AnswerId": "76381592",
"AnswerBody": "You can use numpy broadcasting to consider the individual distances between the coordinates:\n# convert DataFrames to numpy arrays\na1 = df1.to_numpy()\na2 = df2.to_numpy()\n\n# define a distance below which the coordinates are considered equal\nthresh = 500\n\n# compute the distances, identify matches on all coordinates\nmatches = (abs(a1[:,None]-a2) <= thresh).all(axis=-1)\n\nidx1, idx2 = np.where(matches)\n# (array([0, 2]), array([0, 1]))\n\nout = df1.drop(df1.index[idx1])\n\nTo consider the euclidean distance between the points (taking into account all coordinates simultaneously), use scipy.spatial.distance.cdist:\nfrom scipy.spatial.distance import cdist\n\nthresh = 1000\n\nmatches = cdist(a1, a2) <= thresh\n\nidx1, idx2 = np.where(matches)\n\nout = df1.drop(df1.index[idx1])\n\nOutput:\n        x       y       z\n1  252355  135812  547574\n3  135152  124912  346372\n\nremoving the single point from df1 that is closest to each row of df2 and below a threshold\nfrom scipy.spatial.distance import cdist\n\nthresh = 1000\n\ndist = cdist(a1, a2)\n\nidx = np.argmin(dist, axis=0)\n\nout = df1.drop(df1.index[idx[dist[idx, np.arange(len(a2))] <= thresh]])\n\nIf the distance doesn't matter and you only want to remove the closest point:\nfrom scipy.spatial.distance import cdist\n\ndist = cdist(a1, a2)\n\nidx = np.argmin(dist, axis=0)\n\nout = df1.drop(df1.index[idx])\n\n"
},
{
"QuestionId": "76382887",
"QuestionTitle": "How to fix the line ending style (either CRLF or LF) in Python when written a text file?",
"QuestionBody": "I have the following little program in Python\nfrom pathlib import Path\nfilename = Path(\"file.txt\")\ncontent = \"line1\\nline2\\nline3\\n\"\nwith filename.open(\"w+\", encoding=\"utf-8\") as file:\n    file.write(content)\n\nAfter running it I get the following file (as expected)\nline1\nline2\nline3\n\nHowever, depending on where the program runs, line ending is different.\nIf I run it in Windows, I get CRLF line termination:\n$ file -k file.txt\nfile.txt: ASCII text, with CRLF line terminators\n\nIf I run it in Linux, I get LF line termination:\n$ file -k file.txt \nfile.txt: ASCII text\n\nSo, I understand that Python is using the default from the system in which it runs, which is fine most of the times. However, in my case I'd like to fix the line ending style, no matter the system where I run the program.\nHow this could be done?\n",
"AnswerId": "76382994",
"AnswerBody": "It is possible to explicitly specify the string used for newlines using the newline parameter. It works the same with open() and pathlib.Path.open().\nThe snippet below will always use Linux line endings \\n:\nfrom pathlib import Path\nfilename = Path(\"file.txt\")\ncontent = \"line1\\nline2\\nline3\\n\"\nwith filename.open(\"w+\", encoding=\"utf-8\", newline='\\n') as file:\n    file.write(content)\n\nSetting newline='\\r\\n' will give Windows line endings and not setting it or setting newline=None (the default) will use the OS default.\n"
},
{
"QuestionId": "76382888",
"QuestionTitle": "Partially flatten nested JSON and pivot longer",
"QuestionBody": "I have many JSON files with the following structure:\n\n\n{\n  \"requestId\": \"test\",\n  \"executionDate\": \"2023-05-10\",\n  \"executionTime\": \"12:02:22\",\n  \"request\": {\n    \"fields\": [{\n      \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": [-90, 41]\n      },\n      \"colour\": \"blue\",\n      \"bean\": \"blaCk\",\n      \"birthday\": \"2021-01-01\",\n      \"arst\": \"111\",\n      \"arstg\": \"rst\",\n      \"fct\": {\n        \"start\": \"2011-01-10\",\n        \"end\": \"2012-01-10\"\n      }\n    }]\n  },\n  \"response\": {\n    \"results\": [{\n        \"geom\": {\n          \"type\": \"geo\",\n          \"coord\": [-90, 41]\n        },\n        \"md\": {\n          \"type\": \"arstat\",\n          \"mdl\": \"trstr\",\n          \"vs\": \"v0\",\n          \"cal\": {\n            \"num\": 4,\n            \"comment\": \"message\"\n          },\n          \"bean\": [\"blue\", \"green\"],\n          \"result_time\": 12342\n        },\n        \"predictions\": [{\n            \"date\": \"2004-05-19\",\n            \"day\": 0,\n            \"count\": 0,\n            \"eating_stage\": \"trt\"\n          }, {\n            \"date\": \"2002-01-20\",\n            \"day\": 1,\n            \"count\": 0,\n            \"eating_stage\": \"arstg\"\n          }, {\n            \"date\": \"2004-05-21\",\n            \"day\": 2,\n            \"count\": 0,\n            \"eating_stage\": \"strg\"\n          }, {\n            \"date\": \"2004-05-22\",\n            \"day\": 3,\n            \"count\": 0,\n            \"eating_stage\": \"rst\"\n          }\n        }\n      }\n    }\n\n\n\nThe predictions part can be very deep. I want to convert this JSON to a CSV with the following structure:\n\n\n\n\nrequestId\nexecutionDate\nexecutionTime\ncolour\npredictions_date\npredictions_day\npredictions_count\npredictions_eating_stage\n\n\n\n\ntest\n2023-05-10\n12:02:22\nblue\n2004-05-19\n0\n0\ntrt\n\n\ntest\n2023-05-10\n12:02:22\nblue\n2002-01-20\n1\n0\nastrg\n\n\ntest\n2023-05-10\n12:02:22\nblue\n2004-05-21\n2\n0\nstrg\n\n\ntest\n2023-05-10\n12:02:22\nblue\n2004-05-22\n3\n0\nrst\n\n\n\n\nI tried the following code:\nflat_json = pd.DataFrame(\n    flatten(json_data), index=[0]\n)\n\nThe code results in every data point becoming a column, and I am not sure how to pivot longer where at the 'predictions' key using JSON functions in Python. I recognise that at this stage I could pivot longer using column names, but I feel like there is a cleaner way to achieve this.\n",
"AnswerId": "76383031",
"AnswerBody": "I would suggest simply extracting what you need. It seems very specific for it to be solved using specific parsing. Therefore I would start by creating two dataframes:\ndf_prediction = pd.DataFrame(example['response']['results'][0]['predictions'])\ndf_data = pd.DataFrame({x:y for x,y in example.items() if type(y)==str},index=[0]) \n\nRenaming columns in predictions:\ndf_prediction.columns = ['prediction_'+x for x in df_prediction]\n\nJoining and adding the last piece of data (colour):\noutput = df_data.assign(colour = example['request']['fields'][0]['colour']).join(df_prediction,how='right').ffill()\n\nOutputting:\n  requestId executionDate  ... prediction_count prediction_eating_stage\n0      test    2023-05-10  ...                0                     trt\n1      test    2023-05-10  ...                0                   arstg\n2      test    2023-05-10  ...                0                    strg\n3      test    2023-05-10  ...                0                     rst\n\n"
},
{
"QuestionId": "76383903",
"QuestionTitle": "Reorganize nested `dict`",
"QuestionBody": "This question is connected to [-> here].\nI would like to reorganize the following nested dict please:\na = {\n (0.0, 0.0): {'a': [25, 29, nan]},\n (0.0, 2.0): {'a': [25, 29, nan], 'b': [25, 35, 31.0]},\n (0.0, 4.0): {'b': [25, 35, 31.0]},\n (2.0, 0.0): {'a': [25, 29, nan], 'c': [25, 26, 29.0]},\n (2.0, 1.5): {'a': [25, 29, nan], 'c': [25, 26, 29.0]},\n (2.0, 2.0): {'a': [25, 29, nan], 'b': [25, 35, 31.0]},\n (2.0, 4.0): {'b': [25, 35, 31.0]},\n (3.0, 3.0): {'d': [25, 31, 32.0]},\n (3.0, 5.0): {'d': [25, 31, 32.0]},\n (5.0, 0.0): {'c': [25, 26, 29.0]},\n (5.0, 1.5): {'c': [25, 26, 29.0]},\n (5.0, 3.0): {'d': [25, 31, 32.0]},\n (5.0, 5.0): {'d': [25, 31, 32.0]},\n (6.0, 1.0): {'e': [25, 28, 30.0]},\n (6.0, 3.0): {'e': [25, 28, 30.0]},\n (8.0, 1.0): {'e': [25, 28, 30.0]},\n (8.0, 3.0): {'e': [25, 28, 30.0]}\n}\n\nI want to swap the inner and outer keys.\nSome outer keys will duplicate and the value should become a list of lists. The result should be:\n{'a': {(0.0, 0.0): [[25, 29, nan]],\n       (0.0, 2.0): [[25, 29, nan], [25, 35, 31.0]],\n       (2.0, 0.0): [[25, 29, nan], [25, 26, 29.0]],\n       (2.0, 1.5): [[25, 29, nan], [25, 26, 29.0]],\n       (2.0, 2.0): [[25, 29, nan], [25, 35, 31.0]]},\n 'b': {(0.0, 2.0): [[25, 29, nan], [25, 35, 31.0]],\n       (0.0, 4.0): [[25, 35, 31.0]],\n       (2.0, 2.0): [[25, 29, nan], [25, 35, 31.0]],\n       (2.0, 4.0): [[25, 35, 31.0]]},\n 'c': {(2.0, 0.0): [[25, 29, nan], [25, 26, 29.0]],\n       (2.0, 1.5): [[25, 29, nan], [25, 26, 29.0]],\n       (5.0, 0.0): [[25, 26, 29.0]],\n       (5.0, 1.5): [[25, 26, 29.0]]},\n 'd': {(3.0, 3.0): [[25, 31, 32.0]],\n       (3.0, 5.0): [[25, 31, 32.0]],\n       (5.0, 3.0): [[25, 31, 32.0]],\n       (5.0, 5.0): [[25, 31, 32.0]]},\n 'e': {(6.0, 1.0): [[25, 28, 30.0]],\n       (6.0, 3.0): [[25, 28, 30.0]],\n       (8.0, 1.0): [[25, 28, 30.0]],\n       (8.0, 3.0): [[25, 28, 30.0]]}\n}\n\nIntuition tells me pd.DataFrame with a .groupby() [and cull the NaN cells] would be the way to go...\ndf = pd.DataFrame(dict_vertices)\nprint(df.head(2))\n             0.0               2.0                    ...  8.0       6.0\n             0.0               0.0               1.5  ...  1.0  3.0  3.0\na  [25, 29, nan]     [25, 29, nan]     [25, 29, nan]  ...  NaN  NaN  NaN\nc            NaN  [[25, 26, 29.0]]  [[25, 26, 29.0]]  ...  NaN  NaN  NaN\n\n[2 rows x 17 columns]\n\n...but I don't know.\nHow do I reorganize the following nested dict please; where the value follows the outer key?\n",
"AnswerId": "76384969",
"AnswerBody": "You can use:\nout = {}\n\nfor k1, d in a.items():\n    for k2 in d:\n        out.setdefault(k2, {})[k1] = list(d.values())\n\nOutput:\n{'a': {(0.0, 0.0): [[25, 29, nan]],\n       (0.0, 2.0): [[25, 29, nan], [[25, 35, 31.0]]],\n       (2.0, 0.0): [[25, 29, nan], [[25, 26, 29.0]]],\n       (2.0, 1.5): [[25, 29, nan], [[25, 26, 29.0]]],\n       (2.0, 2.0): [[25, 29, nan], [[25, 35, 31.0]]]},\n 'b': {(0.0, 2.0): [[25, 29, nan], [[25, 35, 31.0]]],\n       (0.0, 4.0): [[25, 35, 31.0]],\n       (2.0, 2.0): [[25, 29, nan], [[25, 35, 31.0]]],\n       (2.0, 4.0): [[25, 35, 31.0]]},\n 'c': {(2.0, 0.0): [[25, 29, nan], [[25, 26, 29.0]]],\n       (2.0, 1.5): [[25, 29, nan], [[25, 26, 29.0]]],\n       (5.0, 0.0): [[25, 26, 29.0]],\n       (5.0, 1.5): [[25, 26, 29.0]]},\n 'd': {(3.0, 3.0): [[25, 31, 32.0]],\n       (3.0, 5.0): [[25, 31, 32.0]], \n       (5.0, 3.0): [[25, 31, 32.0]],\n       (5.0, 5.0): [[25, 31, 32.0]]},\n 'e': {(6.0, 1.0): [[25, 28, 30.0]],\n       (6.0, 3.0): [[25, 28, 30.0]],\n       (8.0, 1.0): [[25, 28, 30.0]],\n       (8.0, 3.0): [[25, 28, 30.0]]},\n}\n\n"
},
{
"QuestionId": "76381414",
"QuestionTitle": "How to exclude linebreaks from a regex match in python?",
"QuestionBody": "\nHow can I make the bellow regex exclude matches that span across lines?\nimport re\nreg = re.compile(r'\\b(apple)(?:\\W+\\w+){0,4}?\\W+(tree|plant|garden)')\nreg.findall('my\\napple tree in the garden')\nreg.findall('apple\\ntree in the garden')\n\nThe first one should match, the second one should not.\n(Now both matches...)\n",
"AnswerId": "76381603",
"AnswerBody": "Your \\W matches newlines. To exclude them replace \\W with [^\\w\\n]:\nimport re\nreg = re.compile(r'\\b(apple)(?:[^\\n\\w]+\\w+){0,4}?[^\\n\\w]+(tree|plant|garden)')\nprint(reg.findall('my\\napple tree in the garden'))\n#  [('apple', 'tree')]\nprint(reg.findall('apple\\ntree in the garden'))\n#  []\n\n"
},
{
"QuestionId": "76381292",
"QuestionTitle": "How to declare a constant datatype using a class property datatype in typescript?",
"QuestionBody": "I'm creating a nestjs API so I'm using classes to declare my entities for example\nexport class Customer {\nid: number;\nname: string;\n}\n\nSo now I'm working in my Customer Controller and I would like to type an get query param as customer.id because I'm thinking if some day the customer id data type changes to string automatically making my controller query param as string too.\n@GET()\ngetCustomerById(@Params('id', id: Customer.id)) {\nreturn this.customerService.getCustomerById(id))\n}\n\nIs it possible? Thanks\n",
"AnswerId": "76381604",
"AnswerBody": "You can use TypeScript lookup types:\ngetCustomerById(@Params('id') id: Customer['id']) {}\n\n"
},
{
"QuestionId": "76384902",
"QuestionTitle": "Different X Labels for Different Variables",
"QuestionBody": "I have two data frames t1 and t2. I want a seaborn plot where it plots side by side for every variable using the for loop. I was able to achieve this but I fail when I try to set the customized x labels. How do I incorporate set_xlabel in to the for loop?\ndata1 = {\n    'var1': [1, 2, 3, 4],\n    'var2': [20, 21, 19, 18],\n    'var3': [5, 6, 7, 8]\n    }\n\ndata2 = {\n    'var1': [5. 2. 3. 5],\n    'var2': [21, 18, 3, 11]\n    'var3': [1, 9, 3, 6]\n    }\n\n  \nt1 = pd.DataFrame(data1)\nt2 = pd.DataFrame(data2)\n\nxlabel_list = [\"new_var1\", \"new_var2\", \"new_var3\"]\n\ndef fun1(df1, df2, numvar, new_label):\n    plt.tight_layout()\n\n    fig, ax = plt.subplots(1, 2)\n    sns.kdeplot(data = df1[numvar], linewidth = 3, ax=ax[0])\n    sns.kdeplot(data = df2[numvar], linewidth = 3, ax=ax[1])\n\n    ax[0].set_xlabel(new_label, weight='bold', size = 10)\n    ax[1].set_xlabel(new_label, weight='bold', size = 10)    \n\nfor col in t1.columns: # how to incorporate the new_label parameter in the for loop along with col?\n    fun1(df1 = t1, df2 = t2, numvar = col, new_label??)\n\n",
"AnswerId": "76384970",
"AnswerBody": "Use zip:\nfor col, new_label in zip(t1.columns, xlabels_list):\n\n"
},
{
"QuestionId": "76382981",
"QuestionTitle": "Add pre-defined value to DataFrame on each instance of matching index",
"QuestionBody": "I am trying to add the corresponding value from df to df1 for each time the name and week match in df1\ndf\n                 Name    Week     Value\n0                Frank  Week 3       8.0\n1                  Bob  Week 3       8.0\n2                  Bob  Week 4       8.0\n3            Elizabeth  Week 3       4.0\n4                Mario  Week 2       1.5\n5                Mario  Week 3       2.5\n6             Michelle  Week 3       8.0\n7             Michelle  Week 4       1.0\n8               Darwin  Week 1       1.0\n9               Darwin  Week 2       0.5\n10              Darwin  Week 3      11.0\n11             Collins  Week 1       8.0\n12             Collins  Week 2       6.0\n13             Collins  Week 3      17.0\n14             Collins  Week 4       7.0\n15              Alexis  Week 1       1.5\n16              Daniel  Week 3       2.0\n\ndf1\n                Name    Week  Total\n0              Frank  Week 1     16\n1              Frank  Week 1      3\n2              Frank  Week 3     28\n3              Frank  Week 3      1\n4              Frank  Week 4      3\n..               ...     ...    ...\n310           Daniel  Week 2     50\n311           Daniel  Week 3     56\n312           Daniel  Week 4     78\n313            Kevin  Week 4    162\n314            Kevin  Week 4     46\n\nExpected:\ndf1\n                Name    Week  Total\n0              Frank  Week 1     16\n1              Frank  Week 1      3\n2              Frank  Week 3     **36**\n3              Frank  Week 3      **9**\n4              Frank  Week 4      3\n..               ...     ...    ...\n310           Daniel  Week 2     50\n311           Daniel  Week 3     **58**\n312           Daniel  Week 4     78\n313            Kevin  Week 4    162\n314            Kevin  Week 4     46\n\n",
"AnswerId": "76383058",
"AnswerBody": "Use a merge + assign:\nout = (df1\n  .merge(df, how='left')\n  .assign(Total=lambda d: d['Total'].add(d.pop('Value'), fill_value=0))\n)\n\nOutput:\n     Name    Week  Total\n0   Frank  Week 1   16.0\n1   Frank  Week 1    3.0\n2   Frank  Week 3   36.0\n3   Frank  Week 3    9.0\n4   Frank  Week 4    3.0\n...\n5  Daniel  Week 2   50.0\n6  Daniel  Week 3   58.0\n7  Daniel  Week 4   78.0\n8   Kevin  Week 4  162.0\n9   Kevin  Week 4   46.0\n\n"
},
{
"QuestionId": "76384338",
"QuestionTitle": "Looping through combinations of subsets of data for processing",
"QuestionBody": "I am processing sales data, sub-setting across a combination of two distinct dimensions.\nThe first is a category as indicated by each of these three indicators ['RA','DS','TP']. There are more indicators in the data; however, those are the only ones of interest, and the others not mentioned but in the data can be ignored.\nIn combination with those indicators, I want to subset across varying time intervals 7 days back, 30 days back, 60 days back, 90 days back, 120 days back, and no time constraint\nWithout looping through this would create 18 distinct functions for those combinations of dimensions 3 categories x 6 time which was what I first started to do\nfor example a function that subsets on DS and 7 days back:\ndef seven_days_ds(df):\n\n    subset = df[df['Status Date'] > (datetime.now() - pd.to_timedelta(\"7day\"))]\n    subset = subset[subset['Association Label']==\"DS\"]\n    \n    grouped_subset = subset.groupby(['Status Labelled'])\n    status_counts_seven_ds = (pd.DataFrame(grouped_subset['Status Labelled'].count()))\n    status_counts_seven_ds.columns = ['Counts']\n    status_counts_seven_ds = status_counts_seven_ds.reset_index()\n    \n    return status_counts_seven_ds #(the actual function is more complicated than this).\n\nAnd then repeat this, but changing the subset criteria for each combination of category and time-delta for 18 combinations of the variables of interest. Obviously, this is not ideal.\nIs there a way to have a single function that creates those 18 objects, or (ideally), a single object whose columns indicate the dimensions being subset on? ie counts_ds_7 etc.\nOr is this not possible, and I'm stuck doing it the long way doing them all separately?\n",
"AnswerId": "76384983",
"AnswerBody": "IIUC, you can use :\ndef crossubsets(df):\n    labels = [\"RA\", \"DS\", \"TP\"]\n    time_intervals = [7, 30, 60, 90, 120, None]\n    group_dfs = df.loc[\n        df[\"Association Label\"].isin(labels)\n    ].groupby(\"Association Label\")\n\n    data = []\n    for l, g in group_dfs:\n        for ti in time_intervals:\n            s = (\n                g[g[\"Status Date\"] > (pd.Timestamp.now() - pd.Timedelta(ti, \"d\"))]\n                if ti is not None else g\n            )\n            data.append(s[\"Status Labelled\"].value_counts().rename(f\"counts_{l}_{ti}\"))\n\n    return pd.concat(data, axis=1) #with optional .T to have 18 rows instead of cols\n\n"
},
{
"QuestionId": "76381561",
"QuestionTitle": "How to find columns with three or fewer distinct values",
"QuestionBody": "I'm using the Boston Housing data set from the MASS package, and working with splines from the gam package in R. However, an error is returned with this code:\nlibrary(gam)\nlibrary(MASS)\nlibrary(tidyverse)\n\nBoston.gam <- gam(medv ~ s(crim) + s(zn) + s(indus) + s(nox) + s(rm) + s(age) + s(dis) + s(rad) + s(tax) + s(ptratio) + s(black) + s(lstat), data = Boston)\n\nThe error message is:\nA smoothing variable encountered with 3 or less unique values; at least 4 needed\n\nThe variable that is causing the issue is chas, it only has two values, 1 and 0.\nWhat is a test to determine if a column has 3 or fewer unique values so it can be eliminated from the spline analysis?\n",
"AnswerId": "76381629",
"AnswerBody": "Would this work?\nYou can use dplyr::n_distinct() to perform the unique check.\n# Number of unique values\nn_unique_vals <- map_dbl(Boston, n_distinct)\n\n# Names of columns with >= 4 unique vals\nkeep <- names(n_unique_vals)[n_unique_vals >= 4]\n\n# Model data\ngam_data <- Boston %>%\n  dplyr::select(all_of(keep))\n\n"
},
{
"QuestionId": "76381619",
"QuestionTitle": "Android - How to make the height of a TextInputEditText to be exactly of 2 lines?",
"QuestionBody": "I have a layout like this:\n    <com.google.android.material.textfield.TextInputLayout\n        android:id=\"@+id/user_description_input_layout\"\n        android:layout_width=\"0dp\"\n        android:layout_height=\"wrap_content\"\n        android:layout_marginHorizontal=\"16dp\"\n        android:layout_marginTop=\"16dp\"\n        android:hint=\"Description\"\n        app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintTop_toTopOf=\"parent\"\n        app:startIconContentDescription=\"Lalala\">\n\n        <com.google.android.material.textfield.TextInputEditText\n            android:id=\"@+id/user_description_input\"\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"wrap_content\"\n            android:hint=\"description\" />\n\n    </com.google.android.material.textfield.TextInputLayout>\n\nIt's height is exactly the size of ONE line, but I wish it could be the size of 2 line exactly.\nI tried adding theses attributes to my TextInputEditText tag:\n<com.google.android.material.textfield.TextInputEditText\n    ...\n    android:maxLines=\"4\"\n    android:scrollbars=\"vertical\" />\n\nBut that made it to start as a 1 line height and stop at 2 as the user types on it. I would like it to be fixed on 2 from the begining, even if it did not have enough text to need 2 lines.\nI also would like it to have a fixed size and allow the user to scroll vertically in case he add some text that is larger than 2 lines.\nI know I COULD do it programatically by adding enough caracters until it has a 2 lines height and fix this heigh size and then clean the TextInputEditText, but that is such an ugly solution.\n",
"AnswerId": "76381632",
"AnswerBody": "Try this, in your TextInputEditText\nandroid:minLines=\"2\"\nandroid:gravity=\"top\"\n\n"
},
{
"QuestionId": "76384389",
"QuestionTitle": "Spring boot + JPA problem with post mapping form where is select multiple",
"QuestionBody": "I have a PostMapping whith form where user can create a meeting and invite employees. My problem is that the employees are not saved to the database.\nHere is my MeetingDTO:\n@Data\n@Builder\npublic class MeetingDto {\n    private Long id;\n    @NotEmpty(message = \"Content could not be empty\")\n    private String contentOfMeeting;\n    @FutureOrPresent\n    private LocalDateTime startOfMeeting;\n    private LocalDateTime endOfMeeting;\n    private Status status;\n    private List<Employee> employees;\n    private Visitor visitor;\n}\n\nHere is my controller:\n@GetMapping(\"/visitors/new-meeting\")\n    public String createMeetingForm(Model model) {\n        List<Employee> employeeList = employeeRepository.findAll();\n        model.addAttribute(\"employeeList\", employeeList);\n        model.addAttribute(\"meeting\", new Meeting());\n        return \"visitors-createAMeeting\";\n    }\n\n    @PostMapping(\"/visitors/new-meeting\")\n    public String saveMeeting(@ModelAttribute(\"meeting\") MeetingDto meetingDto) {\n        String nameOfVisitor;\n\n        Object principal = SecurityContextHolder.getContext().getAuthentication().getPrincipal();\n        if (principal instanceof UserDetails) {\n            nameOfVisitor = ((UserDetails)principal).getUsername();\n        } else {\n            nameOfVisitor = principal.toString();\n        }\n\n        Long visitorId = visitorRepository.findByEmailAddress(nameOfVisitor).getId();\n        meetingDto.setVisitor(visitorRepository.findById(visitorId).orElse(null));\n        meetingService.createMeeting(visitorId, meetingDto);\n        return \"redirect:/visitors/home\";\n    }\n\nServiceImpl:\n@Service\npublic class MeetingServiceImpl implements MeetingService {\n    private MeetingRepository meetingRepository;\n    private EmployeeRepository employeeRepository;\n    private VisitorRepository visitorRepository;\n\n    @Autowired\n    public MeetingServiceImpl(MeetingRepository meetingRepository, EmployeeRepository employeeRepository,\n                              VisitorRepository visitorRepository) {\n        this.meetingRepository = meetingRepository;\n        this.employeeRepository = employeeRepository;\n        this.visitorRepository = visitorRepository;\n    }\n\n    private Meeting mapToMeeting(MeetingDto meetingDto) {\n        return Meeting.builder()\n                .id(meetingDto.getId())\n                .contentOfMeeting(meetingDto.getContentOfMeeting())\n                .startOfMeeting(meetingDto.getStartOfMeeting())\n                .endOfMeeting(meetingDto.getEndOfMeeting())\n                .status(Status.valueOf(String.valueOf(Status.REJECTED)))\n                .employees(meetingDto.getEmployees())\n                .build();\n    }\n\n    @Override\n    public void createMeeting(Long visitorId, MeetingDto meetingDto) {\n        Visitor visitor = visitorRepository.findById(visitorId).orElse(null);\n        Meeting meeting = mapToMeeting(meetingDto);\n        meeting.setVisitor(visitor);\n        meeting.setEmployees(meetingDto.getEmployees());\n        meetingRepository.save(meeting);\n    }\n}\n\nAnd my template for GetMapping:\n<!DOCTYPE html>\n<html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns=\"http://www.w3.org/1999/html\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Create a meeting</title>\n    <link rel=\"stylesheet\"\n          href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css\"\n          integrity=\"sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l\"\n          crossorigin=\"anonymous\" />\n</head>\n<body>\n<div class=\"container\">\n    <h3>Create a meeting</h3>\n    <hr/>\n    <form action=\"#\" th:action=\"@{/visitors/new-meeting}\" th:object=\"${meeting}\" method=\"post\">\n        <p>Content: <input type=\"text\" id=\"content\" name=\"content\" th:field=\"*{contentOfMeeting}\" placeholder=\"Content\"></p>\n        <p th:if=\"${#fields.hasErrors('contentOfMeeting')}\" class=\"text-danger\" th:errors=\"*{contentOfMeeting}\"></p>\n        <p>Start of meeting: <input type=\"datetime-local\" id=\"start\" name=\"start\" th:field=\"*{startOfMeeting}\" placeholder=\"Start of meeting\"></p>\n        <p th:if=\"${#fields.hasErrors('startOfMeeting')}\" class=\"text-danger\" th:errors=\"*{startOfMeeting}\"></p>\n        <p>End of meeting: <input type=\"datetime-local\" id=\"end\" name=\"email\" th:field=\"*{endOfMeeting}\" placeholder=\"End of meeting\"></p>\n        <p></pd><span th:if=\"${#fields.hasErrors('endOfMeeting')}\" th:errors=\"*{endOfMeeting}\" class=\"text-danger\">End of meeting can not be before start of meeting</span></p>\n        <label>Employees: </label>\n        <p>To select more than one employee please click ctrl</p>\n        <select id=\"employee\" class=\"form-control\" th:field=\"${employeeList}\" multiple name=\"employeeList\">\n            <option th:each=\"employee : ${employeeList}\" th:value=\"${employee.id}\" th:text=\"${employee.name + ' ' + employee.surname}\"></option>\n        </select>\n        <br>\n        <p><input type=\"submit\" value=\"Submit\"/></p>\n        <br>\n        <h6><a th:href=\"@{/logout}\">Logout</a></h6>\n        <br>\n    </form>\n</div>\n</body>\n</html>\n\nCould you be so kind to take a look and help me to solve the issue?\nI tried refactor template and controller but the problem still exist.\n",
"AnswerId": "76384989",
"AnswerBody": "While reviewing your code, I noticed a potential issue with how the relationships are handled in JPA/Hibernate. When you're dealing with related entities, in this case Meeting and Employee, it's crucial to manage both sides of the relationship correctly.\nIn your code, you're assigning employees to a meeting using meeting.setEmployees(meetingDto.getEmployees());. This is correct, but depending on your relationship setup, it may not be sufficient. You might also need to set the meeting to each employee. For example, you could iterate over each employee and add the meeting:\nList<Employee> employees = meetingDto.getEmployees();\nfor(Employee employee : employees) {\n    employee.getMeetings().add(meeting); // Assumes a getMeetings() method in Employee class\n}\n\nThis snippet adds the current meeting to the list of meetings for each employee. When you save your meeting, the related employees should also be updated.\nOf course, this suggestion is based on common practice when using JPA/Hibernate, and the specific implementation may need adjustment according to your actual entity configuration. It's important to ensure the relationship between Meeting and Employee entities is set correctly, with appropriate cascading settings. You might need to set CascadeType.PERSIST or CascadeType.MERGE to make sure the changes to the employees are stored when saving the meeting.\nIf the problem persists, it would be helpful to take a closer look at the parts of your Employee and Meeting entities that define their relationship. This would allow for a more precise solution to your problem.\nRevised Answer\nThe challenge seems in correctly assigning only the selected employees to the meeting, rather than all the employees as currently happens.\nFrom the look of your form, it seems likely that only the IDs of the selected employees are being sent to the server when the form is submitted. So, we should adjust your MeetingDto to hold a list of these IDs. Here's how:\npublic class MeetingDto {\n    // Other fields...\n    private List<Long> employeeIds; // Replaced from List<Employee> employees\n    // Remaining fields...\n}\n\nNext, we can modify the createMeeting method within your MeetingService to handle these employee IDs:\n@Override\npublic void createMeeting(Long visitorId, MeetingDto meetingDto) {\n    Visitor visitor = visitorRepository.findById(visitorId).orElse(null);\n    Meeting meeting = mapToMeeting(meetingDto);\n    meeting.setVisitor(visitor);\n\n    List<Employee> selectedEmployees = employeeRepository.findAllById(meetingDto.getEmployeeIds()); // Retrieve employees by their IDs\n    meeting.setEmployees(selectedEmployees); \n\n    meetingRepository.save(meeting);\n}\n\nLastly, we need to ensure your form is sending the IDs of the selected employees. Your select element in the form should be modified to look like this:\n<select id=\"employee\" class=\"form-control\" th:field=\"*{employees}\" multiple name=\"employeeList\">\n    <option th:each=\"employee : ${employeeList}\" th:value=\"${employee.id}\" th:text=\"${employee.name + ' ' + employee.surname}\"></option>\n</select>\n\nWith these alterations, your form will be transmitting the IDs of the selected employees to the server. Then, your service can retrieve the relevant employees based on these IDs from the database. As a result, only the selected employees will be associated with the meeting.\n"
},
{
"QuestionId": "76382806",
"QuestionTitle": "How to group variables that falls within a range of numbers",
"QuestionBody": "I a df like this\nmy_df <- data.frame(\n    b1 = c(2, 6, 3, 6, 4, 2, 1, 9, NA), \n    b2 = c(100, 4, 106, 102, 6, 6, 1, 1, 7), \n    b3 = c(75, 79, 8, 0, 2, 3, 9, 5, 80), \n    b4 = c(NA, 6, NA, 10, 12, 8, 3, 6, 2),\n    b5 = c(2, 12, 1, 7, 8, 5, 5, 6, NA),\n    b6 = c(9, 2, 4, 6, 7, 6, 6, 7, 9),\n    b7 = c(1, 3, 7, 7, 4, 2, 2, 9, 5),\n    b8 = c(NA, 8, 4, 5, 1, 4, 1, 3, 6),\n    b9 = c(4, 5, 7, 9, 5, 1, 1, 2, 12))\n\nI wanted to create a new column (NEW) based on the following assumptions.\nIf b9 is <= 2 write yellow.\nIf b9 is between 4 and 7 write white.\nIf b9 is >= 9 write green\nThe idea is to create something like this.\nmy_df1 <- data.frame(\n        b1 = c(2, 6, 3, 6, 4, 2, 1, 9, NA), \n        b2 = c(100, 4, 106, 102, 6, 6, 1, 1, 7), \n        b3 = c(75, 79, 8, 0, 2, 3, 9, 5, 80), \n        b4 = c(NA, 6, NA, 10, 12, 8, 3, 6, 2),\n        b5 = c(2, 12, 1, 7, 8, 5, 5, 6, NA),\n        b6 = c(9, 2, 4, 6, 7, 6, 6, 7, 9),\n        b7 = c(1, 3, 7, 7, 4, 2, 2, 9, 5),\n        b8 = c(NA, 8, 4, 5, 1, 4, 1, 3, 6),\n        b9 = c(4, 5, 7, 9, 5, 1, 1, 2, 12),\n        NEW = c(\"white\", \"white\", \"white\", \"green\", \"white\", \"yellow\", \"yellow\", \"yellow\", \"green\"))\n\nI thought something like this will do it, but it didn't.\ngreater_threshold <- 2\ngreater_threshold1 <- 4\ngreater_threshold2 <- 7\ngreater_threshold3 <- 9\n\nmy_df1 <- my_df %>%\n    mutate(NEW = case_when(b9 <= greater_threshold ~ \"yellow\", b9 >= greater_threshold1 | b9 <= greater_threshold2 ~ \"white\", b9 >= greater_threshold3 ~ \"green\"))\n                       \n\nAny help will be appreciated.\n",
"AnswerId": "76383084",
"AnswerBody": "You can use between from dplyr:\nmy_df %>%\n  mutate(NEW = case_when(\n    b9 <= 2 ~ \"Yellow\",\n    between(b9, 4, 7) ~ \"white\",\n    b9 >= 9 ~ \"green\"\n  ))\n\nOutput:\n  b1  b2 b3 b4 b5 b6 b7 b8 b9    NEW\n1  2 100 75 NA  2  9  1 NA  4  white\n2  6   4 79  6 12  2  3  8  5  white\n3  3 106  8 NA  1  4  7  4  7  white\n4  6 102  0 10  7  6  7  5  9  green\n5  4   6  2 12  8  7  4  1  5  white\n6  2   6  3  8  5  6  2  4  1 Yellow\n7  1   1  9  3  5  6  2  1  1 Yellow\n8  9   1  5  6  6  7  9  3  2 Yellow\n9 NA   7 80  2 NA  9  5  6 12  green\n\nThose not falling within the conditions (ie, 8) will be NA\n"
},
{
"QuestionId": "76381410",
"QuestionTitle": "saving ccf() looped output in r",
"QuestionBody": "I have a df where the first little bit looks like:\n>dput(df_long_binned_sound2[1:48,])\nstructure(list(id = c(20230420, 20230420, 20230420, 20230420, \n20230420, 20230420, 20230420, 20230420, 20230420, 20230420, 20230420, \n20230420, 20230420, 20230420, 20230420, 20230420, 20230424, 20230424, \n20230424, 20230424, 20230424, 20230424, 20230424, 20230424, 20230424, \n20230424, 20230424, 20230424, 20230424, 20230424, 20230424, 20230424, \n20230424, 20230426, 20230426, 20230426, 20230426, 20230426, 20230426, \n20230426, 20230426, 20230426, 20230426, 20230426, 20230426, 20230426, \n20230426, 20230426), cons_id = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, \n8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 16L, 17L, 18L, 19L, \n20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, \n33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, \n46L, 47L), win = c(1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, \n1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, \n1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1), sound = c(1, NA, 1.5, \nNA, 2, NA, 2.75, NA, 7, NA, 8, NA, 4, NA, 6.5, NA, NA, 4.5, NA, \n6, NA, 2, NA, 5.5, NA, 4.66666666666667, NA, 4.8, NA, 6, NA, \n4.5, NA, 3, NA, 2.33333333333333, NA, 6, NA, 1, NA, 1, NA, 1.66666666666667, \nNA, 4.5, NA, 5), sound2 = c(NA, 1, NA, 1.5, NA, 1.5, NA, 6, NA, \n8, NA, 1, NA, 8, NA, 7, 3, NA, 5, NA, 5, NA, 5, NA, 6.5, NA, \n8, NA, 6, NA, 5, NA, 5.66666666666667, NA, 3.5, NA, 2, NA, 2.42857142857143, \nNA, 1.5, NA, 2, NA, 8, NA, 2.33333333333333, NA)), row.names = c(NA, \n-48L), class = c(\"tbl_df\", \"tbl\", \"data.frame\"))\n\nI am running some cross-correlation analysis on it and I would like to save the number outputs of ccf(). I can save all the correlograms using:\nids <- unique(df_long_binned_sound2$id)\nfor (i in 1:length(ids)){\n  pdf(file = paste(\"/Users/myname/Desktop/Current Work/CRTT study - 2022/CRTT - Full/CRTT_r_Full/Wack_A_Mole/CC_CustomBin/CC/plot_\", ids[i], \".pdf\"),\n      width = 10, height = 10\n  )\n  \n  ccf(df_long_binned_sound2$sound[which(df_long_binned_sound2$id == ids[i])], df_long_binned_sound2$sound2[which(df_long_binned_sound2$id == ids[i])],\n      na.action = na.pass,\n      main = paste(\"Corrected Correlogram \\n Pair\", ids[i]),\n      xlim = c(-6, 6)\n  )\n  \n  dev.off()\n}\n\nand I can print the number outputs using:\nfor (i in 1:length(ids)){\n  print(ccf(df_long_binned_sound2$sound[which(df_long_binned_sound2$id == ids[i])], \n                     df_long_binned_sound2$sound2[which(df_long_binned_sound2$id == ids[i])],\n                     na.action = na.pass,\n    )\n  )\n}\n\nI would like to save the number outputs so that I end up with something like:\n\n\n\n\nid\nlag\nlag_value\n\n\n\n\n20230420\n-9\n-0.145\n\n\n20230420\n-8\n-0.057\n\n\n\n\n...\n\n\n\n\nid\nlag\nlag_value\n\n\n\n\n20230420\n8\n-0.183\n\n\n20230420\n9\n-0.203\n\n\n20230424\n-9\n0.234\n\n\n\n\n...\nI'm sure there is a simple solution but I can't seem to find it. I very optimistically tried and failed with:\ndf.cff <- data.frame()\nfor (i in 1:length(ids)){\n  cff.standin <- ccf(df_long_binned_sound2$sound[which(df_long_binned_sound2$id == ids[i])], \n      df_long_binned_sound2$sound2[which(df_long_binned_sound2$id == ids[i])],\n      na.action = na.pass,\n    )\n  df.cff <- cbind(df.cff, cff.standin)\n}\n\nError in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : \n  cannot coerce class ‘\"acf\"’ to a data.frame\n\nand:\ndf.cff <- data.frame()\nfor (i in 1:length(ids)){\n  cff.standin <- ccf(df_long_binned_sound2$sound[which(df_long_binned_sound2$id == ids[i])], \n      df_long_binned_sound2$sound2[which(df_long_binned_sound2$id == ids[i])],\n      na.action = na.pass,\n    )\n  df.cff <- rbind(df.cff, cff.standin)\n}\n\nError in rbind(deparse.level, ...) : \n  invalid list argument: all variables should have the same length\n\nDoes anyone know a good way to save the number outputs of ccf() from a for loop? I am especially interested in a solution that formats the output like the table examples above.\nTYIA :)\n",
"AnswerId": "76381690",
"AnswerBody": "You need to inspect the ccf object with View() or checking it's help page:\n\nValue\nAn object of class \"acf\", which is a list with the following\nelements:\nlag  A three dimensional array containing the lags at which the acf is\nestimated.\nacf  An array with the same dimensions as lag containing the estimated\nacf.\n\nThus, you just want to do something like:\ncbind(id = ids[i], lag = cff.standin$lag, lag_value = cff.standin$acf)\n\nNow for the full solution:\nids <- unique(df_long_binned_sound2$id)\ndf_ccf <- c() #empty vector to save results\nfor (i in ids){ #you can pass the ids directly, instead of their index\n  df1_subset <- df_long_binned_sound2[which(df_long_binned_sound2$id == i),] #saving an extra variable saves space in the call below\n  \n  ccf_output <- ccf(df1_subset$sound, df1_subset$sound2,\n                    na.action = na.pass,\n                    main = paste(\"Corrected Correlogram \\n Pair\", i),\n                    xlim = c(-6, 6)\n  )\n  \n  df_ccf <- rbind(df_ccf, cbind(id = i, lag = ccf_output$lag, lag_value = ccf_output$acf)) #iteratively rbind the results\n}\n\nBut I prefer something using tidyverse:\ndf_ccf <- df_long_binned_sound2 %>%\n  group_split(id) %>%\n  imap_dfr(function(data, index){\n    ccf(data$sound, data$sound2,\n        na.action = na.pass,\n        main = paste(\"Corrected Correlogram \\n Pair\", i),\n        xlim = c(-6, 6)) %>%\n      {tibble(id = ids[index],\n              lag = as.numeric(.$lag),\n              lag_value = as.numeric(.$acf))}\n  })\n\n"
},
{
"QuestionId": "76382508",
"QuestionTitle": "How to make a CMake custom command depends on a target being built but without rerunning on relink?",
"QuestionBody": "I have a executable used to generate a \"cache\" file. In CMake, I have something like this:\nadd_executable(Generator ...)\nadd_custom_target(OUTPUT cache\n    DEPENDS Generator OtherDep1 OtherDep2\n    COMMAND Generator --input OtherDep1 OtherDep2 --output cache)\n\nHowever, because it takes about 10 minutes and I do not care of the cache differs when Generator changes, I do not want cache to be re-computed whenever Generator is re-linked for whatever reason. But if I remove Generator from the dependencies, it may not be available when the custom commands needs it.\nI know this is a bit far from the usual Make/CMake workflow, but is there something I can do to require Generator to have been compiled before running the custom command?\n",
"AnswerId": "76383091",
"AnswerBody": "\nI do not want cache to be re-computed whenever Generator is re-linked for whatever reason.\n\nThen you need to define target-level dependencies instead of file-level ones. Target-level dependencies are defined with add_dependencies command:\nadd_executable(Generator ...)\n\n# Custom command for **file-level** dependencies.\n# The output will be rebuilt whenever it will be found older than one of its dependencies.\nadd_custom_command(OUTPUT cache\n    DEPENDS OtherDep1 OtherDep2\n    COMMAND Generator --input OtherDep1 OtherDep2 --output cache)\n\n# Custom target.\n# It just makes sure, that its dependencies are up-to-date.\nadd_custom_target(create_cache\n   DEPENDS cache\n)\n\n# **target-level** dependencies between the targets.\n# They ensures only order, but do not cause rebuilding of one target\n# because of another target has been rebuilt\nadd_dependencies(create_cache Generator)\n\n"
},
{
"QuestionId": "76384961",
"QuestionTitle": "Unable to connect to Apache MINA sshd server",
"QuestionBody": "I'm trying to setup a sftp server with Apache MINA sshd. But I'm getting subsystem request failed on channel 0 while trying to connect to the server.\nsftp -P 22 john@localhost                                                                                                                                                            \nPassword authentication\n(john@localhost) Password:\nsubsystem request failed on channel 0\nConnection closed\n\nI was following this document. But I'm not sure whether I'm missing any essential parts here.\nFollowing is the code I'm using at the moment with mina-sshd v2.10.0.\n\npublic class Main {\n    public static void main(String[] args) {\n\n        SshServer sshd = SshServer.setUpDefaultServer();\n        sshd.setPort(22);\n        sshd.setKeyPairProvider(new SimpleGeneratorHostKeyProvider(Paths.get(\"hostkey.ser\")));\n\n        sshd.setShellFactory(new ProcessShellFactory(\"/bin/sh\", \"-i\", \"-l\"));\n        sshd.setCommandFactory(new ScpCommandFactory());\n\n        sshd.setPasswordAuthenticator(new MyPasswordAuthenticator());\n\n        try {\n            System.err.println(\"Starting SSHD on port 22\");\n            sshd.start();\n            Thread.sleep(Long.MAX_VALUE);\n            System.err.println(\"Exiting after a very (very very) long time\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n",
"AnswerId": "76385001",
"AnswerBody": "I think the error is caused by the server not allowing SFTP. If you check the SFTP docs for NIMA, you can see that you can enable the SFTP subsystem like this:\nSftpSubsystemFactory factory = new SftpSubsystemFactory.Builder()\n    //...\n    .build();\nsshd.setSubsystemFactories(Collections.singletonList(factory));\n\nFor further diagnosing, you could try creating a custom SftpEventListener and registering it with factory.addSftpEventListener or similar,\n"
},
{
"QuestionId": "76382989",
"QuestionTitle": "Functions intervals",
"QuestionBody": "I have 3 functions, how can I plot them using differents intervals ?\nThis is my code:\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.linspace(-5,5,100)\ny = 2*x+1\nk = 3*x+2\ni = 2*x+2\nplt.plot(x, y, '-r', label='y=2x+1')\nplt.plot(x, k, '-r', label='k =3x+2')\nplt.plot(x, i, '-r', label='i =2x+2')\nplt.title('3 functions on 3 intervals')\nplt.xlabel('x', color='#1C2833')\nplt.ylabel('y', color='#1C2833')\nplt.legend(loc='upper left')\nplt.grid()\nplt.show()\n\nWanted style : 3 intervals, 3 linear functions :\n\nThis is what I get :\n\nMy wish is to draw the first function 2*x+1 on the following interval [x:2->x:8].\nThe second function 3*x+2 has to be plotted on the interval [x:8->x:12]\nThe third function 2*x+2 has to be plotted on the interval [x:12->x:20]\nIs it possible ?\nEdit :\nEnded up with this :\nx = np.linspace(-5,0,100)\nt = np.linspace(0,5,100)\nm = np.linspace(5,10,100)\ny = 2*x+1\nk = 3*x-2\ni = 2*x+2\nplt.plot(x, y, '-r', label='y=2x+1')\nplt.plot(t, k, '-r', label='k =3x-2')\nplt.plot(m, i, '-r', label='i =2x+2')\n\nResult :\n\n",
"AnswerId": "76383095",
"AnswerBody": "Is it this that you want?\n\nIn [33]: import matplotlib.pyplot as plt\n    ...: import numpy as np\n    ...: \n    ...: xs = [np.linspace(0,4), np.linspace(-3, 5), np.linspace(4, 10)]\n    ...: fs = [np.cos, np.sin, lambda x:np.sin(x)-2*np.cos(x)]\n    ...: for x, f in zip(xs, fs):\n    ...:     plt.plot(x, f(x), label=f.__name__)\n    ...: plt.legend()\n    ...: plt.show()\n\nPlotting a linear function is no different,\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nxs = [np.linspace(0,4), np.linspace(-3, 5), np.linspace(4, 10)]\nfs = [np.cos, np.sin, lambda x:(x-6)*0.5]\nfs[-1].__name__ = 'x/2-3'\nfor x, f in zip(xs, fs):\n    plt.plot(x, f(x), label=f.__name__)\nplt.legend()\nplt.show()\n\nIf and only if you are going to plot ONLY LINEAR FUNCTIONS,\nanother approach could be\n\nimport matplotlib.pyplot as plt\n\n# plotting y = a x + b\ny = lambda xmin, xmax, a, b: (a*xmin+b, a*xmax+b)\nformat = lambda b: (\"y = %.2f x + %.2f\"if b>=0 else\"y = %.2f x – %.2f\")\nXmin = [0, 4, 7]\nXmax = [5, 6, 9]\nA = [1, 0.5, 3]\nB = [-2, 0, 3]\n\nfor xmin, xmax, a, b in zip(Xmin, Xmax, A, B):\n    plt.plot((xmin, xmax), y(xmin, xmax, a, b),\n             label=format(b)%(a, abs(b)))\nplt.legend()\nplt.show()\n\n"
},
{
"QuestionId": "76381322",
"QuestionTitle": "Elasticsearch query for deeply nested field",
"QuestionBody": "I am trying to find all records between two dates, but can't figure out the proper query.\nThe mapping looks like this\nGET my-books-index-1/_mapping\n{\n  \"my-books-index-1\": {\n    \"mappings\": {\n      \"properties\": {\n        \"book\": {\n          \"properties\": {\n            \"bookInfo\": {\n              \"properties\": {\n                \"publisherInfo\": {\n                  \"type\": \"nested\",\n                  \"properties\": {\n                    \"publication\": {\n                      \"properties\": {\n                        \"publishedOn\": {\n                          \"type\": \"date\"\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\nFollowing is a sample record for the above mapping\n\"_source\": {\n  \"book\": {\n    \"name\": \"Harry Potter\",\n    \"bookInfo\": {\n      \"author\": \"J.K. Rowling\",\n      \"publisherInfo\": [\n        {\n          \"price\": \"100\",\n          \"publication\": {\n            \"publishedOn\": 1685268404000 // [Sunday, May 28, 2023 10:06:44 AM]\n          }\n        }\n      ]\n    }\n  }\n}\n\n[NOTE]: Some additional properties are removed from the mapping sample to keep it short and precise.\nI am trying to find all books published between 25th May to 31st May.\nAny help is appreciated. Thanks.\n",
"AnswerId": "76381691",
"AnswerBody": "You can use range query inside of nested path.\nPUT test_my-books-index-1\n{\n    \"mappings\": {\n      \"properties\": {\n        \"book\": {\n          \"properties\": {\n            \"bookInfo\": {\n              \"properties\": {\n                \"publisherInfo\": {\n                  \"type\": \"nested\",\n                  \"properties\": {\n                    \"publication\": {\n                      \"properties\": {\n                        \"publishedOn\": {\n                          \"type\": \"date\"\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n}\n\n\nPOST test_my-books-index-1/_bulk?refresh\n{\"index\":{\"_id\":\"1\"}}\n{\"book\":{\"name\":\"Harry Potter\",\"bookInfo\":{\"author\":\"J.K. Rowling\",\"publisherInfo\":[{\"price\":\"100\",\"publication\":{\"publishedOn\":1685268404000}}]}}}\n\ndynamic date bigger than 10 days ago\nGET test_my-books-index-1/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"nested\": {\n            \"path\": \"book.bookInfo.publisherInfo\",\n            \"query\": {\n              \"range\": {\n                \"book.bookInfo.publisherInfo.publication.publishedOn\": {\n                  \"gte\": \"now-10d\",\n                  \"lte\": \"now\"\n                }\n              }\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\nto search with exact date\nGET test_my-books-index-1/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"nested\": {\n            \"path\": \"book.bookInfo.publisherInfo\",\n            \"query\": {\n              \"range\": {\n                \"book.bookInfo.publisherInfo.publication.publishedOn\": {\n                  \"gte\": \"25/05/2023\",\n                  \"lte\": \"31/05/2023\",\n                  \"format\": \"dd/MM/yyyy||yyyy\"\n                }\n              }\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\nanother example here: elasticsearch nested range query\n"
},
{
"QuestionId": "76380576",
"QuestionTitle": "0/1 Knapsack Problem with Dynamic Programming",
"QuestionBody": "This is my attempt at the problem asked in this thread. When I try to run it with input egg_weights = (1,5,10,25) and n = 99, it seems to run into an infinite loop. The code seems to give the correct answer for smaller n, albeit very slowly. What went wrong here?\ndef dp_make_weight(egg_weights, target_weight, memo = {}):\n    if target_weight < 0:\n        return float('inf')\n    elif target_weight == 0:\n        return 0\n    elif target_weight > 0:\n        try:\n            return memo[target_weight]\n        except:\n            memo[target_weight] = float('inf')\n            for weight in egg_weights:\n                result = dp_make_weight(egg_weights, target_weight - weight, memo = {})\n                if result < memo[target_weight]:\n                    memo[target_weight] = result + 1\n        return result + 1\n\nHere's the code that was provided for testing purpose.\nif __name__ == '__main__':\n    egg_weights = (1, 5, 10, 25)\n    n = 99\n    print(\"Egg weights = (1, 5, 10, 25)\")\n    print(\"n = 99\")\n    print(\"Expected ouput: 9 (3 * 25 + 2 * 10 + 4 * 1 = 99)\")\n    print(\"Actual output:\", dp_make_weight(egg_weights, n))\n    print()\n\n",
"AnswerId": "76381711",
"AnswerBody": "If you are planning to call dp_make_weight for different egg weight lists, then the default memo argument should be handled as follows. Also, read my comments in the code:\ndef dp_make_weight(egg_weights, target_weight, memo=None):\n    if memo is None:\n        memo = {}\n\n    infinity = float('inf')\n\n    if target_weight < 0:\n        return float('inf')\n    elif target_weight == 0:\n        return 0\n    else: # target_weight must be > 0\n        if target_weight in memo:\n            return memo[target_weight]\n        result = infinity\n        for weight in egg_weights:\n            # Only update result when dp_make_weight returns a value smaller than\n            # the current result value. Also note that the current value of memo\n            # is what is being passed and not a new, empty dict:\n            new_result = dp_make_weight(egg_weights, target_weight - weight, memo)\n            if new_result < result:\n                result = new_result\n        result += 1\n        memo[target_weight] = result\n        return result\n\nif __name__ == '__main__':\n    egg_weights = (1, 5, 10, 25)\n    n = 99\n    print(\"Egg weights =\", egg_weights)\n    print(\"n =\", n)\n    print(\"Expected ouput: 9 (3 * 25 + 2 * 10 + 4 * 1 = 99)\")\n    print(\"Actual output:\", dp_make_weight(egg_weights, n))\n\n    print()\n\n    egg_weights = (1, 6, 9, 12, 13, 15)\n    n = 724\n    print(\"Egg weights =\", egg_weights)\n    print(\"n =\", n)\n    print(\"Expected ouput: 49\")\n    print(\"Actual output:\", dp_make_weight(egg_weights, n))\n\nPrints:\nEgg weights = (1, 5, 10, 25)\nn = 99\nExpected ouput: 9 (3 * 25 + 2 * 10 + 4 * 1 = 99)\nActual output: 9\n\nEgg weights = (1, 6, 9, 12, 13, 15)\nn = 724\nExpected ouput: 49\nActual output: 49\n\n"
},
{
"QuestionId": "76381523",
"QuestionTitle": "How can I get accumulating weighted-average prices in KDB+ by symbol from a table, taking into account all previous records?",
"QuestionBody": "I would like get accumulating weighted-average prices by sym from a table, meaning taking account of not just the previous record but all previous records.\nInput\nq)show t:([]sym:`a`a`a`b`b;size:(2;6;2;7;5);price:(2;10;3;4;9))\nsym size price\n--------------\na   2    2\na   6    10\na   2    3\nb   7    4\nb   5    9\n\nDesired Output:\nq)show t:([]sym:`a`a`b`b;size:(2;6;7;5);price:(2;10;4;9);avgPrice:(2;8;4;6.083))\nsym size price avgPrice\n-----------------------\na   2    2     2\na   6    10    8\na   2    3     7\nb   7    4     4\nb   5    9     6.083\nso for the second row: (2*2+10*6)/(2+6)=8\nso for the third row: (2*2+10*6+2*3)/(2+6+2)=7\nso for the forth row: (7*4+5*9)/(7+5)=6.083\n\nAny help would be appreciated.\nThanks in advance.\n",
"AnswerId": "76381725",
"AnswerBody": "update avgPrice:(sums price*size)%sums size by sym from t\nsym size price avgPrice\n-----------------------\na   2    2     2\na   6    10    8\na   2    3     7\nb   7    4     4\nb   5    9     6.083333\n\n"
},
{
"QuestionId": "76384914",
"QuestionTitle": "Items are showing blank in DataGrid",
"QuestionBody": "I have a TableData class:\npublic class TableData\n{\n    public string ID, WrestlerID;\n    public string Name;\n}\n\nAnd some data that I then put on a list:\nList<TableData> _tableData = new List<TableData>();\nTableData tableData = new TableData\n{\n    ID = \"0\",\n    WrestlerID = \"000\",\n    Name = \"test1\"\n};\n_tableData.Add(tableData);\nTableData tableData2 = new TableData\n{\n    ID = \"1\",\n    WrestlerID = \"111\",\n    Name = \"test2\"\n};\n_tableData.Add(tableData2);\n\nI then iterate through my _tableData list and add each item on my DataGrid:\nforeach (TableData data1 in _tableData)\n{\n    DGTable.Items.Add(data1);\n}\n\nBTW Here's my DataGrid:\n<DataGrid x:Name=\"DGTable\" Grid.Row=\"1\">\n    <DataGrid.Columns>\n        <DataGridTextColumn Header=\"ID\" Binding=\"{Binding ID}\" Width=\"100\"/>\n        <DataGridTextColumn Header=\"Name\" Binding=\"{Binding Name}\" Width=\"*\"/>\n        <DataGridTextColumn Header=\"Wrestler ID\" Binding=\"{Binding WrestlerID}\" Width=\"200\"/>\n    </DataGrid.Columns>\n</DataGrid>\n\nWhen I run the app, the DataGrid displays 2 rows but all fields are empty. Any thoughts? Thanks!\n",
"AnswerId": "76385010",
"AnswerBody": "Your TableData class needs to have properties instead of fields to be able use bindings.\nIt should also implement the INotifyPropertyChanged interface to use observable properties, so that changes to those properties get reflected in the UI.\nChange your class as follows:\npublic class TableData : INotifyPropertyChanged\n{\n    public event PropertyChangedEventHandler PropertyChanged;  \n  \n    private void OnPropertyChanged([CallerMemberName] String propertyName = \"\")  \n    {  \n        PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName));\n    }  \n\n    private string id;\n    public string ID\n    {\n        get => id;\n        set\n        {\n            if(id == value) return;\n            id = value;\n            OnPropertyChanged();\n        }\n    }\n\n    // repeat for WrestlerID and Name\n    //...\n}\n\nDon't forget to add using System.ComponentModel; at the top.\n"
},
{
"QuestionId": "76382920",
"QuestionTitle": "How to doing dynamic calculation in python",
"QuestionBody": "How to make it like that so odd indexes will be doing (-) and even indexes will do (+) The max iteration is 6. iteration 1 +10, iteration 2 -20, iteration 3 +30, iteration 4 -40, iteration 5 + 50, iteration 6 -60\nAA = np.array([[9.27914]+10,\n              [9.33246]-20,\n              [9.26303]+30,\n              [9.30597]-40,\n              [9.6594 ]+50,\n              [9.04283]-60,\n              [8.88866]+10,\n              [8.89956]-20])\n\nexpected results:\nAA=np.array([\n    [19.27914],\n    [-10.66754],\n    [39.26303],\n    [-30.69403],\n    [59.6594],\n    [-50.95717],\n    [18.88866],\n    [-11.10044],\n])\n\nI try use this code but not working\nmax_iter = 6\niter = 0\nfor i in range(len(AA)):\n    if i % 2 == 0:\n        AA[i][0] = AA[i][0] + (iter % max_iter)\n    else:\n       AA[i][0] = AA[i][0] - (iter % max_iter)\n    iter += 10\n\n",
"AnswerId": "76383096",
"AnswerBody": "You were very close. Just had to make 3 small changes. I added a +1 inside the parenthesis, added *10 for each of the array operations and change iter += 10 to array += 1\nmax_iter = 6\niter = 0\nfor i in range(len(AA)):\n    if i % 2 == 0:\n        AA[i][0] = AA[i][0] + (iter % max_iter+1)*10\n    else:\n        AA[i][0] = AA[i][0] - (iter % max_iter+1)*10\n    iter += 1\n\nIn fact, you can remove the if else statement and do it in a single line if you use the following:\nAA[i][0] = AA[i][0] +(-1)**(i)* (iter % max_iter+1)*10\n\n"
},
{
"QuestionId": "76384866",
"QuestionTitle": "Set value of input control from input_group",
"QuestionBody": "I am trying to set this input control using $input_group.find('input'); but it is not getting set. Is this the correct way to use find and then set the value of the input control or is there anyway to do this?\n            var $container = $('#gridrow-field-container');\n            var template = $('#gridrow-template-input-group').get(0);\n\n            $(item.MeetingPollingPartsValues).each((indexPartsValues, PartsValues) => {\n                var $input_group = $(template.content.cloneNode(true));\n                var inputControl = $input_group.find('input');\n                inputControl.val(PartsValues.QuestionValue);\n\n                console.log(inputControl);\n\n                console.log($input_group);\n                $container.append($input_group);\n                $('input_group').val(PartsValues.QuestionValue);\n            });\n\n\n <template id=\"gridrow-template-input-group\">\n         <div class='row mb-3' id='newrowItem_1'>\n            <div class=\"input-group\">\n               <input type='text' id='fieldrowItem_1' name='name[]' class='form-control fieldrowItem mb-3' placeholder=\"Row 1\" data-value=\"0\" >\n               <span  id='spanrowItem_1' class=\"input-group-addon\" style=\"cursor:pointer;\"  onclick=\"RemoveRow(this)\"  >\n                  <i class=\"fa fa-remove\" style=\"color:#CDCDCD\"></i>\n              </span>\n         </div>\n         </div>\n </template>\n\n",
"AnswerId": "76385024",
"AnswerBody": "I added Bootstrap 5 dependencies and fixed the template.\nYou can clone the contents of the template with:\nconst $inputGroup = $template.contents().clone();\n\n\n\nconst $container = $('#gridrow-field-container');\nconst $template = $('#gridrow-template-input-group');\n\nconst RemoveRow = (span) => {\n  $(span).closest('.row').remove();\n}\n\nconst item = {\n  MeetingPollingPartsValues: [\n    { QuestionValue: 'One'   },\n    { QuestionValue: 'Two'   },\n    { QuestionValue: 'Three' }\n  ]\n};\n\n$(item.MeetingPollingPartsValues).each((index, partValue) => {\n  const $inputGroup = $template.contents().clone();\n  const $inputControl = $inputGroup.find('input');\n  $inputControl.val(partValue.QuestionValue);\n  $inputControl.attr('placeholder', `Row ${index + 1}`);\n  $inputControl.attr('data-value', partValue.QuestionValue);\n  $container.append($inputGroup);\n});\n<link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM\" crossorigin=\"anonymous\">\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\"/>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\" integrity=\"sha384-geWF76RCwLtnZ8qwWowPQNguL3RmwHVBC9FhGdlKrxdiJJigb/j/68SIy3Te4Bkz\" crossorigin=\"anonymous\"></script>\n<template id=\"gridrow-template-input-group\">\n  <div class=\"row\">\n    <div class=\"input-group mb-3\">\n      <input type=\"text\" name=\"name[]\" class=\"form-control\"\n          placeholder=\"Row x\" data-value=\"0\" >\n      <div class=\"input-group-text\" style=\"cursor:pointer;\" onclick=\"RemoveRow(this)\">\n        <i class=\"fa fa-remove\" style=\"color:#CDCDCD\"></i>\n      </div>\n    </div>\n  </div>\n</template>\n<div id=\"gridrow-field-container\" class=\"container\"></div>\n\n\n\n"
},
{
"QuestionId": "76384474",
"QuestionTitle": "How can I modify the inbuilt search bar of RenderDT in R Shiny to allow multiple entries separated by commas?",
"QuestionBody": "I have been trying to add multiple entries on the search bar of the renderdt table function on shiny.\nfor example on the following code, instead of having a new search bar, i want to modify the one which is inbuilt in renderDT and allow it to take multiple entries, comma separated; for example setosa,virginica should bring rows with both setosa and virginica. I found solutions to add a new search bar but i wanted to know if i can modify this one accordingly. Any help regarding this would be highly appreciated.\nif (interactive()) {\n  library(shiny)\n  library(DT)\n  shinyApp(\n    ui = fluidPage(fluidRow(column(12, DTOutput('tbl')))),\n    server = function(input, output) {\n      output$tbl = renderDT(\n        iris, options = list(lengthChange = FALSE)\n      )\n    }\n  )\n}\n\ni tried something like this, but this adds another search bar option and that is unnecessary\nif (interactive()) {\n  library(shiny)\n  library(DT)\n  \n  shinyApp(\n    ui = fluidPage(\n      fluidRow(DTOutput('tbl'))\n    ),\n    server = function(input, output) {\n      output$tbl = renderDT({\n        data <- iris\n        \n        searchItems <- unlist(strsplit(input$search, \",\")) # Split input string by commas\n        searchItems <- trimws(searchItems) # Remove leading/trailing whitespace\n        \n        filteredData <- data[data$Species %in% searchItems, ]\n        \n        datatable(filteredData, options = list(lengthChange = FALSE))\n      })\n    }\n  )\n}\n\n",
"AnswerId": "76385026",
"AnswerBody": "You can use this code:\nlibrary(shiny)\nlibrary(DT)\n\ncallback <- function(sep) {\n  sprintf('\n$(\"div.search\").append($(\"#mySearch\"));\n$(\"#mySearch\").on(\"keyup redraw\", function(){\n  var splits = $(\"#mySearch\").val().split(\"%s\").filter(function(x){return x !==\"\";})\n  var searchString = \"(\" + splits.join(\"|\") + \")\";\n  table.search(searchString, true).draw(true);\n});\n', sep)\n}\n\nui <- fluidPage(\n  tags$head(tags$style(HTML(\".search {float: right;}\"))),\n  br(),\n  tags$input(type = \"text\", id = \"mySearch\", placeholder = \"Search\"),\n  DTOutput(\"dtable\")\n)\n\nserver <- function(input, output){\n  \n  output[[\"dtable\"]] <- renderDT({\n    datatable(\n      iris[c(1, 2, 51, 52, 101, 102),],\n      options = list(\n        dom = \"l<'search'>rtip\"\n      ),\n      callback = JS(callback(\",\"))\n    )\n  }, server = FALSE)\n  \n}\n\nshinyApp(ui, server)\n\n\nPersonally I prefer the search builder:\ndatatable(\n  iris[c(1, 2, 51, 52, 101, 102),],\n  extensions = \"SearchBuilder\",\n  options = list(\n    dom = \"Qlfrtip\", \n    searchbuilder = TRUE\n  )\n)\n\n\n"
},
{
"QuestionId": "76383038",
"QuestionTitle": "Pytestfs write then read doesn't return expected value",
"QuestionBody": "I'm trying to write a test involving the filesystem. I chose to use pyfakefs and pytest for writing these tests. When I was trying to write and then read from the fake filesystem, I couldn't seem to get any tests to work. So, I wrote a simple test to ensure that pyfakefs was reading the right value:\ndef test_filesystem(fs):\n    with open(\"fooey.txt\", \"w+\") as my_file:\n        my_file.write(\"Hello\")\n        read = my_file.read(-1)\n        assert os.path.exists(\"fooey.txt\")\n        assert \"Hello\" in read\n\nThe first assertion passes. The second one fails. When I debug, read has a value of ''. I'm struggling to understand what's going on here. Does file writing or reading not work within pyfakefs? Am I doing something wrong?\n",
"AnswerId": "76383142",
"AnswerBody": "def test_filesystem(fs):\n    with open(\"fooey.txt\", \"w\") as my_file:\n        my_file.write(\"Hello\")\n        \n    with open(\"fooey.txt\", \"r\") as my_file:\n        read = my_file.read()\n        assert os.path.exists(\"hoklh\\\\fooey.txt\")\n        assert \"Hello\" in read\n\nThis should do it!\n"
},
{
"QuestionId": "76381054",
"QuestionTitle": "Adding numpy array to Pandas dataframe cell results in ValueError",
"QuestionBody": "I want to place a numpy array in a cell of a pandas dataframe.\nFor specific reasons, before assigning the array to the cell, I add another column in the same dataframe, whose values are set to NaN.\nCan someone help me understand what adding the column with the nans does to my data frame, why breaks the code, and how I can fix it?\nInserting an array into a column works:\nimport pandas as pd\nimport numpy as np\n\n#%% this works as expected\ndf = pd.DataFrame([0, 1, 2, 3, 4], columns=['a'])\ndf['a'] = df['a'].astype(object)\ndf.loc[4, 'a'] = np.array([5, 6, 7, 8])\ndf\n\nBut after inserting the column with nans, the same code breaks and I get the following error:\nValueError: Must have equal len keys and value when setting with an iterable\n#%% after adding a second column, x, filled with nan, the code breaks\ndf = pd.DataFrame([0, 1, 2, 3, 4], columns=['a'])\ndf['x'] = np.nan\ndf['a'] = df['a'].astype(object)\ndf.loc[4, 'a'] = np.array([5, 6, 7, 8])\ndf\n\nFinally, I want to add the array to the new column, but I get the same error.\n#%% this is what I want to do, breaks, too\ndf = pd.DataFrame([0, 1, 2, 3, 4], columns=['a'])\ndf['x'] = np.nan\ndf['x'] = df['x'].astype(object)\ndf.loc[4, 'x'] = np.array([5, 6, 7, 8])\ndf\n\n\n",
"AnswerId": "76381777",
"AnswerBody": "If you only need to set a single cell, use at:\ndf.at[4, 'a'] = np.array([5, 6, 7, 8])\n\n\n"
},
{
"QuestionId": "76381509",
"QuestionTitle": "How can I overwrite a file in a different folder using shutil.copy() and os.rename() in Python?",
"QuestionBody": "I have a script which outputs an excel file '.xlsx' containing various data. It generates a file with the date in the name in one folder, and then generates a copy, using shutil.copy(), in a separate folder. I then rename the file using os.rename(), however instead of overwriting the file already there, it produces the following error:\n\"FileExistsError: [WinError 183] Cannot create a file when that file already exists:\"\n\nI need the file to be exactly the same name everytime the script is run, as it is subsequently used as an automatic input file for PowerBI.\nCurrent code is as follows:\n# Select file you want to copy & where to copy it to\nsrc_file = vb.output_path\ndestination = vb.path_reports_cashflowcopy\n\n# Copy the file\nshutil.copy(src_file, destination)\n\n# Define copy path\ncashflow_copy_path = vb.ROOT_DIR + '\\\\Data_and_Reports\\\\Reports\\\\Cashflow Copies\\\\'\n\n# Rename the file\nos.rename(cashflow_copy_path + str(date.today()) + ' -  Lettings Report BETA - '  +       vb.academic_year_selection +  '.xlsx',\n          cashflow_copy_path + 'Copy ' + vb.academic_year_selection + '.xlsx')\n\nsrc_file is the original output excel file created.\nvb.xxxxxx is from a connected script which describes various file paths and other inputs used to name the files.\n",
"AnswerId": "76381781",
"AnswerBody": "To avoid the \"FileExistsError\" when renaming the file, you can check if the destination file already exists before renaming it.\nimport os\nimport shutil\nfrom datetime import date\n\n# Select file you want to copy & where to copy it to\nsrc_file = vb.output_path\ndestination = vb.path_reports_cashflowcopy\n\n# Copy the file\nshutil.copy(src_file, destination)\n\n# Define copy path\ncashflow_copy_path = vb.ROOT_DIR + '\\\\Data_and_Reports\\\\Reports\\\\Cashflow Copies\\\\'\n\n# Rename the file\nnew_file_name = cashflow_copy_path + 'Copy ' + vb.academic_year_selection + '.xlsx'\nexisting_file = cashflow_copy_path + str(date.today()) + ' -  Lettings Report BETA - ' + vb.academic_year_selection + '.xlsx'\n\nif os.path.exists(existing_file):\n    os.remove(existing_file) # Delete the existing file if it exists\n\nos.rename(src_file, new_file_name)\n\n"
},
{
"QuestionId": "76385031",
"QuestionTitle": "How to make the index from ngFor part of an html tag value",
"QuestionBody": "I have an ngFor loop set up like this:\n<div *ngFor=\"let record of this.RecordsProcessed; let i = index\">\n   <div class=\"row my-16\" data-test='test'_{{i}}>\n        <div class=\"col-4\">Id:</div>\n        <div class=\"col-8\">{{record?.Id}}</div>\n    </div>\n</div>\n\nI want to put the index from ngFor on the data-text tag within the html. Is it possible to do something like this within the html?\n",
"AnswerId": "76385105",
"AnswerBody": "Try like this:\n  <div *ngFor=\"let record of this.RecordsProcessed; let i = index\">\n  <div class=\"row my-16\" [attr.data-test]=\"'test_' + i\">\n       <div class=\"col-4\">Id:</div>\n       <div class=\"col-8\">{{record?.Id}}</div>\n   </div>\n</div>\n\n[] brackets let angular know that everything inside of \"\" is typescript code.\n"
},
{
"QuestionId": "76385070",
"QuestionTitle": "JavaScript - Code after case in switch statements",
"QuestionBody": "I am trying to decipher this code (MurmurHash) and came across the following lines:\nswitch (remainder) {\n    case 3: k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n    case 2: k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n    case 1: k1 ^= (key.charCodeAt(i) & 0xff);\n    \n    // When is this executed?\n\n    k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n    k1 = (k1 << 15) | (k1 >>> 17);\n    k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= k1;\n}\n\nMy question is as follows: I have never seen code inside a switch statement that is not part of either a case or a default and would greatly appreciate it if someone could explain when the part after the last case statement is supposed to get executed.\nIs it an alternative way of writing a default statement?\nOr will this always get executed, just as if it were written outside of the switch block?\nInformation on this topic seems very difficult to come by as documentation on switch statements generally deals with case and default, and it's also impossible to test without changing the code too much which might affect its behavior.\nThanks in advance!\n",
"AnswerId": "76385109",
"AnswerBody": "The code is part of case 1.\nPersonally I'd re-arrange the whitespace to be more clear:\nswitch (remainder) {\n  case 3:\n    k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n  case 2:\n    k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n  case 1:\n    k1 ^= (key.charCodeAt(i) & 0xff);\n    k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n    k1 = (k1 << 15) | (k1 >>> 17);\n    k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= k1;\n}\n\nThe point is that, without a break; in any of the cases, any matched case will execute and then control will flow to the next case.\nSo, assuming remainder can only be 1, 2, or 3...\n\nIf it's 3, all statements are executed.\nIf it's 2, case 3 is skipped but the rest is executed.\nIf it's 1, case 3 and case 2 are skipped but the rest is executed.\n\nThe logic is, perhaps a bit unintuitively, relying on the control flow of switch to continue on to the next (not-actually-matching) case.\n"
},
{
"QuestionId": "76382771",
"QuestionTitle": "Getting the correct order of factors for parametric terms in gratia::draw(parametric_effects())",
"QuestionBody": "I have a data set:\n   df<- structure(list(Depth = c(6.83999999999997, 8.56, 4.64999999999998, \n8.83999999999997, 6.56, 8.64999999999998, 12.21, 11.82, 5.41000000000003, \n11.63, 9.41000000000003, 11.26, 8.95999999999998, 10.81, 10.68, \n12.74, 14.06, 8.16000000000003, 12.31, 10.76, 10.74, 1, 9.38, \n5, 4, 12, 6.70999999999998, 8.56, 14.65, 16.71, 12.56, 18.65, \n20.21, 11.82, 13.41, 13.63, 13.41, 13.26, 22.96, 14.81, 20.74, \n30.06, 30.16, 32.31, 32.21, 14.76, 14.74, 4.66000000000003, 10, \n4, 15, 8.70999999999998, 32.65, 26.21, 29.82, 29.41, 5.63, 23.41, \n29.26, 2.95999999999998, 2.81, 2.68000000000001, 2.74000000000001, \n2.06, 2.16000000000003, 2.31, 4.20999999999998, 8.75999999999999, \n2.74000000000001, 18.66, 3, 4, 20, 6.83999999999997, 1, 6.64999999999998, \n6.20999999999998, 1.81999999999999, 1.41000000000003, 3.63, 3.41000000000003, \n5.25999999999999, 2.95999999999998, 2.81, 1, 2.74000000000001, \n4.06, 4.16000000000003, 4.31, 4.20999999999998, 2.75999999999999, \n2.74000000000001, 1, 5, 3, 4.70999999999998, 2.56, 2.64999999999998, \n10.21, 7.81999999999999), NEAR_DIST = c(18.77925552, 18.30180262, \n61.36019078, 179.2770495, 10.43166516, 17.9171804, 46.20571245, \n31.99340507, 10.43166516, 26.7170903, 24.47782541, 33.08965222, \n27.27138524, 43.4212158, 46.0670014, 50.11661352, 47.39692573, \n64.4374351, 49.66872737, 12.12884673, 15.13068812, 25.02246826, \n10.46189005, 13.46373164, 16.89230952, 13.51981867, 32.50661183, \n38.24201162, 38.5502434, 82.06185032, 49.57486607, 90.64395203, \n83.61730031, 49.74483449, 397.2686612, 53.49338859, 68.02475678, \n59.6583949, 130.7528811, 67.27058895, 111.2988217, 347.3593823, \n220.5169227, 268.5649787, 194.9220113, 84.48739079, 57.1344938, \n24.35529161, 54.84148996, 18.74063124, 66.63864028, 203.7119682, \n829.3788162, 309.4190672, 395.4959263, 326.7671063, 35.65309711, \n264.2374189, 307.025746, 23.02085763, 26.3683775, 22.93486062, \n25.28307029, 15.49632807, 14.59667995, 13.36925569, 11.9476145, \n152.7517309, 11.30381957, 74.36911773, 3.773174432, 6.825998674, \n79.40020637, 38.8451901, 3.853365482, 34.8719427, 38.02805106, \n21.06138328, 20.76016614, 37.60511548, 25.71672169, 41.9543577, \n26.1675823, 26.1675823, 16.49388675, 29.12695505, 29.12695505, \n25.21064884, 27.6250245, 25.21064884, 21.06138328, 18.59893184, \n11.08799823, 19.92747995, 16.25210115, 18.52964249, 5.582718512, \n10.11944373, 56.29794875, 36.03064946), Season2 = structure(c(3L, \n3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, \n1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, \n3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, \n2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, \n1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, \n4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, \n3L, 3L, 3L), levels = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"), class = c(\"ordered\", \n\"factor\"))), row.names = c(NA, -100L), class = c(\"tbl_df\", \"tbl\", \n\"data.frame\"))\n\nand am running a gam with the data:\nlibrary(mgcv)\nlibrary(gratia)\ngam<-gam(Depth~s(NEAR_DIST)+Season2,data=df)\n\neven though the Season2 variable is ordered:\nunique(df$Season2)\n[1] Summer Fall   Winter Spring\nLevels: Winter < Spring < Summer < Fall\n\nwhen I call:\ndraw(parametric_effects(gam))\n\nThe order of the x-axis is alphabetical.\n\nHow can I get the x-axis to match the order of my factor here? The old version of gratia used to do this. I have: version 0.8.1.34\n",
"AnswerId": "76383156",
"AnswerBody": "As a workaround or fix for your issue you could set the order using the limits argument of scale_x_discrete:\nlibrary(mgcv)\n#> Loading required package: nlme\n#> This is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.\nlibrary(gratia)\nlibrary(ggplot2)\n\npackageVersion(\"gratia\")\n#> [1] '0.8.1.34'\n\ngam <- gam(Depth ~ s(NEAR_DIST) + Season2, data = df)\n\ndraw(parametric_effects(gam)) +\n  ggplot2::scale_x_discrete(limits = levels(df$Season2))\n\n\n"
},
{
"QuestionId": "76383137",
"QuestionTitle": "Why I can't send data using submit button inside Form",
"QuestionBody": "I want to create simple react component with form inside, every time that user click Submit button, data should be send to the server.\nFor testing purposes I created component with two buttons, one stand alone and one inside form.\nreturn (\n    <>\n    <button onClick={submit}>Working example</button>\n    <form style={cellStyle}\n        onSubmit={submit}>\n                \n        <div>\n            <input type=\"submit\"\n                value={reactDict[\"send\"]}\n                className=\"btn btn-success\"\n                style={{ margin: \"15px 5px 5px 0px\" }} />\n        </div>\n    </form>\n    </>\n);\n\nBoth of them use same \"submit\" function\nconst submit = (event) => {\n    event.preventDefault();\n    const requestOptions = {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ test: 'some message' })\n    };\n\n    fetch(`neededitems`, requestOptions)\n        .then(async response => {\n            console.log(response);\n        })\n        .catch(error => {\n            console.error('There was an error!', error);\n        });\n}\n\nWhen I click button outside form everything works fine ,\nWhen I click submit button inside form I got an error .\n",
"AnswerId": "76383166",
"AnswerBody": "Add the attribute method=\"post\" to the  element.\n"
},
{
"QuestionId": "76384759",
"QuestionTitle": "What should be the C# equivalent of Rust's Box<> type?",
"QuestionBody": "I am translating Rust code into C#.\nRust has some type called Box<> which is said to be C++'s equivalent of smart pointers.\nWhat should be the C# equivalent of Rust's Box<> type?\n",
"AnswerId": "76385111",
"AnswerBody": "The short answer is that there isn't an exactly-equivalent type.\nBox is used to put a value on the heap.  There are several reasons why you would want to do that, but that's all it does.\nIn C#, reference types always point to a heap allocation.  \"Boxing\" is therefore pointless on reference types, as they are already effectively boxed.\nC# value types are instead allocated directly, either on the stack or directly inside an object's heap allocation if used as a non-static class field.  You can box a C# value type by casting it to a compatible reference type: either object or an interface type implemented by the value type.\nHowever, reference types in C# are not just boxed, they also have shared ownership as well as shared mutability and so C# reference types are closer to the Rust types that implement those behaviors, such as Rc<RefCell<T>> or Arc<Mutex<T>>, though there are still very relevant semantic differences between those types and C# reference types (Rc<_> can't be sent to other threads, Arc<Mutex<_>> has to be locked to access the inner value, both Rc and Arc can create reference cycles that could cause a memory leak, etc.).  Shared mutability in particular requires some kind of synchronization/atomicity to even pass the Rust compiler, where C# has no problem letting you create data races.\n\nIn other words, you need to look at why the value is boxed.\n\nIs it to enable polymorphism on a set of heterogeneous values (Box<dyn _>)?  Just use C# interfaces.\nIs it to enable a recursive structure?  Just use C# classes, which can self-recurse without issue.\n\n"
},
{
"QuestionId": "76383032",
"QuestionTitle": "Stripe Customer paymentMethod applied to its subscribers",
"QuestionBody": "This is a secondary question as I thought my previously answered question was resolved.\nHere is my use case:\n\nCustomer (office) buys physical products.  We collect the\ninformation on the mobile app and then the server creates a Stripe\nCustomer and a PaymentIntent.  This succeeds, as evidenced by\nStripe portal\nWhen the payment is finalized, my web hook event captures the “charge.succeeded”\nevent and it is my understanding that now that I have a\npaymentMethod I can set it up pay automatically with the confirm and\nredirect-url.  However, no attempt by me has been successful.\nI then create a subscriber, and I want to use the above customer payment\nmethod to manage the subscription payment.  The payment for this\nshows as incomplete, and I have to manually confirm it.\n\nHere is how I am handling the server side:\n\nCreate payment Intent:\n\nStripe.apiKey = API_SECRET_KEY;\nlong totalCharge = calcTotalCharge(purchaseRequest.getRequestedProducts());\nPaymentIntentCreateParams paymentIntentCreateParams = PaymentIntentCreateParams.builder()\n                .setCustomer(customer.getId())\n                .setAmount(totalCharge)\n                .setCurrency(\"usd\")\n                .setDescription(OFFICE_PURCHASE)\n                .setSetupFutureUsage(SetupFutureUsage.OFF_SESSION)\n                .setAutomaticPaymentMethods(PaymentIntentCreateParams.AutomaticPaymentMethods.builder()\n                                .setEnabled(true)\n                                .build())\n                .build();\n\nPaymentIntent paymentIntent = PaymentIntent.create(paymentIntentCreateParams);\nSetupIntentCreateParams setupIntentParms =\n                SetupIntentCreateParams.builder()\n                                       .setCustomer(customer.getId())\n                                       .addPaymentMethodType(\"card\")\n                                       .build();                                     \n\nSetupIntent setupIntent = SetupIntent.create(setupIntentParms);\n\nThis all appears to be correct.  I use the paymentIntento with the Stripe Elements to complete the order.  I I cannot set the confirm or auto payment because I don’t have the payment method at this point.\n\nWebhook event - this throws an exception: java.lang.RuntimeException: com.stripe.exception.InvalidRequestException: Received unknown parameters: enabled, returnUrl, confirm; code: parameter_unknown; request-id: req_My6nCQVFVNbsSgtry\n\ntry {\n  PaymentIntent paymentIntent = PaymentIntent.retrieve(charge.getPaymentIntent());\n  Map<String, Object> automaticPaymentMethods = new HashMap<>();\n  automaticPaymentMethods.put(\"enabled\", true);\n  automaticPaymentMethods.put(\"confirm\", true);\n  automaticPaymentMethods.put(\"returnUrl\", \"https://cnn.com”); <== this is just for Stripe   requirement, it does nothing\n  logger.info(\"webhook updating paymentIntent.automatic payment method as {} \", paymentIntent);\n} catch (StripeException e) {\nthrow new RuntimeException(e);\n}\n\nSo where I appear to be stuck is how do I set the customer paymentMethod to be applied as confirm automatically since the subscriber will not have the ability to confirm the payment.  I also was uncertain about a custom URL scheme or an universal link, despite the links you provided.\nUpdate to answer responses:\nWebhook does this when customer payment is received:\n(I am no longer trying to set the automaticPaymentMethods)\n PaymentIntent paymentIntent = PaymentIntent.retrieve(charge.getPaymentIntent());\npaymentIntent.getAutomaticPaymentMethods().setEnabled(true);\n\n String paymentMethod = charge.getPaymentMethod();\n String customerId = charge.getCustomer();\n Long chargeAmount = charge.getAmountCaptured();\n // now we can update the pending order with the paymentMethod\n try {\n   Customer customer = Customer.retrieve(customerId);\n   customer.update(CustomerUpdateParams.builder()\n   .setInvoiceSettings(InvoiceSettings.builder()\n   .setDefaultPaymentMethod(paymentMethod)\n   .build())\n   .build());\n  } catch (StripeException se) {\n    logger.error(\"unable to customer {} the paymentMethod {}\", customerId, paymentMethod);\n }\n\n",
"AnswerId": "76383179",
"AnswerBody": "In order to create Subscriptions with customer's attached payment method, you need to set it as default payment method for the customer. Specifically on customer.invoice_settings.default_payment_method parameter\nOnce you do that, the subscription should charge the default payment method on creation.\nFor your second question, I don't fully understand what you're trying to do exactly. Automatic Payment Methods parameter on a PaymentIntent only supports enabled property. So not sure why you're trying to set confirm and returnUrl there. Are you following a guide for this?\n"
},
{
"QuestionId": "76381709",
"QuestionTitle": "How to convert a jupyter notebook to a python script with cell delimiters (#%%)?",
"QuestionBody": "How to convert a jupyter notebook to a python script with cell delimiters (#%%)?\nI've already checked nbconvert , but it doesn't seem to have the one. Also, the same question found, the answer doesn't satisfy the need because actual raw source codes of jupyter notebook isn't structured as such. (It'd be better to be able to convert at once, instead of converting with nbconvert first and then pattern matching)\nAny tools recommended? Or could you share a script to achieve this?\n",
"AnswerId": "76381792",
"AnswerBody": "That looks similar to the percent delimiter that Jupytext handles, see the top few commands here also. The specific commands I'm referencing:\njupytext --to py:percent notebook.ipynb         # convert notebook.ipynb to a .py file in the double percent format\njupytext --to py:percent --opt comment_magics=false notebook.ipynb   # same as above + do not comment magic commands\n\nSee the bottom of the percent format section for more about that last command and further customization options.\n"
},
{
"QuestionId": "76385046",
"QuestionTitle": "How do I use itertools in Python to generate all possible variants of a list of keywords with leet code?",
"QuestionBody": "Python - How to make current script iterate through list of words instead of one string/word only?\nI am very new to python, and have put together a script parsing different scripts i've looked at.\nThe goal is to return all possible variants of a list of keywords, replacing the characters by leet code (e.g.: 'L33T' or 'l337' instead of 'Leet')\nI have been able to achieve this for one string/word only, but I wish to be able to input a list of keywords and obtain the same results.\nThis is my first time using Stack overflow, and I would really appreciate any help you can provide me :)\nHere is my code:\nimport itertools\n\ndef leet(word):\n    leet_matches = [['a','@','4','∆','Д','а','а','a','à'],\n    ['b','8','b','ḃ','ḅ','ḇ'],\n    ['c','<','{','[','(','©'],\n    ['d','d','ď','ḋ','ḍ','ḏ','ḑ','ḓ'],\n    ['e','3','£','₤','€','е'],\n    ['f','7','ƒ','ḟ'],\n    ['g','9','[','-','6','ĝ','ğ','ġ','ģ','ǧ','ǵ','ḡ'],\n    ['h','4','#','ĥ','ȟ','ḣ','ḥ','ḧ','ḩ','ḫ','ẖ'],\n    ['i','1','|','!','ì','í'],\n    ['j','√','ĵ','ǰ'],\n    ['k','ķ','ǩ','ḱ','ḳ','ḵ','ķ','ǩ','ḱ','ḳ','ḵ'],\n    ['l','1','|','ĺ','ļ','ľ','ḷ','ḹ','ḻ','ḽ'],\n    ['m','м','ḿ','ṁ','ṃ'],\n    ['n','И','и','п','ñ','ń','ņ','ň','ǹ','ṅ','ṇ','ṉ','ṋ'],\n    ['o','0','Ø','Θ','о','ө','ò','ó','ô','õ','ö','ō','ŏ','ő','ơ','ǒ','ǫ','ǭ'],\n    ['p','р','ṕ','ṗ'],\n    ['q','9','(',')','0'],\n    ['r','Я','®','ŕ','ŗ','ř','ȑ','ȓ','ṙ','ṛ','ṝ','ṟ'],\n    ['s','5','$','§','ś','ŝ','ş','š','ș','ṡ','ṣ','ṥ','ṧ','ṩ'],\n    ['t','7','+','т','ţ','ť','ț','ṫ','ṭ','ṯ','ṱ','ẗ'],\n    ['u','ù','ú','û','ü','ũ','ū','ŭ','ů','ű','ų','ư','ǔ','ǖ','ǘ'],\n    ['v'],\n    ['w','Ш','ŵ','ẁ','ẃ','ẅ','ẇ','ẉ','ẘ'],\n    ['x','×','%','*','Ж','ẋ','ẍ'],\n    ['y','¥','Ч','ү','у','ṽ'],\n    ['z','5','ź','ż','ž','ẑ']]\n    l = []\n    for letter in word:\n        for match in leet_matches:\n            if match[0] == letter:\n                l.append(match)\n    return list(itertools.product(*l))\n\nword = \"hola\"\ntest_list = leet(word)\n\ndef remove(string):\n    return string.replace(\" \", \"\")\n\nres = [''.join(tups) for tups in test_list]\nprint (str(res)+remove(str(res)))\n\n\nimport csv\nwith open ('leet_latinalphabet.csv', mode ='w') as csvfile:\n    fieldnames = ['leet variants']\n    writer = csv.DictWriter(csvfile,fieldnames=fieldnames)\n    writer.writeheader()\n    writer.writerow({\"leet variants\":str(res)[1:-1].replace(\"'\",\"\")})\n\n",
"AnswerId": "76385123",
"AnswerBody": "Loop over the list of words, calling leet() on each word.\nwords = ['hola', 'some', 'other', 'word']\n\nwith open ('leet_latinalphabet.csv', mode ='w') as csvfile:\n    fieldnames = ['word', 'leet variants']\n    writer = csv.DictWriter(csvfile,fieldnames=fieldnames)\n    writer.writeheader()\n    for word in words:\n        row = {\"word\": word, \"leet variants\": \",\".join(leet(word))}\n        writer.writerow(row)\n\n"
},
{
"QuestionId": "76382337",
"QuestionTitle": "ml-kit - barcode-scanning android - Google code scanner",
"QuestionBody": "I am using Google code scanner   Android MLKit for Barcode scanning. I am using below dependencies. I want the use bundled model so that initialisation time is not taken when app is launched. Is there a way can I use bundled version of model :\nPlease find below dependencies I used for this :\nimplementation 'com.google.android.gms:play-services-code-scanner:16.0.0'\nAndroidManifest:\n\nWhen I used the above dependencies , I see below exception during downloading the model:\nWaiting for the Barcode UI module to be downloaded.\nIs there a way can I use bundled version of model so that I need not wait for Barcode UI module to be downloaded. Please help me regarding this\nThanks in Adavance.\n",
"AnswerId": "76383224",
"AnswerBody": "What about this:\ndependencies {\n  // ...\n  // Use this dependency to bundle the model with your app\n  implementation 'com.google.mlkit:barcode-scanning:17.1.0'\n}\n\nFound at: https://developers.google.com/ml-kit/vision/barcode-scanning/android\n"
},
{
"QuestionId": "76381596",
"QuestionTitle": "Spring Rest Validation ObjectNode data size limit",
"QuestionBody": "I have rest controller with token creation call. Here inside ObjectNode I get big json data. The database column is varchar2(4000) nad I want limit this ObjectNode size to 4000 adding validation at controller level. Not sure how to do this?\ndata class TokenRequest(\n    @NotEmpty(message = \"id is mandatory\")\n    open val id: String,\n    @NotEmpty(message = \"gameId is mandatory\")\n    open val game: String,\n    @NotEmpty(message = \"gameType is mandatory\")\n    open val type: String,\n    @NotEmpty(message = \"gameDate is mandatory\")\n    open val date: String,\n    @NotEmpty(message = \"coupon is mandatory\")\n    open val token: ObjectNode,\n)\nclass TokenController {\nfun createToken(@Valid @RequestBody request: TokenRequest): Token {\n        val now = Token.generateNowTimestamp()\n        val token = Token.fromTokenRequest(request, now, now, request.teamId)\n        return tokenService.create(token)\n    }\n}\n\n",
"AnswerId": "76381793",
"AnswerBody": "It sounds like you're trying to cap the size of the JSON data contained in the 'token' field of your request. You want it to be no more than 4000 characters, right? There's actually a way to handle this in Kotlin by creating your own validation annotation. Here's how:\nFirst, you need to create the annotation itself:\n@Target(AnnotationTarget.FIELD)\n@Retention(AnnotationRetention.RUNTIME)\n@MustBeDocumented\n@Constraint(validatedBy = [JsonNodeLengthValidator::class])\nannotation class MaxJsonLength(\n    val message: String = \"JSON Object is too big\",\n    val groups: Array<KClass<*>> = [],\n    val payload: Array<KClass<out Payload>> = [],\n    val value: Int = 4000\n)\n\nThen, we'll make a custom validator for it:\nimport com.fasterxml.jackson.databind.node.ObjectNode\nimport javax.validation.ConstraintValidator\nimport javax.validation.ConstraintValidatorContext\n\nclass JsonNodeLengthValidator : ConstraintValidator<MaxJsonLength, ObjectNode> {\n\n    private var maxLength: Int = 0\n\n    override fun initialize(annotation: MaxJsonLength) {\n        this.maxLength = annotation.value\n    }\n\n    override fun isValid(node: ObjectNode?, context: ConstraintValidatorContext): Boolean {\n        return node?.toString()?.length ?: 0 <= maxLength\n    }\n}\n\nFinally, we'll use our shiny new validator annotation in your data class:\ndata class TokenRequest(\n    @NotEmpty(message = \"id is mandatory\")\n    open val id: String,\n    @NotEmpty(message = \"gameId is mandatory\")\n    open val game: String,\n    @NotEmpty(message = \"gameType is mandatory\")\n    open val type: String,\n    @NotEmpty(message = \"gameDate is mandatory\")\n    open val date: String,\n    @NotEmpty(message = \"coupon is mandatory\")\n    @MaxJsonLength(value = 4000, message = \"Token JSON object is too big\")\n    open val token: ObjectNode,\n)\n\nSo there you have it! This makes sure that your TokenRequest validation will fail if the JSON string of token goes beyond 4000 characters. If it does, you'll get a validation error. Hope this helps!\n"
},
{
"QuestionId": "76384241",
"QuestionTitle": "Not able to format YAML using SnakeYaml keeping original way",
"QuestionBody": "Have following YAML\nimage:\n  repository: \"test.com/test\"\n  pullPolicy: IfNotPresent\n  tag: \"abc\"\n\nJAVA code to modify the YAKL file\npublic class SnakeYaml1 {\n\n    public static void main(String[] args) throws FileNotFoundException {\n        // TODO Auto-generated method stub\n        \n        InputStream inputStream = new FileInputStream(new File(\"C:\\\\yaml\\\\student1.yaml\"));\n        \n        Yaml yaml = new Yaml(new Constructor(Values1.class));\n    \n        Values1 data = yaml.load(inputStream);\n        Image image = new Image();\n        image.setPullPolicy(\"update\");\n        data.setImage(image);\n        \n        DumperOptions options = new DumperOptions();\n        options.setIndent(2);\n        options.setDefaultFlowStyle(DumperOptions.FlowStyle.FLOW);\n        options.setIndicatorIndent(2);\n        options.setIndentWithIndicator(true);\n        \n        PrintWriter writer = new PrintWriter(new File(\"C:\\\\yaml\\\\student1.yaml\"));\n        Yaml yaml1 = new Yaml(new Constructor(Values1.class));\n        yaml1.dump(data, writer);\n\n    }\n}\n\n\npublic class Values1 {\n    \n    private Image image;\n\n    public Image getImage() {\n        return image;\n    }\n\n    public void setImage(Image image) {\n        this.image = image;\n    }\n}\n\npublic class Image {\n    \n    private String repository;\n    private String pullPolicy;\n    private String tag;\n    \n    public Image()\n    {   \n    }\n    \n    public Image (String repository, String pullPolicy, String tags)\n    {\n        super();\n        this.repository = repository;\n        this.pullPolicy = pullPolicy;\n        this.tag = tags;\n        \n    }\n    \n    public String getRepository() {\n        return repository;\n    }\n    public void setRepository(String repository) {\n        this.repository = repository;\n    }\n    public String getPullPolicy() {\n        return pullPolicy;\n    }\n    public void setPullPolicy(String pullPolicy) {\n        this.pullPolicy = pullPolicy;\n    }\n    public String getTag() {\n        return tag;\n    }\n    public void setTag(String tag) {\n        this.tag = tag;\n    }\n    \n\n}\n\nAFter executing the java code , the YAML format is getting changed\nYAML format after executing JAVA code\n!!oe.kubeapi.abc.Values1\nimage: {pullPolicy: update, repository: null, tag: null}\n\nExpected YAML format after execution of java code\nimage:\n      repository: \"test.com/test\"\n      pullPolicy: update\n      tag: \"abc\"\n\nNot getting why the YAML format is getting changed after executing java code. Is this the bug in SnakeYaml ??\nI tried putting property image in List format as well , List<Image> image still it did not work\nplease suggest . what should be done . Any help please ?\n",
"AnswerId": "76385126",
"AnswerBody": "Well, you mentioned it is SnakeYaml lib, so I wonder have you ever looked through its documentation ?\nYour code works as it should.\ntry:\n DumperOptions options = new DumperOptions();\n options.setDefaultFlowStyle(DumperOptions.FlowStyle.BLOCK);\n Yaml yaml  = new Yaml(options);\n\n"
},
{
"QuestionId": "76378684",
"QuestionTitle": "Harbor registry proxy cache vs replication",
"QuestionBody": "I'm new to Harbor registry. I was asked to propose an architecture for harbor in my company. I proposed at first to use an architecture based on proxy cache. But the CISO refused to use proxy cache for the entreprise without saying why. I proposed anoter architecture based on replication. We validate some base images that are pulled from public registries and pushed into our harbor registry ( One active harbor that pulls the images from internet and another passive harbor for high avalibility + 4 other harbors that leaves in special network zones (they get the images form the master harbor)).\nThe question is why the ciso refused the use of proxy cache ? is there any drawbacks for using it ? what are the security risks that can appear using the harbor proxy cache vs replication ? I cant find in the internet clear informations about this question. It seems that the majority is using proxy cache.\nThank you!\n",
"AnswerId": "76383239",
"AnswerBody": "At this stage one can only speculate, about the unprofessional behavior of not explaining the reasons and also for not asking.\nRegarding Harbor proxy and replication, the main difference between both option is the difference of threat surface and its control.\nProxy\n\nPassive, forwards requests upstream if not found locally.\nNo control,\n\nReplication\n\nActive, explicitly specify the images you want to copy from upstream\nFull control\n\n"
},
{
"QuestionId": "76383101",
"QuestionTitle": "Reshaping a Dataframe with repeating column names",
"QuestionBody": "I have data that looks like this:\n    dataframe_1:                \n    week    SITE        LAL SITE     LAL\n0   1   BARTON CHAPEL   1.1 PENASCAL I  1\n1   2   BARTON CHAPEL   1.1 PENASCAL I  1\n2   3   BARTON CHAPEL   1.1 PENASCAL I  1\n\nAnd, i need the final dataframe to look like this:\n    dataframe_2:        \n    week    SITE    LAL\n0   1   BARTON CHAPEL   1.1\n1   2   BARTON CHAPEL   1.1\n2   3   BARTON CHAPEL   1.1\n3   1   PENASCAL I  1\n4   2   PENASCAL I  1\n5   3   PENASCAL I  1\n\nI've tried using 'melt' but I cannot get the desire result. Perhaps I'm using the wrong approach?\nthank you,\n",
"AnswerId": "76383250",
"AnswerBody": "Not a very generalizable solution, but will work on your example:\ndf.groupby('week').apply( lambda _df : pd.concat((_df.iloc[:,1:3], _df.iloc[:,3:5]))).reset_index('week')\n\nit groups by week and then reshapes with column selection + concatenation. Removing a superfluous index column in the end.\n"
},
{
"QuestionId": "76381742",
"QuestionTitle": "How to set a timeout for a popup and close if user clicks elsewhere?",
"QuestionBody": "I created a popup that appears when I click a button, but to make it disappear I have to click again. Is there a way to set a timer and make it disappear?\nFunction:\n// When the user clicks on div, open the popup\nfunction myFunction() {\n  var popup = document.getElementById(\"myPopup\");\n  popup.classList.toggle(\"show\");\n}\n\nStyle:\n.popuptext {\n  display: none;\n}\n.popuptext.show {\n  display: block;\n}\n\nThe HTML:\n<div class=\"popup\" onclick=\"myFunction()\">Click me to toggle the popup!\n  <span class=\"popuptext\" id=\"myPopup\">A Simple Popup!</span>\n</div>\n\nI need the popup to close after 10 seconds OR when the user clicks somewhere else.\nI edited the code to below and it does close after 10 seconds, how to achieve the second part (close when user clicks somewhere else):\nfunction myFunction() {\nvar popup = document.getElementById(\"myPopup\");\npopup.classList.toggle(\"show\");\nif(popup.classList.contains(\"show\"))\n    setTimeout(() => popup.classList.remove(\"show\"), 10000)\n}\n\n",
"AnswerId": "76381799",
"AnswerBody": "To do this you need to:\n\nDefine a function, hide() that hides the popup.\nAdd an mousedown event listener to the whole document that invokes hide\n\nWithin hide, ensure that the click event's target is not contained in the popup.\n\n\nSet up the timeout to call hide\nImportant: Have hide clear the created timeout and remove the listener that was added.\n\n\n\nfunction myFunction() {\n  var popup = document.getElementById(\"myPopup\");\n  popup.classList.add('show')\n  \n  let timeout;\n  \n  function hide(e) {\n    if (popup.contains(e.target)) return;\n\n    popup.classList.remove(\"show\");\n    document.removeEventListener('mousedown', hide);\n    clearTimeout(timeout)\n  }\n  document.addEventListener('mousedown', hide)\n  timeout = setTimeout(hide, 10000)\n}\n.popuptext {\n  display: none;\n}\n\n.popuptext.show {\n  display: block;\n}\n<div class=\"popup\" onclick=\"myFunction()\">Click me to toggle the popup!\n  <span class=\"popuptext\" id=\"myPopup\">A Simple Popup!</span>\n</div>\n\n\n\n"
},
{
"QuestionId": "76382658",
"QuestionTitle": "3-d array with different size of row and column",
"QuestionBody": "i am making a three-d array the problem i am facing is i want to create multiple 3-d array however with varying size of row and column so the first matrix size could be 0-2-2 while next matrix could be say 1-1-3 so on..\nkindly do not suggest making a large matrix that could have value of all the row and columns.\ni personally have tried using structure to create the code, i have defined 2-d array( for row and column) in the structure and then stored it in variable e[1].array(2-d), i have used for loop to continuously change value of row and column in array based on user input, the problem i am facing is every time the for loop changes value to next the code over writes itself hence previous values  of array can not be called so if for first matrix the size of row and column was 2-2 and next is 1-3 so e[1].x[2][2] have some value then for second loops e[1].x[1][3] the dimensions of x have been re-defined hence i could not call x[2][2].\nkindly suggest ways i could store 3-d array with different size of row and column for each matrix.\n int main()\n {\n int matrix;\n printf(\"ENTER NUMBER OF MATRICES\\n\");\n scanf(\"%d`\", &matrix);\n int row, column;\n\n\nfor (int m = 0; m < matrix; m++) {\n    printf(\"ENTER NUMBER OF ROWS IN %d MATRICE\\n\", m + 1);\n    scanf(\"%d\", &row);\n    printf(\"ENTER NUMBER OF column IN %d MATICE\\n\", m + 1);\n    scanf(\"%d\", &column);\n     struct x {\n  int f[row][column];\n};\n    struct x k[m];\n    int g = 1;\n\n    printf(\"ENTER ALL ELEMENT LEFT TO RIGHT\\n\");\n    for (int j = 0; j < row; j++) {\n        \n        for (int u = 0; u < column; u++) {\n            \n            printf(\"%d)\\n\", g);\n            scanf(\"%d\", &k[m].f[j][u]);\n            g = g + 1;\n        }\n    }\n    for (int s = 0; s < row; s++) {\n        printf(\"|\");\n        for (int l = 0; l < column; l++) {\n             \n            printf(\"%d\", k[m].f[s][l]);\n            if (l < column - 1) {\n                printf(\"  \");\n                \n            }\n        }\n        printf(\"|\\n\");\n        \n    }\n    printf(\"%d\", k[0].f[0][0]); // error here calling over written \n value\n }\n  return 0;\n\nexpectation:\n ENTER NUMBER OF MATRICES\n 2\n ENTER NUMBER OF ROWS IN 1 MATRICE\n 2\n ENTER NUMBER OF column IN 1 MATICE\n 2\n ENTER ALL ELEMENT LEFT TO RIGHT  \n 1)\n 1\n 2)\n 2\n 3)\n 3      4\n 4)\n 4\n |1  2|\n |3  4|\n ENTER NUMBER OF ROWS IN 2 MATRICE\n 1\n ENTER NUMBER OF column IN 2 MATICE\n 3\n ENTER ALL ELEMENT LEFT TO RIGHT\n 1)\n 5\n 2)\n 6\n 3)\n 7\n |5  6  7|\n 1 // error here in output\n\n",
"AnswerId": "76383281",
"AnswerBody": "Since each matrix may be a different size, you should manage each matrix separately and record its dimensions separately. The code below shows how to use a structure type to do that.\nCommon C implementations support variable length arrays, so you use this to make addressing the matrix elements simpler. The program below shows how to use a pointer to a variable length array to point to the rows of a matrix. The memory address is recorded in the structure using void *, because we cannot have a variably modified type in the structure, but a separate variable is declared where it is needed, and it is set to the start of memory for the matrix.\nIn the absence of using variable length arrays, you would have to address the elements using manual arithmetic calculations into a linear array.\n#include <stdio.h>\n#include <stdlib.h>\n\n\nint main(void)\n{\n    // Read the number of matrices.\n    int NMatrices;\n    printf(\"Enter the number of matrices:  \");\n    if (1 != scanf(\"%d\", &NMatrices))\n    {\n        fprintf(stderr, \"Error, scanf for number of matrices failed.\\n\");\n        exit(EXIT_FAILURE);\n    }\n    if (NMatrices < 0)\n    {\n        fprintf(stderr, \"Error, number of matrices is negative.\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Define a type to manage a matrix.\n    struct MatrixInformation\n    {\n        void *Memory;        // Memory for the matrix.\n        int NRows, NColumns; // Number of rows and number of columns.\n    };\n\n    // Allocate memory to manage NMatrices matrices.\n    struct MatrixInformation *Matrices = malloc(NMatrices * sizeof *Matrices);\n    if (!Matrices)\n    {\n        fprintf(stderr, \"Error, failed to allocate memory.\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Read each matrix.\n    for (int m = 0; m < NMatrices; ++m)\n    {\n        // Read the number of rows and the number of columns of this matrix.\n        int NRows, NColumns;\n        printf(\"Enter the number of rows in matrix %d:  \", m+1);\n        if (1 != scanf(\"%d\", &NRows))\n        {\n            fprintf(stderr, \"Error, scanf for number of rows failed.\\n\");\n            exit(EXIT_FAILURE);\n        }\n        if (NRows <= 0)\n        {\n            fprintf(stderr, \"Error, number of rows is not positive.\\n\");\n            exit(EXIT_FAILURE);\n        }\n        printf(\"Enter the number of columns in matrix %d:  \", m+1);\n        if (1 != scanf(\"%d\", &NColumns))\n        {\n            fprintf(stderr, \"Error, scanf for number of columns failed.\\n\");\n            exit(EXIT_FAILURE);\n        }\n        if (NColumns <= 0)\n        {\n            fprintf(stderr, \"Error, number of columns is not positive.\\n\");\n            exit(EXIT_FAILURE);\n        }\n\n        // Create a temporary pointer for the matrix and allocate memory.\n        int (*Matrix)[NColumns] = malloc(NRows * sizeof *Matrix);\n        if (!Matrix)\n        {\n            fprintf(stderr, \"Error, failed to allocate memory.\\n\");\n            exit(EXIT_FAILURE);\n        }\n\n        // Save the numbers of rows and columns and the memory address.\n        Matrices[m].NRows = NRows;\n        Matrices[m].NColumns = NColumns;\n        Matrices[m].Memory = Matrix;\n\n        // Get the values for the matrix elements.\n        for (int r = 0; r < NRows; ++r)\n            for (int c = 0; c < NColumns; ++c)\n            {\n                printf(\"Enter the element [%d, %d]:  \", r+1, c+1);\n                if (1 != scanf(\"%d\", &Matrix[r][c]))\n                {\n                    fprintf(stderr, \"Error, scanf for element failed.\\n\");\n                    exit(EXIT_FAILURE);\n                }\n            }\n    }\n\n    // Print each matrix.\n    for (int m = 0; m < NMatrices; ++m)\n    {\n        printf(\"Matrix %d:\\n\", m+1);\n\n        // Get the numbers of rows and columns and the memory address.\n        int NRows = Matrices[m].NRows;\n        int NColumns = Matrices[m].NColumns;\n        int (*Matrix)[NColumns] = Matrices[m].Memory;\n\n        // Print each row.\n        for (int r = 0; r < NRows; ++r)\n        {\n            // Start each row with a delimiter and no spaces.\n            printf(\"|%d\", Matrix[r][0]);\n\n            // Print each element with two spaces for separation.\n            for (int c = 1; c < NColumns; ++c)\n                printf(\"  %d\", Matrix[r][c]);\n\n            // Finish each row with a delimiter and a new-line character.\n            printf(\"|\\n\");\n        }\n    }\n\n    // Free the memory of each matrix.\n    for (int m = 0; m < NMatrices; ++m)\n        free(Matrices[m].Memory);\n\n    // Free the memory for the array of structures about the matrices.\n    free(Matrices);\n}\n\n"
},
{
"QuestionId": "76385092",
"QuestionTitle": "Index of .iloc API in Pandas",
"QuestionBody": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 400 entries, 0 to 399\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   CompPrice    400 non-null    int64 \n 1   Income       400 non-null    int64 \n 2   Advertising  400 non-null    int64 \n 3   Population   400 non-null    int64 \n 4   Price        400 non-null    int64 \n 5   ShelveLoc    400 non-null    object\n 6   Age          400 non-null    int64 \n 7   Education    400 non-null    int64 \n 8   Urban        400 non-null    object\n 9   US           400 non-null    object\n 10  HighSales    400 non-null    object\ndtypes: int64(7), object(4)\nmemory usage: 34.5+ KB\n\nAs shown in the info() result above, there are 11 columns indexed from 0 to 10 in my dataset, DF. Now, I would like to extract only the first 10 columns (that are the columns with the indices 0 to 9). However, when I try to use the code below:\nDF.iloc[:, 0:9]\n\nIt returns only the first 9 columns (that is, from CompPrice to Urban).\nIn this case, I need to change my code to:\nDF.iloc[:, 0:10]\n\nto get what I actually want (that is, from CompPrice to US).\nI'm really confused by iloc() indices. Why it requires '10' instead '9' but starts with the index '0'. The starting and ending indices are not consistent.\n",
"AnswerId": "76385129",
"AnswerBody": "What you are observing is the standard functionality of pandas. If you look in the documentation, you can find the definition. This is intended and logical, as Python lists function the same way. As per the docs:\n\n.iloc is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with Python/NumPy slice semantics).\n\n"
},
{
"QuestionId": "76380777",
"QuestionTitle": "Ruby IPAddr class accepting wrong IPv6 address string",
"QuestionBody": "We are middle of upgrading ruby versions v2.7.3 -> v3.1.3\nOne of our test cases are failing related to valid ipv6 address string, check the following\n# ruby 2.7.3\nIPAddr.new('fe80::85e:7530:69ec:9074%en0').ipv6?\n=> IPAddr::InvalidAddressError (invalid address: fe80::85e:7530:69ec:9074%en0)\n\n# ruby 3.1.3\n\nIPAddr.new('fe80::85e:7530:69ec:9074%en0').ipv6?\n=> true\n\nIs it really a bug or am I missing something? Please help..\n",
"AnswerId": "76381845",
"AnswerBody": "\nIs it really a bug or am I missing something?\n\nThis used to be an issue in the ipaddr default gem up to version 1.2.2 which was fixed in version 1.2.3 in order to be fully compliant with RFC 4007 and RFC 6874. Version 1.2.3 of the ipaddr default gem was shipped as part of Ruby 3.1.0.\nSo, you are correct. This is a bug (although opinions differ on that) which was fixed in ipaddr 1.2.3 / Ruby 3.1.0.\n"
},
{
"QuestionId": "76383210",
"QuestionTitle": "Why does pandas `date_range` rounds up to the next month?",
"QuestionBody": "When using pandas.date_range with start date, frequency, and periods the date range rounds up when using the start date as the last day of a month.\nIt seems like a silent edge case bug. If it's not a bug, any idea why it does that?\nFor example\nimport pandas as pd\n\nstart_date = pd.Timestamp(2023, 5, 31)\ndate_range = pd.date_range(start=start_date, freq=\"MS\", periods=6)\n\nresults in\nDatetimeIndex(['2023-06-01', '2023-07-01', '2023-08-01', '2023-09-01',\n               '2023-10-01', '2023-11-01'],\n              dtype='datetime64[ns]', freq='MS')\n\nFrom the documentation, I'd expect it to start in May and end in October:\nDatetimeIndex(['2023-05-01', '2023-06-01', '2023-07-01', '2023-08-01', '2023-09-01',\n               '2023-10-01'],\n              dtype='datetime64[ns]', freq='MS')\n\nI thought it had to do with the inclusive argument but that's not the reason either.\n",
"AnswerId": "76383298",
"AnswerBody": "pd.date_range is to generate a range of date between start and end. 2023-05-01 is less than start date 2023-05-31, it will never reach it. To do what you want, you can replace the day of pd.Timestamp by 1.\nstart_date = pd.Timestamp(2023, 5, 31)\ndate_range = pd.date_range(start=start_date.replace(day=1), freq=\"MS\", periods=6)\n\nprint(date_range)\n\nDatetimeIndex(['2023-05-01', '2023-06-01', '2023-07-01', '2023-08-01',\n               '2023-09-01', '2023-10-01'],\n              dtype='datetime64[ns]', freq='MS')\n\n"
},
{
"QuestionId": "76383232",
"QuestionTitle": "What is the bug in my Persistent UTM Code?",
"QuestionBody": "I am using the following code to persist utms across my website. However i notice that its adding a question mark to links even without the UTM parameters. Can someone help me figure out what in this code needs to change. It should only be trying to add UTM parameters to the links if there is one present in the URL.\n <script>\n(function() {\n  var domainsToDecorate = [\n          'example.com'\n      ],\n      queryParams = [\n          'utm_medium', //add or remove query parameters you want to transfer\n          'utm_source',\n          'utm_campaign',\n          'utm_content',\n          'utm_term'\n      ]\n  // do not edit anything below this line\n  var links = document.querySelectorAll('a'); \n\n// check if links contain domain from the domainsToDecorate array and then decorates\n  for (var linkIndex = 0; linkIndex < links.length; linkIndex++) {\n      for (var domainIndex = 0; domainIndex < domainsToDecorate.length; domainIndex++) { \n          if (links[linkIndex].href.indexOf(domainsToDecorate[domainIndex]) > -1 && links[linkIndex].href.indexOf(\"#\") === -1) {\n              links[linkIndex].href = decorateUrl(links[linkIndex].href);\n          }\n      }\n  }\n// decorates the URL with query params\n  function decorateUrl(urlToDecorate) {\n      urlToDecorate = (urlToDecorate.indexOf('?') === -1) ? urlToDecorate + '?' : urlToDecorate + '&';\n      var collectedQueryParams = [];\n      for (var queryIndex = 0; queryIndex < queryParams.length; queryIndex++) {\n          if (getQueryParam(queryParams[queryIndex])) {\n              collectedQueryParams.push(queryParams[queryIndex] + '=' + getQueryParam(queryParams[queryIndex]))\n          }\n      }\n      return urlToDecorate + collectedQueryParams.join('&');\n  }\n\n\n  // a function that retrieves the value of a query parameter\n  function getQueryParam(name) {\n      if (name = (new RegExp('[?&]' + encodeURIComponent(name) + '=([^&]*)')).exec(window.location.search))\n          return decodeURIComponent(name[1]);\n  }\n\n})();\n</script>\n\n",
"AnswerId": "76383300",
"AnswerBody": "In decorateUrl you are adding the ? if there is not one\nurlToDecorate = (urlToDecorate.indexOf('?') === -1) ? urlToDecorate + '?' : urlToDecorate + '&';\n\nI would suggest you may only want to do this if collectedQueryParams contains any elements\n function decorateUrl(urlToDecorate) {\n      var collectedQueryParams = [];\n      for (var queryIndex = 0; queryIndex < queryParams.length; queryIndex++) {\n          if (getQueryParam(queryParams[queryIndex])) {\n              collectedQueryParams.push(queryParams[queryIndex] + '=' + getQueryParam(queryParams[queryIndex]))\n          }\n      }\n\n      if(collectedQueryParams.length == 0){\n        return urlToDecorate;\n      }\n\n      //only add the ? if we have params AND if there isn't already one\n      urlToDecorate = (urlToDecorate.indexOf('?') === -1) ? urlToDecorate + '?' : urlToDecorate + '&';\n      return urlToDecorate + collectedQueryParams.join('&');\n  }\n\n"
},
{
"QuestionId": "76385033",
"QuestionTitle": "How can I convert ISCII encoding to unicode for Gujarati language in Python 3?",
"QuestionBody": "I have some Gujarati string but its in ISCII encoding, so python throughing error (SyntaxError: invalid decimal literal).\nstring = TFH[TZDF\\ I]GF.8[0 G[Xg;\n\nline 1\n    string = TFH[TZDF\\ I]GF.8[0 G[Xg;\n                      ^\nSyntaxError: unexpected character after line continuation character\n\nI was tried byte encoding too, but its not giving output like ISCII encoding.\nI am trying this to make ISCII into unicode for Gujarati language.\nI have ISCII based font and character map data also.\nISCII input string: TFH[TZDF\\ I]GF.8[0 G[Xg;\nDesired unicode output: તાજેતરમાં યુનાઇટેડ નેશન્સ (Typed using gujarati phonetic keyboard)\n",
"AnswerId": "76385142",
"AnswerBody": "If you just want to write the string literal, for me, just writing print(\"તાજેતરમાં યુનાઇટેડ નેશન્સ\") worked.\nOr you could write:\ncharacters = [2724, 2750, 2716, 2759, 2724, 2736, 2734, 2750, 2690, 32, 2735, 2753, 2728, 2750, 2695, 2719, 2759, 2721, 32, 2728, 2759, 2742, 2728, 2765, 2744]\nstring = str()\nfor c in characters:\n        string += chr(c)\n\nMaybe you have a look at this conversion script:\nhttps://gist.github.com/pathumego/81672787807c23f19518c622d9e7ebb8\n"
},
{
"QuestionId": "76381570",
"QuestionTitle": "Extracting vcf columns substring with awk",
"QuestionBody": "I have vcf file like this:\n##bcftools_annotateVersion=1.3.1+htslib-1.3.1\n##bcftools_annotateCommand=annotate \n#CHROM  POS ID  REF ALT QUAL    FILTER  INFO    FORMAT  HG005\nchr1    817186  rs3094315   G   A   50  PASS    platforms=2;platformnames=Illumina,CG;datasets=3;datasetnames=HiSeq250x250,CGnormal,HiSeqMatePair;callsets=5;callsetnames=HiSeq250x250Sentieon,CGnormal,HiSeq250x250freebayes,HiSeqMatePairSentieon,HiSeqMatePairfreebayes;datasetsmissingcall=IonExome,SolidSE75bp;callable=CS_HiSeq250x250Sentieon_callable,CS_CGnormal_callable,CS_HiSeq250x250freebayes_callable;AN=2;AF=1;AC=2 GT:PS:DP:ADALL:AD:GQ    1/1:.:809:0,363:78,428:237\nchr1    817341  rs3131972   A   G   50  PASS    platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeq250x250,CGnormal,HiSeqMatePair,SolidSE75bp;callsets=6;callsetnames=HiSeq250x250Sentieon,CGnormal,HiSeq250x250freebayes,HiSeqMatePairSentieon,HiSeqMatePairfreebayes,SolidSE75GATKHC;datasetsmissingcall=IonExome;callable=CS_HiSeq250x250Sentieon_callable,CS_CGnormal_callable,CS_HiSeq250x250freebayes_callable;AN=2;AF=1;AC=2   GT:PS:DP:ADALL:AD:GQ    1/1:.:732:1,330:99,391:302\n\nI need to extract ID column and  AN from INFO column to get:\nID         INFO\nrs3094315   2\nrs3131972   2\n\nI'm trying something like this awk '/^[^#]/ { print $3, gsub(/^[^AN=])/,\"\",$8)}' file.vcf, but still not getting the desired result.\n",
"AnswerId": "76381846",
"AnswerBody": "You can try this awk:\nawk 'BEGIN{OFS=\"\\t\"}\n/^##/{next}\n/^#/{print $3,$8; next}\n{\n    split($8,a,\";\")\n    for(i=1;i<=length(a);i++) if (a[i]~/^AN=/) {sub(/^AN=/,\"\",a[i]); break}\n    printf \"%s%s%s\\n\", $3, OFS, a[i]\n}\n' file\n\nWith the example, prints:\nID  INFO\nrs3094315   2\nrs3131972   2\n\n"
},
{
"QuestionId": "76384930",
"QuestionTitle": "Load AVAsset video in the background and replace playing placeholder video once it's playable in Swift and RealityKit",
"QuestionBody": "I'm using the following code to create a video player for detected reference images in AR session. Currently I display a placeholder video and after 1 second switch to real video that I want played. However, I would like to show the placeholder video until the real video is ready to be played.\nI tried experimenting with AVAsset and observing the playable status based on this: Knowing when AVPlayer object is ready to play - however I didn't have any success.\n        func createVideoNode(_ target: ARReferenceImage) -> ModelEntity {\n        var videoPlane = ModelEntity()\n        var targetName: String = \"\"\n        \n        if let name = target.name,\n           let validURL = URL(string: \"https://testdomain.com/\\(name).mp4\") {\n            targetName = name\n\n            // Use the preloaded placeholder asset to create an AVPlayer\n            if let placeholderAsset = parent.placeholderAsset {\n                let placeholderPlayer = AVPlayer(playerItem: AVPlayerItem(asset: placeholderAsset))\n                let videoMaterial = VideoMaterial(avPlayer: placeholderPlayer)\n                videoPlane = ModelEntity(mesh: .generatePlane(width: Float(target.physicalSize.width), depth: Float(target.physicalSize.height)), materials: [videoMaterial])\n                placeholderPlayer.play()\n\n                DispatchQueue.global(qos: .background).async {\n                    let videoPlayer = AVPlayer(url: validURL)\n                    NotificationCenter.default.addObserver(forName: .AVPlayerItemDidPlayToEndTime, object: videoPlayer.currentItem, queue: .main) { [weak videoPlayer] _ in\n                        videoPlayer?.seek(to: CMTime.zero)\n                        videoPlayer?.play()\n                    }\n                    DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {\n                        let videoMaterial = VideoMaterial(avPlayer: videoPlayer)\n                        videoPlane.model?.materials = [videoMaterial]\n                        videoPlayer.play()\n                        self.parent.videoPlayers[targetName] = videoPlayer\n                        print (target.name as Any)\n                    }\n                }\n            } else {\n                fatalError(\"Failed to load placeholder video asset.\")\n            }\n        }\n\n        return videoPlane\n    }\n\n",
"AnswerId": "76385186",
"AnswerBody": "The key to resolving this issue is making sure the AVPlayer's item is actually ready to play before switching the video. You can use the Key-Value Observing (KVO) on the AVPlayerItem's status property to get notified when it's ready to play.\nHere is the updated createVideoNode(_:) function:\nfunc createVideoNode(_ target: ARReferenceImage) -> ModelEntity {\n    var videoPlane = ModelEntity()\n    var targetName: String = \"\"\n    \n    if let name = target.name,\n       let validURL = URL(string: \"https://testdomain.com/\\(name).mp4\") {\n        targetName = name\n\n        // Use the preloaded placeholder asset to create an AVPlayer\n        if let placeholderAsset = parent.placeholderAsset {\n            let placeholderPlayer = AVPlayer(playerItem: AVPlayerItem(asset: placeholderAsset))\n            let videoMaterial = VideoMaterial(avPlayer: placeholderPlayer)\n            videoPlane = ModelEntity(mesh: .generatePlane(width: Float(target.physicalSize.width), depth: Float(target.physicalSize.height)), materials: [videoMaterial])\n            placeholderPlayer.play()\n\n            DispatchQueue.global(qos: .background).async {\n                let asset = AVAsset(url: validURL)\n                let playerItem = AVPlayerItem(asset: asset)\n                let videoPlayer = AVPlayer(playerItem: playerItem)\n\n                // Observe the status of playerItem.\n                playerItem.addObserver(self, forKeyPath: \"status\", options: .new, context: nil)\n\n                NotificationCenter.default.addObserver(forName: .AVPlayerItemDidPlayToEndTime, object: videoPlayer.currentItem, queue: .main) { [weak videoPlayer] _ in\n                    videoPlayer?.seek(to: CMTime.zero)\n                    videoPlayer?.play()\n                }\n\n                self.parent.videoPlayers[targetName] = videoPlayer\n            }\n        } else {\n            fatalError(\"Failed to load placeholder video asset.\")\n        }\n    }\n\n    return videoPlane\n}\n\n// Add this method to handle observed value change\noverride func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey : Any]?, context: UnsafeMutableRawPointer?) {\n    if keyPath == \"status\" {\n        if let playerItem = object as? AVPlayerItem, playerItem.status == .readyToPlay {\n            DispatchQueue.main.async { [weak self] in\n                if let videoPlane = self?.videoPlane {\n                    let videoMaterial = VideoMaterial(avPlayer: playerItem.player)\n                    videoPlane.model?.materials = [videoMaterial]\n                    playerItem.player?.play()\n                }\n            }\n        }\n    }\n}\n\nThis version of the function now creates an AVPlayerItem using the AVAsset. It then adds the ViewController as an observer of the playerItem's status property. The observeValue(forKeyPath:of:change:context:) method gets called when the status changes. When the status is .readyToPlay, it switches the video on the main queue.\nPlease note that the observeValue method is a standard method for classes that inherit from NSObject, make sure your class does that. Also remember to remove the observer when it's no longer needed.\nYou will also have to hold a strong reference to your AVPlayerItem and AVPlayer in order to observe changes. This might necessitate some architectural changes (adding properties to your class).\nThis solution should give you a general direction, but you might need to adjust it to fit your specific project setup and requirements.\n"
},
{
"QuestionId": "76383308",
"QuestionTitle": "ruby-openai api gem in Ruby on Rails: how to implement a streaming conversation?",
"QuestionBody": "Openai provides an api which allows you to implement AI services such as ChaGPT or DAL-E.\nFor Ruby on Rails application, and there are couple of gems available, obe of them being ruby-openai.\nIt works very well, but the only problem is that it doesn't come with the stream conversation feature, meaning that you can only send one question request at a time without any history tracking of the conversation. In other words, the api forgets every question you asked after having sent the reply.\nSo how can we fix this?\n",
"AnswerId": "76383309",
"AnswerBody": "Basically you need to implement the whole behaviour yourself. Here are all the implementation step, including the implementation of the dal-e ai with a response with several pictures rather then just one.\nYou can also find my whole repository HERE and clone the app!!!\nIMPLEMENTING A STREAM CONVERSATION FEATURE\nBasic implementation\nCheck out Doug Berkley's Notion Page for basic implementation of the API\nImplement a streaming conversation\nBy default the openai gem does not come with that feature, hence having to implement it yourself\n\nCreate your database with 3 tables (conversations, questions, answers) with thw following sctructure:\n\n# schema.rb\nActiveRecord::Schema[7.0].define(version: 2023_05_29_194913) do\n  create_table \"answers\", force: :cascade do |t|\n    t.text \"content\"\n    t.integer \"question_id\", null: false\n    t.datetime \"created_at\", null: false\n    t.datetime \"updated_at\", null: false\n    t.index [\"question_id\"], name: \"index_answers_on_question_id\"\n  end\n\n  create_table \"conversations\", force: :cascade do |t|\n    t.text \"initial_question\"\n    t.datetime \"created_at\", null: false\n    t.datetime \"updated_at\", null: false\n    t.text \"historic\"\n  end\n\n  create_table \"questions\", force: :cascade do |t|\n    t.text \"content\"\n    t.integer \"conversation_id\", null: false\n    t.datetime \"created_at\", null: false\n    t.datetime \"updated_at\", null: false\n    t.index [\"conversation_id\"], name: \"index_questions_on_conversation_id\"\n  end\n\n  add_foreign_key \"answers\", \"questions\"\n  add_foreign_key \"questions\", \"conversations\"\nend\n\n\nRoutes\n\nRails.application.routes.draw do\n  root \"pages#home\" # supposes that you have a pages controller with a home action\n  resources :conversations, only: [:create, :show]\n  post \"question\", to: \"conversations#ask_question\"\nend\n\n\nHome page view (with just a button that redirects to the create conversation action -- see bellow)\n\n<h1>Let's talk</h1>\n<%= button_to \"Create New Conversation\", conversations_path, method: :post, class: \"btn btn-primary my-3\" %>\n\n\nController app/controllers/conversations_controller.rb\n\nclass ConversationsController < ApplicationController\n  def create\n    @convo = Conversation.create\n    redirect_to conversation_path(@convo)\n  end\n\n  def show\n    @convo = Conversation.find(params[:id])\n  end\n\n  def ask_question\n    @question = Question.new(content: params[:entry])\n    conversation = Conversation.find(params[:conversation])\n    @question.conversation = conversation\n    @question.save\n    if conversation.historic.nil?\n      response = OpenaiService.new(params[:entry]).call \n      conversation.historic = \"#{@question.content}\\n#{response}\"\n    else\n      response = OpenaiService.new(\"#{conversation.historic}\\n#{params[:entry]}\").call\n      conversation.historic += \"\\n#{@question.content}\\n#{response}\"\n    end\n    conversation.save\n    @answer = Answer.create(content: response, question: @question)\n    redirect_to conversation_path(conversation)\n  end\nend\n\n\nShow page app/views/conversations/show.html.erb\n\n<h1>This is your conversation</h1>\n<p>Ask your question</p>\n<form action=\"<%= question_path %>\", method=\"post\">\n  <input type=\"hidden\" name=\"conversation\" value=\"<%= @convo.id %>\">\n  <textarea rows=\"5\" cols=\"33\" name=\"entry\"></textarea>\n  <input type=\"submit\" class=\"btn btn-primary\">\n</form>\n\n<br>\n\n<ul>\n  <% @convo.questions.each do |question| %>\n    <li>\n      Q: <%= question.content.capitalize %> <%= \"?\" if question.content.strip.last != \"?\" %>\n    </li>\n    <li>\n      A: <%= question.answers.first.content %>\n    </li>\n  <% end %>\n</ul>\n\n<%= link_to \"Back\", root_path %>\n\n\n\nrails s and test :)\n\nResources:\n\nhttps://github.com/OGsoundFX/ruby-open-ai\nhttps://doug-berkley.notion.site/doug-berkley/Rails-ChatGPT-Service-Object-Setup-21748fc969514b978bf6345f897b6d3e\nhttps://github.com/alexrudall/ruby-openai\n\nGoing Further:\n\nhttps://gist.github.com/alexrudall/cb5ee1e109353ef358adb4e66631799d\n\n"
},
{
"QuestionId": "76381726",
"QuestionTitle": "xUnit IClassFixture reinitialized for every testcase",
"QuestionBody": "I want to write integration tests with shared context (shared state) for all testcases.\nFrom docs:\n\nWhen using a class fixture, xUnit.net will ensure that the fixture instance will be created before any of the tests have run, and once all the tests have finished, it will clean up the fixture object by calling Dispose, if present.\n\nIt follows from docs that I need to use IClassFixture. Ok then.\nI create sample ASP .NET Core Web API with controllers and in Program.cs add the only line:\npublic partial class Program { }\n\nNothing else is changed in a project.\nThen I add xUnit test project where I add reference for my web api project and modify the default UnitTest1 class with the following code:\npublic class UnitTest1 : IClassFixture<WebApplicationFactory<Program>>\n{\n    private readonly HttpClient _client;\n    private string? _val;\n    public UnitTest1(WebApplicationFactory<Program> factory)\n    {\n        _client = factory.CreateClient();\n    }\n\n    [Fact]\n    public void Test1()\n    {\n        Assert.Null(_val);\n        _val = \"smth\";\n    }\n\n    [Fact]\n    public void Test2()\n    {\n        Assert.NotNull(_val);\n    }\n}\n\nSo basically I want to set \"shared context\" (which is a string variable in this case) in Test1 and use it in Test2. I run testcases and I see that Test1 passes and Test2 fails.\nI have seen xUnit IClassFixture constructor being called multiple times and tried using test explorer window or even switch to Rider but that did not help. Did someone encounter such a behavior?\n",
"AnswerId": "76381855",
"AnswerBody": "This is working correctly, but you have implemented it wrong. xUnit runtime will create a new instance of UnitTest1 for every test execution, but it should only create a single instance of WebApplicationFactory<Program> for the lifetime of the current test batch execution context for this test class.\n\nYour _val variable is not defined as part of the test fixture at all, so that makes sense that the value is not persisted across the different tests.\n\nBecause you are passing the factory, and not the instance, you will experience multiple calls to factory.CreateClient(); and this is expected. In this scenario you wouldn't normally use a factory as the test fixture, but your test fixture could use the factory method internally:\n/// <summary>Fixture to share across many tests in the same context</summary>\npublic class MyTestFixture : IDisposable\n{\n    public HttpClient Client { get; private set; }\n    public string? Value { get; set; }\n    \n    public MyTestFixture(WebApplicationFactory<Program> factory)\n    {\n        Client = factory.CreateClient();\n    }\n\n    public void Dispose()\n    {\n        // clean up any unmanaged references\n    }\n}\n\n* if you are not using DI for your factory, then you should instantiate the factory directly in the constructor instead of expecting it as an argument.\npublic class UnitTest1 : IClassFixture<MyTestFixture>\n{\n    private readonly MyTestFixture _sharedContext;\n\n    public UnitTest1(MyTestFixture testFixture)\n    {\n        _sharedContext = testFixture;\n    }\n\n    [Fact]\n    public void Test1()\n    {\n        Assert.Null(_sharedContext.Value);\n        _sharedContext.Value = \"smth\";\n    }\n\n    [Fact]\n    public void Test2()\n    {\n        Assert.NotNull(_sharedContext.Value);\n    }\n}\n\n"
},
{
"QuestionId": "76381615",
"QuestionTitle": "ggplot2: Date range bar graph",
"QuestionBody": "I am trying to build a date range bar graph usins ggplot2 (R) in the spirit of:\n\nI have followed a thread but I am completely unable to reproduce the results with dates.\nIf I understood it correctly, for each \"id\", the bar length is determined by the smallest and largest \"value\" in the database.\nHere is a minimally working example of my data:\n# Example dataframe\nDF <- data.frame(Name = as.factor(c(\"1.Project1\", \"2.Project2\", \"3.Project3\", \"4.Project4\")),\n                 CreationTime = as.POSIXct(c(\"2019-12-10 13:22:20\", \"2019-12-17 12:25:48\", \"2020-01-02 13:02:57\", \"2020-01-14 08:37:10\")),\n                 LastActivity = as.POSIXct(c(\"2019-12-17 10:42:17 \", \"2020-01-02 13:27:10\", \"2021-02-11 11:32:45\", \"2023-05-03 07:41:38\")),\n                 Status = as.factor(c(\"Prod\", \"Prod\", \"Dev\", \"Complete\")))\n\n# From wide to long\nDFGather <- DF %>% tidyr::gather(key=\"Time\", value=\"Value\", 2:3)\n\n# Generate plot\nggplot2::ggplot(DFGather, aes(x = Value, y = Name, fill = Status)) +\n  ggplot2::geom_col() +\n  ggplot2::coord_cartesian(xlim = c(min(DFGather$Value),max(DFGather$Value))) +\n  ggplot2::scale_x_datetime(date_breaks = \"3 months\", labels = scales::label_date_short())\n\nI have also tried converting POSIXct dates to integers but it didn't change my output:\nDFGather$Value <- as.integer(format(DFGather$Value,\"%Y%m%d\"))\n\nThanks for the support,\nC.\n",
"AnswerId": "76381868",
"AnswerBody": "A quick and dirty approach using geom_segment.\n\nggplot2::ggplot(DF, ggplot2::aes(x = CreationTime, xend = LastActivity, y = Name, yend = Name, colour = Status)) +\n  ggplot2::geom_segment(linewidth = 15) +\n  ggplot2::coord_cartesian(xlim = c(min(DFGather$Value),max(DFGather$Value))) +\n  ggplot2::scale_x_datetime(date_breaks = \"3 months\", labels = scales::label_date_short())\n\n\nCreated on 2023-06-01 with reprex v2.0.2\n"
},
{
"QuestionId": "76382858",
"QuestionTitle": "Spark is unable to handle a particular date format",
"QuestionBody": "I am trying to cast multiple date formats from string type field using Pyspark. When I am using below date format it is working fine.\ndef custom_to_date(col):\n    formats = (\"MM/dd/yyyy\", \"yyyy-MM-dd\", \"dd/MM/yyyy\", \"MM/yy\",\"dd/M/yyyy\")\n    return coalesce(*[to_date(col, f) for f in formats])\n    \nfrom pyspark.sql.functions import coalesce, to_date\ndf = spark.createDataFrame([(1, \"01/22/2010\"), (2, \"2018-12-01\")], (\"id\", \"dt\"))\ndf.withColumn(\"pdt\", custom_to_date(\"dt\")).show()\n\nAbove code gives the correct output.\nBut when I use the month in single digit as below, the code fails.\ndf = spark.createDataFrame([(1, \"01/22/2010\"), (2, \"2018-12-1\"),(3,\"24/7/2006\")], (\"id\", \"dt\"))\n\nI got the below error message.\norg.apache.spark.SparkException:\n  Job aborted due to stage failure:\n    Task 2 in stage 2.0 failed 4 times, most recent failure: \n      Lost task 2.3 in stage 2.0 (TID 10) (10.13.82.55 executor 0): \n        org.apache.spark.SparkUpgradeException: \n        [INCONSISTENT_BEHAVIOR_CROSS_VERSION.PARSE_DATETIME_BY_NEW_PARSER] \n        You may get a different result due to the upgrading to Spark >= 3.0:\n\n",
"AnswerId": "76383322",
"AnswerBody": "Adding an answer since the comments and others answer doesn't cover the behaviour. The solution is not to add new formats. Since the formats itself can be better defined.\nwith spark 3.0 M supports 01, 1. January, Jan.\nSo you don't need MM\nspark reference - https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\ndef custom_to_date(col):\n    formats = (\"M/d/yyyy\", \"yyyy-M-d\", \"d/M/y\", \"M/y\")\n    return coalesce(*[to_date(col, f) for f in formats])\n    \nfrom pyspark.sql.functions import coalesce, to_date\ndf = spark.createDataFrame([(1, \"01/22/2010\"), (2, \"2018-12-1\"),(3,\"12/2023\")], (\"id\", \"dt\"))\ndf.withColumn(\"pdt\", custom_to_date(\"dt\")).show()\n\nResults -\n\nAlternatively, if you want legacy behavior then you can use\nspark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\nor\nspark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n"
},
{
"QuestionId": "76384850",
"QuestionTitle": "How to draw LineRenderer above other objects?",
"QuestionBody": "My line renderer is drawing behind objects. I want it to draw on top of other game objects except for the ball.\nHow can I do this?\nSee the following image to reference the problem (the line renderer draws below the goal, and I want it to draw itself on top.\n\nI searched for the issue but haven't found a single answer for 3D.\n",
"AnswerId": "76385187",
"AnswerBody": "To render a material \"above\" some other materials, you must set your LineRenderer or TrailRenderer's material Rendering mode to Transparent.\nAlso, set the Rendering Mode of materials of objects you wish to draw LineRenderer on top to Transparent.\nNow go back to the LineRenderer's material and in Advanced Options set its Render Queue to 3999. (higher than the object's materials)\nNow your LineRenderer will be drawn on top.\n\n"
},
{
"QuestionId": "76381796",
"QuestionTitle": "How to get not duplicate rows in join?",
"QuestionBody": "I got some problems with duplicate rows which I don't wanna get.\nHi!\nI got two tables - tab1, tab2 and I want to join tab2 to tab1 like:\nSELECT t1.column_A1, t2.column_B2 \nFROM tab1 t1\nJOIN\ntab2 t2\nON t1.column_A1=t2.column_A2 \n\ntab1\n| Column A1 | Column B1 | Column C1 |\n|  -------- |  -------- |  -------- |\n|  Z1       |  Cell 2   |  Cell 3   |\n|  Z2       |  Cell 5   |  Cell 6   |\n\ntab2\n| Column A2 | Column B2 | Column C2 |\n|  -------- |  -------- |  -------- |\n|  Z1       |  PW       |  Cell 3   |\n|  Z1       |  RW       |  Cell 6   |\n\nFor some rows in tab1 there are more than 1 rows in tab2.\nThe result will be:\n| Column A2 | Column B2 | Column C2 |\n|  -------- |  -------- |  -------- |\n|  Z1       |  PW       |  RE       |\n|  Z1       |  RW       |  KS       |\n\nI want to get:\nif PW - show only one row with PW;\nif not PW - show only one row with RW\nThe result should be:\n| Column A2 | Column B2 | Column C2 |\n|  -------- |  -------- |  -------- |\n|  Z1       |  PW       |  RE       |\n\n",
"AnswerId": "76381874",
"AnswerBody": "One option is to \"sort\" rows per each column_a1 by value stored in column_b2 and return rows that rank as the highest.\nSample data:\nSQL> WITH\n  2     tab1 (column_a1, column_b1, column_c1)\n  3     AS\n  4        (SELECT 'Z1', 'cell 2', 'cell 3' FROM DUAL\n  5         UNION ALL\n  6         SELECT 'Z2', 'cell 5', 'cell 6' FROM DUAL),\n  7     tab2 (column_a2, column_b2, column_c2)\n  8     AS\n  9        (SELECT 'Z1', 'PW', 'cell 3' FROM DUAL\n 10         UNION ALL\n 11         SELECT 'Z1', 'RW', 'cell 6' FROM DUAL\n 12         UNION ALL\n 13         SELECT 'Z2', 'RW', 'cell 8' FROM DUAL),\n\nQuery begins here:\n 14     temp\n 15     AS\n 16        (SELECT t1.column_A1,\n 17                t2.column_B2,\n 18                ROW_NUMBER () OVER (PARTITION BY t1.column_a1 ORDER BY t2.column_b2) rn\n 19           FROM tab1 t1 JOIN tab2 t2 ON t1.column_A1 = t2.column_A2)\n 20  SELECT column_a1, column_b2\n 21    FROM temp\n 22   WHERE rn = 1;\n\nCOLUMN_A1    COLUMN_B2\n------------ ------------\nZ1           PW\nZ2           RW\n\nSQL>\n\n"
},
{
"QuestionId": "76378880",
"QuestionTitle": "Pick error \"Type 'Pick' cannot be used as an index type.\"",
"QuestionBody": "Trying to modify my axios wrapper and can't figure out why I'm getting this typescript error...\ntype Headers = {\n  Accept: string;\n  'Content-Type': string;\n  Authorization?: string;\n}\n\nexport interface AxiosOptions {\n  params?: any;\n  data?: any;\n  headers: Headers;\n}\n\nconst axiosOptions: AxiosOptions = {\n  headers: {\n    Accept: 'application/json',\n    'Content-Type': 'application/json',\n  },\n};\n\nexport const updateAxiosOptionsHeaders = (\n    key: Pick<Headers, \"Accept\" | \"Content-Type\" | \"Authorization\">,\n    value: string\n  ): void => {\n  axiosOptions.headers[key] = value;\n}\n\n\n\n",
"AnswerId": "76378926",
"AnswerBody": "This doesn't really meet the usage pattern of Pick. You just need keyof Headers for your case:\ntype Headers = {\n  Accept: string;\n  'Content-Type': string;\n  Authorization?: string;\n}\n\nexport interface AxiosOptions {\n  params?: any;\n  data?: any;\n  headers: Headers;\n}\n\nconst axiosOptions: AxiosOptions = {\n  headers: {\n    Accept: 'application/json',\n    'Content-Type': 'application/json',\n  },\n};\n\nexport const updateAxiosOptionsHeaders = (\n    key: keyof Headers,\n    value: string\n  ): void => {\n  axiosOptions.headers[key] = value;\n}\n\nPlayground link\n\nShould you also have different value types in your object (which seems unlikely for a headers object), you can use a generic constraint:\nexport const updateAxiosOptionsHeaders = <K extends keyof Headers>(\n    key: K,\n    value: Headers[K]\n  ): void => {\n  axiosOptions.headers[key] = value;\n}\n\n"
},
{
"QuestionId": "76378929",
"QuestionTitle": "x86 rep prefix with a count of zero: what happens?",
"QuestionBody": "What happens for an initial count of zero for an x86 rep prefix?\nIntel's manual says explicitly it’s a while count != 0 loop with the test at the top, which is the sane expected behaviour.\nBut most of the many vague reports I’ve seen elsewhere suggest that there’s no initial test for zero so it would be like a countdown with a test at the end and so disaster if it’s repeat {… count —=1; } until count == 0; or who knows.\n",
"AnswerId": "76378999",
"AnswerBody": "Nothing happens with RCX=0; rep prefixes do check for zero first like the pseudocode says.  (Unlike the loop instruction which is exactly like the bottom of a do{}while(--ecx), or a dec rcx/jnz but without affecting FLAGS.)\nI think I've heard of this rarely being used as an idiom for a conditional load or store with rep lodsw or rep stosw with a count of 0 or 1, especially in the bad old days before cmov.  (cmov is an unconditional load feeding an ALU select operation, so it needs a valid address, unlike rep lods with a count of zero.)  This is not efficient especially for rep stos on modern x86 with Fast Strings microcode (P6 and later), especially without anything like Fast Short Rep-Movs (Ice Lake IIRC.)\nThe same applies for instructions that treat the prefixes as repz / repnz (cmps/scas) instead of unconditional rep (lods/stos/movs).  Doing zero iterations means they leave FLAGS umodified.\nIf you want to check FLAGS after a repe/ne cmps/scas, you need to make sure the count was non-zero, or that FLAGS was already set such that you'll branch in a useful way for zero-length buffers.  (Perhaps from xor-zeroing a register that you're going to want later.)\n\nrep movs and rep stos have fast-strings microcode on CPUs since P6, but the startup overhead makes them rarely worth it, especially when sizes can be short and/or data might be misaligned.  They're more useful in kernel code where you can't freely use XMM registers.  Some recent CPUs like Ice Lake have fast-short-rep microcode that I think is supposed to reduce startup overhead for small counts.\nrepe/ne scas/cmps do not have fast-strings microcode on most CPUs, only on very recent CPUs like Sapphire Rapids and maybe Alder Lake P-cores.  So they're quite slow, like one load per clock cycle (so 2 cycles per count for cmpsb/w/d/q) according to testing by https://agner.org/optimize/ and https://uops.info/.\n\nWhat setup does REP do?\nWhy is this code using strlen heavily 6.5x slower with GCC optimizations enabled? - GCC -O1 used to use repne scasb to inline strlen.  This is a disaster for long strings.\nWhich processors support \"Fast Short REP CMPSB and SCASB\" (very recent feature)\nEnhanced REP MOVSB for memcpy - even without ERMSB, rep movs will use no-RFO stores for large sizes, similar to NT stores but not bypassing the cache.  Good general Q&A about memory bandwidth considerations.\n\n"
},
{
"QuestionId": "76383242",
"QuestionTitle": "Dictionary Comprehension within pandas dataframe column",
"QuestionBody": "Trying to match a dictionary item with a string value from another column.\nsample data:\ndf =     A    B\n     0  'a'  {'a': '2', 'b': '5'}\n     1  'c'  {'a': '2', 'b': '16', 'c': '32'}\n     2  'a'  {'a': '6', 'd': '23'} \n     3  'd'  {'b': '4', 'd': '76'}\n     \n\nI'm trying to get the following out:\nDf =     A    B\n     0   'a'  {'a': '2'}\n     1   'c'  {'c': '32'}\n     2   'a'  {'a': '6'}\n     3   'd'  {'d': '76'}\n\nI got this far not inside a dataframe:\nd = {k: v for k, v in my_dict.items() if k == 'a'}\n\nfor a single line, but I couldn't get this to work and to be fair, I didn't expect it to work directly, but was hoping i was close:\nTest_df['B'] = {k: v for k, v in test_df['B'].items() if k == test_df['A']}\n\nI get the following error:\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n\nWhat do I need to do to get this to work, or is there a better more efficient way?\n",
"AnswerId": "76383335",
"AnswerBody": "You can use a list comprehension with zip:\ndf['B'] = [{x: d[x]} for x, d in zip(df['A'], df['B'])]\n\nOutput:\n   A            B\n0  a   {'a': '2'}\n1  c  {'c': '32'}\n2  a   {'a': '6'}\n3  d  {'d': '76'}\n\n"
},
{
"QuestionId": "76384672",
"QuestionTitle": "Terraform for_each over yaml file contents which is an object",
"QuestionBody": "I have a yaml file which is similar to the following (FYI: ssm_secrets can be an empty array):\nrabbitmq:\n  repo_name: bitnami\n  namespace: rabbitmq\n  target_revision: 11.1.1\n  path: rabbitmq\n  values_file: charts/rabbitmq/values.yaml\n  ssm_secrets: []\napp_name_1:\n  repo_name: repo_name_1\n  namespace: namespace_1\n  target_revision: target_revision_1\n  path: charts/path\n  values_file: values.yaml\n  ssm_secrets:\n    - name: name-dev-1\n      key: .env\n      ssm_path: ssm_path/dev\nname-backend:\n  repo_name: repo_name_2\n  namespace: namespace_2\n  target_revision: target_revision_2\n  path: charts/name-backend\n  values_file: values.yaml\n  ssm_secrets:\n    - name: name-backend-app-dev\n      ssm_path: name-backend/app/dev\n      key: app.ini\n    - name: name-backend-abi-dev\n      ssm_path: name-backend/abi/dev\n      key: contractTokenABI.json\n    - name: name-backend-widget-dev\n      ssm_path: name-backend/widget/dev\n      key: name.ini\n    - name: name-abi-dev\n      ssm_path: name-abi/dev\n      key: name_1.json\n    - name: name-website-dev\n      ssm_path: name/website/dev\n      key: website.ini\n    - name: name-name-dev\n      ssm_path: name/name/dev\n      key: contract.ini\n    - name: name-key-dev\n      ssm_path: name-key/dev\n      key: name.pub\n\nAnd using External Secrets and EKS Blueprints, I am trying to generate the yaml file necessary to create the secrets\nresource \"kubectl_manifest\" \"secret\" {\n  for_each   = toset(flatten([for service in var.secrets : service.ssm_secrets[*].ssm_path]))\n  yaml_body  = <<YAML\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: ${replace(each.value, \"/\", \"-\")}\n  namespace: ${split(\"/\", each.value)[0]}\nspec:\n  refreshInterval: 30m\n  secretStoreRef:\n    name: ${local.cluster_secretstore_name}\n    kind: ClusterSecretStore\n  data:\n  - secretKey: .env\n    remoteRef:\n       key: ${each.value}\nYAML\n  depends_on = [kubectl_manifest.cluster_secretstore, kubernetes_namespace_v1.namespaces]\n}\n\nThe above works fine, but I also need to use the key value from the yaml into secretKey: <key_value from yaml>.\nIf I try with for_each   = toset(flatten([for service in var.secrets : service.ssm_secrets[*]]))\nresource \"kubectl_manifest\" \"secret\" {\n  for_each   = toset(flatten([for service in var.secrets : service.ssm_secrets[*]]))\n  yaml_body  = <<YAML\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: ${replace(each.value[\"ssm_path\"], \"/\", \"-\")}\n  namespace: ${split(\"/\", each.value[\"ssm_path\"])[0]}\nspec:\n  refreshInterval: 30m\n  secretStoreRef:\n    name: ${local.cluster_secretstore_name}\n    kind: ClusterSecretStore\n  data:\n  - secretKey: .env\n    remoteRef:\n       key: ${each.value[\"ssm_path\"]}\nYAML\n  depends_on = [kubectl_manifest.cluster_secretstore, kubernetes_namespace_v1.namespaces]\n}\n\nIt just gives me the following error:\n\nThe given \"for_each\" argument value is unsuitable: \"for_each\" supports\nmaps and sets of strings, but you have provided a set containing type\nobject.\n\nI have tried converting the variable into a map, used lookup, but it doesn't work.\nAny help would be much appreciated.\nUpdate 1:\nAs per @MattSchuchard suggestion, changing the for_each into\nfor_each   = toset(flatten([for service in var.secrets : service.ssm_secrets]))\nGave the following error:\nError: Invalid for_each set argument\n│ \n│   on ../../modules/02-plugins/external-secrets.tf line 58, in resource \"kubectl_manifest\" \"secret\":\n│   58:   for_each   = toset(flatten([for service in var.secrets : service.ssm_secrets]))\n│     ├────────────────\n│     │ var.secrets is object with 14 attributes\n│ \n│ The given \"for_each\" argument value is unsuitable: \"for_each\" supports maps and sets of strings, but you have provided a set containing type object.\n\nUpdate 2:\n@mariux gave the perfect solution, but here is what I came up with. It's not that cleaner, but definitely works (PS: I myself am going to use Mariux's solution):\nlocals {\n  my_list = tolist(flatten([for service in var.secrets : service.ssm_secrets[*]]))\n}\n\n\nresource \"kubectl_manifest\" \"secret\" {\n\n  count      = length(local.my_list)\n  yaml_body  = <<YAML\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: ${replace(local.my_list[count.index][\"ssm_path\"], \"/\", \"-\")}\n  namespace: ${split(\"/\", local.my_list[count.index][\"ssm_path\"])[0]}\nspec:\n  refreshInterval: 30m\n  secretStoreRef:\n    name: ${local.cluster_secretstore_name}\n    kind: ClusterSecretStore\n  data:\n  - secretKey: ${local.my_list[count.index][\"key\"]}\n    remoteRef:\n       key: ${local.my_list[count.index][\"ssm_path\"]}\nYAML\n  depends_on = [kubectl_manifest.cluster_secretstore, kubernetes_namespace_v1.namespaces]\n}\n\n",
"AnswerId": "76385193",
"AnswerBody": "Assumptions\nBased on what you shared, i make the following assumptions:\n\nthe service is not actually important for you as you want to create external secrets by ssm_secrets.*.name using the given key and ssm_path attributes.\neach name is globally unique for all services and never reused.\n\nterraform hacks\nBased on the assumptions you can create an array of ALL ssm_secrets using\nlocals {\n  ssm_secrets_all = flatten(values(var.secrets)[*].ssm_secrets)\n}\n\nand convert it to a map that can be used in for_each by keying the values by .name:\nlocals {\n  ssm_secrets_map = { for v in local.ssm_secrets_all : v.name => v }\n}\n\nFull (working) example\nThe example below works for me and makes some assumption where the variables should be used.\n\nUsing yamldecode to decode your original input into local.input\nUsing yamlencode to make reading the manifest easier and removing some string interpolcations. This also ensures that the indent is correct as we convert HCL to yaml.\n\nA terraform init && terraform plan will plan to create the following resources:\n kubectl_manifest.secret[\"name-abi-dev\"] will be created\n kubectl_manifest.secret[\"name-backend-abi-dev\"] will be created\n kubectl_manifest.secret[\"name-backend-app-dev\"] will be created\n kubectl_manifest.secret[\"name-backend-widget-dev\"] will be created\n kubectl_manifest.secret[\"name-dev-1\"] will be created\n kubectl_manifest.secret[\"name-key-dev\"] will be created\n kubectl_manifest.secret[\"name-name-dev\"] will be created\n kubectl_manifest.secret[\"name-website-dev\"] will be created\n\nlocals {\n  # input = var.secrets\n  ssm_secrets_all = flatten(values(local.input)[*].ssm_secrets)\n  ssm_secrets_map = { for v in local.ssm_secrets_all : v.name => v }\n\n  cluster_secretstore_name = \"not provided secretstore name\"\n}\n\nresource \"kubectl_manifest\" \"secret\" {\n  for_each = local.ssm_secrets_map\n\n  yaml_body = yamlencode({\n    apiVersion = \"external-secrets.io/v1beta1\"\n    kind       = \"ExternalSecret\"\n    metadata = {\n      name      = replace(each.value.ssm_path, \"/\", \"-\")\n      namespace = split(\"/\", each.value.ssm_path)[0]\n    }\n    spec = {\n      refreshInterval = \"30m\"\n      secretStoreRef = {\n        name = local.cluster_secretstore_name\n        kind = \"ClusterSecretStore\"\n      }\n      data = [\n        {\n          secretKey = \".env\"\n          remoteRef = {\n            key = each.value.key\n          }\n        }\n      ]\n    }\n  })\n\n  # not included dependencies\n  # depends_on = [kubectl_manifest.cluster_secretstore, kubernetes_namespace_v1.namespaces]\n}\n\nlocals {\n  input = yamldecode(<<-EOF\n    rabbitmq:\n      repo_name: bitnami\n      namespace: rabbitmq\n      target_revision: 11.1.1\n      path: rabbitmq\n      values_file: charts/rabbitmq/values.yaml\n      ssm_secrets: []\n    app_name_1:\n      repo_name: repo_name_1\n      namespace: namespace_1\n      target_revision: target_revision_1\n      path: charts/path\n      values_file: values.yaml\n      ssm_secrets:\n        - name: name-dev-1\n          key: .env\n          ssm_path: ssm_path/dev\n    name-backend:\n      repo_name: repo_name_2\n      namespace: namespace_2\n      target_revision: target_revision_2\n      path: charts/name-backend\n      values_file: values.yaml\n      ssm_secrets:\n        - name: name-backend-app-dev\n          ssm_path: name-backend/app/dev\n          key: app.ini\n        - name: name-backend-abi-dev\n          ssm_path: name-backend/abi/dev\n          key: contractTokenABI.json\n        - name: name-backend-widget-dev\n          ssm_path: name-backend/widget/dev\n          key: name.ini\n        - name: name-abi-dev\n          ssm_path: name-abi/dev\n          key: name_1.json\n        - name: name-website-dev\n          ssm_path: name/website/dev\n          key: website.ini\n        - name: name-name-dev\n          ssm_path: name/name/dev\n          key: contract.ini\n        - name: name-key-dev\n          ssm_path: name-key/dev\n          key: name.pub\n    EOF\n  )\n}\n\nterraform {\n  required_version = \"~> 1.0\"\n\n  required_providers {\n    kubectl = {\n      source  = \"gavinbunney/kubectl\"\n      version = \"~> 1.7\"\n    }\n  }\n}\n\nhint: you could also try to use the kubernetes_manifest resource instead of kubectl_manifest\np.s.: We created Terramate to make complex creation of Terraform code easier. But this seems perfectly fine for pure Terraform.\n"
},
{
"QuestionId": "76380957",
"QuestionTitle": "How can I assert that the jest mocked module method was called?",
"QuestionBody": "How can I assert that the jest mocked module method was called?\nE.g. in my .spec.js I have the following jest mocked module:\njest.mock('../../../../services/logs.service.js', () => ({\n    log: jest.fn()\n}));\n\nNow I would like to assert the log method. I.e. something like this:\n//the log was called twice with the text \"foo\"\nexpect(log).toHaveBeenCalledWith(2, \"foo\");\n\nBut I can not access the log. I tried putting the log initialization outside the jest mocked module, like so:\nconst log = jest.fn();\njest.mock('../../../../services/logs.service.js', () => ({\n    log\n}));\n\nBut I got the error:\n\nThe module factory of jest.mock() is not allowed to reference any out-of-scope variables.\n\n",
"AnswerId": "76381877",
"AnswerBody": "You can do the following:\nJavaScript\nimport { log } from '../../../../services/logs.service.js';\n\njest.mock('../../../../services/logs.service.js', () => ({\n    log: jest.fn()\n}));\n\nexpect(log).toHaveBeenCalledWith(2, \"foo\"); // JavaScript\n\nTypeScript\nimport { log } from '../../../../services/logs.service.js';\n\njest.mock('../../../../services/logs.service.js', () => ({\n    log: jest.fn()\n}));\n\nconst mockedLog = log as jest.MockedFunction<typeof log>;\n\nexpect(mockedLog).toHaveBeenCalledWith(2, \"foo\");\n\n"
},
{
"QuestionId": "76382640",
"QuestionTitle": "Ionic app error: No 'Access-Control-Allow-Origin' header is present on the requested resource",
"QuestionBody": "I have a mobile app developed in ionic capacitor. The backend to the app is a .net core web api deployed on amazon elastic beanstalk. I am getting CORS error** No 'Access-Control-Allow-Origin' header is present on the requested resource** when trying to access the back end using the app.\nI have attempted to allow the API to be accessible by any consumer by allowing all origins. Is there need to configure anything on AWS Elastic bean?\nvar app = builder.Build();\napp.UseCors(builder => builder\n     .AllowAnyOrigin()\n     .AllowAnyMethod()\n     .AllowAnyHeader()\n     );\n\n",
"AnswerId": "76383361",
"AnswerBody": "\nLog in to the AWS Management Console and navigate to the Elastic Beanstalk service.\nSelect your application and environment where the .NET Core Web API is deployed.\nIn the navigation pane, click on \"Configuration.\"\nUnder the \"Software\" section, click on \"Edit\" for the \"Environment properties.\"\nAdd a new property with the following details:\n\nName: ACCESS_CONTROL_ALLOW_ORIGIN\nValue: * (or the specific origin you want to allow if you don't want to allow all origins)\n\n\nSave the changes and wait for the environment to update.\n\nMake sure to remove the CORS configuration you mentioned from your .NET Core Web API code, as the CORS handling will now be done by Elastic Beanstalk.\n"
},
{
"QuestionId": "76384683",
"QuestionTitle": "Draw random numbers from a custom probability density function in Julia",
"QuestionBody": "I would like to draw random numbers from a modified exponential distribution:\np(x) = C * a * Exp[-(a*x)^b] with C=1/Gamma[1 + 1/b] for normalization.\nHow can I do this in julia? Unfortunately I have only little experience with Julia and no experiences with creating custom random numbers. I would be very grateful for any help.\n",
"AnswerId": "76385208",
"AnswerBody": "If I'm not mistaken, that is a p-Generalized Gaussian distribution, which has a rather efficient implementation in Distributions.jl:\nusing Distributions\nmu = 0       # your location parameter\nalpha = 1/a  # your scale parameter\nbeta = b     # your shape parameter\np = PGeneralizedGaussian(mu, alpha, beta)\n\nUsing the Distributions.jl API for univariate distributions, you can sample from this distribution by passing it to the exported rand method. Here is an example of how to sample five independent scalars from a PGeneralizedGaussian distribution with mu = 0, alpha = 1/2 and beta = 3:\njulia> p = PGeneralizedGaussian(0, 1/2, 3);\n\njulia> rand(p, 5)\n5-element Vector{Float64}:\n  0.2835117212764108\n -0.023160728370422268\n  0.3075395764050027\n -0.19233721955795835\n  0.21256694763885342\n\nIf you want to try to implement the distribution yourself, which I do not recommend unless you are doing this as an exercise in programming math in Julia, you need to define a type that holds the static parameters of the distribution (in your case, just the shape parameter and the scale parameter), then define and export the methods listed here to extend the Distributions.jl API to your custom distribution. In particular, you need to define:\nstruct MyDistribution <: ContinuousUnivariateDistribution\n  # ... your distribution parameters here\nend\n\nrand(::AbstractRNG, d::MyDistribution) # sample a value from d\nsampler(d::MyDistribution)             # return d or something that can sample from d more efficiently\nlogpdf(d::MyDistribution, x::Real)     # compute the log of the pdf of d at x\ncdf(d::MyDistribution, x::Real)        # compute the cdf of d at x\nquantile(d::MyDistribution, q::Real)   # compute the qth quantile of d\nminimum(d::MyDistribution)             # return the minimum value supported by d\nmaximum(d::MyDistribution)             # return the maximum value supported by d\ninsupport(d::MyDistribution, x::Real)  # query whether x is supported by d\n\nThe documentation of the package is very good, so it's an excellent way to get your feet wet if you are trying to learn Julia.\n"
},
{
"QuestionId": "76385164",
"QuestionTitle": "Border doesn't adapt after collapsing a column",
"QuestionBody": "For my main project, I'm trying to find a way to hide a column in JS. The following function :\nfunction hide() {\n    const table = document.getElementById('test');\n    const cols = table.getElementsByTagName('col');\n    cols[1].style.visibility = \"collapse\";\n}\n\nworks great, but the borders don't move. Here's the problem :\n becomes \nHow can I avoid this issue ?\nEDIT : This works as intended on Chrome and Edge. Is this a bug for Firefox?\nFull html is:\n\n\nfunction hide() {\n    const table = document.getElementById('test');\n    const cols = table.getElementsByTagName('col');\n    cols[1].style.visibility = \"collapse\";\n}\ntable, tr, th, td {\n    border: 1px solid;\n    border-collapse: collapse;\n}\n<table id=\"test\">\n    <colgroup>\n        <col><col><col>\n    </colgroup>\n    <tr>\n        <th>1</th>\n        <th>2</th>\n        <th>3</th>\n    </tr>\n    <tr>\n        <td>un</td>\n        <td>deux</td>\n        <td>trois</td>\n    </tr>\n    <tr>\n        <td>one</td>\n        <td>two</td>\n        <td>three</td>\n    </tr>\n</table>\n\n<button onclick=hide()>Hide</button>\n\n\n\n",
"AnswerId": "76385211",
"AnswerBody": "To address this issue, you can use the border-spacing property instead of border-collapse. Modify your CSS as follows:\n<style>\ntable {\n    border-spacing: 0;\n}\n\nth, td {\n    border: 1px solid;\n    padding: 5px;\n}\n</style>\n\n"
},
{
"QuestionId": "76381785",
"QuestionTitle": "TypeError: data type '>' not understood using dtype from numpy",
"QuestionBody": "first I saw similar questions but nothing helped me.\nI'm trying to sort list of tuples, and convert the data types inside the tuple,\nconvert it according to a list of tuples I get.\nfor example, if I have a list of tuple, every tuple is built like\n(ID,Grade,Height)\n\nA = [(123,23,67),(234,67,45)]\n\nand I have a list of type like that:\n[(ID,int),(grade,'s15'),(height,float)]\nnow I read that 's15' is a dtype from bumpy, but I can't seem to use it.\nI tried to copy from the docs:\nimport numpy as np\ndt = np.dtype(('>14'))\n\nbut all I get is this error:\ndt = np.dtype(('>14'))\nTypeError: data type '>' not understood\n\nthe docs I copied from:\nhttps://numpy.org/doc/stable/reference/arrays.dtypes.html\nand is there a generic converter I can use to convert to any type I'm given?\n",
"AnswerId": "76381889",
"AnswerBody": "I think you maybe overlooked the documentation you are referring.\nYou used\ndt = np.dtype(('>14'))\n\nwhich is >14 (fourteen)...\nBut in fact the documentation clearly mentions\ndt = np.dtype('>i4')\n\nwhich is i4 not 1 (one)\nAlso based on the docs > or < specifies upper/lower bound for each dtype, for example >i would be big endian integer (see Endianess)\nAnd the number after that would indicate number of bytes given to the dtype (see docs)\nFinally the S indicates Zero terminated bytes\nBased on your description, your teacher wants Upper endian ~128 bit Zero terminated bytes\nFurthermore,\ndt = np.dtype(('>S15'))\n\nworks fine.\nI hope this fixes your issue\n"
},
{
"QuestionId": "76381436",
"QuestionTitle": "Is there ST_Intersects alternative that allows two(or more) polygons to share sides",
"QuestionBody": "I am using ST_Intersects to check if two polygons intersect. Relevant part of my query is:\nSELECT entity_number\nFROM coordinates\nWHERE ST_INTERSECTS($1, location)\n\n\nIt works well to determine if one polygon crosses the other's surface:\n\nI expected ST_Intersects to return false when two polygons share sides, but it does not:\n\nI read about other methods like ST_Covers, ST_Contains, ST_ContainsProperly, ST_Within ,ST_DWithin. But i am not sure which one suits my needs.\nIs there any method that allows two polygons to share sides?\n",
"AnswerId": "76381929",
"AnswerBody": "You want ST_Overlaps:\n\nReturns TRUE if geometry A and B \"spatially overlap\". Two geometries overlap if they have the same dimension, each has at least one point not shared by the other (or equivalently neither covers the other), and the intersection of their interiors has the same dimension. The overlaps relationship is symmetrical.\n\n"
},
{
"QuestionId": "76385016",
"QuestionTitle": "React Router - How can I reuse my layout for the errorElement in the root route?",
"QuestionBody": "I'm using React Router v6 and following are my routes:\nconst router = createBrowserRouter([\n  {\n    path: '/',\n    element: <App />,\n    errorElement: <ErrorPage />,\n    children: [\n      {\n        index: true,\n        element: <HomePage />,\n      },\n      {\n        path: '/sign-up',\n        element: <SignUpPage />,\n      },\n      {\n        path: '/log-in',\n        element: <LogInPage />,\n      },\n    ],\n  },\n]);\n\nconst root = ReactDOM.createRoot(\n  document.getElementById('root') as HTMLElement,\n);\n\nroot.render(\n  <React.StrictMode>\n    <RouterProvider router={router} />\n  </React.StrictMode>,\n);\n\nThe App component contains my app's layout and outputs the route elements using the Outlet component. But now if there's an error that bubbles up to the root route, then the ErrorPage gets displayed as expected, but it doesn't make use of the layout from App... So, how can I reuse my layout from App when the error page gets displayed?\n",
"AnswerId": "76385223",
"AnswerBody": "When there's an error it is kind of an either or kind of scenario. Either conditions are fine and the App component is rendered or there's an error condition and the ErrorPage component is rendered.\nWhat you could do is to abstract the layout portion of the App component into a layout component on its own that can render either a passed children prop or the Outlet component for the nested route, and render it in App and also wrap the ErrorPage component.\nExample:\nconst AppLayout = ({ children }) => (\n  ...\n  {children ?? <Outlet />}\n  ...\n);\n\nconst App = () => (\n  ...\n  <AppLayout />\n  ...\n);\n\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <App />, // <-- uses Outlet\n    errorElement: (\n      <AppLayout>     // <-- uses children\n        <ErrorPage />\n      </AppLayout>\n    ),\n    children: [\n      {\n        index: true,\n        element: <HomePage />\n      },\n      {\n        path: \"/sign-up\",\n        element: <SignUpPage />\n      },\n      {\n        path: \"/log-in\",\n        element: <LogInPage />\n      }\n    ]\n  }\n]);\n\n\n"
},
{
"QuestionId": "76381457",
"QuestionTitle": "How to fix a container at a particular spot on the screen",
"QuestionBody": "I'm learning flutter and I have made an app that looks like this:\n\nI'm facing a problem as to how to fix the container fixed on a particular spot on the screen like it has to be aligned to the top center. Here's the problem I'm facing:\n\nHere's the code:\nclass Program7 extends StatefulWidget {\n  const Program7({super.key});\n\n  @override\n  State<Program7> createState() => _Program7State();\n}\n\nclass _Program7State extends State<Program7> {\n  double cHeightAndWidth = 300;\n\n  \n  @override\n  Widget build(BuildContext context) {\n    return SafeArea(\n      child: Column(\n        mainAxisAlignment: MainAxisAlignment.spaceAround,\n        children: [\n          Container(\n            height: cHeightAndWidth,\n            width: cHeightAndWidth,\n            decoration: BoxDecoration(\n              color: Colors.purple,\n            ),\n          ),\n          Column(\n            children: [\n              //A bunch of rows of buttons,\n            ],\n          ),\n        ],\n      ),\n    );\n  }\n}\n\n\nP.S.: I already tried to fix the container to the top center of another container using align but the purple color somehow bleeds out into the bigger container.\n",
"AnswerId": "76381967",
"AnswerBody": "The issue is using MainAxisAlignment.spaceAround,. It will use the free space and put half before and another half at end of the child.\nYou can use fixed gap for top(Container).\nreturn SafeArea(\n  child: Column(\n    children: [\n      SizedBox(height: 50),\n      Container(\n        height: cHeightAndWidth,\n        width: cHeightAndWidth,\n        decoration: BoxDecoration(\n          color: Colors.purple,\n        ),\n      ),\n      Spacer(), // or other widget\n      Column(\n        children: [\n          //A bunch of rows of buttons,\n        ],\n      ),\n    ],\n  ),\n);\n\n"
},
{
"QuestionId": "76383196",
"QuestionTitle": "Find element by class under the same parent",
"QuestionBody": "Any particular reason about this isn't matching the element with that class?\nI have checked a million times and can't see what is that I'm doing wrong.\n\n\n$('.lnk-folder').click(function(e) {\n  e.preventDefault();\n  var header = $(this).parent('thead').find('.folder-header');\n  console.log($(header));\n});\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<thead>\n  <tr>\n    <th colspan=\"10\" style=\"padding:0px; font-size:120%;background-color:#ff0000;\">\n      <div style=\"float:left;min-width:20%;\">\n        <a style=\"color: #000\" class=\"lnk-folder folder-close\" data-hash=\"\" href=\"#\">\n          <i class='fa fa-folder-open'></i> Folder 1\n        </a>\n      </div>\n      <div style=\"float:left;height:26px;padding-left:10px;\">\n        <a href=\"#\"><i class='fas fa-file-upload tooltip' style=\"color:#fff;\"><span class=\"tooltiptext_m\">New</span></i></a>\n      </div>\n    </th>\n  </tr>\n  <tr class=\"folder-header\">\n    <th colspan=\"2\" style='background-color:#0c343d;vertical-align:middle;'> Name </th>\n    <th style='width:7%;background-color:#0c343d;vertical-align:middle;'> Code </th>\n    <th style='width:30%;background-color:#0c343d;vertical-align:middle;'> Act</th>\n    <th style='width:7%;background-color:#0c343d;vertical-align:middle;'> Version</th>\n  </tr>\n</thead>\n\n\n\n",
"AnswerId": "76383405",
"AnswerBody": "parent() is your problem. It looks up the DOM exactly one level, to the parent element, but you need to go higher than that. To do so, use closest()\n\n\n$('.lnk-folder').click(function(e) {\n  e.preventDefault();\n  var header = $(this).closest('thead').find('.folder-header');\n  console.log($(header));\n});\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<table>\n  <thead>\n    <tr>\n      <th colspan=\"10\" style=\"padding:0px; font-size:120%;background-color:#ff0000;\">\n        <div style=\"float:left;min-width:20%;\">\n          <a style=\"color: #000\" class=\"lnk-folder folder-close\" data-hash=\"\" href=\"#\">\n            <i class='fa fa-folder-open'></i> Folder 1\n          </a>\n        </div>\n        <div style=\"float:left;height:26px;padding-left:10px;\">\n          <a href=\"#\"><i class='fas fa-file-upload tooltip' style=\"color:#fff;\"><span class=\"tooltiptext_m\">New</span></i></a>\n        </div>\n      </th>\n    </tr>\n    <tr class=\"folder-header\">\n      <th colspan=\"2\" style='background-color:#0c343d;vertical-align:middle;'> Name </th>\n      <th style='width:7%;background-color:#0c343d;vertical-align:middle;'> Code </th>\n      <th style='width:30%;background-color:#0c343d;vertical-align:middle;'> Act</th>\n      <th style='width:7%;background-color:#0c343d;vertical-align:middle;'> Version</th>\n    </tr>\n  </thead>\n</table>\n\n\n\n"
},
{
"QuestionId": "76384931",
"QuestionTitle": "How to replace a spark dataframe row with another spark dataframe's row using java",
"QuestionBody": "I have 2 data frames\ndf1\n+--------------------+---+--------------------+--------------------+\n|                 ID |B  |C                   |            D       |\n+--------------------+---+--------------------+--------------------+\n|                   1|1.0|                 1.0|                 1.0|\n|                   2|2.0|                 2.0|                 2.0|\n|                   3|3.0|                 3.0|                 3.0|\n|                   4|4.0|                 4.0|                 4.0|\n+--------------------+---+--------------------+--------------------+\n\ndf2\n+--------------------+---+--------------------+--------------------+\n|                 ID |B  |C                   |            D       |\n+--------------------+---+--------------------+--------------------+\n|                   1|100|                 1.0|                 100|\n+--------------------+---+--------------------+--------------------+\n\nIf ID in df2 matches an ID in df1, I want to replace the row in df1 with the updated values in df2. So the new df1 looks like:\ndf1\n+--------------------+---+--------------------+--------------------+\n|                 ID |B  |C                   |            D       |\n+--------------------+---+--------------------+--------------------+\n|                   1|100|                 1.0|                 100|\n|                   2|2.0|                 2.0|                 2.0|\n|                   3|3.0|                 3.0|                 3.0|\n|                   4|4.0|                 4.0|                 4.0|\n+--------------------+---+--------------------+--------------------+\n\nI've been trying to figure this out with union and join and just not having any luck yet.  I first created a new dataframe based on filtering for the ID of df1 and that works and I called that dataframe matchedDF that looks like:\nmatchedDF (dataframe based on finding a match of ID 1 in df1)\n+--------------------+---+--------------------+--------------------+\n|                 ID |B  |C                   |            D       |\n+--------------------+---+--------------------+--------------------+\n|                   1|1.0|                 1.0|                 1.0|\n+--------------------+---+--------------------+--------------------+\n\nBut I don't know if I just want to delete the original ID 1 in df1 and add the new matchedDF or do I somehow want to update the original ID 1 with the matchedDf?  Or am I approaching this all wrong?\nThanks\n",
"AnswerId": "76385224",
"AnswerBody": "To stay computationally efficient, it's always a good idea to avoid joins/shuffles where possible.\nThis looks like a case where it is possible to avoid joining, have a look at the following code (it is in Scala, but the principles remain the same):\n// Constructing the 2 dfs\nval df = Seq(\n  (1, 1.0, 1.0, 1.0),\n  (2, 2.0, 2.0, 2.0),\n  (3, 3.0, 3.0, 3.0),\n  (4, 4.0, 4.0, 4.0)\n).toDF(\"ID\", \"B\", \"C\", \"D\")\n\nval df2 = Seq(\n  (1, 100, 1.0, 100),\n  (2, 100, 1.0, 100)\n).toDF(\"ID\", \"B\", \"C\", \"D\")\n\n// Collecting the IDs to be updated into a single Array\n// IMPORTANT: we make the assumption that this array is not large (in your\n// example there is only 1 row here, so the array only has 1 element which is\n// totally fine)\nval newIds = df2.select(\"ID\").collect.map(_.getInt(0))\n\n// Removing the original rows with the unwanted IDs and unioning the result with\n// the new rows\nval output = df\n  .filter(not(col(\"ID\").isin(newIds: _*)))\n  .union(df2)\n\nscala> output.show\n+---+-----+---+-----+                                                           \n| ID|    B|  C|    D|\n+---+-----+---+-----+\n|  3|  3.0|3.0|  3.0|\n|  4|  4.0|4.0|  4.0|\n|  1|100.0|1.0|100.0|\n|  2|100.0|1.0|100.0|\n+---+-----+---+-----+\n\nSo basically, if we can make the assumption that df2 (with the new values) is small like in your example, you can do something like the following:\n\ncollect the ID values into a single (undistributed) Array. From your example it seems like this is OK. If the amount of new rows is really large this might not be the best approach\nfilter the original df using the isin method of a column and negating using not (basically removing the rows with the new IDs)\nunion the filtered df and df2, resulting in the rows being updated WITHOUT any expensive operation like a shuffle\n\n"
},
{
"QuestionId": "76381864",
"QuestionTitle": "Make a loop to find the distance between stations in R",
"QuestionBody": "I have made this code to find the distance between stations but in the output, there is only one value. Can you find the error?\ndf <- data.frame(\n  station = rep(c(\"A\", \"B\", \"C\", \"D\"), each = 20),\n  temperature = rnorm(80),\n  latitude = c(40.7128, 34.0522, 41.8781, 39.9526),\n  longitude = c(-74.0060, -118.2437, -87.6298, -75.1652)\n)\nstations <- unique(df$station)\n\nmy_points <- matrix(NA, nrow = length(unique(df$station)), ncol = length(unique(df$station)))\n\n# Loop through each station combination\nfor (i in 1:length(stations)) {\n  for (j in 1:length(stations)) {\n    # Get temperatures for the two stations\n    lat1 <- df$latitude[df$station == stations[i]]\n    lon1 <- df$longitude[df$station == stations[i]]\n    lat2 <- df$latitude[df$station == stations[j]]\n    lon2 <- df$longitude[df$station == stations[j]]\n    my_points[i, j] <- as.vector(dist(matrix(c(lon1,lon2,lat1,lat2),\n                                             nrow = 2)))  \n    \n  }\n}\n\ndistance_df <- as.data.frame(my_points)\n\n",
"AnswerId": "76382001",
"AnswerBody": "There are two issues here:\n\nYour input data frame might not look the way you expect it to - the latitude and longitude columns are recycled so you have multiple different coordinates for the same station. Try adding rep() in the lat and long columns as well as station.\n\nIn your code lat1 <- df$latitude[df$station == stations[i]] returns a vector, because there are multiple matches. I think you're expecting a single value. Use only the first matching element (since they are now all the same elements in the vector after adding rep() as above):\n\n\ndf <- data.frame(\n  station = rep(c(\"A\", \"B\", \"C\", \"D\"), each = 20),\n  temperature = rnorm(80),\n  latitude = rep(c(40.7128, 34.0522, 41.8781, 39.9526), each = 20),\n  longitude = rep(c(-74.0060, -118.2437, -87.6298, -75.1652), each = 20)\n)\nstations <- unique(df$station)\n\nmy_points <- matrix(NA, nrow = length(unique(df$station)), ncol = length(unique(df$station)))\n\n# Loop through each station combination\nfor (i in 1:length(stations)) {\n  for (j in 1:length(stations)) {\n    # Get temperatures for the two stations\n    lat1 <- df$latitude[df$station == stations[i]][1]\n    lon1 <- df$longitude[df$station == stations[i]][1]\n    lat2 <- df$latitude[df$station == stations[j]][1]\n    lon2 <- df$longitude[df$station == stations[j]][1]\n    my_points[i, j] <- as.vector(dist(matrix(c(lon1,lon2,lat1,lat2),\n                                             nrow = 2)))  \n    \n  }\n}\n\ndistance_df <- as.data.frame(my_points)\n\n\nThis gives:\n         V1       V2       V3        V4\n1  0.000000 44.73631 13.67355  1.386235\n2 44.736313  0.00000 31.59835 43.480707\n3 13.673546 31.59835  0.00000 12.612446\n4  1.386235 43.48071 12.61245  0.000000\n\nA slightly better way of finding unique stations:\nunique(df[, c(\"station\", \"latitude\", \"longitude\")])\n\nYou can then loop over those instead:\n# Loop through each station combination\nfor (i in 1:length(stations)) {\n  for (j in 1:length(stations)) {\n    # Get temperatures for the two stations\n    lat1 <- unique_df$latitude[unique_df$station == stations[i]]\n    lon1 <- unique_df$longitude[unique_df$station == stations[i]]\n    lat2 <- unique_df$latitude[unique_df$station == stations[j]]\n    lon2 <- unique_df$longitude[unique_df$station == stations[j]]\n    my_points[i, j] <- as.vector(dist(matrix(c(lon1,lon2,lat1,lat2),\n                                             nrow = 2)))  \n    \n  }\n}\n\n\n"
},
{
"QuestionId": "76381890",
"QuestionTitle": "save multiple pdf pages with different sizes in Shiny R",
"QuestionBody": "Im developing a shiny app with several features. I added a button to download a single pdf file that contains many plots. I want to save those plots in individual pages but I want to choose the size of each pdf page. Is that possible?\nThis is he code that  have so far:\noutput$exportall<-downloadHandler(\nfilename=\"Allplots.pdf\",\ncontent=function(file){\n  withProgress(message = 'Exporting', min=0,max=1, { \n    pdf(file,width=8,height=11)\n    print(plot1())\n    print(histogram())\n    print(plots2())\n    print(marrangeGrob(woodsbytimepoint(), nrow=2, ncol=1))\n    print(digestion())\n    print(map())\n    print(marrangeGrob(allplots(), nrow=4, ncol=2, top=NULL))\n    \n  dev.off()\n  })\n }\n)\n\nThe code works fine and exports all the plots that I want. However, all pages in the pdf file are 8x11. Is there a way to speciffy the size of each page? for example I want the first plot to be 7x7 and all other 8x11.\nAny ideas?\n",
"AnswerId": "76382014",
"AnswerBody": "Perhaps the simplest is to create separate PDFs (sized appropriately) and combine them with qpdf::pdf_combine.\nfile <- \"file.pdf\"\npdf(paste0(file, \".8x11\"), width=8, height=11)\nplot(disp ~ mpg, data = mtcars)\ngg <- ggplot(mtcars, aes(disp, mpg)) + geom_point()\nprint(gg)\ndev.off()\npdf(paste0(file, \".7x7\"), width=7, height=7)\nprint(gg) # or anything else\ndev.off()\nqpdf::pdf_combine(paste0(file, c(\".8x11\", \".7x7\")), file)\nfile.remove(paste0(file, c(\".8x11\", \".7x7\")))\n\nThe resulting file.pdf pages:\n\nIf your sizes are not always in order (e.g., 8x11, 7x7, 8x11), you can either:\n\ncreate three PDF files (would need an adjusted file name convention) and concatenate in order, or\ncreate two PDF files (by dimensions), then also use qpdf::pdf_subset ... though since this creates new PDF files that you would then need to include in pdf_combine, it hardly seems the most efficient method.\n\nI cannot test this, but I think this means your code should be\noutput$exportall<-downloadHandler(\nfilename=\"Allplots.pdf\",\ncontent=function(file){\n  withProgress(message = 'Exporting', min=0,max=1, { \n    pdf(paste0(file, \".7x7\"), width=7, height=7)\n    print(plot1())\n    dev.off()\n    pdf(paste0(file, \".8x11\"), width=8, height=11)\n    print(histogram())\n    print(plots2())\n    print(marrangeGrob(woodsbytimepoint(), nrow=2, ncol=1))\n    print(digestion())\n    print(map())\n    print(marrangeGrob(allplots(), nrow=4, ncol=2, top=NULL))\n    dev.off()\n    qpdf::pdf_combine(paste0(file, c(\".7x7\", \".8x11\")), output=file)\n  })\n }\n)\n\n"
},
{
"QuestionId": "76385216",
"QuestionTitle": "Why can I only print the text of a text file once?",
"QuestionBody": "I have written a little class which reads a text file and which have a method for printing the text (file.output()). For the first call it worked, but the second call of the method nothing is happening. I do not understand why, since I assume that the FOR-Loop does not change anything.\nclass Datei():\n    def __init__(self, filename):\n        self.fileobject = open(filename)\n        \n    def output(self): \n        for line in self.fileobject: \n            print(line.rstrip())\n        \n    \n    def end(self): \n        self.fileobject.close()\n\nfile = Datei(\"yellow_snow.txt\")\nfile.output()\nprint(\"second try\")\nfile.output()\n\nfile.end()\n\nI expected the text of the text file to be printed twice, but it is only printed once.\n",
"AnswerId": "76385238",
"AnswerBody": "When you read a file, you move a pointer through it, and it's now at the end - you can .seek(0) to get back to the start (or other positions, 0 is where you started from, which is the beginning if you're not in append mode)\nwith open(path) as fh:\n    print(fh.tell())  # start of file\n    print(fh.read())  # get everything and display it\n    print(fh.tell())  # end of file\n    fh.seek(0)        # go back to the beginning\n    print(fh.tell())  # start of file\n    print(fh.read())\n\nMore detail in Python Documentation 7.2.1. Methods of File Objects\n"
},
{
"QuestionId": "76381693",
"QuestionTitle": "How to sort array elements based on the closest occurrence of a sublist with a numeric value of 1.0? And then combine this sorted matrix with another",
"QuestionBody": "How do I correct my code to be able to order its elements according to which has the canonical vector with a value equal to 1.0 in the element closest to the beginning of its sublists (ignoring the first sublist, which is the one with the titles, although this will also change position according to the position of element 1.0 in the other remaining ones), thus remaining?\nmatrix = [['B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], [8, 2.0, 1.0, -1.0, 0, 0, 1.0, 0], [2, 1.0, 1.0, 0, 1.0, 0, 0, 0], [8, 1.0, 2.0, 0, 0, -1.0, 0, 1.0]]\n\nmatrix_aux = [['X4', 'U1', 'U2'], [0, 1.0, 0], [1.0, 0, 0], [0, 0, 1.0]]\n\n#Extract the first title sublist\ntitles = matrix_aux.pop(0)\n\n#Create a list of tuples, and sort it\ntuple_list = [(sublist.index(1.0), sublist) for sublist in matrix_aux]\nsorted_tuples = sorted(tuple_list, key=lambda x: x[0])\n\n#Rebuild the sorted array\nmatrix_aux_ord = [[titles[i] for i in range(len(titles))]] + [sublist for _, sublist in sorted_tuples]\n\nprint(matrix_aux_ord)\nfor row in matrix_aux_ord: print(row) #print in matrix format\n\nthe problem now with my code is that it forgets to sort the row of titles or headers ['X4', 'U1', 'U2'], incorrectly printing this matrix\n[['X4', 'U1', 'U2'], [1.0, 0, 0], [0, 1.0, 0], [0, 0, 1.0]]\n\ninstead of this that if it maintains consistency\n[['U1', 'X4', 'U2'], [1.0, 0, 0], [0, 1.0, 0], [0, 0, 1.0]]\n\nThen, having these 2 matrices, build the new matrix called new_matrix, in which I would add a column in front of the matrix, that is, I would add an element to each of the sublists that make up the rows of matrix, to the first sublist of the matrix called matrix add an 'X' before it as the first element, and to the rest of the sublists of the matrix called matrix add as the first element in an ordered manner the elements of the first sublist of the matrix called matrix_aux_ord\nmatrix = [['B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], [8, 2.0, 1.0, -1.0, 0, 0, 1.0, 0], [2, 1.0, 1.0, 0, 1.0, 0, 0, 0], [8, 1.0, 2.0, 0, 0, -1.0, 0, 1.0]]\n\n#If the previous code worked, it would get this array sorted like this...\nmatrix_aux_ord = [['U1', 'X4', 'U2'], [1.0, 0, 0], [0, 1.0, 0], [0, 0, 1.0]]\n\n#Add the column title or header 'X' to the front of the first sublist of matrix\nmatrix[0].insert(0, 'X')\n\nSo the resulting final matrix, the correct output, called as new_matrix, would look like this:\nnew_matrix = [['X', 'B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], ['U1', 8, 2.0, 1.0, -1.0, 0, 0, 1.0, 0], ['X4', 2, 1.0, 1.0, 0, 1.0, 0, 0, 0], ['U2', 8, 1.0, 2.0, 0, 0, -1.0, 0, 1.0]]\n\nWhat should I do to get the matrix_aux_ord correctly, and with it to be able to get the matrix new_matrix which basically consists of a way to combine amber matrices, matrix and matrix_aux_ord?\n",
"AnswerId": "76382030",
"AnswerBody": "You need to sort the titles together with the other lists. You can do it with zip\nmatrix = [['B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], [8, 2.0, 1.0, -1.0, 0, 0, 1.0, 0], [2, 1.0, 1.0, 0, 1.0, 0, 0, 0], [8, 1.0, 2.0, 0, 0, -1.0, 0, 1.0]]\nmatrix_aux = [['X4', 'U1', 'U2'], [0, 1.0, 0], [1.0, 0, 0], [0, 0, 1.0]]\n\nmatrix_aux_ord = list(zip(*sorted(zip(*matrix_aux), key=lambda x: x[1:].index(1.0))))\nprint(matrix_aux_ord)\n\n# [('U1', 'X4', 'U2'), (1.0, 0, 0), (0, 1.0, 0), (0, 0, 1.0)]\n\nAnd to add the titles to matrix use list comprehensions\ntitles = ['X'] + list(matrix_aux_ord[0])\nnew_matrix = [[titles[i]] + matrix[i] for i in range(len(titles))]\nprint(new_matrix)\n\n# [['X', 'B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], ['U1', 8, 2.0, 1.0, -1.0, 0, 0, 1.0, 0], ['X4', 2, 1.0, 1.0, 0, 1.0, 0, 0, 0], ['U2', 8, 1.0, 2.0, 0, 0, -1.0, 0, 1.0]]\n\n"
},
{
"QuestionId": "76383130",
"QuestionTitle": "Custom Reverse Scroll view in SwiftUI",
"QuestionBody": "I am building a chat window. We are currently in the migration phase from Objective-C to SwiftUI and we do support a minimum of iOS 13+.\nTo get behaviors of scroll view where I want to point to the bottom always as default and should be able to scroll up and down seamlessly.\nHere only problem is here scroll only works when i drag from bubble of chat from other places it doesn't works.\nI have debug quite long and not able to find the issue.\nReverse scroll view code which I got from here https://www.process-one.net/blog/writing-a-custom-scroll-view-with-swiftui-in-a-chat-application/\nstruct ReverseScrollView<Content>: View where Content: View {\n    @State private var contentHeight: CGFloat = CGFloat.zero\n    @State private var scrollOffset: CGFloat = CGFloat.zero\n    @State private var currentOffset: CGFloat = CGFloat.zero\n    \n    var content: () -> Content\n    \n    // Calculate content offset\n    func offset(outerheight: CGFloat, innerheight: CGFloat) -> CGFloat {        \n        let totalOffset = currentOffset + scrollOffset\n        return -((innerheight/2 - outerheight/2) - totalOffset)\n    }\n    \n    var body: some View {\n        GeometryReader { outerGeometry in\n            // Render the content\n            //  ... and set its sizing inside the parent\n            self.content()\n            .modifier(ViewHeightKey())\n            .onPreferenceChange(ViewHeightKey.self) { self.contentHeight = $0 }\n            .frame(height: outerGeometry.size.height)\n            .offset(y: self.offset(outerheight: outerGeometry.size.height, innerheight: self.contentHeight))\n            .clipped()\n            .animation(.easeInOut)\n            .gesture(\n                 DragGesture()\n                    .onChanged({ self.onDragChanged($0) })\n                    .onEnded({ self.onDragEnded($0, outerHeight: outerGeometry.size.height)}))\n        }\n    }\n    \n    func onDragChanged(_ value: DragGesture.Value) {\n        // Update rendered offset\n\n        self.scrollOffset = (value.location.y - value.startLocation.y)\n    }\n    \n    func onDragEnded(_ value: DragGesture.Value, outerHeight: CGFloat) {\n        // Update view to target position based on drag position\n        let scrollOffset = value.location.y - value.startLocation.y\n        \n        let topLimit = self.contentHeight - outerHeight\n        \n        // Negative topLimit => Content is smaller than screen size. We reset the scroll position on drag end:\n        if topLimit < 0 {\n             self.currentOffset = 0\n        } else {\n            // We cannot pass bottom limit (negative scroll)\n            if self.currentOffset + scrollOffset < 0 {\n                self.currentOffset = 0\n            } else if self.currentOffset + scrollOffset > topLimit {\n                self.currentOffset = topLimit\n            } else {\n                self.currentOffset += scrollOffset\n            }\n        }\n        self.scrollOffset = 0\n    }\n}\n\nstruct ViewHeightKey: PreferenceKey {\n    static var defaultValue: CGFloat { 0 }\n    static func reduce(value: inout Value, nextValue: () -> Value) {\n        value = value + nextValue()\n    }\n}\n\nextension ViewHeightKey: ViewModifier {\n    func body(content: Content) -> some View {\n        return content.background(GeometryReader { proxy in\n            Color.clear.preference(key: Self.self, value: proxy.size.height)\n        })\n    }\n}\n\nChat window\nReverseScrollView {\n\n    VStack{\n        \n        HStack {\n            VStack(spacing: 5){\n                Text(\"message.text\")\n                    .padding(.vertical, 8)\n                    .padding(.horizontal)\n                    .background(Color(.systemGray5))\n                    .foregroundColor(.primary)\n                    .clipShape(ChatBubble(isFromCurrentUser: false))\n                    .frame(maxWidth: .infinity, alignment: .leading)\n                    .padding(.horizontal)\n                    .lineLimit(nil) // Allow unlimited lines\n                    .lineSpacing(4) // Adjust line spacing as desired\n                    .fixedSize(horizontal: false, vertical: true) // Allow vertical expansion\n\n                \n                Text(\"ormatTime(message.timeUtc)\")\n                    .font(.caption)\n                    .foregroundColor(.secondary)\n                    .background(Color.red)\n                    .frame(maxWidth: .infinity, alignment: .leading)\n                    .padding(.horizontal, 5)\n\n\n            }\n            .background(Color.blue)\n\n            \n            Spacer()\n        }\n\n        \n        ForEach(Array(viewModel.chats.indices), id: \\.self){ index in\n            let message = viewModel.chats[index]\n            VStack(alignment: .leading, spacing: 5) {\n                // Chat bubble view for received messages\n                \n                if(message.isIncoming){\n                    HStack {\n                        VStack(spacing: 5){\n                            Text(message.text)\n                                .padding(.vertical, 8)\n                                .padding(.horizontal)\n                                .background(Color(.systemGray5))\n                                .foregroundColor(.primary)\n                                .clipShape(ChatBubble(isFromCurrentUser: false))\n                                .frame(maxWidth: .infinity, alignment: .leading)\n                                .padding(.horizontal)\n                                .lineLimit(nil) // Allow unlimited lines\n                                .lineSpacing(4) // Adjust line spacing as desired\n                                .fixedSize(horizontal: false, vertical: true) // Allow vertical expansion\n                                .frame(maxWidth: .infinity, alignment: .leading)\n\n                            \n                            Text(formatTime(message.timeUtc))\n                                .font(.caption)\n                                .foregroundColor(.secondary)\n                                .frame(maxWidth: .infinity, alignment: .leading)\n                                .padding(.horizontal, 5)\n                        }\n\n                        \n                        Spacer()\n                    }\n                }else{\n                    \n                \n                    HStack {\n                        Spacer()\n                        \n                        VStack(spacing: 5){\n                            Text(message.text)\n                                .padding(.vertical, 8)\n                                    .padding(.horizontal)\n                                    .background(Color(.systemBlue))\n                                    .foregroundColor(.white)\n                                    .clipShape(ChatBubble(isFromCurrentUser: true))\n                                    .padding(.horizontal)\n                                    .lineLimit(nil) // Allow unlimited lines\n                                    .lineSpacing(4) // Adjust line spacing as desired\n                                    .fixedSize(horizontal: false, vertical: true) // Allow vertical expansion\n                            \n                            Text(formatTime(message.timeUtc))\n                                .font(.caption)\n                                .foregroundColor(.secondary)\n                                .frame(maxWidth: .infinity, alignment: .leading)\n                                .padding(.horizontal, 5)\n                        }\n                        .frame(maxWidth: .infinity, alignment: .trailing)\n\n                        \n                    }\n                \n                }\n            }\n          \n        \n        }\n        if(viewModel.messageSending) {\n            VStack(spacing: 5){\n                HStack {\n                    Spacer()\n                    Text(sendingText)\n                        .padding(.vertical, 8)\n                        .padding(.horizontal)\n                        .background(Color(.systemBlue))\n                        .foregroundColor(.white)\n                        .clipShape(ChatBubble(isFromCurrentUser: true))\n                        .padding(.horizontal)\n                }\n                HStack {\n                    Spacer()\n                    ChatBubbleAnimationView()\n                        .padding(.trailing, 8)\n                }\n            }\n            .padding(.bottom, 20)\n            .onDisappear(){\n                sendingText = \"\"\n                messageText = \"\"\n            }\n        }\n    }\n}\n\nChat bubble wrapper\nstruct ChatBubble: Shape {\n    var isFromCurrentUser: Bool\n    \n    func path(in rect: CGRect) -> Path {\n        let path = UIBezierPath(roundedRect: rect, byRoundingCorners: isFromCurrentUser ? [.topLeft, .bottomLeft, .bottomRight] : [.topRight, .bottomLeft, .bottomRight], cornerRadii: CGSize(width: 12, height: 12))\n        \n        return Path(path.cgPath)\n    }\n}\n\nPlease let me know something other information need. I am looking for suggestions to get the behaviours keeping in mind it should support iOS 13+ or any help to get above code fixed.\n",
"AnswerId": "76383421",
"AnswerBody": "One option is to just flip the built-in ScrollView upside down.\nimport SwiftUI\n\nstruct ReverseScroll: View {\n    var body: some View {\n        ScrollView{\n            ForEach(ChatMessage.samples) { message in\n                HStack {\n                    if message.isCurrent {\n                        Spacer()\n                    }\n                    Text(message.message)\n                        .padding()\n                        .background {\n                            RoundedRectangle(cornerRadius: 10)\n                                .fill(message.isCurrent ? Color.blue : Color.gray)\n                        }\n                    if !message.isCurrent {\n                        Spacer()\n                    }\n                }\n            }.rotationEffect(.degrees(180)) //Flip View upside down oldest above newest below.\n        }.rotationEffect(.degrees(180)) //Reverse so it works like a chat message\n    }\n}\n\nstruct ReverseScroll_Previews: PreviewProvider {\n    static var previews: some View {\n        ReverseScroll()\n    }\n}\n\nstruct ChatMessage: Identifiable, Equatable{\n    let id: UUID = .init()\n    var message: String\n    var isCurrent: Bool\n    \n    static let samples: [ChatMessage] = (0...25).map { n in\n            .init(message: n.description + UUID().uuidString, isCurrent: Bool.random())\n    }\n}\n\nThe scroll indicators show on the left with this but can be hidden in iOS 16+ with\n.scrollIndicators(.hidden)\n\nIf you decide to support iOS 14+ you can use ScrollViewReader to scroll to the newest message.\nstruct ReverseScroll: View {\n    @State private var messages = ChatMessage.samples\n    var body: some View {\n        VStack{\n            ScrollViewReader { proxy in\n                ScrollView{\n                    ForEach(messages) { message in\n                        HStack {\n                            if message.isCurrent {\n                                Spacer()\n                            }\n                            Text(message.message)\n                                .padding()\n                                .background {\n                                    RoundedRectangle(cornerRadius: 10)\n                                        .fill(message.isCurrent ? Color.blue : Color.gray)\n                                }\n                            if !message.isCurrent {\n                                Spacer()\n                            }\n                        }\n                        .id(message.id) //Set the ID\n                        \n                    }.rotationEffect(.degrees(180))\n                }.rotationEffect(.degrees(180))\n                    .onChange(of: messages.count) { newValue in\n                        proxy.scrollTo(messages.last?.id) //When the count changes scroll to latest message\n                    }\n            }\n            Button(\"add\") {\n                messages.append( ChatMessage(message: Date().description, isCurrent: Bool.random()))\n                \n            }\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76384846",
"QuestionTitle": "The first timer in a react component list is getting value NaN",
"QuestionBody": "I have a React website where I have 2 toggles for different kinds of cards - one of them is Live markets (this type has a timer component).\n\nHere is the problem- When I switch to classifieds and I switch back to live markets -\nAuction timer for the first card becomes NaN. Note: this only happens to the first card, the other timers are fine.\n\nI have a CardsLayout component, which send a request to the server for data when the above toggle is changed. And if it is in Live Markets tab, then the CardsLayout component maps each object to an AuctionCard component which has a Timer component inside it.\nHere is the code for the Timer component-\nimport { useState, useEffect } from 'react';\n\nexport default function Timer({ id, endTime}) {\n  const [remainingTime, setRemainingTime] = useState(getRemainingTime());\n\n  useEffect(() => {\n    const interval = setInterval(() => {\n      setRemainingTime(getRemainingTime());\n    }, 1000);\n\n    return () => clearInterval(interval);\n  }, []);\n\n  function getRemainingTime() {\n    const now = new Date();\n    const end = new Date(endTime);\n    const diff = end.getTime() - now.getTime();\n    const days = Math.floor(diff / (1000 * 60 * 60 * 24));\n    const hours = Math.floor((diff / (1000 * 60 * 60)) % 24);\n    const minutes = Math.floor((diff / (1000 * 60)) % 60);\n    const seconds = Math.floor((diff / 1000) % 60);\n    return { days, hours, minutes, seconds };\n  }\n\n  console.log('endtime-',id,endTime)\n  console.log('remtime-',id,remainingTime.seconds)\n\n  return (\n    <div className={remainingTime.seconds < 0 ? 'timer-ended' : 'timer'}>\n      {remainingTime.seconds < 0 ? (\n        \"Auction over\"\n      ) : (\n        <>\n          Auction time remaining: {remainingTime.days} Days {remainingTime.hours}:\n          {remainingTime.minutes}:{remainingTime.seconds}\n        </>\n      )}\n    </div>\n  );\n}\n\nI also have 2 console statements. The values are getting printed every second. Here is whats getting printed for the Timer with NaN-\nendtime- 4 2023-06-09T20:30:00.000Z\nremtime- 4 NaN\n",
"AnswerId": "76385239",
"AnswerBody": "Since it works after you add id and endTime as dependencies to the useEffect (as mentioned in the comments of the OP), it seems that the issue is that the first render you do of the first Time is done without/or with a wrong endTime so it end up displaying NaN.\nSubsequent renders, I assume after fetching the data from somewhere, provide a valid endTime value for that property.\nInitially the change in that prop would not alter the functionality of the ongoing interval, since the getRemainingTime would refer to the initial value of endTime.\nThere are a few solutions to this problem.\n\nDo not render the Timer component until after you have valid data to provide to it. This need to be handled at the component using the Timer and not inside it.\nProvide a key for the Timer component when using it (<Timer key={/*what ever you use for id will most likely work here too*/} id={..} endTime={..} /> that is unique and would change once you get the data from the remote location.\nUse correct dependencies for the useEffect.\n\nFor 3. the more correct approach is not to add id and endTime to the useEffect but to use useCallback, with endTime for the getRemainingTime and then use that as dependency for the useEffect.\nconst getRemainingTime = useCallback(function() {\n  const now = new Date();\n  const end = new Date(endTime);\n  const diff = end.getTime() - now.getTime();\n  const days = Math.floor(diff / (1000 * 60 * 60 * 24));\n  const hours = Math.floor((diff / (1000 * 60 * 60)) % 24);\n  const minutes = Math.floor((diff / (1000 * 60)) % 60);\n  const seconds = Math.floor((diff / 1000) % 60);\n  return { days, hours, minutes, seconds };\n}, [endTime]);\n\nuseEffect(() => {\n  const interval = setInterval(() => {\n    setRemainingTime(getRemainingTime());\n  }, 1000);\n\n  return () => clearInterval(interval);\n}, [getRemainingTime]);\n\n"
},
{
"QuestionId": "76381953",
"QuestionTitle": "Reverse the content order of several columns (ideally in tidyverse)",
"QuestionBody": "Assuming the following data:\ndf <- data.frame(a = 1:3, b = c(1, 2, 6), c = c(4, 6, NA), d = c(6, NA, NA))\n\n  a b  c  d\n1 1 1  4  6\n2 2 2  6 NA\n3 3 6 NA NA\n\nAnd what I want is:\n  a b  c  d\n1 1 6  4  1\n2 2 6  2 NA\n3 3 6 NA NA\n\nI thought about some combination of across and rev, but my current attempts don't work.\n",
"AnswerId": "76382049",
"AnswerBody": "You can do the following:\npivot_longer(df, -a) %>%\n  filter(!is.na(value)) %>%\n  mutate(value=rev(value), .by=a) %>%\n  pivot_wider(names_from = name, values_from = value)\n\nOutput:\n      a     b     c     d\n  <int> <dbl> <dbl> <dbl>\n1     1     6     4     1\n2     2     6     2    NA\n3     3     6    NA    NA\n\n"
},
{
"QuestionId": "76380645",
"QuestionTitle": "Azure Diagnostic Logs saved to another location",
"QuestionBody": "I'm looking to create using Bicep, diagnostic settings on a firewall in one location and save to an Event Hub in another location. The two vnets are peered, but I am wondering if it is possibe based on this error message:\nResource '/subscriptions/123/resourceGroups/ukw-rg/providers/Microsoft.Network/azureFirewalls/ukw-fw' is in region 'ukwest' and resource '/subscriptions/123/resourcegroups/uks-rg/providers/microsoft.eventhub/namespaces/uks-evhns' is in region 'uksouth'\n\n",
"AnswerId": "76382058",
"AnswerBody": "You are correct. It isn't possible. https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings?tabs=portal#destination-limitations\n\"The event hub namespace needs to be in the same region as the resource being monitored if the resource is regional.\"\nkind regards\nAlistair\n"
},
{
"QuestionId": "76381970",
"QuestionTitle": "How do I get my embed tag to display videos instead of downloading them?",
"QuestionBody": "My embed tag keeps downloading the video instead of displaying it.\nI have tried changing the file type of the tag, but it just downloads it in a different format. I want the tag to display the video. Here's my code below.\n\n\n<embed type=\"video/mp4\" src=\"videos/ymcaHome.mp4\" width=\"400\" height=\"300\">\n\n\n\n",
"AnswerId": "76382106",
"AnswerBody": "You can do so by specifying the video url or the path as the src attribute value. Like this:\n\n\n<embed src=\"your_video_file_url.mp4\" type=\"video/mp4\" with=\"640\" height=\"360\">\n\n\n\n"
},
{
"QuestionId": "76382470",
"QuestionTitle": "What causes the different NaN behavior when compiling `_mm_ucomilt_ss` intrinsic?",
"QuestionBody": "Can someone explain me why the following code fails for GCC 8.5 with NaNs?\nbool isfinite_sse42(float num)\n{    \n    return _mm_ucomilt_ss(_mm_set_ss(std::abs(num)),\n                          _mm_set_ss(std::numeric_limits<float>::infinity())) == 1;\n}\n\nMy expectation for GCC 8.5 would be to return false.\nThe Intel Intrinsics guide for _mm_ucomilt_ss says\nRETURN ( a[31:0] != NaN AND b[31:0] != NaN AND a[31:0] == b[31:0] ) ? 1 : 0\n\ni.e., if either a or b is NaN it returns 0. On assembly level (Godbolt) one can see a ucomiss abs(x), Infinity followed by a setb.\n# GCC8.5 -O2  doesn't match documented intrinsic behaviour for NaN\n        ucomiss xmm0, DWORD PTR .LC2[rip]\n        setb    al\n\nInterestingly newer GCCs and Clang swap the comparison from a < b to b > a and therefore use seta. But why does the code with setb returns true for NaN and why seta returns false for NaN?\n",
"AnswerId": "76383422",
"AnswerBody": "GCC is buggy before GCC13, not implementing the documented semantics of the intrinsic for the NaN case which require either checking PF separately, or doing it as ucomiss Inf, abs so the unordered case sets CF the same way as abs < Inf.\nSee https://www.felixcloutier.com/x86/ucomiss#operation or the nicer table in https://www.felixcloutier.com/x86/fcomi:fcomip:fucomi:fucomip .  (All x86 scalar FP compares that set EFLAGS do it the same way, matching historical fcom / fstsw / sahf.)\n\n\n\n\nComparison Results\nZF\nPF\nCF\n\n\n\n\nleft > right\n0\n0\n0\n\n\nleft < right\n0\n0\n1\n\n\nleft = right\n1\n0\n0\n\n\nUnordered\n1\n1\n1\n\n\n\n\nNotice that CF is set for both the left < right and unordered cases, but not for the other two cases.\nIf you can arrange things such that you can check for > or >=, you don't need to setnp cl / and al, cl to rule out Unordered.  This is what clang 16 and GCC 13 do to get correct results from ucomiss inf, abs / seta.\nGCC8.5 does the right thing if you write abs(x) < infinity, it's only the scalar intrinsic that it doesn't implement properly.  (With plain scalar code, it uses comiss instead of ucomiss, the only difference being that it will update the FP environment with a #I FP-exception on QNaN as well as SNaN.)\nThis requires a separate movss load instead of a memory source.  But this does let GCC avoid the useless SSE4.1 insertps instruction that zeros the high 3 elements of XMM0, which ucomiss doesn't read anyway.  Clang sees that and optimizes away that part of _mm_set_ss(num) but GCC doesn't. The lack of an efficient way to go from a scalar float to a __m128 with don't-care upper elements is a persistent problem in Intel's intrinsics API that only some compilers manage to optimize around.  (How to merge a scalar into a vector without the compiler wasting an instruction zeroing upper elements? Design limitation in Intel's intrinsics?)  A float is just the low element of a __m128.\n"
},
{
"QuestionId": "76385202",
"QuestionTitle": "Why won't Binary search find an element in Java?",
"QuestionBody": "Why won't Binary Search find an element?\nI have one array with elements: BBBB, BBBB, CCCC. I want to find elements BBBB and BBBB. I want binary search to find two elements and it finds one. The output is \"1\" and it should be \"2\".\nimport java.util.*;\n\npublic class Test{\n    public static void main(String[] args) {\n        ArrayList<String> bricks = new ArrayList<String>(List.of(\"BBBB\",\"BBBB\",\"CCCC\"));\n        ArrayList<String> bricksNeeded = new ArrayList<String>(List.of(\"BBBB\",\"BBBB\"));\n        int nFound = 0;\n        int index;\n        for(String brickNeeded:bricksNeeded){\n            index = Collections.binarySearch(bricks, brickNeeded);\n            if(index >= 0){\n                bricks.remove(bricks.get(index));\n                nFound ++;\n                break;\n            }\n        }\n        System.out.println(nFound);\n    }\n}\n\nOutput:\n1\nExpected output:\n2\n",
"AnswerId": "76385273",
"AnswerBody": "You have statement break - loop will be stopped after first removing.\nSo, nFound will be incremented only once\n"
},
{
"QuestionId": "76381948",
"QuestionTitle": "How to select multiple DIVs by mousedown>mousemove>mouseup (pure JS)",
"QuestionBody": "I'm trying to make a selection of elements when I click on empty point and move pointer.\nIn this example I'm expecting to get selection of two elements:\n\nI've tried range and selection, but not with the proper result.\n\n\nconst mainDiv = document.createElement(\"div\");\nmainDiv.style.width = \"500px\";\nmainDiv.style.height = \"500px\";\ndocument.body.appendChild(mainDiv);\n\nconst div1 = document.createElement(\"div\");\ndiv1.style.position = \"absolute\";\ndiv1.style.top = `${50}px`;\ndiv1.style.left = `${50}px`;\ndiv1.style.width = \"100px\";\ndiv1.style.height = \"100px\";\ndiv1.style.background = \"red\";\nmainDiv.appendChild(div1);\n\nconst div2 = document.createElement(\"div\");\ndiv2.style.top = `${250}px`;\ndiv2.style.left = `${250}px`;\ndiv2.style.width = \"100px\";\ndiv2.style.height = \"100px\";\ndiv2.style.background = \"green\";\ndiv2.style.position = \"absolute\";\nmainDiv.appendChild(div2);\n\nmainDiv.onmousedown = function(event) {\n  function onMouseMove(event) {\n    //add divs to selection\n  }\n  mainDiv.addEventListener('mousemove', onMouseMove);\n\n  mainDiv.onmouseup = function() {\n    console.log(\"selected divs\")\n  }\n}\n\n\n\n",
"AnswerId": "76382120",
"AnswerBody": "You can solve this by keeping an array of selected items and pushing items to it when the mouse moves over the items if the mouse is depressed.\n\n\nconst mainDiv = document.createElement(\"div\");\nmainDiv.style.width = \"500px\";\nmainDiv.style.height = \"500px\";\ndocument.body.appendChild(mainDiv);\n\nconst div1 = document.createElement(\"div\");\ndiv1.style.position = \"absolute\";\ndiv1.style.top = `${50}px`;\ndiv1.style.left = `${50}px`;\ndiv1.style.width = \"100px\";\ndiv1.style.height = \"100px\";\ndiv1.style.background = \"red\";\nmainDiv.appendChild(div1);\n\nconst div2 = document.createElement(\"div\");\ndiv2.style.top = `${250}px`;\ndiv2.style.left = `${250}px`;\ndiv2.style.width = \"100px\";\ndiv2.style.height = \"100px\";\ndiv2.style.background = \"green\";\ndiv2.style.position = \"absolute\";\nmainDiv.appendChild(div2);\n\n\n!(() => {\n  let selection = [];\n  let selecting = false;\n  function beginSelection(e) {\n    selection = [];\n    selecting = true;\n    checkSelection(e);\n  }\n  function mouseMove(e) {\n    checkSelection(e);\n  }\n  function mouseUp(e) {\n    selecting = false;\n    if (selection.length) {\n      console.log(\"selection: \", selection); // access selection before reset\n      selection = [];\n    } else {\n      // no selection\n    }\n  }\n  function checkSelection(e) {\n    if (!selecting) {\n      return; // ignore\n    }\n    const selected = e.target.parentNode === mainDiv && e.target;\n    if (selected && !selection.includes(selected)) {\n      selection.push(selected);\n    }\n  }\n  mainDiv.addEventListener(\"mousedown\", beginSelection);\n  mainDiv.addEventListener(\"mousemove\", mouseMove);\n  window.addEventListener(\"mouseup\", mouseUp);\n  \n})();\n\n\n\n"
},
{
"QuestionId": "76381936",
"QuestionTitle": "create on off toggle Icon for flutter torch",
"QuestionBody": "I tried to implement  the possibility to use the flash of the phone as a torch in my flutter app. The on/ off button is located in the appbar. This runs fine except the light on and light off Button appear both at the same time. How can I make it, that either one or the other is shown. depending on whether the lamp is on or off?\nThank you very much for your help\nI used the flutter torch_light: ^0.4.0\n\nClass TorchController extends StatelessWidget {\n  const TorchController({super.key});\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n\n      body: FutureBuilder<bool>(\n        future: _isTorchAvailable(context),\n        builder: (BuildContext context, AsyncSnapshot<bool> snapshot) {\n          if (snapshot.hasData && snapshot.data!) {\n            return Column(\n              children: [\n                Expanded(\n                  child: Center(\n                    child: IconButton ( icon: const Icon(Icons.flashlight_on_outlined,size: 35,),\n\n\n                      onPressed: () async {\n                        _enableTorch(context);\n                      },\n                    ),\n                  ),\n                ),\n                Expanded(\n                  child: Center(\n                    child: IconButton (icon: const Icon(Icons.flashlight_off_outlined,size: 35,),\n\n\n                      onPressed: () async {\n                        _disableTorch(context);\n                      },\n                    ),\n                  ),\n                ),\n              ],\n            );\n          } else if (snapshot.hasData) {\n            return const Center(\n              child: Text('No torch available.'),\n            );\n          } else {\n            return const Center(\n              child: CircularProgressIndicator(),\n            );\n          }\n        },\n      ),\n    );\n  }\n\n Future<bool> _isTorchAvailable(BuildContext context) async {\n   try {\n    return await TorchLight.isTorchAvailable();\n    } on Exception catch (_) {\n      _showMessage(\n        'Could not check if the device has an available torch',\n       context,\n      );\n      rethrow;\n    }\n  }\n\n  Future<void> _enableTorch(BuildContext context) async {\n    try {\n      await TorchLight.enableTorch();\n    } on Exception catch (_) {\n      _showMessage('Could not enable torch', context);\n    }\n  }\n\n  Future<void> _disableTorch(BuildContext context) async {\n    try {\n      await TorchLight.disableTorch();\n    } on Exception catch (_) {\n      _showMessage('Could not disable torch', context);\n    }\n  }\n\n  void _showMessage(String message, BuildContext context) {\n    ScaffoldMessenger.of(context)\n        .showSnackBar(SnackBar(content: Text(message)));\n  }\n}\n//Ende```\n\n",
"AnswerId": "76382142",
"AnswerBody": "First of all, change the widget from stateless to stateful widget. Then\n\ndefine a variable to show the status of the torch\n\nisTorchOn = false;\n\n\non _enableTorch() update the value to true\n\n(no need to pass context as it is now a stateful widget)\n\n\nFuture<void> _enableTorch(BuildContext context) async {\n        try {\n          await TorchLight.enableTorch();\n          setState(()=> isTorchOn = true);\n        } on Exception catch (_) {\n          _showMessage('Could not enable torch', context);\n        }\n      }\n\n\n\n\ndo the same for _disableTorch() as set isTorchOn to false\n\n\n\nFuture<void> _disableTorch(BuildContext context) async {\n    try {\n      await TorchLight.disableTorch();\n      setState(()=> isTorchOn = false);\n    } on Exception catch (_) {\n      _showMessage('Could not disable torch', context);\n    }\n  }\n\n\n\n"
},
{
"QuestionId": "76383358",
"QuestionTitle": "Delete all the lines including and after nth occurance of pattern",
"QuestionBody": "Basically what the title says, I have some large tsv file (approx. 20k lines) and I want to delete the rest of the files after a specific column matches a string a second time (including said line)\n",
"AnswerId": "76383463",
"AnswerBody": "awk '{print $0} $1==\"yourstring\"{if(++found==2)exit}' test.tsv\n\nWhere $1 is the \"specific column\" and yourstring is the string you are searching for.\nThis prints each line and then checks for the occurrence of yourstring in the first column. If it finds it, it tests a variable found which we increment, to see if it hits 2. If so awk exits.\nEdit: If instead you want to delete the second occurrence (as well as everything after), flipping the two blocks around will accomplish this:\n awk ' $1==\"yourstring\"{if(++found==2)exit}{print $0}' test.tsv\n\n"
},
{
"QuestionId": "76384747",
"QuestionTitle": "how can I do an empty triangle with stars in c++ to after do the british flag?",
"QuestionBody": "This is the flag that I have to get at the end:\n*******************\n**       *       **\n* *      *      * *\n*  *     *     *  *\n*   *    *    *   *\n*    *   *   *    *\n*     *  *  *     *\n*      * * *      *\n*       ***       *\n*******************\n*       ***       *\n*      * * *      *\n*     *  *  *     *\n*    *   *   *    *\n*   *    *    *   *\n*  *     *     *  *\n* *      *      * *\n**       *       **\n*******************\n\nI know how to do full star triangles but when it's empty on the inside I have no idea about how to proceed. Can anyone help me?\nI tried and I just know how to do full star triangles and a star square/rectangle empty on the inside here is the code:\nint main(void)\n{\n    int i, j, length, width;\n\n    cout << \"Length of rectangle? \";\n    cin >> length;\n    cout << endl;\n\n    cout << \"Width of rectangle? \";\n    cin >> width;\n    cout << endl;\n\n    for ( i = 0; i < length; i++ )\n        cout << \"*\";\n\n    cout << endl;\n\n    for ( i = 1; i < width - 1; i++ )\n    {\n        cout << \"*\";\n\n        for ( j = 1; j < length - 1; j++ )\n        {\n            cout << \" \";\n        }\n\n        cout << \"*\";\n        cout << endl;\n    }\n\n    for ( i = 0; i < length; i++)\n        cout << \"*\";\n\n    cout << endl;\n\n    return 0;\n}\n\n",
"AnswerId": "76385292",
"AnswerBody": "Lines 1, 10 and 19 are easy, as they each consist only of 19 *.\nThe problem is the lines 2 to 9 and 11 to 19.\nHowever, do you notice a pattern in lines 2 to 9?\nLine 2 consists of one *\n\nfollowed by 0 spaces\nfollowed by one *\nfollowed by 7 spaces\nfollowed by one *\nfollowed by 7 spaces\nfollowed by one *\nfollowed by 0 spaces\n\nfollowed by one *\nLine 3 consists of one *\n\nfollowed by 1 spaces\nfollowed by one *\nfollowed by 6 spaces\nfollowed by one *\nfollowed by 6 spaces\nfollowed by one *\nfollowed by 1 spaces\n\nfollowed by one *.\nLine 4 consists of one *\n\nfollowed by 2 spaces\nfollowed by one *\nfollowed by 5 spaces\nfollowed by one *\nfollowed by 5 spaces\nfollowed by one *\nfollowed by 2 spaces\n\nfollowed by one *.\nLine 5 consists of one *\n\nfollowed by 3 spaces\nfollowed by one *\nfollowed by 4 spaces\nfollowed by one *\nfollowed by 4 spaces\nfollowed by one *\nfollowed by 3 spaces\n\nfollowed by one *.\nLine 6 consists of one *\n\nfollowed by 4 spaces\nfollowed by one *\nfollowed by 3 spaces\nfollowed by one *\nfollowed by 3 spaces\nfollowed by one *\nfollowed by 4 spaces\n\nfollowed by one *.\nLine 7 consists of one *\n\nfollowed by 5 spaces\nfollowed by one *\nfollowed by 2 spaces\nfollowed by one *\nfollowed by 2 spaces\nfollowed by one *\nfollowed by 5 spaces\n\nfollowed by one *.\nLine 8 consists of one *\n\nfollowed by 6 spaces\nfollowed by one *\nfollowed by 1 spaces\nfollowed by one *\nfollowed by 1 spaces\nfollowed by one *\nfollowed by 6 spaces\n\nfollowed by one *.\nLine 9 consists of one *\n\nfollowed by 7 spaces\nfollowed by one *\nfollowed by 0 spaces\nfollowed by one *\nfollowed by 0 spaces\nfollowed by one *\nfollowed by 7 spaces\n\nfollowed by one *.\nThe pattern is the following:\nAssuming that size is the total size of the triangle (which is 19 in your case), then\nline n consists of one *\n\nfollowed by n-2 spaces\nfollowed by one *\nfollowed by (size/2) - n spaces\nfollowed by one *\nfollowed by (size/2) - n spaces\nfollowed by one *\nfollowed by n-2 spaces\n\nfollowed by one *.\nNote that in C, the result of 19 / 2 is 9, as the fractional part of the division is discarded.\nUsing this information about the pattern, you should be able to create a loop that in every loop iteration, prints one line as described above. That way, you should be able to solve the problem of printing the lines 2 to 9.\nPrinting the lines 11 to 19 should be easy afterwards, because these lines must only be printed in reverse order of the lines 2 to 9.\nIn accordance with the community guidelines for homework questions, I will not provide the full solution at this time. I can provide further information later, if necessary.\nEDIT:\nSince several other solutions have already been posted by other users, I will now also post my solution, which solves the problem as described above:\n#include <iostream>\n\nconst int MAP_SIZE = 19;\n\nstatic_assert( MAP_SIZE % 2 == 1, \"MAP_SIZE must be odd\" );\n\nint main( void )\n{\n    //print first horizontal line\n    for ( int i = 0; i < MAP_SIZE; i++ )\n        std::cout << '*';\n    std::cout << '\\n';\n\n    //print top half of flag\n    for ( int i = 0; i < MAP_SIZE / 2 - 1; i++ )\n    {\n        std::cout << '*';\n        for ( int j = 0; j < i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        for ( int j = 0; j < MAP_SIZE/2 - 2 - i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        for ( int j = 0; j < MAP_SIZE/2 - 2 - i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        for ( int j = 0; j < i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        std::cout << '\\n';\n    }\n\n    //print second horizontal line\n    for ( int i = 0; i < MAP_SIZE; i++ )\n        std::cout << '*';\n    std::cout << '\\n';\n\n    //print bottom half of flag\n    for ( int i = 0; i < MAP_SIZE / 2 - 1; i++ )\n    {\n        std::cout << '*';\n        for ( int j = 0; j < MAP_SIZE/2 - 2 - i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        for ( int j = 0; j < i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        for ( int j = 0; j < i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        for ( int j = 0; j < MAP_SIZE/2 - 2 - i; j++ )\n            std::cout << ' ';\n        std::cout << '*';\n        std::cout << '\\n';\n    }\n\n    //print third horizontal line\n    for ( int i = 0; i < MAP_SIZE; i++ )\n        std::cout << '*';\n    std::cout << '\\n';\n}\n\nHowever, I think that this problem is easier to solve using a 2D array (which you stated that you are not allowed to use). The 2D array is initialized to spaces and then the 3 horizontal, 3 vertical and 2 diagonal lines are drawn:\n#include <iostream>\n\nconst int MAP_SIZE = 19;\n\nstatic_assert( MAP_SIZE % 2 == 1, \"MAP_SIZE must be odd\" );\n\nint main( void )\n{\n    char map[MAP_SIZE][MAP_SIZE];\n\n    //initialize 2D array to spaces\n    for ( int i = 0; i < MAP_SIZE; i++ )\n        for ( int j = 0; j < MAP_SIZE; j++ )\n            map[i][j] = ' ';\n\n    //draw the 3 horizontal lines\n    for ( int i = 0; i < MAP_SIZE; i++ )\n    {\n        map[         0][i] = '*';\n        map[MAP_SIZE/2][i] = '*';\n        map[MAP_SIZE-1][i] = '*';\n    }\n\n    //draw the 3 vertical lines\n    for ( int i = 0; i < MAP_SIZE; i++ )\n    {\n        map[i][         0] = '*';\n        map[i][MAP_SIZE/2] = '*';\n        map[i][MAP_SIZE-1] = '*';\n    }\n\n    //draw the 2 diagonal lines\n    for ( int i = 0; i < MAP_SIZE; i++ )\n    {\n        map[i][           i] = '*';\n        map[i][MAP_SIZE-i-1] = '*';\n    }\n\n    //print the result\n    for ( int i = 0; i < MAP_SIZE; i++ )\n    {\n        std::cout.write( map[i], MAP_SIZE );\n        std::cout.put( '\\n' );\n    }\n}\n\n"
},
{
"QuestionId": "76384972",
"QuestionTitle": "Is it possible to merge two tables in Power Query Editor (Power BI) with Python fuzzy matching?",
"QuestionBody": "Merge two tables in power query editor (Power BI) based on string similarity with Python\nConsider the tables bellow:\nTable1\nTable1\n\n\n\n\nName\n...\n\n\n\n\nApple Fruit A11\n...\n\n\nBanana Fruit B12\n...\n\n\n...\n...\n\n\n\n\nTable2\nTable2\n\n\n\n\nName\nValue\n\n\n\n\nApple A11R/T\n40\n\n\nB4n4n4 Fruit B12_T\n50\n\n\nBerry A11\n60\n\n\n...\n...\n\n\n\n\nI want to get the Value from Table2 into Table1. But for some reason when I use the built-in power query editor merge with fuzzy matching. It will match Apple Fruit A11 with Berry A11 instead of Apple A11 R/T. I've read the documentation, and it says that the built-in function works best with single words. I tried to remove spaces both from Table1[Name] and Table2[Name] but it didn't improve results.\nI looked around trying to find a solution, but wasn't able to figure out yet. Is there a way to do this using python? Or is there a simpler solution?\nThe results that I am expecting:\nTable1\nExpected Result\n\n\n\n\nName\n...\nTable2.Name\nTable2.Value\n\n\n\n\nApple Fruit A11\n...\nApple A11R/T\n40\n\n\nBanana Fruit B12\n...\nB4n4n4 Fruit B12_T\n50\n\n\n...\n...\n...\n...\n\n\n\n\n--- For some reason the tables are not showing up like the preview, that's why there are also images for each table. Disclaimer: The data present in the tables above is just an example of the pattern of the data that I am working with. And fuzzy matching will probably give the right results for the example data.\n",
"AnswerId": "76385313",
"AnswerBody": "Fuzzy matching in Power Query works fine for me.\n\nSet your options to the following:\n\n"
},
{
"QuestionId": "76382116",
"QuestionTitle": "How can I modify my C code to replace words in a file without user input?",
"QuestionBody": "/**\n * C program to find and replace all occurrences of a word in file.\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#define BUFFER_SIZE 1000\n\n/* Function declaration */\nvoid replaceAll(char *str, const char *oldWord, const char *newWord);\n\n\nint main()\n{\n/* File pointer to hold reference of input file */\nFILE * fPtr;\nFILE * fTemp;\nchar path[100];\n\nchar buffer[BUFFER_SIZE];\nchar oldWord[100], newWord[100];\n\n\nprintf(\"Enter path of source file: \");\nscanf(\"%s\", path);\n\nprintf(\"Enter word to replace: \");\nscanf(\"%s\", oldWord);\n\nprintf(\"Replace '%s' with: \");\nscanf(\"%s\", newWord);\n\n\n/*  Open all required files */\nfPtr  = fopen(path, \"r\");\nfTemp = fopen(\"replace.tmp\", \"w\"); \n\n/* fopen() return NULL if unable to open file in given mode. */\nif (fPtr == NULL || fTemp == NULL)\n{\n    /* Unable to open file hence exit */\n    printf(\"\\nUnable to open file.\\n\");\n    printf(\"Please check whether file exists and you have read/write privilege.\\n\");\n    exit(EXIT_SUCCESS);\n}\n\n\n/*\n * Read line from source file and write to destination \n * file after replacing given word.\n */\nwhile ((fgets(buffer, BUFFER_SIZE, fPtr)) != NULL)\n{\n    // Replace all occurrence of word from current line\n    replaceAll(buffer, oldWord, newWord);\n\n    // After replacing write it to temp file.\n    fputs(buffer, fTemp);\n}\n\n\n/* Close all files to release resource */\nfclose(fPtr);\nfclose(fTemp);\n\n\n/* Delete original source file */\nremove(path);\n\n/* Rename temp file as original file */\nrename(\"replace.tmp\", path);\n\nprintf(\"\\nSuccessfully replaced all occurrences of '%s' with '%s'.\", oldWord, newWord);\n\nreturn 0;\n}\n\n\n\n/**\n * Replace all occurrences of a given a word in string.\n */\nvoid replaceAll(char *str, const char *oldWord, const char *newWord)\n{\nchar *pos, temp[BUFFER_SIZE];\nint index = 0;\nint owlen;\n\nowlen = strlen(oldWord);\n\n// Fix: If oldWord and newWord are same it goes to infinite loop\nif (!strcmp(oldWord, newWord)) {\n    return;\n}\n\n\n/*\n * Repeat till all occurrences are replaced. \n */\nwhile ((pos = strstr(str, oldWord)) != NULL)\n{\n    // Backup current line\n    strcpy(temp, str);\n\n    // Index of current found word\n    index = pos - str;\n\n    // Terminate str after word found index\n    str[index] = '\\0';\n\n    // Concatenate str with new word \n    strcat(str, newWord);\n    \n    // Concatenate str with remaining words after \n    // oldword found index.\n    strcat(str, temp + index + owlen);\n}\n}\n\nI have that code in C which can change all \"oldWords\" into \"newWords\". Works fine, but everytime I want to change the code to change the words on its own I'm completely stupid. I want that I don't have to put the words that have to change into the console, but I want to have them in the code. I just want to tell the console the path of the source file and that's it.\nWould be nice if you could help me with some examples like Hello to Bye and Morning to Night.\n",
"AnswerId": "76382155",
"AnswerBody": "If you don't want to take oldWord and newWord from user input, you can define them as constants in the code:\nconst char* oldWord = \"Hello\";\nconst char* newWord = \"Bye\";\n\n"
},
{
"QuestionId": "76383388",
"QuestionTitle": "I want to set new object in local storage",
"QuestionBody": "function addNote() {\n    const givenTitle = document.getElementById('titleInput');\n    const givenNote = document.getElementById('noteInput');\n    \n    let notesObj = []\n\n    let myObj = {\n        title: givenTitle.value,\n        note: givenNote.value,\n    }\n\n    notesObj.push(myObj)\n\n    localStorage.setItem('userNote',JSON.stringify(notesObj));\n}\n\nThis code is everyTime changing the older value I want to get a new object in local storage\n",
"AnswerId": "76383465",
"AnswerBody": "Probably you want to add note into your existing localStorage data so here you can check if there is userNote is already set before then take it or set an empty array,\nlet notesObj = JSON.parse(localStorage.getItem(\"userNote\")) || []\n\nYour whole function would be like this,\nfunction addNote() {\n    const givenTitle = document.getElementById('titleInput');\n    const givenNote = document.getElementById('noteInput');\n    \n    let notesObj = JSON.parse(localStorage.getItem(\"userNote\")) || []\n\n    let myObj = {\n        title: givenTitle.value,\n        note: givenNote.value,\n    }\n\n    notesObj.push(myObj)\n\n    localStorage.setItem('userNote',JSON.stringify(notesObj));\n}\n\n"
},
{
"QuestionId": "76385055",
"QuestionTitle": "Trying to assign a response.data value to a variable in react and the value doesnt pass well",
"QuestionBody": "Im building an AuthContext in react to handle login, i connect it to a django backend where i validate the user and then i get an authorization token\nimport React, { createContext, useState, useEffect} from 'react';\nimport axios from 'axios';\n\nexport const AuthContext = createContext();\n\n\n  export const AuthProvider = ({ children }) => {\n    const [token, setToken] = useState(null);\n  \n    const login = async (username, password) => {\n      try {\n        const response = await axios.post('http://127.0.0.1:8000/token/', {\n          username,\n          password\n        });\n        console.log('Response data:', response.data);\n        const { token: responseToken } = response.data;\n        setToken(responseToken);\n    \n        console.log('Token loaded:', responseToken);\n      } catch (error) {\n        console.error('Error en el inicio de sesión:', error);\n      }\n    };    \n  \n    useEffect(() => {\n      console.log('Token actual value:', token); \n    }, [token]);\n  \n    return (\n      <AuthContext.Provider value={{ token, login }}>\n        {children}\n      </AuthContext.Provider>\n    );\n  };\n\n\nFrom my backend i get the expected answer, an status 200 with the token that i expect, but after assign the response.data to responseToken, in the next log it shows that is undefined. Here is the output in the navigator console:\nconsole logs\nTried to change the variable names to check if there is a conflict between those declared there, but the problem persists.\n",
"AnswerId": "76385319",
"AnswerBody": "Your console log shows that response data has two properties refresh & access. But you are trying to get a property called token, which does not exist (or at least it's not visible in your screenshot).\nconst { access: responseToken } = response.data;\n\nThis should help. (if access is the one you actually need)\n"
},
{
"QuestionId": "76383411",
"QuestionTitle": "ReactJs why do i get two console logs in a simple component?",
"QuestionBody": "i have this simple nav component, but it drives me crazy because it makes every console log i make in the app two times.\nIm new to React btw.\nexport const NavBar = () => {\n  const [showNav, setShowNav] = useState(false);\n\n  const handleNavClick = () => {\n    setShowNav(!showNav);\n  };\n\n  console.log(\"hi\");\n\n  return (\n    <>\n      <nav className=\"flex items-center justify-between pl-8 pr-16 fixed w-full border h-20 top-0 bg-white/30 backdrop-blur-sm z-10\">\n        {/* Logo */}\n        <img\n          src=\"https://res.cloudinary.com/dv8nczwtj/image/upload/v1684896617/Logo_jivlnb.png\"\n          alt=\"Logo\"\n          className=\"logo\"\n        />\n        {/* Nav WEB*/}\n        <div className=\"md:flex flex-row space-x-5 hidden\">\n          <a href=\"#\" className=\"brand\">\n            Apple\n          </a>\n          <a href=\"#\" className=\"brand\">\n            Samsung\n          </a>\n          <a href=\"#\" className=\"brand\">\n            Xiaomi\n          </a>\n          <a href=\"#\" className=\"brand\">\n            Google\n          </a>\n        </div>\n        {/* BTN Nav Mobil */}\n        <button className=\"md:hidden\" onClick={handleNavClick}>\n          <img\n            src=\"https://res.cloudinary.com/dv8nczwtj/image/upload/v1684859901/menu_wh8ccz.png\"\n            alt=\"Menu\"\n            className=\"w-6\"\n          />\n        </button>\n        {/* Cart */}\n        <CartWidget />\n      </nav>\n      {/* Nav Mobil */}\n      {showNav && (\n        <div\n          className=\"flex fixed w-full flex-col justify-center items-center space-y-4 pb-2 border-b-2 border-black md:hidden bg-white/30 top-20 pt-4 backdrop-blur-sm\"\n          style={{ animation: \"fadeIn .5s linear\" }}\n        >\n          <a href=\"#\" className=\"brand\">\n            Apple\n          </a>\n          <a href=\"#\" className=\"brand\">\n            Samsung\n          </a>\n          <a href=\"#\" className=\"brand\">\n            Xiaomi\n          </a>\n          <a href=\"#\" className=\"brand\">\n            Google\n          </a>\n        </div>\n      )}\n    </>\n  );\n};\n\ndouble console.log\nI have tried putting the handleClick function in a useEffect but then when i put it on the onClick it says that the function is never declared\n",
"AnswerId": "76383481",
"AnswerBody": "Is your app using React.StrictMode (https://react.dev/reference/react/StrictMode#fixing-bugs-found-by-double-rendering-in-development) ?\n"
},
{
"QuestionId": "76381116",
"QuestionTitle": "Error in as.vector(x, mode) : cannot coerce type 'closure' to vector of type 'any' -- when running a nested function",
"QuestionBody": "Problem: running get_pi_ij() gives the error:\nError in as.vector(x, mode) : cannot coerce type 'closure' to vector of type 'any'\nCalled from: as.vector(data)\nThe first thing this function does is to make the resulting alphas and beta_prelims into matrixes that match c so that they can be calculated together. This is where something goes wrong, and I have not been able to figure out what. If I use <<- to save the alphas and betas to the global environment in the prior functions for alphas and betas and replace that with those in the faulty function, it works. So I assume it has to do with how I call the functions inside the matrix creation.\nget_pi_ij <- function() {\n  alphas <-\n    matrix(get_alpha(),\n           nrow = length(get_alpha()),\n           ncol = length(get_alpha()),\n           byrow = FALSE)\n  betas <-\n    matrix(get_beta_prelim,\n           nrow = length(get_beta_prelim()),\n           ncol = length(get_beta_prelim()),\n           byrow = TRUE) \n  pi_ij <- exp(alphas + betas + gamma * c)\n  return(pi_ij)\n}\nget_pi_ij()\n\nI added the full code cause it's not too long and the first parts are just definitions. Makes it easier to test it.\nEverything up to the final function works as it is supposed to\nsize <- 18 \ngamma <- -0.07 \n\nc <- structure(c(0, 4, 8, 12, 16, 4, 4, 8, 12, 16, 8, 8, 8, 12, 16, \n            12, 12, 16, 16, 4, 0, 4, 8, 12, 8, 4, 4, 8, 12, 12, 8, 8, 12, \n            16, 12, 12, 16, 16, 8, 4, 0, 4, 8, 12, 8, 4, 8, 12, 16, 12, 8, \n            12, 16, 16, 12, 16, 16, 12, 8, 4, 0, 4, 12, 8, 4, 4, 8, 16, 12, \n            8, 8, 12, 16, 12, 12, 16, 16, 12, 8, 4, 0, 16, 12, 8, 4, 4, 16, \n            12, 8, 8, 8, 16, 12, 12, 16, 4, 8, 12, 12, 16, 0, 4, 8, 12, 16, \n            4, 4, 8, 12, 16, 8, 8, 12, 12, 4, 4, 8, 8, 12, 4, 0, 4, 8, 12, \n            8, 4, 4, 8, 12, 8, 8, 12, 12, 8, 4, 4, 4, 8, 8, 4, 0, 4, 8, 12, \n            8, 4, 8, 12, 12, 8, 12, 12, 12, 8, 8, 4, 4, 12, 8, 4, 0, 4, 12, \n            8, 4, 4, 8, 12, 8, 8, 12, 16, 12, 12, 8, 4, 16, 12, 8, 4, 0, \n            16, 12, 8, 4, 4, 12, 8, 8, 12, 8, 12, 16, 16, 16, 4, 8, 12, 12, \n            16, 0, 4, 8, 12, 16, 4, 8, 12, 8, 8, 8, 12, 12, 12, 4, 4, 8, \n            8, 12, 4, 0, 4, 8, 12, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, \n            8, 8, 4, 0, 4, 8, 8, 4, 8, 8, 12, 12, 12, 8, 8, 12, 8, 8, 4, \n            4, 12, 8, 4, 0, 4, 8, 4, 4, 8, 16, 16, 16, 12, 8, 16, 12, 12, \n            8, 4, 16, 12, 8, 4, 0, 12, 8, 4, 8, 12, 12, 16, 16, 16, 8, 8, \n            12, 12, 12, 4, 4, 8, 8, 12, 0, 4, 8, 4, 12, 12, 12, 12, 12, 8, \n            8, 8, 8, 8, 8, 4, 4, 4, 8, 4, 0, 4, 4, 16, 16, 16, 12, 12, 12, \n            12, 12, 8, 8, 12, 8, 8, 4, 4, 8, 4, 0, 4, 16, 16, 16, 16, 16, \n            12, 12, 12, 12, 12, 8, 8, 8, 8, 8, 4, 4, 4, 0), \n          .Dim = c(19L, 19L), \n          .Dimnames = list(NULL, c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \n                                   \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \n                                   \"X11\", \"X12\", \"X13\", \"X14\", \"X15\", \n                                   \"X16\", \"X17\", \"X18\", \"X19\")))\n\nset.seed(12345) \nh_share <- diff(c(0, sort(runif(size)), 1)) \ne_share <- diff(c(0, sort(runif(size)), 1)) \n\nalpha <- numeric(size + 1)\nbeta <- numeric(size + 1)\n\nget_beta_prelim <- function() {\n  a_matrix <- exp(alpha + t(c) * gamma)\n  beta_prelim <- log(e_share) - log(colSums(a_matrix))\n  return(beta_prelim)\n}\n\nget_beta <- function() {\n  beta <- get_beta_prelim() - get_beta_prelim()[[1]]\n  return(beta)\n}\n\nget_alpha_prelim <- function() {\n  b_matrix <- t(exp(beta + t(c) * gamma))\n  alpha_prelim <- log(h_share) - log(rowSums(b_matrix))\n  return(alpha_prelim)\n}\n\nget_alpha <- function() {\n  alpha <- get_alpha_prelim() - get_alpha_prelim()[[1]]\n  return(alpha)\n}\n\nget_pi_ij <- function() {\n  alphas <-\n    matrix(get_alpha(),\n           nrow = length(get_alpha()),\n           ncol = length(get_alpha()),\n           byrow = FALSE)\n  betas <-\n    matrix(get_beta_prelim,\n           nrow = length(get_beta_prelim()),\n           ncol = length(get_beta_prelim()),\n           byrow = TRUE) \n  pi_ij <- exp(alphas + betas + gamma * c)\n  return(pi_ij)\n}\nget_pi_ij()\n\n",
"AnswerId": "76382168",
"AnswerBody": "get_pi_ij <- function() {\n  alphas <-\n    matrix(get_alpha(),\n           nrow = length(get_alpha()),\n           ncol = length(get_alpha()),\n           byrow = FALSE)\n  betas <-\n    matrix(get_beta_prelim(), # your were missing \"()\"\n           nrow = length(get_beta_prelim()),\n           ncol = length(get_beta_prelim()),\n           byrow = TRUE) \n  pi_ij <- exp(alphas + betas + gamma * c)\n  return(pi_ij)\n}\n\n"
},
{
"QuestionId": "76385032",
"QuestionTitle": "How to Fix NoMethodError Issue with Ruby Compass (1.0.0 and 1.0.3)",
"QuestionBody": "I have a Fedora 38 (6.1.29-1) server with Ruby and the Compass gem installed.\nWhen I try to execute compass -h or perform any compass compiling, I get a NoMethodError (on different lines of different .rb files, but errors nonetheless).\nI've looked all around for similar errors and can't seem to find anyone else that experiences this problem.\nAt first I thought maybe the latest version (1.0.3) of Compass doesn't work on my server, so I also tried 1.0.0 but still get the same error.\nI also tried installing the same version(s) and followed the same process on my Windows machine and had no issues when executing the same compass -h and compass compile commands.\nAnyone have any idea what is causing this error on my fedora server?\nWhen executing \"compass -h\" on the command line on the Fedora server...\nCurrent Output:\nNoMethodError on line [\"144\"] of /home/user1/.local/share/gem/ruby/gems/compass-1.0.0/lib/compass/installers/manifest.rb: undefined method `exists?' for File:Class\n\nExpected Output:\nUsage: compass help [command]\n\nDescription:\n  The Compass Stylesheet Authoring Framework helps you\n  build and maintain your stylesheets and makes it easy\n  for you to use stylesheet libraries provided by others.\n\nDonating:\n  Compass is charityware. If you find it useful please make\n  a tax deductable donation: http://umdf.org/compass\n\nTo get help on a particular command please specify the command.\n\nPrimary Commands:\n  * clean       - Remove generated files and the sass cache\n  * compile     - Compile Sass stylesheets to CSS\n  * create      - Create a new compass project\n  * init        - Add compass to an existing project\n  * watch       - Compile Sass stylesheets to CSS when they change\nOther Commands:\n  * config      - Generate a configuration file for the provided command line options.\n  * extension   - Manage the list of compass extensions on your system\n  * frameworks  - List the available frameworks\n  * help        - Get help on a compass command or extension\n  * imports     - Emit an imports suitable for passing to the sass command-line.\n  * install     - Install an extension's pattern into your compass project\n  * interactive - Interactively evaluate SassScript\n  * sprite      - Generate an import for your sprites.\n  * stats       - Report statistics about your stylesheets\n  * unpack      - Copy an extension into your extensions folder.\n  * validate    - Validate your generated css.\n  * version     - Print out version information\n\nAvailable Frameworks & Patterns:\n\n  * compass\n    - compass/ellipsis  - Plugin for cross-browser ellipsis truncated text.\n    - compass/extension - Generate a compass extension.\n    - compass/project   - The default project layout.\n\nGlobal Options:\n    -r, --require LIBRARY            Require the given ruby LIBRARY before running commands.\n                                       This is used to access compass plugins without having a\n                                       project configuration file.\n    -l, --load FRAMEWORK_DIR         Load the framework or extensions found in the FRAMEWORK directory.\n    -L, --load-all FRAMEWORKS_DIR    Load all the frameworks or extensions found in the FRAMEWORKS_DIR directory.\n    -I, --import-path IMPORT_PATH    Makes files under the IMPORT_PATH folder findable by Sass's @import directive.\n    -q, --quiet                      Quiet mode.\n        --trace                      Show a full stacktrace on error\n        --force                      Allows compass to overwrite existing files.\n        --boring                     Turn off colorized output.\n    -?, -h, --help                   Show this message\n\n",
"AnswerId": "76385330",
"AnswerBody": "File.exists? was deprecated for several minor versions and existed until Ruby 2.7. And was finally removed in Ruby 3.0.\nWhereas the last version of the compass gem is more than 8 years old. That means it doesn't work with current version of Ruby anymore.\nYou have basically three options:\n\nDowngrade your Ruby version to, for example, 2.7.8. That version is not terrible out-dated, but keep in mind that Ruby 2.7 reached end-of-life, it will not get any security or bug fixes anymore.\nFork the compass gem and fix the usage of File.exists? with File.exist?. This seems to be a quick fix, but given that this gem didn't get any update in the last 8 years, you might discover further compatibility issues or unfixed bugs.\nSearch for an alternative and replace that gem.\n\n"
},
{
"QuestionId": "76384401",
"QuestionTitle": "How can I obtain the folder path when right-clicking the background of a folder and invoking a context menu using a shell extension?",
"QuestionBody": "How to obtain path to folder  in which user made right click in its background to invoke context menu? For example, user opened \"D:\\projects\" folder and made right click in empty background area of that folder and it sees a menu item in context menu named 'Display Path'. Upon clicking it, it should invoke a simple console app to display string \"D:\\projects\".\nIt can be done by registry by adding \"%V\" as argument to command to console app, for example, \"C:\\myfolder\\myapp.exe\" \"%V\". Hence, this %V gives folder path to argument list of main() of myuapp.exe. Easy huh!\nHow it can be done using shell extension menu handler? I wrote a simple shell context menu dll which works fine and do its job, except that I don't known how to get that folder path as string where user made right click in background.\nI found that path comes as PCIDLIST_ABSOLUTE pidl argument in IShellExtInit::Initialize() method. But, I couldn't get it in simple string format. The code is below which crashes, of course.\nHRESULT __stdcall Initialize(PCIDLIST_ABSOLUTE pidlFilder, IDataObject* pdtobj, HKEY hkeyProgID)\n    {\n        std::wstring s = L\"null\";\n        \n        // check msg, this msgbox is shown as expected\n        MessageBox(NULL, L\"Before\", L\"Initialize()\", MB_OK);\n                \n                //have problem in this line, I guess\n        SHGetPathFromIDList((LPCITEMIDLIST) pidlFilder, (PWSTR) &s);\n        \n        // check msg, sometimes this msgbox is also shown as expected\n        MessageBox(NULL, L\"After\", L\"Initialize()\", MB_OK);\n        \n        // but this msgbox is never shown. I removed it but code still crashes\n        MessageBox(NULL, std::wstring(s).c_str(), L\"Initialize()\", MB_OK);\n        \n        return S_OK;\n    }\n\nWhen I right click on folder background, it crashes and explorer restarts.\nDoes anyone know the problem and its solution? How to get folder path when right clicking background of folder to invoke context menu using shell extension?\nIn addition, how to get file/folder path when right clicking on it to invoke context menu using shell extension?\nThanks in advance\ntried using this code too, still crashes\n                IShellFolder *sf = NULL;\n        STRRET pName = {};\n        sf->GetDisplayNameOf(pidlFilder, SHGDN_FORPARSING, &pName);\n        wchar_t *d = new wchar_t;\n        lstrcpyW(d,L\"nulld\");\n        size_t inst = MAX_PATH, outst ;\n        mbstowcs_s(&outst, d, inst, pName.cStr, MAX_PATH);\n        s = std::wstring(d);\n                MessageBox(NULL, std::wstring(s).c_str(), L\"Initialize()\", MB_OK);\n\n",
"AnswerId": "76385345",
"AnswerBody": "You are trying to make SHGetPathFromIDList() write the string data to the memory address where a std::wstring object resides, which will not work.\nUse a fixed WCHAR[] array instead, eg:\nHRESULT __stdcall Initialize(PCIDLIST_ABSOLUTE pidlFilder, IDataObject* pdtobj, HKEY hkeyProgID)\n{\n    WCHAR szPath[MAX_PATH] = {};\n\n    SHGetPathFromIDList(pidlFilder, szPath);\n\n    MessageBox(NULL, szPath, L\"Initialize()\", MB_OK);\n        \n    return S_OK;\n}\n\nAlternatively, if you want to receive the string data into a std::wstring object, then you have to pre-allocate its internal character buffer and then receive into that buffer, eg:\nHRESULT __stdcall Initialize(PCIDLIST_ABSOLUTE pidlFilder, IDataObject* pdtobj, HKEY hkeyProgID)\n{\n    std::wstring s;\n    s.resize(MAX_PATH);\n        \n    SHGetPathFromIDList(pidlFilder, s.data() /* or &s[0] before C++17 */ );\n    s.erase(s.find(L'\\0'));\n\n    MessageBox(NULL, s.c_str(), L\"Initialize()\", MB_OK);\n        \n    return S_OK;\n}\n\nOtherwise, you can simply receive into a WCHAR[] and then assign that to your std::wstring, eg:\nHRESULT __stdcall Initialize(PCIDLIST_ABSOLUTE pidlFilder, IDataObject* pdtobj, HKEY hkeyProgID)\n{\n    WCHAR szPath[MAX_PATH] = {};\n    SHGetPathFromIDList(pidlFilder, szPath);\n        \n    std::wstring s = szPath;\n    MessageBox(NULL, s.c_str(), L\"Initialize()\", MB_OK);\n        \n    return S_OK;\n}\n\n\nYour 2nd example doesn't work for several reasons:\n\nYour IShellFolder *sf doesn't point anywhere meaningful. Use SHGetDesktopFolder() to get the top-level IShellFolder object which you can then use to parse pidlFilder.\n\nyou are allocating only 1 wchar_t for wchar_t *d to point at, but then you are trying to copy more than 1 wchar_t into that memory.  You don't really need to allocate any memory at all, as the parsed STRRET already contains the necessary string data, so just use it as-is.  Otherwise, you can pass the STRRET to StrRetToBuf() or StrRetToStr() to get the data in a more usable format.\n\nyou are not paying attention to the STRRET::uType field to know what kind of string data it is holding.  Don't access the cStr field unless the uType field is set to STRRET_CSTR.  StrRetToBuf()/StrRetToStr() will handle this for you.\n\n\nTry this instead:\nHRESULT __stdcall Initialize(PCIDLIST_ABSOLUTE pidlFilder, IDataObject* pdtobj, HKEY hkeyProgID)\n{\n    IShellFolder *sf = NULL;\n    if (SUCCEEDED(SHGetDesktopFolder(&sf))\n    {\n        STRRET pName = {};\n        if (SUCCEEDED(sf->GetDisplayNameOf(pidlFilder, SHGDN_FORPARSING, &pName))\n        {\n            WCHAR szPath[MAX_PATH] = {};\n            StrRetToBufW(&pName, pidlFilder, szPath, MAX_PATH);\n\n            MessageBox(NULL, szPath, L\"Initialize()\", MB_OK);\n        }\n\n        sf->Release();\n    }\n\n    return S_OK;\n}\n\n"
},
{
"QuestionId": "76383425",
"QuestionTitle": "Bash if statement expression evaluates to FALSE but $? is 0, why?",
"QuestionBody": "The example below echoes 1, as expected:\ntest -f /usr/bin\necho \"$?\" #1\n\nWhy does the following example echo 0?\nif [[ -f /usr/bin ]]; then\n    echo \"Inside if statement\" # This line is never executed    \nfi\necho \"$?\" #0\n\nI know that the $?evaluates to the returned value of the last executed command. In my understanding, the last executed command is test, that is implicitly called by the if statement, since the condition evaluates to false it should return 1, but when I execute it, it returns 0. Can anybody explain why the behavior is different than when test is executed directly (like in the first example)?\n",
"AnswerId": "76383491",
"AnswerBody": "According to man bash:\n\n\nif list; then list; [ elif list; then list; ] ... [ else list; ] fi\nThe if list is executed.  If its exit status is zero, the then list is  executed.   Otherwise,  each  elif list  is executed in turn, and if its exit status is zero, the corresponding then list is executed and the\ncommand completes.  Otherwise, the else list is executed, if present.  The exit status is the exit  status\nof the last command executed, or zero if no condition tested true.\n\n\n\n"
},
{
"QuestionId": "76381858",
"QuestionTitle": "How can I convert a left table into a summary table?",
"QuestionBody": "How do I convert table left to summary table right?\n\nI tried using get dummies function to convert values to 0 and 1.\nI don't know how to proceed after that.\n",
"AnswerId": "76382169",
"AnswerBody": "Try this:\nimport pandas as pd\nimport numpy as np\ncol1 = ['']+['Hampshire']*8+['']+['Hampshire']+['']+['Hampshire']+['','']+['Hampshire']*4\ncol2 = ['Southhampton'] + ['']*12 + ['Southhampton']*2 + ['']*4\ncol3 = ['']*11 + ['Isle of wight'] + ['']*7\ncol4 = ['Met']*5 + [''] + ['Met']*13\ncol5 = ['']*5 + ['Partially met'] + ['']*13\ncol6 = ['']*19\n\ndf = pd.DataFrame(data = dict(zip(['Hampshire', 'Southhampton', 'Isle of wight', '5met', '5partially met', '5Not met'],[col1,col2,col3,col4,col5,col6])))\ndf = df.replace('', np.nan)\ndf['Hampshire'] = df['Hampshire'].fillna(df['Southhampton'])\ndf['Hampshire'] = df['Hampshire'].fillna(df['Isle of wight'])\ndf[['Hampshire','5met','5partially met', '5Not met']].groupby(by=['Hampshire']).count()\n\nI had to generate the data for you (since you didn't post any besides the image), but I think this get's the job done. I hope this helps.\n"
},
{
"QuestionId": "76385289",
"QuestionTitle": "Is there a way to use onSchedule and also set a custom 'timeoutSeconds' and 'memory' using Firebase functions V2?",
"QuestionBody": "I have had to revert back to using Firebase functions V1 in order to schedule the running of my functions and also specify the runtime options including timeoutSeconds and memory in my code (written in TypeScript):\nconst runtimeOpts = {\n    timeoutSeconds: 540,\n    memory: \"1GB\" as const,\n};\nexports.cleanupEvents = functions\n    .runWith(runtimeOpts)\n    .pubsub.schedule(\"0 0 * * *\")\n    .timeZone(\"Europe/Berlin\")\n    .onRun(async () => {\n        await cleanupOldEvents(adminDb);\n        logger.log(\"Event cleanup finished\");\n    });\n\n\nDoes anyone know if it is possible with Firebase functions V2 using the onSchedule syntax to also specify these runtimeOpts in code? Without needing to go into the google cloud console and manually setting it there.\nI have tried chaining'onSchedule' and 'runWith' together and seeing what other possibilities Emmet suggests, so far but had no luck.\n",
"AnswerId": "76385350",
"AnswerBody": "The API documentation for onSchedule suggests that you can pass an object as the first parameter, which is a ScheduleOptions object, an extension of GlobalOptions:\nonSchedule({\n    schedule: \"your-schedule-here\",\n    timeoutSeconds: your-timeout,\n    memory: your-memory,\n    // include other options here from SchedulerOptions or GlobalOptions\n}, (event) => { ... })\n\n"
},
{
"QuestionId": "76382755",
"QuestionTitle": "How can I use the ASP.NET [Range] annotation for IEnumerable elements?",
"QuestionBody": "I want to use the ASP.NET [Range] Annotation but for the elements IEnumerables.\nI used the existing RangeAttribute like this:\npublic class RangeEnumerable : RangeAttribute\n{\n    /// <inheritdoc/>\n    public RangeEnumerable(double minimum, double maximum) : base(minimum, maximum)\n    {\n    }\n\n    /// <inheritdoc/>\n    public RangeEnumerable(int minimum, int maximum) : base(minimum, maximum)\n    {\n    }\n\n    /// <inheritdoc/>\n    public RangeEnumerable([DynamicallyAccessedMembers((DynamicallyAccessedMemberTypes)(-1))] Type type, string minimum, string maximum) : base(type, minimum, maximum)\n    {\n    }\n\n    /// <inheritdoc/>\n    public override bool IsValid(object? value)\n    {\n        if (null == value) { return true; } \n\n        IEnumerable<object> list = ((IEnumerable)value).Cast<object>();\n        \n        foreach (object item in list)\n        {\n            if (!base.IsValid(item))\n            {\n                return false;\n            }                \n        }\n\n        return true;\n    }\n}\n\nand annotated my Parameter like this:\n[RangeEnumerable(MINIMUM_ANGLE, MAXIMUM_ANGLE)]\npublic IEnumerable<Double> PhaseAnglesVoltage { get; set; } = new List<double>();\n\nAnd wrote the following unit test:\n[Test]\npublic void TestInvalidPhaseAngleVoltageTooLow()\n{\n    // Arrange       \n    Loadpoint loadpoint1 = new Loadpoint();\n    loadpoint1.PhaseAnglesVoltage.Append(-1);\n\n    // Act\n    var errCount = ValidateObject(loadpoint1);\n\n    // Assert\n    Assert.AreEqual(1, errCount);\n}\n\nprivate int ValidateObject(object obj)\n{\n    var validationContext = new ValidationContext(obj, null, null);\n    var validationResults = new List<ValidationResult>();\n    Validator.TryValidateObject(obj, validationContext, validationResults, true);\n    return validationResults.Count;\n}\n\nI expected the loop to iterate over the elements of the List I used the annotation with, but in the IsValid-Function I always get an empty List instead of one with the element appended in the test.\n",
"AnswerId": "76383517",
"AnswerBody": "Ok, I've found the error, which was in the unit test. IEnumerable.Append doesn't add the element to the original object like List.Add does (see Difference between a List's Add and Append method?).\nChanging the unit test to the following does the trick.\n        [Test]\n        public void TestInvalidPhaseAngleVoltageTooLow()\n        {\n            // Arrange       \n            Loadpoint loadpoint1 = new Loadpoint();\n            loadpoint1.PhaseAnglesVoltage = loadpoint1.PhaseAnglesVoltage.Append(-1);\n\n            // Act\n            var errCount = ValidateObject(loadpoint1);\n   \n            // Assert\n            Assert.AreEqual(1, errCount);\n        }\n\n"
},
{
"QuestionId": "76383286",
"QuestionTitle": "XPath that returns true when at least one element matches",
"QuestionBody": "Let's assume we have the following XML response:\n<People>\n    <Person>\n        <Age>29</Age>\n    </Person>\n    <Person>\n        <Age>25</Age>\n    </Person>\n    <Person>\n        <Age>18</Age>\n    </Person>\n    <Person>\n        <Age>45</Age>\n    </Person>\n</People>\n\nI want an xpath 2.0 expression that will return true if there is at least one person with age between 18 and 22.\nMy current expression is:\nboolean(//*:Person[xs:integer(substring(//*[local-name() = 'Age']/text(), 2)) >= 18 and 22 >= xs:integer(substring(//*[local-name() = 'Age']/text(), 2))])\n\nBut this expression is not recursive so it produces the following error:\n\nA sequence of more than one item is not allowed as the first argument of substring() (\"29\", \"25\", ...)\n\nAny idea as to how I can achieve what I need?\n",
"AnswerId": "76383533",
"AnswerBody": "In XPath 2.0 this is exists(//Person[Age = (18 to 22)])\n"
},
{
"QuestionId": "76385245",
"QuestionTitle": "Strange behavior of str_replace",
"QuestionBody": "I have a user-settable text, where the default one is [Log in] or [register] to view the content.\nWhat I need, is to wrap the two words in square brackets in their respective links. But first, I need to check that the user didn't change this default text, in other words that they kept the square brackets. I won't go in great lengths in checking this. Just the existence of two sets of square brackets is enough. If that's the case, then I'll assume that the first link is for the login page, and the second is for the register-an-account page...\nSo, the if below does the job for me:\nif ( preg_match( '/\\[(.*?)\\].*\\[(.*?)\\]/', $text ) )\n\nThen, inside the if, my plan was to perform a str_replace() with two arrays like this:\n$text = str_replace( array( '[', ']', '[', ']' ), array( '%1$s', '%2$s', '%3$s', '%4$s' ), $text );\n\nBut this doesn't work the way I thought it would. I thought that since the two arrays have equal number of elements it'd do a 1-on-1 search and replace, meaning that it would turn the text to %1$sLog in%2$s or %3$sregister%4$s to view the content, whereas it turned to %1$sLog in%2$s or %1$sregister%2$s to view the content.\nWhy is that? If that's not the proper way to do that (which obviously isn't), what should I do instead?\nAny help would be very much appreciated. TIA.\n",
"AnswerId": "76385381",
"AnswerBody": "Try using preg_replace with your same pattern (with additional capture):\n$text = preg_replace('/\\[(.*?)\\](.*)\\[(.*?)\\]/', '%1$s$1%2$s$2%3$s$3%4$s', $text); \n\nwhich produces\n%1$sLog in%2$s or %3$sregister%4$s to view the content\n\nThe str_replace does not work the way you intended - the first array is an array of needles which has no sense of position so the second set of [] are duplicate needles in your case.\nSee tester\n"
},
{
"QuestionId": "76383155",
"QuestionTitle": "Fluid nodes list layout with JavaFX",
"QuestionBody": "I use ListView to dynamically display items in my JavaFX app. Items are loaded through REST call to my backend app. Each item can be clicked and then product view is displayed instead of product list. That works (looks) fine until app window is resized. After resize, items look ugly and they use too much space.\nThe question: Is there a way to get some kind of fluid item order?\nIn HTML and CSS that would be Flexbox if I remember well.\nAll items would be the same width and the same height not giving a chance to calculate width or height for each item separately.\nThe only solution I found on the internet is here: https://github.com/onexip/FlexBoxFX -\nbut it uses FXML files only and there is no option to add items dynamically. The last project update is 6 years ago which tells me it's abandoned or poorly maintained. Their official website is dead: http://flexboxfx.io\nEDIT: As James_D mentioned, I don't need ListView but any other solution that works.\nAlso I am aware of WebView but I would like to avoid HTML content in my app.\nTo make my case more clear, I made some screenshots and the first one is edited to represent the idea what I want. Numbers on edited screenshot represent desired order of items.\nIf window grows more in width, first row should have items 1, 2 and 3, next row 4, 5 and 6, next row 7, 8 and 9 and last row should have only one item (10). All rows should be centered and item 10 of last row should be positioned below item 8.\n\nThis is the final layout I want to get but I don't know how.\n\n\nEverything is nice when window is not resized, but after resize, it looks ugly.\n\n\n",
"AnswerId": "76383536",
"AnswerBody": "The primary purpose of a ListView is to provide virtualization; i.e. it provides an efficient mechanism to display a large number of items, letting the user scroll through them, without the overhead of UI components for the items that are not currently displayed. It also provides some additional functionality, such as selection (allowing the user to put one or more items in the list into a \"selected\" state which is shown visually).\nIf you actually need virtualization, and perhaps selection, and want a grid-like layout, then the third-party library ControlsFX provides a similarly-virtualized GridView.\nHowever, your question appears to be only about layout and your screenshots appear to show you using a Pagination control, which would (probably) obviate the need for virtualization anyway. If you don't need the functionality of the ListView, then a standard layout pane such as FlowPane or TilePane, possibly wrapped in a ScrollPane, should provide the layout you need.\n"
},
{
"QuestionId": "76382044",
"QuestionTitle": "Factory class in Python with a mapping dictionary returns TypeError",
"QuestionBody": "I made something like this dummy class:\nclass CreateCaseFactory:\n    @classmethod\n    def create(cls, user_id: uuid.UUID, type_: str) -> str:\n        creator = cls.CASE_TO_METHOD_MAP.get(type_)\n        if creator:\n            return creator(user_id)\n        else:\n            raise Exception(\"Invalid type\")\n\n    @classmethod\n    def _create_case_1(cls, user_id: uuid.UUID) -> str:\n        result = f\"Dummy Use Case 1 created for user {user_id}\"\n        return result\n\n    @classmethod\n    def _create_case_2(cls, user_id: uuid.UUID) -> str:\n        result = f\"Dummy Use Case 2 created for user {user_id}\"\n        return result\n\n    CASE_TO_METHOD_MAP = {\n        \"case_1\": _create_case_1,\n        \"case_2\": _create_case_2,\n    }\n\nbut I get an error when I try to run it:\n        if creator:\n>           return creator(user_id)\nE           TypeError: 'classmethod' object is not callable\n\nHow can I make this factory class work.\n",
"AnswerId": "76382185",
"AnswerBody": "As the error message says, instances of classmethod are not callable. When you call a class method with something like CreateCaseFactory.create(...), the descriptor protocol \"extracts\" the underlying function from the class method and calls it with CreateCaseFactory as the first argument.\ncreate_case_1 and _create_case_2 should not be class methods, but regular functions.\nclass CreateCaseFactory:\n    @classmethod\n    def create(cls, user_id: uuid.UUID, type_: str) -> str:\n        creator = cls.CASE_TO_METHOD_MAP.get(type_)\n        if creator:\n            return creator(cls, user_id)\n        else:\n            raise Exception(\"Invalid type\")\n\n    def _create_case_1(cls, user_id: uuid.UUID) -> str:\n        result = f\"Dummy Use Case 1 created for user {user_id}\"\n        return result\n\n    def _create_case_2(cls, user_id: uuid.UUID) -> str:\n        result = f\"Dummy Use Case 2 created for user {user_id}\"\n        return result\n\n    CASE_TO_METHOD_MAP = {\n        \"case_1\": _create_case_1,\n        \"case_2\": _create_case_2,\n    }\n\n"
},
{
"QuestionId": "76384865",
"QuestionTitle": "PathFinding closest Player",
"QuestionBody": "Why Isn't Pathfinding working I'm new to scripting and This just doesn't make sense to me I Understan my other code, and I've read the documentation but when it comes to integrating the pathfinding so he will only find/create a path when he had located the nearest player and follow that path has me stumped. To be honest after reading the documentation I would have figured I could just declare the path inside the if statement gauging if the player is close enough and he would follow the path but I looked up a tutorial and he used the GetWayPoints() but I figured that was to be to no avail so far this is my latest attempt\nlocal runService = game:GetService(\"RunService\") -- Run Service sort of like unitys Update frame by frame, SEE DOCUMENTATION SAVED FOLDER\nlocal players = game:GetService(\"Players\") -- Players will help \"get\" the players in the game\n\nlocal humanoid = script.Parent -- grabs the parent of the script which is humanoid\nlocal root = humanoid.Parent.PrimaryPart --root is the humanoids parent i.e models primary part which is typically the humanoid root part\n\nlocal PathfindingService = game:GetService(\"PathfindingService\"); -- A path finding service\n\n\n\nlocal wantedDistance = 30 --  How far he can search or should be trying to search, The value now is small testing needed\nlocal stopDistance = 5 -- In caase we want to use this to make him stop (like if he had a kill radius instead of touching)\n\nlocal damage = 50\nlocal attackDistance = 8\nlocal attackWait = 1\nlocal lastAttack = tick()\nfunction findNearestPlaya()\n    local playerList = players:GetPlayers()\n    \n    local playerNearest = nil\n    local dist = nil\n    local direction = nil\n    \n    for _, player in pairs(playerList) do -- basically a for each loop that says for each player in the list of players\n        local character = player.Character \n        if character  then -- will only eggsacute if a player/character exists\n            local distanceV = player.Character.HumanoidRootPart.Position - root.Position -- Distance  ''Vector'' equals the distance from the player torso/Root position minus the distance of the models primary part which we have as root\n            \n        \n        \n            \n            \n            if not playerNearest then\n                playerNearest = player\n\n                dist = distanceV.Magnitude -- distance vector magnitude gives us the actual distance\n                direction = distanceV.Unit -- direction of the nearest player, SEE DOCUMENTATIOIN FOR UNIT AND MAGNITUDE\n\n            elseif distanceV.Magnitude < dist then -- If the player is closer than the set nearest player then ''replace'' the player\n\n                playerNearest = player -- resets to new player\n                dist = distanceV.Magnitude\n                direction = distanceV.Unit\n\n            end\n        end\n    \n    end\n    \n    return playerNearest, dist, direction -- function so return which playa and his distance and direction\nend\n\n-- Another call from the runService class that runs every \"physics frame\", Which I think is like the updateBefore in unity\nrunService.Heartbeat:Connect(function() -- lua thing essentially this odd function call thing is just an anonymous function meaning it will execute every heartbeat\nlocal path = PathfindingService:CreatePath()\nlocal playerNearest, distance, direction = findNearestPlaya()\n\nif the distance is within range of the wanted distance\nif playerNearest  then\nif distance <=wantedDistance and distance >= stopDistance then\npath:ComputeAsync(humanoid.PrimaryPart.Position, playerNearest.PrimaryPart.Position)\nlocal waypoints = path:GetWaypoints()\nfor _, waypoint in pairs(waypoints)  do\nhumanoid.MoveTo(waypoint.Position)\nend\n\nelse \nhumanoid:Move(Vector3.new()) -- \n\n\nend\n\nif distance <= attackDistance and tick() - lastAttack >= attackWait then\nlastAttack = tick();\nplayerNearest.Character.Humanoid.Health -= damage\nend\nend\n\n\nend)\n    \n\nI was expecting him to calculate the path to the nearest player hints my code player nearest. I really dont understand why that or just telling him to move to path after calculating it wouldnt work\n",
"AnswerId": "76385382",
"AnswerBody": "Here is the solved version comments should do a good job of explaining but essentially I was just being dumb I was harping to much on the direction as long as you ommit that you can essentially guide the NPC as long as he is in range instead of updating every player playerNearest path,  the heartbeat function is already handling that all that's required is to create a new path for each player that is nearest then guide him along that path. The script isn't perfect  but this will find the nearest player and create a path for the NPC to follow each time for a different nearest player (I'm bad at explanations and I've dragged this on for too long just read the comments)\nlocal runService = game:GetService(\"RunService\") -- Run Service sort of like unitys Update frame by frame, SEE DOCUMENTATION SAVED FOLDER\nlocal players = game:GetService(\"Players\") -- Players will help \"get\" the players in the game\n\nlocal humanoid = script.Parent -- grabs the parent of the script which is humanoid\nlocal root = humanoid.Parent.PrimaryPart --root is the humanoids parent i.e models primary part which is typically the humanoid root part\n\nlocal PathfindingService = game:GetService(\"PathfindingService\"); -- A path finding service\n\n\n\nlocal wantedDistance = 30 --  How far he can search or should be trying to search, The value now is small testing needed\nlocal stopDistance = 5 -- In caase we want to use this to make him stop (like if he had a kill radius instead of touching)\n\nlocal damage = 50\nlocal attackDistance = 8\nlocal attackWait = 1\nlocal lastAttack = tick()\n\n\n\n\n\n\nfunction findNearestPlaya()\n    local playerList = players:GetPlayers()\n\n    local playerNearest = nil\n    local dist = nil\n    local direction = nil   \n    for _, player in pairs(playerList) do -- basically a for each loop that says for each player in the list of players\n        local character = player.Character \n        if character  then -- will only eggsacute if a player/character exists\n            local distanceV = player.Character.HumanoidRootPart.Position - root.Position -- Distance  ''Vector'' equals the distance from the player torso/Root position minus the distance of the models primary part which we have as root\n\n\n\n\n\n            if not playerNearest then\n                playerNearest = player\n\n                dist = distanceV.Magnitude -- distance vector magnitude gives us the actual distance\n                direction = distanceV.Unit -- direction of the nearest player, SEE DOCUMENTATIOIN FOR UNIT AND MAGNITUDE\n\n            elseif distanceV.Magnitude < dist then -- If the player is closer than the set nearest player then ''replace'' the player\n\n                playerNearest = player -- resets to new player\n                dist = distanceV.Magnitude\n                direction = distanceV.Unit\n\n            end\n        end\n\n    end\n\n    return playerNearest, dist, direction -- function so return which playa and his distance and direction\nend\n\n-- Another call from the runService class that runs every \"physics frame\", Which I think is like the updateBefore in unity\nrunService.Heartbeat:Connect(function() -- lua thing essentially this odd function call thing is just an anonymous function meaning it will execute every heartbeat\n\n\n    local playerNearest, distance, direction = findNearestPlaya()   \n    -- if the distance is within range of the wanted distance\n    if playerNearest and distance <= wantedDistance  then\n        local path = PathfindingService:CreatePath(); -- Now if hes in range of the player create a new path\n        path:ComputeAsync(root.Position, playerNearest.Character.HumanoidRootPart.Position) -- compute the path with the positions of the player and Dr. Sturgeon\n        local waypoints = path:GetWaypoints()  -- Assign a new waypoint and and gathers the paths \n        -- standard for each loop for the nodes SEE DOCUMENTATION/TUTORIALS TO UNDERSTAND ''NODES''\n        for _, waypoint in pairs(waypoints)  do \n            humanoid:MoveTo(waypoint.Position) -- For each waypoint/node move Dr. sturgeon to it until it reaches the computed path i.e the distance from the player to the robot vice a versa\n            humanoid.MoveToFinished:Wait()\n        end\n    end\n\n\n    if distance <= attackDistance and tick() - lastAttack >= attackWait then\n        lastAttack = tick();\n        playerNearest.Character.Humanoid.Health -= damage\n    end\n\nend)\n        \n\n"
},
{
"QuestionId": "76383514",
"QuestionTitle": "Pass list to Table.RemoveColumns",
"QuestionBody": "I am looking for a way to pass a list to the Table.RemoveColumns() step in Power Query.\nOverview of the set up, two tables as data sources, one is a config table with all the column names of the second data source with simple 'yes' 'no' selectors identifying which columns should be kept/removed. This table is used as a data source, filtered by 'no', and drilled down as a list like so:\n\nI am looking for a way to pass that list to a step to remove columns in my 'data' source:\nSo the step to remove columns:\n= Table.RemoveColumns(Source,{\"InvoiceDate\", \"T/S Start Date\", \"TotalBreakMinutes\"})\nWould become:\n= Table.RemoveColumns(Source,{cols})\nHowever you can't pass a list to an argument that expects text. I tried a few work arounds like adding a prefix \" and suffix \" to each list item and using Text.Combine with a comma separator however Table.RemoveColumns step handles the string as a single column\n\nIs there a way to pass that list as a recognisable condition for Table.RemoveColumns()?\n",
"AnswerId": "76383541",
"AnswerBody": "= Table.RemoveColumns(Source,cols) where cols is a list of column names\nsample code\nlet Source = #table({\"Column1\", \"Column2\",\"Column3\",\"Column4\"},{{\"A\",\"B\",\"C\",\"D\"}}),\nremovetable = #table({\"Column1\"},{{\"Column1\"},{\"Column2\"}}),\nremovelist = removetable[Column1],\n#\"Removed Columns\" = Table.RemoveColumns(Source,removelist)\nin #\"Removed Columns\"\n\n"
},
{
"QuestionId": "76382000",
"QuestionTitle": "Swagger: how to use the generated json files?",
"QuestionBody": "I've been provided with the json files generated by swashbuckle for a rest api I should be consuming and I was wondering if there are tools that can take those files as input and allow an easier navigation of exposes methods, request payloads, response payloads, headers, etc. Also when working in .NET is there a way or tool to generate payload classes as with wsdl documents?\n",
"AnswerId": "76382205",
"AnswerBody": "You can use the swagger editor\nhttps://editor.swagger.io/\nThis will allow you to view and browse the methods.  Simply paste the contents of your received JSON.\nThen also, at the top of the page you have \"generate client\" options for different languages.  Which will generate C# (or other) langauge files for you.\n"
},
{
"QuestionId": "76378414",
"QuestionTitle": "Add New Polygon to Dash Leaflet Map via a Callback",
"QuestionBody": "Im very new to working with GIS data (using Dash Leaflet and GeoPandas) and am currently stumped.\nMy goal is to create a simple app which does the following:\n\nApp starts with an empty dash_leaflet.Map() figure and a numeric input box titled \"Buffer Distance\" (with a default of 100)\nUser draws a polygon on the map which fires a callback\nCallback takes in the GeoJSON data from the map and the \"buffer distance\"\nUse Geopandas to import the GeoJSON data and create a new polygon which is smaller than the user drawn polygon by \"Buffer Distance\"\nPass these 2 polygons (originally drawn & post processed polygon with buffer) back to the map so that both are now displayed on the map\n\nIm having trouble with the last step of pushing the two polygons back the map via some kind of Output\nThis is the app i am currently working with:\nimport pandas as pd\nfrom dash import Dash, dcc, html, Input, Output, State\nimport dash_leaflet as dl\nimport geopandas as gpd\n\nlat1, lon1 = 36.215487, -81.674006\n\napp = Dash()\n\ninput_details = html.Div([\n    html.Div([\n        html.Div(['Buffer Distance'], style={'width': '37%', 'display': 'inline-block'}),\n        dcc.Input(\n            value=100,\n            id=\"buffer-distance\",\n            type='number',\n            placeholder='Required',\n        ),\n    ]),\n])\n\ndefault_map_children = [\n    dl.TileLayer(),\n    dl.FeatureGroup([\n        dl.EditControl(id=\"edit_control\"),\n    ]),\n    dl.GeoJSON(id='map-geojsons')\n]\n\nmap_input_results_tab = html.Div(\n    [\n        html.H2('Add Shapes to Map an Area of Interest'),\n        dl.Map(\n            id='leaflet-map',\n            style={'width': '100%', 'height': '50vh'},\n            center=[lat1, lon1],\n            zoom=16,\n            children=default_map_children\n        )\n    ])\n\napp.layout = html.Div([input_details, map_input_results_tab])\n\n\n@app.callback(\n    Output('map-geojsons', 'data'),\n    Input('edit_control', 'geojson'),\n    State('buffer-distance', 'value'),\n)\ndef update_estimates(drawn_geojson, perim_clear):\n    if any([x is None for x in [drawn_geojson, perim_clear]]):\n        # some value has not been provided, so do not continue with calculations\n        return drawn_geojson\n    elif not drawn_geojson[\"features\"]:\n        # some value has not been provided, so do not continue with calculations\n        return drawn_geojson\n\n    gdf = gpd.GeoDataFrame.from_features(drawn_geojson[\"features\"])  # extract user drawn geometry data from UI\n    gdf = gdf.set_crs(crs=4326)  # Set the initial CRS to specify that this is lat/lon data\n    gdf = gdf.to_crs(\n        crs=gdf.estimate_utm_crs())  # Let GeoPandas estimate the best CRS and use that for the area calculation\n\n    # create a new geodataframe using buffer that incorporates the perimeter\n    gdf_minus_perim_buffer = gdf['geometry'].buffer(-perim_clear)\n    combine_gdf = pd.concat([gdf['geometry'], gdf_minus_perim_buffer])\n    # convert back to lat, long\n    combine_gdf = combine_gdf.to_crs(crs=4326)\n    # convert back to GeoJSON to be rendered in the dash leaflet map\n    return_geojson_data = combine_gdf.to_json()\n\n    return return_geojson_data\n\n\nif __name__ == '__main__':\n    app.run_server(debug=True, port=8052)\n\nI think I am close, but am just missing something.. Thanks in advance for any help!\n",
"AnswerId": "76383565",
"AnswerBody": "It looks like the callback approach above is valid, I was just providing the wrong data type back to the dl.GeoJSON's data attribute .\nChanging this line:\n# convert back to GeoJSON to be rendered in the dash leaflet map\nreturn_geojson_data = combine_gdf.to_json()\n\nto\n# convert back to GeoJSON to be rendered in the dash leaflet map\nreturn_geojson_data = combine_gdf.__geo_interface__\n\nworked perfectly!\n"
},
{
"QuestionId": "76385364",
"QuestionTitle": "Updating \"anyarray\" or \"anyelement\" polymorphic functions when upgrading to 14.x or higher on AWS RDS aurora postgresql",
"QuestionBody": "When upgrading AWS RDS aurora postgresql cluster from 11.17 -> 15.2, I was met with this fatal error in the pg_upgrade logs:\nfatal\nYour installation contains user-defined objects that refer to internal\npolymorphic functions with arguments of type \"anyarray\" or \"anyelement\".\nThese user-defined objects must be dropped before upgrading and restored\nafterwards, changing them to refer to the new corresponding functions with\narguments of type \"anycompatiblearray\" and \"anycompatible\".\n\nAWS does not mention this in the upgrade docs, so I thought the changed may have been introduced by a system user. After a bit of digging, it seems that the aggregate functions changed the way the types are named (in postgresql version 14 to be clear). So how do I update this?\nI ran a subset the query that the upgrade failed on, on each DB in the target cluster:\n--find incompatibilites on each DB:\n\\c <DATABASE>\n\nSELECT 'aggregate' AS objkind,\n       p.oid::regprocedure::text AS objname\nFROM pg_proc AS p\nJOIN pg_aggregate AS a ON a.aggfnoid=p.oid\nJOIN pg_proc AS transfn ON transfn.oid=a.aggtransfn\nWHERE p.oid >= 16384\n  AND a.aggtransfn = ANY(ARRAY['array_append(anyarray,anyelement)', 'array_cat(anyarray,anyarray)', 'array_prepend(anyelement,anyarray)', 'array_remove(anyarray,anyelement)', 'array_replace(anyarray,anyelement,anyelement)', 'array_position(anyarray,anyelement)', 'array_position(anyarray,anyelement,integer)', 'array_positions(anyarray,anyelement)', 'width_bucket(anyelement,anyarray)']::regprocedure[]);\n\n  objkind  |         objname         \n-----------+-------------------------\n aggregate | array_accum(anyelement)\n(1 row)\n\nOkay, so now what?\n",
"AnswerId": "76385392",
"AnswerBody": "Solution:\n--drop aggregate from sub 14.x db\nmygreatdatabase=> DROP AGGREGATE array_accum(anyelement);\nDROP AGGREGATE\n\n--upgrade to 14.x or higher, and then re-create using updated type:\nmygreatdatabase=> CREATE AGGREGATE array_accum(anycompatible) (SFUNC = array_append,STYPE = anycompatiblearray,INITCOND = '{}');\n\nMy hope is that AWS adds this to the documentation on RDS Aurora PostgresQL Upgrade Pre-Checks, but this will be here until that is more clear.\n"
},
{
"QuestionId": "76382135",
"QuestionTitle": "How to delete rows based on columns' value?",
"QuestionBody": "I am trying to delete rows based on one columns value! But the column length of the range in the worksheet is dynamic and large.\nFor example,\nIf Col C has value less than or equal to 0 that row gets deleted\n\n\n\n\nA\nB\nC\n\n\n\n\n1\nSAM\n100\n\n\n1\nSAM\n0\n\n\n1\nBRI\n-100\n\n\n1\nHAWK\n100\n\n\n\n\nIt should only give me :\n\n\n\n\nA\nB\nC\n\n\n\n\n1\nSAM\n100\n\n\n1\nHAWK\n100\n\n\n\n",
"AnswerId": "76382208",
"AnswerBody": "as said in my comment,try this:\nSub test()\nDim LR As Long\nDim i As Long\n\nLR = Range(\"A\" & Rows.Count).End(xlUp).Row 'get last non blank row number\n\nFor i = LR To 1 Step -1 'go backwards starting at LR until row 1\n    If Range(\"C\" & i).Value <= 0 Then Range(\"C\" & i).EntireRow.Delete\nNext i\n\n\nEnd Sub\n\nBefore code:\n\nAfter code executed:\n\n"
},
{
"QuestionId": "76383277",
"QuestionTitle": "My bootstrap column not working on small screen",
"QuestionBody": "My buttons inside bootstrap columns not appearing when the screen size is small.\nI wanted the buttons to appear one below the other when screen size is small.\nWhat changes should I make to get my buttons one below each other on a small screen.\nfull screen\nsmall screen\nadding the html code below:\n<body>\n  <div class=\"top\">\n    <div class=\"content\">\n      <h1>Welcome To <br /><span class=\"fancy\">Fantasy Talk</span></h1>\n      <div class=\"row\">\n        <div class=\"col-md-4\">\n          <button onClick=\"window.location.href='dothraki.html';\">\n            Dothraki\n          </button>\n        </div>\n\n        <div class=\"col-md-4\">\n          <button onClick=\"window.location.href='valyrian.html'; \">\n            Valyrian\n          </button>\n        </div>\n\n        <div class=\"col-md-4\">\n          <button onClick=\"window.location.href='sindarin.html';\">\n            Sindarin\n          </button>\n        </div>\n      </div>\n    </div>\n  </div>\n</body>\n\n**Adding CSS code: **\nbody{\n    margin: 0;\n    padding: 0;\n    width: 100%;\n    height: 100vh;\n   /* cursor: url(https://cur.cursors-4u.net/games/gam-11/gam1090.png),auto; */\n   \n   cursor: url(https://cur.cursors-4u.net/games/gam-13/gam1229.png),auto;\n }\n .top{\n     width: 100%;\n     height: 100%;\n     padding: 2rem;\n \n     \n     position:absolute;\n     background-image: url(image/img1.jpg);\n     background-position: center;\n     background-size: cover;\n     text-align: center;\n     justify-content: center;\n     animation: change 13s infinite ease-in-out;\n }\n button{\n     font-family: 'Almendra SC', serif;\n     transition: 0.5s;\n     padding: 15px 60px;\n     text-decoration: none;\n     font-size: 2vw;\n position: absolute;\n     border-radius: 5px;\n     \n     top: 50%;\n     transform: translate(-50%, -50%);\n border: 1px;\n     transition: all 0.2s ease-in-out;\n     color: rgba(255, 255, 255, 0.8);\n     background: #146C94;\n }\n button:hover{\n   \n     margin-top: -10px;\n     color: rgba(255, 255, 255, 1);\n     /* box-shadow: 0 5px 15px rgba(145, 92, 182, .4); */\n     box-shadow: 0 5px 15px #39B5E0;\n }\n\n @keyframes change{\n \n     0%{\n         background-image: url(image/img6.jpg);\n     }\n     20%{\n         background-image: url(image/img2.jpg);\n     }\n     40%{\n         background-image: url(image/img3.jpg);\n     }\n     60%{\n         background-image: url(image/img4.jpg);\n     }\n     80%{\n         background-image: url(image/img5.jpg);\n     }\n     100%{\n         background-image: url(image/img6.jpg);\n     }\n }\nh1{\n    padding: 2rem;\n    color:white;\n    font-family: 'Spirax', cursive;\n\n    font-size: 5vw;\n    text-transform: uppercase;\n    text-align: center;\n    line-height: 1;\n}\n.fancy{\n    font-size: 8vw;\n}\n\n",
"AnswerId": "76383567",
"AnswerBody": "Instead of trying to position each button individually in the middle of the page, position the entire row of buttons. This will allow you to use Bootstrap columns better. You were also missing the the extra-small (col-12) and small (col-sm-12) column breakpoints.\nReplace your HTML with this (Bootstrap 5):\n<div class=\"row gy-3 position-absolute top-50 start-50 translate-middle w-100\">\n    <div class=\"col-12 col-sm-12 col-md-4 text-center\">\n        <button onClick=\"window.location.href='dothraki.html';\"> Dothraki</button>\n    </div>\n    <div class=\"col-12 col-sm-12 col-md-4 text-center\">\n        <button onClick=\"window.location.href='valyrian.html';\">Valyrian</button>\n    </div>\n    <div class=\"col-12 col-sm-12 col-md-4 text-center\">\n        <button onClick=\"window.location.href='sindarin.html';\">Sindarin</button>\n    </div>\n</div>\n\nAnd then replace your button CSS with this (removing the button positioning):\nbutton {\n    font-family: 'Almendra SC', serif;\n    transition: 0.5s;\n    padding: 15px 60px;\n    text-decoration: none;\n    font-size: 2vw;\n    border-radius: 5px;\n    border: 1px;\n    transition: all 0.2s ease-in-out;\n    color: rgba(255, 255, 255, 0.8);\n    background: #146C94;\n}\n\nAlso, I recommend you replace your buttons with Anchor tags if they are only going to take the user to a page.\n"
},
{
"QuestionId": "76383962",
"QuestionTitle": "Drag and drop not functioning on dynamically created list",
"QuestionBody": "I have a list of activities that is generated dynamically with javascript in the following manner:\nconst renderList = (activities) => {\n  const display = document.getElementById('task-list-display');\n  activities.forEach((activity) => {\n    console.log(activity);\n    display.insertAdjacentHTML('beforeend', ` \n    <li class=\"task-item draggable\" draggable=\"true\">\n      <div class=\"chk-descr\">\n        <input data-a1=\"${activity.index}\" type=\"checkbox\" name=\"completed\"/>\n        <p data-b1=\"${activity.index}\" class=\"description\" contenteditable=\"true\">${activity.description}</p>\n      </div>\n    </li> \n    `);\n\nI want to have it be responsive in a way that the items can be rearranged using drag and drop. I am not able, however, to make this work. Previously I had designed the very same app but instead of having the items of the list be inserted using insertAdjacentHTML() I was creating each element using createElement() and then appending it to the corresponding HTML element using appendChild(). The drag and drop functionality on that app was fully functioning. My question is: is there some reason why drag and drop might not work with a dynamically generated list using insertAdjacentHTML?.\nHere is all the relevant code:\nlet activities = [];\n\nconst dragstart = (element) => {\n  element.classList.add('skateover');\n};\n\nconst dragover = (element, e) => {\n  e.preventDefault();\n  element.classList.add('dragover');\n};\n\nconst dragleave = (element) => {\n  element.classList.remove('dragover');\n};\n\nconst drop = (element) => {\n  const skateover = document.querySelector('.skateover');\n  element.before(skateover);\n\n  repopulateList();\n  element.classList.remove('dragover');\n};\n\nconst dragend = (element) => {\n  element.classList.remove('skateover');\n};\n\nconst repopulateList = () => {\n  const listItems = document.querySelectorAll('.draggable');\n  emptyList();\n\n  let i = 0;\n  listItems.forEach((listItem) => {\n    listItem.setAttribute('activity', i);\n    i += 1;\n    \n    const description = listItem.getElementsByClassName('description')[0].textContent;\n    const completed = listItem.getElementsByClassName('completed')[0].checked;\n    const index = listItem.getAttribute('activity');\n\n    inputActivity(description, completed, index);\n  });\n};\n\nconst inputActivity = (description, completed, index) => {\n  activities.push({ description, completed, index: parseInt(index, 10) });\n};\n\nAnd in the HTML file:\n<ul id=\"task-list-display\"></ul>\n\n",
"AnswerId": "76385414",
"AnswerBody": "That is not a problem. Here I add the eventlisteners to the unordered list (<ul>). So, the adding, cloning and removing of list items (<li>) is not an issue.\nThere is no problem in using methods like insertAdjacentHTML(). In this example I just use cloneNode() for cloning the node that is moved and then insertBefore() to insert the cloned node before the list item that is hovered/dropped on.\n\n\nconst aktivities = [{\n    index: 1,\n    description: \"Item 1\"\n  },\n  {\n    index: 2,\n    description: \"Item 2\"\n  },\n  {\n    index: 3,\n    description: \"Item 3\"\n  }\n];\n\nconst display = document.getElementById('task-list-display');\n\nconst renderList = (activities) => {\n  activities.forEach((activity) => {\n    display.insertAdjacentHTML('beforeend', ` \n    <li class=\"task-item draggable\" draggable=\"true\" data-id=\"${activity.index}\">\n      <div class=\"chk-descr\">\n        <input data-a1=\"${activity.index}\" type=\"checkbox\" name=\"completed\"/>\n        <p data-b1=\"${activity.index}\" class=\"description\" contenteditable=\"true\">${activity.description}</p>\n      </div>\n    </li> \n    `)\n  });\n};\n\ndisplay.addEventListener(\"dragstart\", e => {\n  e.dataTransfer.setData(\"text/plain\", e.target.dataset.id);\n});\n\ndisplay.addEventListener(\"dragover\", e => {\n  e.preventDefault();\n  [...display.querySelectorAll('li')].forEach(li => li.classList.remove('over'));\n  e.target.closest('li.task-item').classList.add('over');\n});\n\ndisplay.addEventListener(\"drop\", e => {\n  e.preventDefault();\n  [...display.querySelectorAll('li')].forEach(li => li.classList.remove('over'));\n  let original = document.querySelector(`li[data-id=\"${e.dataTransfer.getData(\"text/plain\")}\"]`);\n  let clone = original.cloneNode(true);\n  let target = e.target.closest('li.task-item');\n  display.insertBefore(clone, target);\n  display.removeChild(original);\n});\n\n\nrenderList(aktivities);\nul {\n  margin: 0;\n  padding: 0;\n  list-style: none;\n}\n\nli div {\n  display: flex;\n  flex-direction: row;\n}\n\n.over {\n  border-top: solid thin black;\n}\n<ul id=\"task-list-display\"></ul>\n\n\n\n"
},
{
"QuestionId": "76383234",
"QuestionTitle": "Typescript returns unknown for generic only on undefined input",
"QuestionBody": "I'm trying to write a generic env field getter function and currently have this:\nexport interface Config {\n  readonly PORT: number;\n  readonly DATABASE_URL: string;\n  // ... other fields\n}\nconst config: Config = Object.freeze({\n  ENVIRONMENT,\n  PROJECT_NAME,\n  PORT: parseInt(getEnvVariable('PORT', '9000'), 10),\n  DATABASE_URL: getEnvVariable('DATABASE_URL'),\n  AWS_REGION,\n});\n\nfunction getEnvVariable<T>(name: string, defaultValue?: T): T | string {\n  const val = process.env[name];\n\n  if (val) {\n    return val;\n  }\n\n  if (defaultValue) {\n    return defaultValue;\n  }\n\n  throw new Error(`Missing environment variable: ${name}`);\n}\n\nand I'm currently getting the error:\nType 'Readonly<{ ENVIRONMENT: string; PROJECT_NAME: string; PORT: number; DATABASE_URL: unknown; AWS_REGION: string; }>' is not assignable to type 'Config'.\n  Types of property 'DATABASE_URL' are incompatible.\n    Type 'unknown' is not assignable to type 'string'.\n\n\nFor some reason if my defaultValue input is undefined, it will give this error, even though I do a truthy check.\nHow would I fix this without using an '' as the defaultValue?\n",
"AnswerId": "76383601",
"AnswerBody": "If you don't pass in a defaultValue argument to getEnvVariable, then the compiler has no inference site for the generic type parameter T.  So inference fails, and T falls back to its constraint, which is implicitly the unknown type.\nIf you'd like T to fall back to something else, you can use a default type argument as shown here:\nfunction getEnvVariable<T = string>( \n// default type arg ----> ^^^^^^^^ \n  name: string, defaultValue?: T\n): T | string { /* impl */ }\n\nThen you'll get the desired behavior when defaultValue isn't supplied:\nconst unsuppliedDefault = getEnvVariable(\"Y\");\n// const unsuppliedDefault: string\n\nwithout changing the behavior when it is:\nconst suppliedDefault = getEnvVariable(\"X\", Math.random());\n// const suppliedDefault: string | number\n\nPlayground link to code\n"
},
{
"QuestionId": "76382016",
"QuestionTitle": "Recursive object construction",
"QuestionBody": "Task: to create a tournament bracket according to the double elimination system. For the upper bracket, there were no problems, since the teams that won in the first round meet in the second, and so on. But for the lower bracket, in addition to the games among the losers in the first round, you need to add games among the losers in the second round of the upper bracket.\nFor example, given an array of lower bracket games:\nconst games = [\n  { id: 1, home_name: \"Team 1\", visitor_name: \"Team 3\", home_score: 1, visitor_score: 0, round: 2 },\n  { id: 2, home_name: \"Team 6\", visitor_name: \"Team 7\", home_score: 1, visitor_score: 0, round: 2 },\n  { id: 3, home_name: \"Team 1\", visitor_name: \"Team 6\", home_score: 0, visitor_score: 1, round: 3 },\n  { id: 4, home_name: \"Team 4\", visitor_name: \"Team 5\", home_score: 1, visitor_score: 0, round: 3 },\n  { id: 5, home_name: \"Team 6\", visitor_name: \"Team 4\", home_score: 1, visitor_score: 0, round: 4 },\n];\n\nTo display the structure of the lower bracket, you need to get the following object:\n{\n name: \"Team 6\",\n children: [\n  {\n   name: \"Team 4\",\n   children: [{ name: \"Team 4\" }, { name: \"Team 5\" }],\n  },\n  {\n   name: \"Team 6\",\n   children: [\n    { name: \"Team 1\", children: [{ name: \"Team 1\" }, { name: \"Team 3\" }] },\n    { name: \"Team 6\", children: [{ name: \"Team 6\" }, { name: \"Team 7\" }] },\n   ],\n  },\n ],\n}\n\nIn the parent object \"Team 6\" is the winner of the lower bracket, this can be understood from the last (4) round played between Team 4 and Team 6, in turn Team 4 is determined by the game between Team 4 and Team 5 in round 3.\nWhat the lower bracket will look like for these games:\n\nHow to get such an object from the games array? The number of games may vary depending on the number of teams.\n",
"AnswerId": "76382233",
"AnswerBody": "You could use a plain object to collect subtrees keyed by the winning team's name, starting out with an empty object. Then iterate the games in order of round and look up the two team's subtrees from that object (with a default {name} object). Then construct the children property from that and wrap it into a new root node. Register that node in the collection of subtrees.\nFinally retain the last object that was created which will have the whole tree:\n\n\nfunction getTree(games) {\n    // Ensure the data is sorted by round -- if this is already ensured by caller, then you can drop this statement:\n    games = [...games].sort((a, b) => a.round - b.round);\n    \n    const nodes = {}; // This will collect the subtrees, keyed by the winning team's name.\n    let winner;\n    for (const {home_name, home_score, visitor_name} of games) {\n        const name = home_score ? home_name : visitor_name;\n        winner = nodes[name] = {\n            name,\n            children: [\n                nodes[home_name] ?? { name: home_name }, \n                nodes[visitor_name] ?? { name: visitor_name }\n            ]\n        };\n    }\n    return winner;\n}\n\nconst games = [\n  { id: 1, home_name: \"Team 1\", visitor_name: \"Team 3\", home_score: 1, visitor_score: 0, round: 2 },\n  { id: 2, home_name: \"Team 6\", visitor_name: \"Team 7\", home_score: 1, visitor_score: 0, round: 2 },\n  { id: 3, home_name: \"Team 1\", visitor_name: \"Team 6\", home_score: 0, visitor_score: 1, round: 3 },\n  { id: 4, home_name: \"Team 4\", visitor_name: \"Team 5\", home_score: 1, visitor_score: 0, round: 3 },\n  { id: 5, home_name: \"Team 6\", visitor_name: \"Team 4\", home_score: 1, visitor_score: 0, round: 4 },\n];\nconsole.log(getTree(games));\n\n\n\n"
},
{
"QuestionId": "76385383",
"QuestionTitle": "Removing Prefix from column of names in python",
"QuestionBody": "I have this dataset\nID      Name     \n101    DR. ADAM SMITH\n102    BEN DAVIS\n103    MRS. ASHELY JOHNSON\n104    DR. CATHY JONES \n105    JOHN DOE SMITH\n\nDesired Output\nID        Name \n101     ADAM SMITH\n102     BEN DAVIS\n103     ASHELY JOHNSON\n104     CATHY JONES\n105     JOHN DOE SMITH \n\nI need to get rid of the prefix I tried df['Name'] = df['Name'].replace(to_replace = 'DR. ', value = '')I repeated the same code for all prefixes, but I have when I do it nothing happens. Any reason for this?\nThank you in advance.\n",
"AnswerId": "76385418",
"AnswerBody": "Use a regular expression to match the first word if it ends with ..\ndf['Name'] = df['Name'].str.replace(r'^[A-Z]+\\.\\s+', '', regex=True)\n\n"
},
{
"QuestionId": "76383593",
"QuestionTitle": "Closure might outlive current function even though it is joined",
"QuestionBody": "fn main() {\n    let foo = 5;\n\n    std::thread::spawn(|| { // closure may outlive the current function, but it borrows `foo`, which is owned by the current function\n        println!(\"{}\", foo);\n    })\n    .join()\n    .unwrap();\n}\n\nMoving the value is not an option since it have to make multiple threads\nThe situation in my code is a bit more complicated, but I still need threads and I ended up moving and Arc into it instead of just a reference\nHere is a link to the line in the project, but you don't have to read it: https://github.com/Antosser/web-crawler/blob/5d23ffa7ed64c772080c7be08a26bda575028c7c/src/main.rs#L291\n",
"AnswerId": "76383613",
"AnswerBody": "The compiler does not know it is joined. It does not apply any special analysis to see if threads are joined.\nHowever, if you join your threads, you can use scoped threads to access variables:\nfn main() {\n    let foo = 5;\n\n    std::thread::scope(|s| {\n        s.spawn(|| {\n            println!(\"{}\", foo);\n        });\n        // Thread implicitly joined here.\n    });\n}\n\n"
},
{
"QuestionId": "76383571",
"QuestionTitle": "Perform a specific Mathematical Function on each column dynamically in R",
"QuestionBody": "I wanted to perform a mathematical function on each unique item in a data frame dynamically.\nNormally to perform a mathematical function, we use mutate statement and create a column and perform the mathematical function manually by writing mutate statement after mutate statement.\nWhich is feasible on a few columns. But what if I have 100 columns and I have to perform 2-5 mathematical function, For example: one would be 20% increase on the initial number, The other one would be to divide the initial number by 2 on each column and keep the original column as is.\nIs this possible in R other than writing mutate statement for each specific item?\nThe data frame I am working with is:\nstructure(list(`Row Labels` = c(\"2023-03-01\", \"2023-04-01\", \"2023-05-01\", \n\"2023-06-01\", \"2023-07-01\", \"2023-08-01\", \"2023-09-01\", \"2023-10-01\"\n), X6 = c(14, 16, 14, 11, 9, 9, 11, 11), X7 = c(50, 50, 50, 50, \n50, 50, 50, 50), X8 = c(75, 75, 75, 75, 75, 75, 75, 75), X9 = c(100, \n100, 100, 100, 100, 100, 100, 100), X11 = c(25, 25, 50, 75, 125, \n200, 325, 525), X12 = c(50, 50, 100, 150, 250, 400, 650, 1050\n)), class = c(\"tbl_df\", \"tbl\", \"data.frame\"), row.names = c(NA, \n-8L))\n\nFor individual cases this code would suffice:\nlibrary(readxl)\nlibrary(dplyr)\nBook1 <- read_excel(\"C:/X/X/X- X/X/Book1.xlsx\",sheet = \"Sheet6\")\n\ndput(Book1)\n\nBook1 <- Book1 %>% \n  mutate(`X6 20%` = X6*1.20) %>% \n  mutate(`X6 by 2`= X6/2)\n\nI was thinking of running this through a loop but then selection of columns to multiple becomes a problem as we have to specify the column name in mutate statement, which I believe would not be possible here right.\nCan anyone let me know if this can be achieved in a simple approach?\nThe expected output is given below:\n\n",
"AnswerId": "76383624",
"AnswerBody": "We could use across()\nupdate: shorter:\nlibrary(dplyr)\n\ndf %>% \n  mutate(across(2:7, list(\"20\" = ~. * 1.20, \n                          \"By_2\" = ~. / 2), .names = \"{col}_{fn}\"))\n\nfirst answer:\nlibrary(dplyr)\n\ndf %>% \n  mutate(across(2:7, ~. * 1.20, .names = \"{.col}_20%\"),\n         across(2:7, ~. /2, .names = \"{.col}_By 2\"))\n\n  `Row Labels`    X6    X7    X8    X9   X11   X12 `X6_20%` `X7_20%` `X8_20%` `X9_20%` `X11_20%` `X12_20%` `X6_By 2` `X7_By 2` `X8_By 2` `X9_By 2` `X11_By 2` `X12_By 2`\n  <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>    <dbl>    <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>      <dbl>      <dbl>\n1 2023-03-01      14    50    75   100    25    50     16.8       60       90      120        30        60       7          25      37.5        50       12.5         25\n2 2023-04-01      16    50    75   100    25    50     19.2       60       90      120        30        60       8          25      37.5        50       12.5         25\n3 2023-05-01      14    50    75   100    50   100     16.8       60       90      120        60       120       7          25      37.5        50       25           50\n4 2023-06-01      11    50    75   100    75   150     13.2       60       90      120        90       180       5.5        25      37.5        50       37.5         75\n5 2023-07-01       9    50    75   100   125   250     10.8       60       90      120       150       300       4.5        25      37.5        50       62.5        125\n6 2023-08-01       9    50    75   100   200   400     10.8       60       90      120       240       480       4.5        25      37.5        50      100          200\n7 2023-09-01      11    50    75   100   325   650     13.2       60       90      120       390       780       5.5        25      37.5        50      162.         325\n8 2023-10-01      11    50    75   100   525  1050     13.2       60       90      120       630      1260       5.5        25      37.5        50      262.         525\n\n"
},
{
"QuestionId": "76382036",
"QuestionTitle": "Python Local random seed",
"QuestionBody": "I have a random seed set at the start of my run for reproducibility. But there are a few sub-functions (e.g. rando) that also use random numbers. If I used a different random number seed just for those, it affects the random seed outside of the function. Is it possible to set the random seed and use it only locally inside the function and the random state outside the function does not get affected? I believe I can always get the random state, save it and restore it. Would there be an easier option? I showed an example below.\nimport numpy as np\n\ndef rando():\n    np.random.seed(420)\n    np.random.randint(1, 100)\n    np.random.randint(1, 100)\n    return None\n\n\nnp.random.seed(69)\nfor n in range(3):\n    np.random.randint(1,100) # outputs : 55,76,74\nfor n in range(3):\n    np.random.randint(1,100) # outputs : 91,56,21\n\nIs it possible to make the function below also output the same thing?\nnp.random.seed(69)\nfor n in range(3):\n    np.random.randint(1,100) # outputs : 55,76,74\nrando()\nfor n in range(3):\n    np.random.randint(1,100) # would like it to output : 91,56,21\n\n",
"AnswerId": "76382266",
"AnswerBody": "That's why there are numpy random generators and that is why they recommend using that. Just define one generator for each instance, e.g.:\ndef rando(rng):\n    print('function')\n    print(rng.integers(1, 100))\n    print(rng.integers(1, 100))\n    print('end of function')\n    return None\n\n\n\nrng1 = np.random.default_rng(69)\nrng2 = np.random.default_rng(420)\n\nfor n in range(3):\n    print(rng1.integers(1, 100)) # outputs : 6,58,67\nrando(rng2) # outputs 62, 77\nfor n in range(3):\n    print(rng1.integers(1, 100)) # would like it to output : 53,78,86\n\nyielding:\n6\n58\n67\nfunction\n62\n77\nend of function\n53\n78\n86\n\nand when you comment out the function call, you get:\n6\n58\n67\n53\n78\n86\n\n"
},
{
"QuestionId": "76385267",
"QuestionTitle": "Remix session values don't persist across pages",
"QuestionBody": "I'm making a site using Remix where I'd like to persist session values across pages. I think the issue lies in the getSession request, as the values do not persist across requests to the same page. I have implemented a session cookie in sessions.ts:\nconst { getSession, commitSession, destroySession } =\n    createCookieSessionStorage<SessionData, SessionFlashData>(\n        {\n            //cookie options to create a cookie\n            cookie: {\n                name: \"__session\",\n                maxAge: 1200,\n                path: \"/\",\n                sameSite: \"none\",\n                secure: true,\n                secrets: [\"surprise\"]\n\n            },\n        }\n    );\n\nOn one page I set a value and log it out and receive the expected value\nexport const loader = async ({ request }: LoaderArgs) => {\n    const session = await getSession(\n        request.headers.get(\"Cookie\")\n    );\n    session.set(\"token\", \"abc123\")\n    var data = { \"count\": 2 }\n    console.log(session.get(\"token\"))\n    return json(data, {\n        headers: {\n            \"Set-Cookie\": await commitSession(session),\n        },\n    });\n};\n\nhowever when i try to access the value in a different page, the value is undefined\nexport const loader = async ({ request }: LoaderArgs) => {\n  const session = await getSession(\n    request.headers.get(\"Cookie\")\n  );\n  var data = { \"abc\": 442 }\n  console.log(session.get(\"token\"))\n  return json(data, {\n    headers: {\n      \"Set-Cookie\": await commitSession(session),\n    },\n  });\n\n  return null\n\n\n};\n\nI'm very new to remix and react so appreciate any help!\n",
"AnswerId": "76385442",
"AnswerBody": "the issue was to do with the sameSite option and Secure options.\nas I am working locally, Secure must be set to false which means sameSite must be either lax or strict\n"
},
{
"QuestionId": "76381732",
"QuestionTitle": "How to put 'or' into contraints in Pulp in python",
"QuestionBody": "I have a problem, where I have to find the optimal cost of 3 given motor.\nMotor 1 has a range of 100 - 300\nMotor 2 has a range of 400 - 1000\nMotor 3 has a range of 50 - 250\nThey have a target value of 600\nMotor 1 price is 5000\nMotor 2 price is 5500\nMotor 3 price is 5250\nThe equation looks like this:\nCost = Motor1 * 5000 + Motor2 * 5500 + Motor3 * 5250.\nAnd a very important part, NOT every motor needs to run.\nI have a python code, that can calculate it, but I can give it to it that not every motors needs to be inclued.\nHere is the code:\nfrom pulp import LpProblem, LpVariable, LpMinimize\n\ndef find_lowest_cost():\n    # Define the problem\n    problem = LpProblem(\"Motor Optimization\", LpMinimize)\n\n    # Define the decision variables\n    x = LpVariable(\"Motor1\", lowBound=100, cat='Integer')  # Power of motor 1\n    y = LpVariable(\"Motor2\", lowBound=0, cat='Integer')  # Power of motor 2\n    z = LpVariable(\"Motor3\", lowBound=50, cat='Integer')  # Power of motor 3\n\n    # Define the objective function (cost)\n    problem += x * 5000 + y * 5500 + z * 5250\n\n    # Define the constraints\n    problem += x >= 100  # Motor 1 lower bound\n    problem += x <= 300   # Motor 1 upper bound\n    problem += y >= 350  # Motor 2 lower bound\n    problem += y <= 1000  # Motor 2 upper bound\n    problem += z >= 50  # Motor 3 lower bound\n    problem += z <= 250  # Motor 3 upper bound\n    problem += x + y + z == 500  # Total power constraint\n\n    # Solve the problem\n    problem.solve()\n\n    # Retrieve the optimal solution\n    lowest_cost = problem.objective.value()\n    best_combination = (x.value(), y.value(), z.value())\n    return lowest_cost, best_combination\n\ncost, combination = find_lowest_cost()\nprint(\"Lowest cost:\", cost)\nprint(\"Motor combination:\", combination)\n\nI tried to add 'or' to the \"Define the Constraints' part, but it did not help\n    problem += x >= 100 or x ==0 # Motor 1 lower bound\n    problem += x <= 300  # Motor 1 upper bound\n    problem += y >= 350 or y == 0 # Motor 2 lower bound\n    problem += y <= 1000  # Motor 2 upper bound\n    problem += z >= 50 or z == 0 # Motor 3 lower bound\n    problem += z <= 250  # Motor 3 upper bound\n    problem += x + y + z == 500  # Total power constraint\n\nSo my Questions is, how to implement that 'OR' into my code.\nThank you in advance\n",
"AnswerId": "76382299",
"AnswerBody": "I make some assumptions:\n\nContinuous power of motors, not integral\nObserve the minima in your variable bounds, not the redundant and inconsistent constraints added later\nUse 500 as a target, not 600\n\nYou need binary selection variables, like this:\nfrom pulp import LpProblem, LpVariable, LpMinimize, LpContinuous, lpDot, LpBinary, lpSum\n\npowers = (\n    LpVariable('Motor1', cat=LpContinuous, upBound=300),\n    LpVariable('Motor2', cat=LpContinuous, upBound=1000),\n    LpVariable('Motor3', cat=LpContinuous, upBound=250),\n)\nused = LpVariable.matrix(name='MotorUsed', cat=LpBinary, indices=range(len(powers)))\n\nproblem = LpProblem(name='Motor_Optimization', sense=LpMinimize)\nproblem.objective = lpDot(powers, (5000, 5500, 5250))\n\nproblem.addConstraint(name='target', constraint=lpSum(powers) == 500)\n\nfor power, power_min, use in zip(\n    powers,\n    (100, 0, 50),\n    used,\n):\n    problem.addConstraint(power >= power_min*used)\n    problem.addConstraint(power <= 1000*used)\n\nproblem.solve()\ncombination = [p.value() for p in powers]\nprint('Lowest cost:', problem.objective.value())\nprint('Motor combination:', combination)\n\nResult - Optimal solution found\n\nObjective value:                2550000.00000000\nEnumerated nodes:               0\nTotal iterations:               0\nTime (CPU seconds):             0.01\nTime (Wallclock seconds):       0.01\n\nOption for printingOptions changed from normal to all\nTotal time (CPU seconds):       0.01   (Wallclock seconds):       0.01\n\nLowest cost: 2550000.0\nMotor combination: [300.0, 0.0, 200.0]\n\n"
},
{
"QuestionId": "76383521",
"QuestionTitle": "How to fix - Overflow in int64 addition",
"QuestionBody": "I am trying to calculate future dates by adding a column with number of days df['num_days'] to another column df[\"sampling_date\"] but getting Overflow in int64 addition.\nSource code-\ndf['sampling_date']=pd.to_datetime(df['sampling_date'], errors='coerce')\ndf['future_date'] = df['sampling_date'] + pd.to_timedelta(df['num_days'], unit='D')\ndf['future_date'] = pd.to_datetime(df['future_date']).dt.strftime('%Y-%m-%d')\ndf['future_date'] = df['future_date'].astype(np.str)\ndf['future_date'] = np.where(df['num_days']<=0,0, df['future_date'])\n\nfor column df['num_days'], the values are as follows [0, 866, 729, 48357555, 567, 478]\nI am trying to run this in unix server. Please help me resolving it.\n",
"AnswerId": "76383631",
"AnswerBody": "The issue is this value: 48357555\nYou can create a simple function as shown below to return NaT if error is thrown:\nimport numpy as np\nimport pandas as pd\n\n# Here is an example df\ndf = pd.DataFrame({\n    'sampling_date': ['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01', '2022-05-01', '2022-06-01'],\n    'num_days': [0, 866, 729, 48357555, 567, 478]\n})\n\ndf['sampling_date'] = pd.to_datetime(df['sampling_date'], errors='coerce')\n\ndef calculate_future_date(row):\n    try:\n        return row['sampling_date'] + pd.to_timedelta(row['num_days'], unit='D')\n    except:\n        return pd.NaT\n\n# Apply the function to each row\ndf['future_date'] = df.apply(calculate_future_date, axis=1)\ndf['future_date'] = np.where(df['num_days'] <= 0, df['sampling_date'], df['future_date'])\ndf['future_date'] = df['future_date'].dt.strftime('%Y-%m-%d').replace(pd.NaT, '0').astype(str)\nprint(df)\n\n\n  sampling_date  num_days future_date\n0    2022-01-01         0  2022-01-01\n1    2022-02-01       866  2024-06-16\n2    2022-03-01       729  2024-02-28\n3    2022-04-01  48357555           0\n4    2022-05-01       567  2023-11-19\n5    2022-06-01       478  2023-09-22\n\n"
},
{
"QuestionId": "76383630",
"QuestionTitle": "Remove log files on aws s3 (rails7)",
"QuestionBody": "Which option is better to remove log files on aws s3 for rails7? s3 automation vs cron job\nI wrote some rake tasks.\ntask :delete_stale_logs do\n    s3 = Aws::S3::Resource.new(\n      region: ENV['AWS_REGION'],\n      access_key_id: ENV['AWS_ACCESS_KEY_ID'],\n      secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']\n    )\n\n    bucket = s3.bucket(ENV['AWS_BUCKET'])\n\n    bucket.objects.each do |object|\n      if object.key.include?('.log') && object.last_modified < Time.now - 30.days\n        object.delete\n        puts \"Deleted #{object.key}\"\n      end\n    end\n  end\nend\n\n",
"AnswerId": "76383660",
"AnswerBody": "Cron job is better in case you have some conditional logics for the number of logs, otherwise s3 automation. If you go for cron jobs, you have to handle monitoring to check if jobs fail or not. Check here for more info.\n"
},
{
"QuestionId": "76385395",
"QuestionTitle": "What could be causing my second React JSX function to fail to return  elements, despite properly filtered data?",
"QuestionBody": "I am creating a simple search bar element in React JSX. I'm trying to render a list of elements that include whatever is in a search query. I basically take an array of all the elements and then I use .filter() function to find everything that includes the query. After that I use .map() function to loop through the results and render  elements for each object. I needed to create two different functions for two different datasets as one is an array deeper.\n<ul>\n\n\n{                    \n this.state.searchQuery &&\n                                \n     this.props.searchDB.projects.filter((project)=> {\n         if (this.state.searchQuery === '' || this.state.searchQuery === null) {\n            return project;\n         } else if (project.projectName.toLowerCase().includes(this.state.searchQuery.toLowerCase())) {\n            return project;\n         } else {\n            return null\n         }\n     }).map((project, index) => {\n         //THIS WORKS AS EXPECTED\n         return(\n             <li key={'project_' + index}>\n                 {index + '_' + project.projectName}\n             </li>\n         )\n    })\n                                \n}\n\n{\n     this.state.searchQuery &&\n                                \n         this.props.searchDB.mentions.forEach((mentionYear) => {\n    \n               mentionYear.filter((mention) => {\n    \n                   if (this.state.searchQuery === '' || this.state.searchQuery === null) {\n                     return mention\n                   } else if (mention.mentionTitle.toLowerCase().includes(this.state.searchQuery.toLowerCase())) {\n                     return mention\n                   } else {\n                     return null\n                   }\n              }).map((mention, mentionIndex) => {\n                   console.log(mention.mentionTitle)\n                   //THIS LOGS DATA AS IT SHOULD BUT DOESN'T RENDER ELEMENTS\n                                                \n                   return(\n                            <li key={'project_' + mentionIndex}>\n                               {mentionIndex + '_' + mention.mentionTitle}\n                            </li>\n                         )\n                   })\n               }\n             ) \n}\n\n</ul>\n\nThe first function works fine and returns a  element as it should. For some reason the second one does not and it doesn't return any element at all, even though it is basically the same code. Strange is that the data is there, I can log it from the map function and I can see that it is filtered properly. Can someone explain to me what's wrong? I tried quite a lot of possibile mistakes I could have made but I didn't find anything.\n",
"AnswerId": "76385443",
"AnswerBody": "The second version never does anything with the result of .map().  It's invoked inside a forEach() callback, but its result is discarded.  Contrast that to the first version where the result of .map() is part of the JSX and rendered.\nDon't use forEach() for this.  If the intent is that the .forEach() iteration should produce a result just like in the first version, then what you want isn't forEach().  What you want is .map().\nFor example:\n{\n  this.state.searchQuery &&\n    this.props.searchDB.mentions.map((mentionYear) => {\n      return mentionYear.filter((mention) => {\n        // etc.\n      }).map((mention, mentionIndex) => {\n        // etc.\n      });\n    })\n}\n\nBasically, repeat the same pattern/structure you already know works when iterating over a collection in JSX to produce a rendered result.\n"
},
{
"QuestionId": "76383595",
"QuestionTitle": "Is there a way to get the key at a specified position?",
"QuestionBody": "I wanted to print out a key at a specific position (like 1) in a dictionary, but the code didn't seem to work at all.\n    Hobbies={\n      football(american):1\n      baseball:2\n      basketball:3\n      playing_cards:4\n      swimming:5\n      soccer:7\n   }\n\nI used this line :\n     print (Hobbies[1])\n\nBut it got an error\nHow should I fix it?\n",
"AnswerId": "76383682",
"AnswerBody": "First off, you probably shouldn't do this, because this is not how dictionaries were intended to be accessed.\nBut if you really need to do this, probably the most straightforward way is to get the list of keys from the dictionary, and then access the dictionary using the first key.\nSomething like:\nlist_of_keys = [key for key in Hobbies.keys()]\nkey_of_interest = list_of_keys[0]\nvalue_of_interest = Hobbies[key_of_interest]\n\nOr as a one-liner:\nvalue_of_interest = Hobbies[[key for key in Hobbies.keys()][0]]\n\nThis may also work, but I'm not sure if the order of values is guaranteed the same way the order of keys is.  It probably is, but I can't say for sure:\nvalue_of_interest = [value for value in Hobbies.values()][0]\n\n"
},
{
"QuestionId": "76382170",
"QuestionTitle": "How can I resolve TS7015 in my TypeScript/Next.js/React project when using an index expression that is not of type number?",
"QuestionBody": "I Got Element implicitly has an 'any' type because index expression is not of type 'number'.ts(7015) error\nI have Improted this file\nimport { useAmazon } from \"@context/amazon\";\nI have Used hear\nconst { data, current_product } = useAmazon();\nand Got error\nconst main_image = data[current_product].main_image; // error in current_product\n@context/amazon file\nimport { JSObject } from \"@classes/JSObject\";\nimport React, { useState, useEffect, useContext, createContext } from \"react\";\nimport axios from \"axios\";\nimport { Product } from \"types\";\n\ntype AmazonContextType = {\n  data: Product[] | null;\n  current_product: string;\n  setProduct: (product: string) => void;\n  offers: JSObject | null;\n  setOffers: (offer: JSObject | null) => void;\n};\n\ntype Props = {\n  children: React.ReactNode;\n};\n\nconst amazonDefault: AmazonContextType = {\n  data: null,\n  current_product: '',\n  setProduct: () => undefined,\n  offers: null,\n  setOffers: () => undefined,\n};\n\nconst AmazonContext = createContext<AmazonContextType>(amazonDefault);\n\nexport function useAmazon() {\n  return useContext(AmazonContext);\n}\n\nexport function AmazonProvider({ children }: Props) {\n  const [data, setData] = useState(amazonDefault.data);\n  const [current_product, setProduct] = useState(amazonDefault.current_product);\n  const [offers, setOffers] = useState(amazonDefault.offers);\n\n  useEffect(() => {\n    const fetchData = async () => {\n      const url =\n        \"https://getdata.com/abc\";\n      const result = await axios(url);\n      setData(result.data.payload);\n      \n      \n    };\n    fetchData();\n  }, []);\n\n  return (\n    \n    <AmazonContext.Provider\n      value={{ data, current_product, setProduct, offers, setOffers }}\n    >\n      \n      {children}\n    </AmazonContext.Provider>\n  );\n}\n\nHow i can Solve this Error\nconst main_image = typeof current_product === 'string' ? data[current_product as keyof typeof data].main_image : null; \nI have also try chatGPT and google bard\nkeyword\ntypescript\nnext.js\nreactjs\njavascript\njson\n",
"AnswerId": "76382315",
"AnswerBody": "You can't access the item by a property of the object using the square bracket syntax.\nAssuming that current_product is the name of the product (might be id, but I can't see the Product type), you need to do the following:\nconst main_image = data !== null ? data.find(product => product === current_product).main_image : null;\n\n"
},
{
"QuestionId": "76384888",
"QuestionTitle": "Change Button's color twice when it's clicked",
"QuestionBody": "I'm trying to create a button whose change background color (to green) when it is cliked. But when it is cliked againg the button returns to the original background color (from orange).\nvar btn1 = document.getElementById(\"btn-1\")\n\nif (btn1.style.backgroundColor = \"orange\") {\n        btn1.addEventListener(\"click\", function () {\n        btn1.style.backgroundColor = \"green\"\n    })\n} else {btn1.addEventListener(\"click\", function () {\n    btn1.style.backgroundColor = \"orange\"\n})\n    }\n\nCould you help me? Thx!\nI'm trying to create a button whose change background color (to green) when it is cliked. But when it is cliked againg the button returns to the original background color (from orange).\n",
"AnswerId": "76385463",
"AnswerBody": "\n\nlet button = document.getElementById(\"button\");\n    button.style.backgroundColor = \"orange\";\n\nbutton.addEventListener(\"click\", function () {\n        if(button.style.backgroundColor == \"orange\"){\n           button.style.backgroundColor = \"green\";\n        } else button.style.backgroundColor = \"orange\";\n})\n<button id=\"button\">test</button>\n\n\n\nhow i understand you: you can set starter color of button to orange;\nand then add EventListener to button with this logic:\n-if the color of the button is orange - change to green\nor if the color is not orange - change to orange\n"
},
{
"QuestionId": "76383370",
"QuestionTitle": "Vue 3 Component losing reactivity",
"QuestionBody": "I've been learning Vue 3 for the past month or so and have gotten quite far but I can't fix this no matter what I've tried. I know I'm losing reactivity but I can't figure out how and it's driving me nuts. I am using the Composition API and script setup with a simple Pinia store. I created a github repo for it here: https://github.com/thammer67/vue3-reactivity-problem\nI have a view (ProjectsView.vue) of project elements that loops through a pinia store array of projects using v-for and passing the array object as a prop. ProjectsView.vue uses a hidden form component (ProjectForm.vue) that I use for adding new projects. Each project in the loop is another component (ProjectItem.vue) with a click handler to a route that loads ProjectDetail.vue. ProjectDetail.vue has a click handler that also uses ProjectForm.vue for editing the item.\nEverything works great. I can add new projects, edit projects but when I edit a project the pinia store updates (I can see this in the Vue Dev tools) but the UI doesn't update untill I go back to the project list. I need to update the value in ProjectDetail.vue after saving. Here are the pertinent files.\nProjectDetail.vue:\n<script setup>\nimport { useProjectStore } from '../stores/ProjectStore'\nimport { useRoute } from 'vue-router'\nimport { ref } from 'vue'\nimport ProjectForm from '@/components/Form/ProjectForm.vue'\n\nconst projectStore = useProjectStore()\nconst route = useRoute()\nconst id = route.params.id\nconst project = projectStore.getProjectById(id)\n\nconst showEditProject = ref(false)\nconst editing = ref(false)\n\nconst editProject = (id)=> {\n    editing.value = id\n    showEditProject.value = true\n}\n</script>\n\n<template>\n    <div class=\"main\">\n        <div v-if=\"project\" :project=\"project\">\n            <h2>Project Details</h2>\n            <div>\n                <div class=\"project-name\">{{ project.project }}</div> \n            </div>\n            <div style=\"margin-top: 1em\">\n                <button type=\"button\" @click=\"editProject(project.id)\">Edit</button>\n            </div>\n\n            <ProjectForm\n                @hideForm=\"showEditProject=false\" \n                :project=\"project\"\n                :editing=\"editing\"\n                :showAddEntry=\"showEditProject\" />\n        </div>\n    </div>\n</template>\n\nProjectForm.vue:\n<script setup>\nimport { ref, toRef, reactive } from \"vue\"\nimport { useProjectStore } from '@/stores/ProjectStore.js'\nimport Input from './Input.vue'\n\nconst projectStore = useProjectStore() \nconst showAddType = ref(false)\n\n//Capture 'showAddEntry' prop from parent component\nconst props = defineProps(['showAddEntry', 'editing', 'project'])\n\n//Copy prop values for the form\nconst projName = toRef(props.project.project)\nconst projId = toRef(props.project.id)\n\n//new/edited values are stored on this reactive object\nconst formState = reactive({\n    invalid: false,\n    errMsg:  \"\"\n})\n\nconst saveProject = () => {\n    formState.invalid = false\n\n    if(projId.value) {\n        console.log(`Update existing project ${projId.value}`)\n\n        projectStore.updateProject({\n            id: projId.value,\n            project: projName.value\n        })\n        .then(()=> {\n            console.log(\"save was successful!\")\n            showAddType.value = false\n            formState.invalid = false\n            formState.errMsg = \"\"\n            emit('hideForm')\n        })\n        .catch(err=>console.log(\"Error: \", err))\n    } else {\n        console.log(`Create new project`)\n        //New Project\n        projectStore.createProject({\n            project: projName.value,\n        })\n        .then(()=> {\n            showAddType.value = false\n            formState.invalid = false\n            formState.errMsg = \"\"\n            emit('hideForm')\n        })\n    }\n}\n\nconst hideForm = ()=> {\n    formState.invalid = false\n    showAddType.value=false\n    emit('hideForm')\n}\n\n//Define emit event up to the parent that hides the form\nconst emit = defineEmits(['hideForm'])\n\n</script>\n\n<template>\n    <div class=\"addform\" :class=\"{ show: props.showAddEntry }\">\n        <h1 v-if=\"editing\" class=\"title\">Edit Project</h1>\n        <h1 v-else class=\"title\">Add New Project</h1>\n\n        <div class=\"input-wrap\" :class=\"{ 'input-err' : formState.invalid }\">\n            <Input \n                @input=\"projName = $event.target.value\"\n                type=\"text\" \n                placeholder=\"Enter project name\" \n                :value=\"projName\"\n            />\n           \n            <div class=\"entry-submit\">\n                <button v-if=\"editing\" @click=\"saveProject\">Save</button>\n                <button v-else @click=\"saveProject\">Create Project</button>\n                <button @click=\"hideForm\">Cancel</button>\n            </div>\n        </div>\n        <p v-show=\"formState.invalid\" class=\"err-msg\">{{ formState.errMsg }}</p>\n    </div>\n</template>\n\n",
"AnswerId": "76383691",
"AnswerBody": "project in ProjectDetails.vue is not aware of changes being made to it in the store.  It will if you wrap it with computed()\nimport { computed } from 'vue'\n\nconst project = computed(() => projectStore.getProjectById(id))\n\n"
},
{
"QuestionId": "76381667",
"QuestionTitle": "Elastic Search Regex are not working as expected",
"QuestionBody": "I have go the problem in making elastic search regex work. I have a document that looks like this:\n{\"content\": \"keySyAtUXpd8JxrpUH2Sd\"}\n\nI have trying the following regex key[0-9A-Za-z_]{18} which perfectly matches with the string in regexer.com but when I query the request from elastic search it doesn't show any hits.\nHere's the request that i'm using:\ncurl -XGET 'https://localhost:9200/_search?pretty' -H 'Content-Type: application/json' -H 'Authorization: Basic redacted' -k -d '{\n  \"query\": { \"regexp\": { \"content\": \"key[0-9A-Za-z_]{18}\" } }\n}'\n\nI have also tried the regex with .*key[0-9A-Za-z_]{18}.*, tried to escape - as \\\\- but it doesn't seems to be working as well.\n",
"AnswerId": "76382386",
"AnswerBody": "You need to run the regexp query against the content.keyword field\ncurl -XGET 'https://localhost:9200/_search?pretty' -H 'Content-Type: application/json' -H 'Authorization: Basic redacted' -k -d '{\n  \"query\": { \"regexp\": { \"content.keyword\": \"key[0-9A-Za-z_]{18}\" } }\n}'\n\nPS: easier to test and provide feedback with real content and real queries ;-)\n"
},
{
"QuestionId": "76380607",
"QuestionTitle": ".Net Maui Google Maps Polyline drawning route feature",
"QuestionBody": "I have this situation:\nI'm building a .net Maui smartphone sports app that grabs a list of latitude and longitude (new Location class) of a running activity and draws a line (polyline) in the map to display the route. I can grab the list of exercises from the database and I can draw a polyline in the map, the problem is that I can't do both together because I don't know how to databind the Map functionalitys in my ViewModel class.\nHere is my xaml code for the ExercisePage.xaml:\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<ContentPage xmlns=\"http://schemas.microsoft.com/dotnet/2021/maui\"\n             xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"\n             x:Class=\"DoradSmartphone.Views.ExercisePage\"\n             xmlns:model=\"clr-namespace:DoradSmartphone.Models\"\n             xmlns:viewmodel=\"clr-namespace:DoradSmartphone.ViewModels\"\n             xmlns:maps=\"clr-namespace:Microsoft.Maui.Controls.Maps;assembly=Microsoft.Maui.Controls.Maps\"\n             xmlns:sensors=\"clr-namespace:Microsoft.Maui.Devices.Sensors;assembly=Microsoft.Maui.Essentials\"\n             x:DataType =\"viewmodel:ExerciseViewModel\"\n             Title=\"{Binding Title}\">\n\n\n\n\n    <Grid Padding=\"5\" Margin=\"5\" RowSpacing=\"5\" ColumnSpacing=\"3\">\n        <Grid.RowDefinitions>\n            <RowDefinition Height=\"2*\"/>\n            <RowDefinition Height=\"150\"/>\n        </Grid.RowDefinitions>\n\n        <maps:Map Grid.Row=\"0\" x:Name=\"routeMap\" VerticalOptions=\"CenterAndExpand\" Grid.ColumnSpan=\"3\" HeightRequest=\"400\" IsZoomEnabled=\"False\" IsEnabled=\"False\">\n            <x:Arguments>\n                <MapSpan>\n                    <x:Arguments>\n                        <sensors:Location>\n                            <x:Arguments>\n                                <x:Double>38.744418137669875</x:Double>\n                                <x:Double>-9.128544160596851</x:Double>\n                            </x:Arguments>\n                        </sensors:Location>\n                        <x:Double>0.7</x:Double>\n                        <x:Double>0.7</x:Double>\n                    </x:Arguments>\n                </MapSpan>\n            </x:Arguments>\n        </maps:Map>\n\n        <CarouselView ItemsSource=\"{Binding Exercises}\" Grid.Row=\"1\" PeekAreaInsets=\"100\">\n            <CarouselView.ItemTemplate>\n                <DataTemplate x:DataType=\"model:Exercise\">\n                    <Frame HeightRequest=\"90\" Margin=\"5\">\n                        <Frame.GestureRecognizers>\n                            <TapGestureRecognizer Command=\"{Binding Source={RelativeSource AncestorType={x:Type viewmodel:ExerciseViewModel}}, Path=ExerciseDetailsCommand}\n                                            \" CommandParameter=\"{Binding .}\"></TapGestureRecognizer>\n                        </Frame.GestureRecognizers>\n                        <HorizontalStackLayout Padding=\"10\" Spacing=\"5\" >\n                            <Label Text=\"{Binding Id}\"></Label>\n                            <Label Text=\"{Binding Date}\"></Label>\n                        </HorizontalStackLayout>\n                    </Frame>\n                </DataTemplate>\n            </CarouselView.ItemTemplate>\n        </CarouselView>\n    </Grid>\n</ContentPage>\n\nAs you can see I have my map name declared as routeMap and the first location just to start in somewhere. I also has my  model and viewmodel declared for DataBinding of the exercise list in the CarouselView. The tap feature works fine and take me to a new view called ExerciseDetailsPage.\nThis is the code behind ExercisePage.xaml.cs\nusing DoradSmartphone.Models;\nusing DoradSmartphone.ViewModels;\nusing Microsoft.Maui.Controls.Maps;\nusing Microsoft.Maui.Maps;\n\nnamespace DoradSmartphone.Views;\n\npublic partial class ExercisePage : ContentPage\n{\n    public ExercisePage(ExerciseViewModel exerciseViewModel)\n    {\n        InitializeComponent();\n        BindingContext = exerciseViewModel;\n    }\n\n    \n    private void OnTapGestureRouteUpdate(object sender, EventArgs e)\n    {\n        var route = new Polyline\n        {\n            StrokeColor = Colors.Red,\n            StrokeWidth = 12,\n            Geopath =\n            {\n                new Location(38.70061856336034 , -8.957381918676203 ),\n                new Location(38.70671683905933 , -8.945225024701308 ),\n                new Location(38.701985630081595, -8.944503277546072 ),\n                new Location(38.701872978433386, -8.940750192338834 ),\n                new Location(38.71054663609023 , -8.939162348597312 ),\n                new Location(38.717755109243214, -8.942193686649311 ),\n                new Location(38.7435419727561  , -8.928480490699792 ),\n                new Location(38.78327379379296 , -8.880556478454272 ),\n                new Location(38.925473761602376, -8.881999972299806 ),\n                new Location(38.93692729913667 , -8.869585920414709 ),\n                new Location(38.93493556584553 , -8.86536198145887  )\n            }\n        };\n        routeMap.MoveToRegion(\n            MapSpan.FromCenterAndRadius(\n                new Location(38.93479161472441, -8.865352563545757), Distance.FromMiles(1)));\n        // Add the polyline to the map\n        routeMap.MapElements.Add(route);\n    }\n}\n\nIf I change the actual tap functionality to this tap event, I can drawn any line and other stuffs with in the Map because I can read the map name defined in the xaml code. But in this codebehind class I can't reach my ViewModel, Services or Model class.\nThis is my ExerciseViewModel.cs class:\nusing CommunityToolkit.Mvvm.ComponentModel;\nusing CommunityToolkit.Mvvm.Input;\nusing DoradSmartphone;\nusing DoradSmartphone.Models;\nusing DoradSmartphone.Services;\nusing DoradSmartphone.Views;\nusing Microsoft.Maui.Controls.Maps;\nusing Microsoft.Maui.Maps;\nusing System.Collections.ObjectModel;\n\nnamespace DoradSmartphone.ViewModels\n{\n    public partial class ExerciseViewModel : BaseViewModel\n    {\n        private readonly ExerciseService exerciseService;\n\n        public ObservableCollection<Exercise> Exercises { get; private set; } = new();\n        public ExerciseViewModel(ExerciseService exerciseService)\n        {\n            Title = \"Training Routes\";\n            this.exerciseService = exerciseService;\n            _ = GetExerciseList();                                   \n        }\n\n        [ObservableProperty]\n        bool isRefreshing;\n        \n        async Task GetExerciseList()\n        {\n            if (IsLoading) return;\n            try\n            {\n                IsLoading = true;\n                if (Exercises.Any()) Exercises.Clear();\n\n                var exercices = exerciseService.GetExercises();\n                foreach (var exercise in exercices) Exercises.Add(exercise);\n            } catch(Exception ex) { \n                Console.WriteLine(ex.ToString());\n                await Shell.Current.DisplayAlert(\"Error\", \"Failed to retrieve the exercice list\", \"Ok\");\n            }\n            finally { \n                IsLoading = false; \n                isRefreshing= false;\n             }\n        }\n        [RelayCommand]\n        async Task ExerciseDetails(Exercise exercise)\n        {\n            if(exercise == null) return;\n\n            var routes = GetLocations(exercise.Id);\n\n            DrawRoutes(routes);\n        }\n\n        public List<Location> GetLocations(int exerciseId)\n        {\n            if (exerciseId == 1)\n            {\n                return new List<Location>\n                        {\n                            new Location(35.6823324582143, 139.7620853729577),\n                            new Location(35.679263477092704, 139.75773939496295),\n                            new Location(35.68748054650018, 139.761486207315),\n                            new Location(35.690745005825136, 139.7560362984393),\n                            new Location(35.68966608916097, 139.75147199952355),\n                            new Location(35.68427128680411, 139.7442168083328)\n                        };\n            }\n            else if (exerciseId == 2)\n            {\n                return new List<Location>\n                        {\n                            new Location(35.6823324582143, 139.7620853729577),\n                            new Location(35.679263477092704, 139.75773939496295),\n                            new Location(35.68748054650018, 139.761486207315),\n                            new Location(35.690745005825136, 139.7560362984393),\n                            new Location(35.68966608916097, 139.75147199952355),\n                            new Location(35.68427128680411, 139.7442168083328)\n                        };\n            }\n            else\n            {\n                return new List<Location>\n                        {\n                            new Location(35.6823324582143, 139.7620853729577),\n                            new Location(35.679263477092704, 139.75773939496295),\n                            new Location(35.68748054650018, 139.761486207315),\n                            new Location(35.690745005825136, 139.7560362984393),\n                            new Location(35.68966608916097, 139.75147199952355),\n                            new Location(35.68427128680411, 139.7442168083328)\n                        };\n            }\n        }\n\n        private void DrawRoutes(List<Location> routes)\n        {\n            var polylines = new Polyline\n            {\n                StrokeColor = Colors.Red,\n                StrokeWidth = 12,\n            };\n\n            foreach(var route in routes)\n            {\n                polylines.Geopath.Add(route);\n            }                        \n            \n            routeMap.MoveToRegion(\n                MapSpan.FromCenterAndRadius(\n                    routes.FirstOrDefault(), Distance.FromMiles(1)));\n            // Add the polyline to the map\n            routeMap.MapElements.Add(polylines);\n        }\n    }\n}\n\n\nThis class inherits the BaseViewModel that inherits ObservableObject and has some common properties for all others classes. In the ExerciseViewModel I have my RelayCommand related to the tap feature that grabs the exercise object and add the route, but I cant access the routeMap object. I've tried also to declare a Map class in my viewmodel class, but I get the error all the time that I can't create a instance of a static class.\nThis is my MauiProgram.cs just in case there's something wrong:\nusing DoradSmartphone.Data;\nusing DoradSmartphone.Services;\nusing DoradSmartphone.ViewModels;\nusing DoradSmartphone.Views;\n\nnamespace DoradSmartphone;\n\npublic static class MauiProgram\n{\n    public static MauiApp CreateMauiApp()\n    {\n        var builder = MauiApp.CreateBuilder();\n        builder\n            .UseMauiApp<App>()       \n            .UseMauiMaps()\n            .ConfigureFonts(fonts =>\n            {\n                fonts.AddFont(\"OpenSans-Regular.ttf\", \"OpenSansRegular\");\n                fonts.AddFont(\"OpenSans-Semibold.ttf\", \"OpenSansSemibold\");\n            });\n\n        builder.Services.AddSingleton<DatabaseConn>();\n        builder.Services.AddScoped<IRepository, DatabaseConn>();\n\n        builder.Services.AddSingleton<MainPage>();\n        builder.Services.AddSingleton<UserPage>();\n        builder.Services.AddSingleton<LoginPage>();        \n        builder.Services.AddSingleton<LoadingPage>();\n        builder.Services.AddSingleton<ExercisePage>();\n        builder.Services.AddSingleton<DashboardPage>();\n        builder.Services.AddSingleton<ExerciseDetailsPage>();\n\n        builder.Services.AddSingleton<UserService>();\n        builder.Services.AddSingleton<LoginService>();        \n        builder.Services.AddSingleton<ExerciseService>();\n        builder.Services.AddSingleton<DashboardService>();\n\n        builder.Services.AddSingleton<UserViewModel>();\n        builder.Services.AddSingleton<LoginViewModel>();        \n        builder.Services.AddSingleton<LoadingViewModel>();\n        builder.Services.AddSingleton<ExerciseViewModel>();\n        builder.Services.AddSingleton<DashboardViewModel>();\n        builder.Services.AddTransient<ExerciseDetailsViewModel>();\n\n        return builder.Build();\n    }\n}\n\nThank you in advance!\n",
"AnswerId": "76382427",
"AnswerBody": "unfortunately, MapElements is not a bindable property.  However, you can work around that in a couple of ways\nfor example, create a public method in your VM that returns the route data\npublic Polyline GetRouteData()\n{\n    var polylines = new Polyline\n        {\n            StrokeColor = Colors.Red,\n            StrokeWidth = 12,\n        };\n\n        foreach(var route in routes)\n        {\n            polylines.Geopath.Add(route);\n        } \n\n  return polylines; \n}\n\nthen in your code behind, first create a class reference to the VM\nExerciseViewModel ViewModel;\n\npublic ExercisePage(ExerciseViewModel exerciseViewModel)\n{\n    InitializeComponent();\n    BindingContext = ViewModel = exerciseViewModel;\n}\n\nthen your code behind can get the data from the VM that it needs to update the map\nrouteMap.MapElements.Add(ViewModel.GetRouteData());\n\n"
},
{
"QuestionId": "76385151",
"QuestionTitle": "Replacing values in a string expression based on a matrix and iterating over columns",
"QuestionBody": "In column X are those variables that will have values in each column j, in this case only U1, X4 and U2 have values, the rest of the variables belonging to the list ['B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'] will all have their values 0\n#example matrix\nnew_matrix = [[ 'C',  'X', 'B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], \n              [ 0.0, 'U1',   8,  2.0,  1.0, -1.0,    0,    0,  1.0,    0], \n              ['+M', 'X4',   2,  1.0,  1.0,    0,  1.0,    0,    0,    0], \n              ['+M', 'U2',   8,  1.0,  2.0,    0,    0, -1.0,    0,  1.0]]\n\nvariables = ['X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2', 'B'] #select the first row (only variables)\nvariables_j_col_values = [[variables.pop(variables.index('B'))] + variables, []] # --> ['B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2']\n\nThe problem with this is that I need create the following matrix of values of the variables (without using libraries) where I would have the following:\nvariables_j_col_values = [['B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], \n                          [ 0 ,    0,    0,    0,    2,    0,    8,    8],    #column new_matrix[][2]\n                          [ 0 ,    0,    0,    0,  1.0,    0,  2.0,  1.0],    #column new_matrix[][3]\n                          [ 0 ,    0,    0,    0,  1.0,    0,  1.0,  2.0],    #column new_matrix[][4]\n                          [ 0 ,    0,    0,    0,    0,    0, -1.0,    0],    #column new_matrix[][5]\n                          [ 0 ,    0,    0,    0,  1.0,    0,    0,    0],    #column new_matrix[][6]\n                          [ 0 ,    0,    0,    0,    0,    0,    0, -1.0],    #column new_matrix[][7]\n                          [ 0 ,    0,    0,    0,    0,    0,  1.0,    0],    #column new_matrix[][8]\n                          [ 0 ,    0,    0,    0,    0,    0,    0,  1.0], ]  #column new_matrix[][9]\n\nAfter create the variables_j_col_values, go replacing the values of the rows (except for row 0 of the variables_j_col_values array because it is a header) in the string inside funcion_obj_z\nThe logic would be to use a loop that goes through the rows, and does a\n.replace(new_matrix[][n], this_element)\nfuncion_obj_z = 'Z = 3 * X1 + 2 * X2 + 0 * X3 + 0 * X4 + 0 * X5 + M * U1 + M * U2'\n\nIn this way, using said string as an expression, it would obtain these prints in the console if it printed the value of j_func in each j iteration. These would be the desired correct output:\n#for loop, print the j string replacement the values in the string\n\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 2 + 0 * 0 + M * 8 + M * 8' #iteration 1\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 1.0 + 0 * 0 + M * 2.0 + M * 1.0' #iteration 2\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 1.0 + 0 * 0 + M * 1.0 + M * 2.0' #iteration 3\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 0 + 0 * 0 + M * -1.0 + M * 0' #iteration 4\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 1.0 + 0 * 0 + M * 0 + M * 0' #iteration 5\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 0 + 0 * 0 + M * 0 + M * -1.0' #iteration 6\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 0 + 0 * 0 + M * 1.0 + M * 0' #iteration 7\nj_func = 'Z = 3 * 0 + 2 * 0 + 0 * 0 + 0 * 0 + 0 * 0 + M * 0 + M * 1.0' #iteration 8\n\n",
"AnswerId": "76385493",
"AnswerBody": "Albeit an ugly solution, this should give you the transformation you need:\nnew_matrix = [[ 'C',  'X', 'B', 'X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2'], \n              [ 0.0, 'U1',   8,  2.0,  1.0, -1.0,    0,    0,  1.0,    0], \n              ['+M', 'X4',   2,  1.0,  1.0,    0,  1.0,    0,    0,    0], \n              ['+M', 'U2',   8,  1.0,  2.0,    0,    0, -1.0,    0,  1.0]]\n\nvariables = ['X1', 'X2', 'X3', 'X4', 'X5', 'U1', 'U2', 'B']\n\n# create empty matrix\nvariables_j_col_values = [[0 for _ in range(len(variables))] for _ in range(len(new_matrix[0])-1)]\n\n# replace first row with sorted variables based on new_matrix headers\nvariables_j_col_values[0] = sorted(variables, key=lambda x: new_matrix[0].index(x))\n\n# loop over all value rows\nfor row in new_matrix[1:]\n    # get correct column in variables_j_col_values based\n    col = variables_j_col_values[0].index(row[1])\n    # zip the values and rows and update accordingly\n    for val, target in zip(row[2:], variables_j_col_values[1:]):\n        target[col] = val\n\n"
},
{
"QuestionId": "76382456",
"QuestionTitle": "How can i create a deviations query?",
"QuestionBody": "I wanted to write a query that would allow me to calculate deviations by the number of created orders.\nTask: the query should look back 7 days and based on this data build a minimum allowable threshold (MAT). If the number of orders for a minimum period of time (5 minutes) is less than MAT, then an alert will be generated.\nFeatures: The number of orders directly affects the time of day and seasonality.\nHaving searched the Internet, I found information about so-called Poisson distribution, and tried to apply it to the problem, but it didn't work.\nIn prometheus there are such functions as day_of_week(), avg_over_time() and stddev_over_time.\nFrom what I was able to do:\n\nThe difference between the number of orders in the last 5 min.\nsum(delta(my_search_counter{service_name=\"car.book.v1\"}[5m])\nFive-minute average time variation over the last 30 minutes with a resolution of 5 minutes\navg_over_time(sum(delta(my_search_counter{service_name=\"car.book.v1\"}[5m]))[1w:5m])\nMean square deviation:\nstddev_over_time(sum(delta(my_search_counter{service_name=\"car.book.v1\"}[5m]))[1w:5m])\n\nThis is where I'm stuck and can't figure out how to build a proper query. Maybe there is another way, simpler, but I haven't found it.\nI tried to combine these queries with each other using addition, subtraction and division.\n",
"AnswerId": "76383719",
"AnswerBody": "I'm not sure what statistics is this, and how adequate this is as a threshold, but here is query you described.\nsum(increase(my_search_counter{service_name=\"car.book.v1\"}[5m]))\n< sum(increase(my_search_counter{service_name=\"car.book.v1\"}[5m] offset 1w))\n  - stddev_over_time(sum(increase(my_search_counter{service_name=\"car.book.v1\"}[5m] offset 1w))[1d:5m])\n\nIt returns value if number of oreder over last 5 minutes is less then number of orders over same 5 minutes 1 week ago minus standart deviation of orders number over 24 hours presiding current moment 1 week ago.\nYou might need to play a little with multiplier for stddev part, to get a reasonable percent of alerts.\n"
},
{
"QuestionId": "76383416",
"QuestionTitle": "Group list of objects into Map with value being true if any object in group has field set as true using Java stream API",
"QuestionBody": "In a Java 17 project, I have a collection of objects with a String field propGroupName representing the group this object belongs to and a Boolean field propValActive representing whether this object is flagged as active internally.\nI want to aggregate these objects by the string field into a Map<String, Boolean> with the key being the String field and the Boolean being false if all the booleans in the group are false and true if 1 or more of the booleans in the group are false. I have a working implementation with a simple for loop, but I want to know if there is a way to do this grouping through the Java Stream API, preferably in a way that short circuits? The goal is that I want to know of every group whether there are any objects in that group flagged as active.\nI currently have this implementation which doesn't use the Streams API and doesn't short circuit:\npublic Map<String, Boolean> determineActiveGroups(\n        HashMap<String, PropertyValueDefinitionGroupView> standardPvdgMap) {\n    Map<String, Boolean> activeGroupsMap = new HashMap<String, Boolean>();\n    for (PropertyValueDefinitionGroupView pvdgView : standardPvdgMap.values()) {\n        if(pvdgView.getPropGroupOid() == null) {\n            continue;\n        }\n        activeGroupsMap.putIfAbsent(pvdgView.getPropGroupName(), false);\n        if(pvdgView.getPropValActive()) {\n            activeGroupsMap.put(pvdgView.getPropGroupName(), true);\n        }\n    }\n    return activeGroupsMap;\n}\n\nI have a different bit of code somewhere else that does something similar, but it retains the lists, and I managed to adapt something similar for what I need but I don't know what predicate I can use to finish it with. I assume it's going to use anyMatch, but I have no idea how to integrate it:\nMap<String, Boolean> activeGroups = standardPvdgMap.values().stream()\n    .collect(Collectors.groupingBy(PropertyValueDefinitionGroupView::getPropGroupName, ???????));\n\n",
"AnswerId": "76383740",
"AnswerBody": "groupingBy is such a powerful collector :\npublic Map<String, Boolean> determineActiveGroups(Map<String, PropertyValueDefinitionGroupView> standardPvdgMap) {\n    return standardPvdgMap.values()\n            .stream()\n            .filter(pvdgView -> pvdgView.getPropGroupOid() != null)\n            .collect(Collectors.groupingBy(\n                    PropertyValueDefinitionGroupView::getPropGroupName,\n                    Collectors.mapping(\n                            PropertyValueDefinitionGroupView::getPropValActive,\n                            Collectors.reducing(false, (a, b) -> a || b))\n            ));\n}\n\nThe trick is knowing that you can apply further collectors on the downstream. In this case I map to the flag, and then reduce the flags using the logical or.\n"
},
{
"QuestionId": "76381701",
"QuestionTitle": "MS Word VBA to check for empty text form fields upon file close/exit",
"QuestionBody": "I need to have a MS Word Macro check upon file exit or file close, that certain specified text fields (legacy form fields, not content control) are empty.\nI have used some code that is a pretty intrusive warning box. But its also contingent on the user selecting that field then the macro pops up a warning box either upon entry or exit, as specified in the form field properties menu. I have several fields,\"Text1\", \"text2\", then text7 thru 11. Trouble is, the user MUST select a field to get this code to work, on top of that, the warning box basically sends them into a death loop before they can even close the file. I also have to make a new module for each of field with the code below. Perhaps the best solution here is a macro that runs on close and/or exit of the file, which says \"Hey you forgot to fill out these fields, they are 'mandatory' so go back and do that please, thanks!\" What do you all think?\nSub MustFillIn3()\n    If ActiveDocument.FormFields(\"Text2\").Result = \"\" Then\n        Do\n            sInFld = InputBox(\"Request date required, please fill in below.\")\n        Loop While sInFld = \"\"\n        ActiveDocument.FormFields(\"Text2\").Result = sInFld\n    End If\nEnd Sub\n\n\n",
"AnswerId": "76382431",
"AnswerBody": "Yes, just write the check code in the event handler procedure Document_Close in ThisDocument object, like this\nSub Document_Close()\n    Dim ff As FormField, sInFld As String, msgShown As Boolean, d As Document, i As Byte\n    'Dim ffNameDict As New Scripting.Dictionary, ffNameSpecCln As New VBA.Collection\n    Dim ffNameDict As Object, ffNameSpecCln As New VBA.Collection\n    \n    \n    Dim arr(7) As String, j As Byte\n    arr(0) = \"location\": arr(1) = \"request_date\": arr(2) = \"site\"\n    arr(3) = \"UPC\": arr(4) = \"Current_LOA\": arr(5) = \"Req_LOA\"\n    arr(6) = \"You Lost this One!!\"\n    \n    For i = 1 To 11\n        Select Case i\n            Case 1, 2, 7, 8, 9, 10, 11 '\"Text1\", \"text2\", then text7 thru 11.\n        \n                'to a specific name list?\n                'ffNameSpecCln.Add \"Specific Name HERE \" & i, \"Text\" & i\n                ffNameSpecCln.Add arr(j), \"Text\" & i\n                j = j + 1\n        End Select\n    Next i\n     \n    Set ffNameDict = CreateObject(\"Scripting.Dictionary\")\n    Set d = ActiveDocument\n    For i = 1 To 11\n        Select Case i\n            Case 1, 2, 7, 8, 9, 10, 11 '\"Text1\", \"text2\", then text7 thru 11.\n            'ffNameDict(\"Text\" & i) = \"Text\" & i\n            ffNameDict(\"Text\" & i) = ffNameSpecCln.Item(\"Text\" & i)\n        End Select\n    Next i\n    For Each ff In d.FormFields\n        If ff.Result = \"\" And ffNameDict.Exists(ff.Name) Then\n            If Not msgShown Then\n                MsgBox \"Hey you forgot to fill out these fields, they are 'mandatory' so go back and do that please, thanks!\", vbExclamation\n                msgShown = True\n            End If\n            Do\n'                sInFld = InputBox(\"Request date required, please fill in below.\" + vbCr + vbCr + _\n                                    \"@\" + ff.Name + \" is the current text fields to fill in !\")\n                sInFld = InputBox(\"Request date required, please fill in below.\" + vbCr + vbCr + _\n                                    \"@\" + ffNameDict(ff.Name) + \" is the current text fields to fill in !\")\n            Loop While sInFld = \"\"\n            ff.Result = sInFld\n        End If\n    Next ff\n    d.Save\nEnd Sub\n\n\nnote: The Private modifier in this image should be removed in order to be called in the appWord_DocumentBeforeSave event handler (code above already set)\n\n\nThis check sub is triggered when the current document is closed and is not related to whether ff has focus or not (ie. the user Doesn't MUST  select a field ).\nOption Explicit\n\nPublic WithEvents appWord As Word.Application\n \nPrivate Sub appWord_DocumentBeforeSave(ByVal Doc As Document, SaveAsUI As Boolean, Cancel As Boolean)\n    ThisDocument.Document_Close\nEnd Sub\n\n\n\nYou have to run this sub to Register Event_Handler to Word Application.\nOption Explicit\n\n'https://learn.microsoft.com/en-us/office/vba/word/concepts/objects-properties-methods/using-events-with-the-application-object-word\nPublic X As New app \nPublic Sub Register_Event_Handler() \n    Set X.appWord = Word.Application \nEnd Sub\n\n\n\"物件類別模組\" = class modules\n\n\n\"模組\" = modules\n\n\n\"表單\" = user form\n\n\n\"Microsof Word 物件\" = Microsof Word object\n\n\nAs for the details, you should adjust them yourself. Try to understand the code I have given you to simulate it. Come back to StackOverflow and ask a new question when you encounter difficulties and problems in the implementation.\nI've used the text field to test:\n\nIs this yours?\nBefore closing the document check if it has been modified\nOption Explicit\n\nPublic WithEvents appWord As Word.Application\n \nPrivate Sub appWord_DocumentBeforeClose(ByVal Doc As Document, Cancel As Boolean)\n    If Not Doc.Saved Then\n        If MsgBox(\"Do you want to save?\", vbOKCancel + vbQuestion) = vbOK Then\n            Doc.Save\n        Else\n            Doc.Close wdDoNotSaveChanges\n        End If\n    End If\nEnd Sub\n\nPrivate Sub appWord_DocumentBeforeSave(ByVal Doc As Document, SaveAsUI As Boolean, Cancel As Boolean)\n    MS_Word_VBA_to_check_for_empty_text_form_fields_upon_file_close_exit\nEnd Sub\n\n\n\nComment out the event handler Document_Close code and Registering an event handler when a document is opened:\n\nOption Explicit\n\nrem now can be Private, because there is no other place to call this procedure\nPrivate Sub Document_Close()\n    'MS_Word_VBA_to_check_for_empty_text_form_fields_upon_file_close_exit\nEnd Sub\n\n\nPrivate Sub Document_Open()\n    Register_Event_Handler ' See previous code\nEnd Sub\n\n\n\nExtract the code to become a separate checker procedure or method:\n\nSub MS_Word_VBA_to_check_for_empty_text_form_fields_upon_file_close_exit()\n    Dim ff As FormField, sInFld As String, msgShown As Boolean, d As Document, i As Byte\n    'Dim ffNameDict As New Scripting.Dictionary, ffNameSpecCln As New VBA.Collection\n    Dim ffNameDict As Object, ffNameSpecCln As New VBA.Collection\n    \n    \n    Dim arr(7) As String, j As Byte\n    arr(0) = \"location\": arr(1) = \"request_date\": arr(2) = \"site\"\n    arr(3) = \"UPC\": arr(4) = \"Current_LOA\": arr(5) = \"Req_LOA\"\n    arr(6) = \"You Lost this One!!\"\n    \n    For i = 1 To 11\n        Select Case i\n            Case 1, 2, 7, 8, 9, 10, 11 '\"Text1\", \"text2\", then text7 thru 11.\n        \n                'to a specific name list?\n                'ffNameSpecCln.Add \"Specific Name HERE \" & i, \"Text\" & i\n                ffNameSpecCln.Add arr(j), \"Text\" & i\n                j = j + 1\n        End Select\n    Next i\n     \n    Set ffNameDict = CreateObject(\"Scripting.Dictionary\")\n    Set d = ActiveDocument\n    For i = 1 To 11\n        Select Case i\n            Case 1, 2, 7, 8, 9, 10, 11 '\"Text1\", \"text2\", then text7 thru 11.\n            'ffNameDict(\"Text\" & i) = \"Text\" & i\n            ffNameDict(\"Text\" & i) = ffNameSpecCln.Item(\"Text\" & i)\n        End Select\n    Next i\n    For Each ff In d.FormFields\n        If ff.Result = \"\" And ffNameDict.Exists(ff.Name) Then\n            If Not msgShown Then\n                MsgBox \"Hey you forgot to fill out these fields, they are 'mandatory' so go back and do that please, thanks!\", vbExclamation\n                msgShown = True\n            End If\n            Do\n'                sInFld = InputBox(\"Request date required, please fill in below.\" + vbCr + vbCr + _\n                                    \"@\" + ff.Name + \" is the current text fields to fill in !\")\n                sInFld = InputBox(\"Request date required, please fill in below.\" + vbCr + vbCr + _\n                                    \"@\" + ffNameDict(ff.Name) + \" is the current text fields to fill in !\")\n            Loop While sInFld = \"\"\n            ff.Result = sInFld\n        End If\n    Next ff\n    d.Save\nEnd Sub\n\n\n"
},
{
"QuestionId": "76383035",
"QuestionTitle": "Type inference on function parameters with nested generics?",
"QuestionBody": "I am facing an issue with Typescript generics.\nI have a function which must be called with a type and some attributes depending on this type.\nTypescript does not manage to infer the type of attributes when inside an if guarding the type to TYPES.ME:\nenum TYPES {\n    ME = 'me',\n    YOU = 'you'\n}\n\ntype Attributes<T extends TYPES> =  T extends TYPES.ME ? {keys: true} : {hat: true}\nconst func = <T extends TYPES>(type: T, attr: Attributes<T>) => {\n    if(type === TYPES.ME) {\n        attr.keys // error Property 'keys' does not exist on type '{ keys: true; } | { hat: true; }'\n    }\n} \n\nPlayground link\nI would like to have your opinions on this matter and see if there is a nice workaround.\nCheers!\n",
"AnswerId": "76383754",
"AnswerBody": "Currently, TypeScript is unable to re-constrain generic type parameters as a result of control flow analysis.  Inside the body of func(type, attr), you check that type === Types.ME.  This can narrow the type of type from T to something like T & Types.ME.  But it cannot do anything to T itself.  The type parameter T stubbornly stays the same; it is not constrained to Types.ME. And thus the compiler cannot conclude that attr is of type Attributes<Types.ME>.\nAnd it is technically correct for the compiler to refuse to change T.  That's because, while individual values like type can only be one thing at a time, a type argument like T can be a union.  Indeed, you can call func() with a T equal to the full Types.ME | Types.YOU union, like so:\nfunc(\n    Math.random() < 0.999 ? Types.ME : Types.YOU,\n    { hat: true }\n) // compiles without error\n\nIf you inspect that, you'll see that T is inferred as Types (the full union of Types.ME | Types.YOU, and therefore attr is allowed to be {hat: true} even in the 99.9% likely event that type is Types.ME.\nThere is a longstanding open feature request at microsoft/TypeScript#27808 which asks for a way to say \"T will be exactly one of Types.ME or Types.YOU; it cannot be a union\".  And then, maybe inside the function body, checking type === Types.ME would allow T itself to be constrained to Types.ME, and things would work as expected.  And presumably the call with Math.random() < 0.999 would be rejected.\nBut for now it's not part of the language.\n\nYou might consider taking the approach where instead of having func be generic, you make it similar to an overloaded function, where it has one call signature per member of Types. You can write that as a function with a rest parameter whose type is a discriminated union of tuple types, and the compiler will treat it as such inside the function body.\nPerhaps like this:\ntype FuncArg =\n    [type: Types.ME, attr: { keys: true }] |\n    [type: Types.YOU, attr: { hat: true }];\n\nconst func: (...args: FuncArg) => void = (type, attr) => {\n    if (type === Types.ME) {\n        console.log(attr.keys) // this works\n    }\n}\n\nAnd now you can't make the invalid call:\nfunc(\n    Math.random() < 0.999 ? Types.ME : Types.YOU,\n    { hat: true }\n) // error, type 'Types.ME' is not assignable to type 'Types.YOU'\n\nEverything works because now type and attr are bound together as desired in FuncArg; it's like imagining T were constrained to be just one member of Types at a time, and walking through the possibilities.  Note that FuncArg could, if necessary, be computed from the Attributes type given in the question, or from another mapping interface, but that is out of scope for the question as asked.\nPlayground link to code\n"
},
{
"QuestionId": "76383892",
"QuestionTitle": "SQL query for last rented car with sunroof feature in car rental system",
"QuestionBody": "I'm developing a car rental automation system in SQL, and I'm seeing unwanted data in my table that I've received and constantly updated. The query I need to write is as follows: 'Write a query that retrieves information about the last rented car for customers who have rented cars with the feature of a sunroof at least once.' I've been struggling with it for hours and couldn't solve it. Can you help me?\nselect * from car a\nwhere exists(\n    select * from car a2\n    inner join customer m on m.customer_id=a2.customer_id\n    inner join rent k on k.customer_id=m.customer_id\n    inner join car_rent ak on ak.rent_id=k.rent_id\n    inner join package_package_option pk on pk.package_id=a2.package_id\n    where pk.option_id=2 and a.rent_sell=1\n    group by ak.date\n    having ak.date = max(ak.date)\n\n",
"AnswerId": "76385502",
"AnswerBody": "The solution has two steps:\n\nIdentify all customers who have ever rented a car with a sunroof, and\nFor each such customer, look up the latest rental for each such customer.\n\nThe first step is pretty straight forward - Filter the rentals for sunroof and select distinct customer IDs.\nThe second step can be done a couple of ways. One is to feed the customer IDs into a CROSS APPLY (SELECT TOP 1 ... ORDER BY RentalDate DESC) construct to select the latest rental for each selected customer one at a time. Another is to lookup all rentals for the selected customers, assign sequence numbers using the ROW_NUMBER() window function OVER(... ORDER BY RentalDate DESC), and then filtering for row-number = 1.\nSomething like (pseudocode):\nSELECT *\nFROM (\n    SELECT DISTINCT customer_id\n    FROM rentals\n    WHERE has-a-sunroof\n    AND is-a-rental\n) C\nCROSS APPLY (\n    SELECT TOP 1 rental-info\n    FROM rentals R\n    WHERE R.customer_id = C.customer_id\n    AND is-a-rental\n    ORDER BY R.Rentaldate DESC\n) R\n\nor\nSELECT *\nFROM (\n    SELECT rental-info,\n        ROW_NUMBER() OVER(PARTITION BY R.customer_id ORDER BY R.Rentaldate DESC) RowNum\n    FROM rentals R\n    WHERE R.customer_id IN (\n        SELECT DISTINCT customer_id\n        FROM rentals\n        WHERE has-a-sunroof\n        AND is-a-rental\n    )\n    AND is-a-rental\n) A\nWHERE A.RowNum = 1\n\nYou might try both to compare performance with large data sets.  I recommend also ensuring that you have an index on the rental that includes both customer_id and rental date for best performance.\n"
},
{
"QuestionId": "76382019",
"QuestionTitle": "Read value from SPI on Raspberry Pi Pico using Rust",
"QuestionBody": "I am trying to read a value from a sensor, BMP280 over SPI on a Raspberry Pi Pico. But I am getting an unexpected value.\nI created a new repo based on the rp2040-project-template and modified it to add SPI functionality.\nI added these imports:\nuse embedded_hal::prelude::_embedded_hal_spi_FullDuplex;\nuse rp_pico::hal::spi;\nuse rp_pico::hal::gpio;\nuse fugit::RateExtU32;\n\nThen I setup SPI in the bottom of main function:\nlet _spi_sclk = pins.gpio2.into_mode::<gpio::FunctionSpi>();\nlet _spi_mosi = pins.gpio3.into_mode::<gpio::FunctionSpi>();\nlet _spi_miso = pins.gpio4.into_mode::<gpio::FunctionSpi>();\nlet mut spi_cs = pins.gpio5.into_push_pull_output_in_state(PinState::Low); // initial pull down, for SPI\n\nlet spi = spi::Spi::<_, _, 8>::new(pac.SPI0);\n\nlet mut spi = spi.init(\n    &mut pac.RESETS,\n    clocks.peripheral_clock.freq(),\n    10.MHz(),                           // bmp280 has 10MHz as maximum\n    &embedded_hal::spi::MODE_0,\n);\n\nspi_cs.set_high().unwrap();   // pull up, set as inactive after init\ndelay.delay_ms(200);                     // some delay for testing\n\nThen I try to read the ID registry\nspi_cs.set_low().unwrap();\nlet res_w = spi.send(0xd0 as u8); // 0xd0 is address for ID, with msb 1\nlet res_r = spi.read();\nspi_cs.set_high().unwrap();\n\n// check results\nmatch res_w {\n    Ok(_) => info!(\"write worked\"),\n    Err(_) => info!(\"failed to write\")\n}\n\nmatch res_r {\n    Ok(v) => info!(\"read value from SPI: {}\", v),\n    Err(_) => info!(\"failed to read SPI\")\n}\n\nWith this code, the SPI read fails. Why is that?\nPerhaps it is necessary to set a mode on the sensor, before reading the ID. I can add this code above the read, to set forced mode.\nspi_cs.set_low().unwrap();\nspi.send(0xf4-128 as u8).expect(\"failed to send first byte\");  // registry 0xf4 with msb 0\nspi.send(0x1 as u8).expect(\"failed to send second byte\");\nspi_cs.set_high().unwrap();\n\nNow the read of ID registry works, but I get value 255 and not the expected 0x58.\nWhat am I doing wrong?\n\nI have also tried with transfer using this code:\nlet mut data: [u8; 2] = [0xd0, 0x0];\nlet transfer_success = spi.transfer(&mut data);\nmatch transfer_success {\n    Ok(v) => info!(\"read data {}\", v),\n    Err(_) => info!(\"failed to read\")\n}\n\nBut I read the values as [255, 255] with this code, not the expected 0x58.\n",
"AnswerId": "76382608",
"AnswerBody": "read() is probably not the function you want to use here; it doesn't acutally perform any bus action but only gives you the byte that was read during the last send().\nThe function you actually want to use is transfer(). On a full-duplex SPI bus, a \"read\" action is always also a \"write\" action, and transfer performs both. Be aware that if you only want to read, you need to write the same amount of zeros, because only the bus master can provide the clock to do anything.\nSo if you want to write 0xd0, followed by reading a single byte, you need to transfer() the values [0xd0, 0x00]. The same array that you use to put your sent data into transfer() will then contain the received data; most likely [0x00, <data>] (or [0xff, <data>], not sure. Probably 0xff, as you already mentioned that you read a 255).\nThe implementation of transfer shows how read() is actually supposed to be used:\nfn transfer<'w>(&mut self, words: &'w mut [W]) -> Result<&'w [W], S::Error> {\n    for word in words.iter_mut() {\n        block!(self.send(word.clone()))?;\n        *word = block!(self.read())?;\n    }\n\n    Ok(words)\n}\n\nNote the block!() here - in embedded, asynchronous calls usually return an error indicating that the operation would block, until it is finished. The block!() macro converts an asynchronous call to a blocking call, which is most likely where your error comes from.\nEither way, I would recommend deriving your code from the official example, those are usually pretty good at demonstrating the intended way an object should be used.\n"
},
{
"QuestionId": "76383668",
"QuestionTitle": "Font Color does not update",
"QuestionBody": "I have a simple HTML snippet like this:\n\n\n    <p align= \"left\"> <FONT size=3><STRONG> Asset: &nbsp;    </STRONG></FONT><STRONG><FONT color=\"blue\" size=2> something something here  </FONT></STRONG><br> </p>\n\n\n\nThe font color does not seem to work but the font size does change.\nAlso, I do understand that explicit font description is expiring and we should be using the CSS styling. If you could suggest that option,okay to use that option as well.\n",
"AnswerId": "76383803",
"AnswerBody": "Using HTML elements and classes is the better option although I do admit some might seem overly complicated.\nFor my answer, first I give the paragraph a class. Inside of it, I'm aligning the text left and bolding EVERYTHING in it.\nNext, spans are by default inline (meaning they show inline with the text, but you don't have control over the spacing). You could also use a div. So every span in the paragraph tag, I'm setting to inline block so I can control the spacing around it while keeping the text inline.\nNext each part of the content gets wrapped in its own span.\nSince earlier I already set all content to bold, I'm only going to give the title span a margin to the right to space it out and change the font size.\nNext for the rest I wrapped that content in another span and changed the color to blue (hex is #Red Green Blue) and I changed the font size also.\n\n\n.updated{\n  text-align:left;\n  font-weight:bold;\n}\n\n.updated span{\n  display:inline-block;\n}\n\n.updated .title{\n  margin-right:5px;\n  font-size:18px;\n}\n\n.updated .content{\n  color:#0000FF;  \n  font-size:13px;\n}\nOriginial: <p align= \"left\"> <FONT size=3><STRONG> Asset: &nbsp;    </STRONG></FONT><STRONG><FONT color=\"blue\" size=2> something something here  </FONT></STRONG><br> </p>\n\nUpdated:\n<p class=\"updated\">\n  <span class=\"title\">Asset:</span>\n  <span class=\"content\">something something here</span>\n</p>\n\n\n\n"
},
{
"QuestionId": "76384530",
"QuestionTitle": "TypeError: Cannot read properties of undefined (reading 'params') Django + React",
"QuestionBody": "Uncaught TypeError: Cannot read properties of undefined (reading 'params')\nUnabel to navigate to id can anyone help?\ni am woriking on django as backend and react as frontend\nclass ArticleDetail extends  React.Component{\n\n    state={\n        article:{}\n    }\n    componentDidMount(){\n        const id = this.props.match.params.id;\n      \n      axios.get(`http://127.0.0.1:8000/api/${id}`)\n      .then(res =>{\n        this.setState({\n            article:res.data\n        });\n        console.log(res.data)\n       \n      })\n\n    }\n    render(){\n        return(\n           \n            <Card title={this.state.article.title} >\n                <p>{this.state.article.content }</p>\n            </Card>\n        )\n    }\n}```\n\n\nTypeError: Cannot read properties of undefined (reading 'params') Unabel to navigate to id can anyone help?\ni am working on react + django. My data from server in list is showing but when i try to navigate to particular data id it shows error\n\n",
"AnswerId": "76385508",
"AnswerBody": "This should be a frontend problem.\n1-) Add the following line of code at the beginning of your class:\nimport { useParams } from 'react-router-dom';\n\n2-) Then add this function above your class (copy it exactly):\n export function withRouter(Children){\n return(props)=>{\n\n    const match  = {params: useParams()};\n    return <Children {...props}  match = {match}/>\n  }\n }\n\n3-) Next, change your class definition to this:\nclass ArticleDetail extends Component\n\n4-) Add the following line of code at the end of your class:\nexport default withRouter(ArticleDetail);\n\nRef: https://stackoverflow.com/a/75304487/11897778\nIf it doesn't work, please provide more details about the error, if the API request is being made or is it failing before making the API request?\n"
},
{
"QuestionId": "76381276",
"QuestionTitle": "Getting user ID instead of volunteer ID while joining tables in Laravel GraphQL search handler",
"QuestionBody": "When i join two tables in search handler there is a same column in both tables, i cannot access the value of left table\nfor example if there are two tables user and volunteers they both have id column when I write a search handler like this\n$builder->join('users', 'volunteers.user_id', \"=\", \"users.id\")\n  ->join('policies','volunteers.policy_id',\"=\",\"policies.id\")\n  ->where(function($q) use ($whereConditions){\n      $q->where('users.first_name','like','%'.$whereConditions['OR'][0]['value'].'%');\n      $q->orWhere('users.last_name','like','%'.$whereConditions['OR'][0]['value'].'%');\n      $q->orWhere('policies.name','like','%'.$whereConditions['OR'][0]['value'].'%');\n      $q->orWhere('volunteers.experiences','like','%'.$whereConditions['OR'][0]['value'].'%');\n      $q->orWhere('volunteers.medical_facility','like','%'.$whereConditions['OR'][0]['value'].'%');\n   });\n\nand when i query, it will return user id as volunteer id\nI want the volunteer id but I always get the user id. I hope the question is clear\n",
"AnswerId": "76382625",
"AnswerBody": "I implemented your problem and the problem happened to me but I solved it by using $builder->select('your columns').\n\n\n"
},
{
"QuestionId": "76383738",
"QuestionTitle": "How can I simplify my jQuery code to avoid repeating instructions?",
"QuestionBody": "Novice trying to simplify my jQuery, to avoid repetition\nI am a novice with Javascript and jQuery, but have written some code to display a tooltip on a form depending on the answer selected to a dropdown. Right now I am repeating the steps twice:\n\nOnce to check the dropdown on page load, in case it has reloaded due to a submission error - in this case, if an answer has been selected to that question, it will persist, and I need the tooltip to remain.\n\nOnce to check whenever the dropdown value changes.\n\n\nThe value of the dropdown is a number, so I've used that in the div classes to show the appropriate div. This is the code which is working fine:\n$(document).ready(function(){\n    var service = \"\";\n    var otherservice = \"\";\n\n    // Check for select value on page load, in case it has refreshed due to a form error\n\n    service = '.v' + $('select#989022_58716pi_989022_58716 option:selected').val();\n    otherservice = '#form-tooltips div:not('+service+')';\n    $('#form-tooltips div'+service).show();\n    $(otherservice).hide();\n\n    // Check again for select value, every time that selection changes\n\n    $('select#989022_58716pi_989022_58716').on('change', function(){\n        service = '.v' + $('select#989022_58716pi_989022_58716 option:selected').val();\n        otherservice = '#form-tooltips div:not('+service+')';\n        $('#form-tooltips div'+service).show();\n        $(otherservice).hide();\n    });\n});\n\n//The tooltips for display\n\n$(\"<div id='form-tooltips'><div class='v1381962'>Tooltip 1</div><div class='v1381965'>Tooltip 2</div></div>\").insertAfter(\".add-tooltip-after\");\n\nWhat I would like to do is create a function - checkTooltip - so that I do not have to repeat those tooltip instructions the second time. I have tried the following:\n$(document).ready(function(){\n    var service = '';\n    var otherservice = '';\n    function checkTooltip({\n        service = '.v' + $('select#989022_58716pi_989022_58716 option:selected').val();\n        otherservice = '#form-tooltips div:not(\"+service+\")';\n        $('#form-tooltips div'+service).show();\n        $(otherservice).hide();\n    });\n    checkTooltip();\n    $('select#989022_58716pi_989022_58716').on('change', checkTooltip());\n});\n$(\"<div id='form-tooltips'><div class='v1381962'>Tooltip 1</div><div class='v1381965'>Tooltip 2</div></div>\").insertAfter(\".add-tooltip-after\");\n\nHowever this is not working. In the Chrome console, it says Uncaught SyntaxError: Unexpected token ';' on the 5th line. I have tried removing that semicolon but then it gives me Unexpected identifier 'otherservice' instead.\nAm I completely misunderstanding how this works or making some kind of syntax error? Many thanks in advance to anyone who can help!\n",
"AnswerId": "76383823",
"AnswerBody": "The syntax is definitely wrong, but in the function definition. It should look like this. No guarantees on whether the functionality is correct.:\n$(document).ready(function(){\n    let service = '';\n    let otherservice = '';\n    const checkTooltip = () => {\n        service = '.v' + $('select#989022_58716pi_989022_58716 option:selected').val();\n        otherservice = '#form-tooltips div:not(\"+service+\")';\n        $('#form-tooltips div'+service).show();\n        $(otherservice).hide();\n    }\n    checkTooltip();\n    $('select#989022_58716pi_989022_58716').on('change', checkTooltip);\n});\n\nNote the change in the on.change handler at the end too.\nAlso its out of scope for your question but 989022_58716pi_989022_58716 probably could be rewritten with a more human-readable id or class.\n"
},
{
"QuestionId": "76383689",
"QuestionTitle": "Azure Devops git repository permissions: how to prioritize 'Allow' over 'Deny'?",
"QuestionBody": "I have a git repository created in Azure Devops. I need to restrict access to it in such a way that the repo is accessible only for TeamA. When I set Deny for all other groups and Allow only for TeamA, the permission Deny takes preference when the user belongs to both Contributors and TeamA. Would you please help me to achieve this? I cannot grant access to all contributors except for those in TeamA.\nI tried security settings in repository.\n",
"AnswerId": "76383855",
"AnswerBody": "Use the Not Set permission as an implicit Deny. As you've discovered, explicit Deny takes precedence over explicit Allow.\n"
},
{
"QuestionId": "76382065",
"QuestionTitle": "getting rid of bold characters in a filename",
"QuestionBody": "mysql recently reported me the following error: [HY000][1366] Incorrect string value: '\\xF0\\x9D\\x98\\xBD\\xF0\\x9D...' for column 'name'\nafter investigation, I found that the value with weird characters comes from a filename, which apparently contains bold characters: 4 𝘽𝘼𝙉𝘿𝙀 𝘼𝙉𝙉𝙊𝙉𝘾𝙀 - TV.mp4\nInstead of changing the encoding of my database to accept such characters, i'd rather sanitize the value before inserting it, in PHP. But I have no idea which operation I should run to end with the following sanitized value : 4 BANDE ANNONCE - TV.mp4\nAny help would be appreciated.\n",
"AnswerId": "76382676",
"AnswerBody": "You can use the PHP iconv function to convert the string from one character encoding to another. In this case, you can try converting the string from UTF-8 to ASCII//TRANSLIT, which will attempt to transliterate any non-ASCII characters into their closest ASCII equivalents.\nHere's an example:\nfunction sanitize_string($input_string) {\n    $sanitized_string = iconv(\"UTF-8\", \"ASCII//TRANSLIT\", $input_string);\n    return $sanitized_string;\n}\n\n$filename = \"4 𝘽𝘼𝙉𝘿𝙀 𝘼𝙉𝙉𝙊𝙉𝘾𝙀 - TV.mp4\";\n$sanitized_filename = sanitize_string($filename);\necho $sanitized_filename;\n\nThis should output 4 BANDE ANNONCE - TV.mp4, which is the sanitized value you're looking for.\n"
},
{
"QuestionId": "76385320",
"QuestionTitle": "How to get variable from component for put on the App.js",
"QuestionBody": "even by searching on the internet I did not find, or in all that I did not understand.\nMy problem: I would like the \"inputVal\" variable found in the \"InputField.js\" component to be found where there is \"!!HERE!!\" in the \"App.js\" component(on the fetch)\nplease help me\nthank you for reading my message!\nexport default function InputField() {\n  \n  function handleSubmit(e) {\n    // Prevent the browser from reloading the page\n    e.preventDefault();\n\n    // Read the form data\n    const form = e.target;\n    const inputVal = form.myInput.value;\n\n    console.log(inputVal);\n  }\n\n  return (\n    <form method=\"post\" onSubmit={handleSubmit}>\n      <input name=\"myInput\" id=\"adress-field\" placeholder=\"Enter adress\" autoComplete=\"on\" />\n      <button type=\"submit\" id=\"adress-button\">Send</button>\n    </form>\n  );\n}\n\nimport './App.css';\nimport AccountNumber from \"./components/AccountNumber\";\nimport InputField from \"./components/InputField\";\nimport { useEffect, useState } from \"react\"\n\nfunction App() {\n\n  //token fetch\n  const [tockens, setTockens] = useState([])\n  const [loading, setLoading] = useState(false)\n  useEffect(() => {\n    setLoading(true)\n    fetch(\"https://api.multiversx.com/accounts/!!HERE!!/tokens\")\n      .then(response => response.json())\n      .then(json => setTockens(json))\n      .finally(() => {\n        setLoading(false)\n      })\n      console.log(tockens); \n  }, [])\n\n\n  function round(nr, ten) { // arondi un chiffre.\n    return Math.round(nr * ten) / ten;\n}\n\nfunction numberWithSpaces(nr) { // formate un chiffre(x xxx xxx).\n    return nr.toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, \" \");\n}\n\n\n\n  return (\n    <content className=\"content\">\n        <div className=\"up-side\">\n            <div className=\"account-number-box\">\n                <p id=\"p-account-number\">Total number of accounts</p>\n                <p id=\"account-number\"><AccountNumber/></p>\n            </div>\n            <div className=\"adress-search\">\n                {InputField()}\n            </div>\n            <p>{window.inputVal}</p>\n        </div>\n        <div className=\"down-side\">\n            <table className=\"Token-section-output\">\n            \n\n              {loading ? (\n                <div>Loading...</div>\n              ) : (\n                <>\n                  <h1>Tockens</h1>\n                  <table className='Token-section-output' border={0}>\n                    <tr className='token-row-type'>\n                      <th className='token-column'>Name</th>\n                      <th className='center-column'>Price</th>\n                      <th>Hold</th>\n                    </tr>\n                    <tr className=\"space20\"/>\n\n                    \n                    {tockens.map(tocken => (\n                      <tr className='token-row' key={tocken.id}>\n                        <td className='token-column'>\n                        <img className=\"img-Tockens\" src = {tocken?.assets?.pngUrl ?? \"img/Question.png\"} /> \n                          <p>{tocken.name}</p> \n                        </td>\n\n                        <td className='center-column'> <p>${round(tocken.price, 10000000)}</p> </td>\n\n                        <td> \n                          <p>{round(tocken.balance / Math.pow(10, tocken.decimals), 10000000)}</p> \n                          <p className='token-hold'>${round(tocken.valueUsd, 10000000)}</p>\n                        </td>\n                      </tr>\n                    ))}\n\n                  </table>\n                </>\n              )}\n\n\n            </table>\n        </div>   \n    </content>\n  );\n}\n\nexport default App;\n\nI not very good in react and i mak search on internet\n",
"AnswerId": "76385519",
"AnswerBody": "You want to extend your InputField component to accept a callback function, that can be passed by your app:\nexport default function InputField({onSubmit}) {\n  \n  function handleSubmit(e) {\n    // Prevent the browser from reloading the page\n    e.preventDefault();\n\n    // Read the form data\n    const form = e.target;\n    const inputVal = form.myInput.value;\n\n    console.log(inputVal);\n    onSubmit(inputVal)\n  }\n\n  ...\n}\n\nAnd in your App you need to pass that callback to your component:\n<div className=\"adress-search\">\n  <InputField onSubmit={handleSearchSubmit} />\n</div>\n\nNote: Components are not consumed by calling them like functions.\nIn your App logic, you'll need another state to hold your search value:\n...\nconst [searchValue, setSearchValue] = useState(null);\n\nconst handleSearchSubmit = (val) => {\n  setSearchValue(val);\n}\n\nuseEffect(() => {\n    setLoading(true)\n    fetch(`https://api.multiversx.com/accounts/${searchValue}/tokens`)\n      .then(response => response.json())\n      .then(json => setTockens(json))\n      .finally(() => {\n        setLoading(false)\n      });\n    console.log(tockens); \n}, [searchValue])\n...\n\n"
},
{
"QuestionId": "76381829",
"QuestionTitle": "Default class instantiation results in TypeError (ESM/CJS interop)",
"QuestionBody": "Issue Summary\nHi,\nI have a TypeScript project where I am trying to instantiate a class which was the default export of a different package. I am writing my project in ESM syntax, whereas the package it's dependent upon has CJS output. The issue I am running into is that at runtime, when the flow reaches the point of class instantiation I am getting the following error -\nnew TestClass({ arg1: \"Hello, World!\" });\n^\n\nTypeError: TestClass is not a constructor\n\n\nCode\n//My package.json\n{\n  \"name\": \"myproject\",\n  \"version\": \"1.0.0\",\n  \"main\": \"dist/index.js\",\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"start\": \"node dist/index.js\"\n  },\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"testpackage\": \"^1.0.0\",\n    \"typescript\": \"^5.0.4\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.2.5\"\n  }\n}\n\n\n//My index.ts\nimport TestClass from \"testpackage\";\n\nnew TestClass({ arg1: \"Hello, World!\" });\n\n//My tsconfig.json\n{\n    \"include\": [\"src\"],\n    \"compilerOptions\": {\n        \"outDir\": \"dist\",\n        \"lib\": [\"es2023\"],\n        \"target\": \"es2022\",\n        \"moduleResolution\": \"node\"\n    }\n}\n\n\n//Dependency's package.json\n{\n    \"name\": \"testpackage\",\n    \"version\": \"1.0.0\",\n    \"description\": \"TestPackage\",\n    \"main\": \"./dist/testFile.js\",\n    \"exports\": \"./dist/testFile.js\",\n    \"scripts\": {\n        \"build\": \"tsc\"\n    },\n    \"files\": [\"dist\"],\n    \"devDependencies\": {\n        \"@types/node\": \"^20.2.5\",\n        \"typescript\": \"^5.0.4\"\n    }\n}\n\n//Dependency's testFile.ts\nexport default class TestClass {\n    constructor({ arg1 }: { arg1: string }) {\n        console.log(arg1);\n    }\n}\n\n//Dependency's tsconfig.json\n{\n    \"include\": [\"src\"],\n    \"compilerOptions\": {\n        \"declaration\": true,\n        \"lib\": [\"es2023\"],\n        \"target\": \"es6\",\n        \"module\": \"CommonJS\",\n        \"outDir\": \"dist\"\n    }\n}\n\n//Dependency's testFile.js output\n\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass TestClass {\n    constructor({ arg1 }) {\n        console.log(arg1);\n    }\n}\nexports.default = TestClass;\n\n\nThings work fine if I remove \"type\": \"module\" from my package.json. They also work fine if the class is a named export instead of a default export in the dependency's code. Is this a known incompatibility when trying to import CJS into ESM or am I doing something incorrectly here?\n\nNote - If I set \"moduleResolution\": \"nodenext\" in my tsconfig.json then the error is generated at compile time itself -\nsrc/index.ts:3:5 - error TS2351: This expression is not constructable.\n  Type 'typeof import(\"<project_dir>/node_modules/testpackage/dist/testFile\")' has no construct signatures.\n\n3 new TestClass({ arg1: \"Hello, World!\" });\n      ~~~~~~~~~\n\n\nFound 1 error in src/index.ts:3\n\n",
"AnswerId": "76382696",
"AnswerBody": "There are known compatibility issues between CommonJS (CJS) and ECMAScript modules (ESM). In ESM, default exports of CJS modules are wrapped in default properties instead of being exposed directly. On the other hand, named exports are unaffected and can be imported directly.\nIf you specify \"type\":\nSpecifying \"module\" in package.json makes Node.js treat the .js file as her ESM. Therefore, you must import the module using the ESM import statement. However, if the module you are trying to import is in CJS format, you will run into compatibility issues.\nThere are several options to fix this.\n\nAccess the class through the default property as described above.\n\nimport Test from 'package-name';\nconst TestClass = Test.default;\n\n\n\nTo avoid problems caused by mixing the two module formats, convert all code to use either ESM or CJS.\n\nLoad the CJS module using the Node.js createRequire function.\n\n\nimport { createRequire } from 'module';\nconst require = createRequire(import.meta.url);\nconst TestClass = require('package-name');\n\n\n"
},
{
"QuestionId": "76381891",
"QuestionTitle": "Extract href from string and again bind the updated data to the element in Angular",
"QuestionBody": "I am getting one string like this in innerHtml\n<div class=\"wrapper\" [innerHTML]=\"data.testString\">\n\ndata.testString contains data like below,\ndata.testString=\"<p>some info, email <a href=\"mailto:test@test.com\">test@test.com</a>  info </p>\";\n\nI want to add aria-label for the anchor tag.\n<a aria-label=\"test@test.com\" href=\"mailto:test@test.com\">test@test.com</a>\n\nso I have added below code in .ts file\nngAfterViewInit(): void {\n\n    var myData = this.data.testString;\n    var element = myData!.match!(/href=\"([^\"]*)/)![1];\n    \n   \n    var ariaLabel = \"EmailId \" + element;\n    \n    this.data.testString=\n    this.data.testString!.replace('<a', '<a aria-label = \"' + ariaLabel + '\" ');\n      \n  }\n}\n\n\nBut I am getting below error\nglobal-error-handler.ts:26 TypeError: Cannot assign to read only property 'testString' of object '[object Object]'\n\nHow to resolve this?\n",
"AnswerId": "76382769",
"AnswerBody": "I'm not sure to understand all but below might help you :\n\nString character escaping\n\n\nvar testString=\"<p>some info, email <a href=\"mailto:test@test.com\">test@test.com</a>  info </p>\";\n\nThere is a quote issue : a double-quoted string cannot contain double-quotes unless escaped by the \\ character (cf. https://www.w3schools.com/js/js_strings.asp -> Escape Character section)\nYou may fix this issue by replacing some double quotes by simple quotes :\n\"<p>some info, email <a href='mailto:test@test.com'>test@test.com</a>  info </p>\"\n\nRegular expression\n\n\nvar href = datar!.match!(/href=\"([^\"]*)/)![1];\n\nNot sure this is the pattern you need. Try instead :\nvar href = datar!.match!(/href=\\'mailto:([a-z@.]+)'/)![1];\n\nDOM element manipulation\n\nAbout adding the aria-label attribute to the , you would better go with Angular nativeElement.setAttribute(key, value) native javascript querySelector\n(cf. https://indepth.dev/posts/1336/how-to-do-dom-manipulation-properly-in-angular and https://angular.io/guide/property-binding)\nFinally I would highly recommend the use of RegExr to test your regular expressions https://regexr.com/7ep0u\nas well as jsfiddle.net to test your javascript in a safe environment : https://jsfiddle.net/nkarfgx3/\n"
},
{
"QuestionId": "76383765",
"QuestionTitle": "One instance of Stripe Checkout works, the other gives a Preflight response code of 403",
"QuestionBody": "I am implementing another instance of the Checkout Session in my app.  In my donations controller, the following create action works fine:\ndef create\n        @donation = Donation.create(create_params)\n\n        if @donation.save\n            if Rails.env.development?\n                success_url = \"http://localhost:3000/donations_success?session_id={CHECKOUT_SESSION_ID}\"\n                cancel_url = \"http://localhost:3000/\"\n            elsif Rails.env.production?\n                success_url = \"https://www.dbsan.org/donations_success?session_id={CHECKOUT_SESSION_ID}\"\n                cancel_url = \"https://www.dbsan.org/\"\n            end\n\n            data = {\n                line_items: [{\n                    price_data: {\n                        currency: 'usd',\n                        product_data: {\n                        name: @donation.program\n                    },\n                    unit_amount: @donation.amount.to_i\n                    },\n                    quantity: 1,\n                }], \n                mode: 'payment',\n                customer_email: @donation.email,\n                success_url: success_url,\n                cancel_url: cancel_url\n            }\n\n            session = Stripe::Checkout::Session.create(data)\n            redirect_to session.url, allow_other_host: true\n        end\n    end\n\nI copied the relevant Stripe part into my participant registration controller:\ndef create\n        @registrant = @challenge.challenge_participants.build(register_params)\n        @registrant.user_id = current_user.id\n        unless @registrant.donations.empty?\n            @registrant.donations.first.user_id = current_user.id\n            @registrant.donations.first.email = current_user.email\n        end\n\n        if @registrant.save\n            @challenge = @registrant.challenge\n            ChallengeMailer.with(registrant: @registrant).registered.deliver_now\n            if @registrant.price.price == 0\n                redirect_to challenge_participant_path(@challenge, @registrant)\n            else\n                if Rails.env.development?\n                    success_url = \"http://localhost:3000/donations_success?session_id={CHECKOUT_SESSION_ID}\"\n                    cancel_url = \"http://localhost:3000/\"\n                elsif Rails.env.production?\n                    success_url = \"https://www.dbsan.org/donations_success?session_id={CHECKOUT_SESSION_ID}\"\n                    cancel_url = \"https://www.dbsan.org/\"\n                end\n\n                data = {\n                    line_items: [{\n                        price_data: {\n                            currency: 'usd',\n                            product_data: {\n                            name: \"Registration\"\n                        },\n                        unit_amount: 100\n                        },\n                        quantity: 1,\n                    }], \n                    mode: 'payment',\n                    success_url: success_url,\n                    cancel_url: cancel_url\n                }\n\n                session = Stripe::Checkout::Session.create(data)\n                redirect_to session.url, allow_other_host: true\n            end\n        end\n\nThe Donations one will redirect to Stripe without issue; however, the registration one, if a pricing selected is greater than 0, it will then attempt to initiate a Stripe Checkout.  In my browser console I get a Preflight response was not successful error code 403 with some TypeError that it is not giving me details of.\non both of the views, the Stripe API Javascript is included just above the submit button:\n= javascript_include_tag \"https://js.stripe.com/v3\"\n\nSince I copied the code over from the donations controller, I'm not seeing what my error is.\nI haven't updated the success_url yet as I'm trying to first get redirected to Stripe.  The name and unit_amount are right now hard coded in case my variables aren't working.\n",
"AnswerId": "76383881",
"AnswerBody": "The code you shared is a simple HTTP redirect server-side in Ruby and shouldn't cause a CORS error in the browser unless your client-side code is making an ajax request instead of a page/form submit.\nAlternatively, it's possible your form submission is mis-configured and Rails turns this in a turbo request. Adding data-turbo=false to your form might solve that problem.\n"
},
{
"QuestionId": "76385399",
"QuestionTitle": "intersection across date ranges from multiple rows in oracle",
"QuestionBody": "Intersection of date ranges across rows in oracle.\nI have a table which contains following records\n\n\n\n\nItem_no\nitem_type\nactive_from\nactive_to\nrule_id\n\n\n\n\n10001\nSAR\n2020-01-01\n2023-01-01\nrule1\n\n\n10001\nSAR.\n2024-01-01\n9999-12-31\nrule1\n\n\n10001\nSAR\n2020-05-01\n2021-06-01\nrule2\n\n\n10001\nSAR\n2021-01-01\n2021-02-01\nrule2\n\n\n\n\nWe need to find common dates between rule ids\nOutput will be\n\n\n\n\nItem_no\nitem_type\nactive_from\nactive_to\n\n\n\n\n10001\nSAR\n2020-05-01\n2021-06-01\n\n\n\n\nI tried with connect by level to generate dates and then take intersection, but it is running for long time due to 9999-12-31\n",
"AnswerId": "76385527",
"AnswerBody": "From Oracle 12, you can UNPIVOT the dates and then use analytic functions and MATCH_RECOGNIZE to process the result set row-by-row to find the consecutive rows where both rules are active:\nSELECT *\nFROM   (\n  SELECT item_no,\n         item_type,\n         rule_id,\n         dt,\n         SUM(CASE rule_id WHEN 'rule1' THEN active END) OVER (\n           PARTITION BY item_no, item_type ORDER BY dt, ACTIVE DESC\n         ) AS rule1,\n         SUM(CASE rule_id WHEN 'rule2' THEN active END) OVER (\n           PARTITION BY item_no, item_type ORDER BY dt, ACTIVE DESC\n         ) AS rule2\n  FROM   table_name\n         UNPIVOT (\n           dt FOR active IN ( active_from AS 1, active_to AS -1 )\n         )\n)\nMATCH_RECOGNIZE(\n  PARTITION BY item_no, item_type\n  ORDER BY dt, rule1 DESC, rule2 DESC\n  MEASURES\n    FIRST(dt) AS active_from,\n    NEXT(dt) AS active_to\n  PATTERN ( active_rules+ )\n  DEFINE active_rules AS rule1 > 0 AND rule2 > 0\n)\n\nWhich, for the sample data:\nCREATE TABLE table_name (Item_no, item_type, active_from, active_to, rule_id) AS\nSELECT 10001, 'SAR', DATE '2020-01-01', DATE '2023-01-01', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2024-01-01', DATE '9999-12-31', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2020-05-01', DATE '2021-06-01', 'rule2' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2021-01-01', DATE '2021-02-01', 'rule2' FROM DUAL;\n\nOutputs:\n\n\n\n\nITEM_NO\nITEM_TYPE\nACTIVE_FROM\nACTIVE_TO\n\n\n\n\n10001\nSAR\n2020-05-01 00:00:00\n2021-06-01 00:00:00\n\n\n\n\nand for:\nCREATE TABLE table_name (Item_no, item_type, active_from, active_to, rule_id) AS\nSELECT 10001, 'SPR', DATE '2023-01-01', DATE '2023-01-31', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SPR', DATE '2023-01-31', DATE '2023-02-27', 'rule2' FROM DUAL;\n\nThe output is:\n\n\n\n\nITEM_NO\nITEM_TYPE\nACTIVE_FROM\nACTIVE_TO\n\n\n\n\n10001\nSPR\n2023-01-31 00:00:00\n2023-01-31 00:00:00\n\n\n\n\nfiddle\n"
},
{
"QuestionId": "76384723",
"QuestionTitle": "How to make an Array of images getting by input field and display the Array image as slider",
"QuestionBody": "My problem is to make array of image by input field and display array images as slider in JavaScript\nanyone can solve it please answer me\nPlease give code of JavaScript\n    document.querySelector(\"#a\").addEventListener(\"change\", function(){\n           const reader = new FileReader();\n              reader.addEventListener(\"load\", ()=>{\n                   localStorage.setItem(\"recent-image\", reader.result)\n              });\n           reader.readAsDataURL(this.files[0]);\n    });\n    document.addEventListener(\"DOMContentLoaded()\", ()=> {\n        \n        const imageurl = localStorage.getItem(\"recent-image\");\n\n        if(imageurl){\n            document.querySelector(\"#b\").setAttribute(\"src\", imageurl);\n        }\n    });\n\ncan you do this in array please answer me\nit take only one image image but, I want to store multiple image in local storage by array\nplease answer me\n",
"AnswerId": "76385530",
"AnswerBody": "The problem that I see is to define your localstorage and make sure that the images are stored in it to later go through each one of them, I leave an example of how to solve it\nvar images = localStorage.getItem('images') || [];\n\nfunction saveImages() {\n    localStorage.setItem('images', JSON.stringify(images));\n}\n\nfunction drawImages() {\n    var slider = document.getElementById('slider');\n    slider.innerHTML = '';\n    for (var i = 0; i < images.length; i++) {\n        const img = images[i];\n        const html_img = document.createElement('img');\n        html_img.src = img;\n        html_img.alt = 'Alt img';\n        html_img.width = 200;\n        html_img.height = 150;\n        slider.appendChild(html_img);\n    }\n}\n\ndocument.querySelector(\"#a\").addEventListener(\"change\", function(){\n    const reader = new FileReader();\n    reader.addEventListener(\"load\", ()=>{\n        images.push(reader.result);\n        drawImages();\n    });\n    reader.readAsDataURL(this.files[0]);\n});\n\ndocument.addEventListener(\"DOMContentLoaded()\", drawImages);\n\n"
},
{
"QuestionId": "76380801",
"QuestionTitle": "Problem passing an async function item as parameter in Rust",
"QuestionBody": "[Edit: Updated provided code and compiler error to be easely reproduced]\nI'm trying to pass an async function item as parameter to an other function in Rust but it won't compile, providing a cryptic error.\nHere is the code I'm trying to compile.\nStructure definition (implemented in one crate)\npub struct FirstTestComponent {\n    table: Vec<String>,\n    counter: usize,\n}\n\nimpl FirstTestComponent {\n    fn render(&mut self) {\n        // Some other irrelevant code\n        record_callback(\n            FirstTestComponent::add_component,\n        );\n    }\n}\n\npub struct Services {}\n\nimpl FirstTestComponent {\n\n    async fn add_component(&mut self, _: &mut Services) {\n\n        let counter = self.counter;\n        self.table.push(counter.to_string());\n        self.counter += 1;\n    }\n}   \n\n\npub fn record_callback<F, Fut>(callback: F)\n    where \n        F: 'static + Copy + FnOnce(&mut FirstTestComponent, &mut Services) -> Fut,\n        Fut: core::future::Future<Output = ()>  + 'static\n        {\n        }\n\nfn main() {\n\n}\n\nWhen compiling this code, I get the following error:\nerror[E0308]: mismatched types\n  --> src/main.rs:9:9\n   |\n9  | /         record_callback(\n10 | |             FirstTestComponent::add_component,\n11 | |         );\n   | |_________^ one type is more general than the other\n   |\n   = note: expected trait `for<'r, 's> <for<'r, 's> fn(&'r mut FirstTestComponent, &'s mut Services) -> impl for<'r, 's> std::future::Future<Output = ()> {FirstTestComponent::add_component} as std::ops::FnOnce<(&'r mut FirstTestComponent, &'s mut Services)>>`\n              found trait `for<'r, 's> <for<'r, 's> fn(&'r mut FirstTestComponent, &'s mut Services) -> impl for<'r, 's> std::future::Future<Output = ()> {FirstTestComponent::add_component} as std::ops::FnOnce<(&'r mut FirstTestComponent, &'s mut Services)>>`\nnote: the lifetime requirement is introduced here\n  --> src/main.rs:30:79\n   |\n30 |         F: 'static + Copy + FnOnce(&mut FirstTestComponent, &mut Services) -> Fut,\n   |                                                                               ^^^\n\n\nliterally saying that something is different than itself...\nI guess there is some error linked to the lifetime hidden in the error message but I can't figure it out.\nWhat could cause this error ? What is wrong with what I've implemented ?\n",
"AnswerId": "76382830",
"AnswerBody": "I found the answer here: How to bind lifetimes of Futures to fn arguments in Rust\nThe problem as I understand it is this:\nFrom https://rust-lang.github.io/async-book/03_async_await/01_chapter.html:\n\nUnlike traditional functions, async fns which take references or other non-'static arguments return a Future which is bounded by the lifetime of the arguments\n\nSo I had to force the Fut lifetime to be shorter than the input parameters lifetime.\nThe syntax won't let me simply force this by using Higher Ranked Lifetime bounds (as explained in the answer linked above) so I had to use the pattern proposed there: generate a meta trait linking lifetimes as this:\ntrait XFn<'a, T, S> {\n    type Output: Future<Output = ()> + 'a;\n    fn call(&self, this: T, services: S) -> Self::Output;\n  }\n  \n  impl<'a, T: 'a, S: 'a, F, Fut> XFn<'a, T, S> for F\n  where\n    F: 'static + Copy + FnOnce(T, S) -> Fut,\n    Fut: Future<Output = ()> + 'a,\n  {\n    type Output = Fut;\n    fn call(&self, this: T, services: S) -> Fut {\n        self(this, services)\n    }\n  }\n\nThen I can use this trait to constraints lifetime on arguments and Future like this:\nfn record_callback<F>(callback: F)\n    where \n            for<'a> F: XFn<'a, &'a mut FirstTestComponent, &'a mut Services> + 'static + Copy,\n    {\n    }\n\n\n"
},
{
"QuestionId": "76383199",
"QuestionTitle": "Passing a prop/variable to react router 6 loader function",
"QuestionBody": "My routes are working and accessing components and loader functions. I'm trying now to pass variable filmsPerPage (which is defined once) to both Home component and the loader function in\nApp.js:\nconst App = () => { \n  const filmsPerPage = 12\n    \n  const router = createBrowserRouter([\n    {\n      path: '/',\n      children: [\n        {\n          index: true,\n          element: <Home {...{filmsPerPage}} />,\n          loader: () => { loaderHome(filmsPerPage) }\n        },\n        .................\n\nHome.js:\nconst Home = (props) => {\n  const { loaderData } = useLoaderData() // get loader data --> null\n  console.log(props.filmsPerPage) // printing out correctly: 12\n  .......\n}\n    \nexport default Home;\n    \nexport function loaderHome(filmsPerPage) {\n  console.log(filmsPerPage) --> printing out 12\n  return defer({\n    loaderData: loadPosts(null, 1, 12, null)\n  })\n}\n\nThe prop filmsPerPage is passing correctly to Home.js component and while it's passing to the loader function, the useLoaderData() in Home.js is returning null which means that although the code in the loader function is working properly, it's not returning a loader object to the component. If I do this in App.js, the useLoaderData() function (in Home.js) will get the data but now the loader function doesn't have the prop:\nchildren: [\n  {\n    index: true,\n    element: <Home {...{filmsPerPage}} />,\n    loader: loaderHome\n  },\n\nHow could I pass the filmsPerPage prop to the loader function which will then return loader data to Home.js?\n",
"AnswerId": "76383930",
"AnswerBody": "The loader function isn't returning anything. Perhaps reformatted to a more readable format will make this more apparent:\n{\n  index: true,\n  element: <Home {...{filmsPerPage}} />,\n  loader: () => {\n    loaderHome(filmsPerPage); // <-- not returned!!\n  },\n}\n\nThe loader should still return the result of calling loaderHome.\nExamples:\n{\n  index: true,\n  element: <Home {...{filmsPerPage}} />,\n  loader: () => {\n    return loaderHome(filmsPerPage); // <-- explicit return in function block\n  },\n}\n\n{\n  index: true,\n  element: <Home {...{filmsPerPage}} />,\n  loader: () => loaderHome(filmsPerPage), // <-- implicit arrow function return\n}\n\nYou could even rewrite loaderHome to curry, e.g. close over in function scope, the filmsPerPage argument.\nexport function loaderHome(filmsPerPage) {\n  console.log(filmsPerPage); --> printing out 12\n\n  // Return loader function\n  return (loaderArgs) => {\n    return defer({\n      loaderData:  loadPosts(null, 1, filmsPerPage, null);\n    });\n  };\n}\n\n{\n  index: true,\n  element: <Home {...{filmsPerPage}} />,\n  loader: loaderHome(filmsPerPage),\n}\n\n"
},
{
"QuestionId": "76385338",
"QuestionTitle": "How to send Messages after Spring Integration application restarted?",
"QuestionBody": "I have a small Spring Integration application, I'm storing messages and messaging groups in the database. Currently, I have a case when some messages/groups are waiting to be sent after group timeout, but the application restarted. And when the application started I still have messages in DB and they won't be sent. I need some configuration to send expired message group from DB or resume timer. I tried to use reaper, but it does not work as expected. My code is:\n@Configuration\npublic class ConsumingChannelConfig {\n\n    @Bean\n    public DirectChannel consumingChannel() {\n        return new DirectChannel();\n    }\n\n    @Bean\n    public KafkaMessageDrivenChannelAdapter<String, String> kafkaMessageDrivenChannelAdapter() {\n        KafkaMessageDrivenChannelAdapter<String, String> kafkaMessageDrivenChannelAdapter =\n                new KafkaMessageDrivenChannelAdapter<>(kafkaListenerContainer());\n        kafkaMessageDrivenChannelAdapter.setOutputChannel(consumingChannel());\n        MessagingMessageConverter messageConverter = new MessagingMessageConverter();\n        messageConverter.setGenerateMessageId(true);\n        kafkaMessageDrivenChannelAdapter.setRecordMessageConverter(messageConverter);\n        return kafkaMessageDrivenChannelAdapter;\n    }\n\n    @Bean\n    public DataSource getDataSource() {\n        return ...;\n    }\n\n    @Bean\n    public JdbcMessageStore jdbcMessageStore() {\n        return new JdbcMessageStore(getDataSource());\n    }\n\n    @ServiceActivator(inputChannel = \"consumingChannel\")\n    @Bean\n    public MessageHandler aggregator() {\n        long timeout = 10000L;\n        AggregatingMessageHandler aggregator =\n                new AggregatingMessageHandler(new DefaultAggregatingMessageGroupProcessor(),\n                        jdbcMessageStore());\n        aggregator.setOutputChannel((message, l) -> {\n            System.out.println(\"MESSAGE: \" + message);\n            return true;\n        });\n        aggregator.setGroupTimeoutExpression(new ValueExpression<>(timeout));\n//        aggregator.setTaskScheduler(this.taskScheduler);\n        aggregator.setCorrelationStrategy(new MyCorrelationStrategy());\n        aggregator.setSendPartialResultOnExpiry(true);\n        aggregator.setExpireGroupsUponCompletion(true);\n        aggregator.setExpireGroupsUponTimeout(true);\n        aggregator.setDiscardChannel((message, timeout1) -> {\n            System.out.println(\"DISCARD: \" + message + \", timeout: \" + timeout1);\n            return true;\n        });\n        aggregator.setReleaseStrategy(new ReleaseStrategy() {\n            @Override\n            public boolean canRelease(MessageGroup group) {\n                return System.currentTimeMillis() - group.getTimestamp() >= timeout;\n            }\n        });\n        return aggregator;\n    }\n\n    @Bean\n    public MessageGroupStoreReaper reaper() {\n        MessageGroupStoreReaper reaper = new MessageGroupStoreReaper(jdbcMessageStore());\n        reaper.setPhase(1);\n        reaper.setTimeout(2000L);\n        reaper.setAutoStartup(true);\n//        reaper.setExpireOnDestroy(true);\n        return reaper;\n    }\n\n    @Bean\n    public ConcurrentMessageListenerContainer<String, String> kafkaListenerContainer() {\n        ContainerProperties containerProps = new ContainerProperties(\"spring-integration-topic\");\n\n        return new ConcurrentMessageListenerContainer<>(\n                consumerFactory(), containerProps);\n    }\n\n    @Bean\n    public ConsumerFactory<String, String> consumerFactory() {\n        return new DefaultKafkaConsumerFactory<>(consumerConfigs());\n    }\n\n    @Bean\n    public Map<String, Object> consumerConfigs() {\n        Map<String, Object> properties = new HashMap<>();\n        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092\");\n        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n        properties.put(ConsumerConfig.GROUP_ID_CONFIG, \"spring-integration\");\n        // automatically reset the offset to the earliest offset\n        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n//        DefaultKafkaHeaderMapper mapper = new DefaultKafkaHeaderMapper();\n        return properties;\n    }\n}\n\nUPD: My Solution\n@EnableScheduling\n@SpringBootApplication\npublic class SpringIntegrationExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(SpringIntegrationExampleApplication.class, args);\n    }\n\n\n    @Autowired\n    private MessageGroupStoreReaper reaper;\n\n    @Scheduled(initialDelay = 2000, fixedDelay = Long.MAX_VALUE)\n    public void start() {\n        reaper.run();\n    }\n\n}\n\n",
"AnswerId": "76385536",
"AnswerBody": "The MessageGroupStoreReaper doesn't work by itself, it has to be called from a @Scheduled method: https://docs.spring.io/spring-integration/docs/current/reference/html/message-routing.html#reaper\nHowever there is a nice option for you from an aggregator perspective:\n/**\n * Perform a {@link MessageGroupStore#expireMessageGroups(long)} with the provided {@link #expireTimeout}.\n * Can be called externally at any time.\n * Internally it is called from the scheduled task with the configured {@link #expireDuration}.\n * @since 5.4\n */\npublic void purgeOrphanedGroups() {\n\nYou just need to set that expireTimeout > 0:\n/**\n * Configure a timeout in milliseconds for purging old orphaned groups from the store.\n * Used on startup and when an {@link #expireDuration} is provided, the task for running\n * {@link #purgeOrphanedGroups()} is scheduled with that period.\n * The {@link #forceReleaseProcessor} is used to process those expired groups according\n * the \"force complete\" options. A group can be orphaned if a persistent message group\n * store is used and no new messages arrive for that group after a restart.\n * @param expireTimeout the number of milliseconds to determine old orphaned groups in the store to purge.\n * @since 5.4\n * @see #purgeOrphanedGroups()\n */\npublic void setExpireTimeout(long expireTimeout) {\n\nSee also docs on the matter: https://docs.spring.io/spring-integration/docs/current/reference/html/message-routing.html#aggregator-xml\n\nStarting with version 5.4, the aggregator (and resequencer) can be configured to expire orphaned groups (groups in a persistent message store that might not otherwise be released).\n\n"
},
{
"QuestionId": "76381843",
"QuestionTitle": "Powershell - PSCustomObject with Calculated Property",
"QuestionBody": "I'm importing a .csv file which I'm then modifying using calculated properties in a PSCustomObject.\nI'm stuck on one calculation where I'm attempting to lookup a value from a datarow object using one of the .csv values.\nWe receive data with the supplier Part No and I need to lookup our corresponding Part No.\nWould you be able to suggest how best to do this please?\nThe csv content looks like this:\nVendor Code,Part No,Part Description,Bonded,Quantity,PO No,Vendor Ref\nTEZ,ABC1234,Dark Blue,No,50,4378923,ORD089234\nTEZ,BBC1256,Orange,No,20,4378923,ORD089234\nTEZ,ACD1349,Green,No,10,4378923,ORD089234\n\nThe SQL query $SKUs returns this as datarows:\nITEMNO VALUE\nTYP-5063 ABC1234\nTYP-5037 BBC1256\nTYP-8069 ACD1349\n\nSo I'm looking to use the 'Part No' field from the .csv file to run a lookup against $SKUs.VALUE and return the matching $SKUs.ITEMNO.\nThe output .csv will then include a column called 'OUR_SKU' containing the $SKUs.ITEMNO value.\nHere is my code so far:\n$Files = Get-ChildItem -Path \"D:\\Imports\\Test\\INVENTORY_HUB_RECEIPTS\"\n$ProcessingPath = \"D:\\Imports\\Test\\INVENTORY_HUB_RECEIPTS\\Processing\\\"\n$UKEntity = \"TESTTRG\"\n$HUB_ID = \"TEST\"\n$SKUs = Invoke-Sqlcmd -ServerInstance \"localhost\" -Database \"XXXX\" -Query \"SELECT RTRIM(ITEMNO) AS ITEMNO, RTRIM(VALUE) AS VALUE FROM [XXXX].[dbo].[ICITEMO] WHERE OPTFIELD = 'CUSTITMNO' AND VALUE <>''\"\n\nforeach ($file in $Files) {\n\n    \n    $Content = (Import-Csv -path ($ProcessingPath + $file.Name)) |\n    Select-Object @{n='HUB_ID'; e={ $HUB_ID }},\n    @{e={$_.'Part No'}; l='PART_NO'},\n    @{e={$_.Quantity}; l='QTY_RECEIVED'},\n    DATE,\n    @{n='ENTITY'; e={ $UKEntity }},\n    @{e={$_.'Vendor Ref'.Substring($_.'Vendor Ref'.Length -8)}; l='ORDER_ID'},\n\n    @{n='OUR_SKU'; e={ $SKUs | Where-Object {$($_.VALUE) -eq '123ABC'} | Select-Object -ExpandProperty ITEMNO}},\n    @{n='OUR_SKU_X'; e={ $SKUs | Where-Object {$($_.VALUE) -eq $_.'PART_NO'} | Select-Object -ExpandProperty ITEMNO}}\n\n    if ($Content.Count -eq 0) {Remove-Item ($ProcessingPath + $file.Name)} else {$Content | Export-Csv -Path ($ProcessingPath + $file.Name) -Not -Force}\n    }\n\nI've tried two examples for the new property 'OUR_SKU' this works but is obviously a static value.\nThe property 'OUR_SKU_X' is my attempt to use the supplied $.'PART_NO' and this currently returns a blank field.\nThe variable $SKUs does contain data and so does $.'PART_NO'.\nI'm thinking it's either a simple syntax error or it's not possible to use $_.'PART_NO' in the script block?\nThanks\nColin\n",
"AnswerId": "76382973",
"AnswerBody": "Per comments, inside the where-object scriptblock on the line:\n$SKUs |  Where-Object {$($_.VALUE) -eq $_.'PART_NO'}\nthe automatic variable $_ relates to the individual items piped in from $SKUs, which hides the outer $_ from the $Content = (Import-Csv ...) | Select-Object ...\nIf you want to be able to access the outer $_ inside the where-object you'll need to capture it into a temporary variable like this:\ne={ $tmp = $_; $SKUs | Where-Object { $_.VALUE -eq $tmp.PARTNO } | Select-Object -ExpandProperty ITEMNO}}\nHere's a cut-down example:\n$parts = @\"\nVendor Code,Part No,Part Description,Bonded,Quantity,PO No,Vendor Ref\nTEZ,ABC1234,Dark Blue,No,50,4378923,ORD089234\nTEZ,BBC1256,Orange,No,20,4378923,ORD089234\nTEZ,ACD1349,Green,No,10,4378923,ORD089234\n\"@ | ConvertFrom-Csv\n\n$skus = @\"\nITEMNO,VALUE\nTYP-5063,ABC1234\nTYP-5037,BBC1256\nTYP-8069,ACD1349\n\"@ | ConvertFrom-Csv\n\n$results = $parts | select-object @(\n    @{l=\"PART_NO\";  e={ $_.\"Part No\" } },\n    @{l=\"DESC\";     e={ $_.\"Part Description\" } },\n    @{n='OUR_SKU';  e={ $part = $_; $skus | where-object { $_.VALUE -eq $part.\"Part No\" } | Select-Object -ExpandProperty ITEMNO} }\n)\n\nNote the $part = $_; and $_.VALUE -eq $part.\"Part No\" inside the definition of the third calculated property.\nThe output from the above is:\n$results\n\nPART_NO DESC      OUR_SKU\n------- ----      -------\nABC1234 Dark Blue TYP-5063\nBBC1256 Orange    TYP-5037\nACD1349 Green     TYP-8069\n\n"
},
{
"QuestionId": "76383838",
"QuestionTitle": "Hover is not working on navbar items and the cursor is changing to hand when we hover beside text and not when we hover on text",
"QuestionBody": "The hover effect is not working in my code. Can someone help?When I run this code there is navbar present but is not clickable whereas the empty space on it's left side is clickable nor are my css hover effect working on it.\n\n\n* {\n    padding: 0;\n    margin: 0;\n    box-sizing: border-box;\n    scroll-behavior: smooth;\n    font-family: 'Poppins', sans-serif;\n    list-style: none;\n    text-decoration: none;\n}\n\n:root {\n    /* global variables */\n    --main-color: #ff702a;\n    --text-color: #fff;\n    --background-color: #1e1c2a;\n    --big-font: 5rem;\n    --h2-font: 2.25rem;\n    --p-font: 0.9rem;\n}\n\n*::selection {\n    background: var(--main-color);\n    color: #fff;\n}\n\nbody {\n    color: var(--text-color);\n    background: var(--background-color);\n}\n\nheader {\n    position: fixed;\n    top: 0;\n    left: 0;\n    width: 100%;\n    z-index: 1000;\n    /*z-index defines stack order of element*/\n    display: flex;\n    align-items: center;\n    /*controls space around cross axis*/\n    justify-content: space-between;\n    /*controls space around main axis*/\n    padding: 30px 170px;\n    background: var(--background-color);\n}\n\n.logo {\n    color: var(--main-color);\n    font-weight: 600;\n    font-size: 2.4rem;\n}\n\n.navbar {\n    display: flex;\n}\n\n.navbar li a {\n    color: var(--text-color);\n    font-size: 1.1rem;\n    padding: 10px 20px;\n    font-weight: 500;\n}\n\n.navbar li a:hover {\n    color: var(--main-color);\n    transition: .4s;\n}\n<!DOCTYPE html>\n<html>\n\n<head>\n    <meta charset='utf-8'>\n    <meta http-equiv='X-UA-Compatible' content='IE=edge'>\n    <title>Website for Foodies!</title>\n    <meta name='viewport' content='width=device-width, initial-scale=1'>\n    <link rel='stylesheet' type='text/css' media='screen' href='main.css'>\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/boxicons@latest/css/boxicons.min.css\">\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n    <link\n        href=\"https://fonts.googleapis.com/css2?family=Nunito+Sans:wght@300;800&family=Poppins:wght@100;200;300;400;500;600;700;800;900&display=swap\"\n        rel=\"stylesheet\">\n</head>\n\n<body>\n    <header>\n        <a href=\"#\" class=\"logo\">Foods</a>\n        <div class=\"bx bx-menu\" id=\"menu-icon\"></div>\n        <!--class=\" bx bx-menu\" is responsible for icon from boxicon-->\n        <ul class=\"navbar\">\n            <li><a href=\"#Home\"></a>Home</li>\n            <li><a href=\"#About\"></a>About</li>\n            <li><a href=\"#Menu\"></a>Menu</li>\n            <li><a href=\"#Service\"></a>Service</li>\n            <li><a href=\"#Contact\"></a>Contact</li>\n        </ul>\n    </header>\n</body>\n</html>\n\n\n\nI was trying to make a responsive website and I was expecting the text in my navbar to change color when i hover on it\n",
"AnswerId": "76383944",
"AnswerBody": "According to your code :\n.navbar li a:hover {\n    color: var(--main-color);\n    transition: .4s;\n}\n\nyou tried to give hover effect on anchor tag as  class navbar > li > a.\nLook at this your html code now:\n<ul class=\"navbar\">\n            <li><a href=\"#Home\"></a>Home</li>\n            <li><a href=\"#About\"></a>About</li>\n            <li><a href=\"#Menu\"></a>Menu</li>\n            <li><a href=\"#Service\"></a>Service</li>\n            <li><a href=\"#Contact\"></a>Contact</li>\n        </ul>\n\n<a href=\"#Home\"></a>\n\nThere is nothing to show inside anchor tag. Hope you understand this problem. Put all the menu texts Home about menu service contact inside anchor tag. like this:\n<a href=\"#Home\">Home</a>\n\n"
},
{
"QuestionId": "76383381",
"QuestionTitle": "Adding new column for different rows based on the values present in the same row for a different column",
"QuestionBody": "I have a dataframe with different combination of factors. each factor is presented in its column (see below)\nF1   F2   F3   F4\n1     1\n1          1  \n1                1\n\nI want to add a new column at the end like below\nF1   F2   F3   F4  trt\n1    1             F1_F2\n1          1       F1_F3\n1               1  F1_F4\n\nHow do I create this column with conditional merging in R. Any advice would be appreciated!\n",
"AnswerId": "76383955",
"AnswerBody": "aggregate(ind~row, na.omit(cbind(row = c(row(df)), stack(df))), paste, collapse = \"_\")\n  row   ind\n1   1 F1_F2\n2   2 F1_F3\n3   3 F1_F4\n\n\ndf <- structure(list(F1 = c(1L, 1L, 1L), F2 = c(1L, NA, NA), F3 = c(NA, \n1L, NA), F4 = c(NA, NA, 1L)), class = \"data.frame\", row.names = c(NA, \n-3L))\n\n"
},
{
"QuestionId": "76385226",
"QuestionTitle": "why my basic terraform fails to run terraform plan?",
"QuestionBody": "I have this very basic terraform file: main.tf\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 4.16\"\n    }\n  }\n\n  required_version = \">= 1.2.0\"\n}\n\nprovider \"aws\" {\n    profile = \"default\"\n}\n\nresource \"aws_s3_bucket\" \"test-bucket-terraform-regergjegreg\" {\n  bucket = \"test-bucket-terraform-regergjegreg\"\n\n  tags = {\n    Name        = \"My bucket\"\n    Environment = \"Dev\"\n  }\n}\n\nwhen doing terraform validate, I have no error:\nSuccess! The configuration is valid.\nNow when I do terraform plan, I got this error:\nPlanning failed. Terraform encountered an error while generating this plan.\n\n╷\n│ Error: configuring Terraform AWS Provider: credential type source_profile requires role_arn, profile default\n│ \n│   with provider[\"registry.terraform.io/hashicorp/aws\"],\n│   on main.tf line 12, in provider \"aws\":\n│   12: provider \"aws\" {\n│ \n╵\n\nHere is my terraform version:\nTerraform v1.4.6\non darwin_amd64\n+ provider registry.terraform.io/hashicorp/aws v3.76.1\n\nthe default profile exists in my /.aws/credentials and /.aws/config\nNot sure what could be wrong really. Any help is appreciated. thanks\n",
"AnswerId": "76385541",
"AnswerBody": "Ok, I resolved the issue.\nMy problem was not in credentials file but in config.\nFor some reason I had this:\n[default]\noutput = json\nregion = eu-west-1\nsource_profile = default\n\nremoving source_profile makes it work.\n"
},
{
"QuestionId": "76381780",
"QuestionTitle": "How to visualize formatted text without removing empty space?",
"QuestionBody": "I want to visualize a pre-formatted text (with YAML format and indent). It seems that the <|{text}|> markdown pattern and the state representation removes intents from the text, i.e. all becomes a long mashed text. Here is an example output.\nversion: '3.1' stories: - story: 06a6e2c5e8bd4058b304b4f23d57aa80 steps: - intent: bot_capabilities user: What can you do\n\nCorrect is this:\nversion: '3.1'\nstories:\n-   story: 06a6e2c5e8bd4058b304b4f23d57aa80\n    steps:\n    -   intent: bot_capabilities\n        user: What can you do\n\nIs there a way to keep preformatted text especially with indents?\nI could not yet find a fitting property for the \"text\" control. Raw does not seem to solve the issue. If I print the string before assigning it to a state variable, the output format is correct. Therefore, I assume the stripping of empty space happens automatically afterwards.\n",
"AnswerId": "76383057",
"AnswerBody": "The most straightforward way is to use an input visual element with multiline property turned on.\nmain.py:\nfrom taipy.gui import Gui \n\n#with open(\"file.yaml\", \"r\") as f:\n#    yaml_text = f.read()\n\nyaml_text = \"\"\"\nversion: '3.1'\nstories:\n-   story: loferum ipsi\n    steps:\n    -   intent: bot_capabilities\n        user: What can you do\n\"\"\"\n\npage = \"\"\"\n<|{yaml_text}|input|multiline|label=Input|>\n\n<|{yaml_text}|input|multiline|not active|label=Inactive input|>\n\n<|{yaml_text}|input|multiline|not active|label=Inactive white input|id=yaml|>\n\"\"\"\n\nGui(page).run()\n\nHere is the result:\n\nThe first input is editable\nThe second is not editable and grey\nThe third is not editable and white\n\n\nFor the last element, I added a bit of CSS to make the inactive input white:\nmain.css:\n#yaml.Mui-disabled{\n    color: white !important;\n    -webkit-text-fill-color: white !important;\n}\n\nAn issue has been created on GitHub to improve text visual elements directly.\n"
},
{
"QuestionId": "76383189",
"QuestionTitle": "How can I limit os.walk results for a single file?",
"QuestionBody": "I am trying to search a given directory for a specific file, and if that file does not exist I would want the code to say \"File does not exist\". Currently with os.walk I can get this to work, however this will hit on every single file that isn't the specified file and print \"File dos not exist\". I know that this is how os.walk functions, but I was not sure if there is a way to make it only print out once if it is found or not found.\nFolder structure:\nroot folder|\n|Project Folder\n|file.xml\n|other files/subfolders\nHow I would want the code to work is to go inside of \"Project Folder\", do a recursive search for \"file.xml\", and once it is found print out once \"Found\", otherwise prints out once \"Not found\".\nThe code is:\ndef check_file(x): #x = root folder dir\n   for d in next(os.walk(x))[1]: #if I understand correctly, [1] will be Project Folder\n        for root, directories, files in os.walk(x):\n            for name in files:\n                if \"file.xml\" not in name:\n                    print(\"found\")\n                else:\n                    print(\"File Missing\")\n\nIf I change the code to\n            for name in files:\n                if \"file.xml\" in name:\n                    print(\"found\")\n                else:\n                    pass\n\nThe code technically works as intended, but it doesn't really do much to help point out if it isn't there, so this isn't a good solution. It would be easier if I was able to give the code a specific path to look in, however as the user is able to place the 'root folder' anywhere on their machine as well as the 'project folder' would have different names depending on the project, I don't think I would be able to give the code a specific location.\nIs there a way to get this to work with os.walk, or would another method work best?\n",
"AnswerId": "76383961",
"AnswerBody": "The glob module is very convenient for this kind of wildcard-based recursive search. Particularly, the ** wildcard matches a directory tree of arbitrary depth, so you can find a file anywhere in the descendants of your root directory.\nFor example:\nimport glob\n\ndef check_file(x):  # where x is the root directory for the search\n    files = glob.glob('**/file.xml', root_dir=x, recursive=True)\n    if files:\n        print(f\"Found {len(files)} matching files\")\n    else:\n        print(\"Did not find a matching file\")\n\n"
},
{
"QuestionId": "76385139",
"QuestionTitle": "ABAP ODATA Service implement custom GET or POST request",
"QuestionBody": "How can I implement a custom method to check if the user is exists by the given parameter in the url? So I want to make a GET request.\n",
"AnswerId": "76385542",
"AnswerBody": "Assumption: you are talking about ABAP implmentation of OData v2 with SEGW approach.\nYou are looking for a so called Function Import.\nThis allows you to define custom functions next to the predefined CRUDQ (Create, Read, Update, Delete, Query) functions. This custom function can have custom input parameters and return values as simple types or Complex Types (=Structures/Entities)\nAs stated also in SAP Help this should be only used if it does not fit into the CRUDQ methods for your entities.\nFind an example implementation in this SAP Blog\nFor other approaches, e.g. RESTful ABAP Programming Model (RAP), it would be Actions and Validations but cannot generally be answered without details of the scenario.\n"
},
{
"QuestionId": "76380562",
"QuestionTitle": "Have incremental local perforce scls similar to git for a single file",
"QuestionBody": "Consider i have a file called developers.txt\nWhat i want to do is (and i could do it in git neatly)\nhave 3-4 commits, each adding 1 line per commit\ncommit 2ad54bfe954006bafcb209f06ac0c12091d297c8 (HEAD -> main)\nAuthor: Anuraag <anuraag@something.com>\nDate:   Thu Jun 1 15:04:57 2023 +0530\n\n    author #3 added\n\ndevelopers.txt\n\ncommit 26cabf7fa07154b19deff41c5cbb07bf0782bde7\nAuthor: Anuraag <anuraag@something.com>\nDate:   Thu Jun 1 15:04:43 2023 +0530\n\n    author #2 added\n\ndevelopers.txt\n\ncommit d9e57385b505e2e02a8dc6064466c3974f22e66d\nAuthor: Anuraag <anuraag@something.com>\nDate:   Thu Jun 1 15:04:23 2023 +0530\n\n    author #1 added\n\ndevelopers.txt\n\ncommit 03e7f4abddfa26b4b0518994c81e0a724ba1a778\nAuthor: Anuraag <anuraag@something.com>\nDate:   Thu Jun 1 15:03:56 2023 +0530\n\n    adds heading\n\ndevelopers.txt\n\n% cat developers.txt \nAuthors:\n1. Arthur\n2. Canon\n3. Doyle\n\nWhat i want to know is, is there such an incremental local workspace development method when using perforce?\nI want to have SCL#3 to be on top of SCL#2, SCL#1 etc.. but each SCL will be for the same file, in this case developers.txt\n",
"AnswerId": "76383104",
"AnswerBody": "Yes, this is just basic versioning and should behave similarly across any version control system.  Every version builds on the one before it.\nC:\\Perforce\\test>echo Authors:>developers.txt\n\nC:\\Perforce\\test>p4 add developers.txt\n//stream/main/developers.txt#1 - opened for add\n\nC:\\Perforce\\test>p4 submit -d \"adds heading\"\nSubmitting change 460.\nLocking 1 files ...\nadd //stream/main/developers.txt#1\nChange 460 submitted.\n\nC:\\Perforce\\test>p4 edit developers.txt\n//stream/main/developers.txt#1 - opened for edit\n\nC:\\Perforce\\test>echo 1. Arthur>>developers.txt\n\nC:\\Perforce\\test>p4 submit -d \"author #1 added\"\nSubmitting change 461.\nLocking 1 files ...\nedit //stream/main/developers.txt#2\nChange 461 submitted.\n\nC:\\Perforce\\test>p4 edit developers.txt\n//stream/main/developers.txt#2 - opened for edit\n\nC:\\Perforce\\test>echo 2. Conan>>developers.txt\n\nC:\\Perforce\\test>p4 submit -d \"author #2 added\"\nSubmitting change 462.\nLocking 1 files ...\nedit //stream/main/developers.txt#3\nChange 462 submitted.\n\nC:\\Perforce\\test>p4 edit developers.txt\n//stream/main/developers.txt#3 - opened for edit\n\nC:\\Perforce\\test>echo 3. Doyle>>developers.txt\n\nC:\\Perforce\\test>p4 submit -d \"author #3 added\"\nSubmitting change 463.\nLocking 1 files ...\nedit //stream/main/developers.txt#4\nChange 463 submitted.\n\nNow we have our developers.txt with 4 versions.  We can see that the head revision contains all 4 changes:\nC:\\Perforce\\test>cat developers.txt\nAuthors:\n1. Arthur\n2. Conan\n3. Doyle\n\nWe can see its history as a list of the changes made to it:\nC:\\Perforce\\test>p4 filelog developers.txt\n//stream/main/developers.txt\n... #4 change 463 edit on 2023/06/01 by Samwise@Samwise-dvcs-1509687817 (text) 'author #3 added'\n... #3 change 462 edit on 2023/06/01 by Samwise@Samwise-dvcs-1509687817 (text) 'author #2 added'\n... #2 change 461 edit on 2023/06/01 by Samwise@Samwise-dvcs-1509687817 (text) 'author #1 added'\n... #1 change 460 add on 2023/06/01 by Samwise@Samwise-dvcs-1509687817 (text) 'adds heading'\n\nAnd we can annotate the file to see the content of the file in context of the history, i.e. which revision/changelist added each line of content:\nC:\\Perforce\\test>p4 annotate developers.txt\n//stream/main/developers.txt#4 - edit change 463 (text)\n1: Authors:\n2: 1. Arthur\n3: 2. Conan\n4: 3. Doyle\n\nC:\\Perforce\\test>p4 annotate -c developers.txt\n//stream/main/shelves/developers.txt#4 - edit change 463 (text)\n460: Authors:\n461: 1. Arthur\n462: 2. Conan\n463: 3. Doyle\n\n"
},
{
"QuestionId": "76383470",
"QuestionTitle": "Why by calling new File(\".\").getAbsolutePath() I get completely different path from my project's location?",
"QuestionBody": "My project is located here:\nD:/WorkSpace/PuzzleApp\n\nbut when I am calling\nnew File(\".\").getAbsolutePath();\n\nI get:\nD:\\!Documents\\Desktop\\.\n\nWhy? And how to fix this?\nI'm using Eclipse.\n",
"AnswerId": "76383965",
"AnswerBody": "When you open File with relative path \".\" this path is relative to the current process' working directory.\nUsually, the process working directory is inherited from the parent process (e.g. if you run your app with Terminal - the current terminal's working directory will be your process' working dir).\nUsing a relative path inside your application is considered a bad idea because you can not control this process' working directory.\nBut using an absolute hardcoded path also goes with some problems and can't be called a good practice.\nThere are several ways to solve the issue:\n\nUse a path relative to some NOT hardcoded absolute path. This absolute path should be externalized to environment variables, properties files, etc.\n\n//Getting the directory path from the external system variable\nString myAbsoultePath = System.getenv(\"LOCAL_STORAGE_DIR\");\n\n\nUse a path relative to your application root. It allows you to READ files even located inside .jar or .war archives.\n\n//This path looks absolute, but the path's root is your project's root\nInputStream stream = MyClass.class.getResourceAsStream(\"/dir/another/file.txt\");\n\nBut you should understand, that your application won't run inside your IDE project folder. It will be deployed in a production server/user's desktop/android device environment and usually, it is packed in a jar/war/ear/... archive. It means that you won't have access to your src folder or something like this.\n"
},
{
"QuestionId": "76381260",
"QuestionTitle": "ClassCastException for configuration CGLIB proxy and org.springframework.cglib.proxy.Factory after upgrade Spring to 6.0.9 and Spring Boot to 3.0.6",
"QuestionBody": "In our project, after upgrade the SpringBoot from 3.0.4 to 3.0.9, several of our tests started to fail on\nCaused by: org.springframework.aop.framework.AopConfigException: Unexpected AOP exception\n    at app//org.springframework.aop.framework.CglibAopProxy.buildProxy(CglibAopProxy.java:222)\n    at app//org.springframework.aop.framework.CglibAopProxy.getProxy(CglibAopProxy.java:158)\n    at app//org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:110)\n    at app//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.buildProxy(AbstractAutoProxyCreator.java:517)\n    at app//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.createProxy(AbstractAutoProxyCreator.java:464)\n    at app//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.wrapIfNecessary(AbstractAutoProxyCreator.java:369)\n    at app//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.postProcessAfterInitialization(AbstractAutoProxyCreator.java:318)\n    at app//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:434)\n    at app//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1773)\n    at app//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:598)\n    ... 80 more\nCaused by: java.lang.ClassCastException: class our.project.RepositoryConfiguration$LiquibaseConfiguration$$SpringCGLIB$$0 cannot be cast to class org.springframework.cglib.proxy.Factory (our.project.RepositoryConfiguration$LiquibaseConfiguration$$SpringCGLIB$$0 and org.springframework.cglib.proxy.Factory are in unnamed module of loader 'app')\n    at org.springframework.aop.framework.ObjenesisCglibAopProxy.createProxyClassAndInstance(ObjenesisCglibAopProxy.java:91)\n    at org.springframework.aop.framework.CglibAopProxy.buildProxy(CglibAopProxy.java:213)\n    ... 89 more\n\nIt's not bounded just to the our.project.RepositoryConfiguration$LiquibaseConfiguration. When I disable this configuration, then similar exception occurs on next configuration.\nAnother weird thing is that the test passes if only the single test class is called or if this class is executed first. Otherwise the ClassCastException ocurs.\nWe use TestNG for testing.\nI tried to upgrade Spring to version 3.0.6 from 3.0.4 and Spring Boot to version 3.0.6 from 3.0.4 and I expect that all our current tests will pass. But for 34 tests of our ~ 2000 there is an exception java.lang.ClassCastException: class our.project.RepositoryConfiguration$LiquibaseConfiguration$$SpringCGLIB$$0 cannot be cast to class org.springframework.cglib.proxy.Factory (our.project.RepositoryConfiguration$LiquibaseConfiguration$$SpringCGLIB$$0 and org.springframework.cglib.proxy.Factory are in unnamed module of loader 'app')\n",
"AnswerId": "76383270",
"AnswerBody": "Finally. after almost of week of investigations,  I managed to isolate the sinner. Solr 8.2.1 causes this issue. With Solr 8.2.0 it works with  Solr 8.2.1 there is class cast exception for spring proxies.\nHard to believe that this is related.\n"
},
{
"QuestionId": "76380844",
"QuestionTitle": "How can I create a frequency plot/histogram in R using ggplot2 while normalizing to the total of a factor?",
"QuestionBody": "My problem is the following: I can make a figure in which the data is weighed relative to the entire population, but not relative to their own subpopulation. To illustrate with an example:\nSuppose I have a dataset DS, with two columns: X and type.\nX is a continues value ranging from -5 to 5, and type is either A, B or C.\nHow would I create a frequency plot of X in which each tuple is weighed by the total of its type, not the total of all tuples in the dataset?\nThis is my closest attempt, yet it weighs to the total population:\nfigure1 <- ggplot(data = DS, aes(x = X))+ geom_freqpoly(aes(colour = type, y= after_stat(count / sum(count)))) + ...\nIts not surprising that this normalizes to the entire dataset, but I wouldnt know how to get it such that it only normalizes to a subset.\nUsing dput(), I generate the following example dataframe:\nDS <- structure(list(X = c(0, -0.01, 0.042944432215413, 0.0431301011419889, 0.042944432215413, 0.0424042102083902, 0.2100000012 , 0.13513333335333), TimePoint = c(\"early\", \"early\", \"late\", \"mid\", \"mid\", \"early\", \"late\", \"early\")), row.names = c(NA,8L), class = \"data.frame\")\n\nIn which 'X' is the continous value and 'TimePoint' is the factor which can be either 'early', 'mid' or late.\n",
"AnswerId": "76383334",
"AnswerBody": "One option would be to use e.g. ave() to compute the count per group or Timepoint:\nlibrary(ggplot2)\n\nggplot(data = DS, aes(x = X)) +\n  geom_freqpoly(\n    aes(\n      colour = TimePoint,\n      y = after_stat(count / ave(count, group, FUN = sum))\n    )\n  )\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n"
},
{
"QuestionId": "76385118",
"QuestionTitle": "Powershell/CMD issue",
"QuestionBody": "So I was trying to write a quick Batch file but it only did half the code, so I switched it to PowerShell because I remembered a while back I was able to get it to work and turns out this did work.\nMy issue is essentially I have a handful of users I want to have access to this \"it just closes a program and reopens\". They're familiar with Batch files (which I couldn't get to reopen the program) but would not be used to using a PowerShell script and having to right click to run as PowerShell which I'm expecting will cause issues and many of the users to not use the script in the first place.\nIs there either something I did wrong on the batch file for it not to reopen or is there a way to change the left click option on the PowerShell(currently left click opens the script in notepad; ideally it would just run as PowerShell on left click)\nThe code is the same for both PowerShell and CMD copied and pasted directly to.\ntaskkill /IM ADM.TrayApp.exe /F\nStart-Process  \"C:\\Program Files (x86)\\athenahealth, Inc\\aNetDeviceManager\\3.1.4.0\\TrayApp\\CoreModule\\ADM.TrayApp.EXE\"\n\n",
"AnswerId": "76385549",
"AnswerBody": "\nYou cannot use PowerShell's Start-Process directly in a batch file - you'd have to call via powershell.exe, the Windows PowerShell CLI or pwsh, the PowerShell (Core) CLI).\n\nHowever, as Stephan points out, cmd.exe's internal start command provides similar functionality, so its use should be sufficient in your case (as Stephan notes, some window title enclosed in \"...\" is needed as the first argument if the executable to launch is enclosed in \"...\" too; \"\" will do):\nstart \"\" \"C:\\Program Files (x86)\\athenahealth, Inc\\aNetDeviceManager\\3.1.4.0\\TrayApp\\CoreModule\\ADM.TrayApp.EXE\"\n\n\nIt is possible to make PowerShell scripts execute by default when (double-)left-clicked from File Explorer or the desktop, but requires nontrivial setup on each machine:\n\nSee this answer.\nThe linked answer also describes an alternative technique of providing simple companion batch files whose sole purpose is to execute an associated PowerShell script.\n\n\n\n"
},
{
"QuestionId": "76380912",
"QuestionTitle": "What is the best way to find text content under relatively indistinguishable tags by Selenium-webdriver?",
"QuestionBody": "As newbie I prefer use Abs XPath to get find WebElemnts where text is positioned.\nI tried:\nList<WebElement> elements = web.findElements(By.xpath(\"/html[1]/body[1]/div[2]/div[2]/dl[1]/dd[2]/div[2]/div/div[1]/ol[5]/li[1]/div[2]/div/p\"));\n\nBut i failed to catch text under tags with minor changes\nTarget xpaths:\n/html[1]/body[1]/div[2]/div[2]/dl[1]/dd[2]/div[2]/div[6]/div[1]/ol[5]/li[1]/div[2]/div[4]/div[1]/div[1]/p[1]\n/html[1]/body[1]/div[2]/div[2]/dl[1]/dd[2]/div[2]/div[6]/div[1]/ol[5]/li[1]/div[2]/div[8]/p\n/html[1]/body[1]/div[2]/div[2]/dl[1]/dd[2]/div[2]/div[2]/div[1]/ol[5]/li[1]/div[2]/div[3]/h3[1]\n/html[1]/body[1]/div[2]/div[2]/dl[1]/dd[2]/div[2]/div[2]/div[1]/ol[5]/li[1]/div[2]/div[2]/div[1]/p\n/html[1]/body[1]/div[2]/div[2]/dl[1]/dd[2]/div[2]/div[5]/div[1]/ol[5]/li[1]/div[2]/div[1]/div[1]/p[1]/strong[1]\n\nWhat is correct formula or way to get all text content in the above mentioned xpaths ?\n",
"AnswerId": "76383339",
"AnswerBody": "Not very clear what you want: If you want all elements that contain direct text you could use:\n/html/body[1]//*[text()[normalize-space()]]\n\nthis will return all elements with direct text()-nodes that after filtering unnecessary whitespace, have character-data.\nmeaning XPath-parts:\n// = any descendant; see this info on axes\n* = any element\n[some filter] = predicate to filter on direct previous node.\n[#number] = the position within its siblings. body[1] maybe seems redundant, but can help the XPath-engine not to look any further for other body elements\ntext() = node of type text\nnormalize-space() = strips white-space according this rules\n"
},
{
"QuestionId": "76384278",
"QuestionTitle": "How to do a lookup for the four primary keys columns yet output 6 columns to OLE DB Command",
"QuestionBody": "I'm moving from a SQL Server database to a DB2 database. I'm trying to compare the primary key of the SQL Server database with the DB2 database and if its the same primary key values then do an update if they are not the same do an insert.\nMy problem is when I use a lookup for the primary key (first four columns) it only returns the first four columns, I need someway of getting the other two columns so I can run a OLE DB command and do the update.\nI want to compare the four primary keys columns (FISCAL_YR, LOC_CODE, SYSTEM_ID, SYSTEM_CODE) and see if they exist in the destination table if they do I want to update two other columns (LOC_NAME, ALIAS_NAME) and if they don't match I want to do an insert.\nThis is what I have for the lookup currently but it matches all the columns I just want to do the first four (FISCAL_YR, LOC_CODE, SYSTEM_ID, SYSTEM_CODE) but output 6 columns (FISCAL_YR, LOC_CODE, SYSTEM_ID, SYSTEM_CODE, LOC_NAME, ALIAS_NAME) to OLE DB Command so I can do an update:\nSELECT \n    FISCAL_YR, LOC_CODE, SYSTEM_ID,  \n    SYSTEM_CODE, LOC_NAME, ALIAS_NAME \nFROM \n    LC1U1.Location_Supertbl1;\n\nThis is the update command I want to execute:\nUPDATE LC1U1.Location_Supertbl1 \nSET ALIAS_NAME = UPPER('test') \nWHERE FISCAL_YR = ? \n  AND LOC_CODE = ? \n  AND SYSTEM_ID = ? \n  AND SYSTEM_CODE = ?\n\nHow do I do this with a Lookup transformation in SSIS?\nThank you.\n",
"AnswerId": "76385594",
"AnswerBody": "I think the issue you're not asking for the columns from the lookup component.\nIn the UI, you drag lines between the left (Source) and right (Lookup) side. This defines the equality match for the lookup.\nWhat you want to do is check the 2 additional columns in that menu, something like the following image. This will add LOC_NAME and ALIAS_NAME as new columns, after the Lookup Component, into my data flow\n\n"
},
{
"QuestionId": "76383537",
"QuestionTitle": "How can I validate a MongoDB document using a validation schema from a file?",
"QuestionBody": "I want to validate document before it is inserted into the database. I know that I can set static validator, but I would prefer to have a file with the validation schemas that I could modify at any time.\n//example schema\nconst userCreateValidationSchema = {\n        bsonType: 'object',\n        required: ['username', 'password'],\n        properties: {\n            username: {\n                bsonType: 'string',\n                maxLength: 16,\n            },\n            password: {\n                bsonType: 'string',\n                maxLength: 64,\n            },\n        },\n        additionalProperties: false,\n};\n\n//example document\nconst document = {\n        username: \"user\",\n        password: \"passwd\",\n};\n\nThen I would do something like validate(document, userCreateValidationSchema).\nThanks for any thoughts.\nI have tried looking for the answer in the documentation but unfortunatelly didn't find the solution.\n",
"AnswerId": "76383985",
"AnswerBody": "To perform login validation using the npm package Joi :-\nnpm install joi\n\nImport Joi and Define Validation Schema :-\nconst Joi = require('joi');\n\nconst loginSchema = Joi.object({\n  email: Joi.string().email().required(),\n  password: Joi.string().min(6).required(),\n});\n\nIn the above example, the validation schema requires the email field to be a valid email address and the password field to have a minimum length of 6 characters.\nPerform Validation:\nNow you can use the validate() method provided by Joi for the validation.\nfunction validateLogin(loginData) {\n  const { error, value } = loginSchema.validate(loginData);\n  return error ? error.details[0].message : null;\n}\n\nUsage Example:\nHere's an example of how you can use the validateLogin() function to validate the login data:\nconst loginData = {\n  email: 'test@example.com',\n  password: 'password123',\n};\n\nconst validationError = validateLogin(loginData);\n\nif (validationError) {\n  console.log('Login validation failed:', validationError);\n} else {\n  console.log('Login data is valid.');\n}\n\n"
},
{
"QuestionId": "76385098",
"QuestionTitle": "R-Shiny, Use action button into a leaflet popup inside a Shiny module",
"QuestionBody": "I am trying to use an actionbutton in a leaflet popup into a shiny module\nWhen trying to use an action button into a leaflet popup in a Shiny module, button do not work.\nSee the exemple below :\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(DT)\n\nmap_ui <- function(id) {\n  ns <- NS(id)\n  tagList(\n    \n    leafletOutput(ns(\"mymap\"))\n    \n  )\n}\n\nmap_Server <- function(id) {\n  moduleServer(\n    id,\n    function(input, output, session) {\n      \n      mapdata <- datasets::quakes\n      mapdata$latitude <- as.numeric(mapdata$lat)\n      mapdata$longitude <- as.numeric(mapdata$long)\n      mapdata$id <- 1:nrow(mapdata)\n      \n      output$mymap <- renderLeaflet({\n        leaflet(options = leafletOptions(maxZoom = 18)) %>% addTiles() %>%\n          addMarkers(lat = ~ latitude, lng = ~ longitude,\n                     data = mapdata,\n                     layerId = mapdata$id,\n                     popup= ~paste(\"<b>\", mag, \"</b></br>\", actionLink(inputId = \"modal\", label = \"Modal\", onclick = 'Shiny.setInputValue(\\\"button_click\\\", this.id, {priority: \\\"event\\\"})')))\n      })\n\n      observeEvent(input$button_click, {\n        showModal(modalDialog(\n          title = \"TEST MODAL\"\n        ))      })\n      \n\n      \n    }\n  )\n}\n\nui <- fluidPage(\n  \n  map_ui('ex1')\n  \n)\n\nserver <- function(input, output){\n  map_Server('ex1')\n  \n}\n\nshinyApp(ui, server)\n\nIs there any way to make work that button into the module ? I think that it comes that the button is not ns() but i don't find a way to make it works.\nThanks\n",
"AnswerId": "76385628",
"AnswerBody": "Yes, you have to add the ns:\nfunction(input, output, session) {\n  \n  ns <- session$ns  \n  \n  ...... \n  \n  output$mymap <- renderLeaflet({\n    leaflet(options = leafletOptions(maxZoom = 18)) %>% addTiles() %>%\n      addMarkers(\n        lat = ~ latitude, lng = ~ longitude,\n        data = mapdata,\n        layerId = mapdata$id,\n        popup = \n          ~paste(\n            \"<b>\", mag, \"</b></br>\", \n            actionLink(\n              inputId = \"modal\", label = \"Modal\", \n              onclick = sprintf(\n                'Shiny.setInputValue(\\\"%s\\\", this.id, {priority: \\\"event\\\"})',\n                ns(\"button_click\")\n              )\n            )\n          )\n      )\n  })\n  \n  ......\n  \n}\n\n"
},
{
"QuestionId": "76384287",
"QuestionTitle": "Adding a legend to a ggplot map",
"QuestionBody": "I am using ggplot2 to visualise map-related data. I have coloured regions according to a continuous value, and I would like to add a legend with colors and region names. My own data is a bit cumbersome to share, but I have recreated the scenario with public data (Mapping in ggplot2). The following code creates the included map:\nlibrary(ggplot2)\nlibrary(sf)\n\n# Import a geojson or shapefile\nmap <- read_sf(\"https://raw.githubusercontent.com/R-CoderDotCom/data/main/shapefile_spain/spain.geojson\")\n\nggplot(map) +\n  geom_sf(color = \"white\", aes(fill = unemp_rate)) +\n  geom_sf_text(aes(label = name), size = 2)\n\n\nInstead of the continuous default legend, I would like to have a legend with names, numbers and colors. Basically, a legend that shows the name and unemp_rate columns of the data with colors matching the map (eg. unemp_rate). Somewhat like the legend of the second included picture (but the colors are not right).\n\n\n\n\nname\nunemp_rate\n\n\n\n\n\"Andalucía\"\n18.68\n\n\n\"Aragón\"\n8.96\n\n\n\"Principado de Asturias\"\n11.36\n\n\n\"Islas Baleares\"\n9.29\n\n\n\"Islas Canarias\"\n17.76\n\n\n\"Cantabria\"\n8.17\n\n\n\"Castilla y León\"\n10.19\n\n\n\"Castilla-La Mancha\"\n14.11\n\n\n\"Cataluña\"\n9.29\n\n\n\"Comunidad Valenciana\"\n12.81\n\n\n\"Extremadura\"\n16.73\n\n\n\"Galicia\"\n11.20\n\n\n\"Comunidad de Madrid\"\n10.18\n\n\n\"Región de Murcia\"\n12.18\n\n\n\"Comunidad Foral de Navarra\"\n8.76\n\n\n\"País Vasco\"\n8.75\n\n\n\"La Rioja\"\n10.19\n\n\n\"Ceuta y Melilla\"\n23.71\n\n\n\n\n\nMy actual code looks like so:\nggplot(map, aes(geometry = geometry, fill = Y1)) +\n  theme_bw() + geom_sf(show.legend = FALSE) +\n  scale_fill_gradient2(low = \"brown\", high = \"green\") +\n  theme(\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank())\n\n",
"AnswerId": "76385632",
"AnswerBody": "Perhaps an inset bar chart instead:\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(patchwork)\n# Import a geojson or shapefile\nmap_ <- read_sf(\"https://raw.githubusercontent.com/R-CoderDotCom/data/main/shapefile_spain/spain.geojson\") %>% \n  mutate(name = forcats::fct_reorder(name, desc(unemp_rate)))\n\ng1 <- map_ %>% \n  ggplot() +\n  geom_sf(color = \"white\", aes(fill = unemp_rate)) +\n  geom_sf_text(aes(label = name), size = 2) +\n  scale_fill_gradient2(low = \"brown\", high = \"green\", midpoint = 16) +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text = element_blank(), axis.title = element_blank(), panel.grid = element_blank())\n\ng2 <- map_ %>% \n  ggplot(aes(x = unemp_rate, y = name, fill = unemp_rate)) +\n  geom_col() + \n  scale_fill_gradient2(low = \"brown\", high = \"green\", midpoint = 16) +\n  geom_text(aes(label = name, x = .5, hjust = 0)) +\n  geom_text(aes(label = unemp_rate), nudge_x = - .5, hjust = 1) +\n  theme_void() +\n  theme(legend.position = \"none\")\n\ng1 + inset_element(g2, 0, .2, .9, 1)\n\n\n"
},
{
"QuestionId": "76382104",
"QuestionTitle": "android app LocalDate alternative for older API level",
"QuestionBody": "I am building a calendar app and mostly in my code I use LocalDate to set my RecyclerView and some more functions.\nI have a tablet that it's android version is 7.1.1, so it cant run anything in my code related to LocalDate.\nI want to contest my self and make my app run to min SDK 16. Are there any alternatives for LocalDate for my code? I also use Calendar in my code but for my RecyclerView is almost the triple code to do same task. Any other suggestion would be apreciated.\n",
"AnswerId": "76383359",
"AnswerBody": "If you want to have Java 8+ features available in lower Android version, you can use one of the following options:\n\nimport the ThreeTen Android Backport (ABP)\nmake use of Android API Desugaring\n\nWith (one of) these two, you can use nearly all of the classes and functions of java.time in Android API Levels < 26, including LocalDate.\n"
},
{
"QuestionId": "76383806",
"QuestionTitle": "I cant build my spring-boot multi module project with SAM",
"QuestionBody": "When running SAM build, I get a dependency error on the module that depends on another local module within my project. From mvn or IntelliJ I have no problems, but when i execute SAM build, i got an error of notFound symbols and classses.\n\n    Build Failed\n    Error: JavaMavenWorkflow:MavenBuild - Maven Failed: [INFO] Scanning for projects...\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Reactor Build Order:\n    [INFO]\n    [INFO] backend                                                            [pom]\n    [INFO] Api                                                                [jar]\n    [INFO] Register                                                           [jar]\n    [INFO]\n    [INFO] ------------------------< com.backend:backend >-------------------------\n    [INFO] Building backend 0.0.1-SNAPSHOT                                    [1/3]\n    [INFO] --------------------------------[ pom ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:3.2.0:clean (default-clean) @ backend ---\n    [INFO]\n    [INFO] --- spring-boot-maven-plugin:3.0.6:repackage (repackage) @ backend ---\n    [INFO]\n    [INFO] --- maven-install-plugin:3.0.1:install (default-install) @ backend ---\n    [INFO] Installing /tmp/tmptflbmqgd/pom.xml to /home/laingard/.m2/repository/com/backend/backend/0.0.1-SNAPSHOT/backend-0.0.1-SNAPSHOT.pom\n    [INFO]\n    [INFO] --------------------------< com.backend:Api >---------------------------\n    [INFO] Building Api 0.0.1-SNAPSHOT                                        [2/3]\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:3.2.0:clean (default-clean) @ Api ---\n    [INFO] Deleting /tmp/tmptflbmqgd/Api/target\n    [INFO]\n    [INFO] --- maven-resources-plugin:3.3.1:resources (default-resources) @ Api ---\n    [INFO] Copying 0 resource from src/main/resources to target/classes\n    [INFO] skip non existing resourceDirectory /tmp/tmptflbmqgd/Api/config\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.10.1:compile (default-compile) @ Api ---\n    [INFO] Changes detected - recompiling the module!\n    [INFO] Compiling 93 source files to /tmp/tmptflbmqgd/Api/target/classes\n    [INFO]\n    [INFO] --- maven-resources-plugin:3.3.1:testResources (default-testResources) @ Api ---\n    [INFO] skip non existing resourceDirectory /tmp/tmptflbmqgd/Api/src/test/resources\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.10.1:testCompile (default-testCompile) @ Api ---\n    [INFO] Changes detected - recompiling the module!\n    [INFO]\n    [INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ Api ---\n    [INFO] Tests are skipped.\n    [INFO]\n    [INFO] --- maven-jar-plugin:3.3.0:jar (default-jar) @ Api ---\n    [INFO] Building jar: /tmp/tmptflbmqgd/Api/target/Api-0.0.1-SNAPSHOT.jar\n    [INFO]\n    [INFO] --- spring-boot-maven-plugin:3.0.6:repackage (repackage) @ Api ---\n    [INFO] Replacing main artifact with repackaged archive\n    [INFO]\n    [INFO] --- maven-install-plugin:3.0.1:install (default-install) @ Api ---\n    [INFO] Installing /tmp/tmptflbmqgd/Api/pom.xml to /home/laingard/.m2/repository/com/backend/Api/0.0.1-SNAPSHOT/Api-0.0.1-SNAPSHOT.pom\n    [INFO] Installing /tmp/tmptflbmqgd/Api/target/Api-0.0.1-SNAPSHOT.jar to /home/laingard/.m2/repository/com/backend/Api/0.0.1-SNAPSHOT/Api-0.0.1-SNAPSHOT.jar\n    [INFO]\n    [INFO] ------------------------< com.backend:Register >------------------------\n    [INFO] Building Register 0.0.1-SNAPSHOT                                   [3/3]\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:3.2.0:clean (default-clean) @ Register ---\n    [INFO] Deleting /tmp/tmptflbmqgd/Register/target\n    [INFO]\n    [INFO] --- maven-resources-plugin:3.3.1:resources (default-resources) @ Register ---\n    [INFO] Copying 0 resource from src/main/resources to target/classes\n    [INFO] skip non existing resourceDirectory /tmp/tmptflbmqgd/Register/config\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.10.1:compile (default-compile) @ Register ---\n    [INFO] Changes detected - recompiling the module!\n    [INFO] Compiling 9 source files to /tmp/tmptflbmqgd/Register/target/classes\n    [INFO] -------------------------------------------------------------\n    [ERROR] COMPILATION ERROR :\n    [INFO] -------------------------------------------------------------\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[3,34] package com.careerwatch.Api.entity does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[4,37] package com.careerwatch.Api.exception does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[5,38] package com.careerwatch.Api.repository does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[18,19] cannot find symbol\n      symbol:   class UserRepository\n      location: class com.careerwatch.register.service.RegisterServiceImpl\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[3,34] package com.careerwatch.Api.entity does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[4,38] package com.careerwatch.Api.repository does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/mapper/RegisterDtoMapper.java:[3,34] package com.careerwatch.Api.entity does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[15,1] cannot find symbol\n      symbol:   class UserRepository\n      location: class com.careerwatch.register.service.RegisterServiceImpl\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/mapper/RegisterDtoMapper.java:[13,12] cannot find symbol\n      symbol:   class User\n      location: class com.careerwatch.register.mapper.RegisterDtoMapper\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[26,5] cannot find symbol\n      symbol:   class UserRepository\n      location: class com.careerwatch.register.jwt.JwtService\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[34,33] cannot find symbol\n      symbol:   class User\n      location: class com.careerwatch.register.jwt.JwtService\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[66,47] cannot find symbol\n      symbol:   class User\n      location: class com.careerwatch.register.jwt.JwtService\n    [INFO] 12 errors\n    [INFO] -------------------------------------------------------------\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Reactor Summary for backend 0.0.1-SNAPSHOT:\n    [INFO]\n    [INFO] backend ............................................ SUCCESS [  0.565 s]\n    [INFO] Api ................................................ SUCCESS [  3.314 s]\n    [INFO] Register ........................................... FAILURE [  0.534 s]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD FAILURE\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time:  4.575 s\n    [INFO] Finished at: 2023-06-01T12:51:53-03:00\n    [INFO] ------------------------------------------------------------------------\n    [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project Register: Compilation failure: Compilation failure:\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[3,34] package com.careerwatch.Api.entity does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[4,37] package com.careerwatch.Api.exception does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[5,38] package com.careerwatch.Api.repository does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[18,19] cannot find symbol\n    [ERROR]   symbol:   class UserRepository\n    [ERROR]   location: class com.careerwatch.register.service.RegisterServiceImpl\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[3,34] package com.careerwatch.Api.entity does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[4,38] package com.careerwatch.Api.repository does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/mapper/RegisterDtoMapper.java:[3,34] package com.careerwatch.Api.entity does not exist\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/service/RegisterServiceImpl.java:[15,1] cannot find symbol\n    [ERROR]   symbol:   class UserRepository\n    [ERROR]   location: class com.careerwatch.register.service.RegisterServiceImpl\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/mapper/RegisterDtoMapper.java:[13,12] cannot find symbol\n    [ERROR]   symbol:   class User\n    [ERROR]   location: class com.careerwatch.register.mapper.RegisterDtoMapper\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[26,5] cannot find symbol\n    [ERROR]   symbol:   class UserRepository\n    [ERROR]   location: class com.careerwatch.register.jwt.JwtService\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[34,33] cannot find symbol\n    [ERROR]   symbol:   class User\n    [ERROR]   location: class com.careerwatch.register.jwt.JwtService\n    [ERROR] /tmp/tmptflbmqgd/Register/src/main/java/com/careerwatch/register/jwt/JwtService.java:[66,47] cannot find symbol\n    [ERROR]   symbol:   class User\n    [ERROR]   location: class com.careerwatch.register.jwt.JwtService\n    [ERROR] -> [Help 1]\n    [ERROR]\n    [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n    [ERROR] Re-run Maven using the -X switch to enable full debug logging.\n    [ERROR]\n    [ERROR] For more information about the errors and possible solutions, please read the following articles:\n    [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n    [ERROR]\n    [ERROR] After correcting the problems, you can resume the build with the command\n    [ERROR]   mvn <args> -rf :Register\n\n\nThis is my template.yml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nGlobals:\n  Function:\n    Timeout: 30\n\nResources:\n  CareerWatchFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: .\n      Handler: com.careerwatch.Api.StreamLambdaHandler::handleRequest\n      Runtime: java17\n      AutoPublishAlias: production\n      SnapStart:\n        ApplyOn: PublishedVersions\n      Architectures:\n        - x86_64\n      MemorySize: 1024\n      Environment:\n        Variables:\n          POWERTOOLS_SERVICE_NAME: CareerWatchApi\n          DB_HOST: !Ref DBhost\n          DB_PORT: !Ref DBport\n          DB_NAME: !Ref DBname\n          DB_USERNAME: !Ref DBusername\n          DB_PASSWORD: !Ref DBpassword\n      Events:\n        HelloWorld:\n          Type: Api\n          Properties:\n            Path: /{proxy+}\n            Method: ANY\n  RegisterFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: .\n      Handler: com.careerwatch.register.RegisterLambdaHandler::handleRequest\n      Runtime: java17\n      AutoPublishAlias: production\n      SnapStart:\n        ApplyOn: PublishedVersions\n      Architectures:\n        - x86_64\n      MemorySize: 1024\n      Environment:\n        Variables:\n          POWERTOOLS_SERVICE_NAME: CareerWatchApi\n          DB_HOST: !Ref DBhost\n          DB_PORT: !Ref DBport\n          DB_NAME: !Ref DBname\n          DB_USERNAME: !Ref DBusername\n          DB_PASSWORD: !Ref DBpassword\n          SECRET_KEY: !Ref SecretKey\n      Events:\n        RegisterEndpoint:\n          Type: Api\n          Properties:\n            Path: /api/v1/register\n            Method: POST\nParameters:\n  DBhost:\n    Type: String\n    Default: ''\n    Description: Enter the DB host name or IP address\n  DBport:\n    Type: String\n    Default: ''\n    Description: Enter the DB port\n  DBname:\n    Type: String\n    Default: ''\n    Description: Enter the DB name\n  DBusername:\n    Type: String\n    Default: ''\n    Description: Enter the DB username\n  DBpassword:\n    Type: String\n    Default: ''\n    Description: Enter the DB password\n  SecretKey:\n      Type: String\n      Default: ''\n      Description: Enter the secret jwt key password\n\nI did mvn install and I checked the whole project structure, however with maven it works, but with sam build it doesn't.\n",
"AnswerId": "76384014",
"AnswerBody": "You stated in your comment:\n\"I am building a serverless application, deploying lambdas functions in api gateway.\"\nIf you are intereted in builidng a serverless app with Java, look at the PAM example. This example builds a complete serverless example that uses API Gateway, Lambda functions, Java SDK, a client app that uses Cognito to log in users, etc.\nHere is the overview illustration:\n\nAs well, this example uses the AWS CDK to standup various resources.\nThis does not use SAM.\nSee:\nCreate a photo asset management application that lets users manage photos using labels\n"
},
{
"QuestionId": "76384235",
"QuestionTitle": "Variable not updated in compose",
"QuestionBody": "I have a class in Kotlin (Jetpack compose) with a variable title and an exoplayer that updates the title.\nclass Player{\nvar title by mutableStatOf(\"value\")\n....\n\ntitle= \"new value\"\n...\n}\n\n@Composable\nfun Display(){\nval player = Player()\n\nplayer.title?.let{\nText(it)\n} \n}\n\nIn the user interface an instance of the class is created and the title displayed but it remains unchanged after being updated in the class. Can someone help?\n",
"AnswerId": "76385656",
"AnswerBody": "You forgot to remember the player instance. Here, when you change title, your composable is recomposed because it reads the title. But when it is recomposed, you create new instance of Player with the default title.\nval player = remember { Player() }\n\n"
},
{
"QuestionId": "76384397",
"QuestionTitle": "No loader is configured for \".html\" files: index.html Vitejs",
"QuestionBody": "Greetings I have problem. I am using Visual studio 2022 and created two projects there for one solution. One for back-end (ASP.NET) and the second one for fron-end (vuejs and vite). So here starts the problem. I used npm create vue@3 command to create vue project. And  its launched fine , but when I did same thing in folder of front-end in my sln project vite throws error what it can not find index.html file\nError:   Failed to scan for dependencies from entries:\n  D:/Projects/C#/DAINIS/vueapp/index.html\n\n  X [ERROR] No loader is configured for \".html\" files: index.html\n\n    <stdin>:1:7:\n      1 │ import \"D:/Projects/C#/DAINIS/vueapp/index.html\"\n        ╵        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n    at failureErrorWithLog (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:1638:15)\n    at D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:1050:25\n    at runOnEndCallbacks (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:1473:45)\n    at buildResponseToResult (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:1048:7)\n    at D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:1060:9\n    at new Promise (<anonymous>)\n    at requestCallbacks.on-end (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:1059:54)\n    at handleRequest (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:725:19)\n    at handleIncomingPacket (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:747:7)\n    at Socket.readFromStdout (D:\\Projects\\C#\\DAINIS\\vueapp\\node_modules\\esbuild\\lib\\main.js:675:7)\n\nJust in case I did not changed project it is as is.\nProject structure\nError dump example\nI tried solutions found here and here in stack overflow but still no luck\n",
"AnswerId": "76385670",
"AnswerBody": "The issue is the # symbol in your file path\nD:/Projects/C#/DAINIS/vueapp/\n\nI don't know the technical reason why this causes it to fail, but if you remove it, the project should run.\n"
},
{
"QuestionId": "76382075",
"QuestionTitle": "Saving an extremely long figure as pdf in R will cause all text invisible",
"QuestionBody": "R 4.2.1\npackage usage: netmeta 2.8-1\nIssue:\nIn netmeta package, the function forest() will create a forest plot. One need to know that forest() can generate a forest plot presenting the network inconsistency between direct and indirect comparisons.\nIn my case, I have an extremely large network, which will lead to more than 2000 comparisons. The forest plot describing network inconsistency will be VERY long in height.\nThe following script can only create \"part\" of the forest because the forest is too long.\npdf(\"filename.pdf\",width = 12, height = 200)\nforest(out, show = \"all\")\ndev.off()\n\nI tried to increase the height to make all the content in this document. But any value above 200 in height will generate a \"blank\" pdf (but I think the text should be there because the file size is 240KB rather than a NULL file which only takes 4KB in my disk).\nI have no idea how to make the text visible in pdf and keep all content in this file at the same time. Any suggestion will be appreciated. Thank you.\n",
"AnswerId": "76383557",
"AnswerBody": "PDF 1.x has an implementation limit for the page size:\n\nThe minimum page size should be 3 by 3 units in default user space; the maximum should be 14,400 by 14,400 units. In versions of PDF earlier than 1.6, the size of the default user space unit was fixed at 1⁄72 inch, yielding a minimum of approximately 0.04 by 0.04 inch and a maximum of 200 by 200 inches. Beginning with PDF 1.6, the size of the unit may be set on a page-by-page basis; the default remains at 1/72 inch.\n\n(ISO 32000-1, Annex C.2 Architectural limits)\nIf R doesn't adjust the default user space unit size in case of large width or height arguments, it generates PDFs that go beyond these limits whenever you set either argument to a value greater than 200.\nAs those limits originate from the Adobe implementation of the PDF spec, i.e. Adobe Acrobat, tests with Adobe software may indeed show issues...\n"
},
{
"QuestionId": "76382178",
"QuestionTitle": "Complex Cocatenation in gsheets",
"QuestionBody": "I have a table to entries where I am trying to concatenate few columns and the concatenation should not happen when any one of the required values are empty\nHere is the spreadsheet. https://docs.google.com/spreadsheets/d/1lQUG4TmFTKghV8r6Gg3EilLx6zyuTkrNfnCatRVWp_U/edit#gid=189998773\nI did try to use the formula =MAP(scan(,D5:D,I5:I,lambda(a,b,d,if(or(a=\"\",b=\"\",d=\"\",and(e=\"\",f=\"\")),,if(f<>\"\",f,e)&\" \"&a&\" \"&b&\" \"&c))),D5:D,H5:H,I5:I,J5:J,K5:K,lambda(a,b,c,e,f,if(or(a=\"\",b=\"\",c=\"\",and(e=\"\",f=\"\")),,if(f<>\"\",f,e)&\" \"&a&\" \"&b&\" \"&c)))\nBut not able to get the the desired output.\nPlease help!\n",
"AnswerId": "76383650",
"AnswerBody": "You can simplify your formula by omitting SCAN\n=MAP(D5:D,H5:H,I5:I,J5:J,K5:K,\n      LAMBDA(dd,hh,ii,jj,kk,\n       IF(OR(dd=\"\",hh=\"\",ii=\"\",AND(jj=\"\",kk=\"\")),,dd&\"-\"&hh&\"-\"&ii&\"-\"&if(kk<>\"\",kk,jj))))\n\n(for future reference: try naming your LAMBDAs accordingly)\n\n"
},
{
"QuestionId": "76385291",
"QuestionTitle": "Using glm in R for linear regression on a large dataframe - issues with column subsetting",
"QuestionBody": "I am trying to use glm in R using a dataframe containing ~ 1000 columns, where I want to select a specific independent variable and run as a loop for each of the 1000 columns representing the dependent variables.\nAs a test, the glm equation works perfectly fine when I specify a single column using df$col1 for both my dependent and independent variables.\nI can't seem to correctly subset a range of columns (below) and I keep getting this error, no matter how many ways I try to format the df:\n'data' must be a data.frame, environment, or list\n\nWhat I tried:\ndf = my df\ncols <- df[, 20:1112]\n\nfor (i in cols{\n    glm <- glm(df$col1 ~ ., data=df, family=gaussian)\n}\n\n",
"AnswerId": "76385673",
"AnswerBody": "It would be more idiomatic to do:\npredvars <- names(df)[20:1112]\nglm_list <- list()  ## presumably you want to save the results??\nfor (pv in predvars) {\n    glm_list[[pv]] <- glm(reformulate(pv, response = \"col1\"), \n       data=df, family=gaussian)\n}\n\nIn fact, if you really just want to do a Gaussian GLM then it will be slightly faster to use\nlm(reformulate(pv, response = \"col1\"), data = df)\n\nin the loop instead.\nIf you want to get fancy:\nformlist <- lapply(predvars, reformulate, response = \"col1\")\nlm_list <- lapply(formlist, lm, data = df)\nnames(lm_list) <- predvars\n\n"
},
{
"QuestionId": "76381069",
"QuestionTitle": "Firebase Hosting Can't Add Domain",
"QuestionBody": "When I try to add a custom domain to Firebase Hosting, I encounter this error. Nothing happens when I click Continue.\nUpon clicking continue, it loads for a few seconds, and then the same screen persists.\n\nWhen I checked the console, HTTP requests are responded with 503 Service Unable.\n\n",
"AnswerId": "76383663",
"AnswerBody": "firebaser here\nWhile we did make some changes to our custom domain provisioning this week, it seems that you're hitting another problem.\nIs any part of this on a Google Workspace account by any chance? If that is the case, your domain may not allow the search console. You'll want to reach out to their GSuite organization admin/owner to enable the Search Console. See Turn Google Search Console on or off for users for complete instructions.\n"
},
{
"QuestionId": "76383791",
"QuestionTitle": "Google Sheets vlookup to prioritize a column",
"QuestionBody": "Wonder if anyone can help.\nOn the attached on tab 2 I'm trying to do a vlookup to tab 1 to use column 1 'code' to bring back column 3 'email'. But if there is more than 1 match in column 1 for 'code', prioritize the row that has Level 1 in column 2 in tab 1. For example, there are two code 20, on tab 1 but the formula should bring back row 5 - test4@live.co.uk rather than row 2 - test1@live.co.uk as row 5 has Level 1 in column 2. If there is no duplicate code in column 1 just bring back the first result in column 1.\nI've got a formula already in column 3 in tab 2 but it isn't working as it doesn't bring back anything if there isn't level 1 in column 2, see column 4. On tab 3, I've got an example of what the right result should be. This can be either a vlookup, a match & index or what ever works as long as its in google sheets.\nAddition to the above, it needs to be an array based on something being in column 1 and have an iferror, just in case. Thanks.\nLink to sheet\n",
"AnswerId": "76384034",
"AnswerBody": "You may try:\n=index(ifna(vlookup(A2:A,sort(LookTable!A:C,2,),3,)))\n\n\nthe above code prioritizes Level 1 over blank level. Not sure if there's goin' to be 10s of levels and I have to choose say level 15 over level 8 or so; then use this alternate variant\n=index(ifna(vlookup(A2:A,sort(LookTable!A2:C,--ifna(regexextract(LookTable!B2:B,\"\\d+\")),),3,)))\n\n"
},
{
"QuestionId": "76384189",
"QuestionTitle": "Sort Rows Based on Tuple Index",
"QuestionBody": "Overview:\nPandas dataframe with a tuple index and corresponding 'Num' column:\nIndex                               Num\n\n('Total', 'A')                      23\n\n('Total', 'A', 'Pandas')            3\n\n('Total', 'A', 'Row')               7\n\n('Total', 'A', 'Tuple')             13\n\n('Total', 'B')                      35\n\n('Total', 'B', 'Rows')              12\n\n('Total', 'B', 'Two')               23\n\n('Total', 'C')                      54\n\n('Total', 'C', 'Row')               54\n\nTotal                               112\n\nThe index and 'Num' column are already sorted with a lambda function by Alphabetical Order and based on the length of tuple elements:\ndataTable = dataTable.reindex(sorted(dataTable.index, key=lambda x: (not isinstance(x, tuple), x)))\n\nProblem:\nNow, I want to sort only the 3rd tuple index element based on it's corresponding 'Num' value. Here would be an updated example of the dataframe:\nIndex                               Num\n\n('Total', 'A')                      23\n\n('Total', 'A', 'Tuple')             13\n\n('Total', 'A', 'Row')               7\n\n('Total', 'A', 'Pandas')            3\n\n('Total', 'B')                      35\n\n('Total', 'B', 'Two')               23\n\n('Total', 'B', 'Rows')              12\n\n('Total', 'C')                      54\n\n('Total', 'C', 'Row')               54\n\nTotal                               112\n\nQuestion:\nWhat Lambda function can achieve this?\n",
"AnswerId": "76385755",
"AnswerBody": "You can try:\ndef fn(x):\n    vals = x.sort_values(by='Num', ascending=False)\n    df.loc[x.index] = vals.values\n\nm = df['Index'].apply(len).eq(3)\ndf[m].groupby(df.loc[m, 'Index'].str[1], group_keys=False).apply(fn)\n\nprint(df)\n\nPrints:\n                Index  Num\n0          (Total, A)   23\n1   (Total, A, Tuple)   13\n2     (Total, A, Row)    7\n3  (Total, A, Pandas)    3\n4          (Total, B)   35\n5     (Total, B, Two)   23\n6    (Total, B, Rows)   12\n7          (Total, C)   54\n8     (Total, C, Row)   54\n9               Total  112\n\n\nInitial df:\n                Index  Num\n0          (Total, A)   23\n1  (Total, A, Pandas)    3\n2     (Total, A, Row)    7\n3   (Total, A, Tuple)   13\n4          (Total, B)   35\n5    (Total, B, Rows)   12\n6     (Total, B, Two)   23\n7          (Total, C)   54\n8     (Total, C, Row)   54\n9               Total  112\n\n"
},
{
"QuestionId": "76382968",
"QuestionTitle": "RouteChildrenProps is not an exported member",
"QuestionBody": "I am getting the below error pointing to 'RouteChildrenProps':\n\nI am just trying to get through a tutorial but I got stuck here.  Here is the full code:\nimport React from 'react';\nimport { Route, RouteChildrenProps, Routes } from 'react-router';\nimport routes from './config/routes';\n\nexport interface IApplicationProps {}\n\nconst Application: React.FunctionComponent<IApplicationProps> = (props) => {\n  return (\n    <Routes>\n      {routes.map((route, index) => {\n        return <Route \n          key={index} \n          exact={route.exact} \n          path={route.path} \n          render={(routeProps: RouteChildrenProps<any>) =>\n            <route.component {...routeProps} />} />;\n          }\n      )}\n    </Routes>\n  );\n};\n\nexport default Application;\n\nThe tutorial itself did not encounter this issue, so I'm hoping someone here can me solve this.\n",
"AnswerId": "76384045",
"AnswerBody": "React-Router v6 removed route props, these are a v4/5 export. The Route component API changed significantly from v4/5 to v6. There are no route props, no exact prop since routes are now always exactly matched, and all routed content is rendered on a single element prop taking a React.ReactNode, e.g. JSX, value.\nimport React from 'react';\nimport { Route, Routes } from 'react-router';\nimport routes from './config/routes';\n\nexport interface IApplicationProps {}\n\nconst Application: React.FunctionComponent<IApplicationProps> = (props) => {\n  return (\n    <Routes>\n      {routes.map((route) => {\n        const Component = route.component;\n        return (\n          <Route \n            key={route.path} \n            path={route.path} \n            element={<Component />}\n          />\n        );\n      })}\n    </Routes>\n  );\n};\n\nIf any of the routed component need to access what was previously passed via props, they should use the provided React hooks: useNavigate for navigate function that replaced useHistory, useParams for route path parameters, useLocation for the location object, etc.\n"
},
{
"QuestionId": "76381810",
"QuestionTitle": "Call Rust DLL function to spawn new thread from C wrapper and return the main thread back to C",
"QuestionBody": "I have a use case where C wrapper is loading the Rust DLL. Both C and Rust have infinate loop.\nC code\n#include \"main.h\"\n#include <stdio.h>\n#include \"addition.h\"\n#include <time.h>\n#include <unistd.h>\n\nextern void spawn_thread_and_get_back(); // Rust function :\nextern void keep_calling_rust_fn(); // Rust function :\n\nint main()\n{\n    spawn_thread_and_get_back(); // This should spawn thread with infinite loop in rust\n\n    int sleep_seconds = 7;\n    \n    \n    while(1){\n      \n        printf(\"Calling rust function);\n\n        keep_calling_rust_fn(); // Call rust function\n    }\n}\n\nand here is the rust lib code\n\nasync fn counter() {\n    loop {\n        println!(\"I am getting called by Tokio every 2 seconds\");\n        // Sleep for 1 second\n        sleep(Duration::from_secs(2)).await;\n    }\n}\n\n#[tokio::main]\nasync fn runForever() {\n    let counterTask = tokio::spawn(\n        counter()\n    );\n    tokio::try_join!(counterTask);\n\n}\n\nuse std::thread;\n\n#[no_mangle]\npub unsafe extern \"C\" fn spawn_thread_and_get_back() {\n    let handle = thread::spawn(move || {\n        // some work here\n        println!(\"Trying to create new thread for Tokio runtime\");\n        runForever();\n\n    });\n    handle.join();\n}\n\n#[no_mangle]\npub unsafe extern \"C\" fn keep_calling_rust_fn() {\n    println!(\"I am getting called by C wrapper every 7 second\");\n    someRandomPrintTask();\n}\n\n\nasync fn printTask(task_number: u32) {\n    println!(\"Print task {} -\", task_number);\n}\n\nasync fn someRandomPrintTask() {\n    let printTask = tokio::spawn(\n        printTask(10)\n    );\n    tokio::try_join!(printTask);\n}\n\n\nThe issue I am facing is once I call the spawn_thread_and_get_back() from C and never get the thread back to execute while loop in C\nI would like to call the rust DLL from C and spawn seperate thread for rust. And the idea is the caller thread from C will get free once it initializes the rust forever loop thread.\n",
"AnswerId": "76383698",
"AnswerBody": "Thanks everyone, After discussing in the comments above, here is the working answer. We just need to change Rust code\n\nasync fn counter() {\n    loop {\n        println!(\"I am getting called by Tokio every 2 seconds\");\n        // Sleep for 1 second\n        sleep(Duration::from_secs(2)).await;\n    }\n}\n\n#[tokio::main]\nasync fn runForever() {\n    let counterTask = tokio::spawn(\n        counter()\n    );\n    tokio::try_join!(counterTask);\n\n}\n\nuse std::thread;\n\n#[no_mangle]\npub unsafe extern \"C\" fn spawn_thread_and_get_back() {\n    let handle = thread::spawn(move || {\n        // some work here\n        println!(\"Trying to create new thread for Tokio runtime\");\n        runForever();\n\n    });\n    \n\n   `handle.join();` *** Update - Removed this as it was blocking the main thread as it was waiting for handle to finish ***\n\n}\n\n#[no_mangle]\npub unsafe extern \"C\" fn keep_calling_rust_fn() {\n    println!(\"I am getting called by C wrapper every 7 second\");\n    someRandomPrintTask();\n}\n\n\nasync fn printTask(task_number: u32) {\n    println!(\"Print task {} -\", task_number);\n}\n\n#[tokio::main]  *** Update - Added the decorater here ***\nasync fn someRandomPrintTask() {\n    let printTask = tokio::spawn(\n        printTask(10)\n    );\n    tokio::try_join!(printTask);\n}\n\n\n"
},
{
"QuestionId": "76383253",
"QuestionTitle": "How to show result of static model (=plain number) in Xcos?",
"QuestionBody": "I add two numbers in Xcos and would like to show the result in the diagram. I managed to do so using a CSCOPE element and adding an extra CLOCK_c element:\n\nHowever, I would prefer a display element that simply shows the number:\n\n=> What component could I use for that?\nIf there is no existing display component for plain numbers, how can I create one?\nRelated questions:\nHow to show results of a static model in Modeling view with OpenModelica?\nhttps://softwarerecs.stackexchange.com/questions/87166/python-framework-for-block-simulations-with-graphical-user-interface-like-openm\nxcos example file:\nxcos_demo.xcos\n<?xml version=\"1.0\" ?>\n<XcosDiagram debugLevel=\"0\" finalIntegrationTime=\"30.0\" integratorAbsoluteTolerance=\"1.0E-6\" integratorRelativeTolerance=\"1.0E-6\" toleranceOnTime=\"1.0E-10\" maxIntegrationTimeInterval=\"100001.0\" maximumStepSize=\"0.0\" realTimeScaling=\"0.0\" solver=\"1.0\" background=\"-1\" gridEnabled=\"1\" title=\"Untitled\"><!--Xcos - 2.0 - scilab-2023.1.0 - 20230523 0919-->\n  <Array as=\"context\" scilabClass=\"String[]\"></Array>\n  <mxGraphModel as=\"model\">\n    <root>\n      <mxCell id=\"0:1:0\"/>\n      <mxCell id=\"0:2:0\" parent=\"0:1:0\"/>\n      <BasicBlock id=\"7ca5d227:1887764bffb:-7ff9\" parent=\"0:2:0\" interfaceFunctionName=\"CONST_m\" blockType=\"d\" dependsOnU=\"0\" dependsOnT=\"0\" simulationFunctionName=\"cstblk4_m\" simulationFunctionType=\"C_OR_FORTRAN\" style=\"CONST_m\">\n        <ScilabString as=\"exprs\" height=\"1\" width=\"1\">\n          <data line=\"0\" column=\"0\" value=\"1\"/>\n        </ScilabString>\n        <ScilabDouble as=\"realParameters\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"integerParameters\" height=\"0\" width=\"0\"/>\n        <Array as=\"objectsParameters\" scilabClass=\"ScilabList\">\n          <ScilabDouble height=\"1\" width=\"1\">\n            <data line=\"0\" column=\"0\" realPart=\"1.0\"/>\n          </ScilabDouble>\n        </Array>\n        <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n        <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n        <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n        <mxGeometry as=\"geometry\" x=\"170.0\" y=\"270.0\" width=\"40.0\" height=\"40.0\"/>\n      </BasicBlock>\n      <ExplicitOutputPort id=\"7ca5d227:1887764bffb:-7ff8\" parent=\"7ca5d227:1887764bffb:-7ff9\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.0\" style=\"ExplicitOutputPort;align=right;verticalAlign=middle;spacing=10.0;rotation=0\" value=\"\"/>\n      <BigSom id=\"7ca5d227:1887764bffb:-7ff1\" parent=\"0:2:0\" interfaceFunctionName=\"BIGSOM_f\" blockType=\"c\" dependsOnU=\"1\" dependsOnT=\"0\" simulationFunctionName=\"sum\" simulationFunctionType=\"TYPE_2\" style=\"BIGSOM_f\">\n        <ScilabString as=\"exprs\" height=\"1\" width=\"1\">\n          <data line=\"0\" column=\"0\" value=\"[1;1]\"/>\n        </ScilabString>\n        <ScilabDouble as=\"realParameters\" height=\"1\" width=\"2\">\n          <data line=\"0\" column=\"0\" realPart=\"1.0\"/>\n          <data line=\"0\" column=\"1\" realPart=\"1.0\"/>\n        </ScilabDouble>\n        <ScilabDouble as=\"integerParameters\" height=\"0\" width=\"0\"/>\n        <Array as=\"objectsParameters\" scilabClass=\"ScilabList\"/>\n        <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n        <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n        <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n        <mxGeometry as=\"geometry\" x=\"430.0\" y=\"310.0\" width=\"40.0\" height=\"60.0\"/>\n      </BigSom>\n      <ExplicitInputPort id=\"7ca5d227:1887764bffb:-7ff0\" parent=\"7ca5d227:1887764bffb:-7ff1\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"-1\" initialState=\"0.0\" style=\"ExplicitInputPort;align=left;verticalAlign=middle;spacing=10.0;rotation=0\" value=\"\"/>\n      <ExplicitInputPort id=\"7ca5d227:1887764bffb:-7fef\" parent=\"7ca5d227:1887764bffb:-7ff1\" ordering=\"2\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"-1\" initialState=\"0.0\" style=\"ExplicitInputPort;align=left;verticalAlign=middle;spacing=10.0;rotation=0\" value=\"\"/>\n      <ExplicitOutputPort id=\"7ca5d227:1887764bffb:-7fee\" parent=\"7ca5d227:1887764bffb:-7ff1\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"-1\" initialState=\"0.0\" style=\"ExplicitOutputPort;align=right;verticalAlign=middle;spacing=10.0;rotation=0\" value=\"\"/>\n      <BasicBlock id=\"7ca5d227:1887764bffb:-7fec\" parent=\"0:2:0\" interfaceFunctionName=\"CONST_m\" blockType=\"d\" dependsOnU=\"0\" dependsOnT=\"0\" simulationFunctionName=\"cstblk4_m\" simulationFunctionType=\"C_OR_FORTRAN\" style=\"CONST_m\">\n        <ScilabString as=\"exprs\" height=\"1\" width=\"1\">\n          <data line=\"0\" column=\"0\" value=\"1\"/>\n        </ScilabString>\n        <ScilabDouble as=\"realParameters\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"integerParameters\" height=\"0\" width=\"0\"/>\n        <Array as=\"objectsParameters\" scilabClass=\"ScilabList\">\n          <ScilabDouble height=\"1\" width=\"1\">\n            <data line=\"0\" column=\"0\" realPart=\"1.0\"/>\n          </ScilabDouble>\n        </Array>\n        <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n        <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n        <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n        <mxGeometry as=\"geometry\" x=\"170.0\" y=\"360.0\" width=\"40.0\" height=\"40.0\"/>\n      </BasicBlock>\n      <ExplicitOutputPort id=\"7ca5d227:1887764bffb:-7feb\" parent=\"7ca5d227:1887764bffb:-7fec\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.0\" style=\"ExplicitOutputPort;align=right;verticalAlign=middle;spacing=10.0;rotation=0\" value=\"\"/>\n      <BasicBlock id=\"7ca5d227:1887764bffb:-7fd6\" parent=\"0:2:0\" interfaceFunctionName=\"CSCOPE\" blockType=\"c\" dependsOnU=\"1\" dependsOnT=\"0\" simulationFunctionName=\"cscope\" simulationFunctionType=\"C_OR_FORTRAN\" style=\"CSCOPE;verticalLabelPosition=bottom;verticalAlign=top;spacing=2;displayedLabel=\">\n        <ScilabString as=\"exprs\" height=\"10\" width=\"1\">\n          <data line=\"0\" column=\"0\" value=\"1 3 5 7 9 11 13 15\"/>\n          <data line=\"1\" column=\"0\" value=\"-1\"/>\n          <data line=\"2\" column=\"0\" value=\"[]\"/>\n          <data line=\"3\" column=\"0\" value=\"[600;400]\"/>\n          <data line=\"4\" column=\"0\" value=\"-15\"/>\n          <data line=\"5\" column=\"0\" value=\"15\"/>\n          <data line=\"6\" column=\"0\" value=\"30\"/>\n          <data line=\"7\" column=\"0\" value=\"20\"/>\n          <data line=\"8\" column=\"0\" value=\"0\"/>\n          <data line=\"9\" column=\"0\" value=\"\"/>\n        </ScilabString>\n        <ScilabDouble as=\"realParameters\" height=\"1\" width=\"4\">\n          <data line=\"0\" column=\"0\" realPart=\"0.0\"/>\n          <data line=\"0\" column=\"1\" realPart=\"-15.0\"/>\n          <data line=\"0\" column=\"2\" realPart=\"15.0\"/>\n          <data line=\"0\" column=\"3\" realPart=\"30.0\"/>\n        </ScilabDouble>\n        <ScilabInteger as=\"integerParameters\" height=\"1\" width=\"15\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"-1\"/>\n          <data line=\"0\" column=\"1\" value=\"1\"/>\n          <data line=\"0\" column=\"2\" value=\"20\"/>\n          <data line=\"0\" column=\"3\" value=\"1\"/>\n          <data line=\"0\" column=\"4\" value=\"3\"/>\n          <data line=\"0\" column=\"5\" value=\"5\"/>\n          <data line=\"0\" column=\"6\" value=\"7\"/>\n          <data line=\"0\" column=\"7\" value=\"9\"/>\n          <data line=\"0\" column=\"8\" value=\"11\"/>\n          <data line=\"0\" column=\"9\" value=\"13\"/>\n          <data line=\"0\" column=\"10\" value=\"15\"/>\n          <data line=\"0\" column=\"11\" value=\"-1\"/>\n          <data line=\"0\" column=\"12\" value=\"-1\"/>\n          <data line=\"0\" column=\"13\" value=\"600\"/>\n          <data line=\"0\" column=\"14\" value=\"400\"/>\n        </ScilabInteger>\n        <Array as=\"objectsParameters\" scilabClass=\"ScilabList\"/>\n        <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n        <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n        <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n        <mxGeometry as=\"geometry\" x=\"610.0\" y=\"320.0\" width=\"40.0\" height=\"40.0\"/>\n      </BasicBlock>\n      <ExplicitInputPort id=\"7ca5d227:1887764bffb:-7fd5\" parent=\"7ca5d227:1887764bffb:-7fd6\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"-1\" initialState=\"0.0\" style=\"ExplicitInputPort;align=left;verticalAlign=middle;spacing=10.0;rotation=0\" value=\"\"/>\n      <ControlPort id=\"7ca5d227:1887764bffb:-7fd4\" parent=\"7ca5d227:1887764bffb:-7fd6\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.0\" style=\"ControlPort;align=center;verticalAlign=top;spacing=10.0;rotation=90\" value=\"\"/>\n      <BasicBlock id=\"7ca5d227:1887764bffb:-7fd1\" parent=\"0:2:0\" interfaceFunctionName=\"CLOCK_c\" blockType=\"h\" dependsOnU=\"0\" dependsOnT=\"0\" simulationFunctionName=\"csuper\" simulationFunctionType=\"DEFAULT\" style=\"CLOCK_c\">\n        <ScilabDouble as=\"exprs\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"realParameters\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"integerParameters\" height=\"0\" width=\"0\"/>\n        <Array as=\"objectsParameters\" scilabClass=\"ScilabList\"/>\n        <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n          <data line=\"0\" column=\"0\" value=\"0\"/>\n        </ScilabInteger>\n        <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n        <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n        <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n        <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n        <mxGeometry as=\"geometry\" x=\"610.0\" y=\"180.0\" width=\"40.0\" height=\"40.0\"/>\n        <SuperBlockDiagram as=\"child\" background=\"-1\" gridEnabled=\"1\" title=\"\">\n          <Array as=\"context\" scilabClass=\"String[]\"></Array>\n          <mxGraphModel as=\"model\">\n            <root>\n              <mxCell id=\"7ca5d227:1887764bffc:-7fd1\"/>\n              <mxCell id=\"7ca5d227:1887764bffd:-7fd1\" parent=\"7ca5d227:1887764bffc:-7fd1\"/>\n              <EventOutBlock id=\"7ca5d227:1887764bffb:-7fbc\" parent=\"7ca5d227:1887764bffd:-7fd1\" interfaceFunctionName=\"CLKOUT_f\" blockType=\"d\" dependsOnU=\"0\" dependsOnT=\"0\" simulationFunctionName=\"output\" simulationFunctionType=\"DEFAULT\" style=\"\">\n                <ScilabString as=\"exprs\" height=\"1\" width=\"1\">\n                  <data line=\"0\" column=\"0\" value=\"1\"/>\n                </ScilabString>\n                <ScilabDouble as=\"realParameters\" height=\"0\" width=\"0\"/>\n                <ScilabInteger as=\"integerParameters\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"1\"/>\n                </ScilabInteger>\n                <Array as=\"objectsParameters\" scilabClass=\"ScilabList\"/>\n                <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"0\"/>\n                </ScilabInteger>\n                <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"0\"/>\n                </ScilabInteger>\n                <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n                <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n                <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n                <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n                <mxGeometry as=\"geometry\" x=\"399.0\" y=\"162.0\" width=\"20.0\" height=\"20.0\"/>\n              </EventOutBlock>\n              <ControlPort id=\"7ca5d227:1887764bffb:-7fbb\" parent=\"7ca5d227:1887764bffb:-7fbc\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.0\" style=\"\" value=\"\"/>\n              <BasicBlock id=\"7ca5d227:1887764bffb:-7fba\" parent=\"7ca5d227:1887764bffd:-7fd1\" interfaceFunctionName=\"EVTDLY_c\" blockType=\"d\" dependsOnU=\"0\" dependsOnT=\"0\" simulationFunctionName=\"evtdly4\" simulationFunctionType=\"C_OR_FORTRAN\" style=\"\">\n                <ScilabString as=\"exprs\" height=\"2\" width=\"1\">\n                  <data line=\"0\" column=\"0\" value=\"0.1\"/>\n                  <data line=\"1\" column=\"0\" value=\"0.1\"/>\n                </ScilabString>\n                <ScilabDouble as=\"realParameters\" height=\"1\" width=\"2\">\n                  <data line=\"0\" column=\"0\" realPart=\"0.1\"/>\n                  <data line=\"0\" column=\"1\" realPart=\"0.1\"/>\n                </ScilabDouble>\n                <ScilabDouble as=\"integerParameters\" height=\"0\" width=\"0\"/>\n                <Array as=\"objectsParameters\" scilabClass=\"ScilabList\"/>\n                <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"0\"/>\n                </ScilabInteger>\n                <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"0\"/>\n                </ScilabInteger>\n                <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n                <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n                <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n                <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n                <mxGeometry as=\"geometry\" x=\"320.0\" y=\"232.0\" width=\"40.0\" height=\"40.0\"/>\n              </BasicBlock>\n              <ControlPort id=\"7ca5d227:1887764bffb:-7fb9\" parent=\"7ca5d227:1887764bffb:-7fba\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.0\" style=\"\" value=\"\"/>\n              <CommandPort id=\"7ca5d227:1887764bffb:-7fb8\" parent=\"7ca5d227:1887764bffb:-7fba\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.1\" style=\"\" value=\"\"/>\n              <SplitBlock id=\"7ca5d227:1887764bffb:-7fb7\" parent=\"7ca5d227:1887764bffd:-7fd1\" interfaceFunctionName=\"CLKSPLIT_f\" blockType=\"d\" dependsOnU=\"0\" dependsOnT=\"0\" simulationFunctionName=\"split\" simulationFunctionType=\"DEFAULT\" style=\"\">\n                <ScilabDouble as=\"exprs\" height=\"0\" width=\"0\"/>\n                <ScilabDouble as=\"realParameters\" height=\"0\" width=\"0\"/>\n                <ScilabDouble as=\"integerParameters\" height=\"0\" width=\"0\"/>\n                <Array as=\"objectsParameters\" scilabClass=\"ScilabList\"/>\n                <ScilabInteger as=\"nbZerosCrossing\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"0\"/>\n                </ScilabInteger>\n                <ScilabInteger as=\"nmode\" height=\"1\" width=\"1\" intPrecision=\"sci_int32\">\n                  <data line=\"0\" column=\"0\" value=\"0\"/>\n                </ScilabInteger>\n                <ScilabDouble as=\"state\" height=\"0\" width=\"0\"/>\n                <ScilabDouble as=\"dState\" height=\"0\" width=\"0\"/>\n                <Array as=\"oDState\" scilabClass=\"ScilabList\"/>\n                <Array as=\"equations\" scilabClass=\"ScilabList\"/>\n                <mxGeometry as=\"geometry\" x=\"380.71066\" y=\"172.0\" width=\"0.3333333333333333\" height=\"0.3333333333333333\"/>\n              </SplitBlock>\n              <ControlPort id=\"7ca5d227:1887764bffb:-7fb6\" parent=\"7ca5d227:1887764bffb:-7fb7\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"0.0\" style=\"\" value=\"\"/>\n              <CommandPort id=\"7ca5d227:1887764bffb:-7fb5\" parent=\"7ca5d227:1887764bffb:-7fb7\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"-1.0\" style=\"\" value=\"\"/>\n              <CommandPort id=\"7ca5d227:1887764bffb:-7fb4\" parent=\"7ca5d227:1887764bffb:-7fb7\" ordering=\"2\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"-1.0\" style=\"\" value=\"\"/>\n              <CommandControlLink id=\"7ca5d227:1887764bffb:-7fb3\" parent=\"7ca5d227:1887764bffd:-7fd1\" source=\"7ca5d227:1887764bffb:-7fb8\" target=\"7ca5d227:1887764bffb:-7fb6\" style=\"\" value=\"\">\n                <mxGeometry as=\"geometry\">\n                  <mxPoint as=\"sourcePoint\" x=\"340.0\" y=\"226.29\"/>\n                  <Array as=\"points\">\n                    <mxPoint x=\"340.0\" y=\"172.0\"/>\n                  </Array>\n                  <mxPoint as=\"targetPoint\" x=\"380.71\" y=\"172.0\"/>\n                </mxGeometry>\n              </CommandControlLink>\n              <CommandControlLink id=\"7ca5d227:1887764bffb:-7fb2\" parent=\"7ca5d227:1887764bffd:-7fd1\" source=\"7ca5d227:1887764bffb:-7fb5\" target=\"7ca5d227:1887764bffb:-7fbb\" style=\"\" value=\"\">\n                <mxGeometry as=\"geometry\">\n                  <mxPoint as=\"sourcePoint\" x=\"380.71\" y=\"172.0\"/>\n                  <Array as=\"points\"></Array>\n                  <mxPoint as=\"targetPoint\" x=\"399.0\" y=\"172.0\"/>\n                </mxGeometry>\n              </CommandControlLink>\n              <CommandControlLink id=\"7ca5d227:1887764bffb:-7fb1\" parent=\"7ca5d227:1887764bffd:-7fd1\" source=\"7ca5d227:1887764bffb:-7fb4\" target=\"7ca5d227:1887764bffb:-7fb9\" style=\"\" value=\"\">\n                <mxGeometry as=\"geometry\">\n                  <mxPoint as=\"sourcePoint\" x=\"380.71\" y=\"172.0\"/>\n                  <Array as=\"points\">\n                    <mxPoint x=\"380.71\" y=\"302.0\"/>\n                    <mxPoint x=\"340.0\" y=\"302.0\"/>\n                  </Array>\n                  <mxPoint as=\"targetPoint\" x=\"340.0\" y=\"277.71\"/>\n                </mxGeometry>\n              </CommandControlLink>\n            </root>\n          </mxGraphModel>\n          <mxCell as=\"defaultParent\" id=\"7ca5d227:1887764bffd:-7fd1\" parent=\"7ca5d227:1887764bffc:-7fd1\"/>\n        </SuperBlockDiagram>\n      </BasicBlock>\n      <CommandPort id=\"7ca5d227:1887764bffb:-7fd0\" parent=\"7ca5d227:1887764bffb:-7fd1\" ordering=\"1\" dataType=\"REAL_MATRIX\" dataColumns=\"1\" dataLines=\"1\" initialState=\"-1.0\" style=\"CommandPort;align=center;verticalAlign=bottom;spacing=10.0;rotation=90\" value=\"\"/>\n      <ExplicitLink id=\"7ca5d227:1887764bffb:-7fed\" parent=\"0:2:0\" source=\"7ca5d227:1887764bffb:-7ff8\" target=\"7ca5d227:1887764bffb:-7ff0\" style=\"ExplicitLink\" value=\"\">\n        <mxGeometry as=\"geometry\">\n          <mxPoint as=\"sourcePoint\" x=\"44.0\" y=\"20.0\"/>\n          <Array as=\"points\"></Array>\n          <mxPoint as=\"targetPoint\" x=\"-4.0\" y=\"20.0\"/>\n        </mxGeometry>\n      </ExplicitLink>\n      <ExplicitLink id=\"7ca5d227:1887764bffb:-7fea\" parent=\"0:2:0\" source=\"7ca5d227:1887764bffb:-7feb\" target=\"7ca5d227:1887764bffb:-7fef\" style=\"ExplicitLink\" value=\"\">\n        <mxGeometry as=\"geometry\">\n          <mxPoint as=\"sourcePoint\" x=\"44.0\" y=\"20.0\"/>\n          <Array as=\"points\"></Array>\n          <mxPoint as=\"targetPoint\" x=\"-4.0\" y=\"40.0\"/>\n        </mxGeometry>\n      </ExplicitLink>\n      <ExplicitLink id=\"7ca5d227:1887764bffb:-7fd2\" parent=\"0:2:0\" source=\"7ca5d227:1887764bffb:-7fee\" target=\"7ca5d227:1887764bffb:-7fd5\" style=\"ExplicitLink\" value=\"\">\n        <mxGeometry as=\"geometry\">\n          <mxPoint as=\"sourcePoint\" x=\"44.0\" y=\"30.0\"/>\n          <Array as=\"points\"></Array>\n          <mxPoint as=\"targetPoint\" x=\"-4.0\" y=\"20.0\"/>\n        </mxGeometry>\n      </ExplicitLink>\n      <CommandControlLink id=\"7ca5d227:1887764bffb:-7fce\" parent=\"0:2:0\" source=\"7ca5d227:1887764bffb:-7fd0\" target=\"7ca5d227:1887764bffb:-7fd4\" style=\"CommandControlLink\" value=\"\">\n        <mxGeometry as=\"geometry\">\n          <mxPoint as=\"sourcePoint\" x=\"20.0\" y=\"44.0\"/>\n          <Array as=\"points\"></Array>\n          <mxPoint as=\"targetPoint\" x=\"20.0\" y=\"-4.0\"/>\n        </mxGeometry>\n      </CommandControlLink>\n    </root>\n  </mxGraphModel>\n  <mxCell as=\"defaultParent\" id=\"0:2:0\" parent=\"0:1:0\"/>\n</XcosDiagram>\n\n",
"AnswerId": "76384048",
"AnswerBody": "Use the AFFICH_m block (https://help.scilab.org/AFFICH_m). However, be warned that you still have to run the simulation to see the value:\n\n"
},
{
"QuestionId": "76385130",
"QuestionTitle": "Ms Access running sum with dates and order inside dates",
"QuestionBody": "I am using MS Access to create a DB. I have different physical containers and I want to obtain the running sum of the liquid that has been added and taken out of the container to give the balance of the liquid inside the container.\nThe biggest problem is ordering liquid transactions. I have read lots of resources, and I found out one way of doing this is adding time to the dates so they can be ordered, but I am supposed to not use time, so I have decided to add a manual ordering number within a date which I am not sure is the best way of achieving this, but at least I can do the ordering.\nThe fields I have are:\n-ContainerId\n-DateTransaction\n-OrderInDate\n-Quantity\n\nQuantity is \"-\" for withdrawal and \"+\" for additions, so if I can properly get a running total, I will get the balance.\nI thought of adding OrderInDate as seconds to the Date to correctly order the data and I have written a query like this (qryInventoryTransactionsOrder):\nSELECT ContainerId, Quantity, DateTransaction, OrderInDate,\nDateAdd(\"s\",OrderInDate,DateTransaction) AS Expr1,\nDSum(\"Quantity\",\"qryInventoryTransactionsOrder\",\n\"[ContainerId]=\" & [ContainerId] & \" AND\n[Expr1] <= #\" & [Expr1] & \"#\") AS Balance\nFROM InventoryTransactions\nORDER BY ContainerId, DateAdd(\"s\",OrderInDate,DateTransaction);\n\nThis returns very interesting result like this :\n\n\n\n\nContainerId\nDateTransaction\nOrderInDate\nQuantity\nExpr1\nBalance\n\n\n\n\n1\n29/05/2023\n1\n-50\n29/05/2023 00:00:01\n-50\n\n\n1\n31/05/2023\n1\n100\n31/05/2023 00:00:01\n50\n\n\n1\n31/05/2023\n2\n255\n31/05/2023 00:00:02\n305\n\n\n1\n01/06/2023\n1\n-155\n01/06/2023 00:00:01\n\n\n\n1\n01/06/2023\n2\n-155\n01/06/2023 00:00:02\n\n\n\n1\n01/06/2023\n3\n2500\n01/06/2023 00:00:03\n\n\n\n1\n08/06/2023\n1\n-500\n08/06/2023 00:00:01\n1995\n\n\n\n\nAs you will see \"Balance\" is correct for the first 3 lines, then it returns 3 empty results, and then 1995.\nWhat am I doing wrong here or is there a better way to achieve this result?\n",
"AnswerId": "76385764",
"AnswerBody": "I can't say anything about recursive queries in MS Access.It is interesting.\nTry this query, where DSum counts sum from main table.\nSELECT ContainerId, Quantity, DateTransaction, OrderInDate\n    ,DateAdd(\"s\",OrderInDate,DateTransaction) AS Expr1\n    ,DSum(\"Quantity\",\"InventoryTransactions\"\n       ,\"[ContainerId]=\" & [ContainerId] \n        & \" AND Format(DateAdd(\"\"s\"\",OrderInDate,DateTransaction),\"\"yyyyMMddhhmmss\"\") <= \" \n      & format(DateAdd(\"s\",OrderInDate,DateTransaction),\"yyyyMMddhhmmss\") & \"\") \n    AS Balance\nFROM InventoryTransactions\nORDER BY ContainerId, DateAdd(\"s\",OrderInDate,DateTransaction);\n\n"
},
{
"QuestionId": "76383683",
"QuestionTitle": "IN DRF, how to create a POST serializer where I can add multiple values of a Foreign Key field",
"QuestionBody": "These are 2 models I have:\n\nclass Skill(models.Model):\n    name = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.name + \" - ID: \" + str(self.id)\n\nclass Experience(models.Model):\n    consultant = models.ForeignKey(\"Consultant\", related_name=\"experience\", on_delete=models.CASCADE)\n    project_name = models.CharField(max_length=100)\n    company = models.CharField(max_length=100)\n    company_description = models.TextField(null=True, blank=True)\n    from_date = models.DateField()\n    to_date = models.DateField()\n    project_description = models.CharField(max_length=100)\n    contribution = models.TextField()\n    summary = models.TextField()\n    is_pinned = models.BooleanField(default=False)\n    role = models.CharField(max_length=100, null=True)\n    skill = models.ForeignKey(\"Skill\", related_name=\"experience\", on_delete=models.CASCADE)\n\n\nI want to do something that is quite common but apparently not possible out of the box with DRF: I want to have an endpoint /experience/ with a POST method where I can send a LIST of skill ids (skill field, ForeignKey). For example:\n{\n  \"project_name\": \"Project AVC\",\n  \"company\": \"XYZ Company\",\n  \"company_description\": \"Description of XYZ Company\",\n  \"from_date\": \"2022-01-01\",\n  \"to_date\": \"2022-12-31\",\n  \"project_description\": \"Description of Project ABC\",\n  \"contribution\": \"Contributions to Project ABC\",\n  \"summary\": \"Summary of Experience\",\n  \"is_pinned\": false,\n  \"role\": \"Consultant\",\n  \"skills_ids\": [1,2,3],\n  \"consultant\": 1\n}\n\nIf there are Skill records in the DB with ids 1,2,3 then it will create 3 records in the experience table (one for each skill ofc) . If there's no skill with such id, then during validation it should return an error to the user informing so.\nThe name of the field can be either skill , skills, skill_ids... it does not matter.\nThis is the ExperienceSerializer I created:\nclass ExperienceSerializer(serializers.ModelSerializer):\n    skills = serializers.PrimaryKeyRelatedField(\n        many=True,\n        queryset=Skill.objects.all(),\n        write_only=True\n    )\n\n    class Meta:\n        model = Experience\n        exclude = ['skill']\n\n    def create(self, validated_data):\n        skills_data = validated_data.pop('skills', [])\n        experience = Experience.objects.create(**validated_data)\n\n        for skill in skills_data:\n            experience.skill.add(skill)\n\n        return experience\n\nbut that gives me the error:\ndjango.db.utils.IntegrityError: null value in column \"skill_id\" of relation \"coody_portfolio_experience\" violates not-null constraint\nDETAIL:  Failing row contains (21, BOOM, XYZ Company, 2022-01-01, 2022-12-31, Description of Project ABC, Contributions to Project ABC, Summary of Experience, 1, null, f, Consultant, Description of XYZ Company).\nI also tried using serializers.ListField but it doesn't seem to be quite the serializer for this.\nTried the approach from this answer as well, so then I had my serializer like this:\nclass ExperienceSerializer(serializers.ModelSerializer):\n    skill_ids = serializers.ListField(\n        child=SkillSerializer(),\n        write_only=True\n    )\n\n    class Meta:\n        model = Experience\n        fields = (\n            'consultant',\n            'project_name',\n            'company',\n            'company_description',\n            'from_date',\n            'to_date',\n            'project_description',\n            'contribution',\n            'summary',\n            'is_pinned',\n            'role',\n            'skill',\n            'skill_ids'\n        )\n\n    def create(self, validated_data):\n        skill_ids = validated_data.pop('skill_ids')\n        experience = Experience.objects.create(**validated_data)\n        experience.set(skill_ids)\n\n        return experience\n\n\nI modified the answer a bit from child = serializers.IntegerField, to child=SkillSerializer(), as it was giving me an error of child not being instantiated. Noticed also the use of ListField now as well.\nAnd here is my payload in this version:\n{\n \"project_name\": \"BOOM\",\n \"company\": \"XYZ Company\",\n \"company_description\": \"Description of XYZ Company\",\n \"from_date\": \"2022-01-01\",\n \"to_date\": \"2022-12-31\",\n \"project_description\": \"Description of Project ABC\",\n \"contribution\": \"Contributions to Project ABC\",\n \"summary\": \"Summary of Experience\",\n \"is_pinned\": false,\n \"role\": \"Consultant\",\n \"skill_ids\": [3, 4,2,1],\n   \"consultant\": 1\n}\n\nwhich gives error 400:\n{\n    \"skill\": [\n        \"This field is required.\"\n    ],\n    \"skill_ids\": {\n        \"0\": {\n            \"non_field_errors\": [\n                \"Invalid data. Expected a dictionary, but got int.\"\n            ]\n        },\n        \"1\": {\n            \"non_field_errors\": [\n                \"Invalid data. Expected a dictionary, but got int.\"\n            ]\n        },\n        \"2\": {\n            \"non_field_errors\": [\n                \"Invalid data. Expected a dictionary, but got int.\"\n            ]\n        },\n        \"3\": {\n            \"non_field_errors\": [\n                \"Invalid data. Expected a dictionary, but got int.\"\n            ]\n        }\n    }\n}\n\nTried also this example here to no avail.\nSpend some time reading this entire post explaining the issue of nested serialization, but I don't think it's quite related to my issue. All I want is a list to be sent in POST\nI'm honestly going into a rabbit hole now of just trying different pieces together, but I have no idea how DRF wants me to do these stuff and their documentation is awful and lacking simple examples.\nIf someone could post example but also with explanations and not just the solution that would be much appreciated\n",
"AnswerId": "76384081",
"AnswerBody": "With the current relation, if your payload contains \"skills_ids\": [1,2,3], then you would create three differrent instances of Experience each one containing a skill, which is NOT what you want, that is bad practice.\nInstead, a many-to-many relationship is more adequate, associating multiple skills to an Experience and the other way around, thus avoiding duplicate values in your database.\nWhich is also the syntax that you are using at experience.skill.add(skill) that is how you would attach a Skill to an Experience using such relation. But, in reality you do not need to do anything other than letting the framework work for you!\nmodels.py\nclass Skill(models.Model):\n    ...\n\n\nclass Experience(models.Model):\n    ...\n    skills = models.ManyToManyField(Skill)\n\nserializers.py\nclass ExperienceSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Experience\n        fields = '__all__'\n\npayload\n{\n  \"project_name\": \"Project AVC\",\n  \"company\": \"XYZ Company\",\n  \"company_description\": \"Description of XYZ Company\",\n  \"from_date\": \"2022-01-01\",\n  \"to_date\": \"2022-12-31\",\n  \"project_description\": \"Description of Project ABC\",\n  \"contribution\": \"Contributions to Project ABC\",\n  \"summary\": \"Summary of Experience\",\n  \"is_pinned\": false,\n  \"role\": \"Consultant\",\n  \"skills\": [1,2,3],\n  \"consultant\": 1\n}\n\n"
},
{
"QuestionId": "76381541",
"QuestionTitle": "Generate combinations by combining adjacent characters",
"QuestionBody": "I have a program that should generate combinations of concatenation of all possible adjacent characters.\nFor example\nInput = [a,b,c]\nOutput = [a,b,c], [ab,c], [a,bc]\n\nInput = [a,b,c,d]\nOutput = [a,b,c,d], [ab,c,d], [a,bc,d], [a,b,cd], [ab,cd]\n\nInput = [a,b,c,d,e]\nOutput = [a,b,c,d,e], [ab,c,d,e], [a,bc,d,e], [a,b,cd,e], [a,b,c,de], [ab,cd,e], [a,bc,de], **[ab,c,de]**\nLast one missing from my program output\n\nBasically we are only allowed to combine two adjacent characters.\nI have written the program below.\npublic class Program\n{\n    public static void Main(string[] args)\n    {\n        List<string> cases = new List<string> {\"a b c\", \"a b c d\", \"a b c d e\"};\n        for (int c = 0; c < cases.Count; c++)\n        {\n            var result = F(cases[c]);\n            Console.WriteLine(cases[c]);\n            result.ForEach(Console.WriteLine);\n            Console.WriteLine(\"---------------------------\");\n        }\n    }\n\n    public static List<string> F(string searchTerm)\n    {\n        List<string> result = new List<string>();\n        var terms = searchTerm.Split(new[] { ' ' }, StringSplitOptions.RemoveEmptyEntries).ToList();\n        if (terms.Count == 1)\n            return new List<string> { searchTerm };\n\n        for (int x = 1; x <= 2; x++)\n        {\n            for (int i = 0; i < terms.Count - 1; i++)\n            {\n                if (x == 1)\n                {\n                    int j = i;\n                    var joinedWord = terms[j] + terms[j + 1];\n                    result.Add(searchTerm.Replace($\"{terms[j]} {terms[j + 1]}\", joinedWord));\n                }\n\n                if (x == 2)\n                {\n                    int j = i;\n                    if (j + 3 < terms.Count)\n                    {\n                        var firstJoinedWord = terms[j] + terms[j + 1];\n                        var secondJoinedWord = terms[j + 2] + terms[j + 3];\n                        result.Add(searchTerm.Replace($\"{terms[j]} {terms[j + 1]} {terms[j + 2]} {terms[j + 3]}\", firstJoinedWord + \" \" + secondJoinedWord));\n                    }\n                }\n            }\n        }\n        \n\n        return result;\n    }\n}\n\nAnd here is the output.\n\nI don't know if we need to use Recursion/Dynamic Programming to solve this? because there can be N number of combinations. Any help will be appreciated. Thanks.\n",
"AnswerId": "76383769",
"AnswerBody": "Here's a quick JavaScript version that you can run in your browser to verify the result -\n\n\nfunction *mates(t) {\n  if (t.length == 0) return yield []\n  if (t.length == 1) return yield t\n  for (const m of mates(t.slice(1)))\n    yield [t[0], ...m]\n  for (const m of mates(t.slice(2)))\n    yield [mate(t[0], t[1]), ...m]\n}\n\nfunction mate(a,b) {\n  return a + b\n}\n\nfor (const m of mates([\"a\", \"b\", \"c\", \"d\", \"e\"]))\n  console.log(m.join(\",\"))\n.as-console-wrapper { min-height: 100%; top: 0; }\n\n\n\na,b,c,d,e\na,b,c,de\na,b,cd,e\na,bc,d,e\na,bc,de\nab,c,d,e\nab,c,de\nab,cd,e\n\nWe can easily convert that to a C# program -\nusing System;\nusing System.Linq;\nusing System.Collections.Generic;\n\nclass Program\n{\n    public static IEnumerable<List<string>> Mates(List<string> t)\n    {\n        if (t.Count == 0)\n        {\n            yield return new List<string> {};\n            yield break;\n        }\n    \n        if (t.Count == 1)\n        {\n            yield return t;\n            yield break;\n        }\n        \n        foreach (var m in Mates(t.GetRange(1, t.Count - 1)))\n            yield return new List<string> { t[0] }\n                .Concat(m)\n                .ToList();\n        \n        foreach (var m in Mates(t.GetRange(2, t.Count - 2)))\n            yield return new List<string> { Mate(t[0], t[1]) }\n                .Concat(m)\n                .ToList();\n    }\n    \n    public static string Mate(string a, string b)\n    {\n        return a + b;\n    }\n    \n    public static void Main(string[] args)\n    {\n        var input = new List<string> { \"a\", \"b\", \"c\", \"d\", \"e\" };\n        \n        foreach (var m in Mates(input))\n            Console.WriteLine(string.Join(\",\", m));\n    }\n}\n\na,b,c,d,e\na,b,c,de\na,b,cd,e\na,bc,d,e\na,bc,de\nab,c,d,e\nab,c,de\nab,cd,e\n\n"
},
{
"QuestionId": "76383755",
"QuestionTitle": "Why is my FParsec parser failing to recognize a block comment?",
"QuestionBody": "I'm trying to parse C style comments using FParsec.  Not sure why this is failing:\nMy parser code:\nlet openComment : Parser<_,unit>  = pstring \"/*\"\nlet closeComment : Parser<_,unit> = pstring \"*/\"\nlet comment = pstring \"//\" >>. restOfLine true\n                <|> openComment >>. (charsTillString \"*/\" true System.Int32.MaxValue) |>> Comment\n                //<|> openComment >>. manyCharsTill anyChar closeComment |>> Comment\nlet spaceComments = many ((spaces1 |>> IgnoreU) <|> comment)\nlet str s  = spaceComments >>. pstring s .>> spaceComments\n\nTest Harness:\nlet testStr = @\"\n// test comment\n/* a block comment\n   */\n   x  // another comment\n   \"\nmatch run (str \"x\") testStr with\n| Success(result, _, _)   -> printfn \"Success: %A\" result\n| Failure(errorMsg, _, _) -> assert false\n()\n\n\nError messager.  It is the same for both charsTillString and manyCharsTill\nError in Ln: 6 Col: 4\n   \n   ^\nNote: The error occurred at the end of the input stream.\nCould not find the string '*/'.\n\nComment and IgnoreU are both a discrimated type of string\n",
"AnswerId": "76384101",
"AnswerBody": "The problem is that the combinators in your comment parser don't have the precedence/associativity that you want. You can fix this by grouping with parens:\nlet comment = (pstring \"//\" >>. restOfLine true)\n                <|> (openComment >>. (charsTillString \"*/\" true System.Int32.MaxValue)) |>> Comment\n\nI find that choice is often easier to read than <|> for complex parsers:\nlet comment =\n    choice [\n        pstring \"//\" >>. restOfLine true\n        openComment >>. (charsTillString \"*/\" true System.Int32.MaxValue)\n    ] |>> Comment\n\n"
},
{
"QuestionId": "76385372",
"QuestionTitle": "How can I create a code template in Android Studio to replicate the val template in Kotlin",
"QuestionBody": "Kotlin and Java code templates in Android Studio.\nI tried to create a code template for the truth library that would work like the val template works i.e,\n\nWhen you want to create a variable from the result of calling a function? you just type,\nfunctionName().val.\nWhen you press enter a variable is created ie, val f = functionName().\n\nHow would I replicate this behaviour on the truth library such that when I type f.assert for instance, I get Truth.assertThat(f)?\n",
"AnswerId": "76385796",
"AnswerBody": "This feature is named \"Postfix completion\"\nYou can find details here https://www.jetbrains.com/help/idea/settings-postfix-completion.html\nI have tried now and it's allowed me to add and edit java and groovy templates but kotlin is not supported.\nThe other perfect feature of Idea is Live templates you can use them to implement required templates.\nYou can find details here https://www.jetbrains.com/help/idea/using-live-templates.html\nUpdate: I have checked the current version of Idea, kotlin is not supported yet.\n"
},
{
"QuestionId": "76381363",
"QuestionTitle": "Serialize property access exception to json",
"QuestionBody": "I have a simple class that one of properties is:\npublic TValue Value => IsSuccess\n    ? _value\n    : throw new InvalidOperationException(\"The value of a failure result can not be accessed.\");\n\nSo it works like this, when some operation is a success assign value from this operation to property easy. But now I when I do sutch a thig:\nvar result = new Result (someValue) { IsSuccess = false }\nvar serialized =  JsonConvert.SerializeObject(result); // of course result type is marked as seriazable\n\nSo here I am setting such a result to false, and next I want to serilize it, problem is that exception is not serializing and I am getting just thrown exception. What am I missing here?\n",
"AnswerId": "76383926",
"AnswerBody": "I'm wondering whether there isn't a better design for what you're trying to achieve. Namely, it might be better to move the IsSuccess check logic into a method so that it doesn't get hit during serialization. But if you really decide to do it this way, you could use a JsonConverter to catch and serialize the exception for you:\npublic class ValueOrExceptionConverter : JsonConverter\n{\n    public override void WriteJson(JsonWriter writer, object? value, JsonSerializer serializer)\n    {\n        if (value == null)\n        {\n            return;\n        }\n\n        try\n        {\n            serializer.Serialize(writer, ((dynamic)value).Value);\n        }\n        catch (Exception ex)\n        {\n            serializer.Serialize(writer, new { Value = new { ex.Message } });\n        }\n    }\n\n    public override object? ReadJson(JsonReader reader, Type objectType, object? existingValue, JsonSerializer serializer)\n    {\n        throw new NotImplementedException();\n    }\n\n    public override bool CanConvert(Type objectType) => true;\n}\n\nI'm assuming your Result class is generic so using this converter would look like this:\n[JsonConverter(typeof(ValueOrExceptionConverter))]\npublic class Result<TValue>\n\nThis is all assuming that you're using Newtonsoft.Json. The result of using that converter is something like this:\n{\"Value\":\"Message\":\"The value of a failure result can not be accessed.\"}}\n\nA few notes about the converter code:\n\nInstead of casting to dynamic, you might be better of using an interface or abstract class if you have it. Or if you know exactly which generics you might use for TValue then perhaps you can cast even more specifically.\nI've assumed that you don't want to serialize the entire exception. So if you need more than just the Message then you can add those properties like so for example: new { ex.Message, InnerMessage = ex.InnerException.Message }.\nI've assumed that the Result class only has one property, named Value. You can add more properties in the same way you can add additional Exception properties.\nI haven't implemented the ReadJson because deserializing the exception instead of the value makes that quite tricky. But I'm sure it's not impossible if you need to also deserialize the Result.\n\n"
},
{
"QuestionId": "76383757",
"QuestionTitle": "React Router cancel loader",
"QuestionBody": "I'm throwing an error in my loaders when response.status.ok of fetch is false. Error component is then loaded.\nBut my server sometimes returns 429 status code (too many requests) upon which I don't want to load an error component but instead simply do nothing, or maybe display some message but certainly without reloading the already loaded component, or redirecting, etc.\nHow can that be implemented?\nhttps://codesandbox.io/s/hungry-hooks-yuucsp?file=/src/App.js\n",
"AnswerId": "76384134",
"AnswerBody": "You can check the response status code specifically for a 429 status and return any defined value back to the UI. I think the important detail here that you should return something instead of undefined. null appears to work and not throw any extraneous errors\nfunction loader() {\n  let response = imitateFetch();\n  console.log(response);\n\n  if (response.status === 429) {\n    console.log(429);\n    return null; // <-- return null\n  }\n\n  if (!response.ok) {\n    throw \"loader error\";\n  }\n  return {};\n}\n\nbut you can return anything you like, for example, change the response status to 200.\nfunction loader() {\n  let response = imitateFetch();\n  console.log(response);\n\n  if (response.status === 429) {\n    console.log(429);\n    response.status = 200;\n    response.ok = true;\n    return response;\n  }\n\n  if (!response.ok) {\n    throw \"loader error\";\n  }\n  return {};\n}\n\n\nIt's really up to your app's, or code's, specific use case what it returns and how the UI handles it.\n"
},
{
"QuestionId": "76380714",
"QuestionTitle": "How can I center an ImageView and TextView in a ConstraintLayout while adjusting ImageView size to maintain TextView visibility?",
"QuestionBody": "Question\nHow can I center an ImageView and a TextView within a ConstraintLayout, ensuring that they remain centered regardless of the ConstraintLayout's height, while also ensuring that the ImageView shrinks if necessary to maintain visibility of the TextView?\nExpected results:\nIn case of a large ConstraintLayout (centered, but not larger than the original image):\n\nIn case of a small ConstraintLayout (centered, shrinked image, text still visible):\n\nI build the following reproducible example:\n<androidx.constraintlayout.widget.ConstraintLayout\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"500dp\">\n\n        <ImageView\n            android:id=\"@+id/imageView\"\n            android:layout_width=\"wrap_content\"\n            android:layout_height=\"wrap_content\"\n            tools:srcCompat=\"@tools:sample/avatars\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\"\n            app:layout_constraintBottom_toTopOf=\"@id/textView\" />\n\n        <TextView\n            android:id=\"@+id/textView\"\n            android:layout_width=\"wrap_content\"\n            android:layout_height=\"wrap_content\"\n            android:paddingHorizontal=\"@dimen/primary_margin\"\n            android:text=\"Just a text\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintTop_toBottomOf=\"@+id/imageView\"\n            app:layout_constraintBottom_toBottomOf=\"parent\" />\n\n    </androidx.constraintlayout.widget.ConstraintLayout>\n\nEdit\nThe closest solution I have found so far is as follows. However, the only remaining drawback is that I need to manually specify the maximum width and height, whereas my ideal scenario would be to dynamically adjust them according to the image's actual width and height.\n<androidx.constraintlayout.widget.ConstraintLayout\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"match_parent\">\n\n        <ImageView\n            android:id=\"@+id/imageView\"\n            android:layout_width=\"0dp\"\n            android:layout_height=\"0dp\"\n            android:layout_marginBottom=\"16dp\"\n            app:layout_constraintHeight_max=\"200dp\"\n            app:layout_constraintWidth_max=\"200dp\"\n            tools:srcCompat=\"@tools:sample/avatars\"\n            app:layout_constraintVertical_chainStyle=\"packed\"\n            app:layout_constraintTop_toTopOf=\"parent\"\n            app:layout_constraintBottom_toTopOf=\"@id/textView\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\" />\n\n        <TextView\n            android:id=\"@+id/textView\"\n            android:layout_width=\"wrap_content\"\n            android:layout_height=\"wrap_content\"\n            android:paddingHorizontal=\"@dimen/primary_margin\"\n            android:text=\"Just a text\"\n            app:layout_constraintTop_toBottomOf=\"@id/imageView\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintBottom_toBottomOf=\"parent\" />\n\n    </androidx.constraintlayout.widget.ConstraintLayout>\n\n",
"AnswerId": "76384044",
"AnswerBody": "If you take your closest solution, try setting the ImageView height and width to wrap_content again (so it displays at its native size) but add app:layout_constrainedWidth=\"true\" and app:layout_constrainedHeight=\"true\". This basically lets you define the height and width you want (i.e. whatever the image size actually is), but also enforces the constraints, so it acts like 0dp (i.e. MATCH_CONSTRAINT) when necessary:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<androidx.constraintlayout.widget.ConstraintLayout\n    xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    android:padding=\"16dp\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\">\n\n    <ImageView\n        android:id=\"@+id/image\"\n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        app:layout_constrainedWidth=\"true\"\n        app:layout_constrainedHeight=\"true\"\n        android:src=\"@mipmap/ic_launcher_round\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintTop_toTopOf=\"parent\"\n        app:layout_constraintBottom_toTopOf=\"@id/text\"\n        app:layout_constraintVertical_chainStyle=\"packed\"\n        />\n\n    <TextView\n        android:id=\"@+id/text\"\n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        android:text=\"Hi\"\n        android:textSize=\"85sp\"\n        android:layout_marginTop=\"16dp\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintTop_toBottomOf=\"@id/image\"\n        app:layout_constraintBottom_toBottomOf=\"parent\"\n        />\n\n</androidx.constraintlayout.widget.ConstraintLayout>\n\nHere's the same layout in the Phone and Wear OS Square reference device templates:\n\n\nThe actual ImageView is distorted (because both dimensions are trying to size to wrap_content) but the image maintains its aspect ratio to fit in both dimensions (if you're using the default scaleType).\n\n"
},
{
"QuestionId": "76385243",
"QuestionTitle": "How to mock string as content of file for pytest?",
"QuestionBody": "How can I provide string to function in pytest, so that function under test treat it as content of file ?\nI have function that is parsing file. File is custom text format.\nI want to test multiple different input files.\nInitial idea was to use pytest is this way:\nimport pytest\nimport mymodule as t\n\n# this is all valid one line config file, starting simple\n@pytest.mark.parametrize(\"input_file\", [\n    \"#\",\n    \"##\",\n    \"\",\n    \"   \",\n    \"  \",\n])\n\ndef test_is_input_file_valid(input_file):\n    assert t.myclass(input_file)\n\nProblem that I have is each line need to be content of input file, because t.myclass(input_file) is expecting file not string. So, I need somehow to mock it.\nI am assuming pytest have this functionality by default or plugin, but was not able to find it.\n",
"AnswerId": "76385822",
"AnswerBody": "I wrote a pytest plugin called pytest_tmp_files to solve this exact problem.  Here's how it would look for your example:\n@pytest.mark.parametrize(\n    'tmp_files', [\n        {'f': '#'},\n        {'f': '##'},\n        {'f': ''},\n        {'f': '   '},\n        {'f': '  '},\n    ],\n    indirect=['tmp_files'],\n)\ndef test_is_input_file_valid(tmp_files):\n    assert t.myclass(tmp_files / 'f')\n\nSome things worth noting:\n\nThe parameters are dictionaries where the keys are file names and the values are files contents.  This is a bit more verbose that just specifying the file contents, but much more flexible.\nI'm assuming that your parser accepts pathlib.Path objects, which is what tmp_files / 'f' is.  If not, you might have to do some sort of conversion here, but it should be straight forward.\nThe specified files are actually created in a real temporary directory (unique for each test case), so you can treat them exactly like real files.\nI wrote another pytest plugin called parametrize_from_file that allows you to specify test parameters in structured data files (e.g. YAML), separate from the test code.  I'd recommend checking it out as well.  File contents often end up being long, multi-line strings that mess up the indentation of the parameter list and make the whole test script hard to read.  Moving these parameters to a separate file can really help readability.\n\nSee also this discussion on GitHub, where I tried to get this feature added to pytest proper.\n"
},
{
"QuestionId": "76383483",
"QuestionTitle": "defaultValue for input type 'date' is not working in Nextjs",
"QuestionBody": "I am using Nextjs and I would like to use the html tag, input type of 'date'. I also would like to set a defaultValue and I did something like this and it is not working:\nconst [dDate, setdDate] = useState('17/11/2022');\n\n\nconst ReactComponent = ()=>{\n  \n    return(\n       \n          <input type=\"date\" className=\" border-2 py-1 px-2 rounded-md\" \n         onChange={(text)=>handleDepositeDate(text.target.value, index)} defaultValue={dDate} \n      />\n     )\n\n };\n\nIt does not display on the screen. I also tried using value instead of defaultValue, still didn't work. I also tried other date input on the application and defaultValue didn't work.\n",
"AnswerId": "76384221",
"AnswerBody": "Try using a different date format with the value attribute, like so:\n<input type=\"date\" value=\"2022-11-17\"/>\n\n"
},
{
"QuestionId": "76381366",
"QuestionTitle": "Can't use assume role to accesss aws eks which is created by assume role api",
"QuestionBody": "I created a aws eks using assume role api. Role A assume role B to performe create EKS api. I create the eks and specify that the EKS's cluster role is role C. As I know,the role C's arn will be stored in eks aws-auth configMap.\nWhen A assume role C to access the created EKS, \"Failed to get namespaces: Unauthorized\" returned.\nI always use assume role to invoke API. Does anyone know, whether aws-auth store role C's arn like 'arn:aws:iam::C:role/k8s-cluster-role' or eks store the role arn in aws-auth in another way.\n",
"AnswerId": "76384056",
"AnswerBody": "You have some misconception; The role that is stored in aws-auth configmap for system:masters group in your cluster is not the cluster role, but the iam principal that creates the cluster itself, as per official doc.\n\nWhen you create an Amazon EKS cluster, the IAM principal that creates the cluster is automatically granted system:masters permissions in the cluster's role-based access control (RBAC) configuration in the Amazon EKS control plane.\n\nFrom what you have written, if the sequence is right, and that assume-role approach you are following works properly, you should be able to query your cluster api resources with role-b not role-c, since b is the one you used to create the cluster. In your current setup, you are expecting role C to be able to access cluster resources, though you created with role b.\n"
},
{
"QuestionId": "76380876",
"QuestionTitle": "Description bug in DEB file created by jpackage when opened with QApt installer",
"QuestionBody": "Adding description with --description while creating deb package on linux creates deb file, which when opened with QApt package installer (double click installation) shows defined text in description section, which seems like a bold header and underneath there is that description again with first character stripped:\n\nCommand:\njpackage -t deb \\\n--app-version 1.0.0 \\\n--icon books256.png \\\n--name hello \\\n--description 'my testing text' \\\n--dest target/jpackage_outputdir/ \\\n--temp target/jpackage_tempdir \\\n--input target/jpackage_inputdir \\\n--main-class core.Main \\\n--main-jar jarfile.jar \\\n--linux-menu-group Office \\\n--linux-shortcut\n\nIs there a way to prevent this unprofessional look by finely setting bold header and text underneath separately or at least by removing this duplication in description section?\nUsing Kubuntu 23.0.4, JDK - openjdk 17.0.7 2023-04-18 LTS\n",
"AnswerId": "76384084",
"AnswerBody": "A solution to this problem might be to use multi-line description. First line is then bold text and second line is below it, altough bug still remains when using single-line description.\njpackage -t deb \\\n--app-version 1.0.0 \\\n--icon books256.png \\\n--name hello \\\n--description 'first line\nsecond line' \\\n--dest target/jpackage_outputdir/ \\\n--temp target/jpackage_tempdir \\\n--input target/jpackage_inputdir \\\n--main-class core.Main \\\n--main-jar jarfile.jar \\\n--linux-menu-group Office \\\n--linux-shortcut\n\n\n"
},
{
"QuestionId": "76384941",
"QuestionTitle": "How to type Material UI Icon's fontSize prop?",
"QuestionBody": "I've composed the component below, and I need to apply a type for the custom iconFontSize prop. How can I do this?\nimport { SvgIconComponent } from '@mui/icons-material'\nimport { Typography, TypographyProps} from '@mui/material'\n\ntype Props = TypographyProps & {\n  Icon: SvgIconComponent\n  iconFontSize: /* insert type here! */\n}\n\nexport const IconTypography = ({\n  Icon,\n  iconFontSize = 'inherit',\n  columnGap = 1,\n  children,\n  ...props\n}: Props) => {\n  return (\n    <Typography display=\"flex\" alignItems=\"center\" columnGap={columnGap} {...props}>\n      <Icon fontSize={iconFontSize} />\n      {children}\n    </Typography>\n  )\n}\n\nThanks in advance!\n",
"AnswerId": "76385914",
"AnswerBody": "You can type iconFontSize as a union type of  'inherit' | 'large' | 'medium' | 'small':\ntype Props = TypographyProps & {\n  Icon: SvgIconComponent\n  iconFontSize: \"inherit\" | \"small\" | \"medium\" | \"large\" \n}\n\nIf you want to use the exact type from the MUI type definition file, you can alternatively use:\n\nimport { OverridableStringUnion } from '@mui/types';\n\nfontSize?: OverridableStringUnion<\n  'inherit' | 'large' | 'medium' | 'small',\n  SvgIconPropsSizeOverrides\n>;\n\nThe OverridableStringUnion type is in turn defined as such:\nexport type OverridableStringUnion<T extends string | number, U = {}> = GenerateStringUnion<\n  Overwrite<Record<T, true>, U>\n>;\n\nSee the type definition in the MUI docs here: https://mui.com/material-ui/api/svg-icon/\n"
},
{
"QuestionId": "76381138",
"QuestionTitle": "Cloning a texture created with THREE.WebGLRenderTarget",
"QuestionBody": "I'm using three.js and I need to create a few clones of a texture made with THREE.WebGLRenderTarget().\nI can use the original texture, e.g.:\nscene.background = renderTarget.texture;\nBut if I try to use a clone of it:\nconst tex = renderTarget.texture.clone();\nscene.background = tex;\nI get the following error:\nTHREE.WebGLState: TypeError: Failed to execute 'texSubImage2D' on 'WebGL2RenderingContext': Overload resolution failed.\nIf I add the line:\ntex.isRenderTargetTexture = true;\nNow I don't get any error, but the texture is all black.\nI have also tried to clone the render target (instead of its texture) but it didn't work either. Can you please help me?\nThank you in advance.\n",
"AnswerId": "76384119",
"AnswerBody": "Problem solved: I created a framebuffer texture, and I copied the texture by using method renderer.copyFramebufferToTexture() of class THREE.WebGLRenderer.\n"
},
{
"QuestionId": "76382996",
"QuestionTitle": "algorithm to calculate speeds to move in order to arrive in x turns",
"QuestionBody": "given a distance, turns calculate the number of turns to be on each speed - 1 2 4, and 8. to complete the distance on the last turn.\nyou start on speed 1, and in each turn you can accelerate to the next speed or do nothing (1 -> 2, 2 -> 4, 4 -> 8), once you accelerate you can't slow back down.\neach turn you are moving speed steps (distance -= speed).\nalso, it's ok to go more than distance steps but only if it happens on the last turn.\nfor example: distance = 25, turns = 10 -> speed 1: 1 turn, speed 2: 5 turns, speed 4: 4 turns, the total distance is 1 * 1 + 2 * 5 + 4 * 4 = 27 steps, but we got to 25 steps on the last turn which is what we need.\nI need help writing a function that will calculate that.\ndef calc_speeds(distance: int, arrive_in_x_turns: int) -> dict[int, int]:\n\n\nso far i've used this turns_till_arrival = ((turns_till_arrival - (speed // 2)) // speed) + (speed // 2) + 1 formula, in a for loop, for each speed and if turns_till_arrival is equal to turns I will accelerate until I get to speed without spending extra turns in other speeds (only the 1 necessary turn, because I can only accelerate once per turn) but then there are a lot of times that it doesn't work because in order for it to work I must spend more than 1 turn at other speeds but I can't figure out a way to calculate that.\n",
"AnswerId": "76384240",
"AnswerBody": "This is a fairly exhaustive approach, but it does provide the correct answer to the problem above about how to cover your distance in a specified number of steps.\nFor my method, I first created the output dictionary in the form of {1: distance, 2: 0, 4: 0, 8: 0}, where, for each key-value pair, the key represents your speed and the value represents the total number of turns spent at that speed. This dictionary above represents the way to cover your distance in the maximum number of turns possible, since each turn you are just running at speed=1.\nThe important realization here is that if you subtract two turns from output[1] and add a turn to output[2], you are covering the same distance as before, but you have lost a turn. Therefore, you can make a loop that stops when the number of turns in your output equals arrive_in_x_turns, and during each iteration, you lose a turn by doing the subprocess I have described above. This also works for the other speeds (i.e. subtracting two turns from output[2] and adding a turn into output[4] maintains the distance you want to travel while losing a turn).\nHere is my implementation below. When running your example of calc_speeds(distance=25, arrive_in_x_turns=10), my output is {1: 1, 2: 6, 4: 3, 8: 0}. The number of turns are correct (1 + 6 + 3 = 10), as is the distance covered (1*1 + 2*6 + 4*3 + 8*0 = 1 + 12 + 12 + 0 = 25).\ndef calc_speeds(distance: int, arrive_in_x_turns: int) -> dict[int, int]:\n    output = {1: distance, 2: 0, 4: 0, 8: 0}\n\n    # Loop until the total number of turns is equal to the number of turns requested\n    while (sum(output.values()) > arrive_in_x_turns):\n        # Subtract two turns off of '1' and add a turn to '2' until not possible\n        # This method ensures that during each iteration, number of turns decreases\n        # by one while the distance traveled remains the same\n        if output[1] // 2 > 0:\n            output[1] -= 2\n            output[2] += 1\n        # Do a similar method for the ones above\n        elif output[2] // 2 > 0:\n            output[2] -= 2\n            output[4] += 1\n        elif output[4] // 2 > 0:\n            output[4] -= 2\n            output[8] += 1\n    \n    return output\n\nAgain, this is an exhaustive solution that will have a long runtime with harder examples, but hopefully this will help get you started on finding a more optimal way to solve it!\nEDIT:\nThis answer above can be optimized! Instead of subtracting two turns from a current speed and adding one turn to the next, we can instead find the minimum between half the number of turns of the current speed and the remaining number of turns that need to be gotten rid of. Here's a newer version.\ndef calc_speeds(distance: int, arrive_in_x_turns: int) -> dict[int, int]:\n    output = {1: distance, 2: 0, 4: 0, 8: 0}\n\n    # Loop until the total number of turns is equal to the number of turns requested\n    while sum(output.values()) > arrive_in_x_turns:\n        if output[1] // 2 > 0:\n            # Calculate turns to subtract from current speed as the minimum between half the \n            # current turns under this speed and the number of turns remaining\n            turns_to_subtract = min(output[1] // 2, sum(output.values()) - arrive_in_x_turns)\n            # Use similar logic to the previous version of this algorithm\n            output[1] -= turns_to_subtract * 2\n            output[2] += turns_to_subtract\n        elif output[2] // 2 > 0:\n            turns_to_subtract = min(output[2] // 2, sum(output.values()) - arrive_in_x_turns)\n            output[2] -= turns_to_subtract * 2\n            output[4] += turns_to_subtract\n        elif output[4] // 2 > 0:\n            turns_to_subtract = min(output[4] // 2, sum(output.values()) - arrive_in_x_turns)\n            output[4] -= turns_to_subtract * 2\n            output[8] += turns_to_subtract\n    \n    return output\n\n"
},
{
"QuestionId": "76385015",
"QuestionTitle": "Jolt not printing anything",
"QuestionBody": "I am writing jolt for transforming this data but not getting desired result\nIf practice_loc,prac_num and topId are same for two or more data then they will be combined together with separate S1 and S2 within subList. Else they would pass as it is with addition of subList only.\nData\n[\n  {\n    \"practice_loc\": \"120\",\n    \"prac_num\": \"oswal\",\n    \"topId\": \"t1\",\n    \"S1\": \"A1\",\n    \"S2\": \"B1\"\n  },\n  {\n    \"practice_loc\": \"120\",\n    \"prac_num\": \"oswal\",\n    \"topId\": \"t1\",\n    \"S1\": \"A2\",\n    \"S2\": \"\"\n  },\n  {\n    \"practice_loc\": \"334\",\n    \"prac_num\": \"L3\",\n    \"topId\": \"plumcherry\",\n    \"S1\": \"A3\",\n    \"S2\": \"\"\n  },\n  {\n    \"practice_loc\": \"987\",\n    \"prac_num\": \"L3\",\n    \"topId\": \"artica\",\n    \"S1\": \"A5\",\n    \"S2\": \"B7\"\n  }\n]\n\nExpected Output:\n[\n  {\n    \"practice_loc\": \"120\",\n    \"prac_num\": \"oswal\",\n    \"topId\": \"t1\"\n    \"subList\": [\n      {\n        \"S1\": \"A1\",\n        \"S2\": \"B1\"\n      },\n      {\n        \"S1\": \"A2\",\n        \"S2\": \"\"\n      }\n    ]\n  },\n  {\n    \"practice_loc\": \"334\",\n    \"prac_num\": \"L3\",\n    \"topId\": \"plumcherry\"\n    \"subList\": [\n      {\n        \"SubID1\": \"A3\",\n        \"SubID2\": \"\"\n      }\n    ]\n  },\n  {\n    \"practice_loc\": \"987\",\n    \"prac_num\": \"L3\",\n    \"topId\": \"artica\",\n    \"subList\": [\n      {\n        \"SubID1\": \"A5\",\n        \"SubID2\": \"B7\"\n      }\n    ]\n  }\n]\n\nHere is what I tried but didnt get desired result Its not printing anything\n[\n  {\n    \"operation\": \"shift\",\n    \"spec\": {\n      \"*\": {\n        \"@\": \"@(1,practice_loc).@(1,prac_num).@(1,topId)\"\n      }\n    }\n  },\n  {\n    \"operation\": \"cardinality\",\n    \"spec\": {\n      \"*\": {\n        \"*\": \"MANY\"\n      }\n    }\n  },\n  {\n    \"operation\": \"shift\",\n    \"spec\": {\n      \"*\": {\n        \"*\": {\n          \"*\": {\n            \"practice_loc\": \"[#4].&\",\n            \"prac_num\": \"[#4].&\",\n            \"topId\": \"[#4].&\",\n            \"S*\": \"[#4].subList[&1].&\"\n          }\n        }\n      }\n    }\n  },\n  {\n    \"operation\": \"cardinality\",\n    \"spec\": {\n      \"*\": {\n        \"practice_loc\": \"ONE\",\n        \"prac_num\": \"ONE\",\n        \"topId\": \"ONE\"\n      }\n    }\n  }\n]\n\n",
"AnswerId": "76385939",
"AnswerBody": "Your current spec is pretty good. Would be suitable to rearrange it like that\n[\n  { // group by those three attributes\n    \"operation\": \"shift\",\n    \"spec\": {\n      \"*\": {\n        \"*\": \"@1,practice_loc.@1,prac_num.@1,topId.&\",\n        \"S*\": \"@1,practice_loc.@1,prac_num.@1,topId.subList[&1].&\"\n      }\n    }\n  },\n  { // get rid of wrappers\n    \"operation\": \"shift\",\n    \"spec\": {\n      \"*\": {\n        \"*\": {\n          \"*\": {\n            \"@\": \"\"\n          }\n        }\n      }\n    }\n  },\n  {\n    \"operation\": \"cardinality\",\n    \"spec\": {\n      \"*\": {\n        \"*\": \"ONE\", // pick only single one from repeating components \n        \"subList\": \"MANY\"\n      }\n    }\n  },\n  { // get rid of generated nulls within subList arrays \n    \"operation\": \"modify-overwrite-beta\",\n    \"spec\": {\n      \"*\": \"=recursivelySquashNulls\"\n    }\n  }\n]\n\nEdit for illustration : Below, I have pasted the image what I get after toggling ADVANCED tab of Configure section for the JoltTransformJSON processor which has the version 1.21.0 as NiFi does. Btw, yours is a recent version as well.\n\n"
},
{
"QuestionId": "76381511",
"QuestionTitle": "Different Checkbox groups should write data in textfields",
"QuestionBody": "My problem is that I have found a solution for one group of checkboxes and shows the selected data in a text field in my dynamic formular.\nBut I think the line $('input:checkbox').change((e) does not make sense if I want to use a different, or new, group of checkboxes.\nMy idea is that the two different groups of checkboxes get a unique id to handle with them.\nThe data i want to include in an MariaDB Database.\n                        <tr>\n                            <td>\n                                Entsperrcode:\n                            </td>\n                            <td>\n                                    <script src=\"inc/jquery-3.7.0.min.js\"></script>\n                                    <br>\n                                    <table border=\"1\"cellspacing=\"0\" cellpadding=\"0\">\n                                        <tr>\n                                            <td><center>1</center></td>\n                                            <td><center>2</center></td>\n                                            <td><center>3</center></td>\n                                        </tr>\n                                        <tr>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch1\" value=\"1\"></td>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch2\" value=\"2\"></td>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch3\" value=\"3\"></td>\n                                        </tr>\n                                            <td><center>4</center></td>\n                                            <td><center>5</center></td>\n                                            <td><center>6</center></td>\n                                        </tr>\n                                        <tr>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch4\" value=\"4\"></td>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch5\" value=\"5\"></td>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch6\" value=\"6\"></td>\n                                        </tr>\n                                        <tr>\n                                            <td><center>7</center></td>\n                                            <td><center>8</center></td>\n                                            <td><center>9</center></td>\n                                        </tr>\n                                        <tr>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch7\" value=\"7\"></td>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch8\" value=\"8\"></td>\n                                            <td><input type=\"checkbox\" id=\"entsperrcodewisch9\" value=\"9\"></td>\n                                        </tr>\n                                </table>\n                                    <input type=\"text\" id=\"selected\" name=\"entsperrcode\"/><br><br>\n\n\n                                    <script>\n                                    (function() {\n                                    $('input:checkbox').change((e) => {\n                                        if ($(e.currentTarget).is(':checked')) {\n                                        var curVal = $('#selected').val();\n                                        if (curVal) {\n                                            $('#selected').val(curVal + '-' + e.currentTarget.value);\n                                        } else {\n\n                                            $('#selected').val(e.currentTarget.value);\n                                        }\n                                        } else {\n                                        var curVal = $('#selected').val().split('-');\n                                        var filteredVal = curVal.filter(el => el.trim() !== e.currentTarget.value)\n                                        $('#selected').val(filteredVal.join('-'));\n                                        }\n                                    });\n                                    })();\n                                    </script>\n                            </td>\n                        </tr>\n                        <tr>\n                            <td>\n                                Beschädigungen:\n                            </td>\n                            <td>\n                                    <script src=\"inc/jquery-3.7.0.min.js\"></script>\n                                    <br>\n                                    <input type=\"checkbox\" id=\"beschaedingung1\" value=\"Display\"><br>\n                                    <input type=\"checkbox\" id=\"beschaedingung2\" value=\"Rückseite\"><br>\n                                    <input type=\"checkbox\" id=\"beschaedingung3\" value=\"Rand\"><br>\n\n                                    <input type=\"text\" id=\"beschaedig\" name=\"beschaedig\"/><br><br>\n\n\n                                    <script>\n                                    (function() {\n                                    $('input:checkbox').change((e) => {\n                                        if ($(e.currentTarget).is(':checked')) {\n                                        var curVal = $('#beschaedig').val();\n                                        if (curVal) {\n                                            $('#beschaedig').val(curVal + '-' + e.currentTarget.value);\n                                        } else {\n\n                                            $('#beschaedig').val(e.currentTarget.value);\n                                        }\n                                        } else {\n                                        var curVal = $('#beschaedig').val().split('-');\n                                        var filteredVal = curVal.filter(el => el.trim() !== e.currentTarget.value)\n                                        $('#beschaedig').val(filteredVal.join('-'));\n                                        }\n                                    });\n                                    })();\n                                    </script>\n                            </td>\n                        </tr>\n\n",
"AnswerId": "76384131",
"AnswerBody": "The way I'd approach this is as below, with explanatory comments in the code:\n\n\n// simple utility variable and functions to reduce some of the repetitive typing:\nconst D = document,\n  // here we have means of creating an element, and passing various properties\n  // to that new element (className, textContent, borderColor...):\n  create = (tag, props) => Object.assign(D.createElement(tag), props),\n  // an alias for document, and element, querySelector(), which is used\n  // depends on the context which is the document by default:\n  get = (selector, context = D) => context.querySelector(selector),\n  // as above, but an alias for querySelectorAll(), this explicitly returns\n  // an Array instead of a NodeList in order to allow for Array methods to be\n  // used (map(), filter()...):\n  getAll = (selector, context = D) => [...context.querySelectorAll(selector)];\n\n// named function to handle the events on the <input type=\"checkbox\">\n// elements, this is bound later using EventTarget.addEventListener();\n// this function takes one argument - 'evt', a reference to the Event Object -\n// passed from EventTarget.addEventListener():\nconst checkboxHandler = (evt) => {\n\n    // this is the element to which the event-handling function is bound:\n    let changed = evt.currentTarget,\n      // the 'output' is the element in which I'll be showing the results,\n      // and uses Element.querySelector() to find the first (if any) element\n      // matching the selector which is found within the closest ancestor\n      // <fieldset> element:\n      output = get('.result', changed.closest('fieldset')),\n      // this retrieves the delimiter custom property defined in the CSS,\n      // whether via the stylesheet or the inline \"style\" attribute:\n      delimiter = window.getComputedStyle(output,null).getPropertyValue(\"--delimiter\"),\n      // we retrieve the value of the changed element (removing leading/trailing\n      // white-space; this may or may not be necessary depending on your use-case):\n      result = changed.value.trim(),\n      // here we use a template-literal string to concatenate the various\n      // variables together to create an identifier for the created element\n      // (an id could be used, given that this is likely to be unique, but I\n      // chose to assume that conflicts may happen across the document):\n      resultClass = `${changed.name}${delimiter}${result}`,\n      // we create a <span> element with the given textContent and className:\n      resultWrapper = create('span', {\n          textContent: result,\n          className: resultClass,\n      }),\n      // creating another element - an <em> - to wrap the delimiter character:\n      delimiterWrapper = create('em', {\n      textContent: delimiter,\n      className: \"delimiter\"\n    });\n    \n    // a checkbox may fire the change event both when it's checked or\n    // unchecked by the user; therefore we first test to see whether it\n    // was checked (this returns a Boolean true or false):\n    if (changed.checked) {\n      // if it was checked we append both the created <em> element, along\n      // with the created <span> element to the output element:\n        output.append(delimiterWrapper, resultWrapper);\n    } else {\n      // or if it was unchecked, we retrieve the existing element via\n      // the class we created created earlier and looking within the\n      // output element, using the alias (above) of element.querySelector()\n      // by passing a context:\n    let toRemove = get(`.${resultClass}`, output);\n    \n    // we then use an Array literal, passing in both the previous element\n    // sibling of the element we wish to remove and the element itself:\n    [toRemove.previousElementSibling, toRemove]\n      // we then use Array.prototype.forEach() to iterate over the Array:\n      .forEach(\n        // passing in a reference to the current Array element 'el',\n        // and removing that element:\n        (el) => el.remove()\n      );\n    }\n};\n  \n// here we selector all checkbox <input> elements in the document, and\n// iterate over that Array:\ngetAll('input[type=checkbox]').forEach(\n  // passing in a reference - 'el' - to the current Node of the\n  // Array of Nodes, and using EventTargetTarget.addEventListener()\n  // to bind the named function checkboxHandler() (note the deliberately\n  // missing parentheses) as the event-handler for the 'change' event:\n    (el) => el.addEventListener('change', checkboxHandler)\n);\n/* setting a custom property to use later as a basic\n   demonstration of how custom properties might be\n   used: */\nform {\n  --labelSize: 3rem;\n}\n\nfieldset {\n  /* allows us to easily style the <input> elements\n     into a grid, tabular-style, format: */\n  display: inline grid;\n  /* defining the space between adjacent elements: */\n  gap: 0.5rem;\n  /* defining the size of the various rows: */\n  grid-auto-rows: var(--labelSize);\n  /* defining the size of the various columns, using\n     repeat() to create a number of columns stored in\n     the --columnCount custom variable, with a default\n     value of 3: */\n  grid-template-columns: repeat(var(--columnCount, 3), var(--labelSize));\n}\n\nlabel {\n  border: 1px solid currentColor;\n  display: grid;\n  padding: 0.25rem;\n  text-align: center;\n}\n\n/* this moves the <input> children of the <label>\n   element after their next sibling element in order\n   that the DOM allows for a checked <input> to style\n   the following <span>, despite that <span> visually\n   appearing before the <input>: */\nlabel > input {\n  order: 1;\n}\n\n/* styling the adjacent <span> of the checked <input>: */\ninput:checked + span {\n  /* this isn't particularly great example, but serves\n     only to demonstrate how the <span> may be styled\n     based on the state of the check-box: */\n  background-image:\n    radial-gradient(\n      at 0 0,\n      lightskyblue,\n      palegreen\n    );\n  font-weight: bold;\n}\n\n.result {\n  border: 1px solid currentColor;\n  /* using flex layout: */\n  display: flex;\n  /* shorthand for:\n      flex-direction: row;\n      flex-wrap: wrap;\n     adjust to your preferences: */\n  flex-flow: row wrap;\n  gap: 0.25rem;\n  /* positioning the element so that it\n     starts in grid-column: 1 (the first)\n     and finishes in grid-column: -1\n     (the last) */\n  grid-column: 1 / -1;\n  padding-block: 0.25rem;\n  padding-inline: 0.5rem;\n}\n\n/* within the JavaScript we add the .result\n   elements along with a previous .delimiter\n   element, so here we style a .delimiter\n   when it's the first child so that it's not\n   visible in the document: */\n.result .delimiter:first-child {\n  display: none;\n}\n<form action=\"#\">\n  <!-- I opted to wrap each \"group\" of <input> elements within\n       a <fieldset> element within a <form>, as your demo didn't\n       look tabular (the element choices aren't really important\n       changes require only minor adjustments to the JavaScript: -->\n  <fieldset>\n    <!-- provides a \"title\" to the grouped <input> elements: -->\n    <legend>Group 1</legend>\n    <!-- wrapping the <input> within the <label> so that clicking\n         either the <input> or the text will update the checked\n         state of the <input> and trigger the change event: -->\n    <label><input type=\"checkbox\" value=\"1\" name=\"group-1\">\n      <span class=\"labelText\">1</span>\n      <!-- to associate the <input> elements together in their\n           \"groups\" I've taken advantage of the \"name\"\n           attribute in place of the (invalid duplication of\n           \"id\" attributes) -->\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"2\" name=\"group-1\">\n      <span class=\"labelText\">2</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"3\" name=\"group-1\">\n      <span class=\"labelText\">3</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"4\" name=\"group-1\">\n      <span class=\"labelText\">4</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"5\" name=\"group-1\">\n      <span class=\"labelText\">5</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"6\" name=\"group-1\">\n      <span class=\"labelText\">6</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"7\" name=\"group-1\">\n      <span class=\"labelText\">7</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"8\" name=\"group-1\">\n      <span class=\"labelText\">8</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"9\" name=\"group-1\">\n      <span class=\"labelText\">9</span>\n      \n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n  <fieldset>\n    <legend>Group 2</legend>\n    <label><input type=\"checkbox\" value=\"1\" name=\"group-2\">\n      <span class=\"labelText\">1</span>\n      </label>\n    <label><input type=\"checkbox\" value=\"2\" name=\"group-2\">\n      <span class=\"labelText\">2</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"3\" name=\"group-2\">\n      <span class=\"labelText\">3</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"4\" name=\"group-2\">\n      <span class=\"labelText\">4</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"5\" name=\"group-2\">\n      <span class=\"labelText\">5</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"6\" name=\"group-2\">\n      <span class=\"labelText\">6</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"7\" name=\"group-2\">\n      <span class=\"labelText\">7</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"8\" name=\"group-2\">\n      <span class=\"labelText\">8</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"9\" name=\"group-2\">\n      <span class=\"labelText\">9</span>\n      \n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n  <fieldset>\n    <legend>Group 3</legend>\n    <label><input type=\"checkbox\" value=\"1\" name=\"group-3\">\n      <span class=\"labelText\">1</span>\n      </label>\n    <label><input type=\"checkbox\" value=\"2\" name=\"group-3\">\n      <span class=\"labelText\">2</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"3\" name=\"group-3\">\n      <span class=\"labelText\">3</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"4\" name=\"group-3\">\n      <span class=\"labelText\">4</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"5\" name=\"group-3\">\n      <span class=\"labelText\">5</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"6\" name=\"group-3\">\n      <span class=\"labelText\">6</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"7\" name=\"group-3\">\n      <span class=\"labelText\">7</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"8\" name=\"group-3\">\n      <span class=\"labelText\">8</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"9\" name=\"group-3\">\n      <span class=\"labelText\">9</span>\n      \n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n  <fieldset>\n    <legend>Group 4</legend>\n    <label><input type=\"checkbox\" value=\"1\" name=\"group-4\">\n      <span class=\"labelText\">1</span>\n      </label>\n    <label><input type=\"checkbox\" value=\"2\" name=\"group-4\">\n      <span class=\"labelText\">2</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"3\" name=\"group-4\">\n      <span class=\"labelText\">3</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"4\" name=\"group-4\">\n      <span class=\"labelText\">4</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"5\" name=\"group-4\">\n      <span class=\"labelText\">5</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"6\" name=\"group-4\">\n      <span class=\"labelText\">6</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"7\" name=\"group-4\">\n      <span class=\"labelText\">7</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"8\" name=\"group-4\">\n      <span class=\"labelText\">8</span>\n      \n    </label>\n    <label><input type=\"checkbox\" value=\"9\" name=\"group-4\">\n      <span class=\"labelText\">9</span>\n      \n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n</form>\n\n\n\nJS Fiddle demo.\nIn response to OP's comment:\n\n... but if I change the name \"group-1\" to \"group1[]\" to build an array the code does not reset the numbers.\n\nI've updated the name attribute to reflect those requirements, and added a custom data-* attribute to from which the selector is derived (purely for simplicity's sakes, as [ and ] would have to be escaped in order to be used as part of the selector, which is needlessly complex though still possible of course).\nThis leads to the following, adjusted code:\n\n\nconsole.clear();\nconst D = document,\n  create = (tag, props) => Object.assign(D.createElement(tag), props),\n  get = (selector, context = D) => context.querySelector(selector),\n  getAll = (selector, context = D) => [...context.querySelectorAll(selector)];\n\nconst checkboxHandler = (evt) => {\n  let changed = evt.currentTarget,\n    output = get('.result', changed.closest('fieldset')),\n    delimiter = window.getComputedStyle(output, null).getPropertyValue(\"--delimiter\"),\n    result = changed.value.trim(),\n    // here we use the Element.dataset API to form the resultClass selector to\n    // enable easy removal of the value from the <output>\n    resultClass = `${changed.dataset.name}${delimiter}${result}`,\n    resultWrapper = create('span', {\n      textContent: result,\n      className: resultClass,\n    }),\n    delimiterWrapper = create('em', {\n      textContent: delimiter,\n      className: \"delimiter\"\n    });\n\n  if (changed.checked) {\n    output.append(delimiterWrapper, resultWrapper);\n  } else {\n    let toRemove = get(`.${resultClass}`, output);\n    [toRemove.previousElementSibling, toRemove].forEach((el) => el.remove());\n  }\n};\n\ngetAll('input[type=checkbox]').forEach(\n  (el) => el.addEventListener('change', checkboxHandler)\n);\nform {\n  --labelSize: 3rem;\n}\n\nfieldset {\n  --accent: palegreen;\n  display: inline grid;\n  gap: 0.5rem;\n  grid-auto-rows: var(--labelSize);\n  grid-template-columns: repeat(var(--columnCount, 3), var(--labelSize));\n}\n\nlabel {\n  border: 1px solid currentColor;\n  display: grid;\n  padding: 0.25rem;\n  text-align: center;\n}\n\nlabel input {\n  accent-color: var(--accent, unset);\n  order: 1;\n}\n\ninput:checked+span {\n  background-image: linear-gradient( 90deg, aqua, var(--accent, transparent));\n}\n\n.result {\n  border: 1px solid currentColor;\n  display: flex;\n  flex-flow: row wrap;\n  gap: 0.25rem;\n  grid-column: span 3;\n  padding-block: 0.25rem;\n  padding-inline: 0.5rem;\n}\n\n.result .delimiter:first-child {\n  display: none;\n}\n<form action=\"#\">\n  <fieldset>\n    <legend>Group 1</legend>\n    <label>\n      <!-- adding the \"array-indicator\" to the \"name\" attribute,\n           and adding an additional data-name custom attribute: -->\n      <input type=\"checkbox\" value=\"1\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">1</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"2\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">2</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"3\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">3</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"4\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">4</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"5\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">5</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"6\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">6</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"7\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">7</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"8\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">8</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"9\" name=\"group-1[]\" data-name=\"group-1\">\n      <span class=\"labelText\">9</span>\n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n\n  <fieldset>\n    <legend>Group 2</legend>\n    <label>\n      <input type=\"checkbox\" value=\"1\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">1</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"2\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">2</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"3\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">3</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"4\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">4</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"5\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">5</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"6\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">6</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"7\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">7</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"8\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">8</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"9\" name=\"group-2[]\" data-name=\"group-2\">\n      <span class=\"labelText\">9</span>\n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n\n  <fieldset>\n    <legend>Group 3</legend>\n    <label>\n      <input type=\"checkbox\" value=\"1\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">1</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"2\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">2</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"3\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">3</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"4\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">4</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"5\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">5</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"6\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">6</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"7\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">7</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"8\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">8</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"9\" name=\"group-3[]\" data-name=\"group-3\">\n      <span class=\"labelText\">9</span>\n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n\n  <fieldset>\n    <legend>Group 4</legend>\n    <label>\n      <input type=\"checkbox\" value=\"1\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">1</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"2\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">2</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"3\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">3</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"4\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">4</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"5\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">5</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"6\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">6</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"7\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">7</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"8\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">8</span>\n    </label>\n    <label>\n      <input type=\"checkbox\" value=\"9\" name=\"group-4[]\" data-name=\"group-4\">\n      <span class=\"labelText\">9</span>\n    </label>\n    <output class=\"result\" style=\"--delimiter: -;\"></output>\n  </fieldset>\n</form>\n\n\n\nJS Fiddle demo.\nReferences:\n\nCSS:\n\nbackground-image.\nCSS custom properties.\nCSS logical properties.\ndisplay.\n:first-child.\ngap.\ngrid-auto-rows.\ngrid-template-columns.\nlinear-gradient().\norder.\nradial-gradient().\npadding.\npadding-block.\npadding-inline.\nrepeat().\ntext-align.\nvar().\n\n\nJavaScript:\n\nArray literals.\nArray.prototype.filter().\nArray.prototype.forEach().\nArray.prototype.map().\ndocument.createElement().\ndocument.querySelector().\ndocument.querySelectorAll().\nElement.append().\nElement.previousElementSibling().\nElement.remove().\nElement.querySelector().\nElement.querySelectorAll().\nEventTarget.addEventListener().\nHTMLElement.dataset API.\nObject.assign().\nTemplate literals.\n\n\n\n"
},
{
"QuestionId": "76384666",
"QuestionTitle": "Can't find services package.json when running docker-compose",
"QuestionBody": "I am building a docker-compose.yml file inside a workspace, but when I try to run docker-compose, I can't start my services because of the following error ENOENT: no such file or directory, open '/entity-service/package.json' the same error happens when trying to start the agent-portal-service container as well but the error happens in this directory /agent-portal-service/package.json. But my projects indeed have a package.json file, I think that this is related to the context that docker-compose is running.\nHere is my workspace structure:\n├── agent-portal-service\n├── data\n├── docker-compose.yml\n└── entity-service\n\nMy docker-compose.yml:\nversion: \"3\"\n\nservices:\n  agent_portal_service:\n    working_dir: /agent-portal-service\n    container_name: agent_portal_service\n    image: node:16\n    volumes:\n      - /agent-workspace:/agent-portal-service\n    ports:\n      - 3100:3100\n    command: npm run start:debug\n    tty: true\n\n  entity_service:\n    working_dir: /entity-service\n    container_name: entity_service\n    image: node:16\n    volumes:\n      - /agent-workspace:/entity-service\n    ports:\n      - 3101:3101\n    command: npm run start:debug\n    tty: true\n    depends_on:\n      - mongodb\n\n  mongodb:\n    container_name: mongodb\n    image: mongo:4.4.6\n    ports:\n      - 27017:27017\n    volumes:\n      - ./data/db:/data/db\n    command: mongod --port 27017\n    restart: always\n\nI am expecting to be able to run the agent_portal_service and entity_service containers successfully\n",
"AnswerId": "76385966",
"AnswerBody": "The important parts of your entity-service definition look like this\n  entity_service:\n    working_dir: /entity-service\n    volumes:\n      - /agent-workspace:/entity-service\n    command: npm run start:debug\n\nYou map /agent-workspace to /entity-service in the volumes section. You also set your working directory to /entity-service. In effect, your working directory is /agent-workspace on your host machine. There's no package.json file in the /agent-workspace directory, so your npm command fails.\nTo fix it, I'd map /agent-workspace/entity-service to /entity-service instead. That way, you'll have a package.json file in your /entity-service directory inside the container.\nLike this\nvolumes:\n  - /agent-workspace/entity-service:/entity-service\n\n"
},
{
"QuestionId": "76382916",
"QuestionTitle": "Specify function parameter types in TypeScript mapped trype",
"QuestionBody": "I have two functions that take a single options argument with differing properties, except for type, which is used to identify the function.\ntype FuncAOptions = {\n    type: 'A'\n    opt1: string\n    opt2: boolean\n}\n\nfunction funcA(options: FuncAOptions): number {\n    if (!options.opt1) throw new Error('Missing required option')\n    return 1\n}\n\ntype FuncBOptions = {\n    type: 'B'\n    opt3: number\n    opt4: (a: number) => number\n}\n\nfunction funcB(options: FuncBOptions): string {\n    if (!options.opt3) throw new Error('Missing required option')\n    return 'B'\n}\n\nI then have a map of these functions, with an associated mapped type, so that I can call the functions conditionally with variable runtime data.\ntype AllFunctions = FuncAOptions | FuncBOptions\n\ntype FunctionMap = { [K in AllFunctions['type']]: (options: any) => any; }\n\nconst functionMap: FunctionMap = {\n    A: funcA,\n    B: funcB\n}\n\nfunction callFunction(type: keyof typeof functionMap, options: any) {\n    return functionMap[type](options)\n}\n\nWhen I call the functions directly, I get the proper type-checking to know if I'm passing an incorrect set of options. I want to be able to do the same when calling the function through the intermediary method.\ncallFunction('A', { type: 'B', opt3: 'Hello' }) // NO TS ERROR\nfuncA({ type: 'B', opt3: 'Hello' }) // TS ERROR: The expected type comes from property 'type' which is declared here on type 'FuncAOptions'\n\nI like having the map typed with K in AllFunctions['type'] because when I add a function to AllFunctions, I am reminded that I need to add the key-value pair to functionMap.\nFull example here\n",
"AnswerId": "76384251",
"AnswerBody": "If you want functionMap[type](options) to type check without loosening things up with type assertions or the any type, then you'll need to write it terms of generic indexes into a base key-value type or mapped types of that type.  This is as described in microsoft/TypeScript#47109.\nEssentially you want type to be seen as some generic type K, and functionMap to be seen as some mapped type like {[P in keyof FuncOptionMap]: (arg: FuncOptionMap[P]) => FuncRetMap[P]} and for options to be seen as type FuncOptionMap[K].  Then the compiler can conclude that the function functionMap[type] is of type (arg: FuncOptionMap[K]) => FuncRetMap[K], and is therefore callable with options as an argument, and will return the corresponding return type FuncRetMap[K].  So we'll need to define FuncOptionMap and FuncRetMap in terms of the values you have.\nYou might have hoped that you could have done this with type merely being the union type equivalent to keyof FuncOptionMap without needing generics.  But TypeScript can't follow that sort of logic, as described in microsoft/TypeScript#30581.  The recommended approach is to use generic indexing into mapped types instead; indeed microsoft/TypeScript#47109 is the solution to microsoft/TypeScript#30581 (or at least the closest we have to a solution).\nIt could look like this:\nconst _functionMap = {\n    A: funcA,\n    B: funcB\n}\n\ntype FuncOptionMap =\n    { [K in keyof typeof _functionMap]: Parameters<typeof _functionMap[K]>[0] }\ntype FuncRetMap =\n    { [K in keyof typeof _functionMap]: ReturnType<typeof _functionMap[K]> }\n\nconst functionMap: { [K in keyof FuncOptionMap]: (options: FuncOptionMap[K]) => FuncRetMap[K] }\n    = _functionMap\n\nEssentially we rename your functionMap to _functionMap and then later assign it back with the FuncOptionMap and FuncRetMap types computed from it.  It might look like a no-op, since the type of _functionMap and the type of functionMap appear to be identical.  But this is actually very important; the compiler can only follow the logic when things are written as this mapping. If you try to use _functionMap instead of functionMap in what follows, the compiler will lose the thread and output an error.\nContinuing:\nfunction callFunction<K extends keyof FuncOptionMap>(\n    type: K, options: FuncOptionMap[K]\n) {\n    return functionMap[type](options); // okay\n}\n\nThat type checks, and the return type is FuncRetMap[K].  Now you get the error you expected:\ncallFunction('A', { type: 'B', opt3: 'Hello' }) // error!\n// ---------------------> ~~~ B is not A\n\nand when you call it the compiler knows how the output type as depends on the input type:\nconsole.log(callFunction(\n    \"B\",\n    { type: \"B\", opt3: 1, opt4: x => x + 1 }\n).toLowerCase()); // okay, the compiler knows it's string and not number\n\nPlayground link to code\n"
},
{
"QuestionId": "76381320",
"QuestionTitle": "Spring Security Access Denied with Spring Boot 3.0",
"QuestionBody": "I'm doing a pet project of a social network and I'm having problems with authorization.I getting Access Denied when I send a request with a jwt token.\nI am doing the following chain of actions:\n\nRegistration where I specify the login email and password (Works well)\nAuthorization where by login and password I get a token (Works well)\nI'm trying to send a request in the postman with the received token where I get an error(Access Denied)\n\nWhats wrong with my code?\nMy Security Config:\n@Configuration\n@EnableWebSecurity\n@EnableMethodSecurity( proxyTargetClass = true)\npublic class WebSecurityConfig  {  \n    @Autowired\n    UserDetailsServiceImpl userDetailsService;\n\n    @Autowired\n    private AuthEntryPointJwt unauthorizedHandler;\n\n    @Bean\n    public AuthTokenFilter authenticationJwtTokenFilter() {\n        return new AuthTokenFilter();\n    }\n    \n    @Bean\n    public DaoAuthenticationProvider authenticationProvider() {\n        DaoAuthenticationProvider authProvider = new DaoAuthenticationProvider();\n\n        authProvider.setUserDetailsService(userDetailsService);\n        authProvider.setPasswordEncoder(passwordEncoder());\n\n        return authProvider;\n    }\n    \n    @Bean\n    public AuthenticationManager authenticationManager(AuthenticationConfiguration authConfig) throws Exception {\n        return authConfig.getAuthenticationManager();\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n    \n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        http.cors().and().csrf().disable()\n                .exceptionHandling()\n                .authenticationEntryPoint(unauthorizedHandler)\n                .and()\n                .sessionManagement()\n                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n                .and()\n                .authorizeHttpRequests()\n                .requestMatchers(\"/auth/**\").permitAll()\n                .requestMatchers(\"/swagger/**\").permitAll()\n                .requestMatchers(\"/swagger-ui/**\").permitAll()\n                .requestMatchers(\"/v3/api-docs/**\").permitAll()\n                .requestMatchers(\"/auth/test/**\").permitAll()\n                .requestMatchers(\"/h2/**\").permitAll()\n                .anyRequest().authenticated();\n        \n        http.authenticationProvider(authenticationProvider());\n        http.addFilterBefore(authenticationJwtTokenFilter(), UsernamePasswordAuthenticationFilter.class);\n\n        return http.build();\n    }\n}\n\nAythTokenFilter:\n@Slf4j\npublic class AuthTokenFilter extends OncePerRequestFilter {\n    @Autowired\n    private JwtUtils jwtUtils;\n\n    @Autowired\n    private UserDetailsServiceImpl userDetailsService;\n\n\n    @Override\n    protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain)\n            throws ServletException, IOException {\n        try {\n            String accessToken = parseJwt(request);\n            if (accessToken != null && jwtUtils.validateJwtToken(accessToken)) {\n                String username = jwtUtils.getUserNameFromJwtToken(accessToken);\n\n                UserDetails userDetails = userDetailsService.loadUserByUsername(username);\n                UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(userDetails, null,\n                        userDetails.getAuthorities());\n                authentication.setDetails(new WebAuthenticationDetailsSource().buildDetails(request));\n\n                SecurityContextHolder.getContext().setAuthentication(authentication);\n            }\n        } catch (Exception e) {\n            log.error(\"Cannot set user authentication: {}\", e.getMessage());\n        }\n\n        filterChain.doFilter(request, response);\n    }\n\n    private String parseJwt(HttpServletRequest request) {\n        String headerAuth = request.getHeader(\"Authorization\");\n\n        if (StringUtils.hasText(headerAuth) && headerAuth.startsWith(\"Bearer \")) {\n            return headerAuth.substring(7, headerAuth.length());\n        }\n\n        return null;\n    }\n}\n\nJWTUtils:\n@Component\n@Slf4j\npublic class JwtUtils {\n\n    @Value(\"${jwt.token.secret}\")\n    private String jwtSecret;\n\n    @Value(\"${jwt.token.jwtExpirationMs}\")\n    private int jwtExpirationMs;\n\n    public String generateJwtToken(UserDetailsImpl userPrincipal) {\n        return generateTokenFromUsername(userPrincipal.getUsername());\n    }\n\n    public String generateTokenFromUsername(String username) {\n        return Jwts.builder().setSubject(username).setIssuedAt(new Date())\n                .setExpiration(new Date((new Date()).getTime() + jwtExpirationMs)).signWith(SignatureAlgorithm.HS512, jwtSecret)\n                .compact();\n    }\n\n    public String getUserNameFromJwtToken(String token) {\n        return Jwts.parser().setSigningKey(jwtSecret).parseClaimsJws(token).getBody().getSubject();\n    }\n\n    public boolean validateJwtToken(String authToken) {\n        try {\n            Jwts.parser().setSigningKey(jwtSecret).parseClaimsJws(authToken);\n            return true;\n        } catch (SignatureException e) {\n            log.error(\"Invalid JWT signature: {}\", e.getMessage());\n        } catch (MalformedJwtException e) {\n            log.error(\"Invalid JWT token: {}\", e.getMessage());\n        } catch (ExpiredJwtException e) {\n            log.error(\"JWT token is expired: {}\", e.getMessage());\n        } catch (UnsupportedJwtException e) {\n            log.error(\"JWT token is unsupported: {}\", e.getMessage());\n        } catch (IllegalArgumentException e) {\n            log.error(\"JWT claims string is empty: {}\", e.getMessage());\n        }\n\n        return false;\n    }\n\n}\n\nController method:\n@GetMapping(\"/requests\")\n    @PreAuthorize(\"hasRole('ROLE_USER')\")\n    public UsernamesResponse getFriendRequests() {\n        return userService.getFriendRequests();\n    }\n\nStacktrace:\norg.springframework.security.access.AccessDeniedException: Access Denied\n    at org.springframework.security.authorization.method.AuthorizationManagerBeforeMethodInterceptor.attemptAuthorization(AuthorizationManagerBeforeMethodInterceptor.java:257) ~[spring-security-core-6.0.0.jar:6.0.0]\n    at org.springframework.security.authorization.method.AuthorizationManagerBeforeMethodInterceptor.invoke(AuthorizationManagerBeforeMethodInterceptor.java:198) ~[spring-security-core-6.0.0.jar:6.0.0]\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.0.2.jar:6.0.2]\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:752) ~[spring-aop-6.0.2.jar:6.0.2]\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:703) ~[spring-aop-6.0.2.jar:6.0.2]\n    at ru.effectivemobile.socialnetwork.controller.UserController$$SpringCGLIB$$0.getFriendRequests(<generated>) ~[classes/:na]\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\n    at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:207) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:152) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:884) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1080) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:973) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1003) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:895) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:705) ~[tomcat-embed-core-10.1.1.jar:6.0]\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:880) ~[spring-webmvc-6.0.2.jar:6.0.2]\n    at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:814) ~[tomcat-embed-core-10.1.1.jar:6.0]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:223) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:185) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:110) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:185) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.springframework.security.web.FilterChainProxy.lambda$doFilterInternal$3(FilterChainProxy.java:231) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:365) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.access.intercept.AuthorizationFilter.doFilter(AuthorizationFilter.java:100) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:126) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:120) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:131) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:85) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:100) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:179) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at ru.effectivemobile.socialnetwork.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:47) ~[classes/:na]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:107) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:93) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.context.SecurityContextHolderFilter.doFilterInternal(SecurityContextHolderFilter.java:69) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:62) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:233) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:191) ~[spring-security-web-6.0.0.jar:6.0.0]\n    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:351) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:185) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:185) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:185) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-6.0.2.jar:6.0.2]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:185) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:158) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:119) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:400) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:861) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1739) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-10.1.1.jar:10.1.1]\n    at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]\n\nEDIT 1\nJwt token example:\neyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJ0ZXN0IiwiaWF0IjoxNjg1NjIyMjc4LCJleHAiOjE2ODU2MjU4Nzh9.A_gw2V1c403vxANRcO5LCU7621TMYvYeBKKb-YJv_ZTjEPKym140YAlIjnqAOhoQtfhKRm2O-pJke-7zzglzSg\n\nEDIT 2\n\n\n\n\n",
"AnswerId": "76384140",
"AnswerBody": "Your problem relates to the difference in Spring between ROLES and Authorities and the Spring hack that treats Roles as Authorities prefixed with \"ROLE_\"\nIn order to use the annotation @PreAuthorize(\"hasRole('ROLE_USER')\") you need a Permission as follows:\nROLE_USER(\"ROLE_USER\")\n\nWhich is related to your ERole enum as follows:\nROLE_USER(Set.of(Permission.ROLE_USER, Permission.READ))\nIf you are only using the Permission.READ, etc for Controller level authority checking then drop them.\nAlternatively use annotation like this @PreAuthorize(\"hasAuthotity('READ')\")and drop the roles.\nI have made changes (on branch fix/authorities at https://github.com/KoosieDeMoer/social-network.git) with stubbed out repo that work.\n"
},
{
"QuestionId": "76381531",
"QuestionTitle": "Get product version from a custom action",
"QuestionBody": "I have a Wix installer.\nIn the Product.wxs file, I have the below piece of code:\n<Product Id=\"*\"\n    Name=\"$(var.PRODUCT_NAME)\"\n    Language=\"1033\"\n    Version=\"!(bind.FileVersion.myDLLfile)\"\n    Manufacturer=\"$(var.CompanyName)\"\n    UpgradeCode=\"{D00BA432-7798-588A-34DF-34A65378FD45}\">\n\nIn the Features.wxs, I have the myDLLfile defined as component:\n<Component Id=\"myDLLfile\"\n    Guid=\"{30550881-053F-768D-88B7-BB9853B23C51}\">\n    <File Id=\"myDLLfile\"\n        Source=\"$(var.dllDir)\\myDLLfile.dll\"\n        KeyPath=\"yes\"\n        Checksum=\"yes\"/>\n</Component>\n\nNow, I would like to know if from a custom action in C# I can get that same Product Version (which corresponds to the version of the myDllfile.dll). Is it possible? If so, how?\n",
"AnswerId": "76384167",
"AnswerBody": "The easiest way is probably to store the value in a Property and read that property in the custom action. The bind variable syntax would make setting the property easy.\n   <Property Id=\"ThisIsASillyThingToNeedToDo\" Value=\"!(bind.FileVersion.myDLLfile)\" />\n\n"
},
{
"QuestionId": "76384063",
"QuestionTitle": "Why does Mysql change query execution plan based on query parameters?",
"QuestionBody": "I have the following query.\nSELECT *\nFROM user u\nLEFT JOIN operator o ON o.id = u.id\nWHERE u.user_type_id IN (2,4) AND u.is_enabled = 1 AND u.office_id = 225\n\nIf I run explain on the query above, it shows that it uses the index IX_user_type for the table user.\nIf I just change the office_id comparison value like the following, the execution plan changes.\nSELECT *\nFROM user u\nLEFT JOIN operator o ON o.id = u.id\nWHERE u.user_type_id IN (2,4) AND u.is_enabled = 1 AND u.office_id = 32365487\n\nIn this case, the explain shows that the indexes used for the table user are fk_user_office,IX_user_is_enabled.\nI made some tests and would say, performance wise, the first execution plan is much better than the second one. Now, I know I can force Mysql to use the index I want but, I would like to understand why this happens. Why would Mysql pick an index instead of another based on a query parameter?\n",
"AnswerId": "76385989",
"AnswerBody": "MySQL may decide not to use the index on office_id if the value you are searching for is too common.\nBy analogy, why doesn't a book include common words like \"the\" in the index at the back of the book? Because such common words occur on a majority of pages in the book. It's unnecessary to keep a list of those pages under the respective word in the index, because it's easier to tell the reader to read all the pages in the book, without the index lookup.\nSimilarly, if MySQL estimates that a given value you are searching for occurs on a high enough portion of the pages, it looks for another index if you have other conditions, and if none are found, then it resorts to a table-scan.\nIn this case, I'd ask if you can confirm that office_id 225 is very common in this table.\n\nOne more thought: The best index of all for the query you show would be a compound index on (office_id, is_enabled, user_type). Then it would be able to use that index to narrow down the search by all three columns at once.\nYou might like my presentation How to Design Indexes, Really or the video. I also have a chapter on index design in my book SQL Antipatterns, Volume 1:\nAvoiding the Pitfalls of Database Programming.\n"
},
{
"QuestionId": "76382547",
"QuestionTitle": "Save the output of bigquery in JSON from python",
"QuestionBody": "How can I modify this script to be able to see/print some of the results and write the output in JSON :\nfrom google.cloud import bigquery\n\n\ndef query_stackoverflow(project_id=\"gwas-386212\"):\n    client = bigquery.Client()\nquery_job = client.query(\n        \"\"\"\n        WITH\n  SNP_info AS (\n  SELECT\n    CONCAT(CAST(rs_id AS string)) AS identifier\n  FROM\n  `gwas-386212.gwas_dataset_1.SNPs_intergenic_vep_pha005199`)\nSELECT\n  *\nFROM\n  SNP_info\nJOIN (\n  SELECT\n    CONCAT(CAST(rs_id AS string)) AS identifier,\nchr_id AS chr_id,\nposition AS position, \nref_allele AS ref,\nalt_allele AS alt,\nmost_severe_consequence AS most_severe_consequence, \ngene_id_any_distance AS gene_id_any_distance,\ngene_id_any AS gene_id_any,\ngene_id_prot_coding_distance AS gene_id_prot_coding_distance, \ngene_id_prot_coding AS gene_id_prot_coding\n FROM\n    `bigquery-public-data.open_targets_genetics.variants`) variants\nON\n  SNP_info.identifier = variants.identifier\"\"\" \n  )\nresults = client.query(query)\n\nfor row in results:\n    title = row['identifier']\n    identifier = row['identifier']\n    #print(f'{identifier}')\n\nThis is just printing a column the intentifier. i want to save the resulted table in JSON format. The JSOn from the google cloud platform should look something like this:\n[{\n  \"identifier\": \"rs62063022\",\n  \"identifier_1\": \"rs62063022\",\n  \"chr_id\": \"17\",\n  \"position\": \"51134537\",\n  \"ref\": \"T\",\n  \"alt\": \"G\",\n  \"most_severe_consequence\": \"intergenic_variant\",\n  \"gene_id_any_distance\": \"13669\",\n  \"gene_id_any\": \"ENSG00000008294\",\n  \"gene_id_prot_coding_distance\": \"13669\",\n  \"gene_id_prot_coding\": \"ENSG00000008294\"\n}, {\n  \"identifier\": \"rs12944420\",\n  \"identifier_1\": \"rs12944420\",\n  \"chr_id\": \"17\",\n  \"position\": \"42640692\",\n  \"ref\": \"T\",\n  \"alt\": \"C\",\n  \"most_severe_consequence\": \"intergenic_variant\",\n  \"gene_id_any_distance\": \"18592\",\n  \"gene_id_any\": \"ENSG00000037042\",\n  \"gene_id_prot_coding_distance\": \"18592\",\n  \"gene_id_prot_coding\": \"ENSG00000037042\"\n},\n\n",
"AnswerId": "76384317",
"AnswerBody": "Check out json documentation for further information.\nrecords = [dict(row) for row in results]\nout_file = open(\"bigquery_response.json\", \"w\")\njson.dump(records , out_file, indent = 6)\nout_file.close()\n\n"
},
{
"QuestionId": "76381598",
"QuestionTitle": "How to rewrite sync method using SwiftUI?",
"QuestionBody": "Now I'm using UIImage sync extension.\nstruct PostView: View {\n    let url: String\n    \n    var body: some View {        \n        PrivateImageView(image: UIImage(url:url))\n     }\n}\n\nextension UIImage {\n    public convenience init(url: String) {\n        let url = URL(string: url)\n        do {\n            let data = try Data(contentsOf: url!)\n            self.init(data: data)!\n            return\n        } catch let err {\n            print(\"Error : \\(err.localizedDescription)\")\n        }\n        self.init()\n    }\n}\n\nWhen I post a image, I got the error Synchronous URL loading of http://local.host/images/123.jpeg should not occur on this application's main thread as it may lead to UI unresponsiveness. Please switch to an asynchronous networking API such as URLSession. at try Data(contentsOf: url!).\nIn PostView I use PrivateImageView.\nTo use the view I have to designate the argument like this PrivateImageView(image: UIImage(xxxxxxxxx)).\nI mean I have to use UIImage() not AsyncImage.\nI don't know how to change convenience init to adjust to PrivateImageView.\nPlease tell me how to use an async function in this context.\n",
"AnswerId": "76384253",
"AnswerBody": "There is no way to get a data from the inter/intranet synchronously you have to use an async method and account for the time it takes to download.\nextension String {\n    public func getUIImage() async throws -> UIImage {\n        guard let url = URL(string: self) else {\n            throw URLError(.badURL)\n        }\n        \n        let (data, response) = try await URLSession.shared.data(from: url)\n        \n        guard let httpResponse = response as? HTTPURLResponse else {\n            throw URLError(.badServerResponse)\n        }\n        \n        guard httpResponse.statusCode == 200 else {\n            throw URLError(URLError.Code(rawValue: httpResponse.statusCode))\n        }\n        \n        guard let image = UIImage(data: data) else {\n            throw URLError(.fileDoesNotExist)\n        }\n        return image\n    }\n}\n\nextension UIImage {\n    static public func fromURL(url: String) async throws -> UIImage {\n        let image = try await url.getUIImage()\n        return image\n    }\n}\n\nYou can rewrite PostView to something like.\nstruct PostView: View {\n    let url: String\n    @State private var uiImage: UIImage?\n    var body: some View {\n        Group{\n            if let uiImage {\n                PrivateImageView(image: uiImage)\n            } else {\n                ProgressView() //Show this while downloading\n                    .task {\n                        do {\n                            self.uiImage = try await url.getUIImage()\n                            // or\n                            // self.uiImage = try await UIImage.fromURL(url: url)\n                        } catch {\n                            print(error)\n                        }\n                    }\n            }\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76385236",
"QuestionTitle": "Self signed certificate not working on localhost IIS",
"QuestionBody": "I have am setting up a very simple test site on my localhost under IIS which needs to be accessible locally from https.  IU have followed the steps below:\n\nIn IIS for my local server, I have created a self signed certificate and stored in the \"Personal\" store\nI have added a https binding for my test site to this new certificate, the hostname is testite and the port 7001\nAdded the entry '127.0.0.1   testsite' to hosts file.\n\nWhen I try to access https://testsite/index.html through the browser, the browser returns the following error:\nNET::ERR_CERT_COMMON_NAME_INVALID\nSame problem soccurs if I add the port number to the url, i.e: https://testsite:7001/index.html\nMore informatiom on the error shows the following:\nThis server could not prove that it is testsite; its security certificate is from Muzz2. This may be caused by a misconfiguration or an attacker intercepting your connection.\n\n",
"AnswerId": "76386062",
"AnswerBody": "The solution involved using Powershell rather than IIS manager to generate the self signed certificate.  ISS always used the machine name rather than the sitename as the common name.\nThe powershell command I used was as follows:\nNew-SelfSignedCertificate -DnsName testsite -CertStoreLocation cert:\\LocalMachine\\My\nAfter which mmc was used to place the certificate in the Trusted Root Certification Authorities, and the certificated bindings updated in IIS as you you usually would.\n"
},
{
"QuestionId": "76378736",
"QuestionTitle": "How do I implement SSL in Delphi to connect to a REDCap API server?",
"QuestionBody": "I am trying to use XE7 to connect to an in-house REDCap server. REDCap has a detailed description of the API at https://education.arcus.chop.edu/redcap-api/ and a test server at https://bbmc.ouhsc.edu/redcap/api  with a test token key.  There is assistance at https://mran.microsoft.com/snapshot/2015-08-18/web/packages/REDCapR/vignettes/TroubleshootingApiCalls.html in R.\nI can connect to the test site with Curl and PostMan. My problem is how to implement this in Delphi with SSL.\nThe Curl script from PostMan:\ncurl --location 'https://bbmc.ouhsc.edu/redcap/api/' \\\n--data-urlencode 'token=9A81268476645C4E5F03428B8AC3AA7B' \\\n--data-urlencode 'content=record' \\\n--data-urlencode 'action=export' \\\n--data-urlencode 'format=csv' \\\n--data-urlencode 'rawOrLabel=label'\n\nAfter much searching, this is my Delphi code. What have I missed? IdLogFile1 is a component on the form.\nfunction TForm1.IdSSLIOHandlerSocketOpenSSL1VerifyPeer(Certificate: TIdX509; AOk: Boolean; ADepth, AError: Integer): Boolean;\nbegin\n   showmessage('at  IOhandler');                      \n     Result := true;                             // always returns true\nend;\n\n\nprocedure TForm1.idHTTP2BtnClick(Sender: TObject);\nvar post      : string;\n    Params    : TStringList;\n    idHTTP    : TIdHTTP;\n    SSL1      : TIdSSLIOHandlerSocketOpenSSL;\n    status    : integer;\n    response : TstringStream;\nbegin\n   params   := TStringList.Create;\n   idHTTP   := TIdHTTP.Create(nil);\n   SSL1     := TIdSSLIOHandlerSocketOpenSSL.Create(idHTTP);\n   response  := TstringStream.create;\n\n\n   SSL1.SSLOptions.Mode        := sslmClient ;\n   SSL1.SSLOptions.SSLVersions := [sslvTLSv1, sslvTLSv1_1, sslvTLSv1_2 ];// [  sslvSSLv3,  sslvSSLv23,sslvSSLv2, sslvTLSv1, sslvTLSv1_1, sslvTLSv1_2];\n   SSL1.SSLOptions.VerifyDepth := 0;\n   SSL1.OnVerifyPeer           := IdSSLIOHandlerSocketOpenSSL1VerifyPeer;\n   SSL1.SSLOptions.VerifyMode  := [ ];\n   idHTTP.IOHandler            := SSL1;\n\n   memo1.Lines.clear;\n\n   idHTTP.ReadTimeout                 := 3000;\n   idHTTP.ConnectTimeout              := 3000;\n   idHttp.Request.BasicAuthentication := false;\n\n   try\n\n     idHTTP.HandleRedirects := true;\n     idHTTP.Intercept       := IdLogFile1;\n     IdLogFile1.Active      := true;\n\n     IdHttp.Request.CustomHeaders.Clear;\n\n \n     IdHttp.Request.CustomHeaders.Values['token']          := '9A81268476645C4E5F03428B8AC3AA7B';\n     IdHttp.Request.CustomHeaders.Values['content']        := 'record';\n     IdHttp.Request.CustomHeaders.Values['action']         := 'export';\n     IdHttp.Request.CustomHeaders.Values['format']         := 'csv';\n     IdHttp.Request.CustomHeaders.Values['rawOrLabel']     := 'label';\n     IdHttp.Request.CustomHeaders.Values['verify_ssl']     := 'false';\n     IdHttp.Request.CustomHeaders.Values['ssl_verify']     := 'false'; //various verify options ?\n     IdHttp.Request.CustomHeaders.Values['ssl_verifypeer'] := 'false';\n\n \n     idHTTP.Request.ContentType := 'application/x-www-form-urlencoded';\n     IdHTTP.Request.Charset     := 'utf-8';\n     idHTTP.HTTPOptions         := [hoKeepOrigProtocol, hoForceEncodeParams];\n\n     idHTTP.Post('https://bbmc.ouhsc.edu/redcap/api/', params, response );\n\n\n   finally\n        memo1.Lines.add(' ');\n        memo1.lines.add(idHTTP.ResponseText);\n        memo1.Lines.add(' ');\n        status           := idHTTP.ResponseCode;\n        memo1.Lines.Add('code: ' + inttostr(status));\n \n        idhttp.Disconnect;\n \n   end;\n   Params.Free;\n   SSL1.Free;\n   idHTTP.Free;\n   response.Free;\nend;\n\n",
"AnswerId": "76384351",
"AnswerBody": "You are setting up the TLS connection correctly (provided the appropriate OpenSSL DLLs are available where Indy can find them).\nWhat you are not setting up correctly is your data parameters. Curl's --data-urlencode command puts the data in the HTTP request body, not in the HTTP headers. So you need to put the data in the TStringList that you are posting (TIdHTTP will handle the url-encoding for you).\nTry this instead:\nprocedure TForm1.idHTTP2BtnClick(Sender: TObject);\nvar\n  params    : TStringList;\n  idHTTP    : TIdHTTP;\n  idSSL     : TIdSSLIOHandlerSocketOpenSSL;\n  status    : integer;\n  response  : string;\nbegin\n  params := TStringList.Create;\n  try\n    idHTTP := TIdHTTP.Create(nil);\n    try\n      idSSL := TIdSSLIOHandlerSocketOpenSSL.Create(idHTTP);    \n\n      idSSL.SSLOptions.Mode        := sslmClient ;\n      idSSL.SSLOptions.SSLVersions := [sslvTLSv1, sslvTLSv1_1, sslvTLSv1_2 ];\n      idSSL.SSLOptions.VerifyDepth := 0;\n      idSSL.OnVerifyPeer           := IdSSLIOHandlerSocketOpenSSL1VerifyPeer;\n      idSSL.SSLOptions.VerifyMode  := [ ];\n      idHTTP.IOHandler := idSSL;\n\n      Memo1.Lines.Clear;\n\n      idHTTP.ReadTimeout                 := 3000;\n      idHTTP.ConnectTimeout              := 3000;\n      idHTTP.Request.BasicAuthentication := false;\n\n      try    \n        idHTTP.HandleRedirects := true;\n        idHTTP.Intercept       := IdLogFile1;\n        IdLogFile1.Active      := true;\n\n        params.Add('token=9A81268476645C4E5F03428B8AC3AA7B');\n        params.Add('content=record');\n        params.Add('action=export');\n        params.Add('format=csv');\n        params.Add('rawOrLabel=label');\n\n        idHTTP.Request.ContentType := 'application/x-www-form-urlencoded';\n        idHTTP.Request.Charset     := 'utf-8';\n        idHTTP.HTTPOptions         := [hoKeepOrigProtocol, hoForceEncodeParams];\n\n        response := idHTTP.Post('https://bbmc.ouhsc.edu/redcap/api/', params);    \n      finally\n        Memo1.Lines.Add(' ');\n        Memo1.Lines.Add(idHTTP.ResponseText);\n        Memo1.Lines.Add(' ');\n        status := idHTTP.ResponseCode;\n        Memo1.Lines.Add('code: ' + IntToStr(status));\n      end;\n    finally\n      idHTTP.Free;\n    end;\n  finally\n    params.Free;\n  end;\nend;\n\n"
},
{
"QuestionId": "76381369",
"QuestionTitle": "Stored procedure with EF6 Code first - best practice?",
"QuestionBody": "In my program I have to import data from a remote sqlserver database.\nI am using ASP.NET MVC 5 and EF6 Code First (I'm new with EF and MVC 5).\nFirst, I copy data from a remote view to a table in the local database.\nFor this part I use this code in the action method (names are in italian):\nusing (var source = new TimeWebDBContext())\n{\n using (var target = new GESTPrefContext())\n  {\n   // 1 - Truncate table AnagraficaTimeWeb is exists\n   target.Database.ExecuteSqlCommand(\"IF EXISTS(SELECT 1 FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME='AnagraficaTimeWeb') TRUNCATE TABLE AnagraficaTimeWeb\");\n    \n   // 2 - Copy from remote view  to  AnagraficaTimeWeb table\n   var dati_importati = from i in source.VW_PREFNO_ANAGRAFICORUOLO\n        select new AnagraficaTimeWeb()\n        {\n         Matricola = i.MATRICOLA,\n         Cognome = i.COGNOME,\n         Nome = i.NOME,\n         Sesso = i.SESSO,\n         Email = i.EMAIL,\n         IdRuolo = i.IDRUOLO,\n         Ruolo = i.RUOLO,\n         DataInizio = i.DATAINIZIO,\n         DataFine = i.DATAFINE,\n         DataFineRapporto = i.DATALICENZ,\n         DataUltimaImportazione = DateTime.Now\n        };\n        target.DatiAnagraficaTimeWeb.AddRange(dati_importati.ToList());\n        target.SaveChanges();\n   }\n}\n\nThe view returns a list of employees with their role.\nRoles have to be imported in a distinct local table called PROFILO, while employees data are saved in the IMPIEGATO table.\nThe remaining part of the import process consists of :\na) insert new data in the PROFILO table (data already saved are ignored)\nb) update of employee data already present in the local IMPIEGATO table (name, email,etc. are overwritten)\nc) insert new empoyee not yet in the IMPIEGATO table.\nsince I’m new to EF6 I thought I’d use SQL code .\nIn my opinion the possible solutions are :\n\nexecute SQL code directly in the actionmethod with db.Database.ExecuteSqlCommand\nThis is the code i write:\n\ncode for point a)\nStringBuilder sql = new StringBuilder();\nsql.AppendLine(\"INSERT INTO PROFILO (IdTimeWeb, Descrizione, Ordinamento, Stato, Datainserimento)\");\nsql.AppendLine(\" SELECT DISTINCT IdRuolo, Ruolo, 1,\" + ((int)EnumStato.Abilitato) + \",'\" + DateTime.Now.ToShortDateString()+\"'\");\nsql.AppendLine(\" FROM AnagraficaTimeWeb i\");\nsql.AppendLine(\" WHERE NOT EXISTS\");\nsql.AppendLine(\"(SELECT 1 FROM PROFILO p WHERE p.Descrizione = i.Ruolo)\");\ntarget.Database.ExecuteSqlCommand(sql.ToString());\n\ncode for point b)\nsql.Clear();\nsql.Append(\"UPDATE i \" + Environment.NewLine);\nsql.Append(\" SET i.Cognome = a.Cognome\" + Environment.NewLine);\nsql.Append(\" , i.Nome = a.Nome\" + Environment.NewLine);\nsql.Append(\" , i.Sesso = a.Sesso\" + Environment.NewLine);\nsql.Append(\" ,i.Email = a.Email\" + Environment.NewLine);\nsql.Append(\" ,i.DataModifica = '\" + DateTime.Now.ToShortDateString() +\"'\"+ Environment.NewLine);\nsql.Append(\" FROM Impiegato i \" + Environment.NewLine);\nsql.Append(\" JOIN AnagraficaTimeWeb a on i.Matricola=a.Matricola \" + Environment.NewLine);\nsql.Append(\" WHERE i.Stato =\" + ((int)EnumStato.Abilitato)  + Environment.NewLine);\ntarget.Database.ExecuteSqlCommand(sql.ToString());\n    \n\ncode for point c)\nsql.Clear();\nsql.Append(\"INSERT INTO IMPIEGATO(Cognome, Nome, Matricola, Sesso, Email, Stato, DataInserimento) \" + Environment.NewLine);\nsql.Append(\"SELECT a.Cognome\" + Environment.NewLine);\nsql.Append(\", a.Nome\" + Environment.NewLine);\nsql.Append(\", a.Matricola\" + Environment.NewLine);\nsql.Append(\", a.Sesso\" + Environment.NewLine);\nsql.Append(\", a.Email\" + Environment.NewLine);\nsql.Append(\",\" + ((int)EnumStato.Abilitato )+ Environment.NewLine);\nsql.Append(\",'\"+ DateTime.Now.ToShortDateString() +\"'\" + Environment.NewLine);\nsql.Append(\" FROM AnagraficaTimeWeb a \" + Environment.NewLine);\nsql.Append(\" LEFT OUTER JOIN IMPIEGATO on a.Matricola = Impiegato.Matricola \" + Environment.NewLine);\nsql.Append(\"  WHERE Impiegato.Matricola is null\" + Environment.NewLine);\n\ntarget.Database.ExecuteSqlCommand(sql.ToString());      \n                    \n                \n\n\ncreate a storedprocedure to call in the actionmetghod. in this case how to create the storedprocedure?\n\n2.a) in the Up method of a migration ?\n2.b) or running the storedprocedure creation script directly in the database (after it was first created ) and then run the stored from the action method?\n",
"AnswerId": "76384486",
"AnswerBody": "You can create stored procedure directly in db and write all three remaining part of your process (point a,b,c) in one SP (stored procedure). SP is stored as object file in sql so it's fast and sql server don't spend time in making execution plan and other extra things.\nIn order to create sp, you need to more familiar with sql statements and it's control structures etc. It will feel like learning new language. You can start with below link\nhttps://learn.microsoft.com/en-us/sql/relational-databases/stored-procedures/stored-procedures-database-engine?view=sql-server-ver16\nTo save that stored procedure as migration script you can create a blank migration using\nadd-migration 'SPName' -IgnoreChanges \nThen add your sp\npublic partial class SPName: DbMigration\n{\n    public override void Up()\n    {\n        Sql(@\"Create Stored Procedure script\");\n\n    }\n\n    public override void Down()\n    {\n        Sql(@\"Drop Stored Procedure script\")\n    }\n} \n\ndon't forget to change migration script every time you modify/alter sp. You can also make migration script of modified sp.\nTo execute your sp you can refer the below code snippet. SqlPatameter helps you to make query clean,you can avoid sql injection.\nList<SqlParameter> sqlParms = new List<SqlParameter>\n  {\n    new SqlParameter { ParameterName = \"@Id\", Value = employee.EmployeeID },\n    new SqlParameter { ParameterName = \"@FirstName \", Value = employee.FirstName },\n    new SqlParameter { ParameterName = \"@LastName\", Value = employee.LastName}\n};\ndb.Database.ExecuteSqlRaw(\"EXEC dbo.spName @Id, @FirstName, @LastName\" sqlParms.ToArray());\n\n"
},
{
"QuestionId": "76384694",
"QuestionTitle": "How to do conditional compilation with Zig?",
"QuestionBody": "For example, I can add definitions for C/C++ preprocessor with CMake\nadd_definitions(-DFOO -DBAR ...)\n\nand then I can use them for conditional compilation\n#ifdef FOO\n   code ...\n#endif\n\n#ifdef BAR\n   code ...\n#endif\n\n\nIs there a way to do the same thing with Zig and its build system using compilation arguments or something like that?\n",
"AnswerId": "76386084",
"AnswerBody": "You can do something similar using the build system. This requires some boilerplate code to do the option handling. Following the tutorial on https://zig.news/xq/zig-build-explained-part-1-59lf for the build system and https://ziggit.dev/t/custom-build-options/138/8 for the option handling:\n\nCreate a separate file called build.zig that contains a function build():\n\nconst std = @import(\"std\");\n\npub fn build(b: *std.build.Builder) !void {\n    const build_options = b.addOptions();\n    // add command line flag\n    // and set default value\n    build_options.addOption(bool, \"sideways\", b.option(bool, \"sideways\", \"print sideways\") orelse false);\n\n    // set executable name and source code\n    const exe = b.addExecutable(\"hello\", \"hello.zig\");\n    exe.addOptions(\"build_options\", build_options);\n    // compile and copy to zig-out/bin\n    exe.install();\n}\n\n\nUse the option for conditional compilation in a separate file hello.zig using @import(\"build_options\"):\n\nconst std = @import(\"std\");\n\npub fn main() !void {\n    const print_sideways = @import(\"build_options\").sideways;\n    const stdout = std.io.getStdOut().writer();\n    if (print_sideways) {\n       try stdout.print(\"Sideways Hello, {s}!\\n\", .{\"world\"});\n    } else {\n       try stdout.print(\"Regular Hello, {s}!\\n\", .{\"world\"});\n    }\n}\n\n\nCompile with:\n\nzig build -Dsideways=true\n\n\nExecuting zig-out/bin/hello gives the following output:\n\nSideways Hello, world!\n\n"
},
{
"QuestionId": "76382999",
"QuestionTitle": "Cognito JWT Authorize in ASP.NET Core 6 Web API",
"QuestionBody": "How can I configure my ASP.NET Core 6 Web API controllers to use AWS Cognito authorization?\nThis is the code I wrote in my program.cs file:\nvar AWSconfiguration = builder.Configuration.GetSection(\"AWS:Cognito\");\nvar userPoolId = AWSconfiguration[\"UserPoolId\"];\nvar clientId = AWSconfiguration[\"ClientId\"];\nvar region = AWSconfiguration[\"Region\"];\n\nbuilder.Services.AddAuthentication(options =>\n{\n    options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;\n    options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;\n})\n.AddJwtBearer(options =>\n{\n    options.Authority = $\"https://cognito-idp.{region}.amazonaws.com/{userPoolId}\";\n    options.TokenValidationParameters = new TokenValidationParameters\n    {\n        ValidateIssuerSigningKey = true,\n        ValidateIssuer = true,\n        ValidateAudience = true,\n        ValidIssuer = $\"https://cognito-idp.{region}.amazonaws.com/{userPoolId}\",\n        ValidAudience = clientId,\n        \n    };\n});\n\nI'm getting this error:\n\nwww-authenticate: Bearer error=\"invalid_token\",\nerror_description=\"The audience 'empty' is invalid\"\n\nI validated my clientID in the AWS console.\nThanks for the help\n",
"AnswerId": "76384407",
"AnswerBody": "Cognito access tokens don't have an audience claim - though ideally they should. In other authorization servers, APIs check the received access token has the expected logical name, such as api.mycompany.com.\nFor Cognito you will need to configure .NET to not validate the audience, similar to this. Other token validation parameters are derived from the metadata endpoint derived from the issuer base URL:\nprivate void ConfigureOAuth(IServiceCollection services)\n{\n    services\n        .AddAuthentication(JwtBearerDefaults.AuthenticationScheme)\n        .AddJwtBearer(options =>\n        {\n            options.Authority = this.configuration.IssuerBaseUrl;\n            options.TokenValidationParameters = new TokenValidationParameters\n            {\n                ValidateAudience = false,\n            };\n        });\n\n    services.AddAuthorization(options => \n    {\n        options.FallbackPolicy = new AuthorizationPolicyBuilder().RequireAuthenticatedUser().Build();\n    });\n}\n\n\nThe FallbackPolicy then ensures that authentication is applied globally, except for endpoints annotated with [AllowAnonymous].\n"
},
{
"QuestionId": "76381827",
"QuestionTitle": "How to pass arguments in cron job function",
"QuestionBody": "Im totaly new in wordpress php and cron. So, I have a task. I need to take data from a form and put it into a cron function.\nThis is me code. I created custom plugin page in wordpress admin panel and try to run this code.\nactually the code works if I enter a article id instead of a variable $post_id;\n\nfunction cron_add_one_minute( $schedules ) {\n    $schedules['one_minute'] = array(\n        'interval' => 60,\n        'display'  => 'One in minute'\n    );\n    return $schedules;\n};\n    if(!empty($_POST) && ($_POST['btnaup']) && !wp_next_scheduled( 'update_post' )) {\n        wp_schedule_event( time(), 'one_minute', 'update_post');\n    }\n\n    if(isset( $_POST['btnaup'])) {\n        $post_id = $_POST['id'];\n        $b = $_POST['days'];\n    }\n\nadd_action( 'update_post', 'update_my_post', 10, 1);\n\nfunction update_my_post( $post_id ){\n        $time = current_time('mysql');\n \n        wp_update_post( array (\n            'ID'            => $post_id, \n            'post_date'     => $time,\n            'post_date_gmt' => get_gmt_from_date( $time ),\n            'post_modified' => $time,\n            'post_modified_gmt' => get_gmt_from_date($time),\n        )  );\n}\n\n\n\n",
"AnswerId": "76384517",
"AnswerBody": "Per the docs for wp_schedule_event, the fourth parameter, which you are 't currently using, is $args\n\nArray containing arguments to pass to the hook's callback function. Each value in the array is passed to the callback as an individual parameter.\nThe array keys are ignored.\nDefault: array()\n\nThis means you should be able to use:\nif (!empty($_POST) && ($_POST['btnaup']) && !wp_next_scheduled('update_post')) {\n    $data = [\n        $_POST['id'],\n    ];\n\n    wp_schedule_event(time(), 'one_minute', 'update_post', $data);\n}\n\nYour update_my_post function should just work then.\n"
},
{
"QuestionId": "76381875",
"QuestionTitle": "How to start a GUI executable and a console program and terminate the console application on GUI application closed by the user?",
"QuestionBody": "I am executing a script which starts an executable proc1.exe. When proc1.exe is running, the batch file has to start another executable proc2.exe.\nExample: File A.bat runs proc1.exe with following requirements.\n\nWhen proc1.exe is running, proc2.exe should run.\nWhen proc1.exe is closed, proc2.exe should be terminated.\n\nI tried this code:\ntasklist /fi \"ImageName eq proc1.exe\" /fo csv 2>NUL|find /I \"proc1.exe\">NUL\n\nif \"%ERRORLEVEL%\"==\"0\" \necho proc1.exe  is running\nstart /wait proc2.exe\n\nelse\n\ntaskkill /F /IM proc2.exe \n\nWhen I run the script, the command window displays the error message:\n\nThe syntax of tasklist command is incorrect.\n\nWhat is the issue with the above tasklist command line?\nI am not sure whether the else part would be achieved. How do I come back to else part in the script and kill proc2.exe after proc1.exe is terminated.\nHow could this be achieved?\n\nHere are more information after post of first version of Mofi´s answer.\nThis is what I have tried and I think, I am near to the solution but need your support.\nBatch file A.bat is modified to:\nstart bin\\proc1.exe 2>&1\nrem proc1.exe is running. Proc1.exe is a GUI application with buttons and\nrem widgets. The cmd window and the GUI application window are opened now.\n\nstart /wait proc2.exe 2>&1\nrem proc2.exe is running now too. It is a Windows console application.\nrem A second console window is opened for that reason.\nrem Both proc1.exe and proc2.exe are running as processes.\n    \nrem Now I want to check whether Proc1.exe is running or not.\nrem If it is running do nothing, else terminate proc2.exe.\nrem I have written a loop for that purpose. The issue is that\nrem the control is not coming to the loop.\n\nrem When I close the GUI application, the ELSE part should\nrem be executed and proc2.exe should be terminated/killed.\n\nrem How do I bring the control to loop label or how \nrem to signal proc1.exe is closed and run taskkill?\n\n:loop\ntasklist /FI \"IMAGENAME eq proc1.exe\" 2>NUL | find /I /N \"proc1.exe\">NUL\nif \"%ERRORLEVEL%\"==\"0\" (\n    timeout /T 1 /NOBREAK >NUL\n    goto loop\n) else (\n    taskkill /F /IM proc2.exe  >NUL\n)\n\n",
"AnswerId": "76384775",
"AnswerBody": "The task is very unclear.\n\nIs proc1.exe started outside of the batch file or also by the batch file?\nIs proc1.exe a Windows console or a Windows GUI application and does it open files for read/write operations or makes it registry reads/writes or does it open connections to other processes or even other devices?\nIs proc2.exe a Windows console or a Windows GUI application and does it open files for read/write operations or makes it registry reads/writes or does it open connections to other processes or even other devices?\nIs it possible to start proc2.exe a second before proc1.exe or does proc2.exe depend on an already running proc1.exe for a successful start?\nCan be more instances of proc1.exe and/or proc2.exe already running before the batch file starts just proc2.exe or both applications?\nIs it possible that even more instances of proc1.exe or proc2.exe are started by a user or any other process while the batch file observes the one or two processes started during execution of the batch file.\nIs it really okay forcing a brutal kill of all running instances of proc2.exe by the operating system by using TASKKILL with the options /F /IM proc2.exe giving none of the running proc2 processes the chance to gracefully terminate with closing connections, finishing all read/write operations, saving unsaved data and closing files?\n\nLet me assume the answers on these seven questions are as follows:\n\nThe batch file always starts proc1.exe.\nIt is unknown what proc1.exe is and what it does.\nIt is unknown what proc2.exe is and what it does.\nYes, proc2.exe starts also successful on proc1.exe not already running.\nYes, that is indeed possible.\nYes, that is possible, too.\nNo, that is not okay. proc2.exe should close itself and should not be killed by the OS.\n\nIn this case can be used the following commented batch file:\n@echo off\nsetlocal EnableExtensions DisableDelayedExpansion\nrem Define the two programs to run which can be even twice the same program.\nset \"ProgStart_FullName=%SystemRoot%\\Notepad.exe\"\nset \"ProgWait_FullName=%SystemRoot%\\Notepad.exe\"\n\nrem Get just the file name of the first program with file extension.\nfor %%I in (\"%ProgStart_FullName%\") do set \"ProgStart_FileName=%%~nxI\"\n\nrem Delete all environment variables of which name starts with\nrem #PID_ in the local environment of this batch file context.\nfor /F \"delims==\" %%I in ('set #PID_ 2^>nul') do \"set %%I=\"\n\nrem Get all process identifiers of all already running processes\nrem of the executable which is started next by the the batch file.\nfor /F \"tokens=2\" %%I in ('%SystemRoot%\\System32\\tasklist.exe /FI \"IMAGENAME eq %ProgStart_FileName%\" /NH') do set \"#PID_%%I=1\"\n\nrem Start the program which should run as separate process.\nstart \"\" \"%ProgStart_FullName%\"\n\nrem Find out the process identifier of just started program. There are\nrem hopefully not started two instances of this program at the same time.\nfor /F \"tokens=2\" %%I in ('%SystemRoot%\\System32\\tasklist.exe /FI \"IMAGENAME eq  %ProgStart_FileName%\" /NH') do if not defined #PID_%%I set \"#PID_OBSERVE=%%I\" & goto StartNext\necho ERROR: Failed to start \"%ProgStart_FullName%\"!& echo(& pause & goto EndBatch\n\n:StartNext\nrem Start the next program and wait for its self-termination.\n\"%ProgWait_FullName%\"\n\nrem Check if the first started program is still running and send it in\nrem this case the WM_CLOSE message for a graceful self-termination giving\nrem the process the chance to close all connections, finish all file and\nrem registry accesses with saving all unsaved data and close all files.\n%SystemRoot%\\System32\\tasklist.exe /FI \"PID eq %#PID_OBSERVE%\" | %SystemRoot%\\System32\\find.exe /I \"%ProgStart_FileName%\" >nul || goto EndBatch\n%SystemRoot%\\System32\\taskkill.exe /PID %#PID_OBSERVE% >nul 2>nul\n\nrem Wait five seconds for the self-termination of the first started program.\nrem A Windows GUI program should get even more time, especially if a user uses\nrem that GUI program and the program asks the user if unsaved data should be\nrem saved before exiting. How much time to wait depends on the application.\necho Wait for exit of \"%ProgStart_FileName%\" with PID %#PID_OBSERVE%\" ...\nset \"LoopCount=5\"\n:WaitLoop\n%SystemRoot%\\System32\\timeout.exe /T 1 /NOBREAK >nul\n%SystemRoot%\\System32\\tasklist.exe /FI \"PID eq %#PID_OBSERVE%\" | %SystemRoot%\\System32\\find.exe /I \"%ProgStart_FileName%\" >nul || goto EndBatch\nset /A LoopCount-=5\nif not %LoopCount% == 0 goto WaitLoop\n\nrem Force a brutal kill of the first started program by the operating system.\n%SystemRoot%\\System32\\taskkill.exe /F /PID %#PID_OBSERVE% >nul 2>nul\n\n:EndBatch\nendlocal\n\nThis batch file demonstrates the process management by starting two instances of Windows Notepad. A user can start other Notepad instances before running the batch file and can also start even more Notepad processes while the two instances of Notepad started by the Windows Command Processor during processing of the batch file are still running and wait for user actions. The user can close the first batch started instance and later the second batch started instance of Notepad, but the opposite is also possible. If the user entered text into new file of first batch started instance without saving that text and closes first the second batch started instance, the first batch started instance of Notepad prompts the user if the unsaved text should be saved now. The user has five seconds time for the choice as otherwise the batch file runs TASKKILL with option /F to force a kill of the first batch started Notepad resulting in a loss of the input text.\nThe batch file as is cannot be used for executables with a space in file name.\nThe batch file cannot be used as posted here if ProgStart_FullName is %CompSpec% or %SystemRoot%\\System32\\cmd.exe.\nThe environment variable ProgStart_FullName must be defined with the fully qualified file name of proc2.exe while the environment variable ProgWait_FullName must be defined with the fully qualified file name of proc1.exe. So, proc2.exe is started first as separate, parallel running process and next is started proc1.exe on which cmd.exe halts the batch file execution until proc1.exe exits itself. Then the batch file terminates also proc2.exe on still running or finally kills it if proc2.exe does not close itself within five seconds for whatever reason.\n\nThe task became more clear with the additional information added to the question.\nThe seven questions are answered as follows:\n\nThe batch file always starts proc1.exe.\nThe application proc1.exe is a Windows GUI application.\nThe application proc2.exe is a Windows console application.\nproc2.exe must be started after proc1.exe.\nThere is neither proc1.exe nor proc2.exe started before batch file execution.\nThere are running never more than one proc1.exe one proc2.exe.\nproc2.exe should close itself and should not be killed by the OS.\n\nThe commented batch file for this task with proc1.exe and proc2.exe in subdirectory bin of the batch file directory could be:\n@echo off\nsetlocal EnableExtensions DisableDelayedExpansion\nset \"FullNameProcess1=%~dp0bin\\proc1.exe\"\nset \"FullNameProcess2=%~dp0bin\\proc2.exe\"\n\nrem Get just the file name of the two programs with file extension.\nfor %%I in (\"%FullNameProcess1%\") do set \"FileNameProcess1=%%~nxI\"\nfor %%I in (\"%FullNameProcess2%\") do set \"FileNameProcess2=%%~nxI\"\n\nrem Start the GUI program which should run as separate process in foreground.\nstart \"\" \"%FullNameProcess1%\" 2>nul\nrem Could the first program not be started at all?\nif errorlevel 9059 echo ERROR: Failed to start \"%FullNameProcess1%\"!& echo(& pause & goto EndBatch\n\nrem Start the console program which should run as separate process\nrem without opening a console window.\nstart \"\" /B \"%FullNameProcess2%\"\n\nrem Define an endless running loop searching once per second in the\nrem task list if the first started GUI application is still running.\n:WaitLoop\n%SystemRoot%\\System32\\timeout.exe /T 1 /NOBREAK >nul\n%SystemRoot%\\System32\\tasklist.exe /FI \"IMAGENAME eq %FileNameProcess1%\" /NH | %SystemRoot%\\System32\\find.exe \"%FileNameProcess1%\" >nul && goto WaitLoop\n\nrem The first started GUI program is not running anymore. Check now if the\nrem console program is still running and if that is the case, send it the\nrem message to close itself.\n%SystemRoot%\\System32\\tasklist.exe /FI \"IMAGENAME eq %FileNameProcess2%\" /NH | %SystemRoot%\\System32\\find.exe \"%FileNameProcess2%\" >nul || goto EndBatch\n%SystemRoot%\\System32\\taskkill.exe /IM \"%FileNameProcess2%\" >nul 2>nul\n\nrem Wait one second and check if the console program really terminated itself.\nrem Otherwise force a brutal kill of the console program by the operating system.\n%SystemRoot%\\System32\\timeout.exe /T 1 /NOBREAK >nul\n%SystemRoot%\\System32\\tasklist.exe /FI \"IMAGENAME eq %FileNameProcess2%\" /NH | %SystemRoot%\\System32\\find.exe \"%FileNameProcess2%\" >nul && %SystemRoot%\\System32\\taskkill.exe /F /IM \"%FileNameProcess2%\" >nul 2>nul\n\n:EndBatch\nendlocal\n\nThe batch file as is cannot be used for executables with a space in file name.\nThe batch file cannot be used if proc2.exe is in real cmd.exe because of taskkill.exe /IM \"cmd.exe\" results in termination of all running cmd processes including the one processing the batch file.\nTo understand the commands used and how they work, open a command prompt window, execute there the following commands, and read the displayed help pages for each command, entirely and carefully.\n\necho /?\nendlocal /?\nfind /?\nfor /?\ngoto /?\nif /?\npause /?\nrem /?\nset /?\nsetlocal /?\nstart /?\ntaskkill /?\ntasklist /?\ntimeout /?\n\nRead the Microsoft documentation about Using command redirection operators for an explanation of >nul and 2>nul and |. The redirection operators > and | must be escaped with caret character ^ on the FOR command lines to be interpreted as literal characters when Windows command interpreter processes these command lines before executing command FOR which executes the embedded command line with using a separate command process started in background with %ComSpec% /c and the command line within ' with ^ appended as additional arguments.\nSee also single line with multiple commands using Windows batch file for an explanation of unconditional command operator & and conditional command operator || and correct syntax for an IF condition with an ELSE branch. The usage of \"%ERRORLEVEL%\"==\"0\" is neither described by the usage help of command IF nor is it ever a good idea to use this string comparison for exit code evaluation in a batch file.\n"
},
{
"QuestionId": "76383269",
"QuestionTitle": "the trait `FromSql` is not implemented for `DateTime`",
"QuestionBody": "I'm getting the following error when trying to compile my rust diesel project despite the diesel docs showing that this trait is implemented\n\nthe trait bound DateTime<Utc>: FromSql<diesel::sql_types::Timestamptz, Pg> is not satisfied\n\nMy schema.rs\npub mod offers {\n    diesel::table! {\n        offers.offers (id) {\n            id -> Int4,\n            #[max_length = 255]\n            offername -> Varchar,\n            #[max_length = 255]\n            offertypeid -> Nullable<Varchar>,\n            startdate -> Nullable<Timestamptz>,\n            enddate -> Nullable<Timestamptz>,\n            frequency -> Nullable<Int4>,\n            #[max_length = 255]\n            createdby -> Nullable<Varchar>,\n            createdAt -> Nullable<Timestamptz>\n        }\n    }\n}\n\n\nHere is my models.rs:\nuse diesel::prelude::*;\nuse chrono::{DateTime, Utc};\nuse crate::schema::offers::offers as offerTable;\n\n#[derive(Queryable, Selectable)]\n#[diesel(table_name = offerTable)]\n#[diesel(check_for_backend(diesel::pg::Pg))]\npub struct Offer {\n    pub id: i32,\n    pub enddate: Option<DateTime<Utc>>,\n    pub createdAt: Option<DateTime<Utc>>,\n    pub createdby: Option<String>,\n    pub frequency: Option<i32>,\n    pub offername: String,\n    pub startdate: Option<DateTime<Utc>> <--- ERROR FOR THIS LINE\n}\n\nIn the docs for diesel here is shows that this mapping should work and I haven't been able to figure out why it's not working\n\n",
"AnswerId": "76384410",
"AnswerBody": "You need to enable the \"chrono\" feature for the implementation for DateTime<UTC> from the chrono crate to be provided. This is shown as an annotation in the docs and is not enabled by default. You can read more about this feature and others in Diesel's crate feature flags section of the docs.\nSo your Cargo.toml should contain at least this:\n[dependencies]\ndiesel = { version = \"2.1.0\", features = [\"postgres\", \"chrono\"] }\n\nThis goes for Diesel version 1.x as well.\n"
},
{
"QuestionId": "76381239",
"QuestionTitle": "Is there a faster algorithm for max(ctz(x), ctz(y))?",
"QuestionBody": "For min(ctz(x), ctz(y)), we can use ctz(x | y) to gain better performance. But what about max(ctz(x), ctz(y))?\nctz represents \"count trailing zeros\".\nC++ version (Compiler Explorer)\n#include <algorithm>\n#include <bit>\n#include <cstdint>\n\nint32_t test2(uint64_t x, uint64_t y) {\n    return std::max(std::countr_zero(x), std::countr_zero(y));\n}\n\nRust version (Compiler Explorer)\npub fn test2(x: u64, y: u64) -> u32 {\n    x.trailing_zeros().max(y.trailing_zeros())\n}\n\n",
"AnswerId": "76385356",
"AnswerBody": "These are equivalent:\n\nmax(ctz(a),ctz(b))\nctz((a|-a)&(b|-b))\nctz(a)+ctz(b)-ctz(a|b)\n\nThe math-identity ctz(a)+ctz(b)-ctz(a|b) requires 6 CPU instructions, parallelizable to 3 steps on a 3-way superscalar CPU:\n\n3× ctz\n1× bitwise-or\n1× addition\n1× subtraction\n\nThe bit-mashing ctz((a|-a)&(b|-b)) requires 6 CPU instructions, parallelizable to 4 steps on a 2-way superscalar CPU:\n\n2× negation\n2× bitwise-or\n1× bitwize-and\n1× ctz\n\nThe naïve max(ctz(a),ctz(b)) requires 5 CPU instructions, parallelizable to 4 steps on a 2-way superscalar CPU:\n\n2× ctz\n1× comparison\n1× conditional branch\n1× load/move (so that the \"output\" is always in the same register)\n\n... but note that branch instructions can be very expensive.\nIf your CPU has a conditional load/move instruction, this reduces to 4 CPU instructions taking 3 super-scalar steps.\nIf your CPU has a max instruction (e.g. SSE4), this reduces to 3 CPU instructions taking 2 super-scalar steps.\nAll that said, the opportunities for super-scalar operation depend on which instructions you're trying to put against each other. Typically you get the most by putting different instructions in parallel, since they use different parts of the CPU (all at once). Typically there will be more \"add\" and \"bitwise or\" units than \"ctz\" units, so doing multiple ctz instructions may actually be the limiting factor, especially for the \"math-identity\" version.\nIf \"compare and branch\" is too expensive, you can make a non-branching \"max\" in 4 CPU instructions. Assuming A and B are positive integers:\n\nC = A-B\nsubtract the previous carry, plus D, from D itself (D is now either 0 or -1, regardless of whatever value it previously held)\nC &= D (C is now min(0, A-B))\nA -= C (A' is now max(A,B))\n\n"
},
{
"QuestionId": "76384813",
"QuestionTitle": "Using Office365 Excel array formulas, how to convert this standard formula?",
"QuestionBody": "These two formulas are the same, except the first one is not an array formula and the second one is.  How can the first formula be converted to an array formula?  Getting circular logic when using the array formula.\nStandard Formula (works fine, no circular logic):\n=LET(a, A2, b, B2, c, C2, d, D1, e, E1,\n    dd, IF(a = 1, 0, d),\n    ee, IF(a = 1, 0, e),\n(b * c + dd * ee ) / (b + dd)  )\n\nArray Formula (circular logic error):\n=LET(a, A9:A12, b, B9:B12, c, C9:C12, d, D8:D11, e,E8:E11,\n    dd, IF(a = 1, 0, d),\n    ee, IF(a = 1, 0, e),\n(b * c + dd * ee ) / (b + dd)  )\n\nThe formula is a fairly simple weighted average of two sets of numbers.  Trying to convert it to an array formula.  The previous result is used on the following row, except on the first row where there is no previous result.\nThe difficulty is in how to reference the previous result cell when calculating the current cell.\n\nData:\n\n\n\n\nSeq\nB\nC\nD\n\n\n\n\n1\n100\n1.00\n-\n\n\n2\n100\n3.00\n800\n\n\n3\n250\n2.00\n200\n\n\n4\n400\n5.00\n300\n\n\n\n",
"AnswerId": "76386149",
"AnswerBody": "INDEX each array and use SCAN to return the values:\n=LET(\n    a, A9:A12, \n    b, B9:B12, \n    c, C9:C12, \n    d, D8:D11,\n    dd, IF(a = 1, 0, d),\n    SCAN(0,a,LAMBDA(z,y,(INDEX(b,y)*INDEX(c,y)+INDEX(dd,y)*z)/(INDEX(b,y)+INDEX(dd,y)))))\n\n\n"
},
{
"QuestionId": "76383596",
"QuestionTitle": "Area of each cell covered by polygons",
"QuestionBody": "Is there a way/function to calculate the proportion of each raster cell covered by a polygon? The polygons are usually larger than single cells and the landscape I'm working on is pretty big. I'll like to do it without converting the raster into cell-polygons and st_union/st_join, but I'm not sure if it's possible.\nThe output I'm looking for is a raster with cell values showing the proportion of each cell covered by the polygons layer.\n",
"AnswerId": "76384510",
"AnswerBody": "Thanks for the comments.\nAt the end the terra::rasterize() function with the cover = T parameter applied on the polygons layer does exactly what I was looking for... and it's super fast.\nI was able to keep it all on the \"raster side\" and avoid the more intense processing of vectorizing the raster template and doing intersects/spatial joins.\n"
},
{
"QuestionId": "76381200",
"QuestionTitle": "How to create Custom progress bar minimum value 0 starts from the bottom left corner?",
"QuestionBody": "I want the starting point 0% and the ending point 100% of the progress bar to be in the lower left corner. And the progress of the value changes to display normally. How can I accomplish it?\nI want the progress bar to increase and decrease in value along the circle.\nThe result of my test is not correct, I don't know where is the problem and how to fix it.\nXaml:\n<Window.Resources>\n    <local:AngleToPointConverter x:Key=\"prConverter\"/>\n    <local:AngleToIsLargeConverter x:Key=\"isLargeConverter\"/>\n  \n    <Style x:Key=\"circularProgressBar\" TargetType=\"local:CircularProgressBar\">\n        <Setter Property=\"Value\" Value=\"10\"/>\n        <Setter Property=\"Maximum\" Value=\"100\"/>\n        <Setter Property=\"StrokeThickness\" Value=\"10\"/>\n        <Setter Property=\"Template\">\n            <Setter.Value>\n                <ControlTemplate TargetType=\"local:CircularProgressBar\">\n                  \n                        \n                        <Canvas Width=\"100\" Height=\"130\">\n                            <Ellipse Width=\"101\" Height=\"101\" Stroke=\"LightGray\" Opacity=\"0.7\" StrokeThickness=\"4\"  />\n\n                            <Path Stroke=\"{TemplateBinding Background}\" \n                              StrokeThickness=\"{TemplateBinding StrokeThickness}\">\n                                <Path.Data>\n                                    <PathGeometry>\n                                        <PathFigure x:Name=\"fig\" StartPoint=\"20,90\">\n                                            <ArcSegment RotationAngle=\"0\" SweepDirection=\"Clockwise\"\n                                                    Size=\"50,50\"\n                                                    Point=\"{Binding Path=Angle, Converter={StaticResource prConverter}, RelativeSource={RelativeSource FindAncestor, AncestorType=ProgressBar}}\"\n                                                    IsLargeArc=\"{Binding Path=Angle, Converter={StaticResource isLargeConverter}, RelativeSource={RelativeSource FindAncestor, AncestorType=ProgressBar}}\"\n                                                    >\n                                            </ArcSegment>\n                                        </PathFigure>\n                                    </PathGeometry>\n                                </Path.Data>\n                            </Path>\n                            <Border Width=\"100\" Height=\"100\">\n                                <Grid>\n                                    <Ellipse Width=\"50\" Height=\"50\"   Fill=\"White\"  />\n                                    <Image Width=\"20\" Height=\"20\" Margin=\"30,25,30,30\" Source=\"bulb1.PNG\"/>\n\n                                    <TextBlock Width=\"50\" Foreground=\"Black\" Height=\"20\"  Margin=\"10,40,10,5\" TextAlignment=\"Center\"\n                                   Text=\"{Binding Path=Value, StringFormat={}{0}%,  \n                            RelativeSource={RelativeSource TemplatedParent}}\"\n                                       FontSize=\"{TemplateBinding FontSize}\"/>\n                                </Grid>\n\n                            </Border>\n                            <Canvas  Canvas.Top=\"110\">\n                                <Button x:Name=\"decrease\"  Margin=\"20,0,0,0\" Command=\"{Binding DecreaseCommand}\" >\n                                        <Button.Style>\n                                            <Style TargetType=\"{x:Type Button}\">\n                                                <Setter Property=\"Template\">\n                                                    <Setter.Value>\n                                                        <ControlTemplate>\n                                                            <Grid>\n                                                                <Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\"  />\n                                                                <Border Width=\"20\" Height=\"20\" >\n                                                                    <TextBlock Foreground=\"LightGray\" Text=\"-\" FontWeight=\"Bold\" HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\" />\n                                                                </Border>\n                                                            </Grid>\n                                                        </ControlTemplate>\n                                                    </Setter.Value>\n                                                </Setter>\n                                            </Style>\n                                        </Button.Style>\n                                    </Button>\n                                    <Button x:Name=\"increase\"  Margin=\"60,0,0,0\" Grid.Column=\"1\" Command=\"{Binding IncreaseCommand}\" >\n                                        <Button.Style>\n                                            <Style TargetType=\"{x:Type Button}\">\n                                                <Setter Property=\"Template\">\n                                                    <Setter.Value>\n                                                        <ControlTemplate>\n                                                            <Grid>\n                                                                <Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\" />\n                                                                <Border Width=\"20\" Height=\"20\"   Grid.Column=\"1\">\n                                                                    <TextBlock Foreground=\"LightGray\" Text=\"+\" FontWeight=\"Bold\"  VerticalAlignment=\"Center\" HorizontalAlignment=\"Center\" />\n\n                                                                </Border>\n                                                            </Grid>\n                                                        </ControlTemplate>\n                                                    </Setter.Value>\n                                                </Setter>\n                                            </Style>\n                                        </Button.Style>\n                                    </Button>\n                                    <!--<Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\"  Margin=\"20,0,0,0\"/>\n                                    <Border Width=\"20\" Height=\"20\" Margin=\"20,0,0,0\">\n                                        <TextBlock Foreground=\"LightGray\" Text=\"-\" HorizontalAlignment=\"Center\" />\n                                    </Border>\n                                    <Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\"  Margin=\"60,0,0,0\"/>\n                                    <Border Width=\"20\" Height=\"20\" Margin=\"60,0,0,0\">\n                                        <TextBlock Foreground=\"LightGray\" Text=\"+\" HorizontalAlignment=\"Center\" />\n\n                                    </Border>-->\n\n                            </Canvas>\n                        </Canvas>\n                  \n                </ControlTemplate>\n            </Setter.Value>\n        </Setter>\n    </Style>\n</Window.Resources>\n<Grid Background=\"DarkBlue\">\n    <local:CircularProgressBar Background=\"White\" Style=\"{StaticResource  circularProgressBar }\"\n                                  Value=\"{Binding ElementName=CirularSlider, Path= Value}\"  Foreground=\"Black\" FontWeight=\"Bold\"\n                                 \n                                   StrokeThickness=\"4\"  \n                               \n                                   BorderBrush=\"LightGray\"/>\n\n    <Slider Minimum=\"0\" Maximum=\"100\" \n                x:Name=\"CirularSlider\" IsSnapToTickEnabled=\"True\"\n                VerticalAlignment=\"Top\" Value=\"10\"/>\n</Grid>\n\nCodebedhind:\npublic class CircularProgressBar : ProgressBar\n    {\n        public CircularProgressBar()\n        {\n            this.ValueChanged += CircularProgressBar_ValueChanged;\n        }\n\n        void CircularProgressBar_ValueChanged(object sender, RoutedPropertyChangedEventArgs<double> e)\n        {\n            CircularProgressBar bar = sender as CircularProgressBar;\n            double currentAngle = bar.Angle;\n            double targetAngle = e.NewValue / bar.Maximum * 359.999;\n          //  double targetAngle = e.NewValue / bar.Maximum * 179.999;\n\n            DoubleAnimation anim = new DoubleAnimation(currentAngle, targetAngle, TimeSpan.FromMilliseconds(500));\n            bar.BeginAnimation(CircularProgressBar.AngleProperty, anim, HandoffBehavior.SnapshotAndReplace);\n        }\n\n        public double Angle\n        {\n            get { return (double)GetValue(AngleProperty); }\n            set { SetValue(AngleProperty, value); }\n        }\n\n        // Using a DependencyProperty as the backing store for Angle.  This enables animation, styling, binding, etc...\n        public static readonly DependencyProperty AngleProperty =\n            DependencyProperty.Register(\"Angle\", typeof(double), typeof(CircularProgressBar), new PropertyMetadata(0.0));\n\n        public double StrokeThickness\n        {\n            get { return (double)GetValue(StrokeThicknessProperty); }\n            set { SetValue(StrokeThicknessProperty, value); }\n        }\n\n        // Using a DependencyProperty as the backing store for StrokeThickness.  This enables animation, styling, binding, etc...\n        public static readonly DependencyProperty StrokeThicknessProperty =\n            DependencyProperty.Register(\"StrokeThickness\", typeof(double), typeof(CircularProgressBar), new PropertyMetadata(10.0));\n    }\n\n\n   \n   public class AngleToPointConverter : IValueConverter\n    {\n\n        public object Convert(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture)\n        {\n            double angle = (double)value;\n            double radius = 50;\n            double piang = angle * Math.PI / 180;\n            //double piang = angle * Math.PI / 310;\n\n            double px = Math.Sin(piang) * radius + radius;\n            double py = -Math.Cos(piang) * radius + radius;\n\n            return new System.Windows.Point(px, py);\n        }\n\n        public object ConvertBack(object value, Type targetTypes, object parameter, System.Globalization.CultureInfo culture)\n        {\n            throw new NotImplementedException();\n        }\n    }\n\n    public class AngleToIsLargeConverter : IValueConverter\n    {\n\n        public object Convert(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture)\n        {\n            double angle = (double)value;\n\n           return angle > 180;\n           // return angle > 300;\n        }\n\n        public object ConvertBack(object value, Type targetTypes, object parameter, System.Globalization.CultureInfo culture)\n        {\n            throw new NotImplementedException();\n        }\n    }\n\nThe result:\n\nEdit:\n\nUpdate:\nHow can I change the progress value by dragging the ball?\n<Style x:Key=\"circularProgressBar1\" TargetType=\"local:CircularProgressBar\">\n            <Setter Property=\"Value\" Value=\"10\"/>\n            <Setter Property=\"Maximum\" Value=\"100\"/>\n            <Setter Property=\"StrokeThickness\" Value=\"7\"/>\n            <Setter Property=\"Template\">\n                <Setter.Value>\n                    <ControlTemplate TargetType=\"local:CircularProgressBar\">\n\n\n                        <Canvas Width=\"100\" Height=\"130\">\n                            <Ellipse Width=\"105\" Height=\"104\" Margin=\"-2.4,-1.5,0,0\" Stroke=\"LightGray\" Opacity=\"0.7\"  StrokeThickness=\"8\"  />\n\n\n                           \n                            <Path Stroke=\"{TemplateBinding Background}\"  StrokeStartLineCap=\"Round\" StrokeEndLineCap=\"Round\"\n                              StrokeThickness=\"{TemplateBinding StrokeThickness}\">\n                                <Path.Data>\n                                    <PathGeometry>\n                                        <PathFigure x:Name=\"fig\" StartPoint=\"20,90\">\n                                            <ArcSegment RotationAngle=\"0\" SweepDirection=\"Clockwise\" \n                                                    Size=\"50,50\"\n                                                    Point=\"{Binding Path=Angle, Converter={StaticResource prConverter}, RelativeSource={RelativeSource FindAncestor, AncestorType=ProgressBar}}\"\n                                                    IsLargeArc=\"{Binding Path=Angle, Converter={StaticResource isLargeConverter}, RelativeSource={RelativeSource FindAncestor, AncestorType=ProgressBar}}\"\n                                                    >\n                                            </ArcSegment>\n                                        </PathFigure>\n                                    </PathGeometry>\n                                </Path.Data>\n                            </Path>\n                            <Button>\n                                <Button.Style>\n                                    <Style TargetType=\"Button\">\n                                        <Setter Property=\"Template\">\n                                            <Setter.Value>\n                                                <ControlTemplate>\n                                                    <Path Stroke=\"Black\" StrokeThickness=\"10\" StrokeStartLineCap=\"Round\" StrokeEndLineCap=\"Round\">\n                                                        <Path.Data>\n                                                            <PathGeometry>\n                                                                <PathGeometry.Figures>\n                                                                    <PathFigure StartPoint=\"{Binding Path=Angle, Converter={StaticResource prConverter}, RelativeSource={RelativeSource FindAncestor, AncestorType=ProgressBar}}\">\n                                                                        <PathFigure.Segments>\n                                                                            <LineSegment Point=\"{Binding Path=Angle, Converter={StaticResource prConverter}, RelativeSource={RelativeSource FindAncestor, AncestorType=ProgressBar}}\" />\n                                                                        </PathFigure.Segments>\n                                                                    </PathFigure>\n                                                                </PathGeometry.Figures>\n                                                            </PathGeometry>\n                                                        </Path.Data>\n                                                    </Path>\n                                                </ControlTemplate>\n                                            </Setter.Value>\n                                        </Setter>\n                                    </Style>\n                                </Button.Style>\n                            </Button>\n                        \n\n\n                            <Border Width=\"100\" Height=\"100\">\n                                <Grid>\n                                    <Ellipse Width=\"50\" Height=\"50\"   Fill=\"White\"  />\n                                    <Image Width=\"20\" Height=\"20\" Margin=\"30,25,30,30\" Source=\"bulb1.PNG\"/>\n\n                                    <TextBlock Width=\"50\" Foreground=\"Black\" Height=\"20\"  Margin=\"10,40,10,5\" TextAlignment=\"Center\"\n                                   Text=\"{Binding Path=Value, StringFormat={}{0}%,  \n                            RelativeSource={RelativeSource TemplatedParent}}\"\n                                       FontSize=\"{TemplateBinding FontSize}\"/>\n                                </Grid>\n\n                            </Border>\n                            <Canvas  Canvas.Top=\"110\">\n                                <Button x:Name=\"decrease\"  Margin=\"20,0,0,0\" Command=\"{Binding DecreaseCommand}\" >\n                                    <Button.Style>\n                                        <Style TargetType=\"{x:Type Button}\">\n                                            <Setter Property=\"Template\">\n                                                <Setter.Value>\n                                                    <ControlTemplate>\n                                                        <Grid>\n                                                            <Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\"  />\n                                                            <Border Width=\"20\" Height=\"20\" >\n                                                                <TextBlock Foreground=\"LightGray\" Text=\"-\" FontWeight=\"Bold\" HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\" />\n                                                            </Border>\n                                                        </Grid>\n                                                    </ControlTemplate>\n                                                </Setter.Value>\n                                            </Setter>\n                                        </Style>\n                                    </Button.Style>\n                                </Button>\n                                <Button x:Name=\"increase\"  Margin=\"60,0,0,0\" Grid.Column=\"1\" Command=\"{Binding IncreaseCommand}\" >\n                                    <Button.Style>\n                                        <Style TargetType=\"{x:Type Button}\">\n                                            <Setter Property=\"Template\">\n                                                <Setter.Value>\n                                                    <ControlTemplate>\n                                                        <Grid>\n                                                            <Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\" />\n                                                            <Border Width=\"20\" Height=\"20\"   Grid.Column=\"1\">\n                                                                <TextBlock Foreground=\"LightGray\" Text=\"+\" FontWeight=\"Bold\"  VerticalAlignment=\"Center\" HorizontalAlignment=\"Center\" />\n\n                                                            </Border>\n                                                        </Grid>\n                                                    </ControlTemplate>\n                                                </Setter.Value>\n                                            </Setter>\n                                        </Style>\n                                    </Button.Style>\n                                </Button>\n                                <!--<Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\"  Margin=\"20,0,0,0\"/>\n                                    <Border Width=\"20\" Height=\"20\" Margin=\"20,0,0,0\">\n                                        <TextBlock Foreground=\"LightGray\" Text=\"-\" HorizontalAlignment=\"Center\" />\n                                    </Border>\n                                    <Ellipse Width=\"20\" Height=\"20\" Stroke=\"LightGray\"  StrokeThickness=\"1\"  Margin=\"60,0,0,0\"/>\n                                    <Border Width=\"20\" Height=\"20\" Margin=\"60,0,0,0\">\n                                        <TextBlock Foreground=\"LightGray\" Text=\"+\" HorizontalAlignment=\"Center\" />\n\n                                    </Border>-->\n\n                            </Canvas>\n                        </Canvas>\n\n                    </ControlTemplate>\n                </Setter.Value>\n            </Setter>\n        </Style>\n\n\n",
"AnswerId": "76385707",
"AnswerBody": "change the piang calculation in the convert function so that the starting point at the bottom left is taken into account in the calculation\ndouble piang = (angle - 143.2) * Math.PI / 180;\n\nso the class looks like this\npublic class AngleToPointConverter : IValueConverter\n{\n\n    public object Convert(object value, Type targetType, object parameter, System.Globalization.CultureInfo culture)\n    {\n        double angle = (double)value;\n        double radius = 50;\n        double piang = (angle - 143.2) * Math.PI / 180;\n        //double piang = angle * Math.PI / 310;\n\n        double px = Math.Sin(piang) * radius + radius;\n        double py = -Math.Cos(piang) * radius + radius;\n\n        return new System.Windows.Point(px, py);\n    }\n\n    public object ConvertBack(object value, Type targetTypes, object parameter, System.Globalization.CultureInfo culture)\n    {\n        throw new NotImplementedException();\n    }\n}\n\nyou may have to adjust the angle (143.2).\n"
},
{
"QuestionId": "76384224",
"QuestionTitle": "Why is 'CustomerOrOrganizationInNoUpdateDocRestrictor' inaccessible in my Acumatica project?",
"QuestionBody": "Good morning!  I have a customer ID field included in the table DAC.  I would like for this selector to operate identically to the customer ID field in the sales order form.  I used all pertinent DAC code from the sales order to create the field in my custom screen; however, when I attempt to use all the same attributes for the restrictor, the following attribute cannot be accessed.  I have all the appropriate references included in the project(PX.Objects.AR).  Any assistance or work around for this issue would be greatly appreciated.  Thank you!\n#region CustomerID\n        public abstract class customerID : BqlInt.Field<customerID>\n        {\n            public class PreventEditBAccountCOrgBAccountID<TGraph> :\n                PreventEditBAccountRestrictToBase<BAccount.cOrgBAccountID, TGraph, NXBOL,\n                    SelectFrom<NXBOL>\n                    .Where<NXBOL.bolType.IsNotEqual<NXBOLType.nonProductMovement>.\n                        And<NXBOL.customerID.IsEqual<BAccount.bAccountID.FromCurrent>>>>\n                where TGraph : PXGraph\n            {\n                protected override string GetErrorMessage(BAccount baccount, NXBOL document, string documentBaseCurrency)\n                {\n                    return PXMessages.LocalizeFormatNoPrefix(Messages.CannotChangeRestricToIfShipmentExists,\n                        documentBaseCurrency, baccount.AcctCD, document.BOLNbr);\n                }\n            }\n\n            public class PreventEditBAccountCOrgBAccountIDOnVendorMaint : PreventEditBAccountCOrgBAccountID<VendorMaint>\n            {\n                public static bool IsActive()\n                    => PXAccess.FeatureInstalled<FeaturesSet.multipleBaseCurrencies>();\n            }\n\n            public class PreventEditBAccountCOrgBAccountIDOnCustomerMaint : PreventEditBAccountCOrgBAccountID<CustomerMaint>\n            {\n                public static bool IsActive()\n                    => PXAccess.FeatureInstalled<FeaturesSet.multipleBaseCurrencies>();\n            }\n        }\n        protected Int32? _CustomerID;\n        [CustomerActive(\n            typeof(Search<BAccountR.bAccountID, Where<True, Equal<True>>>), // TODO: remove fake Where after AC-101187\n            Visibility = PXUIVisibility.SelectorVisible, Required = true)]\n        [CustomerOrOrganizationInNoUpdateDocRestrictor]\n        [PXForeignReference(typeof(Field<NXBOL.customerID>.IsRelatedTo<BAccount.bAccountID>))]\n        public virtual Int32? CustomerID\n        {\n            get\n            {\n                return this._CustomerID;\n            }\n            set\n            {\n                this._CustomerID = value;\n            }\n        }\n        #endregion\n        \n\nIt appears that the [CustomerOrOrganizationInNoUpdateDocRestrictor] is not accessible.  The project will not build and receive the following error:\nError   CS0122  'CustomerOrOrganizationInNoUpdateDocRestrictor' is inaccessible due to its protection level\nI have tried manipulating references, I would expect the attribute which is defined in PX.Objects.AR to work the same in my project as the PX.Objects.SO.\n",
"AnswerId": "76386230",
"AnswerBody": "CustomerOrOrganizationInNoUpdateDocRestrictor is an internal class, so you can't access it.\nYou can use this restrictor instead:\n[PXRestrictor(\n        typeof(Where<Customer.type, IsNotNull, Or<Current<PX.Objects.SO.SOOrder.aRDocType>,\n            Equal<ARDocType.noUpdate>, And<Current<PX.Objects.SO.SOOrder.behavior>, Equal<SOBehavior.tR>,\n                And<Where<BAccountR.type, In3<BAccountType.branchType, BAccountType.organizationType>,\n                    Or<PX.Objects.CR.BAccount.isBranch, Equal<True>>>>>>>),\n        \"Only a customer or company business account can be specified.\")]\n\n"
},
{
"QuestionId": "76383243",
"QuestionTitle": "Chain assertions together in kotlin",
"QuestionBody": "I have an operation that I want to succeed with two different conditions. For example, if the status code is 501 OR message is not 'FAILED'. Is there a way to have assertions grouped together logically like AND/OR. If assertion 1 passes OR assertion 2 passes, I want my test case to succeed.\n",
"AnswerId": "76384553",
"AnswerBody": "@cactustictacs suggests \"naming\" your assertions and then chaining them.\nI'll suggest an answer by showing code that validates 4x REST interface inputs that have some complex permutations that allowed / not allowed.  This code is arguably easier to read than a classic if ... else structure.\nSee how they are evaluated using the when construct.   Perhaps you can take these ideas for your assertions...\nval userIdNotNull = userId != null\n        && channelType == null\n        && primaryMentorId == null\n        && primaryClinicianId == null\n\nval userIdAndChannelTypeNotNull = userId != null\n        && channelType != null\n        && primaryMentorId == null\n        && primaryClinicianId == null\n\nval primaryMentorIdNotNull = userId == null\n        && channelType == null\n        && primaryMentorId != null\n        && primaryClinicianId == null\n\nval primaryClinicianIdNotNull = userId == null\n        && channelType == null\n        && primaryMentorId == null\n        && primaryClinicianId != null\n\nval channels = when {\n    userIdNotNull -> getChannelsByUserId(userId)\n    userIdAndChannelTypeNotNull -> channelRepository.findByMemberIdAndChannelType(userId!!, channelType!!)\n        .ifEmpty { throw NotFoundException() }\n\n    primaryMentorIdNotNull -> channelRepository.findByPrimaryMentorId(primaryMentorId)\n        .ifEmpty { throw NotFoundException() }\n\n    primaryClinicianIdNotNull -> channelRepository.findByPrimaryClinicianId(primaryClinicianId)\n        .ifEmpty { throw NotFoundException() }\n\n    else -> throw InvalidRequestParameterException(\"This combination of request parameters is not supported\")\n}\n\n"
},
{
"QuestionId": "76381084",
"QuestionTitle": "use surface pressure to mask 4D netcdf variable",
"QuestionBody": "I've merged a 3D surface pressure field (ERA5, converted from Pa to hPa, function of lat,lon and time) with a 4D variable which is also a function of pressure levels (lat,lon,time,level).\nSo, my netcdf file has two fields, Temperature which is 4D:\nfloat t(time, level, latitude, longitude)\n\nsurface pressure, which is 3d:\nfloat sp(time, latitude, longitude)\n\nThe pressure dimension \"level\" is of course a vector:\nint level(level)\n\nWhat I want to do is make a mask for temperature for all locations where the pressure exceeds the surface pressure.\nI know how to use nco to make a mask using a simple threshold:\n ncap2 -s 'mask=(level>800)' t_ps.nc mask.nc\n\nBut of course when I try to use the surface pressure\nncap2 -s 'mask=(level>sp)' t_ps.nc mask.nc \n\nI get the error\nncap2: ERROR level and template sp share no dimensions\n\nI think what I need to do is make a new variable like \"level3d\" which duplicates the pressure \"level\" to be a function of lat and lon, which I can then use to efficiently make the mask, yes?  But I'm not sure how to do this with a dimension (I thought about cdo enlarge but couldn't get it to work).\nBy the way, instead of posting the data, this is the python api script I used to retrieve it\nimport cdsapi\nc = cdsapi.Client()\nc.retrieve(\n    'reanalysis-era5-single-levels-monthly-means',\n    {\n        'format': 'netcdf',\n        'product_type': 'monthly_averaged_reanalysis',\n        'variable': 'surface_pressure',\n        'year': '2020',\n        'month': '03',\n        'time': '00:00',\n    },\n    'ps.nc')\n\nc.retrieve(\n    'reanalysis-era5-pressure-levels-monthly-means',\n    {\n        'format': 'netcdf',\n        'product_type': 'monthly_averaged_reanalysis',\n        'variable': 'temperature',\n        'pressure_level': [\n            '1', '2', '3',\n            '5', '7', '10',\n            '20', '30', '50',\n            '70', '100', '125',\n            '150', '175', '200',\n            '225', '250', '300',\n            '350', '400', '450',\n            '500', '550', '600',\n            '650', '700', '750',\n            '775', '800', '825',\n            '850', '875', '900',\n            '925', '950', '975',\n            '1000',\n        ],\n        'year': '2020',\n        'month': '03',\n        'time': '00:00',\n    },\n    't.nc')\n\n",
"AnswerId": "76386067",
"AnswerBody": "Your diagnosis of the NCO behavior is essentially correct. The \"broadcast\"\nncap2 -s 'mask=(level>sp)' t_ps.nc mask.nc\n\nfails because level and sp are arrays (not scalars) that share no dimensions. The fix would be to create and use a temporary 3D version of level with something like\nncap2 -s 'level_3D[level,latitude,longitude]=level;mask=(level_3D>sp)' t_ps.nc mask.nc\n\n"
},
{
"QuestionId": "76385355",
"QuestionTitle": "How to set invert_if_negative to fill bars to a solid color in python xlswriter",
"QuestionBody": "I am making graphics on excel from python using xls writer and want to make a graphic with green colored bars for positive values, and red for negative.\nCurrent code seems like this:\nchart3 = workbook.add_chart({'type': 'column'})\nchart3.add_series({\n    'values': '=Summary!$W$2:$W$76',\n    'categories': '=Summary!$A$2:$A$76',\n    'gap': 4,\n    'line': {'width': 1},\n    'name': '=Summary!$W$1',\n    'fill':   {'color': 'green'},\n    'invert_if_negative': True\n})\n\nIt differientiates positive and negative values in the graph but the negative ones are just no-colored. Is there a way to make the inverted color to be red?\nAlready tried with other properties like inverted_color or any syntax like that but does not work\n",
"AnswerId": "76386251",
"AnswerBody": "You will need version >= 3.1.1 of XlsxWriter which supports the invert_if_negative_color parameter:\nfrom xlsxwriter import Workbook\n\n\nworkbook = Workbook(\"chart.xlsx\")\n\nworksheet = workbook.add_worksheet()\nchart = workbook.add_chart({\"type\": \"column\"})\n\nworksheet.write_column(\"A1\", [3, 2, -3, 4, -2])\n\nchart.add_series(\n    {\n        \"values\": \"=Sheet1!$A$1:$A$5\",\n        \"fill\": {\"color\": \"green\"},\n        \"invert_if_negative\": True,\n        \"invert_if_negative_color\": \"red\",\n    }\n)\n\nworksheet.insert_chart(\"C1\", chart)\n\nworkbook.close()\n\n\nOutput:\n\n"
},
{
"QuestionId": "76380701",
"QuestionTitle": "Custom CSS drop caps in Wordpress 6.2.2 with Twenty Twenty Three theme",
"QuestionBody": "I'm trying to do drop caps in the Twenty Twenty-Three theme on WordPress 6.2.2.\nAll the docs I find when I google it are for older versions of WordPress, and possibly on an older theme. It used to be easy, but I can't find relevant docs for how to do this with the Twenty Twenty-Three theme.\nAnd following on from that, how do I add custom CSS to use a different font for the drop caps?\nI have a couple of older posts from an earlier version of WP that have drop caps and I used to have them styled via a child theme I was using, but I upgraded to the Twenty Twenty Three theme and I lost all my customisations.\nI've added the following code via the \"Tools > Theme file editor\", but it doesn't seem to be working.\np.has-drop-cap:not(:focus)::first-letter\n{\n  font-family: 'Fredericka the Great', cursive;\n}\n\n",
"AnswerId": "76386331",
"AnswerBody": "Neither TwentyTwentyTwo nor TwentyTwentyThree currently support dropCaps. Since the layout looks undesirable on certain user systems, it was agreed that dropcap support is not mandatory for either theme. Read more - WordPress issues: https://github.com/WordPress/twentytwentytwo/issues/180\nBut there's a workaround available. Since you have to touch the theme core files, the use of a child theme is probably not a bad idea. Otherwise, adjustments could be overwritten when updating.\nThe workaround was first pointed out in a comment by @colorful-tones a user on GitHub, in this thread. The related CSS is from @justintadlock, another GitHub user, you can read more here.\nSo here are the steps you need to take to enable dropCap support:\n\nSince you are using the theme file editor, go there and open       theme.json.\nAt about line 109, under typography, change the value for dropCap from false to true.\nSave the file.\nOpen the theme's style.css and add:\n\n.has-drop-cap:not(:focus)::first-letter {\n    font-family: var( --wp--custom--drop-cap--typography--font-family, inherit );\n    font-size: var( --wp--custom--drop-cap--typography--font-size, 5.5em );\n    font-weight: var( --wp--custom--drop-cap--typography--font-weight, 700 );\n    font-style: var( --wp--custom--drop-cap--typography--font-style, normal );\n    line-height: var( --wp--custom--drop-cap--typography--line-height, .85 );\n    margin: var( --wp--custom--drop-cap--spacing--margin, 0.05em 0.1em 0 0 );\n    padding: var( --wp--custom--drop-cap--spacing--paddig, 0 );\n}\n\n\nSave the file.\n\nNOTE: If you want to use a custom font you may have to add your font to the typography section in theme.json. A support topic from WordPress.org could be helpful hereby. You can also try to replace all variables directly in the CSS part with your own values. But I'm sorry I can't remember if it worked like that, because I used this workaround only once and it was some time ago and the page doesn't exist like that anymore. You'll just have to test it yourself.\nFinally, don't forget to properly include your Fredericka the Great font into Wordpress.\nHope this works for you.\n"
},
{
"QuestionId": "76383382",
"QuestionTitle": "Axis labeling for subplots",
"QuestionBody": "The following code generates this image \nI want the \"y\"-axis label to be \"Space\" and the \"x\"-axis label to be \"time\" for the left subplot. However, I am failing to achieve this. Why does my plotting code not do as I desire?\np1 = surface(sol.t, x, z, xlabel=\"Time\", ylabel=\"Space\", zlabel=\"|u|²\", colorbar = false)\np2 = contourf(sol.t,x,z, xlabel=\"Time\", ylabel=\"Space\")\nplt = plot(p1,p2,layout=(1,2), size=(1200,800))\n\n\nusing DifferentialEquations, LinearAlgebra, Plots, SparseArrays\nplotlyjs()\n\nN₁=31 # Number of waveguides / size of solution vector\nγ=1  # Nonlinear term strength parameter\nh=1 # Grid spacing \n\ncenterGrid  = (N₁-1)/2;\nx = -centerGrid:centerGrid;\n\n# Coefficient matrix of second-order centered-difference operator (δ²u)ₙ\nM           = spdiagm(-1 => fill(1,N₁-1), 0 => fill(-2,N₁), 1 => fill(1,N₁-1))\nM[N₁,1]     = 1; # Periodic boundary conditions\nM[1,N₁]     = 1;\n\n# RHS of DNLS. The solution vector u is a N₁x1 complex vector\ng₁(u,p,t)   = 1*im*(p[1]*M*u + @.(γ*((abs(u))^2).*u) )\n\n# Julia is explicitly typed (e.g, cannot have Int and Complex in same array) and so we must convert the object containing the initial data to be complex\nu0  = Complex.(sech.(x))\n\ntspan = (0.0,200)\nprob = ODEProblem(g₁,u0,tspan, [h])\nsol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)\n\nz= [abs(sol.u[i][j])^2  for j=1:N₁, i=1:size(sol)[2]] # |u|²\n\np1 = surface(sol.t, x, z, xlabel=\"Time\", ylabel=\"Space\", zlabel=\"|u|²\", colorbar = false)\np2 = contourf(sol.t,x,z, xlabel=\"Time\", ylabel=\"Space\")\nplt = plot(p1,p2,layout=(1,2), size=(1200,800))\n\n",
"AnswerId": "76384575",
"AnswerBody": "Setting custom axis labels for 3d plots doesn't work with Plots and plotlyjs() backend. Only with GR backend your labels are displayed.\nYou can try this version using PLotlyJS.jl instead Plots.jl:\nfig=make_subplots(rows=1, cols=2, specs =[Spec(kind=\"scene\") Spec(kind=\"xy\")], \n                  horizontal_spacing=-0.1, column_widths=[0.65, 0.35])\nadd_trace!(fig, PlotlyJS.surface(x=sol.t, y=collect(x), z=z', showscale=false), row=1, col=1)\nadd_trace!(fig, PlotlyJS.contour(x=sol.t, y=collect(x), z=z), row=1, col=2)\nrelayout!(fig, template=templates[\"plotly_white\"], font_size=11,\n                width=1000, height=600, scene=attr(xaxis_title=\"Time\", yaxis_title=\"Space\", \n                zaxis_title=\"|u|²\", camera_eye=attr(x=1.8, y=1.8, z=1)),\n                xaxis2_title=\"Time\", yaxis2_title=\"Space\",  margin_l=15) \ndisplay(fig)\n\n\n"
},
{
"QuestionId": "76381599",
"QuestionTitle": "'newEmail' box that comes with identity is autopopulating and I can't stop it",
"QuestionBody": "I have created a website and included identity for logging in. On the manage your account page, the new email box keeps autopopulating and I can't figure out how to stop it.\n\nI have tried to add the 'autocomplete=off' to the  tag (see below code) but it still populates.\n@page\n@using FarmersPortal.Areas.Identity.Pages.Account.Manage;\n@model EmailModel\n@{\n    ViewData[\"Title\"] = \"Manage Email\";\n    ViewData[\"ActivePage\"] = ManageNavPages.Email;\n}\n\n<style>\n    body {\n        background-image: url('http://10.48.1.215/PORTAL/hero-range-1.jpg');\n        height: 100%;\n        background-position: center;\n        background-repeat: no-repeat;\n        background-size: cover;\n        /*        background-color: white;*/\n    }\n</style>\n\n<h3 style=\"color:white\">@ViewData[\"Title\"]</h3>\n<partial name=\"_StatusMessage\" for=\"StatusMessage\" />\n<div class=\"row\">\n    <div class=\"col-md-6\">\n        <form id=\"email-form\" method=\"post\">\n            <div asp-validation-summary=\"All\" class=\"text-danger\"></div>\n            <div class=\"form-floating input-group\">\n                <input asp-for=\"Email\" class=\"form-control\" disabled />\n                <div class=\"input-group-append\">\n                    <span class=\"h-100 input-group-text text-success font-weight-bold\">✓</span>\n                </div>\n                <label asp-for=\"Email\" class=\"form-label\"></label>\n            </div>\n\n\n            <div class=\"form-floating\">\n                <input asp-for=\"Input.NewEmail\" class=\"form-control\" autocomplete=\"off\" aria-required=\"true\" />\n                <label asp-for=\"Input.NewEmail\" class=\"form-label\"></label>\n                <span asp-validation-for=\"Input.NewEmail\" class=\"text-danger\"></span>\n            </div>\n            <button id=\"change-email-button\" type=\"submit\" asp-page-handler=\"ChangeEmail\" class=\"w-100 btn btn-lg btn-primary\">Change email</button>\n        </form>\n    </div>\n</div>\n\n@section Scripts {\n    <partial name=\"_ValidationScriptsPartial\" />\n}\n\n",
"AnswerId": "76386720",
"AnswerBody": "asp-for sets the id, name and validation related attributes, and it also sets the value of the input element if there is already a value within the model passed to the view.\nFrom your code, You are using:\n<input asp-for=\"Input.NewEmail\" class=\"form-control\" autocomplete=\"off\" aria-required=\"true\" />\n\nto input the value of Input.NewEmail, I think before you render this view, Input.NewEmail already has the value, asp-for will get this value and set value=\"xxx\" attribute in input tag.\nSo if you don't want show the value, You can just use name property instead of asp-for, Change your code to:\n<input name=\"Input.NewEmail\" class=\"form-control\" autocomplete=\"off\" aria-required=\"true\" />\n\nThen when render this view, Input tag will show nothing.\n"
},
{
"QuestionId": "76384911",
"QuestionTitle": "stick footer to bottom if actual page height is greater than html height",
"QuestionBody": "I have a situation where I use several sliders on the page due to which the actual height of the page changes\nLet's say my html height is 600px but due to some sliders the actual page height is 1000px\nAnd because of this, when I try to stick the footer to the bottom using position: absolute and bottom: 0, I have it placed at the end of the html height\nI used an example to show how everything looks like for me\nIf I use position: relative then on other pages where the height is small, it will not be at the bottom\nHow can I stick the footer to the bottom of the page in this case?\nI have also tried wrapping the entire html content in a class .wrapper { height: 100%; display: flex; flex-direction: column; } and for the footer use position: relative and margin-top: auto\nThis kind of helped, but then there were problems with the blocks that come after the html, they lost their width\n\n\nhtml {\n  height: 500px;\n}\n\n.main-content {\n  padding: 200px;\n  text-align: center;\n}\n\n.content {\n  padding: 300px;\n  text-align: center;\n}\n\n.footer {\n  padding: 40px 0;\n  position: absolute;\n  width: 100%;\n  bottom: 0;\n  text-align: center;\n  background: gray;\n}\n<html>\n<div class=\"main-content\"> MAIN CONTENT</div>\n<div class=\"content\">CONTENT</div>\n<footer class=\"footer\">FOOTER</footer>\n</html>\n\n\n\n",
"AnswerId": "76386287",
"AnswerBody": "You can use flexbox. Uncomment height property in body to see the changes.\nCheck the elements html, body, main and footer in the code below.\nResources: \nCSS Tricks | Flexbox \nCSS Tricks | Flexbox and Auto Margins \nDev | Stick Footer to The Bottom of The Page\n\n\n* {\n  margin: 0;\n  padding: 0;\n  box-sizing: border-box;\n}\n\nhtml, body {\n  height: 100%;\n}\n\nbody {\n  display: flex;\n  flex-direction: column;\n  /*height: 1000px;*/\n}\n\nheader {\n  height: 50px;\n  background-color: cyan;\n}\n\nmain {\n  flex: 1;\n}\n\nfooter {\n  margin-top: auto;\n  height: 70px;\n  background-color: red;\n}\n<html>\n  <body>\n    <header>Header</header>\n    <main>Main</main>\n    <footer>Footer</footer>\n  </body>\n</html>\n\n\n\n"
},
{
"QuestionId": "76387119",
"QuestionTitle": "guard/if let in Java - declare a property or an object if it can be unwrapped",
"QuestionBody": "In swift there is the guard let / if let pattern allowing us to declare an object or a property only if it can be unwrapped.\nit works a follow:\nfunc getMeaningOfLife() -> Int? {\n    42\n}\n\nfunc printMeaningOfLife() {\n    if let name = getMeaningOfLife() {\n        print(name)\n    }\n}\n\nfunc printMeaningOfLife() {\n    guard let name = getMeaningOfLife() else {\n        return\n    }\n\n    print(name)\n}\n\nMy question here is: Is there a Java version of it ?\n",
"AnswerId": "76387120",
"AnswerBody": "The answer is No.\nApparently this syntax also exists in Clojure and according to this Stack Overflow answer there is no way to declare a property if it can be unwrapped in Java.\n"
},
{
"QuestionId": "76387153",
"QuestionTitle": "Powershell GUI, How to take password input without exposing",
"QuestionBody": "I have a situation I am writing a powershell GUI.\nI need to take the password in a secure input.. How can I do it ?\nThe passwd input need to be secured in the window\nbelow is my code\n\n$Passwd                         = New-Object system.Windows.Forms.TextBox\n$Passwd.multiline               = $false\n$Passwd.width                   = 150\n$Passwd.height                  = 20\n$Passwd.location                = New-Object System.Drawing.Point(169,26)\n$Passwd.Font                    = New-Object System.Drawing.Font('Microsoft Sans Serif',10)\n$Passwd.ForeColor               = [System.Drawing.ColorTranslator]::FromHtml(\"#7ed321\")\n$Passwd.BackColor               = [System.Drawing.ColorTranslator]::FromHtml(\"#000000\")\n\nthis is the code\nthe passwd input nee to be secured input ?\n",
"AnswerId": "76387187",
"AnswerBody": "You need to set UseSystemPasswordChar to $true:\n$Passwd.UseSystemPasswordChar = $true\n\n"
},
{
"QuestionId": "76384259",
"QuestionTitle": "String text alignment by decimal point (Swift)",
"QuestionBody": "Is there a way to achieve such kind of alignment of numbers in multiple strings, preferably in interface builder? Please see the attached screenshot.\n\n",
"AnswerId": "76386348",
"AnswerBody": "One approach to achieve this is by using a table view and programmatically adding constraints to align the separator symbol. This method offers scalability as it only includes elements visible on the screen. An interesting aspect of this approach is that the separator's position may change based on the largest offset currently on the screen. Whether this behavior is desired or not depends on your specific requirements.\nIn this solution, I suggest splitting the string into three components and placing them into three separate labels: one for the content before the separator, one for the separator itself, and another for the content after the separator. Additionally, create an invisible reference view at the top level, which will be used to connect the separator label.\nAlthough the following code is implemented programmatically for clarity in understanding constraint connections, it is recommended to move most of the code into the storyboard for better organization and maintainability.\nI hope this code snippet helps you solve your problem.\nclass OffsetNumberViewController: UIViewController {\n    \n    var values: [NSDecimalNumber] = [] {\n        didSet {\n            tableView.reloadData()\n        }\n    }\n    \n    private lazy var tableView: UITableView = {\n        let view = UITableView()\n        view.delegate = self\n        view.dataSource = self\n        return view\n    }()\n    \n    private lazy var numberFormatter: NumberFormatter = {\n        let formatter = NumberFormatter()\n        formatter.decimalSeparator = \".\"\n        formatter.usesGroupingSeparator = true\n        formatter.groupingSeparator = \",\"\n        formatter.groupingSize = 3\n        formatter.maximumFractionDigits = 5\n        return formatter\n    }()\n    \n    private lazy var referenceView = {\n        let view = UIView()\n        view.isHidden = true\n        self.view.addSubview(view)\n        view.translatesAutoresizingMaskIntoConstraints = false\n        self.view.addConstraints([\n            .init(item: view, attribute: .trailing, relatedBy: .lessThanOrEqual, toItem: self.view, attribute: .trailing, multiplier: 1.0, constant: 0.0),\n            .init(item: view, attribute: .top, relatedBy: .equal, toItem: self.view, attribute: .top, multiplier: 1.0, constant: 0.0),\n            .init(item: view, attribute: .bottom, relatedBy: .equal, toItem: self.view, attribute: .bottom, multiplier: 1.0, constant: 0.0)\n        ])\n        return view\n    }()\n    \n    override func viewDidLoad() {\n        super.viewDidLoad()\n        \n        tableView.register(NumberTableViewCell.self, forCellReuseIdentifier: \"amountCell\")\n        tableView.frame = view.bounds\n        view.addSubview(tableView)\n        \n        values = generateRandomValues(count: 1000)\n    }\n    \n    private func generateRandomValues(count: Int) -> [NSDecimalNumber] {\n        (0..<count).map { index in\n            let startValue: Int = 1234567890\n            let maximumDivision = 5\n            \n            let randomDivision: Int = 1<<Int.random(in: 0...maximumDivision)\n            return .init(integerLiteral: startValue).dividing(by: .init(integerLiteral: randomDivision))\n        }\n    }\n    \n    private func formatValue(_ value: NSDecimalNumber) -> String {\n        numberFormatter.string(for: value) ?? \"NaN\"\n    }\n    \n}\n\n// MARK: - UITableViewDelegate, UITableViewDataSource\n\nextension OffsetNumberViewController: UITableViewDelegate, UITableViewDataSource {\n    \n    func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -> Int {\n        values.count\n    }\n    \n    func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -> UITableViewCell {\n        if let cell = tableView.dequeueReusableCell(withIdentifier: \"amountCell\", for: indexPath) as? NumberTableViewCell {\n            cell.setup(withNumberAsString: formatValue(values[indexPath.row]), decimalSeparator: numberFormatter.decimalSeparator)\n            return cell\n        } else {\n            return UITableViewCell()\n        }        \n    }\n    \n    func tableView(_ tableView: UITableView, willDisplay cell: UITableViewCell, forRowAt indexPath: IndexPath) {\n        (cell as? NumberTableViewCell)?.attachCenterTo(referenceView, parent: self.view)\n    }\n    \n    func tableView(_ tableView: UITableView, didEndDisplaying cell: UITableViewCell, forRowAt indexPath: IndexPath) {\n        (cell as? NumberTableViewCell)?.detachExternalConstraints()\n    }\n    \n}\n\n// MARK: - NumberTableViewCell\n\nextension OffsetNumberViewController {\n    \n    class NumberTableViewCell: UITableViewCell {\n        \n        lazy private var leftSideLabel: UILabel = UILabel()\n        lazy private var rightSideLabel: UILabel = UILabel()\n        lazy private var separatorLabel: UILabel = UILabel()\n        \n        private var currentExternalConstraints: [NSLayoutConstraint] = []\n        \n        lazy private var stackView: UIStackView = {\n            let stackView = UIStackView()\n            stackView.translatesAutoresizingMaskIntoConstraints = false\n            stackView.alignment = .fill\n            stackView.axis = .horizontal\n            stackView.distribution = .fill\n            \n            stackView.addArrangedSubview(leftSideLabel)\n            stackView.addArrangedSubview(separatorLabel)\n            stackView.addArrangedSubview(rightSideLabel)\n            \n            addSubview(stackView)\n            \n            addConstraints([\n                .init(item: stackView, attribute: .right, relatedBy: .equal, toItem: self, attribute: .right, multiplier: 1.0, constant: -12.0),\n                .init(item: stackView, attribute: .top, relatedBy: .equal, toItem: self, attribute: .top, multiplier: 1.0, constant: 0.0),\n                .init(item: stackView, attribute: .bottom, relatedBy: .equal, toItem: self, attribute: .bottom, multiplier: 1.0, constant: 0.0),\n            ])\n            \n            return stackView\n        }()\n        \n        func setup(withNumberAsString numberString: String, decimalSeparator: String) {\n            let components = numberString.components(separatedBy: decimalSeparator)\n            \n            let _ = stackView\n            \n            separatorLabel.text = decimalSeparator\n            if components.count == 1 {\n                leftSideLabel.text = components[0]\n                rightSideLabel.text = \"\"\n                separatorLabel.alpha = 0\n            } else if components.count == 2 {\n                leftSideLabel.text = components[0]\n                rightSideLabel.text = components[1]\n                separatorLabel.alpha = 1\n            } else {\n                // Something went wrong\n                leftSideLabel.text = \"\"\n                rightSideLabel.text = \"error\"\n                separatorLabel.alpha = 0\n            }\n        }\n        \n        func detachExternalConstraints() {\n            currentExternalConstraints.forEach { constrain in\n                constrain.isActive = false\n            }\n            currentExternalConstraints = []\n        }\n        \n        func attachCenterTo(_ referenceView: UIView, parent: UIView) {\n            currentExternalConstraints = [\n                .init(item: separatorLabel,\n                                           attribute: .centerX,\n                                           relatedBy: .greaterThanOrEqual,\n                                           toItem: referenceView,\n                                           attribute: .centerX,\n                                           multiplier: 1.0,\n                                           constant: 0.0),\n                .init(item: referenceView,\n                                           attribute: .centerX,\n                                           relatedBy: .greaterThanOrEqual,\n                                           toItem: separatorLabel,\n                                           attribute: .centerX,\n                                           multiplier: 1.0,\n                                           constant: 0.0)\n            ]\n            parent.addConstraints(currentExternalConstraints)\n        }\n        \n    }\n    \n}\n\n"
},
{
"QuestionId": "76385322",
"QuestionTitle": "Banno External Plugin S3 Hosting Question",
"QuestionBody": "I am developing 2 plugins for Banno and have a hosting question.\nMy client will be hosting the plugins on S3. Can I use 1 bucket for both plugins or will they each need a bucket?\nThank you.\nI haven't uploaded anything to S3 yet.\n",
"AnswerId": "76386379",
"AnswerBody": "We don't have material specific to Amazon Web Services (e.g., S3) but here's some general guidance which may be helpful.\nNo matter what, you'll need to make sure that your plugin's content is hosted by your public-facing web server. This means your web server must be accessible via the internet and cannot require the user to be on a specific network or VPN.\nSee these resources for more info:\n\nPlugin Framework / Architecture / Hosting\nPlugin Framework / Guides/ Designing and Developing Plugins\n\nThe gist is that how you build your plugin's web service is at your discretion.\n\nWhether you have separate S3 buckets or a single S3 bucket, that's up to you to decide what's best for your plugin.\n\n"
},
{
"QuestionId": "76382443",
"QuestionTitle": "Google Sheets - Data Validation - Conditional based on Column in another sheet",
"QuestionBody": "Im currently designing a menu for a food festival. I use google sheets. I have a sheet filled with food choices. the menu for a given week should not have food items from the previous weeks. This is a mandatory requirement & I'm not able to get the drop-down if I use Data validation & custom formula.\nI use =FILTER('Item Suggestions'!A:A,'Item Suggestions'!E:E=\"Y\") as the custom formula for validating the data.\nIs there any other way (or a tweak to get the data validation drop down) to get the drop-down & keep the drop-down list filtered?\nEach of the columns in the \"Menu\" sheet should pick from column A of the \"Item Suggestions\" sheet. But the data should be based on column E. If Column E is Y, then that respective data in Column A should be shown in the drop-down\nMenu Sheet:\n\n\n\n\nColumn  A\nColumn B\nColumn C\nColumn D\nColumn E\n\n\n\n\nAppetizers\nMains\nCourse 2\nDessert\nDrinks\n\n\nSoup\nChicken\nCreamy Pasta\nStrawberry Mousse\nFire and Ice\n\n\nBroccoli\nRice & Curry\nRoti & Subzi\nIcecream Sundae\nMojito\n\n\n\n\nItem Suggestions sheet:\n\n\n\n\nColumn A\nColumn B\nColumn C\nColumn D\nColumn E\n\n\n\n\nDish\nCourse\nAllergens\nType\nUsed in Previous weeks?\n\n\nCreamy Pasta\nMain\nGluten\nVegetarian\nY\n\n\nChocolate Marble Cake\nDessert\nWheat\nVegan\nN\n\n\n\n",
"AnswerId": "76384657",
"AnswerBody": "Validation Helper Columns\nI added some 'helper' columns for the validation.\n\nThey can be on the same sheet or a different one.\nThere is one for each course: Appetizer, Main,  Dessert, and Drink. I assume Main and Course 2 both share the same dishes.\nThe FILTER formula would return an array of Dishes that match the correct Course, and haven't yet been used:\n\n=IFERROR(FILTER(Dishes,Courses=thisCourse,isUsed<>\"Y\"),\"-\")\n\n\nFor the validation rule,\n\nthe criteria would be \"Dropdown (from a range)\" with the range being the appropriate helper column for each Course\nThe \"Apply to range\" value would be the appropriate Course column in your Menu table\n\n\nPlease note that all populated menu items will 'always' show the error flag (red triangle in the top right corner).  This is because the moment they are used, they are no longer valid values.  This doesn't affect the functionality of the menu dropdowns.  Used menu items will be filtered from the dropdowns, and you will not be able to add a used menu item manually with the dropdown properties set to reject.  Just a visual distraction.\n\nDropdown Formula\nSingle Formula\nWill generate all dropdowns at once and centralizes modifications\n=BYCOL(M2:P2, LAMBDA(c, \n   IFERROR(FILTER(G:G,H:H=c,K:K<>\"Y\"),\"-\")))\n\nIndividual Formula\nNeeds to be manually copied to each column\n=IFERROR(FILTER($G:$G,$H:$H=M2,$K:$K<>\"Y\"),\"-\")\n\nFiltering Formula\n\nDropdown with Filtered Dishes\n\nFormula to Mark Dishes When Used\n\nYour Master List of dishes includes a column to mark if a dish has been used previously\nYour menu's dropdowns are based on that and it makes sense to update the \"used/not used\" status dynamically when a dish is added or removed from a menu.\nThis can be achieved using a formula in the Master List that marks each dish based on whether it exists in the menu.\n\nDish \"Is Used\" Formula\nNote that the 'Single Formula' includes the column heading \"Used in previous weeks?\".\n\nThis was intentional in order to place the formula a line above the Master List data\nOffsetting the formula from the data by a row, allows the data to be sorted without impacting the formula. For example, you could sort the Master List by any of Dishes, Courses, Allergens, or Type\n\nSingle Formula\n={\"Used in previous weeks?\";\n  BYROW(G3:G51, LAMBDA(r, \n    IFERROR(IF(ROWS(FILTER(r,COUNTIF(A:E,r)))>0,\"Y\"))))}\n\nIndividual Formulas\nNeeds to be copied to each row\n=IFERROR(IF(ROWS(FILTER(G3,COUNTIF(A:E,G3)))>0,\"Y\"))\n\nSorted Asc. by Dishes\n\nSorted Asc. by Courses then Dishes\n\n"
},
{
"QuestionId": "76382591",
"QuestionTitle": "Google Container Registry: Permission issue while trying to pull/push images with authenticated credentials",
"QuestionBody": "In Ubuntu-22, google-cloud has been installed through snap store;\n> whereis gcloud\ngcloud: /snap/bin/gcloud\n> snap list | grep google\ngoogle-cloud-sdk           432.0.0                     346    latest/stable    google-cloud-sdk**  classic\n\nDocker has been installed via snap too;\n> snap list | grep docker\ndocker                     20.10.24                    2893   latest/stable    canonical**\n\nAnd I have authenticated my account to a private GCR as below;\n> gcloud auth login\nYour browser has been opened to visit:\n\n    https://accounts.google.com/o/oauth2/auth?...<long_url>\n\n\nYou are now logged in as [<my_email@address.com>].\nYour current project is [<desired_project_name>].  You can change this setting by running:\n  $ gcloud config set project PROJECT_ID\n\nDouble-checked the login process;\n> gcloud auth list\n           Credentialed Accounts\nACTIVE             ACCOUNT\n*                  <my_email@address.com>\n\nTo set the active account, run:\n    $ gcloud config set account `ACCOUNT`\n\nBut, when I try to pull or push any image, I hit the following permission issue;\nunauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication\n\nI am able to access to the image which I try to pull from the private GCR in my browser, this makes me think that it is an issue related to creds while performing docker pull in my terminal.\nWhat am I missing here?\nPS: The solution in this question did not work for me Unable to push to Google Container Registry - Permission issue\n\nEDIT:\nAs it is asked in the comments, I need to mention that I have performed one more step before auth login which is gcloud auth configure-docker;\n> gcloud auth configure-docker\nAdding credentials for all GCR repositories.\nWARNING: A long list of credential helpers may cause delays running 'docker build'. We recommend passing the registry name to configure only the registry you are using.\nAfter update, the following will be written to your Docker config file located at \n[/home/<user>/.docker/config.json]:\n {\n  \"credHelpers\": {\n    \"gcr.io\": \"gcloud\",\n    \"us.gcr.io\": \"gcloud\",\n    ...\n  }\n}\n\nDo you want to continue (Y/n)?  \n\nDocker configuration file updated.\n\n",
"AnswerId": "76384670",
"AnswerBody": "Removing snap installation and installing docker with package manager apt has fixed my issue.\nThe difference I have observed between two installations;\n\nWith snap, once gcloud auth login directs me to browser, authentication was completed by choosing google account only (Please see the 3rd code block in my question, no authorization code was asked).\nWith apt, after choosing the desired google account, I was directed to another page where the authorization code was provided which needed to be entered in the terminal;\n\n> gcloud auth login\nYour browser has been opened to visit:\n\n    https://accounts.google.com/o/oauth2/auth?...<long_url>\n\nEnter authorization code: <Code_from_browser>  // This is the difference!!\n\nYou are now logged in as [<my_email@address.com>].\nYour current project is [<desired_project_name>].  You can change this setting by running:\n  $ gcloud config set project PROJECT_ID\n\nThank you @JohnHanley pointed out that docker recommends apt installation.\n"
},
{
"QuestionId": "76385271",
"QuestionTitle": "Optimizing joins in a postgres/postgis query",
"QuestionBody": "I'm trying to optimize my Postgres query. I'm running into problems with some of the joins here. My main issue is around the filter h.type='inNetwork' and my geometry search ST_Intersects(ST_MakeValid(ser.boundaries)::geography, ST_MakeValid(ST_SetSRID(ST_GeomFromGeoJson(<INSERT_GEOMETRY_JSON>)). Something about that specific filter increase the search time by ~10x. The other filters don't seem to have much of an effect on the search speed. As a side note, there are additional filters that are used conditionally and that's why some of the join tables here seem irrelevant.\nQuery in question:\nSELECT DISTINCT r.id, r.profitability\nFROM rolloff_pricing as r\nLEFT JOIN service_areas ser on r.service_area_id = ser.id\nLEFT JOIN sizes as s on r.size_id = s.id\nLEFT JOIN sizes as sa on r.sell_as = sa.id\nLEFT JOIN waste_types w on w.id = r.waste_type_id\nLEFT JOIN regions reg on reg.id = ser.region_id\nLEFT JOIN haulers h on h.id = reg.hauler_id\nLEFT JOIN current_availability ca on ca.region_id = reg.id\nLEFT JOIN regions_availability ra on ra.region_id = reg.id\nLEFT JOIN current_availability_new_deliveries cand on ca.id = cand.current_availability_id and r.size_id = cand.size_id\nLEFT JOIN exceptions ex on ex.region_id = reg.id\nWHERE ser.active is true\nand ST_Intersects(ST_MakeValid(ser.boundaries)::geography, ST_MakeValid(ST_SetSRID(ST_GeomFromGeoJson('{\n    \"type\": \"POINT\",\n    \"coordinates\": [\n        \"-95.3595563\",\n        \"29.7634871\"\n    ]\n}'),4326))::geography)\nand h.active is true\nand ra.delivery_type='newDeliveries'\nand h.type='inNetwork'\nGROUP BY r.id ORDER BY profitability desc OFFSET 0 ROWS FETCH NEXT 8 ROWS ONLY\n\nHere is the EXPLAIN (ANALYZE, BUFFERS):\nLimit  (cost=246.23..246.29 rows=8 width=21) (actual time=3711.860..3711.866 rows=8 loops=1)\n  Buffers: shared hit=15048\n  ->  Unique  (cost=246.23..246.29 rows=8 width=21) (actual time=3711.859..3711.860 rows=8 loops=1)\n        Buffers: shared hit=15048\n        ->  Sort  (cost=246.23..246.25 rows=8 width=21) (actual time=3711.858..3711.858 rows=8 loops=1)\n\"              Sort Key: r.profitability DESC, r.id\"\n              Sort Method: quicksort  Memory: 28kB\n              Buffers: shared hit=15048\n              ->  Group  (cost=246.07..246.11 rows=8 width=21) (actual time=3711.820..3711.841 rows=48 loops=1)\n                    Group Key: r.id\n                    Buffers: shared hit=15048\n                    ->  Sort  (cost=246.07..246.09 rows=8 width=21) (actual time=3711.817..3711.823 rows=216 loops=1)\n                          Sort Key: r.id\n                          Sort Method: quicksort  Memory: 41kB\n                          Buffers: shared hit=15048\n                          ->  Hash Left Join  (cost=154.30..245.95 rows=8 width=21) (actual time=3711.508..3711.745 rows=216 loops=1)\n                                Hash Cond: ((reg.id)::text = (ex.region_id)::text)\n                                Buffers: shared hit=15048\n                                ->  Hash Join  (cost=150.45..242.05 rows=8 width=37) (actual time=3711.490..3711.705 rows=144 loops=1)\n                                      Hash Cond: ((ra.region_id)::text = (reg.id)::text)\n                                      Buffers: shared hit=15045\n                                      ->  Seq Scan on regions_availability ra  (cost=0.00..89.11 rows=643 width=16) (actual time=0.006..0.186 rows=643 loops=1)\n                                            Filter: ((delivery_type)::text = 'newDeliveries'::text)\n                                            Rows Removed by Filter: 1286\n                                            Buffers: shared hit=65\n                                      ->  Hash  (cost=150.34..150.34 rows=9 width=53) (actual time=3711.461..3711.461 rows=144 loops=1)\n                                            Buckets: 1024  Batches: 1  Memory Usage: 21kB\n                                            Buffers: shared hit=14980\n                                            ->  Hash Right Join  (cost=73.72..150.34 rows=9 width=53) (actual time=3711.218..3711.442 rows=144 loops=1)\n                                                  Hash Cond: ((ca.region_id)::text = (reg.id)::text)\n                                                  Buffers: shared hit=14980\n                                                  ->  Seq Scan on current_availability ca  (cost=0.00..69.02 rows=2002 width=32) (actual time=0.009..0.124 rows=2002 loops=1)\n                                                        Buffers: shared hit=49\n                                                  ->  Hash  (cost=73.68..73.68 rows=3 width=69) (actual time=3711.173..3711.173 rows=48 loops=1)\n                                                        Buckets: 1024  Batches: 1  Memory Usage: 13kB\n                                                        Buffers: shared hit=14931\n                                                        ->  Nested Loop  (cost=0.84..73.68 rows=3 width=69) (actual time=2262.438..3711.145 rows=48 loops=1)\n                                                              Buffers: shared hit=14931\n                                                              ->  Nested Loop  (cost=0.55..44.90 rows=1 width=48) (actual time=2262.424..3710.955 rows=7 loops=1)\n                                                                    Buffers: shared hit=14877\n                                                                    ->  Nested Loop  (cost=0.28..38.20 rows=3 width=16) (actual time=0.012..4.723 rows=609 loops=1)\n                                                                          Buffers: shared hit=1418\n                                                                          ->  Seq Scan on haulers h  (cost=0.00..21.60 rows=2 width=16) (actual time=0.003..0.698 rows=439 loops=1)\n                                                                                Filter: ((active IS TRUE) AND ((type)::text = 'inNetwork'::text))\n                                                                                Rows Removed by Filter: 89\n                                                                                Buffers: shared hit=15\n                                                                          ->  Index Scan using regions_hauler_id_idx on regions reg  (cost=0.28..8.29 rows=1 width=32) (actual time=0.006..0.007 rows=1 loops=439)\n                                                                                Index Cond: ((hauler_id)::text = (h.id)::text)\n                                                                                Buffers: shared hit=1403\n                                                                    ->  Index Scan using service_areas_region_id_idx on service_areas ser  (cost=0.28..2.22 rows=1 width=32) (actual time=6.035..6.085 rows=0 loops=609)\n                                                                          Index Cond: ((region_id)::text = (reg.id)::text)\n\"                                                                          Filter: ((active IS TRUE) AND ((st_makevalid(boundaries))::geography && '0101000020E610000087646DF802D757C0FA6AFDE373C33D40'::geography) AND (_st_distance((st_makevalid(boundaries))::geography, '0101000020E610000087646DF802D757C0FA6AFDE373C33D40'::geography, '0'::double precision, false) < '1.00000000000000008e-05'::double precision))\"\n                                                                          Rows Removed by Filter: 3\n                                                                          Buffers: shared hit=13459\n                                                              ->  Index Scan using rolloff_pricing_service_area_id_idx on rolloff_pricing r  (cost=0.29..28.70 rows=8 width=83) (actual time=0.013..0.019 rows=7 loops=7)\n                                                                    Index Cond: ((service_area_id)::text = (ser.id)::text)\n                                                                    Buffers: shared hit=54\n                                ->  Hash  (cost=3.38..3.38 rows=38 width=48) (actual time=0.012..0.012 rows=39 loops=1)\n                                      Buckets: 1024  Batches: 1  Memory Usage: 10kB\n                                      Buffers: shared hit=3\n                                      ->  Seq Scan on exceptions ex  (cost=0.00..3.38 rows=38 width=48) (actual time=0.003..0.007 rows=39 loops=1)\n                                            Buffers: shared hit=3\nPlanning Time: 1.031 ms\nExecution Time: 3711.956 ms\n\nMy understanding of what's happening here is that my filter is bringing in additional rows (the large majority of the h table is true for the condition h.type='inNetwork', which is making my geometry query run for a much larger set of rows than intended.\nSomething that I've tried is putting the geometry query into a subquery (because the geometry query actually runs pretty quickly itself) to get a set of r.id's that I could use in an where in clause. This seems to not work as well though. Here is my modified query that also is too slow:\nSELECT DISTINCT r.id, r.profitability\nFROM rolloff_pricing as r\nLEFT JOIN service_areas ser on r.service_area_id = ser.id\nLEFT JOIN sizes as s on r.size_id = s.id\nLEFT JOIN sizes as sa on r.sell_as = sa.id\nRIGHT JOIN waste_types w on w.id = r.waste_type_id\nRIGHT JOIN regions reg on reg.id = ser.region_id\nRIGHT JOIN haulers h on h.id = ser.hauler_id\nRIGHT JOIN current_availability ca on ca.region_id = reg.id\nRIGHT JOIN regions_availability ra on ra.region_id = reg.id\nLEFT JOIN current_availability_new_deliveries cand on ca.id = cand.current_availability_id and r.size_id = cand.size_id\nRIGHT JOIN exceptions ex on ex.region_id = reg.id\nWHERE r.id in (\n    select r2.id\n    from rolloff_pricing as r2\n    LEFT JOIN service_areas ser2 on r2.service_area_id = ser2.id\n    WHERE\n    ST_Intersects(ST_MakeValid(ser2.boundaries)::geography, ST_MakeValid(ST_SetSRID(ST_GeomFromGeoJson('{\n        \"type\": \"POINT\",\n        \"coordinates\": [\n            \"-95.3595563\",\n            \"29.7634871\"\n        ]\n    }'),4326))::geography)\n    and ser2.active is true\n)\nand h.active is true\nand ra.delivery_type='newDeliveries'\nand h.type='inNetwork'\nGROUP BY r.id ORDER BY profitability desc OFFSET 0 ROWS FETCH NEXT 8 ROWS ONLY\n\nIt's interesting to me because the subquery here resolves by itself very quickly. And if I sub out the subquery for the returned results, the whole thing resolves very quickly as well. So I'm not sure how to approach this exactly. My next guess is to just run a completely seperate query for the r.ids and then pass them through to the \"main\" query.\nMaybe relevant info: this query is being generated and executed in an eloquent-based api\nHow can I go about approaching improving the speed here?\n",
"AnswerId": "76386421",
"AnswerBody": "\nthe large majority of the h table is true for the condition h.type='inNetwork', which is making my geometry query run for a much larger set of rows than intended.\n\nI don't understand.  If most of the table meets the condition h.active is true and h.type='inNetwork', then most of the table gets processed.  What else could have possibly been intended? The estimate there is pretty horrible (estimated rows 2, actual 439) but that must be just because your stats are horribly out of date.  There is really no good reason for the estimate to be off by so much. You should run VACUUM ANALYZE on all tables involved in this query, after making sure there are no transactions being held open. If it doesn't fix the query directly, it will at least produce plans which are easier to understand.\n->  Index Scan using service_areas_region_id_idx on service_areas ser  (cost=0.28..2.22 rows=1 width=32) (actual time=6.035..6.085 rows=0 loops=609)\n    Index Cond: ((region_id)::text = (reg.id)::text)\n    Filter: ((active IS TRUE) AND ((st_makevalid(boundaries))::geography && '0101000020E610000087646DF802D757C0FA6AFDE373C33D40'::geography) AND (_st_distance((st_makevalid(boundaries))::geography, '0101000020E610000087646DF802D757C0FA6AFDE373C33D40'::geography, '0'::double precision, false) < '1.00000000000000008e-05'::double precision))\"\n    Rows Removed by Filter: 3\n    Buffers: shared hit=13459\n\nThis is the one place which takes pretty much all of the time.  And it is hard to understand what it is actually doing.  Why on earth would it take 13459 buffers hits to run this scan 609 times?  that is 22 buffers for each loop, but descending an index should only take 3 to 4 buffer accesses.  You could be filtering out a lot of rows due to the filter condition, but in that case Rows Removed by Filter would need to be a lot more than 3.  Maybe the index is stuffed full of dead entries, which then get filtered out but don't get tabulated in 'Rows Removed by Filter'.  (A VACUUM when there are no transactions being held open would fix that).  Or maybe the geometry column is very large and so gets TOASTed over many pages.\nAnd to be clear here, I'm not saying the large number of buffer accesses are causing the slowness, they are all \"buffer hits\" afterall and so should be fast. But it is an oddity that should be investigated.\n"
},
{
"QuestionId": "76383772",
"QuestionTitle": "Link list sidebar widget remove button not working in jquery",
"QuestionBody": "I am creating a link list widget. Whenever we clicked on Title button, it adds a list with add link option. Everything is working fine but whenever I am trying to click the remove title button. The button is not working anymore. Where the alert is working and logs are showing also in console but the action is not working. Can you please check?\nCode Pen Codepen Reference Link\n",
"AnswerId": "76384721",
"AnswerBody": "At line 23 you are only selecting a parent HTML element when the remove-title button is clicked, but doing nothing with it.\n\n\nif ($(\".remove-title\").length) {\n  $(\"body\").on(\"click\", \".remove-title\", function() {\n    console.log(\"clicked\");\n    $(this).parents(\".btn-options\");\n  });\n}\n\n\n\nFirst you should make sure you're not deleting the only section left. If so, the .add-title button is triggered first.\n\n\nif ($(\".remove-title\").length) {\n  $(\"body\").on(\"click\", \".remove-title\", function() {\n    console.log(\"clicked\");\n    var $this = $(this);\n    var parent = $this.parents(\".title-area\");\n    if (!parent.siblings(\".title-area\").length) {\n      $this.siblings(\".add-title\").trigger(\"click\");\n    }\n    var title = parent.find(\"input.title-text\").eq(0).val();\n    var toast = parent.siblings(\".title-area\").find(\".btn-toast\");\n    toast.show().html(\"Title removed: <span>\" + title + \"</span>\")\n      .delay(400).fadeOut(\"slow\");\n    parent.remove();\n  });\n}\n\n\n\nAs you can see, I've also added a \"toast\" element to the btn-options div to briefly display the title of the deleted section. You can find the rest of those changes here: Codepen\n"
},
{
"QuestionId": "76387124",
"QuestionTitle": "What is the equivalent of add.classList in React for toggling visibility?",
"QuestionBody": "Adding and removing classes to elements in React\nI’m a complete newb with React but basically I’ve been trying to make it so that a container goes from hidden to visible when you click a button.\nUsually I’d just do an eventListner and add.classList or remove.classList but I can’t find the equivalent to that in react ?\nI’ve tried figuring it out with useState and everything but I feel like I’m just overlooking something simple.\nI would really appreciate some help it’s been like hours and my tiny brain is gonna explode\n",
"AnswerId": "76387192",
"AnswerBody": "I would recommend adding a condition to render the element/component instead of using classes.\nconst [visible, setVisible] = useState(false);\n\nreturn (\n  <div>\n    <button onClick={() => setVisible(!visible)}>toggle</button>\n    {visible && <span>hello</span>}\n  </div>\n);\n\n"
},
{
"QuestionId": "76383780",
"QuestionTitle": "Find points inside region delimited by two lines",
"QuestionBody": "I have the following point configuration:\nimport numpy as np \n\nT=np.array([9,9])\nX1=np.array([8,16])\nX2=np.array([16,3])\npoints=np.array([[4, 15],\n                 [13,17],\n                 [2, 5],\n                 [16,8]])\n\nThis can be represented as:\n\nGiven T, X1, and X2, I want to find all points of the array points that are inside the yellow region. This yellow region is always in the \"opposite side\" of the points X1 and X2.\nHow can I achieve this in a simple and efficient way?\nEdit1 (trying B Remmelzwaal solution)\nT=np.array([9,9])\nX1=np.array([10,2])\nX2=np.array([2,15])\npoints=np.array([[2, 5]])\n\nvalid_points = list()\n\n# calculating y = mx + b for line T, X1\nslope1 = np.diff(list(zip(T, X1)))\nm1 = np.divide(slope1[1], slope1[0])\nb1 = T[1] - m1*T[0]\n\n# calculating y = mx + b for line T, X2\nslope2 = np.diff(list(zip(T, X2)))\nm2 = np.divide(slope2[1], slope2[0])\nb2 = T[1] - m2*T[0]\n\nfor point in points:\n    # check if point is under both lines\n    for m, b in (m1, b1), (m2, b2):\n        if point[1] > m*point[0] + b:\n            break\n    else:\n        # only append if both checks pass\n        valid_points.append(point)\n        \nprint(valid_points)\n\nThe configuration is the following:\n\nand the code returns returns [2,5] and it should return []. This is not correct since the region of interest is now in the opposite region (see image)\n",
"AnswerId": "76384730",
"AnswerBody": "The naive solution to this can be thought of as a series of stages\n\nembed the values into equations in a Two-Point Form\nfor each line defined by the Equations\n\nfor each point in the collection to compare\n\nat X, see if Y is below the line value\n\n\n\n\nboolean AND on the results, such that only values below both lines match\n\nHowever, this can be much faster with NumPy's powerful numeric methods, as you can directly use the values in collections without bothering to create the intermediate equations, but need to then pose it in a manner it expects and would make more sense to do for a great number of lines (hundreds, millions..)\nvery extended approach\nimport numpy as np \n\nT=np.array([9,9])\nX1=np.array([8,16])\nX2=np.array([16,3])\npoints=np.array([[4, 15],\n                 [13,17],\n                 [2, 5],\n                 [16,8]])\n\nequations = []\nfor point_pair in [(T, X1), (T, X2)]:\n    # extract points\n    (x1, y1), (x2, y2) = point_pair  # unpack\n    # create equation as a function of X to get Y\n    fn = lambda x, x1=x1, y1=y1, x2=x2, y2=y2: (y2-y1)/(x2-x1)*(x-x1)+y1\n    equations.append(fn)\n\nresults = {}  # dict mapping lines to their point comparisons\nfor index, equation in enumerate(equations):\n    key_name = \"line_{}\".format(index + 1)\n    results_eq = []\n    for point in points:\n        point_x, point_y = point  # unpack\n        line_y = equation(point_x)\n        results_eq.append(point_y < line_y)  # single bool\n    array = np.array(results_eq)             # list -> array of bools\n    results[key_name] = array                # dict of arrays of bools\n\n# & is used here to compare boolean arrays such that both are True\nfinal_truthyness = results[\"line_1\"] & results[\"line_2\"]\nprint(final_truthyness)\n\n>>> print(final_truthyness)\n[False False  True False]\n\n\nAlternatively, you can carefully order your points and take the Cross Product\nNOTE that the point ordering matters here such that points below are really to the right of the line (vector), you can calculate this by comparing the X values of the points\n>>> X1[0] < T[0], X2[0] < T[0]             # determine point ordering\n(True, False)\n>>> a = np.cross(points - X1, T - X1) > 0\n>>> b = np.cross(points - T, X2 - T) > 0\n>>> a,b ; a&b                              # individual arrays ; AND\n(array([ True, False,  True, False]), array([False, False,  True, False]))\narray([False, False,  True, False])\n\nFinally, you might take some caution in a larger program to special case point pairs which are exactly the same point\n"
},
{
"QuestionId": "76384948",
"QuestionTitle": "Xdebug not stopping at breakpoints",
"QuestionBody": "Xdebug does not stop at breakpoints.\nI tried different versions of Xdebug. (current v1.32.1, v1.32.0,  v1.31.1, v1.31.0, v1.30.0)\nThis is my configuration at the launch.json file:\n{\n// Use IntelliSense to learn about possible attributes.\n// Hover to view descriptions of existing attributes.\n// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n\"version\": \"0.2.0\",\n\"configurations\": [\n    {\n        \"name\": \"Listen for Xdebug\",\n        \"type\": \"php\",\n        \"request\": \"launch\",\n        \"port\": 9003\n    },\n    {\n        \"name\": \"Launch currently open script\",\n        \"type\": \"php\",\n        \"request\": \"launch\",\n        \"program\": \"${file}\",\n        \"cwd\": \"${fileDirname}\",\n        \"port\": 0,\n        \"runtimeArgs\": [\n            \"-dxdebug.start_with_request=yes\"\n        ],\n        \"env\": {\n            \"XDEBUG_MODE\": \"debug,develop\",\n            \"XDEBUG_CONFIG\": \"client_port=${port}\"\n        }\n    },\n    {\n        \"name\": \"Launch Built-in web server\",\n        \"type\": \"php\",\n        \"request\": \"launch\",\n        \"runtimeArgs\": [\n            \"-dxdebug.mode=debug\",\n            \"-dxdebug.start_with_request=yes\",\n            \"-S\",\n            \"localhost:0\"\n        ],\n        \"program\": \"\",\n        \"cwd\": \"${workspaceRoot}\",\n        \"port\": 9003,\n        \"serverReadyAction\": {\n            \"pattern\": \"Development Server \\\\(http://localhost:([0-9]+)\\\\) started\",\n            \"uriFormat\": \"http://localhost:%s\",\n            \"action\": \"openExternally\"\n        }\n    }\n]}\n\nCould there be a conflict with the web server?\nThis is my configuration in the php.ini (all the way at the bottom of the file):\n[xdebug]\nzend_extension=C:\\xampp\\php\\ext\\php_xdebug.dll\nxdebug.mode = debug\nxdebug.start_with_request = yes\nxdebug.client_port = 9003        // it also doesnt work without this line.\n\nInstallation Wizard\nSummary from <https://xdebug.org/wizard> \n\n    • Xdebug installed: 3.2.1\n    • Server API: Apache 2.0 Handler\n    • Windows: yes \n    • Compiler: MS VS16\n    • Architecture: x64\n    • Zend Server: no \n    • PHP Version: 8.2.4\n    • Zend API nr: 420220829\n    • PHP API nr: 20220829\n    • Debug Build: no\n    • Thread Safe Build: yes\n    • OPcache Loaded: no\n    • Configuration File Path: no value\n    • Configuration File: C:\\xampp\\php\\php.ini\n    • Extensions directory: C:\\xampp\\php\\ext\n\n\n\n\n\nI've downloaded the file from the wizard and renamed it correctly.\nPort 9003 is correct according to the documentation. But I also tried port 9000 as well.\nIf I go to https://portchecker.co/checking and check for Port 9000 or 9003 they are closed.\n\nI reinstalled XAMPP\nI reinstalled VS Code\n\nI also went to Settings -> Features -> Debug -> Allow Breakpoints Everywhere.\n",
"AnswerId": "76386605",
"AnswerBody": "I went ahead and installed xampp and xdebug.\nOur launch.json files and wizard output are identical and it seems to work ok for me.\nMy php.ini doesn't include the last line with the port number or the apostrophe after the xdebug closing brace that you have.\n[xDebug]\nzend_extension = xdebug\nxdebug.mode = debug\nxdebug.start_with_request = yes\n\nYou shouldn't need the entire file path for your zend_extension considering that the extensions directory is already mapped for you.\nI would double check that you've defined your \"php.debug.executablePath\": in vscode settings as well.\nHere's what mine looks like after\n\nRunning Listen for Xdebug in vscode\nNavigating to the file I used here at http://localhost/info/index.php in the browser\n\n\nIf making those changes still doesn't work, maybe double check that the breakpoint is actually reachable.\n"
},
{
"QuestionId": "76382864",
"QuestionTitle": "How do I prevent 'NotImplementedError' and 'TypeError' when using numeric aggregate functions in Pandas pivot tables with string columns?",
"QuestionBody": "I have tried severally to perform some numeric aggregation methods on numeric data with pandas. However, I have received a NotImplementedError, which then throws a TypeError, whenever I do so. I hypothesize that pandas is refusing to ignore the string columns when performing said numerical tasks. How do I prevent this?\nGiven a pivot table named matrix_data, and with pandas imported as pan:\n  Account Number  Company      Contact Account Manager     Product  Licenses   \n0         2123398   Google  Larry Pager    Edward Thorp   Analytics       150  \n1         2123398   Google  Larry Pager    Edward Thorp  Prediction       150   \n2         2123398   Google  Larry Pager    Edward Thorp    Tracking       300   \n3         2192650     BOBO  Larry Pager    Edward Thorp   Analytics       150   \n4          420496     IKEA    Elon Tusk    Edward Thorp   Analytics       300   \n\n   Sale Price        Status  \n0     2100000     Presented  \n1      700000     Presented  \n2      350000  Under Review  \n3     2450000          Lost  \n4     4550000           Won  \n\nTrying to aggregate all numerical values by company:\npan.pivot_table(matrix_data, index = \"Company\", aggfunc=\"mean\");\n\nthrows an exception like so:\nNotImplementedError                       Traceback (most recent call last)\nFile ~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\groupby\\groupby.py:1490, in GroupBy._cython_agg_general..array_func(values)\n   1489 try:\n-> 1490     result = self.grouper._cython_operation(\n   1491         \"aggregate\",\n   1492         values,\n   1493         how,\n   1494         axis=data.ndim - 1,\n   1495         min_count=min_count,\n   1496         **kwargs,\n   1497     )\n   1498 except NotImplementedError:\n   1499     # generally if we have numeric_only=False\n   1500     # and non-applicable functions\n...\n   1698             # e.g. \"foo\"\n-> 1699             raise TypeError(f\"Could not convert {x} to numeric\") from err\n   1700 return x\n\nTypeError: Could not convert Larry PagerLarry PagerLarry Pager to numeric\n\ndataframe.groupby([\"col_name1\"]).mean() will throw an identical error\nI'm on windows 10, python 3.11, with pandas version 2.0.1. All this was performed on Jupyter Notebook with VScode\n",
"AnswerId": "76384737",
"AnswerBody": "This has been deprecated in Pandas 2.0. This is the warning pandas 1.5.3 gives:\n\nFutureWarning: pivot_table dropped a column because it failed to\naggregate. This behavior is deprecated and will raise in a future\nversion of pandas. Select only the columns that can be aggregated.\n\nYou now have to select the specific columns you want to aggregate.\ncols = ['Licenses', 'Sale Price']\npd.pivot_table(matrix_data, values=cols, index=\"Company\", aggfunc=\"mean\")\n\n"
},
{
"QuestionId": "76387117",
"QuestionTitle": "Can I be guaranteed that a variable value will be passed along to a new running Task?",
"QuestionBody": "Can I assume the following code will always pass my assertions? I'm a worried about the index value. I'm not sure if the scoped value will be passed along to the Task.Run lambda expression. I think it will be scoped just like the attributesChunked value seems to be. But I'd like some confirmation.\nvar tasks = new List<Task>();\nvar attributes = new string[4]{ \"att1\", \"att2\", \"att3\", \"att4\" };\nvar chunkIndex = -1;\nforeach (var attributesChunked in attributes.Chunk(2))\n{\n    var index = Interlocked.Increment(ref chunkIndex);\n    tasks.Add(Task.Run(() =>\n    {\n        if (index == 0)\n             Assert.Equal(\"attr1\", attributesChunked.First());\n        if (index == 2)\n             Assert.Equal(\"attr3\", attributesChunked.First());\n    }\n}\nawait Task.WhenAll(tasks);\n\n",
"AnswerId": "76387222",
"AnswerBody": "For each task you create, you are introducing a closure on the index variable declared in that iteration. So yes your Task will use the right value, as can be tested using following code:\nstatic async Task Main(string[] args)\n{\n    var tasks = new List<Task>();\n    var attributes = new string[4] { \"att1\", \"att2\", \"att3\", \"att4\" };\n    var chunkIndex = -1;\n    foreach (var attributesChunked in attributes.Chunk(2))\n    {\n        var index = Interlocked.Increment(ref chunkIndex);\n        tasks.Add(Task.Run(async () =>\n        {\n            //simulate some work...\n            await Task.Delay(50);\n            Console.WriteLine($\"index: {index}\");\n        }));\n    }\n    await Task.WhenAll(tasks);\n}\n\nThe result:\n\nindex: 0\nindex: 1\n\nNote that the sequence of the output is entirely dependent on the scheduling of the individual Tasks and cannot be predicted...\nUseful reference: What are 'closures' in .NET?\n"
},
{
"QuestionId": "76384430",
"QuestionTitle": "Strange behavior from CMake when importing a STATIC library",
"QuestionBody": "I'm experiencing a strange (bug?) when importing the yaml-cpp static library with CMake.\nmain.cpp\n#include \"yaml-cpp/yaml.h\"\n\nCMakeLists.txt (working)\nadd_library(yaml-cpp ${PROJECT_BINARY_DIR}/path/to/libyaml-cpp.a)\ntarget_link_libraries(main yaml-cpp)\n\nCMakeLists.txt (not working)\nadd_library(yaml-cpp STATIC IMPORTED)                                \nset_target_properties(yaml-cpp PROPERTIES IMPORTED_LOCATION ${PROJECT_BINARY_DIR}/path/to/libyaml-cpp.a)  \ntarget_link_libraries(main yaml-cpp)  \n\nWhen I use the second CMakeLists.txt, my main.cpp cannot find yaml-cpp/yaml.h. When I use the first CMakeLists.txt, it can, however, I get the \"ar: no archive members specified\" message every time I configure the project, which is annoying. Would like to import it the second way to get rid of that message.\n",
"AnswerId": "76386630",
"AnswerBody": "For both of you who answered, I appreciate it. Turns out I should have provided more information in my question. The issue was arising basically from the fact that I am attempting to create a portable installation, with the entire source of each of the dependencies within the project folder-structure, which is something that I haven't attempted before. It seemed logical to me that the library files (.a, .dylib, etc..) would contain all of the headers within them, but apparently that is not the case. I will provide a few details on how I was able to fix the issue.\n\nBuilding the libraries before the rest of the project was the right move, but I forgot to install them. cmake -> make -> make install\n\nBuildLibraries.txt (cmake file)\n    set(yaml-cpp_cmakelists \"${CMAKE_SOURCE_DIR}/external/yaml-cpp-master\")\n    set(yaml-cpp_build_location \"${CMAKE_BINARY_DIR}/external/yaml-cpp-master\")        \n    file(MAKE_DIRECTORY ${yaml-cpp_build_location})  \n\n    execute_process(                                                                     \n        COMMAND ${CMAKE_COMMAND} -S ${yaml-cpp_cmakelists} -B ${yaml-cpp_build_location} -D CMAKE_INSTALL_PREFIX=${CMAKE_LIBRARY_OUTPUT_DIRECTORY} -D BUILD_SHARED_LIBS=OFF\n        WORKING_DIRECTORY ${yaml-cpp_build_location}\n        RESULT_VARIABLE result\n    )\n    if(NOT result EQUAL 0)\n        message(FATAL_ERROR \"Failed to configure yaml-cpp\")\n    endif()\n\n    execute_process(                                                                     \n        COMMAND make -C ${yaml-cpp_build_location} -j4\n        WORKING_DIRECTORY ${yaml-cpp_build_location}\n        RESULT_VARIABLE result\n    )\n    if(NOT result EQUAL 0)\n        message(FATAL_ERROR \"Failed to generate yaml-cpp\")\n    endif()\n\n    execute_process(                                                                     \n        COMMAND make install -C ${yaml-cpp_build_location} -j4\n        WORKING_DIRECTORY ${yaml-cpp_build_location}\n        RESULT_VARIABLE result\n    )\n    if(NOT result EQUAL 0)\n        message(FATAL_ERROR \"Failed to install yaml-cpp\")\n    endif()\n\n\nInside project-root directory CMakeLists.txt:\n\nensure that find_package() knows where to look for the libraries that you installed using set(CMAKE_PREFIX_PATH ...)\ngo ahead and use find_package(). It is, as these users suggested, much easier.\n\n\n\nCMakeLists.txt (in root project directory)\n       cmake_minimum_required(VERSION 3.26.0)                           \n       set(CMAKE_CXX_STANDARD 17)\n       set(CMAKE_CXX_STANDARD_REQUIRED ON)\n\n       set(REBUILD_LIBS ON)                                             # choose wether to rebuild libraries during the generate phase\n\n       set(PROJECT_BINARY_DIR \"${CMAKE_SOURCE_DIR}/build\")              # root build directory\n       set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY \"${PROJECT_BINARY_DIR}\")      # static libraries\n       set(CMAKE_INSTALL_LIBDIR ${PROJECT_BINARY_DIR}/lib)\n       set(CMAKE_INSTALL_BINDIR ${PROJECT_BINARY_DIR})\n       set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${PROJECT_BINARY_DIR}\")      # shared libraries\n       set(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${PROJECT_BINARY_DIR}\")      # executables\n       set(CMAKE_PREFIX_PATH                                            # define search-paths for find_package()\n           \"${PROJECT_BINARY_DIR}/lib/cmake\"\n       )  \n\n       if(REBUILD_LIBS)\n           include(${CMAKE_SOURCE_DIR}/CMakeFiles/BuildLibraries.txt)   # Build external libraries using the BuildLibraries.txt CMakeLists.txt file\n       endif()\n\n\n       project(myProject)     \n       add_executable(main main.cpp) \n\n       find_package (yaml-cpp)\n\n       target_link_libraries(main yaml-cpp)  \n\n"
},
{
"QuestionId": "76384877",
"QuestionTitle": "Rshiny-Use slider values to cacluate a dataset and plot the calculated values",
"QuestionBody": "I'm fairly new to Rshiny and looking for some help to understand how to create a plot using slider values as input. The user selected slider values are displayed as a table, and used as inputs to calculate an equation. The resulting calculated values are stored in a table (if possible I'd like to be able to download the generated values as a csv file) and used to generate a simple plot. This is what I have so far:\nui <- fluidPage(titlePanel(p(\"title\", style = \"color:#3474A7\"),\n sidebarLayout(\n                sidebarPanel(\n                    sliderInput(\"Max\", \"Max:\",\n                                min = 0, max = 1000,\n                                value = 116.8, step=0.1),\n                    sliderInput(\"Rate\", \"Rate:\",\n                                min = 0, max = 5,\n                                value = 0.12, step=0.01),\n                    sliderInput(\"Inflection\", \"Inflection:\",\n                                min = 0, max = 20,\n                                value = 11.06, step=0.01),\n                    sliderInput(\"Area\", \"Area:\",\n                                min = 0, max = 10000,\n                                value = 180, step=20),\n                         p(\"Made with\", a(\"Shiny\",\n                        href = \"http://shiny.rstudio.com\"), \".\"),\n                  ),\n                  mainPanel(\n                    \n                    # Output: Table summarizing the values entered ----\n                    tableOutput(\"values\"),\n                    plotOutput(\"plot\")\n                    \n                  )\n                )\n)\n\n\n#use the slider values to estimate growth for any given year using the equation\nGrowth = function(x, A, B, C, R) \n{R *(A *exp(-B * C^x))} \n\n\n#create a Table Ouptut with selected Slider values \nserver <- function(input, output){ \n  \n  # Reactive expression to create data frame of all input values ----\n  \n  sliderValues <- reactive({\n    data.frame(\n      Name = c(\"Max\",\n               \"Inflection\",\n               \"Rate\",\n               \"Area\"),\n      Value = as.character(c(input$Max,\n                             input$Inflection,\n                             input$Rate,\n                             input$Area)),\n      stringsAsFactors = FALSE)\n  })\n  \n# Show the values in an HTML table ----\n  output$values <- renderTable({\n    sliderValues()\n  })\n    \n#reactive expression to let users download the data as a table \n##restC <- reactive({\n  #run the code for all time with the selected parameters from the slider\n  mylist<-list(c(1:50))\n  mydata<-data.frame(lapply(mylist, Growth, A=values$Max, B=values$Rate, C=values$Inflection, R=values$Area),mylist)\n  names(mydata)[1]<-\"Pop\"\n  names(mydata)[2]<-\"Time\"\n  \n #output$my_table<-renderDataTable({\n   #restC() \n# })\n#plot the values in a graph\n output$plot <- renderPlot({\n  ggplot(mydata, aes(Time,Pop)) + geom_line()\n})\n\n }\n\nshinyApp(ui = ui, server = server)\n\n",
"AnswerId": "76386661",
"AnswerBody": "Made some tweakings in your code; now it does what you want:\nlibrary(shiny)\nlibrary(ggplot2)\n\nui <- fluidPage(titlePanel(p(\"title\", style = \"color:#3474A7\")),\n                           sidebarLayout(\n                             sidebarPanel(\n                               sliderInput(\"Max\", \"Max:\",\n                                           min = 0, max = 1000,\n                                           value = 116.8, step=0.1),\n                               sliderInput(\"Rate\", \"Rate:\",\n                                           min = 0, max = 5,\n                                           value = 0.12, step=0.01),\n                               sliderInput(\"Inflection\", \"Inflection:\",\n                                           min = 0, max = 20,\n                                           value = 11.06, step=0.01),\n                               sliderInput(\"Area\", \"Area:\",\n                                           min = 0, max = 10000,\n                                           value = 180, step=20),\n                               downloadButton(\"download\", \"Download data\"),\n                               p(\"Made with\", a(\"Shiny\",\n                                                href = \"http://shiny.rstudio.com\"), \".\"),\n                             ),\n                             mainPanel(\n                               \n                               # Output: Table summarizing the values entered ----\n                               tableOutput(\"values\"),\n                               plotOutput(\"plot\")\n                               \n                             )\n                           )\n)\n\n#use the slider values to estimate growth for any given year using the equation\nGrowth = function(x, A, B, C, R) \n{R *(A *exp(-B * C^x))} \n\n#create a Table Ouptut with selected Slider values \nserver <- function(input, output){ \n  \n  # Reactive expression to create data frame of all input values ----\n  \n  sliderValues <- reactive({\n    data.frame(\n      Name = c(\"Max\",\n               \"Inflection\",\n               \"Rate\",\n               \"Area\"),\n      Value = as.character(c(input$Max,\n                             input$Inflection,\n                             input$Rate,\n                             input$Area)),\n      stringsAsFactors = FALSE)\n  })\n  \n  # Show the values in an HTML table ----\n  output$values <- renderTable({\n    sliderValues()\n  })\n  \n  #reactive expression to let users download the data as a table \n  restC <- reactive({\n  #run the code for all time with the selected parameters from the slider\n  mylist<-list(c(1:50))\n  mydata<-data.frame(lapply(mylist, Growth, A=input$Max, B=input$Rate, C=input$Inflection, R=input$Area),mylist)\n  names(mydata)[1]<-\"Pop\"\n  names(mydata)[2]<-\"Time\"\n  mydata\n  })\n  #output$my_table<-renderDataTable({\n  #restC() \n  # })\n  #plot the values in a graph\n  output$plot <- renderPlot({\n    ggplot(restC(), aes(Time,Pop)) + geom_line()\n  })\n  \n  output$download <- downloadHandler(\n    filename = function() {\n      paste(\"data-\", Sys.Date(), \".csv\", sep=\"\")\n    },\n    content = function(file) {\n      write.csv(restC(), file)\n    }\n  )\n  \n}\n\nshinyApp(ui = ui, server = server)\n\n\n"
},
{
"QuestionId": "76382956",
"QuestionTitle": "React - integrate custom Bootstrap theme",
"QuestionBody": "I've been trying for couple days to integrate a poor Bootstrap theme template in a React app with no success.\nSo, I've created a new application in my folder. All good. Installed all the packages required by the theme and upgraded to the latest version. All good.\n\nNow, let's customize the App.js component in React with some custom code:\nfunction App() {\n  return (\n    <div className=\"App\">\n      <section className=\"slice slice-lg delimiter-top delimiter-bottom\">\n        <div className=\"container\">\n          <div className=\"row mb-6 justify-content-center text-center\">\n            <div className=\"col-lg-8 col-md-10\">\n              <span className=\"badge badge-primary badge-pill\">\n                What we do\n              </span>\n              <h3 className=\"mt-4\">Leading digital agency for <span className=\"text-warning typed\" id=\"type-example-1\" data-type-this=\"business, modern, dedicated\"></span> solutions</h3>\n            </div>\n          </div>\n          <div className=\"row row-grid\">\n            <div className=\"col-md-4\">\n              <div className=\"pb-4\">\n                <div className=\"icon\">\n                  <img alt=\"Image placeholder\" src=\"../../assets/img/svg/icons/Apps.svg\" className=\"svg-inject img-fluid\" />\n                </div>\n              </div>\n              <h5>Designed for developers</h5>\n              <p className=\"text-muted mb-0\">Quick contains components and pages that are built to be customized and used in any combination.</p>\n            </div>\n            <div className=\"col-md-4\">\n              <div className=\"pb-4\">\n                <div className=\"icon\">\n                  <img alt=\"Image placeholder\" src=\"../../assets/img/svg/icons/Ballance.svg\" className=\"svg-inject img-fluid\" />\n                </div>\n              </div>\n              <h5>Responsive and scalable</h5>\n              <p className=\"text-muted mb-0\">Scalable and easy to maintain, Quick enables consistency while developing new features and pages.</p>\n            </div>\n            <div className=\"col-md-4\">\n              <div className=\"pb-4\">\n                <div className=\"icon\">\n                  <img alt=\"Image placeholder\" src=\"../../assets/img/svg/icons/Book.svg\" className=\"svg-inject img-fluid\" />\n                </div>\n              </div>\n              <h5 className=\"\">Very well documented</h5>\n              <p className=\"text-muted mb-0\">No matter you are a developer or new to web design, you will find our theme very easy to customize with an intuitive code.</p>\n            </div>\n          </div>\n        </div>\n      </section>\n    </div>\n  );\n}\n\nexport default App;\n\nNow, let's import everything we need from the custom theme in index.js:\n...\n\nimport './assets/css/quick-website.css';\nimport './assets/js/quick-website.js';\nimport './assets/libs/@fortawesome/fontawesome-free/css/all.min.css';\nimport './assets/libs/jquery/dist/jquery.min.js';\n\n...\n\nHowever, when I import the core JS (quick-website.js) file of the time, I get this types of errors:\n\nFrom quick-website.js\n\n\n\nFrom 'jquery.min.js`\n\n\nWhat am I missing here?\n",
"AnswerId": "76384761",
"AnswerBody": "Rather than importing jquery.min.js from assets, you should use npm to install the jquery package and then import relevant modules in the files where you need them. This is a more \"react\" way of doing things and it's much easier to update dependencies from the command line.\n\nRun npm install jquery from the command line\nNow, just import modules where you need them (in this case, quick-website.js):\n\nimport $ from 'jquery'\n\nIn general, if you see the error 'Something' is not defined, checking if you have imported the module is a good place to start.\n"
},
{
"QuestionId": "76383351",
"QuestionTitle": "Google.Apis.Oauth2.v2 + UWP: Access to path c:\\users is denied",
"QuestionBody": "After updating Google.Apis.Oauth2.v2 NuGet package to v. 1.60.0.1869, I start getting exception Access to the path C:\\Users is denied when trying login with Google in my UWP app. Here's my code:\nstring fname = @\"Assets\\User\\Auth\\google_client_secrets.json\";\nStorageFolder InstallationFolder = Windows.ApplicationModel.Package.Current.InstalledLocation;\nvar stream = await InstallationFolder.OpenStreamForReadAsync(fname);\ncredential = await GoogleWebAuthorizationBroker.AuthorizeAsync(\n    stream,\n    new[] { \"profile\", \"email\" },\n    \"me\",\n    CancellationToken.None);\n\nThe exception occurs in GoogleWebAuthorizationBroker.AuthorizeAsync call.\nThis code (with some light changes) worked well before with Google.Apis.Oauth2.v2 package v. 1.25.0.859, but now this package is obsolete and doesn't work anymore.\nHow to login with Google in my UWP app?\nNOTE: I understand that UWP app doesn't have access to c:\\Users, but my code never request anything in the folder. google_client_secrets.json exists and I can read it in the app from the stream, so this file is unrelated to the issue.\nUPDATE\nAfter I set the 5th parameter of AuthorizeAsync like this:\ncredential = await GoogleWebAuthorizationBroker.AuthorizeAsync(\n    stream,\n    new[] { \"profile\", \"email\" },\n    \"me\",\n    CancellationToken.None\n    new FileDataStore(ApplicationData.Current.LocalCacheFolder.Path, true));\n\nthe exception is gone. Now the execution thread just dies inside the AuthorizeAsync and I start getting the following error popup:\n\n",
"AnswerId": "76384817",
"AnswerBody": "After some tried, I failed to make Google.Apis.Oauth2.v2 NuGet package v. 1.60.0.1869 to work with UWP. I made Google Login works by removing the NuGet and implementing OAuth flow myself as described in my answer here.\n"
},
{
"QuestionId": "76387092",
"QuestionTitle": "What is the cause of the deadlock in my Go code using WaitGroups and Buffered Channels?",
"QuestionBody": "WaitGroups, Buffered Channels, and Deadlocks\nI have this bit of code which results in a deadlock and I'm not certain why. I have tried using mutex locking in a few different places, closing channels in and outside of separate go routines, but the result is still the same.\nI'm trying to send data through one channel (inputChan), and then read it from another (outputChan)\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc listStuff(wg *sync.WaitGroup, workerID int, inputChan chan int, outputChan chan int) {\n    defer wg.Done()\n\n    for i := range inputChan {\n        fmt.Println(\"sending \", i)\n        outputChan <- i\n    }\n}\n\nfunc List(workers int) ([]int, error) {\n    _output := make([]int, 0)\n\n    inputChan := make(chan int, 1000)\n    outputChan := make(chan int, 1000)\n\n    var wg sync.WaitGroup\n    wg.Add(workers)\n\n    fmt.Printf(\"+++ Spinning up %v workers\\n\", workers)\n    for i := 0; i < workers; i++ {\n        go listStuff(&wg, i, inputChan, outputChan)\n    }\n\n    for i := 0; i < 3000; i++ {\n        inputChan <- i\n    }\n\n    done := make(chan struct{})\n    go func() {\n        close(done)\n        close(inputChan)\n        close(outputChan)\n        wg.Wait()\n    }()\n\n    for o := range outputChan {\n        fmt.Println(\"reading from channel...\")\n        _output = append(_output, o)\n    }\n\n    <-done\n    fmt.Printf(\"+++ output len: %v\\n\", len(_output))\n    return _output, nil\n}\n\nfunc main() {\n    List(5)\n}\n\n",
"AnswerId": "76387227",
"AnswerBody": "The code in your main function is sequential and first tries to write 3k values into inputChan then will read values from outputChan.\nYour code blocks on the first of those steps:\n\nnothing drains from outputChan before 3k values are succesfully sent to inputChan, so the workers end up stuck on outputChan <- i after the first 1k  value\nonce the workers stop draining from inputChan, main will get stuck on inputChan <- i after ~2k values\n\n\nOne way to fix this can be to have the producer (inputChan <- i) and the end consumer (for o := range outputChan {) run in separate goroutines.\nYou can keep one of these actors in the main goroutine, and spin a new one for the other. For example :\ngo func(inputChan chan<- int){\n    for i := 0; i < 3000; i++ {\n        inputChan <- i\n    }\n    close(inputChan)\n}(inputChan)\n\ndone := make(chan struct{})\ngo func() {\n    close(done)\n    // close(inputChan) // I chose to close inputChan above, don't close it twice\n    close(outputChan)\n    wg.Wait()\n}()\n\n...\n\nhttps://go.dev/play/p/doBgfkAbyaO\none extra note: the order of actions around signaling done is important ; channels done and outputChan should only be closed after wg.Done() indicates that all workers are finished\n    // it is best to close inputChan next to the code that controls\n    // when its input is complete.\n    close(inputChan)\n    // If you had several producers writing to the same channel, you\n    // would probably have to add a separate waitgroup to handle closing,\n    // much like you did for your workers\n\n    go func() {\n        wg.Wait()\n        // the two following actions must happen *after* workers have\n        // completed\n        close(done)\n        close(outputChan)\n    }()\n\n"
},
{
"QuestionId": "76387085",
"QuestionTitle": "mat-select panel still shows overlapped like version 14 and below even after upgrade to angular material 15",
"QuestionBody": "we have used mat-select in our project, the panel shows overlapping on the trigger text like version 14 and before (material version 12 was used in our project)\n\nafter finding few hacks, the panel showed below the trigger text, but it was not consistent with different screen sizes, specially the mobile view.\nWe found that from material version 15, the select panel showed below the trigger text - \nso we upgraded to material version 15, and also upgraded the angular version to 15. But even after the upgrade the mat-select is still showing in the previous style.\nCan someone please suggest what could be going wrong here and what needs to be done to get working like material version 15 mat-select\n",
"AnswerId": "76387252",
"AnswerBody": "Based on the comments, you have only updated to Angular material 15, but is running in legacy mode.\nTo fully migrate you need to run.\nschematic: ng generate @angular/material:mdc-migration\nhowever due to class name changes to the mdc- prefix etc and structual changes in some of the componets. you should follow their migration guide.\nhttps://rc.material.angular.io/guide/mdc-migration\n"
},
{
"QuestionId": "76383522",
"QuestionTitle": "ASP.NET Core 7.0 container: Failed to create CoreCLR, HRESULT: 0x8007000E",
"QuestionBody": "That's a result when I receive after trying to run ASP.NET Core 7.0 runtime image in Amazon ECS container (AWS Fargate service).\nMy project in on ASP.NET Core 7.0 Web API.\nHere is a docker file for image which built on Jenkins and sent to Amazon ECS\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:7.0 AS build\nWORKDIR /src\nCOPY [\"src/MetaGame/MyMetaGame.API/MyMetaGame.API.csproj\", \"src/MetaGame/MyMetaGame.API/\"]\nRUN dotnet restore \"src/MetaGame/MyMetaGame.API/MyMetaGame.API.csproj\"\nCOPY . .\nWORKDIR \"/src/src/MetaGame/MyMetaGame.API\"\nRUN dotnet build \"MyMetaGame.API.csproj\" -c Release -o /app/build\n\nFROM build AS publish\nRUN dotnet publish \"MyMetaGame.API.csproj\" -c Release -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"MyMetaGame.API.dll\"] \n\nAfter some googling I've found a decision to increase GC Heap limit by environment parameter. I set it to 512Mb\nDOTNET_GCHeapHardLimit=20000000\n\nBut it hasn't fixed my problem.\nNo idea what's the problem\nHere is the configuration of csproj file\n<PropertyGroup>\n    <TargetFramework>net7.0</TargetFramework>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <DockerDefaultTargetOS>Linux</DockerDefaultTargetOS>\n</PropertyGroup>\n\n",
"AnswerId": "76384890",
"AnswerBody": "So, the problem is fixed by adding\nENV COMPlus_EnableDiagnostics=0\n\nin the final stage of Dockerfile.\nSo, it should looks like\nFROM base AS final\nENV COMPlus_EnableDiagnostics=0\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"MyMetaGame.API.dll\"]\n\nFound the solution here\n"
},
{
"QuestionId": "76384192",
"QuestionTitle": "How to make sure that my virtual machine does not change its IP address when connecting to different networks?",
"QuestionBody": "I have two virtual machines. First has apache server, and wordpress on virtualhost. Second has mysql server for my wordpress in first vm. Mysql configuration use ip adress of first vm. But when i leave my home and in result leave my home wi-fi, ip adress of first vm is changing when i connect to internet from my phone and my web-site crashes.\n",
"AnswerId": "76386662",
"AnswerBody": "It is said that by default IP addresses are assigned dynamically, so the IP changes if you are in different network (that is, when you access the Internet through mobile data instead of home wifi). You may assign static IP address to your VM. This is done from inside of your VM.\n"
},
{
"QuestionId": "76384852",
"QuestionTitle": "How can I change the size of the text in TextComponent using Flutter Flame?",
"QuestionBody": "How do you change the size of the text in the TextComponent in Flame?  I want to make the text larger\nI used the Flame documentation to get this, but I don't know how to modify it for a larger text size (like 20pt vs 14pt).  Also, what is the anchor?\nfinal style = TextStyle(color: BasicPalette.darkBlue.color);\nfinal regular = TextPaint(style: style);\n\nTextComponent startText = TextComponent(text: 'test text', textRenderer: regular)\n  ..anchor = Anchor.topCenter\n  ..x = (width * 0.2)\n  ..y = (height - (height*0.5))\n  ..priority = 300;\n\n",
"AnswerId": "76386672",
"AnswerBody": "final style = TextStyle(\n  color: BasicPalette.darkBlue.color,\n  fontSize: 20.0, // Change the font size here\n);\nfinal regular = TextPaint(style: style);\n\nTextComponent startText = TextComponent(\n  text: 'test text',\n  textRenderer: regular,\n)\n  ..anchor = Anchor.topCenter\n  ..x = (width * 0.2)\n  ..y = (height - (height * 0.5))\n  ..priority = 300;\n\nWhat's anchor?\nThe anchor in Flame's TextComponent determines where the text is positioned relative to its given coordinates (x and y). You can choose from options like top-left, top-center, top-right, center-left, center, center-right, bottom-left, bottom-center, and bottom-right to align the text as you want. Adjust the anchor and position values to position the text as needed.\n"
},
{
"QuestionId": "76384267",
"QuestionTitle": "How to clear cache for a route with the 'apicache' package",
"QuestionBody": "I'm using NPM install API cache for my MERN application. I want one of my requests to be cached and then when a request is made to another route it refreshes the cache (it fetches the new data). I've managed to get one of my requests to be cached but I can't manage to clear it.\nThis is my code\nconst apicache = require(\"apicache\")\n\nlet cache = apicache.middleware\n\napp.get(\"/api/users/checkJWT\",cache(\"2 minutes\"), async (req,res) => {\n  const token = req.headers.authorization?.split(\" \")[1]\n\n  const decoded = jwt.verify(token,SECRET_KEY)\n\n  if(decoded != null && await User.findById(decoded.id) != null) {\n    return res.status(200).json({valid: true, user: await User.findById(decoded.id)})\n  }\n  else {\n    return res.status(400).json({valid: false})\n  }\n})\n\napp.patch(\"/api/users/user\",authenticateJWTUser, async (req, res) => {\n  apicache.clear('/api/users/checkJWT')\n  const user = await User.findOne({ name: req.body.username });\n  if (req.body.name != null) {\n    user.name = req.body.name;\n  }\n  if (req.body.email != null) {\n    user.email = req.body.email;\n  }\n  if (req.body.password != null) {\n    user.password = await bcrypt.hash(req.body.password, 10);\n  }\n  if (req.body.tasks != null) {\n    user.tasks = req.body.tasks;\n  }\n  try {\n    const updatedUser = await user.save();\n    res.json(updatedUser);\n  } catch (error) {\n    res.status(400).json({ message: error.message });\n  }\n});\n\nLink to my Git repo: https://github.com/JesseOgunlaja/Task-Tracker-MERN/tree/ae1b0027bfa40f90ab7a3d6208c05a9eb41a4478\n",
"AnswerId": "76386693",
"AnswerBody": "I was able to get this work using the apicache-plus package.\nconst apicache = require(\"apicache-plus\");\n\nrouter.get(\n  \"/api/users/getName/1\",\n  apicache.middleware(\"10 minutes\"),\n  async (req, res, next) => {\n    req.apicacheGroup = \"toClear\";\n    const someData = { someName: \"Amy\" };\n    res.json(someData);\n  }\n);\n\nrouter.get(\"/api/users/user/1/2\", async (req, res, next) => {\n  console.log(\"something\");\n  apicache.clear(\"toClear\");\n\n  const user = { name: \"Jeff\" };\n  res.json(user);\n});\n\n"
},
{
"QuestionId": "76387202",
"QuestionTitle": "Razor page redirect to another folder page",
"QuestionBody": "I'm facing an issue with razor page navigation. I'm in the https://localhost:7154/Application/setupAccount page and i have to redirect to https://localhost:7154/Loan/setupLoan page.\nSo I used RedirectToPage(\"setupLoan\", new{id=123}. but the issue is that it's looking like a setupLoan page inside the Application folder. ( URL - https://localhost:7154/Application/setupLoan )\nThen I'm getting an error like page not found\nI can use redirect functionality. But the thing is, I can't send dynamic query parameters.\nSo let me know if anyone know a correct path to navigate razor page into another folder\n",
"AnswerId": "76387264",
"AnswerBody": "Try:\n   return RedirectToPage(\"setupLoan\", new { area = \"Application\",id=1 }); \n\nresult:\n\nYou can read Areas with Razor Pages to know more.\nUpdate\n return RedirectToPage(\"setupLoan\", new { area = \"Loan\",id=1 }); \n\nUpdate 2\nLoan is a page folder. not area folder ,\ntry:\n  return RedirectToPage(\"/Loan/setupLoan\", new { id = 1 });\n\n"
},
{
"QuestionId": "76383257",
"QuestionTitle": "Is there a way to stop old observable and set new after event in Nest Gateways?",
"QuestionBody": "I'm developing a simple message server app, using WebSockets and NestJs gateways. Server receives an event to indentify a listener with name, and then sends websocket updates to that listener.\nRight now I'm using subject/observable approach, server after listen-as event returns a new observable, which filters all upcoming messages:\nexport class ListenAsDto {\n  name: string;\n}\n\nexport interface PersonalisedMessage {\n  from: string;\n  title: string;\n  content: string;\n}\n\nexport class MessagesService {\n  // ...\n  listenAs(listener: ListenAsDto): Observable<WsResponse<PersonalisedMessage>> {\n    return this.messageObservable.pipe(\n      filter((item) => item.to === listener.name),\n      map((item) => {\n        const copy = { ...item };\n        delete copy.to;\n        return { event: INBOX_MESSAGE_NAME, data: copy };\n      }),\n    );\n  }\n}\n\nBut this only works for the first time, after another request client now receives both updates from 2 users at the time.\nIs there a way to stop previous observable for current user an start new?\nEDIT: I'm using ws platform\n",
"AnswerId": "76384992",
"AnswerBody": "Found a solution by using a native WebSocket instance. It passes the same object if request was made by same client. So, using a WeakMap, we can manually track all subscriptions objects, and unsubscribe them, if we get the same WebSocket client\nexport class MessagesService {\n  private subs = new WeakMap<WebSocket, Subscription>();\n\n  listenAs(ip: WebSocket, dto: ListenAsDto) {\n    if (this.subs.has(ip)) this.subs.get(ip).unsubscribe();\n    // 'createObservable' is basically question`s 'listenAs' function\n    const obs = this.createObservable(dto);\n    this.subs.set(\n      ip,\n      obs.subscribe({\n        next(value) {\n          ip.send(JSON.stringify(value));\n        },\n      }),\n    );\n\n    return dto;\n  }\n}\n\n"
},
{
"QuestionId": "76385199",
"QuestionTitle": "How to start Jupyter Notebook on a GCP VM with predefined token automatically on VM start?",
"QuestionBody": "OK I have set up jupyter notebook on a gcp VM, I want it to start automatically every time VM is started with a predefined token. (OS in Centos)\nDoes any one have any idea how to solve this final issue so that we can get the jupyter notebook started under the user test1 , everytime the VM starts ?\nHere is what I have done so far\n\nCreated a local test1 user and created a Virtual env for it, installed jupyter notebook inside the virtual env for isolation of python\n\npyton3 -m venv tvenv\nsource tvenv\\bin\\activate\npip install jupyter\n\n\nUnderstood that I would need to generate config and update token / ip / port etc inside the config becuase dynamically generated token cannot be used\n\njupyter notebook --generate-config \n\n\nmodified NotebookApp.token/NotebookApp.port/NotebookApp.ip etc attributes to get that to work.\nbased on an existing question created a shell script to be added to the start up to the gcp VM\n\nsudo -u test1 bash -c 'cd ~/; nohup tvenv/bin/jupyter-notebook &'\n\nWhen i run the command manually from root it works when I update in GCP startup it constantly fails saying\nAccount or password is expired, reset your password and try again\n\nNote : Helpful debugging tip. You can get the startup script logs by running below command once inside the VM\nsudo journalctl -u google-startup-scripts.service\n\n",
"AnswerId": "76386831",
"AnswerBody": "As John has already pointed out to you in the comment, sudo is not a good option, since the Startup scripts run as root, su can be used to switch to another profile.\nFew other things that you should be aware of is that as you are using virtual enviornment, you have to set up similar enviornment variables as 'activate'\ndoes.\none possible solution that you can try is below\n su -c 'PATH=\"/home/test1/tvenv/bin:$PATH\";export PATH; cd ~/; nohup tvenv/bin/jupyter-notebook &' -s /bin/sh test1\n\nWhat it does is sets the path to the virtual enviornment ( activity that is done via the activate among other tasks ) moves to home directory of the user and runs the notebook in background with test1 user profile.\nI would also suggest that you use shutdown script in the gcp vm to shutdown notebook gracefully, make sure that you replace the port with the port that you are using in your config\njupyter notebook stop 8888\n\nSimilar to start up you can check the shutdown logs by using the command below\nsudo journalctl -u google-shutdown-scripts.service\n\nLet me know if you still face any issues.\n"
},
{
"QuestionId": "76383937",
"QuestionTitle": "How do I remove deleted Python environments in PyCharm?",
"QuestionBody": "When I'm creating a new project in PyCharm, I can see some environments I created for old projects that have been deleted:\n\nbut I can't find a way to delete these entries. Where are they? How do I delete them?\nI tried going to \"Python Interpreters\" following https://www.jetbrains.com/help/pycharm/configuring-python-interpreter.html#removing_interpreter but they are just not there:\n\n\n",
"AnswerId": "76388079",
"AnswerBody": "The Interpreters list from the New Project dialogue has a different entry point from the project specific list. Go to File > New Projects Setup > Settings for New Projects (instead of going to File > Settings as usual):\n\nGoing through the other entry point you can already notice the Python Interpreter item in the sidebar is slightly different visually from if you had gone the other route. From there on the renaming dialogues are the same as usual but the lists are different. Continue to Python Interpreter > Show All... at the bottom of the drop down list:\n\n"
},
{
"QuestionId": "76387278",
"QuestionTitle": "How to remove 3 dots after end of line limit",
"QuestionBody": "In SwiftUI,\nText(\"a \\n b \\n c \\n d \\n e\")\n     .lineLimit(3)\n\nIn SwiftUI, the above code shows output including 3 dots in the end.\nOutput:\na\nb\nc...\n\nBut my target is to show the output without dots like this -\nTarget:\na\nb\nc\n\n",
"AnswerId": "76387294",
"AnswerBody": "implement the following way.\nText(\"1\\n 2 \\n 3 \\n 4 \\n 5\".truncateToLineLimit(3))\n\nextension String {\n    func truncateToLineLimit(_ lineLimit: Int) -> String {\n        var truncatedString = \"\"\n        let lines = self.components(separatedBy: \"\\n\").prefix(lineLimit)\n        for line in lines {\n            truncatedString += line.trimmingCharacters(in: .whitespacesAndNewlines)\n            if line != lines.last {\n                truncatedString += \"\\n\"\n            }\n        }\n        return truncatedString\n    }\n}\n\n\n"
},
{
"QuestionId": "76382914",
"QuestionTitle": "How to remove gap between a frame and its scrollbar?",
"QuestionBody": "I have three frames; left_frame, middle_frame and right_frame. I would like to have no gap between left_frame and its scrollbar. How can I achieve it?\nimport tkinter as tk\nfrom tkinter import ttk\n\ndef create_dummy_chart(frame, index):\n    # Create a dummy chart\n    label = tk.Label(frame, text=f\"Chart {index}\", width=10, height=2, relief=\"solid\")\n    label.pack(side=\"top\", pady=5)\n\n# Create the main window\nwindow = tk.Tk()\nwindow.title(\"Chart Display\")\nwindow.geometry(\"800x300\")\n\n# Create the left frame\nleft_frame = tk.Frame(window, width=200, height=300, relief=\"solid\", bd=1)\nleft_frame.pack(side=\"left\", fill=\"y\")\n\n# Create a canvas to hold the left_frame and the scrollbar\ncanvas = tk.Canvas(left_frame, width=200, height=300)\ncanvas.pack(side=\"left\", fill=\"y\")\n\n# Create the scrollbar\nscrollbar = ttk.Scrollbar(left_frame, orient=\"vertical\", command=canvas.yview)\nscrollbar.pack(side=\"right\", fill=\"y\")\n\n# Configure the canvas to use the scrollbar\ncanvas.configure(yscrollcommand=scrollbar.set)\ncanvas.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n\n# Create a frame inside the canvas to hold the charts\nchart_frame = tk.Frame(canvas)\n\n# Add the frame to the canvas\ncanvas.create_window((0, 0), window=chart_frame, anchor=\"nw\")\n\n# Create dummy charts in the chart_frame\nnum_charts = 200\nfor i in range(num_charts):\n    create_dummy_chart(chart_frame, i)\n\n# Update the canvas scrollable area\nchart_frame.update_idletasks()\ncanvas.configure(scrollregion=canvas.bbox(\"all\"))\n\n# Create the middle frame\nmiddle_frame = tk.Frame(window, width=200, height=300, relief=\"solid\", bd=1)\nmiddle_frame.pack(side=\"left\", fill=\"y\")\n\n# Create the right frame\nright_frame = tk.Frame(window, width=400, height=300, relief=\"solid\", bd=1)\nright_frame.pack(side=\"left\", fill=\"both\", expand=True)\n\n# Run the Tkinter event loop\nwindow.mainloop()\n\n\nI have left_frame and vertical scrollabr. But, I ended up having a gap between them. I expect to have no gap between them. How can I achieve this?\nWhat I have:\n\nWhat I expect:\n\n",
"AnswerId": "76385022",
"AnswerBody": "If you're referring to the one or two pixel space between the canvas and the scrollbar, you can set the highlightthickness attribute of the canvas to zero, or you can set the highlightcolor to the same color as the background of the canvas so that the highlight ring is not visible when the canvas has the keyboard focus.\nYou might also need to explicitly set the padx value to zero when packing the canvas and scrollbar. On some platforms it might default to 1.\nIf you're referring to the fact that the canvas is wider than the items in the canvas, then you can set up a binding to set the width of the canvas to always match the width of the items on the canvas.\nYou can do that like this:\nchart_frame.bind(\"<Configure>\", lambda event: canvas.configure(width=chart_frame.winfo_width()))\n\n"
},
{
"QuestionId": "76385290",
"QuestionTitle": "What is the point of the ILoggingBuilder interface in ASP.NET Core?",
"QuestionBody": "I looked inside the the built in WebApplicationBuilder class and noticed the\npublic ILoggingBuilder Logging { get; }\n\nproperty. Here is the entire ILoggingBuilder interface:\npublic interface ILoggingBuilder\n{\n    IServiceCollection Services { get; }\n}\n\nIt just stores a single property so what is the point of this interface? Couldn't the WebApplicationBuilder just store an instance of IServiceCollection directly?\n",
"AnswerId": "76388158",
"AnswerBody": "It's about scoping and reducing intellisense hell. If everything was on IServiceCollection it would get cluttered quickly. Subsystems that are highly configurable and are themselves extensible need a \"target\" to extend. This is one of the patterns the platform employs to solve this problem.\nSome of the patterns you'll see:\nSimple options via a callback:\nservices.AddComponent((ComponentOptions options) => \n{\n    options.SomeFlag = true;\n});\n\nThis pattern works well when the number of options on component is small, self-contained and has limited extensibility.\nComplex builder returned from the API:\nIComponentBuilder builder = services.AddComponent();\n\nbuilder.AddExtensibleThing1();\nbuilder.AddExtensibleThing2();\n\nBreaks the fluent API pattern but reduces nested lambdas.\nOR\nservices.AddComponent((IComponentBuilder builder) =>\n{\n    builder.AddExtensibleThing1();\n    builder.AddExtensibleThing2();\n});\n\nSimilar to the above but nested instead of a return value. Keeps the fluent API working at the cost of more callbacks.\n"
},
{
"QuestionId": "76387293",
"QuestionTitle": "How to seach text not translate in VSCode?",
"QuestionBody": "I'm added i18next React for old project. So many text not can be translate. How can I search all of them in VSCode?\nSome case:\n<Button className=\"w-full\" onClick={onClick}>\n  Save\n<Button>\n\n<Button\n  type=\"primary\"\n  onClick={onCLick}\n  className=\"ml-2\"\n>\n  Save\n</Button>\n\n<Button>Save</Button>\n\n<ContentWrapper title=\"Connection\" headerAction={<Button size=\"small\">Add</Button>}>\n  <div>{`Connection`}</div>\n</ContentWrapper>\n\n<p className=\"mt-2 text-center\">\n  Drag and drop files here or <span className=\"text-blue-500\">{t('browse')}</span>\n</p>\n\n<div>\n  {mediaRecorder?.state === 'recording' ? (\n    <Button onClick={handleStop}>{t('Stop')}</Button>\n  ) : (\n    <Button onClick={handleStart}>Start</Button>\n  )}\n</div>\n\nTranslated:\n<Button>{t('Save')}</Button>\n\n<ContentWrapper title=\"Connection\" headerAction={<Button size=\"small\">{t('Add')}</Button>}>\n      <div>{t('Connection')}</div>\n    </ContentWrapper>\n\n",
"AnswerId": "76387324",
"AnswerBody": "Find:\n(<Button[\\s\\S\\n]*?>[\\n\\s]*)(\\w+)([\\n\\s]*</Button>)\n\nReplace:\n$1{t('$2')}$3\n\n"
},
{
"QuestionId": "76384368",
"QuestionTitle": "Bokeh plot is missing in layout when checkbox group is used",
"QuestionBody": "Bokeh scatter plot disappears when checkbox is added to layout.\nIf I exclude layout = row([checkbox_group, p]) and do show(p), I get the intended scatter plot with the color bar.\nBut when I include layout = row([checkbox_group, p]) and do show(layout), the scatter plot disappears whereas the checkbox and color bar appear.\nimport pandas as pd\nimport numpy as np\nfrom bokeh.plotting import figure, show, curdoc\nfrom bokeh.models import ColumnDataSource, ColorBar, HoverTool, CustomJS\nfrom bokeh.models.widgets import CheckboxGroup\nfrom bokeh.transform import linear_cmap\nfrom bokeh.palettes import Iridescent18\nfrom bokeh.models.mappers import LinearColorMapper\nfrom bokeh.layouts import row\n\ngene_list = ['A', 'B', 'C']\nfile_paths = [r\"home/File1.feather\", r\"home/File2.feather\"]\ncheckbox_group = CheckboxGroup(labels=['File 1', 'File 2'], active = [0])\n\ndef checkbox_change(attr, old, new):\n    if new:\n        selected_file_index = new[0] \n        if selected_file_index >= len(file_paths):\n            print(\"Selected file index is out of range.\")\n            return\n        selected_file_path = file_paths[selected_file_index]\n        df = pd.read_feather(selected_file_path, columns=gene_list + ['umap1', 'umap2', 'index'])\n        df = df.replace({'index' : 'cell_type'})\n\n        median_score = []\n        for idx, r in df.iterrows():\n            score = np.sum(r[gene_list])\n            median_score.append(score)\n        df['score'] = median_score\n\n        source.data = df.to_dict(orient='list')\n\n    checkbox_group.on_change('active', checkbox_change)\n\n# Create the initial plot\ndf = pd.read_feather(file_paths[0], columns=gene_list + ['umap1', 'umap2', 'index'])\n\nmedian_score = []\nfor idx, r in df.iterrows():\n    score = np.sum(r[gene_list])\n    median_score.append(score)\ndf['score'] = median_score\n\nsource = ColumnDataSource(df)\n\nmapper = linear_cmap(\n    field_name='score', palette=Iridescent18, low=df['score'].min(), high=df['score'].max()\n)\n\np = figure(\n    title='UMAP Visualization',\n    x_axis_label='umap1',\n    y_axis_label='umap2',\n    sizing_mode='stretch_width',\n    height=1500,\n    toolbar_location='above'\n)\nhover = HoverTool(tooltips=[('Cell Name', '@index')], mode='mouse')\np.add_tools(hover)\n\np.scatter(\"umap1\", \"umap2\", color=mapper, source=source)\n\ncolor_mapper = LinearColorMapper(\n    palette=Iridescent18, low=df['score'].min(), high=df['score'].max()\n)\ncolor_bar = ColorBar(\n    color_mapper=color_mapper, label_standoff=12, location=(0, 0), title='Score'\n)\np.add_layout(color_bar, 'right')\n\nlayout = row([checkbox_group, p])\n\nshow(layout) #show(p)\n\n",
"AnswerId": "76388195",
"AnswerBody": "Your problem comes from the selected sizing_modes in the figure and the row function calls.\nYour are setting the sizing_mode of the figure to stretch_width and you are using the default sizing_mode of the row-layout which is fixed. This leads to a behavoir where the figure is shrunk to a minimal width of 0.\nTo fix this, you can\n\nset the sizing_mode of the row to stretch_width or\nset the figure to a fixed width\n\nMinimal Example\nsource = ColumnDataSource(dict(A=[1,2,3], B=[1,2,3], score=[2,4,6]))\n\np = figure(sizing_mode='stretch_width')\nmapper = linear_cmap(\n    field_name='score', palette=Iridescent18, low=df['score'].min(), high=df['score'].max()\n)\np.scatter(\"A\", \"B\", color=mapper, source=source)\ncheckbox_group = CheckboxGroup(labels=['Checkbox 1', 'Checkbox 2'], active = [0])\ncolor_mapper = LinearColorMapper(palette=Iridescent18, low=1, high=3)\ncolor_bar = ColorBar(\n    color_mapper=color_mapper, label_standoff=12, location=(0, 0), title='Score'\n)\np.add_layout(color_bar, 'right')\nlayout = row([checkbox_group, p], sizing_mode='stretch_width')\nshow(layout)\n\nOutput\n\nComment\nThe output was created with bokeh 3.1.1. I am not sure if this will work for older versions.\n"
},
{
"QuestionId": "76378492",
"QuestionTitle": "How to calculate rotation matrix for an accelerometer using only basic algebraic operations",
"QuestionBody": "There is a C function that gets the acceleration values of x,y,z of an accelerometer sensor (MEMS IMU) as input, and calculates the rotation matrix in a way that the z axis is aligned with the gravity. It is being used for calibrating the accelerometer data.\n\n#define X_AXIS (0u)\n#define Y_AXIS (1u)\n#define Z_AXIS (2u)\n\nstatic float matrix[3][3];\nvoid calculate_rotation_matrix(float raw_x, float raw_y, float raw_z)\n{ \n  const float r = sqrtf(raw_x * raw_x + raw_y * raw_y + raw_z * raw_z);\n  const float x = raw_x / r;\n  const float y = raw_y / r;\n  const float z = raw_z / r;\n\n  const float x2 = x * x;\n  const float y2 = y * y;\n\n  matrix[X_AXIS][X_AXIS] = (y2 - (x2 * z)) / (x2 + y2);\n  matrix[X_AXIS][Y_AXIS] = ((-x * y) - (x * y * z)) / (x2 + y2);\n  matrix[X_AXIS][Z_AXIS] = x;\n  matrix[Y_AXIS][X_AXIS] = ((-x * y) - (x * y * z)) / (x2 + y2);\n  matrix[Y_AXIS][Y_AXIS] = (x2 - (y2 * z)) / (x2 + y2);\n  matrix[Y_AXIS][Z_AXIS] = y;\n  matrix[Z_AXIS][X_AXIS] = -x;\n  matrix[Z_AXIS][Y_AXIS] = -y;\n  matrix[Z_AXIS][Z_AXIS] = -z;\n}\n\n\n\nfloat result[3];\nvoid apply_rotation(float x, float y, float z)\n{\n  result[AXIS_X] = matrix[X_AXIS][X_AXIS] * x\n                 + matrix[X_AXIS][Y_AXIS] * y\n                 + matrix[X_AXIS][Z_AXIS] * z;\n  \n  result[AXIS_Y] = matrix[Y_AXIS][X_AXIS] * x\n                 + matrix[Y_AXIS][Y_AXIS] * y\n                 + matrix[Y_AXIS][Z_AXIS] * z;\n  \n  result[AXIS_Z] = matrix[Z_AXIS][X_AXIS] * x\n                 + matrix[Z_AXIS][Y_AXIS] * y\n                 + matrix[Z_AXIS][Z_AXIS] * z;\n\n}\n\nI'm trying to wrap my head around how it works and why there is no use of trigonometric functions here?\nis it just simplifying the trigonometric functions by normalizing the input values and using the equivalent equations to calculate the trigonometric functions?\nWhat are the limitations of this method? for example when the denominator calculated is zero, we will have division by zero. Anything else?\nTried to search on the internet and stackoverflow, but couldn't find a similar method to calculate the rotation matrix.\nUPDATE:\nJust simplified the calculations so they are more readable.\nTo add more context this code is used to rotate the readings of an accelerometer in a way that regardless of the orientation of the device, the z-axis is perpendicular to the ground.\nThe calculate_rotation_matrix() is called when we know that the object is stationary and is on a flat surface. This results in calculating the 3x3 matrix. Then the apply_rotation() is used to rotate subsequent readings.\n",
"AnswerId": "76385025",
"AnswerBody": "A quaternion representation can apply rotations without trig functions.  But this appears to be a version of: https://math.stackexchange.com/a/476311 . The math appears to be a variation thereof, where \"a\" and \"b\" are the accelerometer and gravity vectors.\nThe method also appears to assume measurements will not be perfect.  And MEMS sensors fit that description.  Otherwise, as you stated, if x and y are both zero then you have a divide by zero condition.\n"
},
{
"QuestionId": "76384085",
"QuestionTitle": "Kotlin Firebase Realtime Database correct return value for setValue() in MVVM",
"QuestionBody": "What would be the correct return value of my setMyBirthday function in the HomeRepository class for the code to work? Void doesn't seem to be the right return value.\nFragment:\nprivate fun HomeViewModel.setupObserver() {\n    myBirthday.observe(viewLifecycleOwner) { response ->\n        when(response) {\n            is Resource.Error -> {\n                response.message?.let { message ->\n                    Log.e(TAG, \"An error occurred: $message\")\n                }\n            }\n            is Resource.Loading -> {\n                binding.buttonChangeBirthday.isClickable = false\n            }\n            is Resource.Success -> {\n                binding.buttonChangeBirthday.isClickable = true\n            }\n        }\n    }\n}\n\nHomeViewModel:\nval myBirthday: MutableLiveData<Resource<Void>> = MutableLiveData()\nfun setMyBirthday(birthday: String) = viewModelScope.launch {\n    try {\n        myBirthday.postValue(Resource.Loading())\n        val response = homeRepository.setMyBirthday(birthday)\n        myBirthday.postValue(Resource.Success(response))\n    } catch (e: Exception) {\n        myBirthday.postValue(Resource.Error(e.message!!))\n    }\n}\n\nHomeRepository:\n    suspend fun setMyBirthday(birthday: String) =\n    databaseReference\n        .child(\"users\")\n        .child(myUserID)\n        .child(\"birthday\")\n        .setValue(birthday)\n        .await()\n\n",
"AnswerId": "76388372",
"AnswerBody": "\nWhat would be the correct return value of my function in the HomeRepository class for the code to work? Void doesn't seem to be the right return value.\n\nIndeed Void is the type of object the setMyBirthday function returns. So your function should look like this:\n//                                            👇\nsuspend fun setMyBirthday(birthday: String): Void =\ndatabaseReference\n    .child(\"users\")\n    .child(myUserID)\n    .child(\"birthday\")\n    .setValue(birthday)\n    .await()\n\nWhile your approach will work, it will be more convenient to return a Resource<Boolean> as in the following lines of code:\nsuspend fun setMyBirthday(birthday: String): Resource<Boolean> = try {\n    databaseReference\n        .child(\"users\")\n        .child(myUserID)\n        .child(\"birthday\")\n        .setValue(birthday)\n        .await()\n    Resource.Success(true)\n} catch (e: Exception) {\n    Resource.Error(e)\n}\n\nThis is more useful because you can pass the error further, otherwise, you won't know if something fails.\n"
},
{
"QuestionId": "76387171",
"QuestionTitle": "Beautiful Soup Img Src Scrape",
"QuestionBody": "Problem: I am trying to scrape the image source locations for pictures on a website, but I cannot get Beautiful Soup to scrape them successfully.\nDetails:\n\nHere is the website\n\nThe three images I want have the following HTML tags:\n\n<img src=\"https://ik.imagekit.io/02fmeo4exvw/exercise-library/large/14-1.jpg\" style=\"display: none;\">\n<img src=\"https://ik.imagekit.io/02fmeo4exvw/exercise-library/large/14-2.jpg\" style=\"display: none;\">\n<img src=\"https://ik.imagekit.io/02fmeo4exvw/exercise-library/large/14-3.jpg\" style=\"display: none;\">\n\n\n\nCode I've Tried:\n\nsoup.find_all('img')\nsoup.select('#imageFlicker')\nsoup.select('#imageFlicker > div')\nsoup.select('#imageFlicker > div > img:nth-child(1)')\nsoup.find_all('div', {'class':'exercise-post__step-image-wrap'})\nsoup.find_all('div', attrs={'id': 'imageFlicker'})\nsoup.select_all('#imageFlicker > div > img:nth-child(1)')\n\nThe very first query of soup.find_all('img') gets every image on the page except the three images I want. I've tried looking at the children and sub children of each of the above, and none of that works either.\nWhat am I missing here? I think there may be javascript that is changing the css display attribute from block to none and back so the three images look like a gif instead of three different images. Is that messing things up in a way I'm not understanding? Thank you!\n",
"AnswerId": "76387347",
"AnswerBody": "The content is provided dynmaically via JavaScript, but not rendered by requests per se, unlike in the browser.\nHowever, you can search for the JavaScript variable:\nvar data = {\"images\":[\"https://ik.imagekit.io/02fmeo4exvw/exercise-library/large/14-1.jpg\",\"https://ik.imagekit.io/02fmeo4exvw/exercise-library/large/14-2.jpg\",\"https://ik.imagekit.io/02fmeo4exvw/exercise-library/large/14-3.jpg\"],\"interval\":600};\n\nwith regex re.search() and convert its content string with json.loads() to JSON, so that you can access it easily.\nExample\nimport requests\nimport re, json\n\nurl = 'https://www.acefitness.org/resources/everyone/exercise-library/14/bird-dog/'\n\njson.loads(re.search(r'var data = (.*?);', requests.get(url).text).group(1))['images']\n\n"
},
{
"QuestionId": "76383602",
"QuestionTitle": "Javascript event.offset alternative for final value during CSS scale & transition",
"QuestionBody": "I have an HTML image that I want to pan & zoom programatically. In order to improve the experience, I added a CSS transition for smoothness.\nWhen I click on the image, I need to determine the mouse position within the image. Currently, event.offsetX gives me the mouse position within the image at the current frame of the animation.\nI would like to know the mouse position as if the animation finished already (even though it hadn't).\nHere is another way of explaining the problem. I created below an example where an image zooms in after we click on the button. The zoom takes 5 seconds. During the zoom, if I keep my mouse fixed and keep clicking, the offset value changes as the image moves on the screen and then it stabilizes after 5 seconds and returns the same offset value. I would like to know that final offset value before the animation finishes if possible.\n\n\n<button onclick=\"onButton()\">Zoom</button>\n<br>\n<img\n    id='img'\n    onclick=\"onImage(event)\"\n    src=\"https://picsum.photos/id/237/200\"\n    style=\"transition: 5s ease\"\n>\n\n<script>\nfunction onButton() {\n    const img = document.querySelector('#img')\n    img.style.scale = 5.0\n}\nfunction onImage(event) {\n    console.log(event.offsetX, event.offsetY)\n}\n</script>\n\n\n\n",
"AnswerId": "76385062",
"AnswerBody": "If you don't mind adding some additional HTML and CSS:\n\n\nfunction onButton() {\n  const img = document.querySelector(\"#img\");\n  img.style.scale = 5.0;\n  const target = document.querySelector(\"#target\");\n  target.style.scale = 5.0;// make sure target's style matches img's style\n}\nfunction onImage(event) {\n  console.log(event.offsetX, event.offsetY);\n}\n#wrapper {\n  display: inline-block;\n  position:relative;\n  font-size:0;\n}\n#target{\n  position:absolute;\n  width:100%;\n  height:100%;\n}\n#img {\n  transition: 5s ease;\n  z-index:2;\n  pointer-events:none;\n}\n<button onclick=\"onButton()\">Zoom</button>\n<br>\n<div id=\"wrapper\">\n  <div id=\"target\" onclick=\"onImage(event)\"></div>\n  <img id=\"img\" src=\"https://picsum.photos/id/237/200\">\n</div>\n\n\n\nThis work by zooming an invisible div behind the image without transition, and transfer the click event to that div instead of the image itself\n"
},
{
"QuestionId": "76383390",
"QuestionTitle": "How to ignore safe area for a background with a linear gradient and image in swiftUI?",
"QuestionBody": "I have a VStack like this:\n    var body: some View{\n        VStack{\n            //some view\n        }\n        .background(\n            ZStack{\n                LinearGradient(gradient: Gradient(\n                    colors: [\n                        .yellow_500,\n                        .yellow_500,\n                        .yellow_500,\n                        .yellow_50\n                    ]), startPoint: .top, endPoint: .bottom)\n                .ignoresSafeArea(.container, edges: [.top])\n                \n                \n                Image(R.image.home_bg_try.name)\n                    .resizable()\n                    .scaledToFill()\n                    .frame(maxWidth: .infinity, maxHeight: .infinity)\n                    .ignoresSafeArea(.container, edges: [.top])\n\n            }\n//                .offset(y: -20)\n        )\n    }\n\n\nI want the image to be displayed without considering the safe area, which currently results in a white space appearing at the top, as shown in this image: (https://i.stack.imgur.com/knRdm.png).\nI attempted to fix this issue by adding an offset, but I noticed that the height of the white space varies across different models.\nHow can I resolve this problem?\n",
"AnswerId": "76385275",
"AnswerBody": "Your current setup has the right idea, but if you want to completely ignore the safe area for the VStack's background, you should apply the .ignoresSafeArea() modifier on each of the backgrounds.\nThe white space you are seeing might be a result of the VStack not filling up the whole screen.\nTry moving .ignoresSafeArea() modifier outside of the ZStack, and apply it to the whole VStack. Here is the updated code:\nvar body: some View {\n    VStack{\n        //some view\n    }\n    .background(\n        ZStack {\n            LinearGradient(gradient: Gradient(\n                colors: [\n                    .yellow_500,\n                    .yellow_500,\n                    .yellow_500,\n                    .yellow_50\n                ]), startPoint: .top, endPoint: .bottom)\n                .resizable()\n                .aspectRatio(contentMode: .fill)\n\n            Image(R.image.home_bg_try.name)\n                .resizable()\n                .scaledToFill()\n                .frame(maxWidth: .infinity, maxHeight: .infinity)\n        }\n    )\n    .ignoresSafeArea()\n}\n\nBy using .ignoresSafeArea(), you instruct SwiftUI to layout the VStack and its background across the whole screen, including under the status bar and home indicator on iPhone models with edge-to-edge screens.\nAdditionally, you might want to apply .edgesIgnoringSafeArea(.all) instead of .ignoresSafeArea() in certain situations. For example, if your view doesn't play well with safe area insets when it's embedded in another view hierarchy, you might find .edgesIgnoringSafeArea(.all) works better. However, in SwiftUI 2.0 and later, .ignoresSafeArea() is generally recommended.\n"
},
{
"QuestionId": "76387297",
"QuestionTitle": "How to conditionally assign a value to Flutter List",
"QuestionBody": "How to conditionally assign a value to \"ingList\" based on the value of recipeList?\n class Calculator extends StatefulWidget {\n    List<IngredientList> recipeList;\n    Calculator(this.recipeList, {Key? key}) : super(key: key);\n\n  @override\n  State<Calculator> createState() => _CalculatorState();\n}\n\nclass _CalculatorState extends State<Calculator> {\n  List<IngredientList> ingList = [];\n\n",
"AnswerId": "76387372",
"AnswerBody": "You can use initState to do that\nclass Calculator extends StatefulWidget {\n  List<IngredientList> recipeList;\n  Calculator(this.recipeList, {Key? key}) : super(key: key);\n\n  @override\n  State<Calculator> createState() => _CalculatorState();\n}\n\nclass _CalculatorState extends State<Calculator> {\n  List<IngredientList> ingList = [];\n\n  @override\n  void initState() {\n    super.initState();\n\n    ingList = widget.recipeList; // you can do any condition here\n  }\n}\n\n"
},
{
"QuestionId": "76384547",
"QuestionTitle": "Passing a variable to a function within another function",
"QuestionBody": "I am learning Rust. I am working on an embedded Rust project to interface with an I2C LED driver.\nI have defined a pub enum LedRegister that defines all of the I2C registers used to control each LED. These register definitions are always one byte, they set by the chip's datasheet, and they will never change. However, I like having them in an enum, because it allows me to create a function that will only accept LedRegisters as inputs.\npub enum LedRegister {\n    // 0-255 PWM value. 255 = max LED brightness.\n    CpuStatusR    = 0x03,\n    CpuStatusG    = 0x02,\n    CpuStatusB    = 0x01,\n    Ch1Cor        = 0x04,\n    Ch1Ptt        = 0x06,\n    Ch1SpareR     = 0x05,\n    Ch1StatusR    = 0x0C,\n    Ch1StatusG    = 0x0B,\n    Ch1StatusB    = 0x0A,\n    Ch2Cor        = 0x07,\n    Ch2Ptt        = 0x09,\n    Ch2SpareR     = 0x08,\n    Ch2StatusR    = 0x0E,\n    Ch2StatusG    = 0x0D,\n    Ch2StatusB    = 0x0F,\n    SpareLedR     = 0x12,\n    SpareLedG     = 0x11,\n    SpareLedB     = 0x10,\n}\n\nIn the same scope, I have a pub fn enable_led to toggle each LED on or off:\npub fn enable_led(i2c: &mut I2c, led: LedRegister, state: bool) -> Result<(), Box<dyn Error>> {\n    if state {\n        i2c.write(&[led as u8, 0xFF])?;\n    } else {\n        i2c.write(&[led as u8, 0x00])?;\n    }\n\n    i2c.write(&[ControlRegister::Update as u8, 0x00])?;\n\n    Ok(())\n}\n\nFrom main, I can call this function and see that my LED turns on:\nled_driver::enable_led(&mut i2c, led_driver::LedRegister::SpareLedG, true);\nI would like to write another function that allows me to blink the LED by calling enable_led multiple times with a delay in between:\npub fn blink_led(i2c: &mut I2c, led: LedRegister, duration_ms: u64) -> Result<(), Box<dyn Error>> {\n    enable_led(i2c, led, true);\n    // add a delay\n    enable_led(i2c, led, false);\n    // add a delay\n\n    Ok(())\n}\n\nHere, Rust complains because the value of 'led' has moved into the first call of enable_led. I understand that there can only be one owner of the value - so I get why Rust is complaining.\nI have attempted to 'borrow' the value of LedRegister:\npub fn enable_led(i2c: &mut I2c, led: &LedRegister, state: bool) -> Result<(), Box<dyn Error>> {\n    if state {\n        i2c.write(&[led as u8, 0xFF])?;\n    } else {\n        i2c.write(&[led as u8, 0x00])?;\n    }\n\n    i2c.write(&[ControlRegister::Update as u8, 0x00])?;\n\n    Ok(())\n}\n\nled_driver::enable_led(&mut i2c, &led_driver::LedRegister::SpareLedG, true);\n\n\nThis gives me E0606 and a suggestion to implement casting through a raw pointer and unsafe blocks, which seems needlessly complicated for this use case.\nI have also considered implementing copy on my LedRegister, so I can make copies of the initial reference before calling led_enable() with the same LED. This compiles, but it also seems more difficult than it should be. I don't think I actually need multiple copies of my register definition byte in RAM. Is this actually necessary?\nI get the feeling that I'm not using the right features of Rust for this task. I am not strongly tied to using an enum here if that is the wrong tool for the job. However, I do want to limit the inputs to enable_led and blink_led so they only accept valid LEDs.\nWhat is the best approach to accomplish my objective here in Rust?\n",
"AnswerId": "76388486",
"AnswerBody": "Casting a reference to an integer is like casting a pointer to an integer, which gives you the address and not the value inside casted, except it is not allowed and you need to go through a raw pointer explicitly. This doesn't require unsafe (led as *const LedRegister as u8), but this also doesn't do what you want.\nThe correct solution is to implement Copy for your enum. You should always implement Copy for simple enums, unless there is a strong reason not to. Taking references to the value is not in any way better than copying it: it is slower, requiring dereferences and storing in the stack instead of potentially in registers, and it complicates the source code for no reason.\n"
},
{
"QuestionId": "76383164",
"QuestionTitle": "Z Index complexity - How to position a component inside of a div to have a higher z-index value against a component outside to its level?",
"QuestionBody": "\n\n.App {\n  font-family: sans-serif;\n  text-align: center;\n}\n\n.section-01 {\n  position: relative;\n  z-index: 0;\n  background-color: red;\n  color: white;\n  padding: 2rem;\n}\n\n.section-02 {\n  position: fixed;\n  z-index: 1;\n  background-color: blue;\n  color: white;\n  padding: 1rem;\n  top: 25vh;\n  left: 30vh;\n}\n\n.div-01 {\n  z-index: 2;\n  position: absolute;\n  background-color: purple;\n  padding: 1rem;\n  top: 15vh;\n  left: 25vh;\n}\n<section class=\"section-01\">\n        Section-01\n        <div class=\"div-01\">Div-01</div>\n      </section>\n      <section class=\"section-02\">\n        <div>Section - 02</div>\n</section>\n\n\n\nI have a component like this:\n<section id='section-01' style={{zIndex: 0}}>\n    <div id='div-01' style={{zIndex: 2}}>Hello World</div>\n</section>\n<section id='section-02' style={{zIndex: 1}}>\n</section>\n\nNow my problem is that due to absolute positioning of #section-02 and #div-01, #section-02 takes the precedence and shows above #div-01. However I don't want that, I want #div-01 to show up above #section-02 and #section-02 show up above #section-01.\nPlease note that I don't have access to alter code of #section-01 or #section-02. I can only control the code of #div-01.\nI know that if parent element has lower z-index then its child won't be able to show above any other entity in hierarchy of parent element and so no matter how high I set the value of div-01 it will always show below section-02 so I wanted to know how can I solve this problem?\nAdding code sandbox for example: https://codesandbox.io/s/ecstatic-flower-u5plui?file=/src/styles.css\nHere's how it shows atm:\n\nAnd here's how I want it to be:\n\nPlease note that you're only allowed to make changes in\n.div-01 {\n  position: relative;\n  z-index: 2;\n  position: absolute;\n  background-color: purple;\n  padding: 1rem;\n  top: 6vh;\n  left: 25vh;\n}\n\nor in JSX part (HTML):\n<div className=\"div-01\">Div-01</div>\n\nI don't have access to section-01 or section-02.\nI cannot restructure the HTML as these comes from different App owners and I have only control to div and its inner content.\n",
"AnswerId": "76385416",
"AnswerBody": "Objective\nGiven 2 sibling positioned elements (.section-01 and .section-02), of which the first element sits at a lower stacking context than the second element. Place the child positioned element of the first element (.section-01 > .div-01) above the second element (.section-02) in the z-axis.\nCriterias\nOnly the child element of the first element (.section-01 > .div-01) may be modified by CSS (apparently by stylesheet?) and HTML (by JSX). The 2 sibling elements are generated by an app and for some reason are beyond reach (please read the XY problem).\nTaking the aforementioned criterias into consideration, we cannot:\n\nadd, remove, or modify HTML (.div-01 is the exception)\nadd, remove, or modify CSS (.div-01 is the exception)\n\nProblem\nThere are two stacking contexts:\n\n.section-01 sits at z-index: 0 without any extended positioning (top, right, bottom, and left) nor does it reference any other positioned elements (position: relative).\n\n.section-02 sits above everything else at z-index: 1 and it's position references the viewport (top, left, and position: fixed).\n\n\nNaturally #2 stacking context will occupy the foreground. Even if .section-02 had z-index: 0 it would still be in the foreground because in HTML layout it proceeds .section-01. The only way to affect stacking context is to change the element that started it (ie. .section-01 and .section-02).\nSolutions\nIf we could just resolve this issue without having to consider the impossible restrictions mentioned under Criterias, we can simply place .section-01 back into the normal flow of the document by assigning it position: static (or removing position: all together), thereby removing it as an origin of a stacking context and allowing it's child element, .div-01 to be the origin of it's own stacking context. (see Figure I).\nFigure I\n.section-01 {\n  position: static;\n  /* As it was originally, there was no real reason for it to have any `position` \n  property */;\n}\n\n.div-01 {\n  position: fixed /* or `absolute` */;\n  z-index: 2;\n  /* ... */\n}\n\nPutting aside my doubts about the criterias being a genuine concern, (maybe it's too difficult to target the app's HTML/CSS because it assigns randomly determined #ids or .classes), there is a solution with the same result but in an indirect way.\nSince the only element in our complete control is .div-01, we can target it's parent by using the .has() pseudo-class. (see Figure II)/\nFigure II\n/* This will target anything that is a direct ancestor (aka parent) of\n.div-01 */\n:has(> .div-01) {\n  position: static\n} \n\n.div-01 {\n  position: fixed /* or absolute */;\n  z-index: 2;\n\nExample\n\n\nhtml,\nbody {\n  margin: 0;\n  padding: 0;\n  min-height: 100vh;\n  font: 2ch/1.15 \"Segoe UI\";\n}\n\n.section-01 {\n  position: relative;\n  z-index: 0;\n  padding: 2rem;\n  color: white;\n  background-color: red;\n}\n\n.section-02 {\n  position: fixed;\n  top: 10vh;\n  left: 30vw;\n  z-index: 1;\n  Width: 40vw;\n  height: 30vh;\n  padding: 6rem 1rem 1rem;\n  text-align: right;\n  color: white;\n  background-color: blue;\n}\n\n.div-01 {\n  position: fixed;\n  top: 5vh;\n  left: 25vw;\n  z-index: 2;\n  width: 30vw;\n  height: 30vh;\n  padding: 1rem;\n  color: white;\n  background-color: purple;\n}\n\n:has(> .div-01) {\n  position: static;\n}\n<section class=\"section-01\">\n  Section-01\n  <div class=\"div-01\">Div-01</div>\n</section>\n<section class=\"section-02\">\n  <div>Section - 02</div>\n</section>\n\n\n\n"
},
{
"QuestionId": "76387354",
"QuestionTitle": "How can I use url query parameter to set the value of a 'Parameters' in PowerBI?",
"QuestionBody": "In PowerBI, I have a managed parameter which is a list of text.\nabc, def, ghi.\nAnd that parameter is being use to call a custom function in powerbi i.e. MyCustomFunction(@Name)\nMy question is how can I change the value of the parameter from the url when I load the report (after i published it to PowerBI service)?\ni.e. I would like to\nhttps://mypowerbi url?filter Name eq 'abc'  \n`MyCustomFunction('abc')' will be called.\n\nhttps://mypowerbi url?filter Name eq 'def'  \n`MyCustomFunction('def')' will be called.\n\n\n",
"AnswerId": "76387413",
"AnswerBody": "\nMy question is how can I change the value of the parameter from the url when I load the report (after i published it to PowerBI service)?\n\nYou can't. In Power BI reports, the URL query parameters can be used to filter the report. See Filter a report using query string parameters in the URL\nParameters can be set from the URL in paginated reports only (legacy from SSRS). See Pass a report parameter within a URL for a Power BI paginated report.\nFor Power BI reports published to Power BI Service, the parameter values can be changed from the dataset's settings. See Edit parameter settings in the Power BI service. Keep in mind that this affects all users, who see the report, and it is not something that can affect your viewing session only. Changing parameter values of imported datasets usually will take a dataset refresh for the changes to take effect.\nParameters of published reports can also be updated using the Power BI's REST API - see Update Parameters and Update Parameters In Group.\n"
},
{
"QuestionId": "76387183",
"QuestionTitle": "Need help personalizing my CSS navbar: how do I highlight the  element on mouseover?",
"QuestionBody": "I am trying to make a simple navbar I managed to make the base but when I try to personalize I am getting stuck.\nMy objective is that when the mouse goes over each element(home, etc) it highlights like a box, but currently it only highlights the <a> I tried and not the <li> holding it.\nI'm trying to make the <li> an anchor that can be clicked and highlighted similar to stack's navbar.\n\n\n.nav-top {\n  background: rgb(151, 138, 63);\n  margin: 0;\n  padding: 1rem 0;\n  display: flex;\n  justify-content: flex-end;\n  align-items: center;\n}\n\n.nav-item {\n  list-style: none;\n  margin-right: 1.2rem;\n  padding: 5px 10px;\n}\n\n.nav-top ul {\n  margin: 0 auto;\n  padding: 0;\n  list-style: none\n}\n\n.nav-top li:hover {\n  display: block\n}\n\n.nav-top a:hover {\n  background: #F2F2F2;\n  color: #444444;\n}\n\n.nav-item a {\n  text-decoration: none;\n  color: white;\n  width: 100px;\n}\n\n.nav-item:first-child {\n  margin-right: auto;\n  margin-left: 2rem;\n}\n\n.nav-item a:hover {\n  color: aqua;\n}\n<navbar>\n  <ul class=\"nav-top\">\n    <li class=\"nav-item\"><label class=\"logo\">LoremX</label></li>\n    <li class=\"nav-item\"><a href=\"index.html\">Home</a></li>\n    <li class=\"nav-item\"><a href=\"#\">About</a></li>\n    <li class=\"nav-item\" id=\"contact\"><a href=\"#\">Contact</a></li>\n  </ul>\n</navbar>\n\n\n\n",
"AnswerId": "76387423",
"AnswerBody": "The only :hover declaration you have for li is the default value of display: block while the color change declarations are made only for a. However, the effect that I believe you are trying to achieve is better accomplished by making the anchors block-level with padding.\nNot related to the hover effect, just correcting your markup:\n\nYou have .nav-top ul selector but the example doesn't include a nested ul\nI suspect that you are misusing the label element.\nnavbar is not an HTML element and I suspect you want nav\n\n\n\n.nav-top {\n  display: flex;\n  margin: 0;\n  padding: 0;\n  list-style-type: none;\n  background: rgb(151, 138, 63);\n}\n\n.logo {\n  margin-right: auto;\n  margin-left: 2rem;\n  padding: 5px 10px;\n  align-self: center;\n}\n\n.nav-item {\n  margin-right: 1.2rem;\n  padding: 5px 10px;\n}\n\n.nav-item a {\n  display: block;\n  padding: .5em;\n  text-decoration: none;\n  color: white;\n}\n\n.nav-item a:hover {\n  color: aqua;\n  background: #F2F2F2;\n}\n<nav>\n  <ul class=\"nav-top\">\n    <li class=\"logo\">LoremX</li>\n    <li class=\"nav-item\"><a href=\"#\">Home</a></li>\n    <li class=\"nav-item\"><a href=\"#\">About</a></li>\n    <li class=\"nav-item\" id=\"contact\"><a href=\"#\">Contact</a></li>\n  </ul> \n</nav>\n\n\n\n"
},
{
"QuestionId": "76383862",
"QuestionTitle": "Mysql in docker container doesn't accept credentials",
"QuestionBody": "I have a Dockerfile which I later want to feed some initial sql dump into:\nFROM mysql:debian\n\nEXPOSE 3306\n\nENTRYPOINT [\"docker-entrypoint.sh\"]\n\nCMD [\"mysqld\"]\n\nThen there is my docker-compose.yaml:\nversion: '3'\n\nservices:\n  mysql:\n    container_name: ${CONTAINER_NAME}\n    build:\n      context: .\n    restart: always\n    environment:\n      - MYSQL_ROOT_PASSWORD=${ROOT_PASSWORD}\n      - MYSQL_USER=${MYSQL_USER}\n      - MYSQL_PASSWORD=${MYSQL_PASSWORD}\n      - MYSQL_DATABASE=${MYSQL_DATABASE}\n\nI can docker exec -it sqlcontainer mysql -uroot -p into my container just fine (works with the $MYSQL_USER as well), but when I try to do the same from outside, e.g. with  mysql -uroot -p, I always get ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES).\nI'm out of my wits. What am I doing wrong? The communication to mysqld inside the container apparently works, otherwise I wouldn't get back any response.\nI'm on Windows, if that's a hint for anyone. But the above is true for PowerShell, CMD and even Git Bash.\n",
"AnswerId": "76388595",
"AnswerBody": "It is embarrassing to admit, but both commenters @RiggsFolly and @DavidMaze are right in what they said: I hadn't used MySQL for quite a while on my machine. When I checked the task manager, I indeed found a local mysqld running already, which of course was primed with different credentials. After killing the process (and adding the missing port in the compose file), I was able to connect to my containerized instance.\nHope this will help out somebody else in the future who falls into the same trap.\n"
},
{
"QuestionId": "76387405",
"QuestionTitle": "Why seize queue cant be zero in AnyLogic",
"QuestionBody": "Let's imagine a situation where we have a queue positioned before the seize block, and this queue has the timeout property activated.\nIn such cases, it is important to note that the seizure queue cannot be reduced to zero. The seize queue always has a minimum capacity of 1. If the seize queue capacity were set to 1, one agent would be taken out of the timeout property of the original queue and placed directly into the seize queue.\nThis behavior is generally not desirable, particularly when dealing with a large number of agents or running the simulation for extended periods, such as years, to collect the statistics, especially for the timeout property of the original queue.\n\nSo how can I avoid having an agent in the seize queue, or is there another way to achieve this?\n",
"AnswerId": "76387433",
"AnswerBody": "You can manually avoid having agents in the Seize queue by using a Hold block upstream and only releasing agents into the Seize block if its queue is empty.\n"
},
{
"QuestionId": "76382756",
"QuestionTitle": "Efficiently match all values of a vector in another vector",
"QuestionBody": "I'm looking to find an efficient method of matching all values of vector x in vector y rather than just the first position, as is returned by match().  What I'm after essentially is the default behavior of pmatch() but without partial matching:\nx <- c(3L, 1L, 2L, 3L, 3L, 2L)\ny <- c(3L, 3L, 3L, 3L, 1L, 3L)\n\nExpected output:\npmatch(x, y)  \n[1]  1  5 NA  2  3 NA\n\nOne way is to use ave() however this becomes slow and very memory inefficient as the number of groups increases:\nave(x, x, FUN = \\(v) which(y == v[1])[1:length(v)])\n[1]  1  5 NA  2  3 NA\n\nCan anyone recommend an efficient way to achieve this in preferably (but not mandatory) base R?\nLarger dataset for benchmarking:\nset.seed(5)\nx <- sample(5e3, 1e5, replace = TRUE)\ny <- sample(x, replace = TRUE)\n\n",
"AnswerId": "76385488",
"AnswerBody": "A variant in base using split.\nsplit the indices of both vectors by its value. Subset the second list with the names of the first, that both have the same order. Change NULL to NA and bring the lengths of the second list to those from the first. Reorder the indices of the second list by those of the first.\nx <- c(3L, 1L, 2L, 3L, 3L, 2L)\ny <- c(3L, 3L, 3L, 3L, 1L, 3L)\n\na <- split(seq_along(x), x)\nb <- split(seq_along(y), y)[names(a)]\nb[lengths(b)==0] <- NA\nb <- unlist(Map(`length<-`, b, lengths(a)), FALSE, FALSE)\n`[<-`(b, unlist(a, FALSE, FALSE), b)\n#[1]  1  5 NA  2  3 NA\n\nI tried to exchange the part\nb <- split(seq_along(y), y)[names(a)]\nb[lengths(b)==0] <- NA\n\nwith\nb <- list2env(split(seq_along(y), y))\nb <- mget(names(a), b, ifnotfound = NA)\n\nBut it was not faster.\nAn RCPP version.\nStore the indices of the second vector ín a queue for each unique value in an unordered_map. Iterate over all values of the first vector and take the indices from the queue.\nRcpp::sourceCpp(code=r\"(\n#include <Rcpp.h>\n#include <unordered_map>\n#include <queue>\n\nusing namespace Rcpp;\n// [[Rcpp::export]]\nIntegerVector pm(const std::vector<int>& a, const std::vector<int>& b) {\n  IntegerVector idx(no_init(a.size()));\n  std::unordered_map<int, std::queue<int> > lut;\n  for(int i = 0; i < b.size(); ++i) lut[b[i]].push(i);\n  for(int i = 0; i < idx.size(); ++i) {\n    auto search = lut.find(a[i]);\n    if(search != lut.end() && search->second.size() > 0) {\n      idx[i] = search->second.front() + 1;\n      search->second.pop();\n    } else {idx[i] = NA_INTEGER;}\n  }\n  return idx;\n}\n)\")\npm(x, y)\n#[1]  1  5 NA  2  3 NA\n\nA for this case specialized RCPP version.\nCreate a vector of the length of the maximum value of the first vector and count how many times a value is present. Create another queue vector of the same length and sore there the indices of the values of the second vector until it has reached the number of the first. Iterate over all values of the first vector and take the indices from the queue.\nRcpp::sourceCpp(code=r\"(\n#include <Rcpp.h>\n#include <vector>\n#include <array>\n#include <queue>\n#include <algorithm>\n\nusing namespace Rcpp;\n// [[Rcpp::export]]\nIntegerVector pm2(const std::vector<int>& a, const std::vector<int>& b) {\n  IntegerVector idx(no_init(a.size()));\n  int max = 1 + *std::max_element(a.begin(), a.end());\n  std::vector<int> n(max);\n  for(int i = 0; i < a.size(); ++i) ++n[a[i]];\n  std::vector<std::queue<int> > lut(max);\n  for(int i = 0; i < b.size(); ++i) {\n    if(b[i] < max && n[b[i]] > 0) {\n      --n[b[i]];\n      lut[b[i]].push(i);\n    }\n  }\n  for(int i = 0; i < idx.size(); ++i) {\n    auto & P = lut[a[i]];\n    if(P.size() > 0) {\n      idx[i] = P.front() + 1;\n      P.pop();\n    } else {idx[i] = NA_INTEGER;}\n  }\n  return idx;\n}\n)\")\npm2(x,y)\n#[1]  1  5 NA  2  3 NA\n\n\nBenchmark\nset.seed(5)\nx <- sample(5e3, 1e5, replace = TRUE)\ny <- sample(x, replace = TRUE)\n\nlibrary(data.table)\n\nmatchall <- function(x, y) {\n  data.table(y, rowid(y))[\n    data.table(x, rowid(x)), on = .(y = x, V2), which = TRUE\n  ]\n}\n\nrmatch <- function(x, y) {\n  xp <- cbind(seq_along(x), x)[order(x),]\n  yp <- cbind(seq_along(y), y)[order(y),]\n  result <- numeric(length(x))\n  \n  xi <- yi <- 1\n  Nx <- length(x)\n  Ny <- length(y)\n  while (xi <= Nx) {\n    if (yi > Ny) {\n      result[xp[xi,1]] <- NA\n      xi <- xi + 1\n    } else if (xp[xi,2] == yp[yi,2]) {\n      result[xp[xi,1]] = yp[yi,1]\n      xi <- xi + 1\n      yi <- yi + 1\n    } else if (xp[xi,2] < yp[yi,2]) {\n      result[xp[xi,1]] <- NA\n      xi <- xi + 1\n    } else if (xp[xi,2] > yp[yi,2]) {\n      yi <- yi + 1\n    }\n  }\n  result  \n}\n\nbench::mark(\nave = ave(x, x, FUN = \\(v) which(y == v[1])[1:length(v)]),\nrmatch = rmatch(x, y),\nmake.name = match(make.names(x, TRUE), make.names(y, TRUE)),\npaste = do.call(match, lapply(list(x, y), \\(v) paste(v, ave(v, v, FUN = seq_along)))),\nmake.unique = match(make.unique(as.character(x)), make.unique(as.character(y))),\nsplit = {a <- split(seq_along(x), x)\n  b <- split(seq_along(y), y)[names(a)]\n  b[lengths(b)==0] <- NA\n  b <- unlist(Map(`length<-`, b, lengths(a)), FALSE, FALSE)\n  `[<-`(b, unlist(a, FALSE, FALSE), b)},\ndata.table = matchall(x, y),\nRCPP = pm(x, y),\nRCPP2 = pm2(x, y)\n)\n\nResult\n  expression       min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n  <bch:expr>  <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n1 ave            1.66s    1.66s     0.603    3.73GB    68.7      1   114\n2 rmatch      258.29ms 259.35ms     3.86     5.34MB    30.8      2    16\n3 make.name   155.69ms 156.82ms     6.37    14.06MB     1.59     4     1\n4 paste         93.8ms 102.06ms     9.74    18.13MB     7.79     5     4\n5 make.unique  81.67ms   92.8ms    10.4      9.49MB     5.22     6     3\n6 split        12.66ms  13.16ms    65.8      7.18MB    16.0     33     8\n7 data.table    6.22ms   6.89ms   114.       5.13MB    28.0     57    14\n8 RCPP          3.06ms    3.2ms   301.     393.16KB     3.98   151     2\n9 RCPP2         1.64ms   1.82ms   514.     393.16KB     8.00   257     4\n\nIn this case the C++ version is the fastest and allocates the lowest amount of memory. In case using base the splitB variant is the fastest and rmatch allocates the lowest amount of memory.\n"
},
{
"QuestionId": "76378680",
"QuestionTitle": "R - How to rename xml parent node based on child element (or associate child elements)?",
"QuestionBody": "I'm trying to extract a couple of elements from XML files into an R dataframe but the parent nodes are all named the same, so I don't know how to associate child elements. I'm very new to xml (about 3 hours) so apologies if I use the wrong terminology. I did not find any R-based solutions.\nThis is the general structure of the xml files:\n<Annotations>\n    <Version>1.0.0.0</Version>\n    <Annotation>\n        <MicronLength>14.1593438418</MicronLength>\n        <MicronHeight>0.0000000000</MicronHeight>\n        <ObjIndex>1</ObjIndex>\n    </Annotation>\n    <Annotation>\n        <MicronLength>5.7578076896</MicronLength>\n        <MicronHeight>0.0000000000</MicronHeight>\n        <ObjIndex>2</ObjIndex>\n    </Annotation>\n</Annotations>\n\nThere are many \"Annotation\" nodes. There are also several other children node names in there but they don't matter as I'm just trying to extract MicronLength and ObjIndex into a dataframe. So I need to either:\n\nAssociate and get both elements from within each \"Annotation\" node\n\nOR\n\nRename each \"Annotation\" based on the ObjIndex within (e.g. \"Annotation 1\", \"Annotation 2\", etc.) and then get parent name and child element into the df.\n\nI also have several xml files so I want to iterate over each one to eventually create a DF like the example below.\n| filename           | ObjIndex | MicronLength  |\n\n| ------------------ | -------- | ------------- |\n\n| examplefile1(.xml) | 1        | 14.1593438418 |\n\n| examplefile1       | 2        | 5.7578076896  |\n\n| examplefile2       | 1        | 12.6345661343 |\n\n\nThe filenames (with or without extension) will then be str_split into some more columns but I can do that myself.\nMuch appreciated!\n",
"AnswerId": "76385544",
"AnswerBody": "I have previously used xml_find_all() for this kind of simple conversion.\nThis works as long as each Annotation node always has exactly\none ObjIndex and MicronLength child node:\nlibrary(xml2)\n\nxml <- read_xml(\"\n<Annotations>\n    <Version>1.0.0.0</Version>\n    <Annotation>\n        <MicronLength>14.1593438418</MicronLength>\n        <MicronHeight>0.0000000000</MicronHeight>\n        <ObjIndex>1</ObjIndex>\n    </Annotation>\n    <Annotation>\n        <MicronLength>5.7578076896</MicronLength>\n        <MicronHeight>0.0000000000</MicronHeight>\n        <ObjIndex>2</ObjIndex>\n    </Annotation>\n</Annotations>\n\")\n\ndata.frame(\n  ObjIndex = xml_integer(xml_find_all(xml, \"Annotation/ObjIndex\")),\n  MicronLength = xml_double(xml_find_all(xml, \"Annotation/MicronLength\"))\n)\n#>   ObjIndex MicronLength\n#> 1        1    14.159344\n#> 2        2     5.757808\n\n"
},
{
"QuestionId": "76387362",
"QuestionTitle": "How to set UID and GID for the container using python sdk?",
"QuestionBody": "How to set UID and GID for the container when Python SDK is used to spin up the container?\n",
"AnswerId": "76387470",
"AnswerBody": "As the documentation you've linked says, pass in user and group_add to run():\nclient.containers.run('alpine', 'echo hello world', user='foo', group_add=[123])\n\nBoth accept both IDs and names, but group_add needs to be a list.\n"
},
{
"QuestionId": "76387121",
"QuestionTitle": "How to align text vertically according to the highest point of the text and lowest point?",
"QuestionBody": "I want to center a text vertically such that the highest point of the text and the lowest point of text are on equal distance from the ending div that it is enclosed in.\nI have the following css code:\npadding-left: 30px;\nfont-family: 'Playfair Display', serif;\nfont-weight: 100;\nwidth: 140%;\nline-height: 68px;\ncolor: #fff;\nfont-size: 46px;\nborder-style: solid;\nborder-color: #1faf2d;\nbackground-color: #1faf2d;\nmargin-bottom: 0 !important;\nmargin-top: 38px;\n\nThis is what gives the colour and height etc to the font and it look like the below image.\n\n",
"AnswerId": "76387471",
"AnswerBody": "This can only be done by adding padding at the bottom or Top and this may vary as per different Fonts. I question is why do you want to do this? As anigning center as per your way would further discurb the balance.\nAlso, The positioning of certain letters, such as \"p,\" \"g,\" \"y,\" and \"q,\" are lower than the center line is due to their design and the rules of typography. These letters have descenders, which are the parts of the letterforms that extend below the baseline.\nDescenders are common in lowercase letters and serve to maintain the overall balance and legibility of the text. They allow for differentiation between similar letterforms and help to create a visually pleasing text block.\nWhen aligning text vertically, the descenders are taken into account to ensure proper spacing and balance. By aligning the baseline of the text, which includes the descenders, it maintains the overall visual harmony of the text and prevents the descenders from interfering with the line spacing or overlapping other elements.\nIn the case of vertically aligning text to the highest point and lowest point, the descenders will naturally make the text appear lower as they extend below the baseline. This is considered the correct alignment for maintaining legibility and preserving the intended design of the typeface.\nIt's worth noting that the alignment of text can vary depending on the context and the specific design choices made by the typographer or designer. Different fonts may have slightly different alignments, and some artistic or decorative fonts may intentionally deviate from traditional alignment principles for creative purposes.\n"
},
{
"QuestionId": "76388879",
"QuestionTitle": "Timer isn't dealing with seconds properly",
"QuestionBody": "Whenever I change the minutes on the timer it works perfectly, but when I change the seconds on the timer, no matter what, it instantly stops. I'm not sure what I'm doing wrong. This program is apart of a codepen exercise. When I had the timer on a countdown setting it worked perfectly, but when I changed it to countup it stopped working for the seconds.\n\n\nwindow.addEventListener('DOMContentLoaded', documentLoaded, false);\n\nvar startTime;\nvar limit;\nvar timer;\n\nfunction documentLoaded() {\n  \"use strict\";\n\n  var timerElement = document.getElementById(\"timer\");\n  timerElement.addEventListener(\"keydown\", function (event) {\n    if (event.key === 'Enter') {\n      event.preventDefault();\n      startTimer();\n      timerElement.blur();\n    }\n  });\n}\n\nfunction startTimer() {\n  startTime = new Date();\n  limit = parseInt(document.getElementById(\"timer\").innerHTML);\n\n  clearInterval(timer);\n  timer = setInterval(updateTime, 1000);\n}\n\nfunction updateTime() {\n  var currentTime = new Date();\n  var elapsed = (currentTime.getTime() - startTime.getTime()) / 1000;\n\n  var minutes = Math.floor(elapsed / 60);\n  var seconds = Math.floor(elapsed % 60);\n\n  if (minutes < 10) {\n    minutes = \"0\" + minutes;\n  }\n  if (seconds < 10) {\n    seconds = \"0\" + seconds;\n  }\n\n  document.getElementById(\"timer\").innerHTML = minutes + \":\" + seconds;\n\n  var totalSeconds = minutes * 60 + seconds;\n  if (totalSeconds >= limit * 60) {\n    document.getElementById(\"timer\").classList.add(\"red\");\n    clearInterval(timer); // Stop the timer\n  } else {\n    document.getElementById(\"timer\").classList.remove(\"red\");\n  }\n}\nbody {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n\n#timer-container {\n  width: 200px;\n  height: 200px;\n  border-radius: 50%;\n  background-color: #0781D4;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n\n#timer {\n  font-size: 36px;\n  text-align: center;\n}\n\n.red {\n  background-color: red;\n}\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Ejercio No. 3</title>\n  <link rel=\"stylesheet\" href=\"style.css\">\n</head>\n<body>\n  <div id=\"timer-container\">\n    <div id=\"timer\" contenteditable=\"true\">00:00</div>\n  </div>\n  <script src=\"script.js\"></script>\n</body>\n</html>\n\n\n\n",
"AnswerId": "76388972",
"AnswerBody": "You don't set the limit correctly - you set it directly to the content of the timer, which includes non numeric characters such as \":\". When using parseInt on something that isn't all digits, anything after the first non numeric character is discarded. Therefore, by using anything under a minute to test with, limit will be set to 0, as \"00:30\" would result in 0 from parseInt, as only text from before the colon is used. To fix this, split the text at the colon and convert the minutes into seconds, as shown in the snippet\nlet time = document.getElementById(\"timer\").innerHTML.split(\":\");\n//if time = \"01:30\", limit = 1 + 30/60 = 1.5 minutes\nlimit = parseInt(time[0]) + parseInt(time[1])/60;\n\n\n\nwindow.addEventListener('DOMContentLoaded', documentLoaded, false);\n\nvar startTime;\nvar limit;\nvar timer;\n\nfunction documentLoaded() {\n  \"use strict\";\n\n  var timerElement = document.getElementById(\"timer\");\n  timerElement.addEventListener(\"keydown\", function (event) {\n    if (event.key === 'Enter') {\n      event.preventDefault();\n      startTimer();\n      timerElement.blur();\n    }\n  });\n}\n\nfunction startTimer() {\n  startTime = new Date();\n  let time = document.getElementById(\"timer\").innerHTML.split(\":\");\n  limit = parseInt(time[0]) + parseInt(time[1])/60;\n\n  clearInterval(timer);\n  timer = setInterval(updateTime, 1000);\n}\n\nfunction updateTime() {\n  var currentTime = new Date();\n  var elapsed = (currentTime.getTime() - startTime.getTime()) / 1000;\n\n  var minutes = Math.floor(elapsed / 60);\n  var seconds = Math.floor(elapsed % 60);\n\n  if (minutes < 10) {\n    minutes = \"0\" + minutes;\n  }\n  if (seconds < 10) {\n    seconds = \"0\" + seconds;\n  }\n\n  document.getElementById(\"timer\").innerHTML = minutes + \":\" + seconds;\n\n  var totalSeconds = minutes * 60 + seconds;\n  if (totalSeconds >= limit * 60) {\n    document.getElementById(\"timer\").classList.add(\"red\");\n    clearInterval(timer); // Stop the timer\n  } else {\n    document.getElementById(\"timer\").classList.remove(\"red\");\n  }\n}\nbody {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n\n#timer-container {\n  width: 200px;\n  height: 200px;\n  border-radius: 50%;\n  background-color: #0781D4;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n\n#timer {\n  font-size: 36px;\n  text-align: center;\n}\n\n.red {\n  background-color: red;\n}\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Ejercio No. 3</title>\n  <link rel=\"stylesheet\" href=\"style.css\">\n</head>\n<body>\n  <div id=\"timer-container\">\n    <div id=\"timer\" contenteditable=\"true\">00:00</div>\n  </div>\n  <script src=\"script.js\"></script>\n</body>\n</html>\n\n\n\n"
},
{
"QuestionId": "76383134",
"QuestionTitle": "Is it possible to run a sudo command in go without running the program itsself as sudo",
"QuestionBody": "The program runs multiple commands that require sudo privileges (such as sudo dnf update). Since the program should be installed using the go install command, it can't be run as sudo its self without configuration done by the user (afaik).\nThe program doesn't show the output to the user to keep the output clean. To show that a process is running, it uses a spinner from the spinner library.\nIs it possible to do any of these things?\n\nObtain sudo privileges from within the program\nMake the program runnable as sudo, even when installed using go install\nShow the output of the sudo command (including the password request) without it being overwritten by the spinner\n\nHere is a shortened version of what I would like my code to do:\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"os/exec\"\n    \"time\"\n\n    \"github.com/briandowns/spinner\"\n)\n\nfunc main() {\n    // Spinner to show that it's running\n    s := spinner.New(spinner.CharSets[14], time.Millisecond*100)\n    s.Start()\n\n    // Somehow execute this with sudo\n    _, err := exec.Command(os.Getenv(\"SHELL\"), \"-c\", \"dnf update -y\").Output()\n\n    // Stop the spinner and handle any error\n    if err != nil {\n        fmt.Printf(\"Err: %s\", err)\n        os.Exit(1)\n    }\n    s.Stop()\n\n    // Finish\n    fmt.Println(\"Success\")\n}\n\n",
"AnswerId": "76385590",
"AnswerBody": "_, err := exec.Command(os.Getenv(\"SHELL\"), \"-c\", \"sudo dnf update -y\").Output()\nIn this exapmle, with adding sudo before the command that you want run as sudo, and after running the program, will ask password for sudo, If you apply this to your example code you can't see password request message, because the spinner graphics will overwrite it, but if you try this without spinner graphics you can see it. Even you don't see the message, if you type your correct password and press enter your commands will work as sudo. With this, you don't need run your application as sudo. I have ran similar commands with using this and they have worked.\n"
},
{
"QuestionId": "76387535",
"QuestionTitle": "error: could not find `sui` in https://github.com/MystenLabs/sui.git?branch=devnet with version `*`",
"QuestionBody": "When trying to install sui binaries using\ncargo install --locked --git https://github.com/MystenLabs/sui.git --branch devnet sui\n\nas suggested by the official docs,\ngives the below error\nUpdating git repository `https://github.com/MystenLabs/sui.git` \nerror: could not find `sui` in https://github.com/MystenLabs/sui.git?branch=devnet with version `*`\n\nWhat could be the possible reason?\n",
"AnswerId": "76387552",
"AnswerBody": "I used the below command which includes the tag to install it\ncargo install --locked --git https://github.com/MystenLabs/sui.git --branch devnet --tag devnet-<version> sui\n\nwhere you can replace version as required (e.g v1.3.0)\n"
},
{
"QuestionId": "76387474",
"QuestionTitle": "Wierd behavior with raising intgers to the negative powers in python",
"QuestionBody": "I am observing this weird behavior when I am raising an integer to the negative power using an np.array. Specifically, I am doing\nimport numpy as np\n\na = 10**(np.arange(-1, -8, -1))\n\nand it results in the following error.\n\nValueError: Integers to negative integer powers are not allowed.\n\nThis is strange as the code 10**(-1) works fine. However the following workaround (where 10 is a float instead of integer) works fine.\nimport numpy as np\n\na = 10.**(np.arange(-1, -8, -1)\nprint(a)  # Prints array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07])\n\nWhy is it not valid for integers? Any explanation is appreciated.\n",
"AnswerId": "76387579",
"AnswerBody": "This is happening because the input 10 is an integer.\n10**(np.arange(-1, -8, -1))\n\nnumpy.arange() is designed such a way that that has to give 10**(np.arange(-1, -8, -1)) integers or nothing since input is an integer.\nOn the contrary;\na = 10.**(np.arange(-1, -8, -1)\n\ngives results happily as 10.0 is a float\n\nEdit: found an answer to back my point; voted for a duplicate:\nWhy can't I raise to a negative power in numpy?\n"
},
{
"QuestionId": "76383413",
"QuestionTitle": "Get value of a field from a foreigKey in Django Models",
"QuestionBody": "I have two classes in my Database in Django\nclass Test(models.Model):\n    sequenzaTest = models.ForeignKey(\"SequenzaMovimento\", null=True, on_delete=models.SET_NULL)\n\nclass SequenzaMovimento(models.Model):\n    nomeSequenza = models.CharField(max_length=50, blank=False, null=False)\n    serieDiMovimenti = models.TextField(blank=False, null=False, default=\"\")\n\nNow, every Test object created can be associated with just one SequenzaMovimento object. Different Test objects can have the same SequenzaMovimento\nNow, I know the primary key of my Test. How do I find the serieDiMovimenti inside the SequenzaMovimento object which is linked to the Test object?\nI can get the sequenzaTest from the Test object with\ntesto_sequenza = Test.objects.get(pk=idObj)\ntesto_sequenza.sequenzaTest\n\nbut I can't find to understand how access serieDiMovimenti\n",
"AnswerId": "76385687",
"AnswerBody": "This should work:\ntry:\n    testo_sequenza = Test.objects.get(pk=idObj)\nexcept Test.DoesNotExist:\n    # do here what you need the program to do if not found. maybe a return if function or a continue/break if you're in a loop\n    print(\"Testo Sequenza not found\")\nsequenza_test = testo_sequenza.sequenzaTest\nserie_di_movimenti = sequenza_test.serieDiMovimenti\n\nAlso you should check\nserieDiMovimenti = models.TextField(blank=False, null=False, default=\"\")\n\nBecause if you want it to be \"optional field\" then it would be blank=True\n"
},
{
"QuestionId": "76388965",
"QuestionTitle": "How to use integer methods using `method`, not their infix form, in Ruby",
"QuestionBody": "I am looking to programmatically apply a typically infixed operation (eg: +, -, *, /) on two integers, where the operation is specified via a string. I have had success accessing the method itself using .method\nThis is a pattern that works, 1.+(2) which correctly resolves to 3\nBy extension, I'd to define a way that could take a variable string for the operator, like so: 1 + 2 as 1.method('+')(2)\nThe above causes a syntax error, though up til the point of retrieving the method this way does work, I'm not sure what the syntax needs to be to then pass the second integer argument. e.g:\n1.method('+')     # <Method: Integer#+(_)>\n1.method('+') 2   # syntax error, unexpected integer literal, expecting end-of-input\n1.method('+')(2)  # syntax error, unexpected '(', expecting end-of-input\n\nWhat is the right syntax to perform an operation 1 + 2 in this way?\nI am using: ruby 3.1.2p20 (2022-04-12 revision 4491bb740a) [x86_64-linux]\n",
"AnswerId": "76389014",
"AnswerBody": "The Method class has several instance method of it's own. The one you're looking for here is call\nIt is also aliased to [] and ===\n1.method('+').call(2) #=> 3\n1.method('+')[2] #=> 3\n1.method('+') === 2 #=> 3\n\n"
},
{
"QuestionId": "76387189",
"QuestionTitle": "Fatal error relating to \"include S.h\" when installing R 'scalop' package",
"QuestionBody": "I am attempting to install an R package named 'infercna', the github repository to which is linked here.\nThe install process attempts to load another package named 'scalop', which is linked here.\nSpecifically, this command:\ndevtools::install_github(\"jlaffy/infercna\")\n\nreturns\nDownloading GitHub repo jlaffy/infercna@HEAD\n── R CMD build ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/private/var/folders/hj/1wvjfb692c3gswybcg8xdcwm0000gn/T/RtmpqQIEYL/remotes7d75586a9ac5/jlaffy-infercna-98a8db8/DESCRIPTION’ (343ms)\n─  preparing ‘infercna’:\n✔  checking DESCRIPTION meta-information ...\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n     NB: this package now depends on R (>= 3.5.0)\n     WARNING: Added dependency on R >= 3.5.0 because serialized objects in\n     serialize/load version 3 cannot be read in older versions of R.\n     File(s) containing such objects:\n       ‘infercna/data-raw/genes.rda’\n─  building ‘infercna_1.0.0.tar.gz’\n   \n* installing *source* package ‘infercna’ ...\n** using staged installation\n** R\n** data\n*** moving datasets to lazyload DB\n** byte-compile and prepare package for lazy loading\nError in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : \n  there is no package called ‘scalop’\nCalls: <Anonymous> ... loadNamespace -> withRestarts -> withOneRestart -> doWithOneRestart\nExecution halted\nERROR: lazy loading failed for package ‘infercna’\n* removing ‘/Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library/infercna’\n\nAs such, I backtracked and attempted to install scalop, like so:\nremotes::install_github(\"jlaffy/scalop\")\n\nThis is where things start to really get hairy. To install, scalop requires 95 dependencies. Upon successful installation of all 95, the installation for scalop will eventually still fail, like so:\nchecking for file ‘/private/var/folders/hj/1wvjfb692c3gswybcg8xdcwm0000gn/T/RtmpqQIEYL/remotes7d757fe15404/jlaffy-scalop-021999d/DESCRIPTION’ ...\n─  preparing ‘scalop’: (385ms)\n✔  checking DESCRIPTION meta-information ...\n─  cleaning src\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n─  building ‘scalop_1.1.0.tar.gz’\n   \n* installing *source* package ‘scalop’ ...\n** using staged installation\n** libs\nusing C compiler: ‘Apple clang version 11.0.3 (clang-1103.0.32.62)’\nusing SDK: ‘MacOSX10.15.sdk’\nclang -arch x86_64 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG  -I'/Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library/Rcpp/include' -I/opt/R/x86_64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c init.c -o init.o\nclang -arch x86_64 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG  -I'/Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library/Rcpp/include' -I/opt/R/x86_64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c nd.c -o nd.o\nnd.c:24:10: fatal error: 'S.h' file not found\n#include \"S.h\"\n         ^~~~~\n1 error generated.\nmake: *** [nd.o] Error 1\nERROR: compilation failed for package ‘scalop’\n* removing ‘/Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library/scalop’\n\nI am writing to ask if anyone knows enough about this output to know what to do to fix the \"fatal error, 'S.h' file not found\" error, which ultimately kills the download.\nSeveral people have reached out to the author, as per the issues posted on scalop; specifically issues 4 and 5, but no reply. Additionally, posting the error message into google does not return useful hits, so far as I can see.\nFinally, I am happy to provide any and all necessary info; e.g. sessionInfo(), R version (4.3) Mac OS (11.7) etc.\nHelp me Stack Overflow-Kenobi, you're my only hope.\n",
"AnswerId": "76387609",
"AnswerBody": "The \"S.h\" headers file is from the \"S\" language (the precursor to R); replacing \"S.h\" with \"R.h\" fixes the 'cant find S.h' error, but causes other issues. Clearly this package is not being maintained :(\nI've forked the repository and made a couple of changes to the source code (commits fe15cf9 and ab9fe5c). I successfully installed both the scalop and infercna packages via Bioconductor, but there are a lot of warnings when they compile. I used gcc to compile them, rather than Apple Clang, with these flags:\ncat ~/.R/Makevars\nLOC=/usr/local/gfortran\nCC=$(LOC)/bin/gcc -fopenmp\nCXX=$(LOC)/bin/g++ -fopenmp\nCXX11=$(LOC)/bin/g++ -fopenmp\n\nCFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe\nCXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipe\nLDFLAGS=-L$(LOC)/lib -Wl,-rpath,$(LOC)/lib,-L/usr/local/lib\nCPPFLAGS=-I$(LOC)/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/usr/local/include\n\nFLIBS=-L/usr/local/gfortran/lib/gcc/x86_64-apple-darwin19/10.2.0 -L/usr/local/gfortran/lib -lgfortran -lquadmath -lm\nCXX1X=/usr/local/gfortran/bin/g++\nCXX98=/usr/local/gfortran/bin/g++\nCXX11=/usr/local/gfortran/bin/g++\nCXX14=/usr/local/gfortran/bin/g++\nCXX17=/usr/local/gfortran/bin/g++\n\nIf you have problems installing the scalop package from source using Apple Clang, and you have an intel processor, my instructions for compiling R packages from source are here: https://stackoverflow.com/a/65334247/12957340\nIf you have an Apple silicon processor, you can try the instructions here: https://stackoverflow.com/a/68275558/12957340\n\nThis is how I installed the packages:\ninstall.packages(\"BiocManager\")\nlibrary(BiocManager)\nBiocManager::install(\"Homo.sapiens\")\nBiocManager::install(\"jpmam1/scalop\") # my forked copy\nBiocManager::install(\"jlaffy/infercna\")\n\nThe example from the vignette runs, but some of the functions no longer work as expected:\nlibrary(infercna)\n#> \n#> \n#> Warning: replacing previous import 'AnnotationDbi::select' by 'dplyr::select'\n#> when loading 'scalop'\n#> \n#> Attaching package: 'infercna'\n#> The following object is masked from 'package:graphics':\n#> \n#>     clip\nset.seed(1014)\nuseGenome('hg19')\n#> Genome has been set to hg19\nretrieveGenome()\n#> Retrieving: hg19\n#> # A tibble: 33,575 × 8\n#>    symbol     start_position end_position chromosome_name arm   band   strand\n#>    <chr>               <dbl>        <dbl> <fct>           <fct> <chr>   <int>\n#>  1 DDX11L1             11869        14412 1               1p    p36.33      1\n#>  2 WASH7P              14363        29806 1               1p    p36.33     -1\n#>  3 MIR1302-11          29554        31109 1               1p    p36.33      1\n#>  4 FAM138A             34554        36081 1               1p    p36.33     -1\n#>  5 OR4G4P              52473        54936 1               1p    p36.33      1\n#>  6 OR4G11P             62948        63887 1               1p    p36.33      1\n#>  7 OR4F5               69091        70008 1               1p    p36.33      1\n#>  8 CICP27             131025       134836 1               1p    p36.33      1\n#>  9 RNU6-1100P         157784       157887 1               1p    p36.33     -1\n#> 10 CICP7              329431       332236 1               1p    p36.33     -1\n#> # ℹ 33,565 more rows\n#> # ℹ 1 more variable: ensembl_gene_id <chr>\nm = useData(mgh125)\ndim(m)\n#> [1] 8556 1266\nrange(m)\n#> [1]  0.000 15.328\nlengths(refCells)\n#> oligodendrocytes      macrophages \n#>              219              707\n\ncna = infercna(m = m, refCells = refCells, n = 5000, noise = 0.1, isLog = TRUE, verbose = FALSE)\ncnaM = cna[, !colnames(cna) %in% unlist(refCells)]\n\ncnaScatterPlot(cna = cna,\n               signal.threshold = NULL,\n               main = 'Default')\n\n\n\nobj = cnaPlot(cna = cna,\n              order.cells = TRUE,\n              subtitle = 'Copy-Number Aberrations in a patient with Glioblastoma')\n#> Error in if (class(x) == \"matrix\") {: the condition has length > 1\n\nDepending on your use-case, you'll probably need to make further changes to the source code to get your desired output. If you have further errors/questions please post them in the comments and I'll take a look at them when I have some time.\n\nsessionInfo()\n#> R version 4.3.0 (2023-04-21)\n#> Platform: x86_64-apple-darwin20 (64-bit)\n#> Running under: macOS Ventura 13.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n#> \n#> locale:\n#> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n#> \n#> time zone: Australia/Melbourne\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#> [1] infercna_1.0.0\n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.3.0                          \n#>   [2] BiocIO_1.10.0                          \n#>   [3] bitops_1.0-7                           \n#>   [4] ggplotify_0.1.0                        \n#>   [5] filelock_1.0.2                         \n#>   [6] tibble_3.2.1                           \n#>   [7] R.oo_1.25.0                            \n#>   [8] polyclip_1.10-4                        \n#>   [9] graph_1.78.0                           \n#>  [10] reprex_2.0.2                           \n#>  [11] XML_3.99-0.14                          \n#>  [12] lifecycle_1.0.3                        \n#>  [13] rstatix_0.7.2                          \n#>  [14] edgeR_3.42.4                           \n#>  [15] Homo.sapiens_1.3.1                     \n#>  [16] lattice_0.21-8                         \n#>  [17] MASS_7.3-60                            \n#>  [18] OrganismDbi_1.42.0                     \n#>  [19] backports_1.4.1                        \n#>  [20] magrittr_2.0.3                         \n#>  [21] limma_3.56.1                           \n#>  [22] plotly_4.10.1                          \n#>  [23] rmarkdown_2.22                         \n#>  [24] yaml_2.3.7                             \n#>  [25] metapod_1.8.0                          \n#>  [26] cowplot_1.1.1                          \n#>  [27] DBI_1.1.3                              \n#>  [28] RColorBrewer_1.1-3                     \n#>  [29] abind_1.4-5                            \n#>  [30] zlibbioc_1.46.0                        \n#>  [31] Rtsne_0.16                             \n#>  [32] R.cache_0.16.0                         \n#>  [33] GenomicRanges_1.52.0                   \n#>  [34] purrr_1.0.1                            \n#>  [35] mixtools_2.0.0                         \n#>  [36] R.utils_2.12.2                         \n#>  [37] msigdbr_7.5.1                          \n#>  [38] ggraph_2.1.0                           \n#>  [39] BiocGenerics_0.46.0                    \n#>  [40] RCurl_1.98-1.12                        \n#>  [41] styler_1.10.0                          \n#>  [42] yulab.utils_0.0.6                      \n#>  [43] tweenr_2.0.2                           \n#>  [44] rappdirs_0.3.3                         \n#>  [45] GenomeInfoDbData_1.2.10                \n#>  [46] IRanges_2.34.0                         \n#>  [47] S4Vectors_0.38.1                       \n#>  [48] enrichplot_1.20.0                      \n#>  [49] ggrepel_0.9.3                          \n#>  [50] irlba_2.3.5.1                          \n#>  [51] tidytree_0.4.2                         \n#>  [52] dqrng_0.3.0                            \n#>  [53] DelayedMatrixStats_1.22.0              \n#>  [54] codetools_0.2-19                       \n#>  [55] DelayedArray_0.26.3                    \n#>  [56] scuttle_1.10.1                         \n#>  [57] DOSE_3.26.1                            \n#>  [58] xml2_1.3.4                             \n#>  [59] ggforce_0.4.1                          \n#>  [60] tidyselect_1.2.0                       \n#>  [61] aplot_0.1.10                           \n#>  [62] farver_2.1.1                           \n#>  [63] ScaledMatrix_1.8.1                     \n#>  [64] viridis_0.6.3                          \n#>  [65] matrixStats_0.63.0                     \n#>  [66] stats4_4.3.0                           \n#>  [67] BiocFileCache_2.8.0                    \n#>  [68] GenomicAlignments_1.36.0               \n#>  [69] jsonlite_1.8.4                         \n#>  [70] BiocNeighbors_1.18.0                   \n#>  [71] tidygraph_1.2.3                        \n#>  [72] survival_3.5-5                         \n#>  [73] segmented_1.6-4                        \n#>  [74] tools_4.3.0                            \n#>  [75] progress_1.2.2                         \n#>  [76] treeio_1.24.1                          \n#>  [77] TxDb.Hsapiens.UCSC.hg19.knownGene_3.2.2\n#>  [78] Rcpp_1.0.10                            \n#>  [79] glue_1.6.2                             \n#>  [80] gridExtra_2.3                          \n#>  [81] xfun_0.39                              \n#>  [82] qvalue_2.32.0                          \n#>  [83] MatrixGenerics_1.12.0                  \n#>  [84] GenomeInfoDb_1.36.0                    \n#>  [85] dplyr_1.1.2                            \n#>  [86] withr_2.5.0                            \n#>  [87] BiocManager_1.30.20                    \n#>  [88] fastmap_1.1.1                          \n#>  [89] bluster_1.10.0                         \n#>  [90] fansi_1.0.4                            \n#>  [91] rsvd_1.0.5                             \n#>  [92] caTools_1.18.2                         \n#>  [93] digest_0.6.31                          \n#>  [94] R6_2.5.1                               \n#>  [95] gridGraphics_0.5-1                     \n#>  [96] colorspace_2.1-0                       \n#>  [97] GO.db_3.17.0                           \n#>  [98] biomaRt_2.56.0                         \n#>  [99] RSQLite_2.3.1                          \n#> [100] R.methodsS3_1.8.2                      \n#> [101] utf8_1.2.3                             \n#> [102] tidyr_1.3.0                            \n#> [103] generics_0.1.3                         \n#> [104] data.table_1.14.8                      \n#> [105] rtracklayer_1.60.0                     \n#> [106] prettyunits_1.1.1                      \n#> [107] graphlayouts_1.0.0                     \n#> [108] httr_1.4.6                             \n#> [109] htmlwidgets_1.6.2                      \n#> [110] S4Arrays_1.0.4                         \n#> [111] scatterpie_0.2.0                       \n#> [112] pkgconfig_2.0.3                        \n#> [113] gtable_0.3.3                           \n#> [114] blob_1.2.4                             \n#> [115] SingleCellExperiment_1.22.0            \n#> [116] XVector_0.40.0                         \n#> [117] shadowtext_0.1.2                       \n#> [118] clusterProfiler_4.8.1                  \n#> [119] htmltools_0.5.5                        \n#> [120] carData_3.0-5                          \n#> [121] fgsea_1.26.0                           \n#> [122] scalop_1.1.0                           \n#> [123] RBGL_1.76.0                            \n#> [124] scales_1.2.1                           \n#> [125] Biobase_2.60.0                         \n#> [126] png_0.1-8                              \n#> [127] scran_1.28.1                           \n#> [128] ggfun_0.0.9                            \n#> [129] knitr_1.43                             \n#> [130] rstudioapi_0.14                        \n#> [131] reshape2_1.4.4                         \n#> [132] rjson_0.2.21                           \n#> [133] nlme_3.1-162                           \n#> [134] curl_5.0.0                             \n#> [135] org.Hs.eg.db_3.17.0                    \n#> [136] cachem_1.0.8                           \n#> [137] stringr_1.5.0                          \n#> [138] parallel_4.3.0                         \n#> [139] HDO.db_0.99.1                          \n#> [140] AnnotationDbi_1.62.1                   \n#> [141] restfulr_0.0.15                        \n#> [142] pillar_1.9.0                           \n#> [143] grid_4.3.0                             \n#> [144] vctrs_0.6.2                            \n#> [145] ggpubr_0.6.0                           \n#> [146] BiocSingular_1.16.0                    \n#> [147] car_3.1-2                              \n#> [148] beachmat_2.16.0                        \n#> [149] dbplyr_2.3.2                           \n#> [150] cluster_2.1.4                          \n#> [151] evaluate_0.21                          \n#> [152] zeallot_0.1.0                          \n#> [153] GenomicFeatures_1.52.0                 \n#> [154] locfit_1.5-9.7                         \n#> [155] cli_3.6.1                              \n#> [156] compiler_4.3.0                         \n#> [157] Rsamtools_2.16.0                       \n#> [158] rlang_1.1.1                            \n#> [159] crayon_1.5.2                           \n#> [160] ggsignif_0.6.4                         \n#> [161] plyr_1.8.8                             \n#> [162] fs_1.6.2                               \n#> [163] stringi_1.7.12                         \n#> [164] viridisLite_0.4.2                      \n#> [165] BiocParallel_1.34.2                    \n#> [166] babelgene_22.9                         \n#> [167] munsell_0.5.0                          \n#> [168] Biostrings_2.68.1                      \n#> [169] lazyeval_0.2.2                         \n#> [170] GOSemSim_2.26.0                        \n#> [171] Matrix_1.5-4.1                         \n#> [172] patchwork_1.1.2                        \n#> [173] hms_1.1.3                              \n#> [174] sparseMatrixStats_1.12.0               \n#> [175] bit64_4.0.5                            \n#> [176] ggplot2_3.4.2                          \n#> [177] statmod_1.5.0                          \n#> [178] KEGGREST_1.40.0                        \n#> [179] SummarizedExperiment_1.30.1            \n#> [180] kernlab_0.9-32                         \n#> [181] igraph_1.4.3                           \n#> [182] broom_1.0.4                            \n#> [183] memoise_2.0.1                          \n#> [184] ggtree_3.8.0                           \n#> [185] fastmatch_1.1-3                        \n#> [186] bit_4.0.5                              \n#> [187] downloader_0.4                         \n#> [188] gson_0.1.0                             \n#> [189] ape_5.7-1\n\nCreated on 2023-06-02 with reprex v2.0.2\n"
},
{
"QuestionId": "76383296",
"QuestionTitle": "Broadcast receiver change UI",
"QuestionBody": "I have searched widely but not found an answer to this question:\nIs it possible to change a variable in a Jetpack compose user interface from a broadcast receiver?\n",
"AnswerId": "76385696",
"AnswerBody": "You can't modify your compose ui from Broadcast receiver directly. Instead, your Broadcast receiver should change some data in your data layer - datastore, preferences, database or just in memory in some Repository singleton class. Then you should make this data observable and observe them from your compose ui.\n"
},
{
"QuestionId": "76389017",
"QuestionTitle": "Automatic template argument deduction fails for return type",
"QuestionBody": "I have a template function\ntemplate <typename B, typename A>\nB func(A x) {/*do something*/}\n\nAnd in my code I am doing something like\nuint32_t a[6] = {1,2,3,4,5,6};\nuint64_t b = func(a);\n\nBut this fails with\ntest.cxx:10:16: error: no matching function for call to 'func'\n  uint64_t b = func(a);\n               ^~~~~~~~~\ntest.cxx:5:6: note: candidate template ignored: couldn't infer template argument 'B'\n\nSo it seems that the type of a is automatically deduced but the type of b not. I can specify it (uint64_t b = <uint64_t>func(a);), sure, but why the compiler is not able to deduce it?\nEDIT\nFollowing comments also posting the content of the function (which is actually taking 2 other parameters)\ntemplate <typename B, typename A>\nB bit_slice(A words[], int start, int end) {\n  int wordSize = sizeof(A)*8;\n  B s = 0;\n  int n = end / wordSize;\n  for(int i= 0; i <= n; ++i){\n    s = (s << wordSize) + words[i];\n  }\n  s >>= (n+1) * wordSize - (end+1);\n  B mask = (((T)1) << (end - start + 1))- 1;\n  s &= mask;\n  return s;\n};\n\nSo basically a bit slicing of an array (representing something).\n",
"AnswerId": "76389067",
"AnswerBody": "If the argument cannot be deduced from func(a); then it cannot be deduced. auto return type can be deduced from the return statement, but not here. What you assign the return value to is not relevant. It simply doesnt work like this.\nIt does work however with a templated conversion:\n#include <iostream>\n#include <cstdio>\n\ntemplate <typename A,typename B>\nA the_implementation(B x) { return x*2; }\n\ntemplate <typename B>\nstruct proxy {\n    B b;\n    template <typename A>\n    operator A() {\n        return the_implementation<A>(b);\n    }\n};\n\ntemplate<typename B>\nproxy<B> func(B x) {\n    return {x};\n}\n\n\nint main() { \n    int x = 42;\n    int y = func(x);\n}\n\nfunc returns a proxy<B>, B is deduced from x. Then proxy<B> can be converted to int via its conversion operator, which calls the actual function (because only now A and B have been deduced).\nHowever, I have doubts that the above is a good idea in your code. Consider to write instead:\nauto b = func<uint64_t>(a);\n\n"
},
{
"QuestionId": "76381199",
"QuestionTitle": "How to increase allocated memory in a k3d cluster",
"QuestionBody": "I am on a learning curve with Kubernetes and recently started working with K3D. I am trying to deploy my project on a local K3D cluster. When I created a pod to run an application, I saw it hang in the pending state for some time, and below is the kubectl describe pod output (events).\n\napplication.yaml file's resource requirements are as below\nresources:\n        requests:\n          memory: \"4Gi\"\n          cpu: \"2\"\n\nThe output of kubectl decribe node is as below: I assumed this was due to the fact that my node has around 3 GB of memory and the app is requesting 4 GB. I am getting the error in Pod. I looked for an answer to increase the memory but had no luck so far.\n\nHow can I increase the memory to get the application up and running? If I reduce the app.yaml resource to --> memory: 3 Gi or 2 Gi, the app starts running, but the actual functionality of the app is not there. Whenever I try to do something in the app, it then gives me Not enough CPU and/or memory is available for error in my application.\nI am running this on Linux and k3d version k3d version v5.5.1 k3s version v1.26.4-k3s1 (default)\nThanks!\n",
"AnswerId": "76387620",
"AnswerBody": "Assuming the machine where you are running has more than 3GB of RAM (you can check by running lsmem or free), you can try re-creating the Kubernetes cluster using k3d, by passing an explicit memory limit. E.g.\nk3d cluster create --agents-memory 8G\n\nOr if you are doing a multi-node deployment, by adding a node with sufficient memory, e.g.\nk3d node create --memory 8G\n\nBut when running on Linux, you typically would not have a memory limit applied to the Kubernetes cluster, unless that limit was requested explicitly. So I would suggest checking your previous cluster creation commands, or double-check any scripts you may have used.\nIf you are running Linux, another option is to run k3s directly, without k3d. That is unlikely to see limits applied to it as well.\nFinally, an alternative is to use an ephemeral cloud environment for this type of testing. For example, using https://namespace.so you can create a Kubernetes cluster with 8GB of RAM in a few seconds, and use it to test your application.\n"
},
{
"QuestionId": "76382660",
"QuestionTitle": "update PyqtGraph plot in PyQt5",
"QuestionBody": "I'm writing a small interface in PyQT5 that has a graph that I use PyQtGraph to create. The graph starts to be drawn by pressing the \"Start\" button, and at first everything looks fine:\nBut over time and an increase in the number of points, the entire graph shrinks to the width of the screen and becomes not informative:\n\nIn this regard, there are two questions:\nHow can I make the window not try to fit the whole graph at once, squeezing it, but rather move behind it, showing the latest data?\nNow the data comes in once a second and I redraw the graph every time. Is it possible to make it a partial update so that I just pass only new data into it?\nfrom pyqtgraph import PlotWidget\nimport pyqtgraph\nfrom PyQt5 import QtCore\nfrom PyQt5.QtCore import Qt, QThread, QTimer, QObject, pyqtSignal, QTimer\nfrom PyQt5.QtWidgets import QHBoxLayout, QMainWindow,  QPushButton, QVBoxLayout, QWidget, QApplication\nimport sys\nimport random\n\n\ndef get_kl_test():\n    choices = [50, 50, 50, 51, 51, 51, 52, 52, 52]\n    list = [random.choice(choices) for i in range(11)]\n    return list\n\n\ndef get_iopd_test():\n    choices = [40, 40, 40, 50, 50, 50, 60, 60, 60]\n    return random.choice(choices)\n\n\nclass Graph(PlotWidget):\n    def __init__(self):\n        super().__init__()\n        self.setBackground('white')\n        self.addLegend()\n        self.showGrid(x=True, y=True)\n        self.setYRange(0, 255, padding=0)\n\n\nclass ReadingWorker(QObject):\n    update_graph = pyqtSignal(list, list, list, list)\n\n    def __init__(self):\n        super().__init__()\n        self.time_from_start = 0\n        self.time_values = []\n        self.green_values = []\n        self.blue_values = []\n        self.red_values = []\n\n    def run(self):\n        self.read()\n        self.update_time()\n\n    def read(self):\n        ipd_values = get_kl_test()\n        iopd_value = get_iopd_test()\n\n        self.green_values.append(ipd_values[0])\n        self.blue_values.append(ipd_values[1])\n        self.red_values.append(iopd_value)\n        self.time_values.append(self.time_from_start)\n\n        self.update_graph.emit(\n            self.green_values, self.blue_values, self.red_values, self.time_values)\n        QTimer.singleShot(1000, self.read)\n\n    def update_time(self):\n        self.time_from_start += 1\n        QTimer.singleShot(1000, self.update_time)\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n        self.central_widget = QWidget(self)\n        self.setGeometry(50, 50, 1300, 700)\n        self.setCentralWidget(self.central_widget)\n        self.layout_main_window = QVBoxLayout()\n        self.central_widget.setLayout(self.layout_main_window)\n\n        # конфигурация тулбара\n        self.layout_toolbar = QHBoxLayout()\n        self.layout_toolbar.addStretch(1)\n        self.btn_start = QPushButton(\"Старт\")\n        self.btn_start.clicked.connect(self.start)\n        self.layout_toolbar.addWidget(self.btn_start)\n        self.layout_main_window.addLayout(self.layout_toolbar)\n\n        # конфигурация графика\n        self.graph = Graph()\n        self.layout_main_window.addWidget(self.graph)\n\n    def start(self):\n        self.reading_thread = QThread(parent=self)\n        self.reading_widget = ReadingWorker()\n        self.reading_widget.moveToThread(self.reading_thread)\n        self.reading_widget.update_graph.connect(self.draw_graph)\n        self.reading_thread.started.connect(self.reading_widget.run)\n        self.reading_thread.start()\n\n    @QtCore.pyqtSlot(list, list, list, list)\n    def draw_graph(self, ipd_1_values, ipd_2_values, iopd_values, time_values):\n        \n        self.graph.plotItem.clearPlots()\n        pen_ipd_1 = pyqtgraph.mkPen(color='green', width=4)\n        pen_ipd_2 = pyqtgraph.mkPen(color='blue', width=4, style=Qt.DashDotLine)\n        pen_iopd = pyqtgraph.mkPen(color='red', width=4, style=Qt.DashLine)\n\n        line_ipd_1 = self.graph.plotItem.addItem(pyqtgraph.PlotCurveItem(\n            time_values, \n            ipd_1_values,\n            pen=pen_ipd_1,\n            name='1'\n        ))\n        line_ipd_2 = self.graph.plotItem.addItem(pyqtgraph.PlotCurveItem(\n            time_values, \n            ipd_2_values,\n            pen=pen_ipd_2,\n            name='2'\n        ))\n        line_iopd = self.graph.plotItem.addItem(pyqtgraph.PlotCurveItem(\n            time_values, \n            iopd_values,\n            pen=pen_iopd,\n            name='3'\n        ))\n\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    app.setStyle('Fusion')\n    main_window = MainWindow()\n    main_window.show()\n    sys.exit(app.exec_())\n\n",
"AnswerId": "76385756",
"AnswerBody": "\nstep 1: add the PlotCurveItems as members of Mainwindow, set them up in the constructor, so you can access them later\nstep 2: in the draw_graph function use the getData() and setData() functions of the PlotcurveItems, update them\nstep 3: if you have enough x-values set the xRange, so not all data is shown, I use a maximal xRange of 20 here (self.window_size)\n\nIn the code below I only use the last entry in your lists (e.g. ipd_1_values[-1]), you can just pass scalars and remove the [-1].\nAlso I used import numpy as np for the np.append().\n    class MainWindow(QMainWindow):\n        def __init__(self):\n            super().__init__()\n            self.central_widget = QWidget(self)\n            self.setGeometry(50, 50, 1300, 700)\n            self.setCentralWidget(self.central_widget)\n            self.layout_main_window = QVBoxLayout()\n            self.central_widget.setLayout(self.layout_main_window)\n\n            # конфигурация тулбара\n            self.layout_toolbar = QHBoxLayout()\n            self.layout_toolbar.addStretch(1)\n            self.btn_start = QPushButton(\"Старт\")\n            self.btn_start.clicked.connect(self.start)\n            self.layout_toolbar.addWidget(self.btn_start)\n            self.layout_main_window.addLayout(self.layout_toolbar)\n\n            # конфигурация графика\n            self.graph = Graph()\n            self.layout_main_window.addWidget(self.graph)\n\n            self.setup_graphs() # step 1\n            self.window_size = 20 # step 3\n\n        def start(self):\n            self.reading_thread = QThread(parent=self)\n            self.reading_widget = ReadingWorker()\n            self.reading_widget.moveToThread(self.reading_thread)\n            self.reading_widget.update_graph.connect(self.draw_graph)\n            self.reading_thread.started.connect(self.reading_widget.run)\n            self.reading_thread.start()\n\n        def setup_graphs(self):\n            pen_ipd_1 = pyqtgraph.mkPen(color='green', width=4)\n            pen_ipd_2 = pyqtgraph.mkPen(color='blue', width=4, style=Qt.DashDotLine)\n            pen_iopd = pyqtgraph.mkPen(color='red', width=4, style=Qt.DashLine)\n            self.line_ipd_1 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_1, name='1')\n            self.line_ipd_2 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_2, name='2')\n            self.line_iopd = pyqtgraph.PlotCurveItem([], [], pen=pen_iopd, name='3')\n            self.graph.plotItem.addItem(self.line_ipd_1)\n            self.graph.plotItem.addItem(self.line_ipd_2)\n            self.graph.plotItem.addItem(self.line_iopd)\n\n        @QtCore.pyqtSlot(list, list, list, list)\n        def draw_graph(self, ipd_1_values, ipd_2_values, iopd_values, time_values): # step 2\n            x, y = self.line_ipd_1.getData()\n            x = np.append(x, time_values[-1])\n            self.line_ipd_1.setData(y=np.append(y, ipd_1_values[-1]), x=x)\n            _, y = self.line_ipd_2.getData()\n            self.line_ipd_2.setData(y=np.append(y, ipd_2_values[-1]), x=x)\n            _, y = self.line_iopd.getData()\n            self.line_iopd.setData(y=np.append(y, iopd_values[-1]), x=x)\n            if (len(x)>0 and x[-1]-x[0]>self.window_size): # step 3\n                self.graph.plotItem.setXRange(x[-1]-self.window_size, x[-1])\n\n"
},
{
"QuestionId": "76388928",
"QuestionTitle": "Can not update @State variable via delegate set in View.init()",
"QuestionBody": "The following is a minimum example code with the problem.\nstruct TestView: View {\n    @State var text = \"Hello\"\n    let useCase = TestUseCase()\n\n    init() {\n        useCase.output = self\n    }\n\n    var body: some View {\n        Text(text)\n            .onAppear {\n                // ① useCase.output = self\n                useCase.show()\n            }\n    }\n}\nextension TestView: TestUseCaseOutput {\n    func showText(text: String) {\n        self.text = text\n    }\n}\n\nclass TestUseCase {\n    var output: TestUseCaseOutput?\n    func show() {\n        output?.showText(text: \"Changed\")\n    }\n}\nprotocol TestUseCaseOutput {\n    func showText(text: String)\n}\n\nThis code changes the text from \"Hello\" to \"Changed\" when the view is displayed, but the change is not reflected. The showText method was called, but it had no effect. I also found that if I set the delegate at ①, the text was updated correctly.\nCan anyone tell me the cause of this problem?\n",
"AnswerId": "76389086",
"AnswerBody": "SwiftUI views are structs, and therefore immutable.  Whenever a SwiftUI changes, a new instance of that view struct is created.\nWhen you update text, SwiftUI needs to create a new instance of TestView.  But, the new instance  has text set to Hello (and it was also have a new instance of TestUseCase) so you don't see any change.\nThe sequence of events is:\n\nYou create an instance of TestView - This is initialised with text = \"Hello\"\nYou update text which triggers SwiftUI to recreate TestView\nThe newly created instance of TestView is initialised with text = \"Hello\"`\n\nIn SwiftUI no object should ever need to hold a reference to a View.\ninit() {\n    useCase.output = self\n}\n\nThe self you store in your TestUseCase instance will be thrown away as soon as the view is updated.  It simply isn't useful to try and hold references to SwiftUI views.\nYou should structure your code so that views respond to changes in your model (Via @Published for example).  Your model should never try and update a view directly.\n"
},
{
"QuestionId": "76387595",
"QuestionTitle": "react-number-format Showing Format On inserting value",
"QuestionBody": "react-number-format Showing Format On inserting value\nI have used this package for the Phone Input format\nimport { PatternFormat } from 'react-number-format';\n\n<PatternFormat \n   value={value} \n   className='form-control'   \n   format=\"(###) ###-####\" \n />\n\nDue to this format whenever I add any single value, The formatted value show in the input. before the value reaches there.\n\nI want to show the value in This format but when the value reaches there,\nwhen I have entered only a single value it should not show that '-' there.\nI want something like below\n\nThis is the link to the npm package I am using:\nhttps://s-yadav.github.io/react-number-format/docs/intro\n",
"AnswerId": "76387683",
"AnswerBody": "You could build the pattern diffrent if the value reaches said length then change   (empty space) for a - (dash)\nimport { PatternFormat } from 'react-number-format';\n\nlet pattern;\nif (value.length >= 9) {\n    pattern = \"(###) ###-####\";\n} else {\n    pattern = \"(###) ### ####\";\n}\n\n<PatternFormat \n   value={value} \n   className='form-control'   \n   format={pattern} \n />\n\n\n"
},
{
"QuestionId": "76387605",
"QuestionTitle": "Compiling C++ code using libssh library through vcpkg",
"QuestionBody": "I installed libssh through vcpkg on my Windows 8.1 machine.\nvcpkg install libssh\n\nNow I am trying to compile my c++ code making use of libssh.\n#include <libssh/libssh.h>\n#include <stdlib.h>\n \nint main()\n{\n  ssh_session my_ssh_session = ssh_new();\n  if (my_ssh_session == NULL)\n    exit(-1);\n  ...\n  ssh_free(my_ssh_session);\n}\n\nBut I am receiving following error.\nD:\\remoteDesktopTimeZone>gcc sample.cpp -o sampl\nsample.cpp:1:10: fatal error: libssh/libssh.h: No such file or directory\n    1 | #include <libssh/libssh.h>\n      |          ^~~~~~~~~~~~~~~~~\ncompilation terminated.\n\n",
"AnswerId": "76387686",
"AnswerBody": "First, you should ensure that you are installing libraries with correct \"triplet\" matching your compiler and architecture.\nI don't know if your gcc is MingW or Cygwin.\nSee instructions here.\nSecond, you should either use CMake as described here, or manually point the compiler where to find the library headers and static libraries using the -I and -L command line flags.\n"
},
{
"QuestionId": "76388987",
"QuestionTitle": "How can I sort a JSON array by a key inside of it?",
"QuestionBody": "I have an unknown number of items and item categories in a json array like so:\n[\n    {\n        \"x_name\": \"Some Name\",\n        \"x_desc\": \"Some Description\",\n        \"id\": 1,\n        \"category\": \"Email\"\n    },\n    {\n        \"x_name\": \"Another name here\",\n        \"x_desc\": \"Another description\",\n        \"id\": 2,\n        \"category\": \"Email\"\n    },\n    {\n        \"x_name\": \"Random Name\",\n        \"x_desc\": \"Random Description\",\n        \"id\": 3,\n        \"category\": \"Email\"\n    },\n    {\n        \"x_name\": \"Owner Meetings\",\n        \"x_desc\": \"Total count\",\n        \"id\": 167,\n        \"category\": \"Owner Specific\"\n    },\n    {\n        \"x_name\": \"Owner Tasks\",\n        \"x_desc\": \"Total count of tasks\",\n        \"id\": 168,\n        \"category\": \"Owner Specific\"\n    },\n    {\n        \"x_name\": \"Owner Calls\",\n        \"x_desc\": \"Total count of calls\",\n        \"id\": 169,\n        \"category\": \"Owner Specific\"\n    },\n    {\n        \"x_name\": \"Overall Total Views\",\n        \"x_desc\": \"The total views\",\n        \"id\": 15,\n        \"category\": \"Totals Report\"\n    }\n    ......\n]\n\nI need to group these JSONObjects based on the property \"category\".\nI've seen similar examples in JS using the reduce function but couldn't get a similar python solution. How can I efficiently do this in Python?\nThe desired outcome would be:\n{\n    \"category\": \"Email\",\n    \"points\": [\n        {\n            \"x_name\": \"Some Name\",\n            \"x_desc\": \"Some Description\",\n            \"id\": 1,\n            \"category\": \"Email\"\n        },\n        {\n            \"x_name\": \"Another name here\",\n            \"x_desc\": \"Another description\",\n            \"id\": 2,\n            \"category\": \"Email\"\n        },\n        {\n            \"x_name\": \"Random Name\",\n            \"x_desc\": \"Random Description\",\n            \"id\": 3,\n            \"category\": \"Email\"\n        }\n    ]\n}\n\nand then:\n{\n    \"category\": \"Owner Specific\",\n    \"points\": [\n        {\n            \"x_name\": \"Owner Meetings\",\n            \"x_desc\": \"Total count\",\n            \"id\": 167,\n            \"category\": \"Owner Specific\"\n        },\n        {\n            \"x_name\": \"Owner Tasks\",\n            \"x_desc\": \"Total count of tasks\",\n            \"id\": 168,\n            \"category\": \"Owner Specific\"\n        },\n        {\n            \"x_name\": \"Owner Calls\",\n            \"x_desc\": \"Total count of calls\",\n            \"id\": 169,\n            \"category\": \"Owner Specific\"\n        }\n    ]\n}\n\nand so on.\nI do not know the value of the key \"category\" or the number of \"categories\" in the original JSON array.\n",
"AnswerId": "76389120",
"AnswerBody": "Here is a small script I made for that.\nScript\ndef sort_by_category():\n    categories = {}\n    output = []\n\n    a = [\n        {\n            \"x_name\": \"Some Name\",\n            \"x_desc\": \"Some Description\",\n            \"id\": 1,\n            \"category\": \"Email\",\n        },\n        ...\n    ]\n\n    for i in a:\n        if i[\"category\"] in categories:\n            categories[i[\"category\"]].append(i)\n        else:\n            categories[i[\"category\"]] = [i]\n\n    for c in categories:\n        o = {\"category\": c, \"points\": categories[c]}\n        output.append(o)\n    return(output)\n\nIt browses your a array and creates another array based on categories, then it formats the output as you asked.\nOutput\n[\n    {\n        \"category\":\"Email\",\n        \"points\":[\n            {\n                \"x_name\":\"Some Name\",\n                \"x_desc\":\"Some Description\",\n                \"id\":1,\n                \"category\":\"Email\"\n            },\n            {\n                \"x_name\":\"Another name here\",\n                \"x_desc\":\"Another description\",\n                \"id\":2,\n                \"category\":\"Email\"\n            },\n            {\n                \"x_name\":\"Random Name\",\n                \"x_desc\":\"Random Description\",\n                \"id\":3,\n                \"category\":\"Email\"\n            }\n        ]\n    },\n    {\n        \"category\":\"Owner Specific\",\n        \"points\":[\n            {\n                \"x_name\":\"Owner Meetings\",\n                \"x_desc\":\"Total count\",\n                \"id\":167,\n                \"category\":\"Owner Specific\"\n            },\n            {\n                \"x_name\":\"Owner Tasks\",\n                \"x_desc\":\"Total count of tasks\",\n                \"id\":168,\n                \"category\":\"Owner Specific\"\n            },\n            {\n                \"x_name\":\"Owner Calls\",\n                \"x_desc\":\"Total count of calls\",\n                \"id\":169,\n                \"category\":\"Owner Specific\"\n            }\n        ]\n    },\n    {\n        \"category\":\"Totals Report\",\n        \"points\":[\n            {\n                \"x_name\":\"Overall Total Views\",\n                \"x_desc\":\"The total views\",\n                \"id\":15,\n                \"category\":\"Totals Report\"\n            }\n        ]\n    }\n]\n\n"
},
{
"QuestionId": "76387588",
"QuestionTitle": "Casting a void pointer to a 2D String array pointer (C/CPP)",
"QuestionBody": "I'm using a library which requires a function with a void* pointer as a parameter. I have a 2D string array and I want to pass that array through that parameter and extract it inside the function. I successfully passed the array as a pointer but I don't know how to convert that pointer back to my array.\nThis is my current code:\nString str_array[100][10];\n\nint callback(void* data) {\n\n  String* str_array_ptr[100][10] = (String* [100][10])data;\n\n  (*str_array_ptr)[0][0] = \"text\";\n\n  return 0;\n\n}\n\nvoid test() {\n  callback(&str_array);\n}\n\nHowever, when compiling, I obtain the following error message:\n\nerror: ISO C++ forbids casting to an array type 'String* [100][10]' [-fpermissive]\n\nPS: I'm trying to use the SQLite library's sqlite3_exec() function and store the result of a \"SELECT SQL query\" into a 2D string array.\nSQLite C Interface - One-Step Query Execution Interface\n",
"AnswerId": "76387690",
"AnswerBody": "You cannot cast a pointer to an array. Instead you access your array through another pointer. That pointer has type String (*)[10]. Like this\nString str_array[100][10];\n\nint callback(void* data) { \n\n    String (*str_array_ptr)[10] = (String (*)[10])data;\n\n    str_array_ptr[0][0] = \"text\"; // Note no '*'\n\n    return 0;\n\n}\n\nvoid test() {\n    callback(str_array); // Note no '&'\n}\n\nBoth the way you create the pointer, you don't need to use &, and the way you access the pointer, you don't need to use *, are also wrong in your code. See the code above for details.\nThe fundamental issue here (and maybe the issue you are misunderstanding) is the difference between String *x[10]; and String (*x)[10];. In the first case x is an array of 10 pointers to String, in the second case x is a pointer to an array of ten String. It's the second option that you want.\n"
},
{
"QuestionId": "76382813",
"QuestionTitle": "BizTalk 2020 with BTDF & Azure Pipelines - Application dependencies",
"QuestionBody": "Currently transitioning from BizTalk 2013r2 to 2020, and implementing Azure Pipelines to automate deployment with BTDF.\nSo far, we're able to deploy our Core applications, but we've just realised there are dependencies with the 'child applications' (applications that take schemas from the Core apps).\n\nHow should I refer to the Core application within Visual Studio in our dev environment (we used to reference the .dll from the local repos solution)\nHow can we configure BTDF and CI/CD pipelines to point to the correct application when deploying the child?\nWhat happens if we need to update the Core application via BTDF/Pipeline - we'll need to undeploy all child applications that reference it before we can deploy surely - can this be done via the BTDF config?\n\n",
"AnswerId": "76385918",
"AnswerBody": "No, I don't believe that BTDF can take care of that.\nYou should either.\nVersion increase your assembly version number of your Core Application and do a side by side deployment (e.g. leave the original ones in place).\nLater on when you need the newer version in the dependent application then reference the later DLL (and yes, just have the DLL as an external assembly in the solution).\nOr\nHave your Core Application Pipeline undeploy all the dependent applications, before undeploying the Core Application and deploying it, and then re-deploying all the dependent applications.\nMy preference would be for the first option, less complicated.\n"
},
{
"QuestionId": "76387658",
"QuestionTitle": "Nattable Display converter shifts columns when the table is scrolled horizontally",
"QuestionBody": "I have used a custom DisplayConverter on some columns of my Nattable.This displayconverter shows long values as hex strings.\nWhenever I scroll my Nattable horizontally, this converter shifts one/mulitple columns. This results in columns which show hex values to be shown in default numeral format. On the other hand, columns which should be showing numerals show hex values.\nIn the following images, the first image shows how it should be displayed, that is column number 2 and 7 should show hex values (these are just long values with my custom converter applied).\nWhen I scroll my table to the right, this converter is then applied to column number 3 and 8.\nDefault (as it should be)\nScrolled right \nI have applied my CustomDisplayConverter ( column override HEX_FORMAT) to certain columns. LinkerMapHexAddressDisplayConverter is the custom display converter which converts long values to hex strings for display.\n'columnLabelAccumulator.registerColumnOverrides(\n            pnames.indexOf(ILinkerMapConstants.PROP_KEY_SECTION_SIZE), NUMBER_FORMAT);//column 3\n    columnLabelAccumulator.registerColumnOverrides(\n            pnames.indexOf(ILinkerMapConstants.PROP_KEY_OBJECT_SIZE), NUMBER_FORMAT);//column 8\n\n    configRegistry.registerConfigAttribute(CellConfigAttributes.DISPLAY_CONVERTER,\n            new DefaultLongDisplayConverter(), DisplayMode.NORMAL, NUMBER_FORMAT);\n\n    columnLabelAccumulator.registerColumnOverrides(\n            pnames.indexOf(ILinkerMapConstants.PROP_KEY_SECTION_ADDRESS), HEX_FORMAT);//column 2\n    columnLabelAccumulator.registerColumnOverrides(\n            pnames.indexOf(ILinkerMapConstants.PROP_KEY_OBJECT_MODULE_ADDRESS),\n            HEX_FORMAT);//column 7\n\n    configRegistry.registerConfigAttribute(CellConfigAttributes.DISPLAY_CONVERTER,\n            new LinkerMapHexAddressDisplayConverter(), DisplayMode.NORMAL,\n            HEX_FORMAT);'\n\n",
"AnswerId": "76387707",
"AnswerBody": "This happens if you apply your custom labels (HEX_FORMAT in your case) on the ViewportLayer or above. If you have a strong relation on the structure, you should apply the labels on the DataLayer as there is no index-position conversion.\n"
},
{
"QuestionId": "76383599",
"QuestionTitle": "Getting SQLSTATE[23000] error with Laravel global scope in many-to-many relationship",
"QuestionBody": "Subject 1: I am using Laravel version 7 in my project, and in order to add a query to all my models in Laravel, I have added a global scope to all my models. In this way, all my models inherit from another model. The mentioned model is provided below.\nnamespace App\\Models;\n\nuse Illuminate\\Database\\Eloquent\\Builder;\n\nclass Model extends \\Illuminate\\Database\\Eloquent\\Model\n{\n    /**\n     * The \"booting\" method of the model.\n     * @return void\n     */\n    protected static function boot()\n    {\n        parent::boot();\n        if(!empty(Client::$Current_Token)) {\n            static::addGlobalScope('client_token', function (Builder $builder) {\n                $builder->where('client_token', Client::$Current_Token);\n            });\n        }\n    }\n}\n\nSubject 2: There is a model named \"user\" and a model named \"role\", and there is a many-to-many relationship between these 2 tables. Now, imagine that I want to retrieve all the roles associated with a user in the \"user\" model using the belongsToMany method, based on their relationship defined in the intermediate table.\n/**\n* The roles that belong to the user.\n*/\npublic function roles(): BelongsToMany\n{\n    return $this->belongsToMany(Role::class, 'role_user', 'user_id', 'role_id');\n}\n\nProblem: I encounter the following error: SQLSTATE\\[23000\\]: Integrity constraint violation: 1052 Column 'client_token' in the WHERE clause is ambiguous and I know it is related to the condition I added in the global scope.\n",
"AnswerId": "76386234",
"AnswerBody": "I believe you got that error because a number of your tables are having that client_token column. So when you got a database query involving multiple tables, it just doesn't know which client_token column you are talking about.\nLets create a scope class so we can access the table name of the model:\n<?php\n \nnamespace App\\Scopes;\n \nuse Illuminate\\Database\\Eloquent\\Scope;\nuse Illuminate\\Database\\Eloquent\\Model;\nuse Illuminate\\Database\\Eloquent\\Builder;\n \nclass ClientTokenScope implements Scope\n{\n    /**\n     * Apply the scope to a given Eloquent query builder.\n     *\n     * @param  \\Illuminate\\Database\\Eloquent\\Builder  $builder\n     * @param  \\Illuminate\\Database\\Eloquent\\Model  $model\n     * @return void\n     */\n    public function apply(Builder $builder, Model $model)\n    {\n        $builder->where(\"{$model->getTable()}.client_token\", Client::$Current_Token);\n    }\n}\n\nThen applying the scope in the boot method:\nnamespace App\\Models;\n\nuse App\\Scopes\\ClientTokenScope;\n\nuse Illuminate\\Database\\Eloquent\\Builder;\n\nclass Model extends \\Illuminate\\Database\\Eloquent\\Model\n{\n    /**\n     * The \"booting\" method of the model.\n     * @return void\n     */\n    protected static function boot()\n    {\n        parent::boot();\n        if(!empty(Client::$Current_Token)) {\n            static::addGlobalScope(new ClientTokenScope);\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76389075",
"QuestionTitle": "Return data from database and show in calendar",
"QuestionBody": "I'm creating a calendar for event bookings. The calendar is already working at the event registration level. I'm having trouble then showing the events registered in the database on the calendar.\nTo show the data in the database I am trying this way:\nvar datta = [\n   {PequenoAlm:  \"Peq_Almoço\", Valencia: \"Teste1\", Ano: \"2023\", Mes: \"6\", Dia: \"27\", },\n];\n\nvar verif = [];\nvar verif1 = [];\nvar verif2 = [];\nvar verif3 = [];\nvar verif4 = [];\nfor (var i = 0; i < datta.length; i++) {\n  var PequenoAlm = datta[0].PequenoAlm;\n  var Valencia = datta[0].Valencia;\n  var Ano = datta[0].Ano;\n  var Mes = datta[0].Mes;\n  var Dia = datta[0].Mes;\n  \n  verif.push(PequenoAlm);\n  verif1.push(Valencia);\n  verif2.push(Ano);\n  verif3.push(Mes);\n  verif4.push(Dia);\n}\n    \n var event_data = {\n   \"events\": [\n     {\n       \"occasion\": verif,\n       \"invited_count\": verif1,\n       \"year\": verif2,\n       \"month\": verif3,\n       \"day\": verif4,\n       \"cancelled\": true\n     }\n   ]\n };\n\nThe problem is that it doesn't show any information on the calendar.\nI leave the complete code of how I am doing it and with the part of the code that I am trying to return the data from the database to the calendar.\nSnippet below:\n\n\n$(document).ready(function() {\n  var date = new Date();\n  var today = date.getDate();\n\n  $(\".right-button\").click({\n    date: date\n  }, next_year);\n  $(\".left-button\").click({\n    date: date\n  }, prev_year);\n  $(\".month\").click({\n    date: date\n  }, month_click);\n  $(\".right-button1\").click({\n    date: date\n  }, next_mes);\n  $(\".left-button1\").click({\n    date: date\n  }, prev_mes);\n  $(\"#add-button\").click({\n    date: date\n  }, new_event);\n  $(\".months-row\").children().eq(date.getMonth()).addClass(\"active-month\");\n  init_calendar(date);\n  var events = check_events(today, date.getMonth() + 1, date.getFullYear());\n  show_events(events, months[date.getMonth()], today);\n});\n\nfunction init_calendar(date) {\n  $(\".tbody\").empty();\n  $(\".events-container\").empty();\n  var calendar_days = $(\".tbody\");\n  var month = date.getMonth();\n  var year = date.getFullYear();\n  var day_count = days_in_month(month, year);\n  var row = $(\"<tr class='table-row'></tr>\");\n  var today = date.getDate();\n\n  date.setDate(1);\n  var first_day = date.getDay();\n  for (var i = 0; i < 35 + first_day; i++) {\n    var day = i - first_day + 1;\n    if (i % 7 === 0) {\n      calendar_days.append(row);\n      row = $(\"<tr class='table-row'></tr>\");\n    }\n\n    if (i < first_day || day > day_count) {\n      var curr_date = $(\"<td class='table-date nil'>\" + \"</td>\");\n      row.append(curr_date);\n    } else {\n      var curr_date = $(\"<td class='table-date'>\" + day + \"</td>\");\n      var events = check_events(day, month + 1, year);\n\n      if (today === day && $(\".active-date\").length === 0) {\n        curr_date.addClass(\"active-date\");\n        show_events(events, months[month], day);\n      }\n\n      if (events.length !== 0) {\n        curr_date.addClass(\"event-date\");\n      }\n\n      curr_date.click({\n        events: events,\n        month: months[month],\n        day: day\n      }, date_click);\n      row.append(curr_date);\n    }\n  }\n\n  calendar_days.append(row);\n  $(\".year\").text(year);\n\n  calendar_days.append(row);\n  if (month == 0) {\n    $(\".mes\").text(\"Janeiro\");\n  }\n  if (month == 1) {\n    $(\".mes\").text(\"Fevereiro\");\n  }\n  if (month == 2) {\n    $(\".mes\").text(\"Março\");\n  }\n  if (month == 3) {\n    $(\".mes\").text(\"Abril\");\n  }\n  if (month == 4) {\n    $(\".mes\").text(\"Maio\");\n  }\n  if (month == 5) {\n    $(\".mes\").text(\"Junho\");\n  }\n  if (month == 6) {\n    $(\".mes\").text(\"Julho\");\n  }\n  if (month == 7) {\n    $(\".mes\").text(\"Agosto\");\n  }\n  if (month == 8) {\n    $(\".mes\").text(\"Setembro\");\n  }\n  if (month == 9) {\n    $(\".mes\").text(\"Outubro\");\n  }\n  if (month == 10) {\n    $(\".mes\").text(\"Novembro\");\n  }\n  if (month == 11) {\n    $(\".mes\").text(\"Dezembro\");\n  }\n}\n\nfunction days_in_month(month, year) {\n  var monthStart = new Date(year, month, 1);\n  var monthEnd = new Date(year, month + 1, 1);\n  return (monthEnd - monthStart) / (1000 * 60 * 60 * 24);\n}\n\nfunction date_click(event) {\n  $(\".events-container\").show(250);\n  $(\"#diaalog\").hide(250);\n  $(\".active-date\").removeClass(\"active-date\");\n  $(this).addClass(\"active-date\");\n  show_events(event.data.events, event.data.month, event.data.day);\n};\n\nfunction month_click(event) {\n  $(\".events-container\").show(250);\n  $(\"#diaalog\").hide(250);\n  var date = event.data.date;\n  $(\".active-month\").removeClass(\"active-month\");\n  $(this).addClass(\"active-month\");\n  var new_month = $(\".month\").index(this);\n  date.setMonth(new_month);\n  init_calendar(date);\n}\n\nfunction next_year(event) {\n  $(\"#diaalog\").hide(250);\n  var date = event.data.date;\n  var new_year = date.getFullYear() + 1;\n  $(\"year\").html(new_year);\n  date.setFullYear(new_year);\n  init_calendar(date);\n}\n\nfunction prev_year(event) {\n  $(\"#diaalog\").hide(250);\n  var date = event.data.date;\n  var new_year = date.getFullYear() - 1;\n  $(\"year\").html(new_year);\n  date.setFullYear(new_year);\n  init_calendar(date);\n}\n\nfunction next_mes(event) {\n  $(\"#diaalog\").hide(250);\n  var date = event.data.date;\n  var new_mes = date.getMonth() + 1;\n  $(\"mes\").html(new_mes);\n  date.setMonth(new_mes);\n  init_calendar(date);\n}\n\nfunction prev_mes(event) {\n  $(\"#diaalog\").hide(250);\n  var date = event.data.date;\n  var new_mes = date.getMonth() - 1;\n  $(\"mes\").html(new_mes);\n  date.setMonth(new_mes);\n  init_calendar(date);\n}\n\nfunction new_event(event) {\n  if ($(\".active-date\").length === 0)\n    return;\n  $(\"inpuut\").click(function() {\n    $(this).removeClass(\"error-inpuut\");\n  })\n  $(\"#diaalog input[type=text]\").val('');\n  $(\"#diaalog input[type=number]\").val('');\n  $(\".events-container\").hide(250);\n  $(\"#diaalog\").show(250);\n\n  $(\"#cancel-button\").click(function() {\n    $(\"#reff\").removeClass(\"error-inpuut\");\n    $(\"#reff1\").removeClass(\"error-inpuut\");\n    $(\"#reff2\").removeClass(\"error-inpuut\");\n    $(\"#almm\").removeClass(\"error-inpuut\");\n    $(\"#almm1\").removeClass(\"error-inpuut\");\n    $(\"#almm2\").removeClass(\"error-inpuut\");\n    $(\"#almm3\").removeClass(\"error-inpuut\");\n    $(\"#valref\").removeClass(\"error-inpuut\");\n    $(\"#Dataref\").removeClass(\"error-inpuut\");\n    $(\"#diaalog\").hide(250);\n    $(\".events-container\").show(250);\n  });\n}\n\nfunction show_events(events, month, day) {\n  $(\".events-container\").empty();\n  $(\".events-container\").show(250);\n  console.log(event_data[\"events\"]);\n\n  if (events.length === 0) {\n    var event_card = $(\"<div class='event-card'></div>\");\n    var event_name = $(\"<div class='event-name'>Não há refeições marcadas para \" + day + \"  \" + month + \".</div>\");\n    $(event_card).css({\n      \"border-left\": \"10px solid #FF1744\"\n    });\n    $(event_card).append(event_name);\n    $(\".events-container\").append(event_card);\n  } else {\n    for (var i = 0; i < events.length; i++) {\n      var event_card = $(\"<div class='event-card'></div>\");\n      var event_name = $(\"<div class='event-name'>\" + events[i][\"occasion\"] + \":</div>\");\n      var event_count = $(\"<div class='event-count'>\" + events[i][\"invited_count\"] + \" Invited</div>\");\n\n      if (events[i][\"cancelled\"] === true) {\n        $(event_card).css({\n          \"border-left\": \"10px solid #FF1744\"\n        });\n        event_count = $(\"<div class='event-cancelled'>Cancelled</div>\");\n      }\n      $(event_card).append(event_name).append(event_count);\n      $(\".events-container\").append(event_card);\n    }\n  }\n}\n\nfunction check_events(day, month, year) {\n  var events = [];\n  for (var i = 0; i < event_data[\"events\"].length; i++) {\n    var event = event_data[\"events\"][i];\n    if (event[\"day\"] === day &&\n      event[\"month\"] === month &&\n      event[\"year\"] === year) {\n      events.push(event);\n    }\n  }\n  return events;\n}\n\nvar datta = [{\n  PequenoAlm: \"Peq_Almoço\",\n  Valencia: \"Teste1\",\n  Ano: \"2023\",\n  Mes: \"6\",\n  Dia: \"27\",\n}, ];\n\nvar verif = [];\nvar verif1 = [];\nvar verif2 = [];\nvar verif3 = [];\nvar verif4 = [];\nfor (var i = 0; i < datta.length; i++) {\n  var PequenoAlm = datta[0].PequenoAlm;\n  var Valencia = datta[0].Valencia;\n  var Ano = datta[0].Ano;\n  var Mes = datta[0].Mes;\n  var Dia = datta[0].Mes;\n\n  verif.push(PequenoAlm);\n  verif1.push(Valencia);\n  verif2.push(Ano);\n  verif3.push(Mes);\n  verif4.push(Dia);\n}\n\nvar event_data = {\n  \"events\": [{\n    \"occasion\": verif,\n    \"invited_count\": verif1,\n    \"year\": verif2,\n    \"month\": verif3,\n    \"day\": verif4,\n    \"cancelled\": true\n  }]\n};\n\nconst months = [\n  \"Janeiro\",\n  \"Fevereiro\",\n  \"Março\",\n  \"Abril\",\n  \"maio\",\n  \"Junho\",\n  \"Julho\",\n  \"Agosto\",\n  \"Setembro\",\n  \"Outubro\",\n  \"Novembro\",\n  \"Dezembro\"\n];\n.conteent {\n  overflow: none;\n  max-width: 790px;\n  padding: 0px 0;\n  height: 500px;\n  position: relative;\n  margin: 20px auto;\n  background: #52A0FD;\n  background: -moz-linear-gradient(right, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  background: -webkit-linear-gradient(right, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  background: linear-gradient(to left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  border-radius: 3px;\n  box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n  -moz-box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n  -webkit-box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n}\n\n\n/*  Events display */\n\n.events-container {\n  overflow-y: scroll;\n  height: 100%;\n  margin: 0px auto;\n  font: 13px Helvetica, Arial, sans-serif;\n  display: inline-block;\n  padding: 0 10px;\n  border-bottom-right-radius: 3px;\n  border-top-right-radius: 3px;\n}\n\n.events-container:after {\n  clear: both;\n}\n\n.event-card {\n  padding: 20px 0;\n  width: 350px;\n  margin: 20px auto;\n  display: block;\n  background: #fff;\n  border-left: 10px solid #52A0FD;\n  border-radius: 3px;\n  box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n  -moz-box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n  -webkit-box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n}\n\n.event-count,\n.event-name,\n.event-cancelled {\n  display: inline;\n  padding: 0 10px;\n  font-size: 1rem;\n}\n\n.event-count {\n  color: #52A0FD;\n  text-align: right;\n}\n\n.event-name {\n  padding-right: 0;\n  text-align: left;\n}\n\n.event-cancelled {\n  color: #FF1744;\n  text-align: right;\n}\n\n\n/*  Calendar wrapper */\n\n.calendar-container {\n  position: relative;\n  margin: 0px auto;\n  height: 100%;\n  background: #fff;\n  font: 13px Helvetica, Arial, san-serif;\n  display: inline-block;\n  border-bottom-left-radius: 3px;\n  border-top-left-radius: 3px;\n}\n\n.calendar-container:after {\n  clear: both;\n}\n\n.calendar {\n  display: table;\n}\n\n\n/* Calendar Header */\n\n.year-header {\n  background: #52A0FD;\n  background: -moz-linear-gradient(left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  background: -webkit-linear-gradient(left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  background: linear-gradient(to right, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  font-family: Helvetica;\n  box-shadow: 0 3px 6px rgba(0, 0, 0, 0.16), 0 3px 6px rgba(0, 0, 0, 0.23);\n  -moz-box-shadow: 0 3px 6px rgba(0, 0, 0, 0.16), 0 3px 6px rgba(0, 0, 0, 0.23);\n  -webkit-box-shadow: 0 3px 6px rgba(0, 0, 0, 0.16), 0 3px 6px rgba(0, 0, 0, 0.23);\n  height: 40px;\n  text-align: center;\n  position: relative;\n  color: #fff;\n  border-top-left-radius: 3px;\n}\n\n.year-header span {\n  display: inline-block;\n  font-size: 20px;\n  line-height: 40px;\n}\n\n.left-button,\n.right-button {\n  cursor: pointer;\n  width: 28px;\n  text-align: center;\n  position: absolute;\n}\n\n.left-button1,\n.right-button1 {\n  cursor: pointer;\n  width: 28px;\n  text-align: center;\n  position: absolute;\n}\n\n.left-button {\n  left: 0;\n  -webkit-border-top-left-radius: 5px;\n  -moz-border-radius-topleft: 5px;\n  border-top-left-radius: 5px;\n}\n\n.left-button1 {\n  left: 0;\n  -webkit-border-top-left-radius: 5px;\n  -moz-border-radius-topleft: 5px;\n  border-top-left-radius: 5px;\n}\n\n.right-button {\n  right: 0;\n  top: 0;\n  -webkit-border-top-right-radius: 5px;\n  -moz-border-radius-topright: 5px;\n  border-top-right-radius: 5px;\n}\n\n.right-button1 {\n  right: 0;\n  top: 0;\n  -webkit-border-top-right-radius: 5px;\n  -moz-border-radius-topright: 5px;\n  border-top-right-radius: 5px;\n}\n\n.left-button:hover {\n  background: #3FADFF;\n}\n\n.left-button1:hover {\n  background: #3FADFF;\n}\n\n.right-button:hover {\n  background: #00C1FF;\n}\n\n.right-button1:hover {\n  background: #00C1FF;\n}\n\n.ajustebot {\n  margin-top: -5%;\n}\n\n\n/* Buttons */\n\n.bbuutton {\n  cursor: pointer;\n  -webkit-appearance: none;\n  -moz-appearance: none;\n  appearance: none;\n  outline: none;\n  font-size: 1rem;\n  border-radius: 25px;\n  padding: 0.65rem 1.9rem;\n  transition: .2s ease all;\n  color: white;\n  border: none;\n  box-shadow: -1px 10px 20px #9BC6FD;\n  background: #52A0FD;\n  background: -moz-linear-gradient(left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  background: -webkit-linear-gradient(left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  background: linear-gradient(to right, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n}\n\n#cancel-button {\n  box-shadow: -1px 10px 20px #FF7DAE;\n  background: #FF1744;\n  background: -moz-linear-gradient(left, #FF1744 0%, #FF5D95 80%, #FF5D95 100%);\n  background: -webkit-linear-gradient(left, #FF1744 0%, #FF5D95 80%, #FF5D95 100%);\n  background: linear-gradient(to right, #FF1744 0%, #FF5D95 80%, #FF5D95 100%);\n}\n\n#add-button {\n  display: block;\n  position: absolute;\n  right: 20px;\n  bottom: 20px;\n}\n\n#add-button:hover,\n#ok-button:hover,\n#cancel-button:hover {\n  transform: scale(1.03);\n}\n\n#add-button:active,\n#ok-button:active,\n#cancel-button:active {\n  transform: translateY(3px) scale(.97);\n}\n\n\n/* Days/months tables */\n\n.days-table,\n.dates-table {\n  border-collapse: separate;\n  text-align: center;\n}\n\n.day {\n  height: 26px;\n  width: 26px;\n  padding: 0 10px;\n  line-height: 26px;\n  border: 2px solid transparent;\n  text-transform: uppercase;\n  font-size: 90%;\n  color: #9e9e9e;\n}\n\n.active-month {\n  font-weight: bold;\n  font-size: 14px;\n  color: #FF1744;\n  text-shadow: 0 1px 4px RGBA(255, 50, 120, .8);\n}\n\n\n/*  Dates table */\n\n.table-date {\n  cursor: default;\n  color: #2b2b2b;\n  height: 26px;\n  width: 26px;\n  font-size: 15px;\n  padding: 10px;\n  line-height: 26px;\n  text-align: center;\n  border-radius: 50%;\n  border: 2px solid transparent;\n  transition: all 250ms;\n}\n\n.table-date:not(.nil):hover {\n  border-color: #FF1744;\n  box-shadow: 0 2px 6px RGBA(255, 50, 120, .9);\n}\n\n.event-date {\n  border-color: #52A0FD;\n  box-shadow: 0 2px 8px RGBA(130, 180, 255, .9);\n}\n\n.active-date {\n  background: #FF1744;\n  box-shadow: 0 2px 8px RGBA(255, 50, 120, .9);\n  color: #fff;\n}\n\n.event-date.active-date {\n  background: #52A0FD;\n  box-shadow: 0 2px 8px RGBA(130, 180, 255, .9);\n}\n\n\n/* input dialog */\n\n.diaalog {\n  z-index: 5;\n  background: #fff;\n  position: absolute;\n  width: 438px;\n  height: 500px;\n  left: 352px;\n  border-top-right-radius: 3px;\n  border-bottom-right-radius: 3px;\n  display: none;\n  border-left: 1px #aaa solid;\n  top: 0%;\n}\n\n.diaalog-header {\n  margin: 20px;\n  color: #333;\n  text-align: center;\n}\n\n.form-ccontainer {\n  margin-top: 5%;\n}\n\n.form-labeel {\n  color: #333;\n}\n\n.inpuut {\n  border: none;\n  background: none;\n  border-bottom: 1px #aaa solid;\n  display: block;\n  margin-bottom: 50px;\n  width: 200px;\n  height: 40px;\n  text-align: center;\n  transition: border-color 250ms;\n}\n\n.inpuut:focus {\n  outline: none;\n  border-color: #00C9FB;\n}\n\n.error-inpuut {\n  border-color: #FF1744;\n}\n\n\n/* Tablets and smaller */\n\n@media only screen and (max-width: 780px) {\n  .conteent {\n    overflow: visible;\n    position: relative;\n    max-width: 100%;\n    width: 370px;\n    height: 100%;\n    background: #52A0FD;\n    background: -moz-linear-gradient(left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n    background: -webkit-linear-gradient(left, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n    background: linear-gradient(to right, #52A0FD 0%, #00C9FB 80%, #00C9FB 100%);\n  }\n  .diaalog {\n    width: 370px;\n    height: 450px;\n    border-radius: 3px;\n    top: 0;\n    left: 0;\n  }\n  .events-container {\n    float: none;\n    overflow: visible;\n    margin: 0 auto;\n    padding: 0;\n    display: block;\n    left: 0;\n    border-radius: 3px;\n  }\n  .calendar-container {\n    float: none;\n    padding: 0;\n    margin: 0 auto;\n    margin-right: 0;\n    display: block;\n    left: 0;\n    border-radius: 3px;\n    box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n    -moz-box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n    -webkit-box-shadow: 3px 8px 16px rgba(0, 0, 0, 0.19), 0 6px 6px rgba(0, 0, 0, 0.23);\n  }\n}\n\n\n/* Small phone screens */\n\n@media only screen and (max-width: 400px) {\n  .conteent,\n  .events-container,\n  .year-header,\n  .calendar-container {\n    width: 320px;\n  }\n  .diaalog {\n    width: 320px;\n  }\n  .days-table {\n    width: 320px;\n    padding: 7px 7px;\n  }\n  .event-card {\n    width: 300px;\n  }\n  .day {\n    padding: 7px 7px;\n  }\n  .table-date {\n    width: 320px;\n    height: 20px;\n    line-height: 20px;\n  }\n  .event-name,\n  .event-count,\n  .event-cancelled {\n    font-size: .8rem;\n  }\n  #add-button {\n    bottom: 2px;\n    right: 5px;\n    padding: 0.5rem 1.5rem;\n  }\n  .ajustebot {\n    margin-top: -12%;\n  }\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<div class=\"conteent\">\n  <div class=\"calendar-container\">\n    <div class=\"calendar\">\n      <div class=\"year-header\">\n        <span class=\"left-button\" id=\"prev\"> &lang; </span>\n        <span class=\"year\" id=\"label\"></span>\n        <span class=\"right-button\" id=\"next\"> &rang; </span>\n      </div>\n      <div class=\"year-header\">\n        <span class=\"left-button1\" id=\"prev1\"> &lang; </span>\n        <span class=\"mes\" id=\"label\"></span>\n        <span class=\"right-button1\" id=\"next1\"> &rang; </span>\n      </div>\n      <table class=\"days-table\">\n        <td class=\"day\">Dom</td>\n        <td class=\"day\">Seg</td>\n        <td class=\"day\">Ter</td>\n        <td class=\"day\">Qua</td>\n        <td class=\"day\">Qui</td>\n        <td class=\"day\">Sex</td>\n        <td class=\"day\">Sab</td>\n      </table>\n      <div class=\"frame\">\n        <table class=\"dates-table\">\n          <tbody class=\"tbody\">\n          </tbody>\n        </table>\n      </div>\n      <button class=\"bbuutton\" id=\"add-button\">Marcação</button>\n    </div>\n  </div>\n  <div class=\"events-container\"></div>\n  <div class=\"diaalog\" id=\"diaalog\">\n    <h2 class=\"diaalog-header\"> Adicionar Nova Refeição </h2>\n    <form class=\"fform\" id=\"fform\">\n      <div class=\"form-ccontainer\" align=\"center\">\n        <p class=\"form-labeel\">Pequenas Refeições <span style=\"color: red;\">*</span></p>\n        <div class=\"radio_containner\">\n          <input type=\"checkbox\" class=\"inradio\" name=\"reff\" id=\"reff\" value=\"Peq_Almoço\">\n          <label for=\"reff\" class=\"labradio\">Pequeno-Almoço</label>\n          <input type=\"checkbox\" class=\"inradio\" name=\"reff1\" id=\"reff1\" value=\"Lanche\">\n          <label for=\"reff1\" class=\"labradio\" style=\"margin-left: 3%;\">Lanche</label>\n          <input type=\"checkbox\" class=\"inradio\" name=\"reff2\" id=\"reff2\" value=\"Ceia\">\n          <label for=\"reff2\" class=\"labradio\" style=\"margin-left: 3%;\">Ceia</label>\n        </div>\n        <p class=\"form-labeel\">Refeição <span style=\"color: red;\">*</span></p>\n        <div class=\"radio_containner\">\n          <input type=\"checkbox\" class=\"inradio\" name=\"almm\" id=\"almm\" value=\"Almoço\">\n          <label for=\"almm\" class=\"labradio\">Almoço</label>\n          <input type=\"checkbox\" class=\"inradio\" name=\"almm1\" id=\"almm1\" value=\"Almoço_(Dieta)\">\n          <label for=\"almm1\" class=\"labradio\" style=\"margin-left: 3%;\">Almoço Dieta</label>\n          <input type=\"checkbox\" class=\"inradio\" name=\"almm2\" id=\"almm2\" value=\"Jantar\">\n          <label for=\"almm2\" class=\"labradio\" style=\"margin-left: 3%;\">Jantar</label>\n          <input type=\"checkbox\" class=\"inradio\" name=\"almm3\" id=\"almm3\" value=\"Jantar_(Dieta)\">\n          <label for=\"almm3\" class=\"labradio\" style=\"margin-left: 3%;\">Jantar Dieta</label>\n        </div>\n        <div class=\"form-group\">\n          <p class=\"form-labeel\"> Valência <span style=\"color: red;\">*</span></p>\n          <select class=\"js-states form-control ajuste sssinglett\" name=\"valref\" id=\"valref\">\n            <option></option>\n            <option value=\"3\" selected> ERPI</option>\n          </select>\n        </div>\n        <label for=\"Dataref\" class=\"form-labeel\">Período de Marcação </label>\n        <input type=\"date\" class=\"inpuut\" name=\"Dataref\" id=\"Dataref\">\n        <div class=\"ajustebot\">\n          <input type=\"button\" value=\"Cancel\" class=\"bbuutton\" id=\"cancel-button\">\n          <input type=\"button\" value=\"OK\" class=\"bbuutton\" id=\"ok-button\">\n        </div>\n      </div>\n    </form>\n  </div>\n</div>\n\n\n\ncodepen\nCan you help overcome this difficulty?\nI'm trying like this:\nvar event_data = {\n  \"events\": []\n};\n\n$(document).ready(function () {\n\n  $.getJSON('consrefeicoes.php', function (datta) {\n  \n    for (var i = 0; i < datta.length; i++) {\n\n      PequenoAlm = datta[i].PequenoAlm;     \n      Valencia = datta[i].Valencia;\n      Ano = datta[i].Ano;\n      mes = datta[i].mes;\n      dia = datta[i].dia;\n      \n      event_data.events.push({\n        \"occasion\": PequenoAlm,\n        \"invited_count\": Valencia,\n        \"year\": Number(Ano),\n        \"month\": Number(mes),\n        \"day\": Number(dia),\n        \"cancelled\": true\n      })\n      \n    };\n\n  });\n});\n\nphp:\n$Colaborador = $_SESSION['usuarioId'];\n\n$query = $conn->prepare(\"SELECT PequenoAlm, Alm, Lan, jant, Ceia, Valencia, YEAR(Data) AS Ano, Colaborador, MONTH(Data) AS mes, DAY(Data) AS dia\n\nFROM raddb.MarcErpi WHERE raddb.MarcErpi.Colaborador = ?\");\n\n$query->execute([$Colaborador]);\n\n$json = [];\nwhile($row=$query->fetch(PDO::FETCH_ASSOC)){\n    extract($row);\n\n    $json[]= ['PequenoAlm' =>(string)$PequenoAlm, 'Alm' =>(string)$Alm, 'Lan' =>(string)$Lan, 'jant' =>(string)$jant, 'Ceia' =>(string)$Ceia, 'Valencia' =>(string)$Valencia, \n    'Ano' =>(string)$Ano, 'Colaborador' =>(string)$Colaborador, 'mes' =>(string)$mes, 'dia' =>(string)$dia];\n}\n\necho json_encode($json);\n\n\n(3) [{…}, {…}, {…}]  \n0 :  {PequenoAlm: 'Peq_Almoço', Alm: 'Almoço', Lan: 'Lanche', jant: '', Ceia: '', …}  \n1 :  {PequenoAlm: 'Peq_Almoço', Alm: 'Almoço', Lan: '', jant: '', Ceia: '', …}  \n2 :  {PequenoAlm: '', Alm: '', Lan: 'Lanche', jant: 'Jantar', Ceia: '', …} length :   \n3 [[Prototype]] :  Array(0)\n\n",
"AnswerId": "76389126",
"AnswerBody": "You are configuring your event incorrectly - when defining event_data, you define a single event that has arrays of all of the events. For example, the first event has the date of all of them. Since there is only one, you end up with day = [\"23\"] instead of 23, which is breaking the calendar code. You also need to convert each element to a number, as they are currently strings. Here is the correction:\nvar event_data = {\n    \"events\": []\n};\n\nfor (var i = 0; i < verif.length; i++) {\n    event_data.events.push({\n        \"occasion\": verif[i],\n        \"invited_count\": Number(verif1[i]),\n        \"year\": Number(verif2[i]),\n        \"month\": Number(verif3[i]),\n        \"day\": Number(verif4[i]),\n        \"cancelled\": true\n    });\n}\n\nThis code adds an event to event data for each item in verif.\nIn addition, earlier in your code, you define Dia incorrectly, with the month rather than the day.\nCorrection:\nvar Dia = datta[0].Dia;\n\nrather than\nvar Dia = datta[0].Mes;\n\nUpdated pen: https://codepen.io/CoderMuffin/pen/RweXKJM\n"
},
{
"QuestionId": "76381797",
"QuestionTitle": "Get Calendar Events of all group members via Power Automate",
"QuestionBody": "I want to get the Calendar Events of all of the members in the organization/team via Power Automate. As I see now the \"Get Calendars (V2)\" and the \"Get Calendar View of Events (V3)\" only return the corresponding values of the user itself (the one who owns the flow). I was wondering if there's a way to get the calendar events of the group members given the fact that they've given the corresponding permission to share all the calendar data with the organization members.\nAny help on this will be much appreciated.\nThanks!\n",
"AnswerId": "76387767",
"AnswerBody": "The built-in connector will use the current user.\nI don't think you can impersonate a user this way.\nThe best approach or alternative is to use Graph API with a servcie account (Azure AD app registration). You can get events from anyone, so from each users part of a group.\nGET /users/{id | userPrincipalName}/calendar/events\n\nGET /groups/{id}/members\n\nTo call Graph API with Power Automate you will need HTTP connector (it's a premium connector and the connector must be enable for your environment)\nYou have to declare a service account in Azure AD (or Microsoft Entra):\n\nCreate a new app registration (Applications > App registrations)\n\nCopy the client id\nCopy the tenant id\n\n\n\n\n\nAdd the following permissions (Applications > App registrations > API permissions)\n\nGraph API > Application > Calendars.Read.All\nGraph API > Application > Directory.Read.All\nGraph API > Application > GroupMember.Read.All\n\n\nGrant admin consent for the permissions\n\n\n\nGenerate a client secret (Applications > App registrations > Certificate & secrets > Client secrets)\n\nIn Power Automate, create a new cloud flow, for example a button with the group id as input.\nDeclare variables:\n\nClient ID on the app registration\nClient secret for the app registration\nTenant ID\nArray to store all the events\n\n\nNext, call Graph API to get group members with the generic HTTP connector\nMethod: GET\nURI: https://graph.microsoft.com/v1.0/groups/<your group id input>/members\nHeaders: Content-Type application/json\nHeaders: Accept application/json\nAuthentication: Active Directory OAuth\nTenant: your tenant id variable\nAudience: https://graph.microsoft.com\nClient ID: your client id variable\nCrendential Type: Secret\nSecret: your client secret variable\n\n\nTransform the result in JSON using the schema:\n{\n\"type\": \"object\",\n\"properties\": {\n    \"@@odata.context\": {\n        \"type\": \"string\"\n    },\n    \"value\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": {\n                    \"type\": \"string\"\n                },\n                \"mail\": {\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"id\",\n                \"mail\"\n            ]\n        }\n    }\n}\n}\n\nFor each members, call Graph API to get user's events\nMethod: GET\nURI: https://graph.microsoft.com/v1.0/users/<user id fron json foreach>/event\nHeaders: Content-Type application/json\nHeaders: Accept application/json\nAuthentication: Active Directory OAuth\nTenant: your tenant id variable\nAudience: https://graph.microsoft.com\nClient ID: your client id variable\nCrendential Type: Secret\nSecret: your client secret variable\n\n\nTransform the result in JSON using the schema:\n{\n\"type\": \"object\",\n\"properties\": {\n    \"@@odata.context\": {\n        \"type\": \"string\"\n    },\n    \"value\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"@@odata.etag\": {\n                    \"type\": \"string\"\n                },\n                \"id\": {\n                    \"type\": \"string\"\n                },\n                \"createdDateTime\": {\n                    \"type\": \"string\"\n                },\n                \"lastModifiedDateTime\": {\n                    \"type\": \"string\"\n                },\n                \"changeKey\": {\n                    \"type\": \"string\"\n                },\n                \"categories\": {\n                    \"type\": \"array\"\n                },\n                \"transactionId\": {\n                    \"type\": \"string\"\n                },\n                \"originalStartTimeZone\": {\n                    \"type\": \"string\"\n                },\n                \"originalEndTimeZone\": {\n                    \"type\": \"string\"\n                },\n                \"iCalUId\": {\n                    \"type\": \"string\"\n                },\n                \"reminderMinutesBeforeStart\": {\n                    \"type\": \"integer\"\n                },\n                \"isReminderOn\": {\n                    \"type\": \"boolean\"\n                },\n                \"hasAttachments\": {\n                    \"type\": \"boolean\"\n                },\n                \"subject\": {\n                    \"type\": \"string\"\n                },\n                \"bodyPreview\": {\n                    \"type\": \"string\"\n                },\n                \"importance\": {\n                    \"type\": \"string\"\n                },\n                \"sensitivity\": {\n                    \"type\": \"string\"\n                },\n                \"isAllDay\": {\n                    \"type\": \"boolean\"\n                },\n                \"isCancelled\": {\n                    \"type\": \"boolean\"\n                },\n                \"isOrganizer\": {\n                    \"type\": \"boolean\"\n                },\n                \"responseRequested\": {\n                    \"type\": \"boolean\"\n                },\n                \"seriesMasterId\": {},\n                \"showAs\": {\n                    \"type\": \"string\"\n                },\n                \"type\": {\n                    \"type\": \"string\"\n                },\n                \"webLink\": {\n                    \"type\": \"string\"\n                },\n                \"onlineMeetingUrl\": {},\n                \"isOnlineMeeting\": {\n                    \"type\": \"boolean\"\n                },\n                \"onlineMeetingProvider\": {\n                    \"type\": \"string\"\n                },\n                \"allowNewTimeProposals\": {\n                    \"type\": \"boolean\"\n                },\n                \"occurrenceId\": {},\n                \"isDraft\": {\n                    \"type\": \"boolean\"\n                },\n                \"hideAttendees\": {\n                    \"type\": \"boolean\"\n                },\n                \"responseStatus\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"response\": {\n                            \"type\": \"string\"\n                        },\n                        \"time\": {\n                            \"type\": \"string\"\n                        }\n                    }\n                },\n                \"body\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"contentType\": {\n                            \"type\": \"string\"\n                        },\n                        \"content\": {\n                            \"type\": \"string\"\n                        }\n                    }\n                },\n                \"start\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"dateTime\": {\n                            \"type\": \"string\"\n                        },\n                        \"timeZone\": {\n                            \"type\": \"string\"\n                        }\n                    }\n                },\n                \"end\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"dateTime\": {\n                            \"type\": \"string\"\n                        },\n                        \"timeZone\": {\n                            \"type\": \"string\"\n                        }\n                    }\n                },\n                \"location\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"displayName\": {\n                            \"type\": \"string\"\n                        },\n                        \"locationType\": {\n                            \"type\": \"string\"\n                        },\n                        \"uniqueIdType\": {\n                            \"type\": \"string\"\n                        },\n                        \"address\": {\n                            \"type\": \"object\",\n                            \"properties\": {}\n                        },\n                        \"coordinates\": {\n                            \"type\": \"object\",\n                            \"properties\": {}\n                        }\n                    }\n                },\n                \"locations\": {\n                    \"type\": \"array\"\n                },\n                \"recurrence\": {},\n                \"attendees\": {\n                    \"type\": \"array\"\n                },\n                \"organizer\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"emailAddress\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"name\": {\n                                    \"type\": \"string\"\n                                },\n                                \"address\": {\n                                    \"type\": \"string\"\n                                }\n                            }\n                        }\n                    }\n                },\n                \"onlineMeeting\": {},\n                \"calendar@odata.associationLink\": {\n                    \"type\": \"string\"\n                },\n                \"calendar@odata.navigationLink\": {\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"@@odata.etag\",\n                \"id\",\n                \"createdDateTime\",\n                \"lastModifiedDateTime\",\n                \"changeKey\",\n                \"categories\",\n                \"transactionId\",\n                \"originalStartTimeZone\",\n                \"originalEndTimeZone\",\n                \"iCalUId\",\n                \"reminderMinutesBeforeStart\",\n                \"isReminderOn\",\n                \"hasAttachments\",\n                \"subject\",\n                \"bodyPreview\",\n                \"importance\",\n                \"sensitivity\",\n                \"isAllDay\",\n                \"isCancelled\",\n                \"isOrganizer\",\n                \"responseRequested\",\n                \"seriesMasterId\",\n                \"showAs\",\n                \"type\",\n                \"webLink\",\n                \"onlineMeetingUrl\",\n                \"isOnlineMeeting\",\n                \"onlineMeetingProvider\",\n                \"allowNewTimeProposals\",\n                \"occurrenceId\",\n                \"isDraft\",\n                \"hideAttendees\",\n                \"responseStatus\",\n                \"body\",\n                \"start\",\n                \"end\",\n                \"location\",\n                \"locations\",\n                \"recurrence\",\n                \"attendees\",\n                \"organizer\",\n                \"onlineMeeting\",\n                \"calendar@odata.associationLink\",\n                \"calendar@odata.navigationLink\"\n            ]\n        }\n    }\n}\n}\n\n\nActivate and start the flow with a group id as input:\n\n"
},
{
"QuestionId": "76387472",
"QuestionTitle": "tidyr::pivot_longer() with duplicate problems with no apparent duplicate column names or dataset in R",
"QuestionBody": "My goal is to change value 99999 with the value adjacent to it unless it's 99999 again.\nI took the advice from here before, now I am having a new problem.\nMRE:\n'as' is a dataframe with 9 different cohort datasets; 10030 obs of 7060 variables. I am mainly (as of now) dealing with as$AS1_WEIGHT ... as$AS9_WEIGHT\n> as %>%\n+     select(starts_with(\"AS\") & ends_with(\"_WEIGHT\")) %>% head() %>% dput()\n\nstructure(list(AS1_WEIGHT = c(72, 59, 50, 55.2, 82.1, 50.4), \n    AS2_WEIGHT = c(74.8, NA, NA, 54.8, 84.5, 52.5), AS3_WEIGHT = c(75.2, \n    NA, NA, 55.9, 81.7, 54.6), AS4_WEIGHT = c(75, NA, NA, 55.1, \n    80.6, NA), AS5_WEIGHT = c(75.4, NA, NA, 58.8, 89.5, NA), \n    AS6_WEIGHT = c(77.3, NA, NA, NA, NA, NA), AS7_WEIGHT = c(70.7, \n    NA, NA, 56, NA, NA), AS8_WEIGHT = c(73.8, NA, NA, 55.5, NA, \n    NA), AS9_WEIGHT = c(74.5, NA, NA, 54.8, NA, 52)), row.names = c(NA, \n-6L), class = c(\"tbl_df\", \"tbl\", \"data.frame\"))\n\n\n\nas %<>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_longer(starts_with(\"AS\") & ends_with(\"_WEIGHT\")) %>%\n  mutate(value = if_else(value == '99999', lead(value), value), .by = row) %>%\n  pivot_wider(names_from = name, values_from = value)\n\nreturns:\nError in tidyr::pivot_longer():\n! Names must be unique.\n✖ These names are duplicated:\n\n\"name\" at locations 7049 and 7053.\n\"value\" at locations 7050 and 7054.\nℹ Use argument names_repair to specify repair strategy.\nRun rlang::last_trace() to see where the error occurred.\n\nSo I ran this code to see which columns are duplicated:\n> dup_col <- duplicated(base::as.list(as))\ncolnames(as[dup_col])\n\ncharacter(0)\n\nI ran another code to see if I am referring to the right columns\n> as %>%\n  select(starts_with(\"AS\") & ends_with(\"_WEIGHT\")) %>%\n  colnames()\n\n[1] \"AS1_WEIGHT\" \"AS2_WEIGHT\" \"AS3_WEIGHT\" \"AS4_WEIGHT\" \"AS5_WEIGHT\" \"AS6_WEIGHT\" \"AS7_WEIGHT\" \"AS8_WEIGHT\"\n[9] \"AS9_WEIGHT\"\n\n\nThank you in advance!\n\n",
"AnswerId": "76387866",
"AnswerBody": "I suspect you already have a column named name or value before you run pivot_longer, which by default tries to create columns with those names. As noted here, the error message isn't necessarily clear that's the problem.\nTry grep(\"name\", colnames(as)) and grep(\"value\", colnames(as)) to find those columns.\nEither rename in your data frame or use pivot_longer( ... names_to = \"a_new_name_col\", values_to = \"a_new_value_col\")\ndata.frame(a = 1:2, name = 3:4, value = 7:8) %>%\n  tidyr::pivot_longer(a)\n#Error in `vec_cbind()`:\n#! Names must be unique.\n#✖ These names are duplicated:\n#  * \"name\" at locations 1 and 3.\n#  * \"value\" at locations 2 and 4.\n#ℹ Use argument `names_repair` to specify repair strategy.\n#Run `rlang::last_trace()` to see where the error occurred.\n\ndata.frame(a = 1:2, name2 = 3:4, value2 = 7:8) %>%\n  tidyr::pivot_longer(a)\n## A tibble: 2 × 4\n#  name2 value2 name  value\n#  <int>  <int> <chr> <int>\n#1     3      7 a         1\n#2     4      8 a         2\n\n"
},
{
"QuestionId": "76383552",
"QuestionTitle": "Create Record With \"has_many_through\" Association – Ruby on Rails",
"QuestionBody": "I have a has_many_through association where Users have many Projects through ProjectUsers. Rails has some magic that allows updating this relationship with:\nu = User.first\nu.update(project_ids: [...])\n\nIs there a clean way to do the same thing with create?\nRunning User.create(name: ..., project_ids: [...]) fails with Validation failed: Project users is invalid.\nI suspect this is because Rails tries to create the ProjectUser record before creating the User record and has some built-in validation on join tables to validate that both sides of the join already exist. The ProjectUser model has no custom validation.\nclass ProjectUser < ApplicationRecord\n  belongs_to :project\n  belongs_to :user\nend\n\nIs there a simple way to get around this?\n",
"AnswerId": "76386291",
"AnswerBody": "Active Record supports automatic identification for most associations with standard names. However, Active Record will not automatically identify bi-directional associations that contain the :through or :foreign_key options. (You can check here)\nSo you have to define inverse_of explicitly.\nclass Project < ApplicationRecord\n  has_many :project_users, foreign_key: :project_id, inverse_of: :project\n  has_many :users, through: :project_users\nend\n\nclass User < ApplicationRecord\n  has_many :project_users, foreign_key: :user_id, inverse_of: :user\n  has_many :projects, through: :project_users\nend\n\nclass ProjectUser < ApplicationRecord\n  belongs_to :project\n  belongs_to :user\nend\n\n\n"
},
{
"QuestionId": "76387583",
"QuestionTitle": "SQL Function DIFFERENCE returns interesting scores",
"QuestionBody": "Can anyone explain why the SQL function (using SQL Server 2019) returns results that to me appear to be counter intuitive? Here are the queries and the scores:\nSELECT \n    DIFFERENCE('Good', 'Good Samaritans'); --Result is 4 (High score match)\n\nSELECT \n    DIFFERENCE('Samaritans', 'Good Samaritans'); --Result is 1 (Low score match)\n\nSELECT \n    DIFFERENCE('Sam', 'Good Samaritans'); --Result is 2 (A higher score than above!)\n\nI understand DIFFERENCE uses SOUNDEX to match consonants phonetically, but the results above seem very odd particularly with the second query. Is it something to do with the space and the proceeding string?\n",
"AnswerId": "76387869",
"AnswerBody": "If you change the order of words you will see there is a bias on the first word. Then if you consider SOUNDEX you will begin to understand why. Also read the reference below.\n\nSOUNDEX converts an alphanumeric string to a four-character code that is based on how the string sounds when spoken in English. The\nfirst character of the code is the first character of\ncharacter_expression, converted to upper case. The second through\nfourth characters of the code are numbers that represent the letters\nin the expression. The letters A, E, I, O, U, H, W, and Y are ignored\nunless they are the first letter of the string. Zeroes are added at\nthe end if necessary to produce a four-character code. For more\ninformation about the SOUNDEX code, see The Soundex Indexing\nSystem\n\n-- Bias based on left to right order of words\nSELECT 10 id, DIFFERENCE('Good', 'Good Samaritans') --Result is 4 (High score match)\nunion all\nSELECT 11 id, DIFFERENCE('Good', 'Samaritans Good') --Result is 1 (Low score match)\nunion all\nSELECT 20, DIFFERENCE('Samaritans', 'Good Samaritans') --Result is 1 (Low score match)\nunion all\nSELECT 21, DIFFERENCE('Samaritans', 'Samaritans Good') --Result is 4 (High score match)\nunion all\nSELECT 30, DIFFERENCE('Sam', 'Good Samaritans') --Result is 2 (On the upper low side)\n\n\n\n\n\n\nid\n(No column name)\n\n\n\n\n10\n4\n\n\n11\n1\n\n\n20\n1\n\n\n21\n4\n\n\n30\n2\n\n\n\n\nfiddle\nYour expectations from difference may be too high.\n"
},
{
"QuestionId": "76389016",
"QuestionTitle": "How to get the index with the minimum value in a column avoiding duplicate selection",
"QuestionBody": "I have the following dataframe:\nimport pandas as pd\npd.DataFrame({'index': {0: 'x0',\n  1: 'x1',\n  2: 'x2',\n  3: 'x3',\n  4: 'x4',\n  5: 'x5',\n  6: 'x6',\n  7: 'x7',\n  8: 'x8',\n  9: 'x9',\n  10: 'x10'},\n 'distances_0': {0: 0.42394711275317537,\n  1: 0.40400179114038315,\n  2: 0.4077213959237454,\n  3: 0.3921048592156785,\n  4: 0.25293154279281627,\n  5: 0.2985576890173001,\n  6: 0.0,\n  7: 0.32563550923886675,\n  8: 0.33341592647322754,\n  9: 0.30653189426783256,\n  10: 0.31749957588191197},\n 'distances_1': {0: 0.06684300576184829,\n  1: 0.04524728117549289,\n  2: 0.04896118088709522,\n  3: 0.03557204741075342,\n  4: 0.10588973399963886,\n  5: 0.06178330590643222,\n  6: 0.0001,\n  7: 0.6821440376099591,\n  8: 0.027074111335967314,\n  9: 0.6638424898747833,\n  10: 0.674718181953208},\n 'distances_2': {0: 0.7373816871931514,\n  1: 0.7184619375104593,\n  2: 0.7225072199147892,\n  3: 0.7075191710741303,\n  4: 0.5679436864793461,\n  5: 0.6142446533143044,\n  6: 0.31652743219529056,\n  7: 0.010859948083988706,\n  8: 0.6475070638933254,\n  9: 0.010567926115431175,\n  10: 0.0027932480510772413}}\n\n)\nindex   distances_0 distances_1 distances_2\n0   x0  0.423947    0.066843    0.737382\n1   x1  0.404002    0.045247    0.718462\n2   x2  0.407721    0.048961    0.722507\n3   x3  0.392105    0.035572    0.707519\n4   x4  0.252932    0.105890    0.567944\n5   x5  0.298558    0.061783    0.614245\n6   x6  0.000000    0.000100    0.316527\n7   x7  0.325636    0.682144    0.010860\n8   x8  0.333416    0.027074    0.647507\n9   x9  0.306532    0.663842    0.010568\n10  x10 0.317500    0.674718    0.002793\n\nI would like to get, for every distances_ column, the index with the minimum value.\nThe requirement is that each distances_ column, should have a different index: For instance index==\"x6\" has the minimum value for both distances_0 and distances_1, columns, but it should be chosen only for one (and in this case it should be chosen for distances_0, since 0.000000 < 0.000100).\nHow could I do that ?\n",
"AnswerId": "76389173",
"AnswerBody": "Use Series.idxmin with filter out existing values in ouput list:\ndf1 = df.set_index('index')\n\nout = []\nfor c in df1.columns:\n    out.append(df1.loc[~df1.index.isin(out), c].idxmin())\nprint (out)\n['x6', 'x8', 'x10']\n\n"
},
{
"QuestionId": "76381633",
"QuestionTitle": "Ensuring a minimum time interval between successive observations in a Pandas dataframe",
"QuestionBody": "I have a pandas dataframe which is sorted by a date column. However I wish to ensure a minimum time interval between observations. Say for simplicity this window is 10 minutes, what this means is that if my first observation occurred at 8:05 AM then the second observation must occur at at least 8:15 AM. Any observations occurring between 8:05-8:15 AM must be dropped from the dataframe. Say without loss of generality that after dropping observations the second observation occurs at 8:17 AM. Then all observations between 8:17-8:27 AM are dropped to find the third data point and this process continues.\nI have a script which works but iterates over the rows one at a time and is excruciatingly slow as the dataframe has hundreds of thousands of rows. My current script (window is the minimum threshold in minutes):\ncur_time = df.iloc[0].Date\n\nfor idx, row in df[1:].iterrows():\n\ntime_diff = (row.Date - cur_time).total_seconds()\n\nif time_diff > window*60:\n\n    cur_time = row.Date\n\nelse:\n\n    trades_df.drop(idx, inplace=True)\n\nCan anyone think of a more speed optimized way of doing this operation? If I switch to the Date column as the index are there functions readily available for performing this function?\nEdit: After doing further research the function that I'm looking for is similar to df.resample(window + 'M').first(). However the issue with using this is that my data set is sparsely spaced. I.e. I don't have data for every minute, the gap between data points could be 1 second or it could be 1 month.\n",
"AnswerId": "76387897",
"AnswerBody": "With your condition mentioned in comments, I think you can't vectorize whole code. However, you can browse through the dataset faster:\nwindow = 10\n# convert date as numpy array (in seconds)\narr = df['Date'].values.astype(float) / 1e9\n# compute dense matrix using numpy broadcasting\nm = arr - arr[:, None] > window * 60\nlocs = []  # list of valid observations\nidx = 0  # first date is always valid\n\nwhile True:\n    # append the current observation\n    locs.append(idx)\n    if m[idx].sum() == 0:\n        # no more observations to check\n        break\n    # next valid observation\n    idx = np.argmax(m[idx])\n\nout = df.iloc[locs]\n\nOutput:\n>>> out\n                  Date\n0  2023-06-01 00:02:10\n3  2023-06-01 00:14:20\n8  2023-06-01 00:24:42\n11 2023-06-01 00:35:35\n13 2023-06-01 00:48:39\n\n>>> locs\n[0, 3, 8, 11, 13]\n\nMinimal Reproducible Example:\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\noffsets = pd.to_timedelta(np.random.randint(0, 60*60, 20), unit='S')\ndf = (pd.DataFrame({'Date': pd.Timestamp('2023-06-01') + offsets})\n        .sort_values('Date', ignore_index=True))\nprint(df)\n\n# Output\n                  Date\n0  2023-06-01 00:02:10  # OK, first value is always valid\n1  2023-06-01 00:05:30\n2  2023-06-01 00:07:46\n3  2023-06-01 00:14:20  # OK, 00:02:10 + 10min < 00:14:20\n4  2023-06-01 00:18:15\n5  2023-06-01 00:18:50\n6  2023-06-01 00:20:38\n7  2023-06-01 00:21:34\n8  2023-06-01 00:24:42  # OK, 00:14:20 + 10min < 00:24:42\n9  2023-06-01 00:27:18\n10 2023-06-01 00:28:05\n11 2023-06-01 00:35:35  # OK, 00:24:42 + 10min < 00:35:35\n12 2023-06-01 00:36:09\n13 2023-06-01 00:48:39  # OK, 00:35:35 + 10min < 00:48:39\n14 2023-06-01 00:51:32\n15 2023-06-01 00:52:51\n16 2023-06-01 00:52:54\n17 2023-06-01 00:56:20\n18 2023-06-01 00:57:24\n19 2023-06-01 00:58:27\n\n"
},
{
"QuestionId": "76382810",
"QuestionTitle": "Have difficulty understanding the syntax of generic lambdas for SFINAE-based traits",
"QuestionBody": "I am reading some examples of SFINAE-based traits, but unable to make sense out of the one related to generic lambdas in C++17 (isvalid.hpp).\nI can understand that it roughly contains some major parts in order to implement a type trait such as isDefaultConstructible or hasFirst trait (isvalid1.cpp):\n1. Helper functions using SFINAE technique:\n#include <type_traits>\n\n// helper: checking validity of f(args...) for F f and Args... args:\ntemplate<typename F, typename... Args,\n         typename = decltype(std::declval<F>()(std::declval<Args&&>()...))>\nstd::true_type isValidImpl(void*);\n\n// fallback if helper SFINAE'd out:\ntemplate<typename F, typename... Args>\nstd::false_type isValidImpl(...);\n\n2. Generic lambda to determine the validity:\n// define a lambda that takes a lambda f and returns whether calling f with args is valid\ninline constexpr\nauto isValid = [](auto f) {\n                 return [](auto&&... args) {\n                          return decltype(isValidImpl<decltype(f),\n                                                      decltype(args)&&...\n                                                     >(nullptr)){};\n                        };\n               };\n\n3. Type helper template:\n// helper template to represent a type as a value\ntemplate<typename T>\nstruct TypeT {\n    using Type = T;\n};\n\n// helper to wrap a type as a value\ntemplate<typename T>\nconstexpr auto type = TypeT<T>{};\n\n// helper to unwrap a wrapped type in unevaluated contexts\ntemplate<typename T>\nT valueT(TypeT<T>);  // no definition needed\n\n4. Finally, compose them into isDefaultConstructible trait to check whether a type is default constructible:\nconstexpr auto isDefaultConstructible\n    = isValid([](auto x) -> decltype((void)decltype(valueT(x))()) {\n        });\n\nIt is used like this (Live Demo):\nstruct S {\n    S() = delete;\n};\n\nint main() {\n    std::cout << std::boolalpha;\n    std::cout << \"int: \" << isDefaultConstructible(type<int>) << std::endl;    // true\n    std::cout << \"int&: \" << isDefaultConstructible(type<int&>) << std::endl;  // false\n    std::cout << \"S: \" << isDefaultConstructible(type<S>) << std::endl;        // false\n\n    return 0;\n}\n\nHowever, some of the syntax are so complicated and I cannot figure out.\nMy questions are:\n\nWith respect to 1, as for std::declval<F>()(std::declval<Args&&>()...), does it mean that it is an F type functor taking Args type constructor? And why it uses forwarding reference Args&& instead of simply Args?\n\nWith respect to 2, as for decltype(isValidImpl<decltype(f), decltype(args)&&...>(nullptr)){} , I also cannot understand why it passes forwarding reference decltype(args)&& instead of simply decltype(args)?\n\nWith respect to 4, as for decltype((void)decltype(valueT(x))()), what is the purpose of (void) casting here? ((void) casting can also be found in isvalid1.cpp for hasFirst trait) All I can find about void casting is Casting to void to avoid use of overloaded user-defined Comma operator, but it seems it is not the case here.\n\n\nThanks for any insights.\n\nP.S. For one who wants more detail could check C++ Templates: The Complete Guide, 2nd - 19.4.3 Using Generic Lambdas for SFINAE. The author also mentioned that some of the techniques are used widely in Boost.Hana, so I also listen to Louis Dionne's talk about it. Yet, it only helps me a little to understand the code snippet above. (It is still a great talk about the evolution of C++ metaprogramming)\n",
"AnswerId": "76386312",
"AnswerBody": "\nF is a function object callable with Args...\nFor the sake of mental model, picture std::declval<F>() as a \"fully constructed object of type F\". std::declval is there just in case F is not default-constructible and still needs to be used in unevaluated contexts.\nFor a default-constructible type this would be equivalent:\nF()(std::declval<Args&&>()...); In essence it's a call to F's constructor and then call to its operator() with forwarded Args. But imagine one type is constructible with int, another one is default-constructible, yet another one requires a string. Without some unevaluated constructor-like metafunction it would be impossible to cover all those cases.\nYou can read more on that in Alexandrescu's Modern C++ Design: Generic Programming and Design Patterns Applied.\n\nAdding && to the argument type is effectively perfect-forwarding it. It may look obscure, but it's just a shorthand for decltype(std::forward<decltype(args)>(args)). See the implementation of std::forward and reference collapsing rules for more details. Keep in mind though, that this snippet adds rvalue-reference that collapses to the correct one when combined with the original type, not a forwarding one.\n\nAs it was stated in the comments: the type is not really needed, possibilty exists it cannot be returned, its presence there is just to check expression's correctness, afterwards it can be discarded.\n\n\n"
},
{
"QuestionId": "76383773",
"QuestionTitle": "Taildwind css align bottom",
"QuestionBody": "Hello I just tring send to bottom of its parent:\n <form class=\"flex flex-col w-full\" (submit)=\"updatePhoto(title, description)\">\n        <div class=\"w-full block\">\n            <input type=\"text\" class=\"shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline\" placeholder=\"Photo's Title\" [value]=\"photo.title\" #title>\n        </div>\n        <div class=\"my-4 w-full\">\n            <textarea rows=\"2\" class=\"shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline resize-none\" placeholder=\"Photo's Description\" [value]=\"photo.description\" #description></textarea>\n        </div>\n        <div class=\"grid justify-items-end  mt-auto  border \">\n            <div>\n                <button class=\"text-white bg-gradient-to-r from-red-400 via-red-500 to-red-600 hover:bg-gradient-to-br focus:ring-4 focus:outline-none focus:ring-red-300 dark:focus:ring-red-800 shadow-lg shadow-red-500/50 dark:shadow-lg dark:shadow-red-800/80 font-medium rounded-lg text-sm px-5 py-2.5 text-center mr-2 mb-2\" (click)=\"deletePhoto(photo._id)\">\n                    Delete\n                </button>\n                <button class=\"text-white bg-gradient-to-r from-blue-500 via-blue-600 to-blue-700 hover:bg-gradient-to-br focus:ring-4 focus:outline-none focus:ring-blue-300 dark:focus:ring-blue-800 shadow-lg shadow-blue-500/50 dark:shadow-lg dark:shadow-blue-800/80 font-medium rounded-lg text-sm px-5 py-2.5 text-center mr-2 mb-2 \">\n                    Update\n                </button>\n            </div>\n        </div>\n </form>\n\nso I want align element(buttons) to the bottom of its parent, I'm using flex flex-col in parent and child I'm using grid justify-items-end  mt-auto but don't work, so I just added border to see the position, I'm getting this:\n\nyou can see the buttons are up, what's wrong? why\n",
"AnswerId": "76386482",
"AnswerBody": "It works fine just use grid on the outer container.  There's also a lot of opportunity to streamline both the markup and the classes.\n\n\n<script src=\"https://cdn.tailwindcss.com\"></script>\n\n<div class=\"m-4 grid max-w-4xl grid-cols-2 gap-3 rounded border p-4 shadow\">\n  <img class=\"w-full\" src=\"https://picsum.photos/id/237/900\" />\n  <form class=\"flex flex-col\" (submit)=\"updatePhoto(title, description)\">\n    <input type=\"text\" class=\"focus:shadow-outline mb-4 w-full appearance-none rounded border px-3 py-2 leading-tight text-gray-700 shadow focus:outline-none\" placeholder=\"Photo's Title\" [value]=\"photo.title\" #title />\n    <textarea rows=\"2\" class=\"focus:shadow-outline w-full resize-none appearance-none rounded border px-3 py-2 leading-tight text-gray-700 shadow focus:outline-none\" placeholder=\"Photo's Description\" [value]=\"photo.description\" #description></textarea>\n    <div class=\"ml-auto mt-auto\">\n      <button class=\"mb-2 mr-2 rounded-lg bg-gradient-to-r from-red-400 via-red-500 to-red-600 px-5 py-2.5 text-center text-sm font-medium text-white shadow-lg shadow-red-500/50 hover:bg-gradient-to-br focus:outline-none focus:ring-4 focus:ring-red-300 dark:shadow-lg dark:shadow-red-800/80 dark:focus:ring-red-800\" (click)=\"deletePhoto(photo._id)\">Delete</button>\n      <button class=\"mb-2 mr-2 rounded-lg bg-gradient-to-r from-blue-500 via-blue-600 to-blue-700 px-5 py-2.5 text-center text-sm font-medium text-white shadow-lg shadow-blue-500/50 hover:bg-gradient-to-br focus:outline-none focus:ring-4 focus:ring-blue-300 dark:shadow-lg dark:shadow-blue-800/80 dark:focus:ring-blue-800\">Update</button>\n    </div>\n  </form>\n</div>\n\n\n\n"
},
{
"QuestionId": "76389093",
"QuestionTitle": "How do I display Javascript variable using ",
"QuestionBody": "According to the chrome console there are no problems however there are as my variable is \"undefined\" despite it being set as \"0\"\nI have used the following resources:\nResource 1\nResource 2\nI am trying to make it so when the user clicks my image it will add +1 to the points variable (Game.points) here is my code (for context purposes):\n<!DOCTYPE html>\n\n<script>\nfunction Game() {\nvar points = \"0\"\ndocument.getElementById(\"myText\").innerHTML = Game.points;\n\n}\n</script>\n<center>  <img onclick=\"Game.points = Game.points + 1\" src=\"https://static.wikia.nocookie.net/villains/images/5/5d/Frieza.png/revision/latest?cb=20200625063534\" width=\"350px\"> </center>\n<body onload=\"Game()\">\n\n    <h1>\"The value for number is: \" <span id=\"myText\"></span></h1>\n\n",
"AnswerId": "76389203",
"AnswerBody": "The points variable is not a member of the Game object. To reference it, just use the points keyword.\nThere's also a couple of changes you can make to improve the code quality:\n\nRemove the inline onclick and onload attributes. They are outdated and not good practice. Use addEventListener() to bind events within JS, instead of HTML.\nSet points to be a numeric value, not a string. This way there's no type coercion needed when you increment its value.\nPut any CSS styling in a separate stylesheet, not the HTML\n\n\n\nconst myText = document.querySelector('#myText');\nconst img = document.querySelector('img');\nlet points = 0;\n\ndocument.addEventListener('DOMContentLoaded', () => {\n  updateText();\n});\n\nimg.addEventListener('click', () => {\n  points++;\n  updateText();\n});\n\nupdateText = () => {\n  myText.textContent = points;\n};\nimg {\n  width: 350px;\n}\n<center>\n  <img src=\"https://static.wikia.nocookie.net/villains/images/5/5d/Frieza.png/revision/latest?cb=20200625063534\" />\n</center>\n\n<h1>\n  The value for number is: \n  <span id=\"myText\"></span>\n</h1>\n\n\n\n"
},
{
"QuestionId": "76382922",
"QuestionTitle": "Dask map_partition does no use all workers on client",
"QuestionBody": "I have very CPU heavy process and would like to use as many workers are possible in Dask.\nWhen I read the csv file using the read_csv from dask and then process the dataframe using map_partitions only one worker is used. If I use read_csv from pandas and then convert the file to a Dask dataframe, all my workers are used. See code below.\nCould someone explain the difference in behavior?\nIdeally, I would like to use read_csv from Dask so that I dont have to have a conversion step. Could anyone help me with that?\nimport dask as d\nimport pandas as pd\n\ndef fWrapper(x):\n            p = doSomething(x.ADDRESS, param)\n            return(pd.DataFrame(p, columns=[\"ADDRESS\", \"DATA\",\"TOKEN\", \"CLASS\"]))\n\n# only use 1 worker instead of the available 8\ndask_df = d.dataframe('path\\to\\file')\ndask_df.set_index(UID, npartitions = 8,   drop = False)\nddf2 = dask_df.map_partitions(fWrapper, meta={\"ADDRESS\" : object, \"DATA\" : object, \"TOKEN\" : object, \"CLASS\" : object}).compute() \n\n#uses all 8 workers\ndf = pd.read_csv('path\\to\\file')\ndf.set_index('UID', drop=False)\ndask_df2 =d.dataframe.from_pandas(df, npartitions=dask_params['df_npartitions'], sort=True)\nddf3 = dask_df2.map_partitions(fWrapper, meta={\"ADDRESS\" : object, \"DATA\" : object, \"TOKEN\" : object, \"CLASS\" : object}).compute() \n\n",
"AnswerId": "76386636",
"AnswerBody": "The DataFrame.set_index method in both dask.dataframe and pandas returns the updated dataframe, so it must be assigned to a label. pandas does have a convenience kwarg inplace, but that's not available in dask. This means that in your snippet, the first approach should look like this:\ndask_df = dask_df.set_index(UID, npartitions = 8,   drop = False)\n\nThis will make sure that the new indexed dask dataframe has 8 partitions, so downstream work should be allocated across multiple workers.\n"
},
{
"QuestionId": "76378627",
"QuestionTitle": "User can't create objects in the page",
"QuestionBody": "I made a program where users can keep track of their expenses by entering them into the system after creating their own account. The system requires users to fill in four fields: customer, category, price, and month. I would like the first field (customer) to automatically populate with the username of the logged-in user, so that users don't have to choose from all available customers.\nHowever, I encountered an issue where users are unable to create objects in the system. I can only create objects through the admin dashboard. When I try to create an object on the page, it throws an error message saying,\nRelatedObjectDoesNotExist at / User has no customer.\n\nI suspect this problem is related to the fact that users are added in the authentication and authorization section under Users in the admin page, instead of being created under Customers by my app, alongside the Finance section where the objects are stored.\nTo summarize my two main issues:\n\nI want the first field to automatically populate with the username of the logged-in user.\nI want users to be able to create objects directly from the page, as they could in the past when this issue didn't occur.\n\nThank you so much for your help.\nmodels.py:\nclass Customer(models.Model):\n    user = models.OneToOneField(User, null=True, on_delete=models.CASCADE)\n    name = models.CharField(max_length=200, null=True)\n    email = models.CharField(max_length=200, null=True, blank=True)\n    date_created = models.DateTimeField(auto_now_add=True, null=True)\n\n    # def __str__(self):\n    #     return self.name #I don't now if it's correct\n\n\nclass Finance(models.Model):\n    expenses_category = [\n        (\"Saving\", \"Saving\"),\n        (\"Food\", \"Food\"),\n        (\"Bills\", \"Bills\"),\n        (\"Rent\", \"Rent\"),\n        (\"Extra\", \"Extra\"),\n    ]\n\n    expenses_month = [\n        (\"January\", \"January\"),\n        (\"February\", \"February\"),\n        (\"March\", \"March\"),\n        (\"April\", \"April\"),\n        (\"May\", \"May\"),\n        (\"June\", \"June\"),\n        (\"July\", \"July\"),\n        (\"August\", \"August\"),\n        (\"September\", \"September\"),\n        (\"October\", \"October\"),\n        (\"November\", \"November\"),\n        (\"December\", \"December\"),\n    ]\n\n    customer = models.ForeignKey(User, on_delete=models.CASCADE, null=True, blank=True)\n    category = models.CharField(choices=expenses_category, max_length=200)\n    price = models.IntegerField()\n    month = models.CharField(choices=expenses_month, max_length=200)\n\n\nviews.py:\n@csrf_exempt\ndef registerPage(request):\n    if request.user.is_authenticated:\n        return redirect('home')\n    else:\n        form = CreateUserForm()\n        if request.method == 'POST':\n            form = CreateUserForm(request.POST)\n            if form.is_valid():\n                # form.instance.user = request.user\n                user = form.save()\n                username = form.cleaned_data.get('username')\n\n                group = Group.objects.get(name='customer')\n                user.groups.add(group)\n\n                messages.success(request, 'Account was created for ' + username)\n\n                return redirect('login')\n\n        context = {'form': form}\n        return render(request, 'app_finance/register.html', context)\n\n\ndef loginPage(request):\n    username = None\n    if request.user.is_authenticated:\n        username = request.user.customer\n        return redirect('home')\n    else:\n        if request.method == 'POST':\n            username = request.POST.get('username')\n            password = request.POST.get('password')\n\n            user = authenticate(request, username=username, password=password)\n\n            if user is not None:\n                login(request, user)\n                return redirect('home')\n            else:\n                messages.info(request, 'Username or password incorrect.')\n\n        context = {}\n        return render(request, 'app_finance/login.html', context)\n\n\ndef logoutUser(request):\n    logout(request)\n    return redirect('login')\n\n\ndef userPage(request):\n    return render(request, 'app_finance/user.html')\n\n\n@login_required(login_url='login')\ndef homeView(request):\n    # customer = Customer.objects.get(id=pk) (not sure#)\n    username = None\n    items = Finance.objects.filter(customer_id=request.user.id)\n    form = FinanceForm(initial={'customer': User})\n    if request.method == 'POST':\n        username = request.user.customer\n        form = FinanceForm(request.POST)  # initial={'customer': user}\n        if form.is_valid():\n            form.save()\n            return HttpResponseRedirect('/')\n    else:\n        form = FinanceForm()\n        return render(request, 'app_finance/home.html', {'form': form, 'items': items})\n\n\nforms.py:\nclass CustomerForm(ModelForm):\n    class Meta:\n        model = Customer\n        fields = '__all__'\n        exclude = ['user']\n\n\nclass CreateUserForm(UserCreationForm):\n    class Meta:\n        model = User\n        fields = ['username', 'email', 'password1', 'password2']\n\n\nclass FinanceForm(ModelForm):\n    class Meta:\n        model = Finance\n        fields = '__all__'\n\n\ntemplates/home.html:\n<div>\n    <span>Hello, {{ request.user }}</span> <br>\n    <span><a class=\"hello-msg\" href=\"{% url 'logout' %}\">Logout</a></span>\n</div>\n\n\n<form action=\"\" method=\"post\">\n    {% csrf_token %}\n    {{ form }}\n    <!-- {{ form }} -->\n\n    <input type=\"submit\" value=\"Submit\">\n</form>\n\n<br>\n<div class=\"row\">\n    <div class=\"col-md\">\n        <div class=\"card card-body\">\n            <h1>Expenses</h1>\n        </div>\n        <div class=\"card card-body\">\n            <table class=\"table\">\n                <tr>\n                    <th>User</th>\n                    <th>Category</th>\n                    <th>Price</th>\n                    <th>Month</th>\n                </tr>\n                {% for i in items %}\n                    <tr>\n                        <td>{{ i.customer }}</td>\n                        <td>{{ i.category }}</td>\n                        <td>{{ i.price }}</td>\n                        <td>{{ i.month }}</td>\n                        <td>&nbsp;&nbsp;</td>\n                        <td><a class=\"btn btn-sm btn-info\" href=\"\">Update</a></td>\n                        <td><a class=\"btn btn-sm btn-danger\" href=\"\">Delete</a></td>\n                    </tr>\n                {% endfor %}\n            </table>\n        </div>\n    </div>\n</div>\n\n\nThanks again for helping.\n",
"AnswerId": "76387024",
"AnswerBody": "This is the solution i found and worked perfect too.\nI made 2 changes:\n\nviews.py:\n\n    @login_required(login_url='login')\ndef homeView(request):\n    items = Finance.objects.filter(customer=request.user).order_by(Cast('month', IntegerField())).reverse()\n\n    if request.method == 'POST':\n        form = FinanceForm(request.POST, request=request)  # Pass the request object to the form\n        if form.is_valid():\n            finance_obj = form.save(commit=False)\n            finance_obj.customer = request.user\n            finance_obj.save()\n            return redirect('home')\n    else:\n        form = FinanceForm(request=request)  # Pass the request object to the form\n\n    context = {'form': form, 'items': items}\n    return render(request, 'app_finance/home.html', context)\n\n\nforms.py\n\n    class FinanceForm(ModelForm):\n    def __init__(self, *args, **kwargs):\n        self.request = kwargs.pop('request')  # Retrieve the request object\n        super().__init__(*args, **kwargs)\n        self.fields['customer'].initial = self.request.user\n\n"
},
{
"QuestionId": "76387813",
"QuestionTitle": "Find Min/max for X and Y, then interpolate for 5000 txt files with python",
"QuestionBody": "I have this working code to process a single file:\nimport pandas as pd\nimport pygmt\n\n#import table\ndf = pd.read_table(\"file1.txt\", sep=\" \", names=['X', 'Y', 'Z'] ) \n\n#min/max\nXmin = df['X'].min()\nXmax = df['X'].max()\nYmin = df['Y'].min()\nYmax = df['Y'].max()\n#print(Xmin, Xmax)\n#print(Ymin, Ymax)\n\n#gridding with pyGMT\ngrid = pygmt.surface(data=df, spacing=1, region=[Xmin, Xmax, Ymin, Ymax]) \n\n#print(grid) \n#export\ngrid.to_netcdf('file1.nc') \n\nNow I want to repeat this code for all *.txt files in a directory. How can I do that? I tried writing a loop like:\nfor file in glob.glob(\"*.txt\"):\n\nBut how can I make the respective input (.txt) and output (.nc) have the same name?\n",
"AnswerId": "76387951",
"AnswerBody": "As said before in comment section you also can do it by iterating all .txt filenames and changes their formats to .nc with saving names.\nimport glob\nimport pandas as pd\nimport pygmt\n\nfilenames_in = glob.glob(\"*.txt\")\n\nfor filename_in in filenames_in:\n    filename_out = filename_in.replace('.txt', '.nc')\n    # YOUR CODE\n    # import table\n    df = pd.read_table(filename_in, sep=\" \", names=['X', 'Y', 'Z'])\n\n    # min/max\n    Xmin = df['X'].min()\n    Xmax = df['X'].max()\n    Ymin = df['Y'].min()\n    Ymax = df['Y'].max()\n    # print(Xmin, Xmax)\n    # print(Ymin, Ymax)\n\n    # gridding with pyGMT\n    grid = pygmt.surface(data=df, spacing=1, region=[Xmin, Xmax, Ymin, Ymax])\n\n    # print(grid)\n    # export\n    grid.to_netcdf(filename_out)\n\n\n\n"
},
{
"QuestionId": "76383379",
"QuestionTitle": "How do you manually calculate imul -1 * 3?",
"QuestionBody": "I am learning x86-64 assembly with an online course and the course is horribly unclear in detail. I've searched online and read several SO questions but couldn't get an answer.\nI tried to figure out how to calculate binary multiplication by hand, but I am stuck with imul .\nGiven this example of binary multiplication, 11111111 * 00000011, it can be viewed as 255 * 3 unsigned or -1 * 3 signed.\n255*3\n   mov al, 255\n   mov bl, 3\n   mul bl\n\nthis is easy and here's how I calculate by hand, just like decimal multiplication:\n     11111111\nx    00000011 \n--------------\n     11111111       \n    11111111\n--------------\n   1011111101  \n\nThe result overflows, the upper half is 10 in ah and the lower half is 11111101 in al. My manual calculation matches the program result.\n-1*3\nwhen it comes to signed,\n   mov al, -1\n   mov bl, 3\n   imul bl\n\nthe program result is 11111111 in ah and 11111101 in al.\nHow can I calculate this result by hand? I was told that sign extension is involved in imul, but I really don't know how it works here.\nI am using SASM IDE and NASM Assembler.\n",
"AnswerId": "76387122",
"AnswerBody": "Honestly, I can't fully understand the other two answers. It's over complicated for me. I just need a dumb, simple and universal rule.\nI'd like to just pick up what works for me.\n\nThe result is equivalent to sign-extending (imul) or zero-extending\n(mul) both inputs to the destination width and then doing a\nnon-widening multiply\n@Peter Cordes\n\n\nTo manually compute there are several approaches: you can sign extend\nboth inputs to 16-bits and do 16 × 16 keeping only the low 16-bits\n@Erik Eidt\n\nI tried and verified and this rule works for me.\n-1*3,\nsign extended\n  11111111 11111111\n x00000000 00000011\n-------------------\n  11111111 11111111\n 111111111 1111111\n-------------------\n1011111111 11111101\n\nkeep the low 16 bits, I get the correct result 11111111(ah) 11111101(al).\nTry a 4 bit example:\n-2 * 3, 1110 imul 0011\nsign extended\n  1111 1110\n x0000 0011\n-----------\n  1111 1110\n 11111 110\n-----------\n101111 1010\n\nkeep the lower 8 bits, the result is 1111 1010, -6.\nBefore I wasn't sure how sign extended works in imul, now I get it and it's easy to verify. Btw, if you find manual calculation tedious for some examples (e.g. 4 bit -7 * -1, 1001 x 1111, sign extended 1111 1001 x 1111 1111, many lines to add), you can use the Windows Calculator (programmer mode) and verify the result very quickly.\n"
},
{
"QuestionId": "76388975",
"QuestionTitle": "How do I eliminate this circular dependency",
"QuestionBody": "The circular dependency between self.buttons and self.radiobuttons has been impossible for me to solve\nclass Program(tk.Tk):\n\n    def __init__(self, title, size):\n        super().__init__()\n        self.title(title)\n        self.geometry(f\"{size[0]}x{size[1]}\")\n        \n        self.frame = tk.Frame(self, background = \"#D3D3D3\")\n        self.frame.pack(expand = 1, fill = tk.BOTH)\n\n        self.entries = Entries(self) \n        self.output = Output(self)\n        self.buttons = Buttons(self, self.entries, self.output, self.radiobuttons) # here\n        self.radiobuttons = (self, self.buttons) # here\n\n\n        self.filemenu = FileMenu(self)\n\n\n        self.mainloop()\n\nI am trying to use functools among other things to fix my problem but I can't seem to fix it. I could always just move the entirety of one class into the other but it would make using classes redundant\n",
"AnswerId": "76389211",
"AnswerBody": "You can create another class method of Buttons to pass self.radiobuttons to it after self.radiobuttons is created.\nBelow is an example:\nclass Buttons(ttk.Frame):\n    def __init__(self, master, entries, output):\n        super().__init__(master)\n        self.entries = entries\n        self.output = output\n\n    # another class method to pass radiobuttons\n    def set_radiobuttons(self, radiobuttons):\n        self.radiobuttons = radiobuttons\n        # do whatever you want on radiobuttons\n\nclass Radiobuttons(ttk.Frame):\n    def __init__(self, master, buttons):\n        super().__init__(master)\n        self.buttons = buttons\n\nclass Program(tk.Tk):\n\n    def __init__(self, title, size):\n        super().__init__()\n        self.title(title)\n        self.geometry(f\"{size[0]}x{size[1]}\")\n\n        self.frame = tk.Frame(self, background = \"#D3D3D3\")\n        self.frame.pack(expand = 1, fill = tk.BOTH)\n\n        self.entries = Entries(self)\n        self.output = Output(self)\n        self.buttons = Buttons(self, self.entries, self.output)\n        self.radiobuttons = Radiobuttons(self, self.buttons)\n        self.buttons.set_radiobuttons(self.radiobuttons) # pass self.radiobuttons to class Buttons\n\n        self.filemenu = FileMenu(self)\n\nif __name__ == \"__main__\":\n    app = Program(\"Hello World\", (600,400))\n    app.mainloop() # call mainloop() here instead of inside __init__()\n\n"
},
{
"QuestionId": "76387859",
"QuestionTitle": "Maps containing keys with spaces are not properly validated when those keys are used as resource names",
"QuestionBody": "I faced an issue when I had to terraform import some role_assignment resources, specially regarding the APP CONFIG DATA READER role assignment, in terraform.\nthe problem I had to solve was due to an evolution of our iac to make the terraform plan more readable and explicit.\nHere is the code for role assignment that changed :\nmodule \"my_role_assignment_slot_to_app_config\" {\n  for_each = local.map_slot_app_config\n  source = \"../../resourceModules/role_assignment\"\n  scope = each.value.config_id\n  role_definition_names = [\"Reader\",\"App Configuration Data Reader\"]\n  principal_id = each.value.slot_guid\n}\n\nwith the following module for role assignments : \n\n```hcl\nresource \"azurerm_role_assignment\" \"my_role_assignment\" {\n  for_each              = toset(var.role_definition_names)\n  scope                = var.scope\n  role_definition_name = each.value\n  principal_id         = var.principal_id\n}\n\nThis code would plan the following, more readable :\n\nBut as you can see, the index for the azurerm_role_assignment.my_role_assignment contains spaces.\nThis was preventing us to terraform import the role assignment (as it has been created manually before the iac was coded) using powershell script in an azureCli task on azure Devops :\n      - task: AzureCli@2\n        displayName: Runs tfImport.ps1\n        condition: and(succeeded(), eq(variables['toUpdate.scriptExists'], 'true'))  # test script presence\n        name: tfImport.ps1\n        inputs:\n          azureSubscription: ${{ parameters.serviceConnection }}\n          scriptType: ps\n          scriptLocation: InlineScript\n          inlineScript: |\n            $Env:ARM_CLIENT_ID       = \"$Env:servicePrincipalId\"\n            $Env:ARM_CLIENT_SECRET   = \"$Env:servicePrincipalKey\"\n            $Env:ARM_TENANT_ID       = \"$Env:tenantId\"\n            $Env:ARM_SUBSCRIPTION_ID = az account list --query \"[?isDefault].id\" -o tsv        \n            $Env:TF_LOG = \"${{ parameters.TF_LOG }}\"\n        \n            terraform init `\n              -migrate-state `\n              -backend-config=\"resource_group_name=${{ parameters.storageAccountResourceGroup }}\"`\n              -backend-config=\"storage_account_name=${{ parameters.storageAccount}}\" `\n              -backend-config=\"key=${{ parameters.storageContainer }}\" `\n              -backend-config=\"container_name=${{ parameters.stateBlobContainer }}\"\n        \n            // runs my tfImport.ps1 script here\n            ./tfImport.ps1 \n        \n          workingDirectory: $(pipeline_artefact_folder_extract)/   \n          addSpnToEnvironment: true\n          failOnStderr: false  \n        continueOnError: true    \n\nThe script I used had the following terraform import line,\nterraform import  'module.my_role_assignment_slot_to_app_config[\\\"sit03_z-adf-ftnd-shrd-npd-ew1-cfg01\\\"].azurerm_role_assignment.my_role_assignment[\\\"App Configuration Data Reader\\\"]'  /subscriptions/**********/resourceGroups/*********/providers/Microsoft.AppConfiguration/configurationStores/z-adf-ftnd-shrd-npd-ew1-cfg01/providers/Microsoft.Authorization/roleAssignments/<role_assignment_id>\n\nand so I've had the following error :\n\n(id datas removed)\nAfter some researches, I've found the following link that explains the why and give to me one start of solution :\nhttps://github.com/hashicorp/terraform/issues/25116\nBut I had to go further and find a way to use my powershell script without the startProcess method.\nAnd as I had also to get my role_assignment resourceId from its PrincipalId (as we can gets the PrincipalId of resources that have the 'App Configuration Data Reader' role on the app_config using the following)\n    # role assignment over a specific scope (such as app_config)\n    $rsRolesCfg = az role assignment list  --scope /subscriptions/******/resourceGroups/*******/providers/Microsoft.AppConfiguration/configurationStores/******-cfg01 | ConvertFrom-Json\n    $myRole = $rsRolesCfg | Where-Object roleDefinitionName -eq 'App Configuration Data Reader'  | Where-Object id -like \"*<app_config_resourceId>\"\n    ## principalId is the id of the object that get the role over the scope !\n    \n    # GetsresourceId from PrincipalId / ObjetcId (without the '<>' on body, off course :) ) : \n    $resourceId = (az rest --method POST --url 'https://graph.microsoft.com/v1.0/directoryObjects/getByIds' --headers 'Content-Type=application/json'  --body '{\\\"ids\\\":[\\\"<PrincipalId>\\\"]}' | ConvertFrom-Json | Select-Object value).value.alternativeNames[1]\n\nSolution from How to Get Azure AD Object by Object ID Using Azure CLI (thanks a lot !)\nI had to test it locally in powershell terminal... So it did not work as expected.\nSo then, I change a little bit the script and got the solution (next post, as solution from my problem).\n",
"AnswerId": "76387955",
"AnswerBody": "So I've had to test my get_ResourceId methods in local on a powershell VSCode terminal, that does not accept the above code (as the paces wher badly interpreted by powershell)\nSo, after a quick search that explain to me that the \"`\" was the escape character for Powershell, I've tested this that works and give to me the expected resourceId for role_assignment :\n$rsRolesCfg = az role assignment list  --scope /subscriptions/************/resourceGroups/******/providers/Microsoft.AppConfiguration/configurationStores/<app_configuration_name> | ConvertFrom-Json\n\n($rsRolesCfg | Where-Object roleDefinitionName -eq 'App Configuration Data Reader') | ForEach-Object {$local=$_.principalId; (az rest --method POST --url 'https://graph.microsoft.com/v1.0/directoryObjects/getByIds' --headers 'Content-Type=application/json'  --body \"{\\`\"ids\\`\":[\\`\"$local\\`\"]}\" | ConvertFrom-Json | Select-Object value).value.alternativeNames[1] }\n\nSo, the use of \"`\" was the solution for my point, so I've tried to use it on my terraform import script (on first post) and it works fine also :\nterraform import \"module.my_role_assignment_slot_to_app_config[\\`\"sit03_z-adf-ftnd-shrd-npd-ew1-cfg01\\`\"].azurerm_role_assignment.my_role_assignment[\\`\"App Configuration Data Reader\\`\"]\"  /subscriptions/*****/resourceGroups/******/providers/Microsoft.AppConfiguration/configurationStores/z-adf-ftnd-shrd-npd-ew1-cfg01/providers/Microsoft.Authorization/roleAssignments/<role_assignment_id>\n\nBut I had also to change the yaml task, using pscore rather than ps, like the following :\n      - task: AzureCli@2\n        displayName: Runs tfImport.ps1\n        condition: and(succeeded(), eq(variables['toUpdate.scriptExists'], 'true'))  # test script presence\n        name: tfImport.ps1\n        inputs:\n          azureSubscription: ${{ parameters.serviceConnection }}\n          scriptType: **pscore**\n\nSo then, the terrform import script was running with success !\nI've used the same \"title\" for this stackOverflow question / solution as the one in the GitHub, so them peoples who are lokking for that solution could find easily the solution with the question... At least, I hope so :-P\nthanks for reading !\n"
},
{
"QuestionId": "76378706",
"QuestionTitle": "(WMI) IWbemServices::Release() throws \"Access Denied\" exception when connected to remote machine",
"QuestionBody": "In C++, I can't find a way to appropriately terminate a WMI session with a remote server.  Any attempt to release the IWbemServices pointer throws an exception; the TCP connection to the server remains established until the process exits (it's open after the last CoUninitialize call).  This problem (thrown exception) does not occur when connecting to the local machine.\nI've looked at a similar question asked here, but the solution from Microsoft (retrieving the IUnknown pointer and releasing it first) didn't solve the issue.\nHere's the code (error checking has been omitted for readability):\nHRESULT hRes = S_OK;\n\nIWbemLocator* pWbemLocator = NULL;\nIWbemServices* pWbemServices = NULL;\n\n// these three pointers are already initialized...\nPWCHAR wcUser; // L\"theuser\"\nPWCHAR wcPass; // L\"thepassword\"\nPWCHAR wcAuth; // L\"ntlmdomain:THEDOMAIN\"\n\nstd::wstring wstrNsPath = L\"\\\\\\\\remoteserver\\\\ROOT\\\\CIMV2\";\n\nhRes = CoInitializeEx(NULL, COINIT_MULTITHREADED);\n\nhRes = CoCreateInstance(CLSID_WbemLocator, NULL, CLSCTX_INPROC_SERVER, IID_IWbemLocator, (LPVOID*)&pWbemLocator);\n\n// this returns S_OK :)\nhRes = pWbemLocator->ConnectServer((BSTR)wstrNsPath.c_str(),\n        (BSTR)wcUser,\n        (BSTR)wcPass,\n        NULL,\n        WBEM_FLAG_CONNECT_USE_MAX_WAIT,\n        (BSTR)wcAuth,\n        NULL,\n        &pWbemServices);\n\nhRes = CoSetProxyBlanket(pWbemServices,\n        RPC_C_AUTHN_DEFAULT,\n        RPC_C_AUTHZ_DEFAULT,\n        COLE_DEFAULT_PRINCIPAL,\n        RPC_C_IMP_LEVEL_IMPERSONATE,\n        RPC_C_AUTHN_LEVEL_DEFAULT,\n        NULL, // domain info already specified in 'wcAuth'\n        EOAC_NONE);\n\n// do some queries..\n\n// cleanup\npWbemServices->Release(); // on remote sessions, this throws an exception\npWbemLocator->Release();\nCoUninitialize();\n\nThe exception is displayed in the debug output (Visual Studio):\nonecore\\com\\combase\\dcomrem\\call.cxx(1234)\\combase.dll!0000ABCDEFABCDEF: (caller: 0000FEDCBAFEDCBA) ReturnHr(1) tid(4321) 80070005 Access is denied.\n\nIs this expected behavior? Should the connection between the client and server not be terminated once the session is released?\nI attempted to follow MSDN's advice and added the following after the CoSetProxyBlanket() call in the code above.  It didn't change anything.\nIUnknown* pUnknown = NULL;\npWbemServices->QueryInterface(IID_IUnknown, (LPVOID*)&pUnknown);\nif (pUnknown)\n{\n    hRes = CoSetProxyBlanket(pUnknown,\n        RPC_C_AUTHN_DEFAULT,\n        RPC_C_AUTHZ_DEFAULT,\n        COLE_DEFAULT_PRINCIPAL,\n        RPC_C_IMP_LEVEL_IMPERSONATE,\n        RPC_C_AUTHN_LEVEL_DEFAULT,\n        NULL,\n        EOAC_NONE);\n    pUnknown->Release();\n}\n\nAny advice is greatly appreciated!\nEDIT So after capturing session packets, it would appear that setting the proxy security with pAuthInfo == NULL causes the request to be made by the current logged on user of the client machine.  It ignores the credentials that I provided when calling ConnectServer.  I'm aware that the COAUTHIDENTITY structure allows you to pass the correct credentials to CoSetProxyBlanket, but I'd like to avoid having to input the domain as a separate variable.  In other words, is there a way that this information can be extracted using the wcAuth when the request is made to a remote server? If so, how could I distinguish local vs. remote requests?\nHere is the output from Wireshark that led me to believe this is the problem (see packet 1617):\nNo.     Time        Source      Destination Protocol Length Info\n1615    162.221354  [CLIENT_IP] [SERVER_IP] DCERPC  174 Alter_context: call_id: 8, Fragment: Single, 1 context items: IRemUnknown2 V0.0 (32bit NDR), NTLMSSP_NEGOTIATE\n1616    162.228517  [SERVER_IP] [CLIENT_IP] DCERPC  366 Alter_context_resp: call_id: 8, Fragment: Single, max_xmit: 5840 max_recv: 5840, 1 results: Acceptance, NTLMSSP_CHALLENGE\n1617    162.229396  [CLIENT_IP] [SERVER_IP] DCERPC  612 AUTH3: call_id: 8, Fragment: Single, NTLMSSP_AUTH, User: .\\[client_user]\n1618    162.229495  [CLIENT_IP] [SERVER_IP] IRemUnknown2    182 RemRelease request Cnt=1 Refs=5-0\n1619    162.235567  [SERVER_IP] [CLIENT_IP] TCP  60 49669 → 59905 [ACK] Seq=1606 Ack=4339 Win=64768 Len=0\n1620    162.235567  [SERVER_IP] [CLIENT_IP] DCERPC  86  Fault: call_id: 8, Fragment: Single, Ctx: 0, status: nca_s_fault_access_denied\n\n",
"AnswerId": "76387141",
"AnswerBody": "I was able to resolve the issue.  If you are not using the current logged-on user token, you must specify the pAuthInfo parameter of CoSetProxyBlanket to a valid COAUTHIDENITY structure pointer.  The docs for IWbemLocator::ConnectServer actually state that it's best practice to include the domain in the strUser parameter... and that if you do so, you must pass the authority string as NULL.\nOne thing to note is that if ConnectServer succeeds, you don't have to go crazy with the sanitizing of the username string for correctness; the login either worked or it didn't (and breaks/throws an exception, depending on how you handle errors).  In other words, just search the string for the domain delimiters ('\\\\' or '@') and split them appropriately into domain name and username.\n"
},
{
"QuestionId": "76383760",
"QuestionTitle": "Going through the react-router tutorial and rather than using default or null values when loading an empty object, it kicks up an error",
"QuestionBody": "I've been going through react-router's tutorial, and I've been following it to the letter as far as I'm aware. I'm having some issues with the url params in loaders  segment.\nThe static contact code looks like this\nexport default function Contact() {\n  const contact = {\n    first: \"Your\",\n    last: \"Name\",\n    avatar: \"https://placekitten.com/g/200/200\",\n    twitter: \"your_handle\",\n    notes: \"Some notes\",\n    favorite: true,\n  }\n\nAnd when it loads, it looks like this. That works just fine, however, the tutorial then tells me to change that code so that I use data that's loaded in instead. The code now looks like this\nimport { Form, useLoaderData } from \"react-router-dom\";\nimport { getContact } from \"../contacts\"\n\nexport async function loader({ params }) {\n  const contact = await getContact(params.contactid);\n  return {contact}\n}\n\nexport default function Contact() {\n  const { contact } = useLoaderData();\n\nAccording to the tutorial, it should just load in an empty contact that looks like this  but instead, every time I try to open one of the new contacts, it kicks up an error saying\nReact Router caught the following error during render TypeError: contact is null\nThe actual line of code this error points to is in the return segment of the contact component, which looks like this\nreturn (\n    <div id=\"contact\">\n      <div>\n        <img\n          key={contact.avatar}\n          src={contact.avatar || null}\n        />\n      </div>\n\n      <div>\n        <h1>\n          {contact.first || contact.last ? (\n            <>\n              {contact.first} {contact.last}\n            </>\n          ) : (\n            <i>No Name</i>\n          )}{\" \"}\n          <Favorite contact={contact} />\n        </h1>\n\n        {contact.twitter && (\n          <p>\n            <a\n              target=\"_blank\"\n              href={`https://twitter.com/${contact.twitter}`}\n            >\n              {contact.twitter}\n            </a>\n          </p>\n        )}\n\n        {contact.notes && <p>{contact.notes}</p>}\n\n        <div>\n          <Form action=\"edit\">\n            <button type=\"submit\">Edit</button>\n          </Form>\n          <Form\n            method=\"post\"\n            action=\"destroy\"\n            onSubmit={(event) => {\n              if (\n                !confirm(\n                  \"Please confirm you want to delete this record.\"\n                )\n              ) {\n                event.preventDefault();\n              }\n            }}\n          >\n            <button type=\"submit\">Delete</button>\n          </Form>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nPretty much anywhere contacts is called gets an error. So, anyone have any idea what I'm doing wrong here? To my knowledge, I've been following their guide to the letter and it seems like it should be able to handle contacts not having any data, but it's not.\nThese are the pieces of my code that are supposed to be working together to render a contact, or at least the pertinent parts\nThe router, this is the main file, the only part missing is the part where it's rendered\nimport * as React from \"react\";\nimport * as ReactDOM from \"react-dom/client\";\nimport {\n  createBrowserRouter,\n  RouterProvider,\n} from \"react-router-dom\";\nimport \"./index.css\";\nimport Root, { loader as rootLoader, action as rootAction } from \"./routes/root\";\nimport ErrorPage from \"./error-page\";\nimport Contact, { loader as contactLoader } from \"./routes/contact\"\n\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    errorElement: <ErrorPage />,\n    loader: rootLoader,\n    action: rootAction,\n    children: [\n      {\n        path: \"contacts/:contactID\",\n        element: <Contact />,\n        loader: contactLoader\n      }\n    ]\n  }\n\nThese are the functions in the root file that are called when a new contact is made and when it needs to be displayed\nimport { Outlet, Link, useLoaderData, Form } from \"react-router-dom\"\nimport { getContacts, createContact } from \"../contacts\"\n\nexport async function action() {\n  const contact = await createContact();\n  console.log(\"Contact made\")\n  return {contact}\n}\n\nexport async function loader(){\n  const contacts = await getContacts();\n  return {contacts};\n}\n\nThis is the createContacts function that gets called when a contact is created, and this is the getContacts function\nexport async function createContact() {\n  await fakeNetwork();\n  let id = Math.random().toString(36).substring(2, 9);\n  let contact = { id, createdAt: Date.now() };\n  let contacts = await getContacts();\n  contacts.unshift(contact);\n  await set(contacts);\n  return contact;\n}\n\nexport async function getContact(id) {\n  await fakeNetwork(`contact:${id}`);\n  let contacts = await localforage.getItem(\"contacts\");\n  let contact = contacts.find(contact => contact.id === id);\n  return contact ?? null;\n}\n\nThis is the contacts.jsx file where things are currently going wrong. When a new contact is made, it's going to be empty, which I imagine is the source of the problem, but there are checks here to deal with that, or at least there are supposed to be.\nimport { Form, useLoaderData } from \"react-router-dom\";\nimport { getContact } from \"../contacts\"\n\nexport async function loader({ params }) {\n  const contact = await getContact(params.contactid);\n  return { contact }\n}\n\nexport default function Contact() {\n  const { contact } = useLoaderData();\n\n  return (\n    <div id=\"contact\">\n      <div>\n        <img\n          // these next two lines are where the errors typically start, \n          // although it seems to extend down to any instance where contact\n          // gets called.\n          key={contact.avatar}\n          src={contact.avatar || null}\n        />\n      </div>\n\n      <div>\n        <h1>\n          {contact.first || contact.last ? (\n            <>\n              {contact.first} {contact.last}\n            </>\n          ) : (\n            <i>No Name</i>\n          )}{\" \"}\n          <Favorite contact={contact} />\n        </h1>\n\n        {contact.twitter && (\n          <p>\n            <a\n              target=\"_blank\"\n              href={`https://twitter.com/${contact.twitter}`}\n            >\n              {contact.twitter}\n            </a>\n          </p>\n        )}\n\n        {contact.notes && <p>{contact.notes}</p>}\n\n        <div>\n          <Form action=\"edit\">\n            <button type=\"submit\">Edit</button>\n          </Form>\n          <Form\n            method=\"post\"\n            action=\"destroy\"\n            onSubmit={(event) => {\n              if (\n                !confirm(\n                  \"Please confirm you want to delete this record.\"\n                )\n              ) {\n                event.preventDefault();\n              }\n            }}\n          >\n            <button type=\"submit\">Delete</button>\n          </Form>\n        </div>\n      </div>\n    </div>\n  );\n}\n\n",
"AnswerId": "76387258",
"AnswerBody": "There are some subtle, but detrimental, casing issues in the route path params.\nThe Contacts component's route path param is declared as contactID.\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    errorElement: <ErrorPage />,\n    loader: rootLoader,\n    action: rootAction,\n    children: [\n      {\n        path: \"contacts/:contactID\", // <-- \"contactID\"\n        element: <Contact />,\n        loader: contactLoader,\n      },\n    ],\n  },\n]);\n\nThe contact loader is referencing a contactid path parameter.\nexport async function loader({ params }) {\n  const contact = await getContact(params.contactid); // <-- \"contactid\"\n  return { contact };\n}\n\nAs such, the loader function is unable to find a match and returns null to the Contact component. An error is thrown in the UI when attempting to access properties of the null reference.\nAny valid Javascript identifier will work as the name of the route path parameter, but they should all be in agreement. Casing matters in variable names in Javascript. The common convention in variable names is to use camelCasing, e.g. contactId.\nconst router = createBrowserRouter([\n  {\n    path: \"/\",\n    element: <Root />,\n    errorElement: <ErrorPage />,\n    loader: rootLoader,\n    action: rootAction,\n    children: [\n      {\n        path: \"contacts/:contactId\",\n        element: <Contact />,\n        loader: contactLoader,\n      },\n    ],\n  },\n]);\n\nexport async function loader({ params }) {\n  const contact = await getContact(params.contactId);\n  return { contact };\n}\n\n"
},
{
"QuestionId": "76387927",
"QuestionTitle": "Checking the values of JSON response in React Native",
"QuestionBody": "I would like to display either one of two images in a modal based on an API response...unfortunately, the API returns a long string array. I need to be able to determine if the word \"Congratulations\" is in this array. So far, I've tried a couple basic things:\nHere is an example API response:\n{\n    id: 12,\n    message: [\"1 bonus point!\", \"Congratulations\", \"You have leveled up!\"]\n}\n\n\n   console.log(response) // the full response prints to the console, no problem\n   console.log(response?.message) //undefined\n   console.log(reponse.message) //undefined\n   console.log(response[\"message\"]) //undefined\n\nI want to be able to do something like this:\nsetSuccess(response[\"message\"].contains(\"Congratulations\"))\nI'm sure it will be some small syntax thing, but I'm been banging my head against the wall. Any help is appreciated, let me know what I should try!\n",
"AnswerId": "76387999",
"AnswerBody": "I would join the array and than call include.\n\n\nconst data = {\n    id: 12,\n    message: [\"1 bonus point!\", \"Congratulations\", \"You have leveled up!\"]\n}\n\nconst containTerm = data.json().message.join().includes('Congratulations')\n\nconsole.log('Is term in array',  containTerm)\n\n\n\n"
},
{
"QuestionId": "76383873",
"QuestionTitle": "Creating a \"FootBall Field Chart\"",
"QuestionBody": "I have a DataFrame consisting of the following columns:\nVP-ID,\nMotivA_MotivatorA_InnerDriverA_PR,\nMotivA_MotivatorA_InnerDriverB_PR,\nMotivA_MotivatorB_InnerDriverA_PR,\nMotivA_MotivatorB_InnerDriverB_PR,\nMotivA_MotivatorC_InnerDriverA_PR,\nMotivA_MotivatorC_InnerDriverB_PR,\nMotivA_MotivatorD_InnerDriverA_PR,\nMotivA_MotivatorD_InnerDriverB_PR,\n...\nMotivC_MotivatorA_InnerDriverA_PR,\nMotivC_MotivatorA_InnerDriverB_PR,\nMotivC_MotivatorB_InnerDriverA_PR,\nMotivC_MotivatorB_InnerDriverB_PR,\nMotivC_MotivatorC_InnerDriverA_PR,\nMotivC_MotivatorC_InnerDriverB_PR,\nMotivC_MotivatorD_InnerDriverA_PR,\nMotivC_MotivatorD_InnerDriverB_PR.\n\nBehind the designations MotivatorA etc. are of course correct terms (column names).\nHere, \"PR\" stands for Percentile Rank (0-100).\nA graphic represents a motive, which consists of four motivators with two variations, which then have the values from InnerDriverA_PR and InnerDriverB_PR.\nThe final result should look like this:\n\nIs this a \"Football Field Chart\"?\nHow can I implement this graph with Matplotlib?\nMinimal reproducible example:\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create example data\ncolumns = [\n    'MotivA_MotivatorA_InnerDriverA_PR',\n    'MotivA_MotivatorA_InnerDriverB_PR',\n    'MotivA_MotivatorB_InnerDriverA_PR',\n    'MotivA_MotivatorB_InnerDriverB_PR',\n    'MotivA_MotivatorC_InnerDriverA_PR',\n    'MotivA_MotivatorC_InnerDriverB_PR',\n    'MotivA_MotivatorD_InnerDriverA_PR',\n    'MotivA_MotivatorD_InnerDriverB_PR',\n    'MotivB_MotivatorA_InnerDriverA_PR',\n    'MotivB_MotivatorA_InnerDriverB_PR',\n    'MotivB_MotivatorB_InnerDriverA_PR',\n    'MotivB_MotivatorB_InnerDriverB_PR',\n    'MotivB_MotivatorC_InnerDriverA_PR',\n    'MotivB_MotivatorC_InnerDriverB_PR',\n    'MotivB_MotivatorD_InnerDriverA_PR',\n    'MotivB_MotivatorD_InnerDriverB_PR'\n]\n\ndf = pd.DataFrame(columns=columns)\n\nfor i in range(1, 6):  \n    df.loc[f'Subject_{i}'] = [random.randint(0, 100) for _ in range(len(columns))]\n\n#────────────────────────────────────────────────\n\ndef create_horizontal_bar_chart(df, proband):\n    motives = sorted(set(col.split('_')[0] for col in df.columns))\n\n    for motive in motives:\n        columns = [col for col in df.columns if col.startswith(motive)]\n\n        data = df.loc[proband, columns].reset_index()\n\n        data['Motivator'] = data['index'].apply(lambda x: x.split('_')[1])\n        data['InnerDriver'] = data['index'].apply(lambda x: x.split('_')[2])\n        data['Value'] = data[proband]\n        data = data.drop(['index', proband], axis=1)\n\n        plt.figure(figsize=(10, 6))\n        sns.barplot(x='Value', y='Motivator', hue='InnerDriver', data=data)\n        plt.title(f'{proband} - {motive}')\n        plt.show()\n\ncreate_horizontal_bar_chart(df, 'Subject_1')\n\nHowever, this creates the motivators as extra bars and is still far from how I would want it, as in the example above.\n",
"AnswerId": "76389257",
"AnswerBody": "It's a spine chart. The issue with that is it'll not line up your bars. So to do that, you need to get creative:\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ncolumns = [\n    'MotivA_MotivatorA_InnerDriverA_PR',\n    'MotivA_MotivatorA_InnerDriverB_PR',\n    'MotivA_MotivatorB_InnerDriverA_PR',\n    'MotivA_MotivatorB_InnerDriverB_PR',\n    'MotivA_MotivatorC_InnerDriverA_PR',\n    'MotivA_MotivatorC_InnerDriverB_PR',\n    'MotivA_MotivatorD_InnerDriverA_PR',\n    'MotivA_MotivatorD_InnerDriverB_PR',\n    'MotivB_MotivatorA_InnerDriverA_PR',\n    'MotivB_MotivatorA_InnerDriverB_PR',\n    'MotivB_MotivatorB_InnerDriverA_PR',\n    'MotivB_MotivatorB_InnerDriverB_PR',\n    'MotivB_MotivatorC_InnerDriverA_PR',\n    'MotivB_MotivatorC_InnerDriverB_PR',\n    'MotivB_MotivatorD_InnerDriverA_PR',\n    'MotivB_MotivatorD_InnerDriverB_PR'\n]\n\ndf = pd.DataFrame(columns=columns)\n\nfor i in range(1, 6):  # 5 Probanden\n    df.loc[f'Subject_{i}'] = [random.randint(0, 100) for _ in range(len(columns))]\n\ndef create_horizontal_bar_chart(df, proband):\n    motives = sorted(set(col.split('_')[0] for col in df.columns))\n\n    for motive in motives:\n        columns = [col for col in df.columns if col.startswith(motive)]\n\n        data = df[df.index == proband].reset_index()\n\n        # Rename the new column to \"Subject\"\n        data = data.rename(columns = {\"index\": \"Subject\"})\n        \n        # Melt the dataframe\n        data_melted = data.melt(id_vars=[\"Subject\"], var_name=\"Motiv_Motivator_InnerDriver_PR\", value_name=\"PR\")\n        \n        # Create new columns from the \"Motiv_Motivator_InnerDriver_PR\" column\n        data_melted[['Motiv', 'Motivator', 'InnerDriver', '_']] = data_melted['Motiv_Motivator_InnerDriver_PR'].str.split(\"_\",expand=True)\n        data_melted = data_melted[data_melted['Motiv'] == motive]\n        \n        # Drop unnecessary columns\n        data_melted = data_melted.drop(columns=['Motiv_Motivator_InnerDriver_PR', '_'])\n        \n        # Reorder the columns\n        data_melted = data_melted[['Subject', 'Motiv', 'Motivator', 'InnerDriver', 'PR']]\n        \n        # Pivot the table\n        data_pivot = pd.pivot_table(data_melted, values='PR', index=['Subject', 'Motiv', 'Motivator'],\n                            columns='InnerDriver', aggfunc='first').reset_index()\n\n        data_pivot['InnerDriverA'] = -data_pivot['InnerDriverA']\n        data_pivot = data_pivot.sort_values('Motivator', ascending=False).reset_index(drop=True)\n\n\n        fig, ax = plt.subplots(figsize=(10, 8))\n        # Stacked bar chart\n        data_pivot.plot(kind='barh', x='Motivator', y=['InnerDriverA', 'InnerDriverB'], \n                        ax=ax, stacked=True, color='#5fba7d', alpha=0.5, legend=False)\n        \n        ax.set_xlabel('PR')\n        ax.axvline(0, color='grey', linewidth=4) # Add a vertical line at x=0\n        ax.set_xlim(-100, 100)  # set x limit as -100 to 100\n        \n        # Add horizontal grid lines every 25 units\n        ax.set_xticks(range(-100, 101, 25))\n        ax.grid(True, axis='x', linestyle='dotted')\n        \n        # Adjust the x-axis tick labels to display all values as positive\n        ax.set_xticklabels([abs(x) for x in ax.get_xticks()], fontsize=16, color='white')\n        \n        \n        # Add y-axis labels\n        yticks = np.arange(len(data_pivot))\n        yticklabels_left = [f'{motive}   InnerDriverA' for motive in data_pivot['Motivator']]\n        yticklabels_right = ['InnerDriverB'] * len(data_pivot)\n        ax.set_yticks(yticks)\n        ax.set_yticklabels(yticklabels_left, va='center', ha='right', fontsize=14, color='black')\n        \n        # Calculate y-tick positions for right-side labels\n        split = len(data_pivot)\n        intervals = np.linspace(0, 1, split + 1)  # Split the number line into specified number of intervals\n        yticks_right = (intervals[:-1] + intervals[1:]) / 2  # Compute the midpoints\n        \n        # Add right-side y-axis labels\n        ax2 = ax.twinx()\n        ax2.set_yticks(yticks_right)\n        ax2.set_yticklabels(yticklabels_right, va='center', ha='left', fontsize=14, color='black')\n        \n\n        # Remove x and y tick marks\n        ax.tick_params(axis='x', which='both', bottom=False, top=False)\n        ax.tick_params(axis='y', which='both', left=False, right=False)\n        ax2.tick_params(axis='y', which='both', left=False, right=False)\n\n        # Remove border around the axes\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n        \n        # Remove border around the axes\n        ax2.spines['top'].set_visible(False)\n        ax2.spines['right'].set_visible(False)\n        ax2.spines['bottom'].set_visible(False)\n        ax2.spines['left'].set_visible(False)\n\n        \n        # Add values inside the bars\n        for i, row in data_pivot.iterrows():\n            value_a = row['InnerDriverA']\n            value_b = row['InnerDriverB']\n            ax.text(value_a + 2, i, str(-value_a), va='center', ha='left', color='white', fontsize=18, fontweight='bold')\n            ax.text(value_b - 2, i, str(value_b),va='center', ha='right', color='white', fontsize=18, fontweight='bold')\n\n\n        # Create a rectangle to set the background for bottom x-axis tick labels\n        rect = plt.Rectangle((-.05, -0.08), 1.10, 0.08, transform=ax.transAxes, color='grey', clip_on=False)\n        ax.add_patch(rect)        \n        \n        plt.title(f'{proband} - {motive}')\n        plt.show()\n\ncreate_horizontal_bar_chart(df, 'Subject_1')\n\nOutput:\n\nand...\n\n"
},
{
"QuestionId": "76383427",
"QuestionTitle": "AOSP build not working - failed to build some targets",
"QuestionBody": "I am trying to build the AOSP but i always get this error.\n\nIn every thread the answer is that its a RAM problem.\nI have tried the build with the following commands. Nothing works\nm -j32\nm -j16\nm -j12\nm -j8\nm -j2\nm -j1\nI am using a 32GB 14Core Native Linux Workstation.\n",
"AnswerId": "76387760",
"AnswerBody": "After adding 20GB of Swap Storage it now works.\n"
},
{
"QuestionId": "76389244",
"QuestionTitle": "Use python schedule module in an efficient manner",
"QuestionBody": "I want to use python scheduler module for an api call.\nI have two main tasks.\n1-Generate token at interval of 10 mins\n2-Call the api using the token generated in previous step\nThe expected behavior is when a user calls the api it should use the same token for 10 mins and after 10 mins the toekn will be updated in background\nHere are the sample piece of code\ntoken=\"\"(This is a global variable)\ndef generate_token():\n token=//Logic to generate token//\n\n\ndef apicall():\n postreq=//api call using the token//\n\n\ndef schedule_run():\n schedule.every(10).minutes.do(get_token_api)\n while 1:\n        schedule.run_pending()\n        time.sleep(1)\n\nif __name__ == \"__main__\":\n schedule_run()\n apicall()\n \n\n\nWhen I am running above code the code is getting stuck in the while loop of schedule_run()  and not calling apicall()\nIs there any efficient way to handle this?\n",
"AnswerId": "76389294",
"AnswerBody": "You are getting stuck in the (infinite) loop inside schedule_run. First define the two scheduled jobs, the run the schedule waiting loop:\ntoken=\"\"(This is a global variable)\ndef generate_token():\n token=//Logic to generate token//\n\n\ndef apicall():\n schedule.run_pending() #will update the token if it has not been done in the last 10 minutes\n postreq=//api call using the token//\n\nif __name__ == \"__main__\":\n schedule.every(10).minutes.do(get_token_api)\n apicall()\n\n"
},
{
"QuestionId": "76388900",
"QuestionTitle": "PostgreSQL - Get value from from the same table",
"QuestionBody": "Get the average traffic from last week data per WEEK number and get the traffic data for last week Traffic(D-7)\nFor example if date = 5/13/2023, need to output traffic data (Traffic(D-7)) for date = 5/6/2023\n\nI manage to get the Average but no idea how to retrieve the date-7 data and output it altogether\ncreate table a\n(\ndate  varchar(50),\nTname varchar(50),\nWeek varchar(5),\nTraffic float\n)\n\ninsert into  a values ('5/1/2023', 'ID1', '18', 7.98)\ninsert into  a values ('5/2/2023', 'ID1', '18', 4.44)\ninsert into  a values ('5/3/2023', 'ID1', '18', 5.66)\ninsert into  a values ('5/4/2023', 'ID1', '18', 10.01)\ninsert into  a values ('5/5/2023', 'ID1', '18', 9.41)\ninsert into  a values ('5/6/2023', 'ID1', '18', 6.71)\ninsert into  a values ('5/7/2023', 'ID1', '18', 8.24)\ninsert into  a values ('5/8/2023', 'ID1', '19', 8.97)\ninsert into  a values ('5/9/2023', 'ID1', '19', 6.74)\ninsert into  a values ('5/10/2023', 'ID1', '19', 6.45)\ninsert into  a values ('5/11/2023', 'ID1', '19', 9.33)\ninsert into  a values ('5/12/2023', 'ID1', '19', 8.08)\ninsert into  a values ('5/13/2023', 'ID1', '19', 8.36)\n\n\nSELECT date, Tname, Week,\nAVG(Traffic) OVER(PARTITION BY Week) AS AVTraffic\nFROM a\nORDER BY week\n\nhttp://sqlfiddle.com/#!18/538b7/3\n",
"AnswerId": "76389306",
"AnswerBody": "First of all, you need to fix your flaws in your table schema design, and declare:\n\ndates with the \"DATE\" type (instead of VARCHAR(50))\nweek values with the INT type (instead of VARCHAR(5))\ntraffic values with the DECIMAL type (instead of FLOAT)\n\nCREATE TABLE tab(\n    DATE      DATE,\n    Tname     VARCHAR(50),\n    Week      INT,\n    Traffic   DECIMAL(4,2)\n);\n\nOnce you've carried it out, you can solve this problem by:\n\ncreating a ranking value for each day of the week in your weeks, using EXTRACT on your date\nextracting your traffic value from previous week with LAG, by partitioning on your ranking created at previous step, and ordering on the week_number.\n\nWITH cte AS (\n    SELECT date, Tname, Week, Traffic,\n           ROUND(AVG(Traffic) OVER(PARTITION BY Week), 2) AS AVGTraffic,\n           EXTRACT(ISODOW FROM date) - 1                  AS week_day\n    FROM tab\n)\nSELECT date, Tname, Week, \n       LAG(Traffic) OVER(PARTITION BY week_day ORDER BY Week) AS prevweek_traffic,\n       AVGTraffic\nFROM cte\nORDER BY Week, week_day\n\nAnd if you realize that you may have holes among your weeks (..., week 17, week 18, week 20, week 21, ...) and specifically want values from the exact previous week (that may be missing), you can add a filter on the LAG function, that checks if week and previous week are consecutive:\n...\nCASE WHEN LAG(Week) OVER(PARTITION BY week_day ORDER BY Week) = Week-1\n     THEN LAG(Traffic) OVER(PARTITION BY week_day ORDER BY Week) \nEND\n...\n\n(in place of LAG(Traffic) OVER(...) only)\nOutput:\n\n\n\n\ndate\ntname\nweek\nprevweek_traffic    avgtraffic\n\n\n\n\n2023-05-01T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-02T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-03T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-04T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-05T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-06T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-07T00:00:00.000Z\nID1\n18\nnull\n\n\n2023-05-08T00:00:00.000Z\nID1\n19\n7.98\n\n\n2023-05-09T00:00:00.000Z\nID1\n19\n4.44\n\n\n2023-05-10T00:00:00.000Z\nID1\n19\n5.66\n\n\n2023-05-11T00:00:00.000Z\nID1\n19\n10.01\n\n\n2023-05-12T00:00:00.000Z\nID1\n19\n9.41\n\n\n2023-05-13T00:00:00.000Z\nID1\n19\n6.71\n\n\n\n\nCheck the demo here.\nThis query allows any kind of holes in your data, if that's a needed requirement.\nNote: The last ORDER BY clause is not needed. It's there just for visualization purposes.\n"
},
{
"QuestionId": "76382863",
"QuestionTitle": "Firebase RT Database Query on field value hash equality",
"QuestionBody": "I have a Firebase Realtime Database with users and the email is stored in a child field, for example:\n/users/00Vho6lTQke46IqpRv0D5dw6DXs2/email -> user@email.com\n\nI want to query once and get a user based on the MD5 hash of the email address. For example, MD5('user@email.com') -> 'b58c6f14d292556214bd64909bcdb118'.\nI don't have the email address of the user, I only have the MD5 hash. Is it possible to query using an MD5 function to transform the email field to MD5 and query on that?\n",
"AnswerId": "76388174",
"AnswerBody": "\nIs it possible to query using an MD5 function to transform the email field to MD5 and query on that?\n\nNo, unless you save the MD5 as a field inside the database. If you do that, you'll be able to query using the MD5. Your schema should look like this:\ndb\n|\n--- users\n     |\n     --- 00Vho6lTQke46IqpRv0D5dw6DXs2\n           |\n           --- email: \"user@email.com\"\n           |\n           --- md5: \"b58c6f14d292556214bd64909bcdb118\"\n\nAnd the query should look like this:\nval query = db.child(\"users\").orderByChild(\"md5\").equalTo(\"b58c6f14d292556214bd64909bcdb118\");\n\n"
},
{
"QuestionId": "76387305",
"QuestionTitle": "Update + join from two databases",
"QuestionBody": "Help me create an sql query.\nThere are two databases DB1 and DB2. In each of them there are tables \"users\" and \"cities\" with the names of cities. Users and city names are the same in both databases. But the city ID values are different in the two databases. In the first DB1 database, the \"users\" table contains the city IDs from the \"cities\" table.\nI need to update the city data in the second DB2 database. For each \"users\" value from DB1, find the name \"cities\" and update the values in DB2.users. The problem is that the city ID values are different in the two databases. Only the names are the same.\n\n",
"AnswerId": "76388059",
"AnswerBody": "Use an update with join:\nupdate DB2.users set\ncity = DB2.cities.ID\nfrom DB2.users \njoin DB1.users on DB1.users.ID = DB2.users.ID\njoin DB1.cities on DB1.cities.ID = DB1.users.city\njoin DB2.cities on DB2.cities.name = DB1.cities.name\n\nThe join from DB2.users to DB2.cities goes via DB1's tables, going over using user ID and coming back using city name.\n"
},
{
"QuestionId": "76389247",
"QuestionTitle": "Writing a Nested List of Strings to CSV using CSV helper",
"QuestionBody": "I have a nested list of strings that I would like to write to a CSV file using CSV helper. So, it is a list called Entries and each element has a list of strings called Entry.\nMy current code is exporting a blank CSV file.\nEntry example:\n{\"Date\", \"param1\", \"param2\", \"param3\", \"param4\"}\n\nand the Entries list will have a list of those.\nI would like to write to a CSV file with each entry being a new line.\nIntended outcome:\n\"Date\", \"param1\", \"param2\", \"param3\", \"param4\"\n\"Date\", \"param1\", \"param2\", \"param3\", \"param4\"\n\"Date\", \"param1\", \"param2\", \"param3\", \"param4\"\n\"Date\", \"param1\", \"param2\", \"param3\", \"param4\"\n\nMy current code:\nvar rawDataList = await _siteRepository.GetRawSiteData(siteGuid);\n\nvar Entries = _siteRepository.GetSiteData(rawDataList);\nvar writer = new StreamWriter(\"YodelTesting.csv\");\nvar csv = new CsvWriter(writer, CultureInfo.InvariantCulture);\n\nforeach(var record in Entries)\n{\n    csv.WriteRecord(record);\n}\n\nHelp would be appreciated!\n",
"AnswerId": "76389335",
"AnswerBody": "I used the current code to get it working\nusing (var stream = new MemoryStream())\nusing (var writer = new StreamWriter(\"yodelTesting.csv\"))\nusing (var reader = new StreamReader(stream))\nusing (var csv = new CsvWriter(writer, CultureInfo.InvariantCulture))\n{\n    foreach (var record in output)\n    {\n        foreach (var field in record)\n        {\n            csv.WriteField(field);\n\n        }\n        csv.NextRecord();\n    }\n    //not sure what this does tbh\n    writer.Flush();\n    stream.Position = 0;\n}\n\n"
},
{
"QuestionId": "76382701",
"QuestionTitle": "How to deal with 48 or 64bit images in C#",
"QuestionBody": "I've been using the Bitmap-class and it's png-ByteStream to deal with images in my WPF-application, mostly with reading/writing files, getting images from native cam libs and showing them in the UI.\nLately I've got some new requirements and tried to upgrade some of that to deal with 64 bit deep images (or 48 bits, I don't need an alpha channel). In pretty much every operation bitmap is converting my image back to 32bppArgb. I've figured out deepcopying and am currently looking into Image.FromStream(), but needing to deal with this got me wondering:\nIs there a way to properly deal with non 32bppArgb-images within a C#-application (including true greyscale)? Or does microsoft just neglect the need for it? I've found some related questions, but mostly with 10 year old hacks, so I'd expect there to be a proper way by now...\nEdit: As requested, I'm gonna show some code. It's running on .netStandard2.0 to be used mostly inside .net6.0 apps; with System.Drawing.Common on Version 5.0.2 (I don't think it matters but would be willing to upgrade if that's the case). Imagine nativeImage to be a struct from some cameraLib, so we want a deepcopy to get away from the shared memory:\nusing Bitmap bitmap = new(nativeImage.Width, nativeImage.Height, nativeImage.stride, PixelFormat.Format64bppArgb, nativeImage.DataPtr);\nusing Bitmap copy = bitmap.DeepCopy(); //custom function\n\nusing MemoryStream stream = new();\ncopy.Save(stream, ImageFormat.Png);\nbyte[] byteStream = stream.ToArray(); //Saving this to file shows it's really 64 bit\n\n//These bits are stitched together for testing, normally this byte-Array might get passed around quite a bit\nusing MemoryStream ms = new(byteStream);\nusing Image image = Image.FromStream(ms, true); //this suddenly is 32bppArgb\n\nwith:\npublic static Bitmap DeepCopy(this Image original)\n{\n// this just copies the code of the Bitmap(Image)-constructor but uses the original pixelFromat instead of 32bppArgb\n    var result = new Bitmap(original.Width, original.Height, original.PixelFormat);\n    using (Graphics g = Graphics.FromImage(result))\n    {\n        g.Clear(Color.Transparent);\n        g.DrawImage(original, 0, 0, original.Width, original.Height);\n    }\n    return result;\n}\n\n",
"AnswerId": "76388249",
"AnswerBody": "I do not think you will have much success with System.Drawing.Bitmap. In my experience these just have poor support high bit depths. I would instead take a look at the corresponding System.Windows.Media classes. I know PngBitmapEncoder/decoder at least support 16 bit grayscale, but I suspect 48/64 bit works fine as well.\nFor display I would expect that you would want to do your own tone mapping, since I have never seen any builtin method do a particular good job.\nIf you want a format for interchange I would suggest creating your own. Any image is essentially represented using just a few properties:\n\nWidth\nHeight\nStride - The number of bytes on a row. This must be at least large enough to fit a row of pixels, but may be larger for alignment reasons.\nPixelFormat\nPixel Data - This can essentially anything representing binary data. Byte[], a pointer, a stream, Memory<T> etc. The total size of the data should be Height * Stride.\n\nMost image processing libraries should have methods accepting raw image data. You might need to jump thru some hoops to get it to work, like using unsafe code or doing a blockCopy. You also likely need some mapping code to convert between all the various PixelFormat enums.\nLibraries typically provide Bitmap access for convenience, but convert this data to some internal format as soon as possible. You should be able to do the same.\n"
},
{
"QuestionId": "76387881",
"QuestionTitle": "Ansible Variable precedence - what are 'role params' & 'include params'",
"QuestionBody": "The Ansible documentation has a list of Variable precedence\nSome of them are clear to me but I wonder whether anybody coulde kinkdy shed some light on those 2.\n\n20. role (and include_role) params\n21. include params\n\nusage, location, syntax.\nI am trying to get Variable declaration a little further to the surface inside a little more complex playbook utilizing 2 roles I am currently working on.\nconcrete ... some values inside task files of a role should rather be declared as variables in a single location.\n",
"AnswerId": "76388086",
"AnswerBody": "In a nutshell examples:\nrole params\n(full playbook)\n- name: I'm a dummy play\n  hosts: localhost\n\n  roles:\n    - role: somerole\n      vars:\n        param1: \"I'm a role param\"\n\nInclude role params\n(task only)\n- name: Including role somerole\n  ansible.builtin.include_role:\n    name: somerole\n  vars:\n    param1: \"I'm an include role param\"\n\nInclude params\n(task only)\n- name: Including a task file\n  ansible.builtin.include_tasks: sometasks.yaml\n  vars:\n    param1: \"I'm an include param\"\n\n\nAs a fictive and (most probably bad practice) example: if you include a role passing a parameter and later include a task file in that role passing that same parameter with a different value, the include param will take precedence over the role param.\n"
},
{
"QuestionId": "76389245",
"QuestionTitle": "Why garbage value is not being returned in a recursive call to a function with undefined behavior?",
"QuestionBody": "I came across this code somewhere when practicing basic C questions:\nint func(num) {\n    if (num > 0) {\n        return (num + func(num - 2));\n    }\n}\n\nint main() {\n    printf(\"%d\\n\", func(5));\n    return 0;\n}\n\nThe code when executed returns 8 as the answer. But I think that the answer should be \"cannot be determined\".\nThe recursive calls in my head looks like this:\n5 + func(3)  => 5 + (3 + func(1))\n3 + func(1)  => 3 + (1 + func(-1))\n1 + func(-1) => 1 + (?)\n\nFor the ? symbol, I think reading the return value for func(-1) is undefined behavior. I'm basing this on the assumption that for func(-1) no explicit int value is being returned. So reading from func(-1) in the expression (1 + func(-1)) should produce some garbage result + 1 in my opinion.\nWhy is that the code is returning 8 as the answer and not something garbage?\nWhen I explicitly pass a negative number to func and read the result I do get the garbage value, such as in this code;\nint main() {\n    printf(\"%d\\n\", (1 + func(-1)));   // returns garbage result and not 0\n    return 0;\n}\n\nWhy is that in the recursive call (1 + func(-1)) is being evaluated to 0 value?\nI compiled the code on a 64-bit machine with gcc as gcc myfile.c. Compiling the code as gcc -W -Wall -ansi -pedantic myfile.c gives warning about the func function, but that's not the point. I am unable to figure out how 8 is the answer.\n",
"AnswerId": "76389353",
"AnswerBody": "\nWhy garbage value is not being returned in a recursive call to a function with undefined behavior?\n\nBecause \"garbage\" does not mean what you think it means in this context.  In particular, \"garbage\" does not mean \"random\".  (Or if it does, it's more in the sense of xkcd 221.)\nComputers are usually deterministic.  You have to work pretty hard to get truly random behavior.  Even a program that contains the worst kind of undefined behavior will quite often return exactly the same strange and indeterminate number every time you run it.\nI have used this analogy:\n\nSuppose you go to the store and buy a brand-new garbage can. But it's completely clean! There's no garbage in it at all! It's so clean you could eat out of it! Was this false advertising? Did the store fraudulently sell you a non-garbage can?\n\nSee more discussion at these previous questions:\n1\n2\n3\n4\n5.\n(Most of those are talking about the values of uninitialized local variables, not the values of functions that fail to execute a proper return statement, but the arguments are the same.)\n"
},
{
"QuestionId": "76387483",
"QuestionTitle": "SQL to fetch the count between tow date range",
"QuestionBody": "I require to fetch the count of PRODUCT_ID between 00:15:00 and 01:15:00 and subsequentially for any date range.\nExample Scripts:-\nMy DB structure and data is as follows.\nCREATE TABLE time1 (cr_date date , product_id number );\n\ninsert into time1 values (to_date ('01-JAN-2022 01:00:00', 'DD_MON-YYYY HH:MI:SS') , 12345);\ninsert into time1 values (to_date ('01-JAN-2022 01:00:00', 'DD_MON-YYYY HH:MI:SS') , 12346);\ninsert into time1 values (to_date ('01-JAN-2022 01:00:00', 'DD_MON-YYYY HH:MI:SS') , 12347);\ninsert into time1 values (to_date ('01-JAN-2022 03:30:00', 'DD_MON-YYYY HH:MI:SS') , 42345);\ninsert into time1 values (to_date ('01-JAN-2022 03:30:00', 'DD_MON-YYYY HH:MI:SS') , 42346);\ninsert into time1 values (to_date ('01-JAN-2022 03:35:00', 'DD_MON-YYYY HH:MI:SS') , 42347);\ninsert into time1 values (to_date ('01-JAN-2022 03:40:00', 'DD_MON-YYYY HH:MI:SS') , 42348);\ninsert into time1 values (to_date ('01-JAN-2022 10:40:00', 'DD_MON-YYYY HH:MI:SS') , 10348);\ninsert into time1 values (to_date ('01-JAN-2022 10:42:00', 'DD_MON-YYYY HH:MI:SS') , 10349);\ninsert into time1 values (to_date ('01-JAN-2022 10:43:00', 'DD_MON-YYYY HH:MI:SS') , 11348);\n\nCOMMIT;\n\nOutput is required to be as below:-\n| hours   | count |\n|:------  |:------|\n|00:15:00 |3|\n|01:15:00 |0|\n|02:15:00 |0|\n|03:15:00 |0|\n|04:15:00 |4|\n|05:15:00 |0|\n|06:15:00 |0|\n|07:15:00 |0|\n|08:15:00 |0|\n|09:15:00 |0|\n|10:15:00 |0|\n|11:15:00 |3|\n|..\n|...\n|23:15:00 |0|\n\n",
"AnswerId": "76388088",
"AnswerBody": "Sample data you (initially) posted is pretty much useless, there's no time component involved.\nIn one of my tables, there's a datum column and values look like this:\nSQL> SELECT id, TO_CHAR (datum, 'hh24:mi') hrs FROM obr WHERE rownum <= 10;\n\n        ID HRS\n---------- -----\n     21547 08:41\n     21541 08:17\n     21563 09:03\n     21614 10:46\n     21618 11:01\n     21620 11:04\n     21622 11:05\n     21626 11:10\n     21629 11:14\n     21642 13:35\n\n10 rows selected.\n\nSQL>\n\nThis is query which\n\nin fmin CTE creates 24 rows (00:15, 01:15, ... 23:15)\njoin is done on datum \"rounded\" to previous 15-minute value (whether in the same hour, or in previous hour - depends on minutes)\n\nSo:\nSQL> WITH\n  2     fmin\n  3     AS\n  4        (    SELECT TRUNC (SYSDATE) + (LEVEL - 1) / 24 + INTERVAL '15' MINUTE c_time\n  5               FROM DUAL\n  6         CONNECT BY LEVEL <= 24)\n  7    SELECT TO_CHAR (f.c_time, 'hh24:mi') c_time, COUNT (z.id) cnt\n  8      FROM fmin f\n  9           LEFT JOIN obr z\n 10              ON TO_CHAR (f.c_time, 'hh24:mi') =\n 11                 TO_CHAR (\n 12                      TRUNC (datum, 'hh24')\n 13                    + CASE\n 14                         WHEN TO_NUMBER (TO_CHAR (datum, 'mi')) >= 15\n 15                         THEN\n 16                            INTERVAL '15' MINUTE\n 17                         WHEN TO_NUMBER (TO_CHAR (datum, 'mi')) < 15\n 18                         THEN\n 19                            INTERVAL '-45' MINUTE\n 20                      END,\n 21                    'hh24:mi')\n 22  GROUP BY TO_CHAR (f.c_time, 'hh24:mi')\n 23  ORDER BY 1;\n\nResult:\nC_TIM        CNT\n----- ----------\n00:15          0\n01:15          0\n02:15          0\n03:15          0\n04:15          0\n05:15          0\n06:15          0\n07:15          2\n08:15         10\n09:15          1\n10:15         14\n11:15          6\n12:15         10\n13:15         38\n14:15          5\n15:15          0\n16:15          0\n17:15          0\n18:15          0\n19:15          0\n20:15          0\n21:15          0\n22:15          0\n23:15          0\n\n24 rows selected.\n\nSQL>\n\n"
},
{
"QuestionId": "76383461",
"QuestionTitle": "DB2 Group by specific columns",
"QuestionBody": "\n\n\n\nID_1\nID_2\nID_3\nLANG\n\n\n\n\n1\n11\n111\nF_lang\n\n\n1\n11\n111\nnull\n\n\n2\n22\n222\nnull\n\n\n\n\nIs it possible to build  a query which returns only these two lines below.\nIt should be grouped by the first three columns and should take only that line with value of column LANG which is preferably not null, if no value for LANG exists, it should take the line with language null.\n\n\n\n\nID_1\nID_2\nID_3\nLANG\n\n\n\n\n1\n11\n111\nF_lang\n\n\n2\n22\n222\nnull\n\n\n\n",
"AnswerId": "76388255",
"AnswerBody": "Does this anwser the question ?\nwith t1(id_1, id_2, id_3, lang) as (\n  VALUES\n  ('1', '11', '111', 'F_lang'),\n  ('1', '11', '111', NULL),\n  ('2', '22', '222', NULL),\n  ('3', '33', '333', 'F_lang_3_1'),\n  ('3', '33', '333', 'F_lang_3_2'),\n  ('3', '33', '333', NULL)\n)\nselect id_1, id_2, id_3, lang from t1 where lang is not null\nunion all\nselect id_1, id_2, id_3, null as lang from t1 group by id_1, id_2, id_3 having max(lang) is null\norder by id_1, id_2, id_3\n\n\n\n\n\nID_1\nID_2\nID_3\nLANG\n\n\n\n\n1\n11\n111\nF_lang\n\n\n2\n22\n222\nnull\n\n\n3\n33\n333\nF_lang_3_1\n\n\n3\n33\n333\nF_lang_3_2\n\n\n\n\nfiddle\n"
},
{
"QuestionId": "76382933",
"QuestionTitle": "How to express h(n) which is the \"union\" of the two sequences f(n) & g(n)",
"QuestionBody": "I am on thin ice both syntax-wise and English-wise here, apologise if my way of expressing maths here is a rambling of a mad-man.\nI have two sequences/\"functions\" f(n) and g(n). They are technically not functions, I have them just defined as a sequence of repeating modulus of 9 and 10.\nn = 0,1,2,3,...\nf(n): nMOD9={0,3,4,6}\ng(n): nMOD10={0,3,4,5,8,9}\n\nThis means that f(n) is will go 0,3,4,6,9,12,13,15,18,ect. Just repeating the four numbers in the brackets of modulus of 9. \n\ng(n) will be 0,3,4,5,8,9,10,13,14,15,18,19,20,ect. Repeating the six numbers in brackets of modulus of 10.\n\nNow I wonder, can I express h(n) which is the list of numbers that is both present in f(n) and g(n)? This will be 0,3,4,9,13,15,18,ect. Either as a function or as some nMODx={a,b,c}? Or some other genius way I have not thought about. \n\nCurrently I do a manual check of both list, and I wonder if can be done more elegant.\n",
"AnswerId": "76388472",
"AnswerBody": "One possible solution would be to find all values of h(n) up to 90, then h(n) will be those nMOD90, so\nh(n): nMOD90={0,3,4,9,13,15,18,24,30,33,39,40,45,48,49,54,58,60,63,69,75,78,84,85}\n\n"
},
{
"QuestionId": "76388049",
"QuestionTitle": "\"BASE64DecoderStream\" gives error for javax-mail dependency",
"QuestionBody": "I recently changed the dependency\n<dependency>\n    <groupId>javax.mail</groupId>\n    <artifactId>mail</artifactId>\n    <version>1.4</version>\n</dependency>\n\nto\n<dependency>\n    <groupId>javax.mail</groupId>\n    <artifactId>javax.mail-api</artifactId>\n    <version>1.6.0</version>\n</dependency>\n\nbecause Java 8 doesn't support 1.4 version as it uses TLS 1.0.\nAfter changing the dependency this code starts giving error.\nError code:\nif (p.getContentType().contains(\"image/\")) {\n    File f = new File(\"image\" + new Date().getTime() + \".jpg\");\n    DataOutputStream output = new DataOutputStream(\n            new BufferedOutputStream(new FileOutputStream(f)));\n    \n    com.sun.mail.util.BASE64DecoderStream test = (com.sun.mail.util.BASE64DecoderStream) p\n            .getContent();\n    byte[] buffer = new byte[1024];\n    int bytesRead;\n    while ((bytesRead = test.read(buffer)) != -1) {\n        output.write(buffer, 0, bytesRead);\n    }\n\nEclipse suggestion error:\nMultiple markers at this line\n    - com.sun.mail.util.BASE64DecoderStream cannot be resolved to a type\n    - com.sun.mail.util.BASE64DecoderStream cannot be resolved to a type\n\n",
"AnswerId": "76388104",
"AnswerBody": "You're using the wrong dependency. You have only added the JakartaMail API. You should use the JakartaMail 1.6.x implementation:\n<dependency>\n    <groupId>com.sun.mail</groupId>\n    <artifactId>jakarta.mail</artifactId>\n    <version>1.6.7</version>\n</dependency>\n\nThis dependency does include com.sun.mail.util.BASE64DecoderStream.\nAs an aside, instead of what you're doing now (using getContent() and casting to an implementation-specific class), you could also use Part.getInputStream():\ntry (var in = p.getInputStream()) {\n    in.transferTo(output);\n}\n\nAlso, your use of DataOutputStream is suspect, as you don't seem to be using any DataOutputStream specific methods, so using the BufferedOutputStream directly should be sufficient.\n"
},
{
"QuestionId": "76389296",
"QuestionTitle": "Where should pygame.time.Clock().tick() be called in the script",
"QuestionBody": "According to this statement, pygame.time.Clock().tick() should be called at the end of the main loop. However, I couldn't see any differences on my screen display regardless where I executed that method within the loop. Could someone please give some clarification on this? Thanks\n",
"AnswerId": "76389365",
"AnswerBody": "The documentation say :\n\nA call to the tick() method of a Clock object in the game loop can\nmake sure the game runs at the same speed no matter how fast of a\ncomputer it runs on\n\nSo it is better to call it at the end of the loop because if you do it in the middle of your display fonction, a part of the element will be refresh before the wainting and a part after.You should call pygame.display.update() before that otherwise you refresh the screen after the \"frame wait time\".\n"
},
{
"QuestionId": "76383813",
"QuestionTitle": "Remote Interpreter DataSpell",
"QuestionBody": "I am trying to run scripts on a remote server with DataSpell, so I am trying to configure a remote interpreter.\nI follow these instructions and I get the error\nCannot Save Settings:\nSSH Python x.x.x user@IP : Python x.x.x\n(path/to/interpreter) can't be used as a workspace interpreter\n\nAs a path to the interpreter I have used the .../bin/python file that is created in a virtual environment. I have tried virtual environments created both with conda and venv. I have also found this, but I cannot understand the solution clearly.\nAny ideas?\n",
"AnswerId": "76388631",
"AnswerBody": "It appears that Dataspell can have different interpreters for its workspace and projects or notebooks that are opened in the workspace.\nI right-clicked the project folder in the Project window, and selected a remote interpreter just for the project. This is what the second source that I posted on my OP says. This works fine.\n"
},
{
"QuestionId": "76382654",
"QuestionTitle": "Microsoft Graph .NET SDK on-behalf-of flow returns Access Denied 403 for Sites/Files",
"QuestionBody": "I'm trying to implement on-behalf-of user flow for Microsoft Graph API. I'm using Microsoft Graph .NET SDK and I'm encountering Access Denied (status code 403) for my requests. I'm not sure how to correctly set up permissions for users of my organization in Active Azure Directory. I'm trying to implement SharePoint / OneDrive file operations like list files/download/upload etc. with on-behalf-of flow. I want to be able to access any drive/site files and be able to upload/download/list.\nThe way my application is designed is like this:\n\nBut instead of Desktop WPF app, I have next.js website using next-auth. This is how I define my Azure Active Directory provider to sign-in in my next.js application using next-auth:\nproviders: [\n    AzureADProvider({\n      clientId: process.env.AZURE_AD_CLIENT_ID, // NextAuth client id in AAD\n      clientSecret: process.env.AZURE_AD_CLIENT_SECRET, // NextAuth client secret value in AAD\n      tenantId: process.env.AZURE_AD_TENANT_ID, \n      authorization: {\n        params: {\n          scope: \"openid email profile offline_access api://NextAuthAPI/.default\",\n          prompt: \"consent\",\n        }\n      },\n    }),\n  ]\n\nIn my AAD I registered my frontend app and web api as NextAuth and NextAuthAPI, generated client secret for both of them. For the NextAuthAPI (webAPI) I created a scope:\n\nand added these permissions:\n\nFor the NextAuth (next.js) app I added this permission:\n\nAfter signing in my next.js frontend application, I'm able to receive an access token with:\n\"aud\": \"api://NextAuthAPI\",\n\"scp\": \"access_as_user\"\n....\n\nThen I provide this access_token to the webAPI and create client like this:\nvar scopes = new[] { \"https://graph.microsoft.com/.default\" };\n\nvar tenantId = \"c0dc-------------------5ce7\";\nvar clientId = \"087e66-----------------------b5\";\nvar clientSecret = \"p5Q8Q-----------------------JddpK\";\n\n// using Azure.Identity;\nvar options = new OnBehalfOfCredentialOptions\n{\n    AuthorityHost = AzureAuthorityHosts.AzurePublicCloud\n};\n\nvar oboToken = /* HERE I PASTE ACCESS_TOKEN FROM NEXTJS APP */;\n\nvar onBehalfOfCredential = new OnBehalfOfCredential(tenantId, clientId, clientSecret, oboToken, options);\n\nm_GraphClient = new GraphServiceClient(onBehalfOfCredential, scopes);\n\nNow, when I have the m_GraphClient initialized, I'm trying to make some requests. This request works for me:\nvar response = await m_GraphClient.Me.GetAsync();\n\nBut something like this:\nvar response2 = await m_GraphClient.Sites.GetAllSites.GetAsync();\n\nthrows an ODataError exception with status code 403 and message \"Access denied\".\nPackages I use:\n\nMicrosoft.Graph 5.11.0 (backend)\nAzure.Identity 1.9.0 (backend)\nNext.JS 13.4.5-canary.2 (frontend)\nnext-auth 4.22.1 (frontend)\n\n",
"AnswerId": "76388806",
"AnswerBody": "You want to be able to access any drive/site files and be able to upload/download/list. Then on-behalf-of flow isn't suitable for you. OBO flow will generate access token with Delegated API permission, which can't be used to access any others' drive/site files. We need to use access token with Application API permission.\nThen in this scenario, we can only use client credential flow so that we can generate access token with Application API permission. First, grant application API permission in Azure portal. For example, we are trying to use this Graph API.\n\nThen in your API application, your code should look like this which used ClientSecretCredential instead of your OnBehalfOfCredential:\nvar scopes = new[] { \"https://graph.microsoft.com/.default\" };\nvar tenantId = \"tenant_id\";\nvar clientId = \"client_id\";\nvar clientSecret = \"client_secret\";\nvar clientSecretCredential = new ClientSecretCredential(\n                            tenantId, clientId, clientSecret);\nvar graphClient = new GraphServiceClient(clientSecretCredential, scopes);\n\n"
},
{
"QuestionId": "76387995",
"QuestionTitle": "Gitlab CI Deploy Token cant push to repo",
"QuestionBody": "I am trying to copy some files from Firebase into a Gitlab repo.\nUsing my personal SSH credentials, I am able to do this.\nI'd like to use deploy tokens. I generated a fresh token and gave it all the permissions I can. However, when I run the CI pipeline I get an \"fatal: Authentication failed\"\n",
"AnswerId": "76388110",
"AnswerBody": "A deploy token is simply not made for that. As per the documentation a deploy token is not capable to write to a GitLab repository. Here is what you can do with a deploy token:\n\nClone Git repositories.\nPull from and push to a GitLab container registry.\nPull from and push to a GitLab package registry.\n\nWhat may be a better fit for your use case is a so called Deploy Key. If the deploy key has read-write permissions you should be able to solve your issues.\n"
},
{
"QuestionId": "76389214",
"QuestionTitle": "Replace one button with another when countdown timer ends",
"QuestionBody": "I have a simple countdown timer which is launched on the click of the .btn-submit-a button. I tried to make it so that after the timer ends, button A is replaced by button B (.btn-submit-b), but, unfortunately, nothing comes out. How can I achieve this? I will be glad for any help.\n\n\njQuery(function($){\n  $('.btn-submit-a').on('click', doCount);\n});\n\nfunction doCount() {\nvar timeleft = 5;\nvar downloadTimer = setInterval(function(){\n  if(timeleft <= 0){\n    clearInterval(downloadTimer);\n    document.getElementById(\"countdown\").innerHTML = \"Time is Up\";\n  } else {\n    document.getElementById(\"countdown\").innerHTML = timeleft + \"<span class='remain'>seconds remain</span>\";\n  }\n  timeleft -= 1;\n}, 1000);\n};\n.btn-submit-b {\n  display: none;\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<button type=\"submit\" class=\"btn-submit-a\">Button A</button>\n<button type=\"submit\" class=\"btn-submit-b\">Button B</button>\n\n<div id=\"countdown\"></div>\n\n\n\n",
"AnswerId": "76389384",
"AnswerBody": "You had a weird combination between jquery and native code. You can do that ofcourse but I would recommend to stick to either jQuery or native where possible. Therefore I changed some code to jQuery functions.\nThis said you can hide and show elements with the hide() and show() jQuery functions as you can see in the example below.\nIf you want to toggle them instead you can use toggle()\n\n\njQuery(function($) {\n  $('.btn-submit-a').on('click', doCount);\n});\n\nfunction doCount() {\n  var timeleft = 5;\n  var downloadTimer = setInterval(function() {\n    if (timeleft <= 0) {\n      clearInterval(downloadTimer);\n      $(\"#countdown\").html(\"Time is Up\");\n      $('.btn-submit-a').hide();\n      $('.btn-submit-b').show();\n    } else {\n      $(\"#countdown\").html(timeleft + \"<span class='remain'>seconds remain</span>\");\n    }\n    timeleft -= 1;\n  }, 1000);\n};\n.btn-submit-b {\n  display: none;\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<button type=\"submit\" class=\"btn-submit-a\">Button A</button>\n<button type=\"submit\" class=\"btn-submit-b\">Button B</button>\n\n<div id=\"countdown\"></div>\n\n\n\n"
},
{
"QuestionId": "76389116",
"QuestionTitle": "Clob Issues- Splitting a clob column to multiple rows",
"QuestionBody": "I have a table (description of table):\n\n\n\n\nName\nType\n\n\n\n\nKEYVALUE\nVARCHAR2(100)\n\n\nTEXT\nCLOB\n\n\n\n\nExample\n\n\n\n\nKeyvalue\nText\n\n\n\n\n101\nCustomer Input 05/15/2023 07:20:20 My name is ABX +++ Private Notes What is you name+++Customer Input 04/30/2023 19:40:58 I have issue related to water purifier purchased on Jan 23 +++ Public Notes 04/30/2023 18:19:18 +++Customer Input 04/30/2023 Requesting to send a technicial, we could not bring them up due to the same issue that was looked into in ticket 20092. We dont know if this is the same issue as the previous ticket, but need to know the reason Language Preference: English\n\n\n102\nCustomer Input 05/15/2023 07:20:20 20424596 Reference to the above ticket+++Customer Input 04/30/2023 19:40:58 Plesae replace the item as this is a faulty one +++ Public Notes 04/30/2023 18:19:18 +++Customer Input 04/30/2023 17:54:54 Shared the faulty machine pics for quick action Problem Context: When was the issue first observed? - 4/30, 1AM or so Were there any recent changes or maintenance performed? - Language Preference: English\n\n\n\n\nI am basically splitting the entire phase to multiple rows by the word \"customer Input\".\nSomething like below:\nSELECT distinct keyvalue, level pos, trim(regexp_substr(text, 'Customer Input[^+++]*', 1, level))  x\n  FROM \n  (\n    SELECT 101 as keyvalue,'Customer Input 05/15/2023 07:20:20 My name is ABX +++ Private Notes What is you name+++Customer Input 04/30/2023 19:40:58 I have issue related to water purifier purchased on Jan 23 \n    +++ Public Notes 04/30/2023 18:19:18 +++Customer Input 04/30/2023 Requesting to send a technicial, we could not bring them up due to the same issue that was looked into in ticket 20092. We dont know if this is the same issue as the previous ticket, but need to know the reason Language Preference: English| '\n    as text from dual\n    union all \n    SELECT 102 as keyvalue,' Customer Input 05/15/2023 07:20:20 20424596 Reference to the above ticket+++Customer Input 04/30/2023 19:40:58 Plesae replace the item as this is a faulty one \n    +++ Public Notes 04/30/2023 18:19:18 +++Customer Input 04/30/2023 17:54:54 Shared the faulty machine pics for quick action Problem Context: When was the issue first observed? - 4/30, 1AM or so Were there any recent changes \n    or maintenance performed? - Language Preference: English| '\n    as text from dual  \n\n  ) t\nCONNECT BY instr(text, 'Customer Input', 1, level - 1) > 0\norder by keyvalue;\n\n\n\n\n\nkeyvalue\npos\ntext\n\n\n\n\n101\n1\nCustomer Input 05/15/2023 07:20:20 My name is ABX\n\n\n101\n2\nCustomer Input 04/30/2023 19:40:58 I have issue related to water purifier purchased on Jan 23\n\n\n101\n3\nCustomer Input 04/30/2023 Requesting to send a technicial, we could not bring them up due to the same issue that was looked into in ticket 20092. We dont know if this is the same issue as the previous ticket, but need to know the reason Language Preference: English\n\n\n101\n4\n\n\n\n102\n1\nCustomer Input 05/15/2023 07:20:20 20424596 Reference to the above ticket\n\n\n102\n2\nCustomer Input 04/30/2023 19:40:58 Please replace the item as this is a faulty one\n\n\n102\n3\nCustomer Input 04/30/2023 17:54:54 Shared the faulty machine pics for quick action Problem Context: When was the issue first observed? - 4/30, 1AM or so Were there any recent changes or maintenance performed? - Language Preference: English\n\n\n102\n4\n\n\n\n\n\nThis is working fine since the text column is of character datatype.\nBut when I am running this below query (on the actual column which is of clob datatype)\nSELECT distinct keyvalue, level pos, trim(regexp_substr(customer_input_info, 'Customer Input[^+++]*', 1, level)) str\n  FROM (select 101 as keyvalue,to_clob('Customer Input 05/15/2023 07:20:20 20424596 Reference to the above ticket+++Customer Input 04/30/2023 19:40:58 Plesae replace the item as this is a faulty one \n    +++ Public Notes 04/30/2023 18:19:18 +++Customer Input 04/30/2023 17:54:54 Shared the faulty machine pics for quick action Problem Context: When was the issue first observed? - 4/30, 1AM or so Were there any recent changes \n    or maintenance performed? - Language Preference: English| ') as customer_input_info from dual) t\nCONNECT BY instr(customer_input_info, 'Customer Input', 1, level - 1) > 0\norder by 1\n\nI am getting below error\nORA-00932: inconsistent datatypes: expected - got CLOB\n00932. 00000 -  \"inconsistent datatypes: expected %s got %s\"\n*Cause:\n*Action:\nError at Line: 44 Column: 38.\nI can't make changes to inner sql query as the source table is of clob data type. What changes should I make to outer query.\n",
"AnswerId": "76389387",
"AnswerBody": "The code you posted will get that error if the source text is a CLOB, whatever the length. The problem isn't the length itself, it's that each split row value is also a CLOB, and you can't use distinct with CLOBs.\nThe use of distinct is often a sign that there's a deeper problem that's just covering up. Without it you do get duplicates, but that's a well-known issue with connect-by queries against multiple source rows, and will get progressively worse with more rows.\nYou need to limit the connect-by to the same source row, which is simple assuming keyvalue is unique; but you also need to introduce a non-deterministic function call to prevent it ballooning the results, for example:\nCONNECT BY instr(text, 'Customer Input', 1, level - 1) > 0\nAND keyvalue = PRIOR keyvalue\nAND PRIOR dbms_random.value IS NOT NULL\n\nfiddle\nYou might finder it easier to understand and maintain if you switch to using recursive subquery factoring instead of a hierarchical query:\nWITH r (keyvalue, text, pos, x) as (\n  SELECT keyvalue, text, 1, trim(regexp_substr(text, 'Customer Input[^+++]*', 1, 1))\n  FROM t\n  UNION ALL\n  SELECT keyvalue, text, pos + 1, trim(regexp_substr(text, 'Customer Input[^+++]*', 1, pos + 1))\n  FROM r\n  WHERE instr(text, 'Customer Input', 1, pos) > 0\n)\nSELECT keyvalue, pos, x\nFROM r\norder by keyvalue, pos;\n\n\n\n\n\nKEYVALUE\nPOS\nX\n\n\n\n\n101\n1\nCustomer Input 05/15/2023 07:20:20 My name is ABX\n\n\n101\n2\nCustomer Input 04/30/2023 19:40:58 I have issue related to water purifier purchased on Jan 23 \n\n\n101\n3\nCustomer Input 04/30/2023 Requesting to send a technicial, we could not bring them up due to the same issue that was looked into in ticket 20092. We dont know if this is the same issue as the previous ticket, but need to know the reason Language Preference: English|\n\n\n101\n4\n\n\n\n102\n1\nCustomer Input 05/15/2023 07:20:20 20424596 Reference to the above ticket\n\n\n102\n2\nCustomer Input 04/30/2023 19:40:58 Plesae replace the item as this is a faulty one \n\n\n102\n3\nCustomer Input 04/30/2023 17:54:54 Shared the faulty machine pics for quick action Problem Context: When was the issue first observed? - 4/30, 1AM or so Were there any recent changes     or maintenance performed? - Language Preference: English|\n\n\n102\n4\n\n\n\n\n\nfiddle\nI've left it with the same stop condition, which generates a final null entry. You may want to revisit that, for either approach.\n"
},
{
"QuestionId": "76383547",
"QuestionTitle": "How can I get Ansible client IP from target host?",
"QuestionBody": "On an isolated network (without internet access to do public IP address lookups), I want to run a playbook from a controller against a number of target hosts where one of the tasks is to download a file via HTTP/HTTPS from the controller without hard-coding the controller IP as part of the task. E.g.\nController: 192.168.0.5\nTarget 1: 192.168.0.10\nTarget 2: 192.168.0.11\nTarget 3: 192.168.0.12\n\nThe controller can have different IPs configured via DHCP, and there could be multiple network interfaces listed in ansible_all_ipv4_addresses (some of which may not be available to the target hosts) so it may not be straight forward to determine which network interface the target hosts should use from ansible_facts on localhost without exploring the idea of looping through them with a timeout until the file has been downloaded. It seems as though the most robust way to determine the public IP of the controller (assuming the web server is listening on 0.0.0.0) would be to determine the originating IP of the established connection (192.168.0.5) from the target host - is there a way to do this?\nThe motivation for downloading the file from the controller rather than sending it to remote hosts is that some of the target hosts are running Windows and the win_copy module is incredibly slow via WinRM so the Ansible documentation includes the following note:\n\nBecause win_copy runs over WinRM, it is not a very efficient transfer\nmechanism. If sending large files consider hosting them on a web\nservice and using ansible.windows.win_get_url instead.\n\n",
"AnswerId": "76389112",
"AnswerBody": "Limited test on my machine which has a single ip and with a single target. But I don't see why it would not work in your scenario.\nGiven the following inventories/default/hosts.yml\nall:\n  hosts:\n    target1:\n      ansible_host: 192.168.0.10\n    target2:\n      ansible_host: 192.168.0.11\n    target3:\n      ansible_host: 192.168.0.12\n\nThe following test playbook should do what you expect. Replace the dummy debug task with get_url/uri to initiate the download.\nNotes:\n\nthis playbook infers you have access to the ip command line tool on the controller.\nI took for granted that the controller IP used to connect to target is the one that the target has access to in the other direction. If this isn't the case then the below will not work in your situation.\n\n---\n- hosts: all\n  gather_facts: false\n\n  tasks:\n    - name: Check route on controller for each target destination\n      ansible.builtin.command: ip route get {{ ansible_host }}\n      register: route_cmd\n      delegate_to: localhost\n\n    - name: Register the controller outgoing ip for each target\n      ansible.builtin.set_fact:\n        controller_ip: \"{{ route_cmd.stdout_lines[0] | regex_replace('^.* src (\\\\d*(\\\\.\\\\d*){3}).*$', '\\\\1') }}\"\n\n    - name: Show result\n      ansible.builtin.debug:\n        msg: \"I would connect from target {{ inventory_hostname }} ({{ ansible_host }}) \n          to controller using ip {{ controller_ip }}\"\n\n"
},
{
"QuestionId": "76387851",
"QuestionTitle": "How can I split an array of objects and extract specific keys while adding 0s to fill up to a specific length?",
"QuestionBody": "My array of objects looks like this:\n[{\"data\": [5, 2, 7, 2, 4, 2], \"date\": {\"begin\": \"03.07.\", \"beginYear\": \"2023\", \"end\": \"10.07.\", \"endYear\": \"2023\", \"timestamp\": 1688335200000}}, {\"data\": [5, 2, 7, 2, 4, 2], \"date\": {\"begin\": \"26.06.\", \"beginYear\": \"2023\", \"end\": \"03.07.\", \"endYear\": \"2023\", \"timestamp\": 1687730400000}}, {\"data\": [5, 2, 7, 2, 4, 2], \"date\": {\"begin\": \"19.06.\", \"beginYear\": \"2023\", \"end\": \"26.06.\", \"endYear\": \"2023\", \"timestamp\": 1687125600000}}, {\"data\": [5, 2, 7, 2, 4, 2], \"date\": {\"begin\": \"12.06.\", \"beginYear\": \"2023\", \"end\": \"19.06.\", \"endYear\": \"2023\", \"timestamp\": 1686520800000}}, {\"data\": [5, 2, 7, 2, 4, 2], \"date\": {\"begin\": \"05.06.\", \"beginYear\": \"2023\", \"end\": \"12.06.\", \"endYear\": \"2023\", \"timestamp\": 1685916000000}}, {\"data\": [5, 2, 7, 2, 4, 2], \"date\": {\"begin\": \"29.05.\", \"beginYear\": \"2023\", \"end\": \"05.06.\", \"endYear\": \"2023\", \"timestamp\": 1685311200000}}]\n\nI want to map through the array, checking if the data key contains more than 4 numbers and if so, I want to extract the first 4 numbers (each data key is the same in all objects) and put it into a new object key \"data\" and the date key should look like the first item of the original array. The rest of the data key (in this example [4,2] should go into a new array that will be filled up with 0s until the data's length is 4. The date key of this should contain the date in 4 weeks starting from the first date.\nI want to modify it so the result will be like this:\n[{\n    data: [ 5, 2, 7, 2 ],\n    date: {\n      begin: '29.05.',\n      beginYear: '2023',\n      end: '05.06.',\n      endYear: '2023',\n      timestamp: 1685311200000\n    }\n  },\n{\n    data: [4, 2, 0, 0 ],\n    date: {\n      begin: '26.06.',\n      beginYear: '2023',\n      end: '03.07.',\n      endYear: '2023',\n      timestamp: 1687730400000\n    }\n  }\n]\n\nThe logic should also applicable if the data key contains more numbers\nI tried it several times but somehow it doesn't as planned.\nconst fourStack = []\n\n    const firstFourItems = result.slice(0, 4)\n    const restItems = result.slice(4)\n\n    const firstItem = firstFourItems[0]\n    const newData = firstFourItems.map((item) => item.data.slice(0, 4))\n    const newObj = {\n      data: newData,\n      date: {\n        begin: firstItem.date.begin,\n        beginYear: firstItem.date.beginYear,\n        end: firstItem.date.end,\n        endYear: firstItem.date.endYear,\n        timestamp: firstItem.date.timestamp\n      }\n    }\n\n    fourStack.push(newObj)\n\n    restItems.forEach((item) => {\n      fourStack.push({\n        data: item.data.slice(0, 4),\n        date: {\n          begin: newObj.date.begin,\n          beginYear: newObj.date.beginYear,\n          end: newObj.date.end,\n          endYear: newObj.date.endYear,\n          timestamp: newObj.date.timestamp\n        }\n      })\n    })\n\nIt gives me, not the result I want. Instead, it gives me this:\n[{\"data\": [[Array], [Array], [Array], [Array]], \"date\": {\"begin\": \"03.07.\", \"beginYear\": \"2023\", \"end\": \"10.07.\", \"endYear\": \"2023\", \"timestamp\": 1688335200000}}, {\"data\": [5, 2, 7, 2], \"date\": {\"begin\": \"03.07.\", \"beginYear\": \"2023\", \"end\": \"10.07.\", \"endYear\": \"2023\", \"timestamp\": 1688335200000}}, {\"data\": [5, 2, 7, 2], \"date\": {\"begin\": \"03.07.\", \"beginYear\": \"2023\", \"end\": \"10.07.\", \"endYear\": \"2023\", \"timestamp\": 1688335200000}}]\n\n",
"AnswerId": "76388128",
"AnswerBody": "\n\nlet arr = [{\n  \"data\": [5, 2, 7, 2, 4, 2],\n  \"date\": {\n    \"begin\": \"03.07.\",\n    \"beginYear\": \"2023\",\n    \"end\": \"10.07.\",\n    \"endYear\": \"2023\",\n    \"timestamp\": 1688335200000\n  }\n}, {\n  \"data\": [5, 2, 7, 2, 4, 2],\n  \"date\": {\n    \"begin\": \"26.06.\",\n    \"beginYear\": \"2023\",\n    \"end\": \"03.07.\",\n    \"endYear\": \"2023\",\n    \"timestamp\": 1687730400000\n  }\n}, {\n  \"data\": [5, 2],\n  \"date\": {\n    \"begin\": \"19.06.\",\n    \"beginYear\": \"2023\",\n    \"end\": \"26.06.\",\n    \"endYear\": \"2023\",\n    \"timestamp\": 1687125600000\n  }\n}, {\n  \"data\": [5, 2, 7, 2, 4, 2],\n  \"date\": {\n    \"begin\": \"12.06.\",\n    \"beginYear\": \"2023\",\n    \"end\": \"19.06.\",\n    \"endYear\": \"2023\",\n    \"timestamp\": 1686520800000\n  }\n}, {\n  \"data\": [5, 2, 7, 2, 4, 2],\n  \"date\": {\n    \"begin\": \"05.06.\",\n    \"beginYear\": \"2023\",\n    \"end\": \"12.06.\",\n    \"endYear\": \"2023\",\n    \"timestamp\": 1685916000000\n  }\n}, {\n  \"data\": [5],\n  \"date\": {\n    \"begin\": \"29.05.\",\n    \"beginYear\": \"2023\",\n    \"end\": \"05.06.\",\n    \"endYear\": \"2023\",\n    \"timestamp\": 1685311200000\n  }\n}];\n\narr.map((e) => {\n  if (e.data.length > 4) {\n    e.data = e.data.slice(0, 4);\n  } else {\n    let length = 4 - e.data.length;\n    for (let i = 0; i < length; i++) {\n      e.data.push(0);\n    }\n  }\n\n})\nconsole.log(arr);\n\n\n\n"
},
{
"QuestionId": "76382277",
"QuestionTitle": "How to create/update key/value pair in JFrog Artifactory with PHP and cURL?",
"QuestionBody": "I am using PHP 8.2 to read our JFrog Artifactory API and this works fine. Now I am in the need to either create or update some of the properties on an artifact - so either create it if it does not exists, and update it if it does exists.\nFor example I can read all properties for a specific artifactory with this code:\n<?PHP\n\n// The full URL for the specific artifact and its \"properties\"\n$api = \"https://mysrv/api/storage/TestProduct/TestComponent/1.0.0/?properties\";\n\n$ch = curl_init($api);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, false);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, array(\n    \"X-JFrog-Art-Api: \". $artifactoryKey,\n));\n\n// Execute the request to retrieve existing properties\n$response = curl_exec($ch);\necho \"<pre>\";\nvar_dump($response);\n\n?>\n\nThis will dump something like this:\nstring(123) \"{\n    \"properties\" : {\n        \"ComponentName\" : [ \"TestComponent\" ],\n        \"ContactEmail\" : [ \"me@nowhere.com\" ],\n        \"ContactName\" : [ \"John Doe\" ],\n        \"VersionNumber\" : [ \"1.0.0\" ]\n    },\n    \"uri\" : \"https://mysrv/api/storage/TestProduct/TestComponent/1.0.0\"\n}\"\n\nNow I want to create a new key/value pair inside the properties.\nFor example if I want to create a new key named MyKey with a value of False then I would like to see this result:\nstring(123) \"{\n    \"properties\" : {\n        \"ComponentName\" : [ \"TestComponent\" ],\n        \"ContactEmail\" : [ \"me@nowhere.com\" ],\n        \"ContactName\" : [ \"John Doe\" ],\n        \"VersionNumber\" : [ \"1.0.0\" ]\n        \"MyKey\" : [ \"False\" ]\n    },\n    \"uri\" : \"https://mysrv/api/storage/TestProduct/TestComponent/1.0.0\"\n}\"\n\nI have of course tried various solutions like:\n// Define the new key/value pair\n$newProperty = array(\n    'key' => \"MyKey\",\n    'value' => \"False\"\n);\n\n// Prepare the JSON payload\n$payload = json_encode(array(\"properties\" => array($newProperty)));\n\n// Initialize cURL to update the properties\n$ch = curl_init($api);\ncurl_setopt($ch, CURLOPT_CUSTOMREQUEST, 'PUT');\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, false);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, array(\n    'Content-Type: application/json',\n    'X-JFrog-Art-Api: ' . $artifactoryKey\n));\ncurl_setopt($ch, CURLOPT_POSTFIELDS, $payload);\n\n// Execute the request to update the properties\n$response = curl_exec($ch);\necho \"<pre>\";\nvar_dump($response);\n\n... and various tweaks to this but I cannot get it to work. Doing the above solution will give me this error:\nstring(98) \"{\n    \"errors\" : [ {\n        \"status\" : 400,\n        \"message\" : \"Properties value cannot be empty.\"\n    } ]\n}\"\n\nMy account should have anough access to write/modify (I am not the admin but have been told so) but the error message does not look like it is related to permissions either, so any help on this would be appreciated - I expect this may be a simple fix as I have not much experience with handling Artifactory stuff :-)\n",
"AnswerId": "76389186",
"AnswerBody": "Actually I did figure out this myself and it was a stupid/simple mistake. I easily solved this after finding the right help page - I should probably have invested more time in finding this in the first place :-)\nLet me show the solution first:\n<?PHP\n\n// Full URL for specific artifact and the property to create/update\n$api = \"https://mysrv/api/storage/TestProduct/TestComponent/1.0.0/?properties=MyKey=False\";\n\n// Initialize cURL to create/update the properties\n$ch = curl_init($api);\ncurl_setopt($ch, CURLOPT_CUSTOMREQUEST, \"PUT\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, false);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, array(\n    \"Content-Type: application/json\",\n    \"X-JFrog-Art-Api: \". $artifactoryKey\n));\n\n// Execute the cURL request\n$response = curl_exec($ch);\n\n// Dump the result\necho \"<pre>\";\nvar_dump($response);\n\n// Check if the request was successful\n$httpCode = curl_getinfo($ch, CURLINFO_HTTP_CODE);\nvar_dump($httpCode);\n\n// Close the cURL session\ncurl_close($ch);\n\n?>\n\nThis code will result in a HTTP Status 204 (No Content) which equals a success and it will create the new propery named MyKey with the value of False. The cURL PUT command will work for both creating it or updating the value.\nFound the help for it here, https://jfrog.com/help/r/jfrog-rest-apis/set-item-properties\n"
},
{
"QuestionId": "76388109",
"QuestionTitle": "How to export a PyTorch model for HuggingFace?",
"QuestionBody": "I have been training my custom Image classification model on the PyTorch transformers library to deploy to hugging face however, I cannot figure out how to export the model in the correct format for HuggingFace with its respective config.json file.\nI'm new to PyTorch and AI so any help would be greatly appreciated\ntrain.py\nfrom tqdm import tqdm\n\nbest_accuracy = 0\n\n# Train the model for a number of epochs\nfor epoch in range(20):\n    # Create a progress bar for this epoch\n    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{20}')\n    \n    # Loop over each batch of data\n    for X_batch, y_batch in pbar:\n        # Move the batch of data to the device\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        # Zero the gradients...\n        # Define an optimizer...\n        \n        # Update the progress bar\n        pbar.set_postfix({'Loss': loss.item()})\n    \n    # Evaluate the model on the validation set\n    model.eval()\n    correct = 0\n    total = 0\n    val_loss = 0\n    \n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            # Move the batch of data to the device\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            \n            # Compute the model's predictions for this batch of data\n            y_pred = model(X_batch)\n            \n            # Compute the loss\n            loss = criterion(y_pred, y_batch)\n            val_loss += loss.item()\n            \n            # Compute the number of correct predictions\n            _, predicted = torch.max(y_pred.data, 1)\n            total += y_batch.size(0)\n            correct += (predicted == y_batch).sum().item()\n    \n    val_loss /= len(test_loader)\n    accuracy = correct / total\n    \n    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n    \n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        torch.save(model.state_dict(), 'best_model.pth')\n    \n    model.train()\n\n",
"AnswerId": "76388143",
"AnswerBody": "You are using HuggingFace Transformers, you can use:\nmodel.save_pretrained(\"FOLDER_NAME_HERE\")\n\nAfter you saved the model, the folder will contain the pytorch_model.bin along with config JSONs.\n"
},
{
"QuestionId": "76389395",
"QuestionTitle": "AttributeError: module 'numpy' has no attribute 'long'",
"QuestionBody": "I am trying to find 9 raise to power 19 using numpy.\nI am using numpy 1.24.3\nThis is the code I am trying:\nimport numpy as np\nnp.long(9**19)\n\nThis is the error I am getting:\nAttributeError: module 'numpy' has no attribute 'long'\n\n",
"AnswerId": "76389396",
"AnswerBody": "Sadly, numpy.long was deprecated in numpy 1.20 and it is removed in numpy 1.24\nIf you wan the result you have to try numpy.longlong\nimport numpy as np\nnp.longlong(9**19)\n\n#output\n1350851717672992089\n\nhttps://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
},
{
"QuestionId": "76390641",
"QuestionTitle": "403 for the new pages in the cloudfront distribution",
"QuestionBody": "I have a static web site in the s3 bucket behind the cloudfront distribution.\nThe bucket serves the static site, and the origin is bound to the web site endpoint.\nI see a couple of pages if they were added before the distribution\nHowever, when I upload some new html files, I receive 403 for them.\nHow should I fix this issue?\nBucket policy:\n{\n    \"Version\": \"2008-10-17\",\n    \"Id\": \"PolicyForCloudFrontPrivateContent\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AllowCloudFrontServicePrincipal\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"cloudfront.amazonaws.com\"\n            },\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:PutObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::a-test-upload/*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"AWS:SourceArn\": \"arn:aws:cloudfront::xxx:distribution/yyy\"\n                }\n            }\n        }\n    ]\n}\n\n",
"AnswerId": "76390728",
"AnswerBody": "Try to invalidate cloudfront cache. Go to cloud front distribution and click on invalidation enter \"/*\". Click on create invalidation.\nIf you are trying to access object publicly, then provide public access to s3 bucket objects.\n"
},
{
"QuestionId": "76387987",
"QuestionTitle": "Get the end_time in a query using the start time of the next sorted column",
"QuestionBody": "Imagine I have the following SQL table:\n| id | price | start_time |\n---------------------------\n|  1 |  0.1  | 2023-01-01 |\n|  2 |  0.3  | 2023-03-01 |\n|  3 |  0.2  | 2023-02-01 |\n\nBut then I want to query the prices in that table in a way that I can also get the end time as the start time of the next in time column. So, as an example, if I want to query all the entries in the table I would get something like this:\n| id | price | start_time | end_time   |\n----------------------------------------\n|  1 |  0.1  | 2023-01-01 | 2023-02-01 | // end_time = start_time of the next entry\n|  3 |  0.2  | 2023-02-01 | 2023-03-01 |\n|  2 |  0.3  | 2023-03-01 |            |\n\nBut, I would also like to query that table with others filters, as an example, all entries whose prices are lower than 0.25, then I expect:\n| id | price | start_time | end_time   |\n----------------------------------------\n|  1 |  0.1  | 2023-01-01 | 2023-02-01 |\n|  3 |  0.2  | 2023-02-01 | 2023-03-01 | end_time = start_time of entry with id 2\n\nSo even that the entry with id 2 is filtered out, its start_time is still used as end_time of one of the entries.\nIs this possible to achieve with one single query? I am bit lost on how to solve this approach without doing multiple queries.\n",
"AnswerId": "76388168",
"AnswerBody": "This can be done using the window function lead() to get the which follows the current row :\nselect *, lead(start_time) over (order by start_time) as end_time\nfrom mytable\n\nWith where clause it can be :\nselect * from (\n  select *, lead(start_time) over (order by start_time) as end_time\n  from mytable\n) as s\nwhere price < 0.25\n\nDemo here\n"
},
{
"QuestionId": "76388994",
"QuestionTitle": "Next.js 13.4 and NextAuth Type Error: 'AuthOptions' is not assignable to type 'never'",
"QuestionBody": "I'm currently working on a Next.js 13.4 project and trying to set up NextAuth using the app/ router. However, I'm encountering a type error that I can't seem to resolve.\nHere's my route.ts file:\nimport NextAuth, { AuthOptions } from \"next-auth\";\nimport DiscordProvider from \"next-auth/providers/discord\";\n\nexport const authOptions: AuthOptions = {\n  providers: [\n    DiscordProvider({\n      clientId: process.env.CLIENT_ID as string,\n      clientSecret: process.env.CLIENT_SECRET as string,\n    }),\n  ],\n  session: {\n    strategy: \"jwt\",\n  },\n  secret: process.env.NEXTAUTH_SECRET,\n}\n\nconst handler = NextAuth(authOptions);\n\nexport { handler as GET, handler as POST }\n\nAnd here's the error message when running 'npm run build':\n- info Linting and checking validity of types ...Failed to compile.\n\n.next/types/app/api/auth/[...nextauth]/route.ts:8:13\nType error: Type 'OmitWithTag<typeof import(\"C:/Users/Luk/Documents/Workspace/zerotwo-dash/src/app/api/auth/[...nextauth]/route\"), \"GET\" | \"POST\" | \"HEAD\" | \"OPTIONS\" | \"PUT\" | \"DELETE\" | \"PATCH\" | \"config\" | ... 6 more ... | \"runtime\", \"\">' does not satisfy the constraint '{ [x: string]: never; }'.\n  Property 'authOptions' is incompatible with index signature.\n    Type 'AuthOptions' is not assignable to type 'never'.\n\n   6 |\n   7 | // Check that the entry is a valid entry\n>  8 | checkFields<Diff<{\n     |             ^\n   9 |   GET?: Function\n  10 |   HEAD?: Function\n  11 |   OPTIONS?: Function\n\nI really have no idea whats happening here... when looking up the 'AuthOptions' on t he github page from nextauth i see nothing wrong with my code..\nI would appreciate any insights or suggestions on how to resolve this issue. Thanks in advance!\n",
"AnswerId": "76389403",
"AnswerBody": "Okay i solved it myself. For anyone having the same issue, i created a new file @/utils/authOptions.ts:\nimport { NextAuthOptions } from \"next-auth\";\nimport DiscordProvider from \"next-auth/providers/discord\";\n\nexport const authOptions: NextAuthOptions = {\n    providers: [\n        DiscordProvider({\n            clientId: process.env.CLIENT_ID as string,\n            clientSecret: process.env.CLIENT_SECRET as string,\n        }),\n    ],\n    session: {\n        strategy: \"jwt\",\n    },\n    secret: process.env.NEXTAUTH_SECRET,\n}\n\nand used it in @/api/auth/[...nextauth]/route.ts:\nimport { authOptions } from \"@/utils/authOptions\";\nimport NextAuth from \"next-auth/next\";\n\nconst handler = NextAuth(authOptions);\n\nexport { handler as GET, handler as POST };\n\nI changed the imports a little (import NextAuth from \"next-auth/next\")\nI dont know why this works tbh, but it does... even changing the imports around in my route.ts as it was before wont fix it. Only if its seperated like that...\n"
},
{
"QuestionId": "76390749",
"QuestionTitle": "is defined but never used no-unused-var",
"QuestionBody": "I'm New to React, and I'm trying to learn about React Component right now. but when I create nameList.js, add data in there, and export to app.js, it does not show anything in the browser. I read some answers in Stackoverflow and tried it. but not show anything.\nApp.js\nimport './App.css';\nimport nameList from './Components/nameList';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <div className=\"App\" >\n            <nameList/>\n        </div>\n    </div>\n  );\n}\n\nexport default App;\n\n\nnameList.js in Component Folder\n\nimport React from 'react';\n\nfunction nameList() {\n    return (\n    <div>\n       <h1>Name List</h1>\n        <ul>\n            <li>Stu1</li>\n            <li>Stu2</li>\n            <li>Stu3</li>\n        </ul>\n    </div>\n  )\n}\n\nexport default nameList;\n\nI need to get data in nameList.js into App.js\n",
"AnswerId": "76390796",
"AnswerBody": "Ensure that nameList starts with a capital letter so that React knows it's a component and not an HTML element.\nimport React from 'react';\n\nfunction NameList() {\n    return (\n    <div>\n       <h1>Name List</h1>\n        <ul>\n            <li>Stu1</li>\n            <li>Stu2</li>\n            <li>Stu3</li>\n        </ul>\n    </div>\n  )\n}\n\nexport default NameList;\n\nApp.js\nimport './App.css';\nimport NameList from './Components/nameList';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <div className=\"App\" >\n            <NameList/>\n        </div>\n    </div>\n  );\n}\n\nexport default App;\n\nhttps://react.dev/learn/your-first-component#what-the-browser-sees\n"
},
{
"QuestionId": "76387775",
"QuestionTitle": "useState() not updated when state is used in a loop",
"QuestionBody": "This code is where I modified the data, wherein I update the \"checked\" to whether \"true\" or \"false\". and this code works because when I console.log() it it updates the state.\n    setRolesData((prevState) => {\n        const newState = Array.from(prevState);\n        newState[targetCb][\"checked\"] = e.target.checked;\n        return newState;\n    });\n    console.log(rolesData);\n\nImage of the result:\n\nThis code is where I loop thru the data that is updated, but the problem is it doesnt return the same data as the log data if tried for the second time.\n    // get all checked roles\n    const roleArr: any = [];\n    rolesData.map((item, index) => {\n\n        console.log(item.checked + \" ^ \" + item.name);\n\n    });\n\nImage of the Result:\n\n",
"AnswerId": "76388177",
"AnswerBody": "In React, components have a lifecycle that is based around the idea of preserving state. When you update a value in a component we effectively trigger a re-render of the component. So if you have a variable at the top of your component with a certain value and try to update this value inside a function, you'll find that this value gets reset. React is replacing the component including the JavaScript variables inside it.\nIn order to preserve any variables we use useState to persist the state of the component between re-renders. However, in a function, using useState does not save the value to state immediately. useState is an instruction that is sent to React that tells it that when the component re-renders, we need to save that value. If you try to access the value in state before your re-render has begun you will be using the \"previous\" value instead. In your case, your component will not re-render until the calling function has been completed.\nSo how do you listen for changes?\nUseEffect is a special hook that takes an array of dependencies as \"listeners\". When we use useEffect and give it a value in state as a dependency, it's telling it to run the code inside the useEffect if there is a mutation to that value.\nuseEffect(() => {\n\n    rolesData.map((item, index) => {\n      console.log(item.checked + \" ^ \" + item.name);\n    });\n\n}, [rolesData]);\n\nThis code will run every time myState is changed, including on component initialisation. So we can use useEffect to process logic that requires the newly updated stateful values.\n"
},
{
"QuestionId": "76389309",
"QuestionTitle": "How to capture words with letters separated by a consistent symbol in Python regex?",
"QuestionBody": "I am trying to write a Python regex pattern that will allow me to capture words in a given text that have letters separated by the same symbol or space.\nFor example, in the text \"This is s u p e r and s.u.p.e.r and s👌u👌p👌e👌r and s!u.p!e.r\", my goal is to extract the words \"s u p e r\", \"s.u.p.e.r\", and s👌u👌p👌e👌r. However, I want to exclude \"s!u.p!e.r\" because it does not have the same consistent separating symbol within the word.\nI'm currently using the following:\nx=\"This is s u p e r and s.u.p.e.r and s👌u👌p👌e👌r and s!u.p!e.r\"\n\n\npattern = r\"(?:\\b\\w[^\\w\\d]){2,}\"\n\nre.findall(pattern, x)\n\n\n['s u p e r ', 's.u.p.e.r ', 's👌u👌p👌e👌r ', 's!u.p!e.']\n\nI'm just curious if it's possible to exclude the cases that do not have the same symbol.\n",
"AnswerId": "76389422",
"AnswerBody": "You may consider using\npattern = r\"(?<!\\S)\\w(?=(\\W))(?:\\1\\w)+(?!\\S)\"\nresults = [m.group() for m in re.finditer(pattern, x)]\n\nSee the Python demo and the regex demo.\nimport re\nx=\"This is s u p e r and s.u.p.e.r and s👌u👌p👌e👌r and s!u.p!e.r\"\npattern = r\"(?<!\\S)\\w(?=(\\W))(?:\\1\\w)+(?!\\S)\"\nprint([m.group() for m in re.finditer(pattern, x)])\n# => ['s u p e r', 's.u.p.e.r', 's👌u👌p👌e👌r']\n\nPattern details\n\n(?<!\\S) - left-hand whitespace boundary\n\\w - a word char\n(?=(\\W)) - a positive lookahead that requires the next char to e a non-word char capturing it into Group 1 (\\1)\n(?:\\1\\w)+ - one or more repetitions of the same char as captured in Group 1 and then a single word char\n(?!\\S) - right-hand whitespace boundary\n\n"
},
{
"QuestionId": "76390683",
"QuestionTitle": "How to transform Microsoft Graph API query with expand=extensions to SDK code",
"QuestionBody": "I am transforming from Graph API to Graph SDK. How can I transform this API call?\nhttps://graph.microsoft.com/v1.0/users/XXX/calendarView?startDateTime=YYY&endDateTime=ZZZ&$expand=extensions($filter=id eq 'NAME')\n\nExpand part is missing. How should I add Expand = ??? or do it somehow with Filter or Select?\nvar ret = await graphClient.Users[XXX].CalendarView.GetAsync((requestConfiguration) =>\n            {\n                requestConfiguration.QueryParameters.StartDateTime = YYY;\n                requestConfiguration.QueryParameters.EndDateTime = ZZZ;\n            });\n\nThank you for help.\n",
"AnswerId": "76390801",
"AnswerBody": "Thank you @user2250152 . I made a typo. Solution:\nrequestConfiguration.QueryParameters.Expand = new string[] { \"extensions($filter=id+eq+'NAME')\" };\n"
},
{
"QuestionId": "76387285",
"QuestionTitle": "Unable to add horizontal ListView.builder while using overlapping_panels 0.0.3",
"QuestionBody": "\nI am new to Flutter development\nThe horizontal list stops scrolling but is able To Scroll while using Axis.vertical.\nWhat is expected is Once All the content of List Scrolls then only go to the next Slider.\nProblem = only displays the list of items that we can visible on a screen unable to scroll horizontally\nlib-link https://pub.dev/packages/overlapping_panels\nCode\nbody: OverlappingPanels(\n      right: Builder(\n          builder: (context)  {\n            return Text(\"right\");\n          }\n      ),\n      main: Builder(\n        builder: (context) {\n          var items = [\"item1\",\"Item2\", \"Item3\", \"Item4\", \"Item5\", \"Item6\", \"Item7\"];\n          return Container(\n              width: double.infinity,\n              height: 200,\n              color: Colors.blue,\n              child: Scrollbar(\n                  child: ListView.builder(\n                      scrollDirection: Axis.horizontal,\n                      itemCount: items.length,\n                      itemBuilder: (BuildContext context , int index) {\n                        return Container(\n                          width: 150,\n                          margin: const EdgeInsets.all(8),\n                          child: Center(\n                            child: Text(\n                              items[index],\n                              style: const TextStyle(\n                                  color: Colors.black,\n                                  fontSize: 18\n                              ),\n                            ),\n                          ),\n                        );\n                      })\n              )\n          );\n\n        },\n      ),\n      onSideChange: (side) {\n\n        setState(() {\n          if (side == RevealSide.main) {\n            // hide something\n          } else if (side == RevealSide.left) {\n            // show something\n          }\n        });\n      },\n    )\n\n",
"AnswerId": "76388205",
"AnswerBody": "I Looked at your code. And also looked at the Library of OverlappingPanels.\nThe thing is, if you wrap you page with Overlapping Panels, It wrap you whole Screen with a Gesture Detector and it listens to a gesture to swipe from right to left.\nIf you are new, I would try something else. Otherwise you can copy their library and make it to your own class 'my_overlapoing_panels.dart like:\nlibrary overlapping_panels;\n\nimport 'package:flutter/material.dart';\nimport 'dart:core';\n\nconst double bleedWidth = 20;\n\n/// Display sections\nenum RevealSide { left, right, main }\n\n/// Widget to display three view panels with the [MyOverlappingPanels.main] being\n/// in the center, [MyOverlappingPanels.left] and [MyOverlappingPanels.right] also\n/// revealing from their respective sides. Just like you will see in the\n/// Discord mobile app's navigation.\nclass MyOverlappingPanels extends StatefulWidget {\n  /// The left panel\n  final Widget? left;\n\n  /// The main panel\n  final Widget main;\n\n  /// The right panel\n  final Widget? right;\n\n  /// The offset to use to keep the main panel visible when the left or right\n  /// panel is revealed.\n  final double restWidth;\n\n  final bool allowSidePanel;\n\n  /// A callback to notify when a panel reveal has completed.\n  final ValueChanged<RevealSide>? onSideChange;\n\n  const MyOverlappingPanels({\n    this.left,\n    required this.main,\n    this.right,\n    this.restWidth = 40,\n    this.onSideChange,\n    this.allowSidePanel = true,\n    Key? key,\n  }) : super(key: key);\n\n  static MyOverlappingPanelsState? of(BuildContext context) {\n    return context.findAncestorStateOfType<MyOverlappingPanelsState>();\n  }\n\n  @override\n  State<StatefulWidget> createState() {\n    return MyOverlappingPanelsState();\n  }\n}\n\nclass MyOverlappingPanelsState extends State<MyOverlappingPanels> with TickerProviderStateMixin {\n  AnimationController? controller;\n  double translate = 0;\n\n  double _calculateGoal(double width, int multiplier) {\n    return (multiplier * width) + (-multiplier * widget.restWidth);\n  }\n\n  void _onApplyTranslation() {\n    final mediaWidth = MediaQuery.of(context).size.width;\n\n    final animationController = AnimationController(vsync: this, duration: const Duration(milliseconds: 200));\n\n    animationController.addStatusListener((status) {\n      if (status == AnimationStatus.completed) {\n        if (widget.onSideChange != null) {\n          widget.onSideChange!(translate == 0 ? RevealSide.main : (translate > 0 ? RevealSide.left : RevealSide.right));\n        }\n        animationController.dispose();\n      }\n    });\n\n    if (translate.abs() >= mediaWidth / 2) {\n      final multiplier = (translate > 0 ? 1 : -1);\n      final goal = _calculateGoal(mediaWidth, multiplier);\n      final Tween<double> tween = Tween(begin: translate, end: goal);\n\n      final animation = tween.animate(animationController);\n\n      animation.addListener(() {\n        setState(() {\n          translate = animation.value;\n        });\n      });\n    } else {\n      final animation = Tween<double>(begin: translate, end: 0).animate(animationController);\n\n      animation.addListener(() {\n        setState(() {\n          translate = animation.value;\n        });\n      });\n    }\n\n    animationController.forward();\n  }\n\n  void reveal(RevealSide direction) {\n    // can only reveal when showing main\n    if (translate != 0) {\n      return;\n    }\n\n    final mediaWidth = MediaQuery.of(context).size.width;\n\n    final multiplier = (direction == RevealSide.left ? 1 : -1);\n    final goal = _calculateGoal(mediaWidth, multiplier);\n\n    final animationController = AnimationController(vsync: this, duration: const Duration(milliseconds: 200));\n\n    animationController.addStatusListener((status) {\n      if (status == AnimationStatus.completed) {\n        _onApplyTranslation();\n        animationController.dispose();\n      }\n    });\n\n    final animation = Tween<double>(begin: translate, end: goal).animate(animationController);\n\n    animation.addListener(() {\n      setState(() {\n        translate = animation.value;\n      });\n    });\n\n    animationController.forward();\n  }\n\n  void onTranslate(double delta) {\n    setState(() {\n      final translate = this.translate + delta;\n      if (translate < 0 && widget.right != null || translate > 0 && widget.left != null) {\n        this.translate = translate;\n      }\n    });\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return Stack(children: [\n      Offstage(\n        offstage: translate < 0,\n        child: widget.left,\n      ),\n      Offstage(\n        offstage: translate > 0,\n        child: widget.right,\n      ),\n      Transform.translate(\n        offset: Offset(translate, 0),\n        child: widget.main,\n      ),\n      widget.allowSidePanel\n          ? GestureDetector(\n              behavior: HitTestBehavior.translucent,\n              onHorizontalDragUpdate: (details) {\n                onTranslate(details.delta.dx);\n              },\n              onHorizontalDragEnd: (details) {\n                _onApplyTranslation();\n              },\n            )\n          : SizedBox(),\n    ]);\n  }\n}\n\n\nNow you can use also the variable  'allowSidePanel' in your code. And If you update your code to:\nclass TestScreen extends StatefulWidget {\n  const TestScreen({super.key});\n\n  @override\n  State<TestScreen> createState() => _TestScreenState();\n}\n\nclass _TestScreenState extends State<TestScreen> {\n  ScrollController controller = ScrollController();\n\n  bool allowScroll = false;\n\n  @override\n  void initState() {\n    super.initState();\n\n    // Setup the listener.\n    controller.addListener(() {\n      if (controller.position.atEdge) {\n        bool atBegin = controller.position.pixels == 0;\n        if (atBegin) {\n          /// here you can later allow left panel later\n        } else {\n          /// here allow sidepannel\n          setState(() {\n            allowScroll = true;\n          });\n        }\n      }\n    });\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      body: MyOverlappingPanels(\n        allowSidePanel: allowScroll,\n        right: Builder(builder: (context) {\n          return Text(\"right\");\n        }),\n        main: Builder(\n          builder: (context) {\n            var items = [\"item1\", \"Item2\", \"Item3\", \"Item4\", \"Item5\", \"Item6\", \"Item7\"];\n            return Container(\n                width: double.infinity,\n                height: 200,\n                color: Colors.blue,\n                child: ListView.builder(\n                    controller: controller,\n                    scrollDirection: Axis.horizontal,\n                    itemCount: items.length,\n                    itemBuilder: (BuildContext context, int index) {\n                      return Container(\n                        width: 150,\n                        margin: const EdgeInsets.all(8),\n                        child: Container(\n                          padding: EdgeInsets.all(8),\n                          color: Colors.red,\n                          child: Center(\n                            child: Text(\n                              items[index],\n                              style: const TextStyle(color: Colors.black, fontSize: 18),\n                            ),\n                          ),\n                        ),\n                      );\n                    }));\n          },\n        ),\n        onSideChange: (side) {\n          setState(() {\n            if (side == RevealSide.main) {\n              /// here deaktivate ssidepannel again\n              allowScroll = false;\n            } else if (side == RevealSide.left) {\n              // show something\n            }\n          });\n        },\n      ),\n    );\n  }\n}\n\nthis will work.\n"
},
{
"QuestionId": "76390731",
"QuestionTitle": "Parsing multiple date string languages and formats",
"QuestionBody": "I'm parsing a list of emails in a text file and I need to parse dates in the email headers. The dates are in a multitude of formats and languages:\nsexta-feira, 26 de agosto de 2022 16:41\nviernes, 26 de agosto de 2022 19:24\n2022/08/26 13:30:56\n26 de agosto de 2022 13:32:49 BRT\n\nMostly portuguese, spanish, italian and english.\nWhat would be the best aproach? I have tried Babel but the date parsing is very basic. For now I only have access to the text files exported from Outlook not the smpt sources.\n",
"AnswerId": "76390810",
"AnswerBody": "The dateparser package provides modules to parse localized dates in most string formats.\nThe following snippet successfully retrieves all dates in the given example:\nimport dateparser\n\ntext_dates = [\n    \"sexta-feira, 26 de agosto de 2022 16:41\",\n    \"viernes, 26 de agosto de 2022 19:24\",\n    \"2022/08/26 13:30:56\",\n    \"26 de agosto de 2022 13:32:49 BRT\",\n]\n\ndatetimes = [dateparser.parse(line) for line in text_dates]\n\nprint(datetimes)\n\n>>> [datetime.datetime(2022, 8, 26, 16, 41),\n datetime.datetime(2022, 8, 26, 19, 24),\n datetime.datetime(2022, 8, 26, 13, 30, 56),\n datetime.datetime(2022, 8, 26, 13, 32, 49, tzinfo=<StaticTzInfo 'BRT'>)]\n\n"
},
{
"QuestionId": "76389259",
"QuestionTitle": "Window function, order by clause, between operator",
"QuestionBody": "Consider the MWE below\nWITH samp AS (\n    SELECT '2023-01-01' AS day, 1 AS spent UNION ALL\n    SELECT '2023-01-02' AS day, 2 AS spent UNION ALL \n    SELECT '2023-01-03' AS day, 3 AS spent\n) \nSELECT day, \n       spent \n     , ARRAY_AGG(spent) OVER(ORDER BY day BETWEEN '2023-01-02' AND '2023-01-03') ss\nFROM samp \nORDER BY day\n\nI cannot figure out what the order by clause is doing here. I'd expect to restrict the entries to those of the selected dates, but dates outside it also have a contribution? E.g., outcome of the above\n\n\n\n\nday\nspent\nss\n\n\n\n\n'2023-01-01'\n1\n[1]\n\n\n'2023-01-02'\n2\n[1,2,3]\n\n\n'2023-01-03'\n3\n[1,2,3]\n\n\n\n",
"AnswerId": "76389434",
"AnswerBody": "The clause\nday between '2023-01-02' and '2023-01-03'\n\nis a boolean expression, and will only evaluate to two possible values, true or false (1 or 0).  Therefore, your window function array_agg(spent) will compute using an order where dates other than 2023-01-02 and 2023-01-03 will be ordered first, followed by these dates next.\nHere is your updated output showing the ordering logic:\n     day         spent         ss      order (day between ...)\n'2023-01-01'       1           [1]       0\n'2023-01-02'       2         [1,2,3]     1\n'2023-01-03'       3         [1,2,3]     1\n\n"
},
{
"QuestionId": "76389304",
"QuestionTitle": "How do I print the user and umask for all running processes?",
"QuestionBody": "The username is in column one and PID in column two of ps gaux, so I have:\nps gaux | awk '{print $2;}' | while read line ; do grep -i umask /proc/$line/status ; done\n\nbut is there a way to print the username as well?\n",
"AnswerId": "76389435",
"AnswerBody": "I hope this helps\nps gaux | awk '{printf $1 \" \" ; system(\"grep Umask /proc/\"$2\"/status | tr -dc [:digit:]\"); printf \"\\n\"}'\n\nExplanation:\n\nget output from ps\nprint first column (username) and space\nrun the grep and remove everything except the actual umask, which is a number (awk does not print the command output, it gets just printed directly from the subshells stdout)\nprint a new line\n\n"
},
{
"QuestionId": "76383190",
"QuestionTitle": "Django - INTEGRITY ERROR on column that no longer exists",
"QuestionBody": "I am getting this error:\nIntegrityError at /register/\nnull value in column \"total_daily_mission_progress\" violates not-null constraint\nDETAIL:  Failing row contains (363, 0, 374, free, 0, null, unranked, 0, , odifj@gmail.com, 0, f, [], 0, {}, {}, t, null, null, null, null, null, {}, null, null, No phone number set, This user has not set a description yet., /static/images/profilepictures/defaultavatar.png, {}, {}, {}, {}, {}, 0).\n\nHowever, the column total_daily_mission_progress no longer exists in my UserDetail model. I deleted it a while ago and migrated. However, this issue comes up every time I try to create a new UserDetail model.\nWhy is this occuring? I don't have the total_daily_mission_progress anywhere in my code. And how can I fix it?\nEDIT:\nHere is my output after running python3 manage.py showmigrations --verbosity 2\n [X] 0001_initial (applied at 2022-12-29 19:39:10)\n [X] 0002_logentry_remove_auto_add (applied at 2022-12-29 19:39:10)\n [X] 0003_logentry_add_action_flag_choices (applied at 2022-12-29 19:39:10)\nauth\n [X] 0001_initial (applied at 2022-12-29 19:39:09)\n [X] 0002_alter_permission_name_max_length (applied at 2022-12-29 19:39:11)\n [X] 0003_alter_user_email_max_length (applied at 2022-12-29 19:39:11)\n [X] 0004_alter_user_username_opts (applied at 2022-12-29 19:39:11)\n [X] 0005_alter_user_last_login_null (applied at 2022-12-29 19:39:12)\n [X] 0006_require_contenttypes_0002 (applied at 2022-12-29 19:39:12)\n [X] 0007_alter_validators_add_error_messages (applied at 2022-12-29 19:39:12)\n [X] 0008_alter_user_username_max_length (applied at 2022-12-29 19:39:12)\n [X] 0009_alter_user_last_name_max_length (applied at 2022-12-29 19:39:13)\n [X] 0010_alter_group_name_max_length (applied at 2022-12-29 19:39:13)\n [X] 0011_update_proxy_permissions (applied at 2022-12-29 19:39:13)\n [X] 0012_alter_user_first_name_max_length (applied at 2022-12-29 19:39:13)\ncodera_main\n [X] 0001_initial (applied at 2022-12-29 19:39:14)\n [X] 0002_achievement_reward_alter_achievement_rarity (applied at 2022-12-29 19:39:15)\n [X] 0003_achievement_num (applied at 2022-12-29 19:39:15)\n [X] 0004_alter_achievement_name_alter_achievement_num (applied at 2022-12-29 19:39:15)\n [X] 0005_alter_achievement_description_alter_achievement_name (applied at 2022-12-29 19:39:16)\n [X] 0006_userdetail (applied at 2022-12-29 19:39:17)\n [X] 0007_userdetail_skilllevel (applied at 2022-12-29 19:39:17)\n [X] 0008_userdetail_plan (applied at 2022-12-29 19:39:17)\n [X] 0009_userdetail_friends_alter_userdetail_skilllevel (applied at 2022-12-29 19:39:17)\n [X] 0010_alter_userdetail_friends (applied at 2022-12-29 19:39:18)\n [X] 0011_alter_userdetail_friends (applied at 2022-12-29 19:39:18)\n [X] 0012_alter_userdetail_friends (applied at 2022-12-29 19:39:18)\n [X] 0013_userstat (applied at 2022-12-29 19:39:19)\n [X] 0014_usercode (applied at 2022-12-29 19:39:19)\n [X] 0015_userreward (applied at 2022-12-29 19:39:20)\n [X] 0016_remove_userstat_ribbons_remove_userstat_shards_and_more (applied at 2022-12-29 19:39:20)\n [X] 0017_alter_userdetail_totallearningtime (applied at 2022-12-29 19:39:21)\n [X] 0018_alter_userdetail_totallearningtime (applied at 2022-12-29 19:39:21)\n [X] 0019_alter_userdetail_totallearningtime (applied at 2022-12-29 19:39:22)\n [X] 0020_alter_userdetail_totallearningtime (applied at 2022-12-29 19:39:22)\n [X] 0021_userstat_last_login (applied at 2022-12-29 19:39:23)\n [X] 0022_userstat_monthly_streaks (applied at 2022-12-29 19:39:23)\n [X] 0023_userdetail_user_spent (applied at 2022-12-29 19:39:23)\n [X] 0024_remove_userdetail_user_spent_and_more (applied at 2022-12-29 19:39:24)\n [X] 0025_alter_userdetail_totallearningtime (applied at 2022-12-29 19:39:24)\n [X] 0026_alter_usercode_levelscompleted (applied at 2022-12-29 19:39:25)\n [X] 0027_remove_achievement_rarity_remove_achievement_reward_and_more (applied at 2022-12-29 19:39:25)\n [X] 0028_achievement_achive_date (applied at 2022-12-29 19:39:25)\n [X] 0029_alter_achievement_num (applied at 2022-12-29 19:39:26)\n [X] 0030_rename_name_achievement_title (applied at 2022-12-29 19:39:26)\n [X] 0031_delete_userreward (applied at 2022-12-29 19:39:26)\n [X] 0032_userdetail_profilepicture (applied at 2022-12-29 19:39:27)\n [X] 0033_alter_userdetail_profilepicture (applied at 2022-12-29 19:39:27)\n [X] 0034_alter_userdetail_profilepicture (applied at 2022-12-29 19:39:27)\n [X] 0035_alter_userdetail_profilepicture (applied at 2022-12-29 19:39:27)\n [X] 0036_userstat_badges (applied at 2022-12-29 19:39:28)\n [X] 0037_remove_userstat_badges_userreward (applied at 2022-12-29 19:39:28)\n [X] 0038_remove_userdetail_profilepicture (applied at 2023-01-16 15:38:38)\n [X] 0039_remove_userdetail_friends (applied at 2023-01-16 15:40:34)\n [X] 0040_emailverified (applied at 2023-02-18 02:18:32)\n [X] 0041_remove_usercode_levelscompleted_and_more (applied at 2023-02-18 02:18:33)\n [X] 0042_userdetail_isverified (applied at 2023-02-18 02:18:33)\n [X] 0043_remove_usercode_user_remove_userreward_user_and_more (applied at 2023-02-18 02:40:26)\n [X] 0044_alter_userdetail_levelscompleted (applied at 2023-02-18 02:40:28)\n [X] 0045_userdetail_xp_alter_userdetail_league (applied at 2023-02-18 02:40:28)\n [X] 0046_avatar (applied at 2023-02-18 02:40:29)\n [X] 0047_alter_avatar_moves_unlocked (applied at 2023-02-18 02:40:29)\n [X] 0048_alter_avatar_moves_unlocked (applied at 2023-02-18 02:40:29)\n [X] 0049_userdetail_yesturday_diamonds (applied at 2023-02-18 02:40:29)\n [X] 0050_remove_userdetail_yesturday_diamonds_and_more (applied at 2023-02-18 02:40:30)\n [X] 0051_alter_userdetail_dimaond_progress (applied at 2023-02-18 02:40:30)\n [X] 0052_rename_dimaond_progress_userdetail_diamond_progress (applied at 2023-02-18 02:40:30)\n [X] 0053_userdetail_medal_progress (applied at 2023-02-18 02:40:30)\n [X] 0054_alter_userdetail_totallearningtime_badge (applied at 2023-02-18 02:40:31)\n [X] 0055_badge_image (applied at 2023-02-18 02:40:32)\n [X] 0056_badge_popup_image (applied at 2023-02-18 02:40:32)\n [X] 0057_alter_badge_badge_date_and_more (applied at 2023-02-18 02:40:32)\n [X] 0058_alter_badge_badge_date (applied at 2023-02-18 02:40:33)\n [X] 0059_alter_badge_badge_date (applied at 2023-02-18 02:40:33)\n [X] 0060_alter_achievement_user_alter_badge_user (applied at 2023-02-18 02:40:34)\n [X] 0061_userdetail_iscurrentlyactive (applied at 2023-02-18 02:40:34)\n [X] 0062_avatar_accuracy_avatar_speed_alter_avatar_character_and_more (applied at 2023-02-18 02:40:35)\n [X] 0063_avatar_rank (applied at 2023-02-18 02:40:35)\n [X] 0064_alter_avatar_moves_unlocked_alter_avatar_rank (applied at 2023-02-18 02:40:35)\n [X] 0065_alter_avatar_moves_unlocked (applied at 2023-02-18 02:40:36)\n [X] 0066_avatar_strenght (applied at 2023-02-18 02:40:36)\n [X] 0067_rename_strenght_avatar_strength (applied at 2023-02-18 02:40:37)\n [X] 0068_userdetail_plan_purchase_date (applied at 2023-02-18 02:40:37)\n [X] 0069_userdetail_checkout_id (applied at 2023-02-18 02:40:37)\n [X] 0070_alter_avatar_accuracy_alter_avatar_energy_and_more (applied at 2023-02-20 17:13:05)\n [X] 0071_guideemail (applied at 2023-02-22 23:52:59)\n [X] 0072_dailymission_userdetail_todays_daily_mission_and_more (applied at 2023-04-20 22:14:25)\n [X] 0074_alter_userdetail_totallearningtime (applied at 2023-04-24 13:54:24)\n [X] 0075_chest (applied at 2023-04-24 17:10:00)\n [X] 0076_userdetail_friends_list (applied at 2023-05-01 14:30:12)\n [X] 0077_friendrequest (applied at 2023-05-01 14:37:47)\n [X] 0078_friendrequest_date_sent (applied at 2023-05-01 22:54:00)\n [X] 0079_alter_friendrequest_date_sent (applied at 2023-05-01 23:00:54)\n [X] 0080_alter_friendrequest_date_sent (applied at 2023-05-02 01:07:36)\n [X] 0081_alter_userdetail_friends_list (applied at 2023-05-02 23:57:12)\n [X] 0082_remove_userdetail_friends_list (applied at 2023-05-02 23:59:09)\n [X] 0083_userdetail_friends_list (applied at 2023-05-02 23:59:27)\n [X] 0084_userdetail_first_name_userdetail_last_name_and_more (applied at 2023-05-09 20:39:01)\n [X] 0085_userdetail_description (applied at 2023-05-09 20:43:14)\n [X] 0086_userdetail_profile_picture (applied at 2023-05-09 21:41:22)\n [X] 0087_alter_userdetail_phone_number (applied at 2023-05-09 22:48:31)\n [X] 0088_alter_userdetail_profile_picture (applied at 2023-05-09 22:59:01)\n [X] 0089_remove_userdetail_profile_picture (applied at 2023-05-09 23:00:03)\n [X] 0090_userdetail_profile_picture (applied at 2023-05-09 23:00:13)\n [X] 0091_alter_userdetail_profile_picture (applied at 2023-05-09 23:08:33)\n [X] 0092_remove_userdetail_profile_picture (applied at 2023-05-09 23:09:17)\n [X] 0093_userdetail_profile_picture (applied at 2023-05-09 23:09:55)\n [X] 0094_remove_userdetail_profile_picture (applied at 2023-05-10 00:31:07)\n [X] 0095_userdetail_profile_picture (applied at 2023-05-10 00:31:20)\n [X] 0096_remove_userdetail_profile_picture (applied at 2023-05-10 00:34:04)\n [X] 0097_userdetail_profile_picture (applied at 2023-05-10 00:34:17)\n [X] 0098_remove_userdetail_profile_picture (applied at 2023-05-10 00:37:46)\n [X] 0099_userdetail_profile_picture (applied at 2023-05-10 00:41:59)\n [X] 0100_alter_userdetail_profile_picture (applied at 2023-05-10 00:46:03)\n [X] 0101_alter_userdetail_profile_picture (applied at 2023-05-10 00:48:49)\n [X] 0102_remove_userdetail_profile_picture (applied at 2023-05-10 00:49:22)\n [X] 0103_userdetail_profile_picture (applied at 2023-05-10 00:50:02)\n [X] 0104_alter_userdetail_profile_picture (applied at 2023-05-10 14:32:59)\n [X] 0105_alter_userdetail_league (applied at 2023-05-21 23:31:23)\n [X] 0106_userdetail_xp_progress_and_more (applied at 2023-05-28 23:28:41)\n [X] 0107_remove_userdetail_todays_daily_mission_completed_and_more (applied at 2023-05-29 16:14:45)\n [X] 0108_remove_userdetail_todays_daily_mission_and_more (applied at 2023-05-29 16:14:45)\n [X] 0109_userdetail_todaysdailymission_and_more (applied at 2023-06-01 14:39:33)\n [X] 0110_rename_todaysdailymissioncompelted_userdetail_todaysdailymissioncompleted (applied at 2023-06-01 14:39:33)\n [X] 0111_mainmission_alter_dailymission_num_and_more (applied at 2023-06-01 14:39:34)\ncontenttypes\n [X] 0001_initial (applied at 2022-12-29 19:39:05)\n [X] 0002_remove_content_type_name (applied at 2022-12-29 19:39:11)\nsessions\n [X] 0001_initial (applied at 2022-12-29 19:39:29)\n\n",
"AnswerId": "76390828",
"AnswerBody": "Ended up figuring it out, ended up using python3 manage.py dbshell and runnning the following command:\nALTER TABLE_NAME FROM USERMODAL\n"
},
{
"QuestionId": "76387798",
"QuestionTitle": "How to change color scheme for static methods in IntelliJ IDEA / Android Studio",
"QuestionBody": "How to disable italics on static methods called inside AndroidStudio IDE?\n\nI know, it's a personal preference question but is there a way to disable italics? and only keep the colour coding?\n",
"AnswerId": "76388214",
"AnswerBody": "Settings/Preferences (on macOS) | Editor | Color Scheme | Java | Methods | Static method\n\nAdditional trick: to easily find the corresponding color scheme settings do the following:\n\nPut the cursor at the needed element you need to change\nPress Shift twice\nType Just to Colors and Fonts and press Enter. Then select the corresponding option\n\n"
},
{
"QuestionId": "76389341",
"QuestionTitle": "common/unified regex for a set of pattern",
"QuestionBody": "I am trying to do some text processing and was interested to know if I can have a common/unified regex for a certain pattern. The pattern of interest is strings that ends with {string}_{i} where i is a number, on the second column of test.csv. Once the regex is matched, I wish to replace it with {string}[i].\nFor now the python script works as expected for the strings for which I explicitly mention the regex pattern. I want to have a more generic regex pattern that will match all the strings that have {string}_{i} instead of writing a regex for all the patterns (which is not scalable).\ninput test.csv\nbom_a14 , COMP_NUM_0\nbom_a17 , COMP_NUM_2\nbom_a27 , COMP_NUM_11\nbom_a35 , FUNC_1V8_OLED_OUT_7\nbom_a38 , FUNC_1V8_OLED_OUT_9\nbom_a39 , FUNC_1V8_OLED_OUT_10\nbom_a46 , CAP_4\nbom_a47 , CAP_3\nbom_a48 , CAP_6\n\ntest.py\nimport csv\nimport re\n\n# Match the values in the first column of the second file with the first file's data\nwith open('test.csv', 'r') as file2:\n    reader = csv.reader(file2)\n    for row in reader:\n        row_1=row[1]\n        # for matching COMP_NUM_{X}\n        match_data = re.match(r'([A-Z]+)_([A-Z]+)_(\\d+)',row_1.strip())\n        # for matching FUNC_1V8_OLED_OUT_{X}\n        match_data2 = re.match(r'([A-Z]+)_([A-Z0-9]+)_([A-Z]+)_([A-Z]+)_(\\d+)',row_1.strip())\n        # if match found, reformat the data\n        if match_data:\n            new_row_1 = match_data.group(1) +'_'+ match_data.group(2)+ '[' + match_data.group(3) + ']'\n        elif match_data2:\n            new_row_1 = match_data2.group(1) +'_'+ match_data2.group(2)+ '_'+ match_data2.group(3)+'_'+ match_data2.group(4)+'[' + match_data2.group(5) + ']'\n        else:\n            new_row_1 = row_1\n        print new_row_1\n\n\noutput\nCOMP_NUM[0]\nCOMP_NUM[2]\nCOMP_NUM[11]\nFUNC_1V8_OLED_OUT[7]\nFUNC_1V8_OLED_OUT[9]\nFUNC_1V8_OLED_OUT[10]\n CAP_4\n CAP_3\n CAP_6\n\nexpected output\nCOMP_NUM[0]\nCOMP_NUM[2]\nCOMP_NUM[11]\nFUNC_1V8_OLED_OUT[7]\nFUNC_1V8_OLED_OUT[9]\nFUNC_1V8_OLED_OUT[10]\nCAP[4]\nCAP[3]\nCAP[6]\n\n",
"AnswerId": "76389488",
"AnswerBody": "I would use sub with a single generic pattern :\nwith open(\"test.csv\", \"r\") as file2:\n    for row in csv.reader(file2):\n\n        s = re.sub(r\"(.+)_(\\d+)$\", r\"\\1[\\2]\", row[-1].strip())\n\n        print(s)\n\n\nRegex : [demo]\n\nOutput :\nCOMP_NUM[0]\nCOMP_NUM[2]\nCOMP_NUM[11]\nFUNC_1V8_OLED_OUT[7]\nFUNC_1V8_OLED_OUT[9]\nFUNC_1V8_OLED_OUT[10]\nCAP[4]\nCAP[3]\nCAP[6]\n\n"
},
{
"QuestionId": "76387936",
"QuestionTitle": "How to use array variable in my sql statement in plpgsql",
"QuestionBody": "total nube in PL/PGSQL. I would like to define an array of strings and then used that in my SELECT... WHERE In statement but can't seem to get it to work, help appreciated.\nDO $$\nDECLARE \n    testArray varchar[] := array['john','lisa'];    \n    ids integer[];\nBEGIN\n    ids = array(select id from tableA where name in (testArray));\n    -- this works\n    ids = array(select id from tableA where name in ('john','lisa'));\nEND $$;\n\n",
"AnswerId": "76388264",
"AnswerBody": "You can use any near of testarray.\nDO $$\nDECLARE \n    testArray varchar[] := array['john','lisa'];    \n    ids integer[];\nBEGIN\n    ids = array(select id from tableA where name = any(testArray));\n    -- this works\n    ids = array(select id from tableA where name in ('john','lisa'));\nEND $$;\n\n"
},
{
"QuestionId": "76390640",
"QuestionTitle": "Adding 3D masked arrays results in TypeError: 'numpy.bool_' object is not iterable",
"QuestionBody": "I have two 3D masked arrays (netCDF4 files output from climate model) that I want to add together. I followed this thread and got the following (simplified) code out of it:\nimport numpy as np\nfrom netCDF4 import Dataset\nfrom operator import and_\nfrom numpy.ma.core import MaskedArray\n\nwith Dataset(dir + 'V10.nc') as file_V10:\n    with Dataset(dir + 'U10.nc') as file_U10:\n        raw_V10 = file_V10.variables['V10'][744 : 9503, :, :] ** 2\n        raw_U10 = file_U10.variables['U10'][744 : 9503, :, :] ** 2                                                                                                                                                                                                               \n        10m_raw_squared = MaskedArray(raw_V10[:].data + raw_U10[:].data, mask=list(map(and_,raw_V10.mask, raw_U10.mask)))\n\nHowever, I get the error message:\nTraceback (most recent call last):\n  File \"code.py\", line 92, in <module>\n    10m_raw_squared = MaskedArray(raw_V10[:].data + raw_U10[:].data, mask=list(map(and_,raw_V10.mask, raw_U10.mask)))    \nTypeError: 'numpy.bool_' object is not iterable\n\nIf I try changing the mask from boolean to string (in order to make it iterable) by adding mask.astype('str'), I get this error message:\nTraceback (most recent call last):\n  File \"code.py\", line 92, in <module>\n    10m_raw_squared = MaskedArray(raw_V10[:].data + raw_U10[:].data, mask=list(map(and_,raw_V10.mask.astype('str'),raw_U10.mask.astype('str'))))    \nTypeError: unsupported operand type(s) for &: 'str' and 'str'\n\nI have also tried to add the arrays together using a for-loop, but somehow couldn't get that to work without losing a dimension and the majority of the array elements of the data.\nHow can I add my two datasets together?\nEdit: I called for the class of the dataset and got the following output:\n<class 'numpy.ma.core.MaskedArray'>\n\n",
"AnswerId": "76390875",
"AnswerBody": "You can use np.logical_and to create the mask.\nwith Dataset(dir + 'V10.nc') as file_V10:\n    with Dataset(dir + 'U10.nc') as file_U10:\n        raw_V10 = file_V10.variables['V10'][744 : 9503, :, :] ** 2\n        raw_U10 = file_U10.variables['U10'][744 : 9503, :, :] ** 2\n        mask = np.logical_and(raw_V10.mask, raw_U10.mask)\n        10m_raw_squared = MaskedArray(raw_V10[:].data + raw_U10[:].data, mask=mask)\n\n"
},
{
"QuestionId": "76389299",
"QuestionTitle": "Select the data and generate the SELECT for each day from date to date?",
"QuestionBody": "I have this SELECT statement in SQL Server:\nselect testname as 'Test', \n       tests_morning , \n       tests_evening ,\n       Date\nfrom  labtests_hajj \nleft join departments_statistics on departments_statistics.test_id = labtests_hajj.testid \ninner join departments on labtests_hajj.dept_id = departments.dept_id\n\nThe output now like this:\nTest      tests_morning         tests_evening Date \nCBC       null                  null          null \nCALCIUM   null                  null          null   \nSODIUMN   null                  null          null   \n\nHow can I get the output as script and add the date also depends on date range for example I need the output for 3 days to be like this :\nTest      tests_morning      tests_evening   Date \nCBC       null                  null     01/06/2023 \nCALCIUM   null                  null     01/06/2023  \nSODIUMN   null                  null     01/06/2023\n\nCBC       null                  null     02/06/2023 \nCALCIUM   null                  null     02/06/2023  \nSODIUMN   null                  null     02/06/2023     \n                                           \nCBC       null                  null     03/06/2023 \nCALCIUM   null                  null     03/06/2023  \nSODIUMN   null                  null     03/06/2023  \n\nHow can I do the select and put 2 dates and show the output like thie?\n",
"AnswerId": "76389493",
"AnswerBody": "There are have two ways\n\nuse DimDate or calendar table\nyou create a date table yourself with CTE\n\nWith DimDate\ndeclare @StartData date='2023-02-01'\ndeclare @EndData date='2023-02-06'\n;with _t as \n(\n    select testname as 'Test', \n           tests_morning , \n           tests_evening ,\n           Date\n    from  labtests_hajj \n    left join departments_statistics \n                     on departments_statistics.test_id = labtests_hajj.testid \n    inner join departments on labtests_hajj.dept_id = departments.dept_id\n\n)\nselect \n             a.Test\n            ,a.tests_morning\n            ,a.tests_evening\n            ,s.Date_ as  Date\nfrom _t \ncross apply (select * from DimDate where date_ between  @StartData and @EndData )s\n\nIf your date range is consecutive, you can create the desired data by setting the start and end dates with CTE.\ndeclare @StartData date='2023-02-01'\ndeclare @EndData date='2023-02-06'\n;WITH List\nas\n(\n    SELECT @StartData as Date_\n    UNION ALL\n    SELECT DATEADD(day, 1, Date_) as 'MonthStart'\n    FROM List\n    where Date_<= @EndData\n),\n_t as \n(\n    select testname as 'Test', \n           tests_morning , \n           tests_evening ,\n           Date\n    from  labtests_hajj \n    left join departments_statistics on departments_statistics.test_id = labtests_hajj.testid \n    inner join departments on labtests_hajj.dept_id = departments.dept_id\n)\nselect \n              a.Test\n            ,a.tests_morning\n            ,a.tests_evening\n            ,s.Date_ as  Date\nfrom _t  a\ncross apply (select * from List)s\n\n\n"
},
{
"QuestionId": "76389280",
"QuestionTitle": "sed doesn't replace a string when this is at the end of the line",
"QuestionBody": "Why this works\nsed -n '242p' /usr/local/lib/python3.6/site-packages/keras/models.py\n\n        model_config = json.loads(model_config.decode('utf-8'))\n\n\nsed -i \"242s/.decode('utf-8')//\" /usr/local/lib/python3.6/site-packages/keras/models.py\n\nsed -n '242p' /usr/local/lib/python3.6/site-packages/keras/models.py\n        model_config = json.loads(model_config)\n\n\nand this doesn´t\nsed -n '3328p' /usr/local/lib/python3.6/site-packages/keras/engine/topology.py\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n\nsed -i \"3328s/.decode('utf-8')//\"  /usr/local/lib/python3.6/site-packages/keras/engine/topology.py\n\nsed -n '3328p' /usr/local/lib/python3.6/site-packages/keras/engine/topology.py\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n\nWhy I cannot delete the second .decode('utf8'). It is because it is at the end of the string.\nI could another approach but I would like to be consistent with the code. I don't get any errors so I don't know what to do although I have been working around and looking for the answer on Internet.\n",
"AnswerId": "76389522",
"AnswerBody": "There's an important one character difference:\nutf8\nutf-8\n\n"
},
{
"QuestionId": "76388209",
"QuestionTitle": "Cannot Mock but can Mock?",
"QuestionBody": "I am trying to build a mock factory, like this:\npublic Mock<T> CreateMock<T>(SomeParams someParams) where T : IMyInterface\n{\n    Mock<T> result = new Mock<T>();\n    ...\n}\n\nHowever, I am getting the compiler error CS0452: The type 'T' must be a reference type in order to use it as parameter 'T' in the generic type or method 'Mock'.\nYet, when I tried this, it worked just fine:\npublic Mock<IMyInterface> CreateMock(SomeParams someParams)\n{\n    Mock<IMyInterface> result = new Mock<IMyInterface>();\n    ...\n}\n\nI don't understand, why I am getting the compiler error, when the code is functionally the same? Is there any simple way to workaround this? I would like to avoid the second approach, as it would require considerable changes in our testing infrastructure.\n",
"AnswerId": "76388265",
"AnswerBody": "\nI don't understand, why I am getting the compiler error, when the code is functionally the same?\n\nConsider this case:\npublic struct Awkward : IMyInterface\n{\n}\n...\nMock<Awkward> mock = MockFactory.CreateMock<Awkward>();\n\nThat satisfies the constraint you've put on CreateMock - but Awkward is a value type. Mock<T> requires T to be a reference type.\nYou need to constrain the T type parameter in your method to be a reference type that implements the interface:\npublic Mock<T> CreateMock<T>(SomeParams someParams) where T : class, IMyInterface\n\n"
},
{
"QuestionId": "76390665",
"QuestionTitle": "Does an error existe on the next code? it shows error on line 7",
"QuestionBody": "import pandas as pd\nfrom sklearn.cluster import KMeans\n\ndataset = pd.read_csv(\"smogon.csv\")\ndataset.drop([\"url\", 'texto'], axis=1, inplace=True)\nkm = KMeans(n_clusters=1, n_init='auto')\ncluster = km.fit_predict(dataset[[\"moves\"]])\ndataset[\"Grupo\"] = cluster\nprint(dataset)\n\nit shows (cluster = km.fit_predict(dataset[[\"moves\"]])\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nalso it shows ( could not convert string to float)\nim doing a project with kmeans and pandas and when im trying to do the clustering with the csv file it shows an error but when i do it with another csv file, it doesnt show any problem running it.\n",
"AnswerId": "76390920",
"AnswerBody": "Try to use LabelEncoder to convert your column moves as numeric:\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\n\ndataset = pd.read_csv(\"smogon.csv\")\ndataset.drop([\"url\", 'texto'], axis=1, inplace=True)\n\n# It does not make sense to have only one cluster...\n# There is many documentation to find the best number of clusters (elbow method, ...)\nkm = KMeans(n_clusters=3, n_init='auto')\nlbe = LabelEncoder()\ndataset['moves_num'] = lbe.fit_transform(dataset['moves'])\n\ncluster = km.fit_predict(dataset[['moves_num']])\ndataset[\"Grupo\"] = cluster\nprint(dataset)\n\n"
},
{
"QuestionId": "76380543",
"QuestionTitle": "Detecting page refresh c#",
"QuestionBody": "I have created a document upload site with asp.net core web app's, and I have encountered a small bug but I'm not sure how to fix it.\nOn my site, you first create a 'file' like so:\n\nIt then appears in a list like so:\n\nAnd when you press upload attachment, it passes the id from the previous table to ensure it uploads to the correct file.\n\nThe code behind the upload page is as below, and the error is if you press upload before choosing a file, it does a page refresh to display an error and then the ID passed through before has been lost, so myInv ends up being null.\nusing FarmersPortal.Data;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing File = FarmersPortal.Data.File;\n\nnamespace FarmersPortal.Pages.Admin\n{\n    [Authorize(Roles =\"Admin\")]\n    public class UploadModel : PageModel\n    {\n        private readonly filedbContext _context;\n\n        public UploadModel(filedbContext context)\n        {\n\n            _context = context;\n        }\n        public int? myID { get; set; }\n\n        [BindProperty]\n        public IFormFile file { get; set; }\n\n        [BindProperty]\n        public int? ID { get; set; }\n        public void OnGet(int? id)\n        {\n            myID = id;\n        }\n\n        [BindProperty]\n        public File File { get; set; }\n        public async Task<IActionResult> OnPostAsync()\n        {\n            if (file != null)\n            {\n                if (file.Length > 0 && file.Length < 300000)\n                {\n                    var myInv = _context.Files.FirstOrDefault(x => x.Id == ID);\n                    var date = DateTime.Today;\n\n                    using (var target = new MemoryStream())\n                    {\n                        file.CopyTo(target);\n                        myInv.UploadDate = date;\n                        myInv.Attachment = target.ToArray();\n                    }\n                    if (myInv == null)\n                    {\n                        return NotFound();\n                    }\n                    else\n                    {\n                        File = myInv;\n                    }\n                    _context.Files.Update(myInv);\n                    await _context.SaveChangesAsync();\n                }\n\n            }\n\n            if (File.FileType == \"Purchase Order\")\n            {\n                return RedirectToPage(\"./PurchaseOrders\");\n            }\n            else if (File.FileType == \"Remittance\")\n            {\n                return RedirectToPage(\"./Remittance\");\n            }\n            else if (File.FileType == \"Haulage Self Bill\")\n            {\n                return RedirectToPage(\"./HaulageSelfBill\");\n            }\n            else if (File.FileType == \"Growers Return\")\n            {\n                return RedirectToPage(\"./GrowersReturn\");\n            }\n            return Page();\n        }\n    }\n}\n\nI am not sure how to work my way around this, any ideas?\n@page\n@model FarmersPortal.Pages.Admin.UploadModel\n@{\n}\n\n<h1 style=\"color:white\">Upload File</h1>\n\n<style>\n    body {\n        background-image: url(\"http://10.48.1.215/PORTAL/hero-range-1.jpg\");\n        height: 100%;\n        background-position: center;\n        background-repeat: no-repeat;\n        background-size: cover;\n    }\n</style>\n\n<hr />\n<div class=\"row\">\n    <div class=\"col-md-4\">\n        <form method=\"post\" enctype=\"multipart/form-data\">\n            <div class=\"form-group\">\n                <div class=\"col-md-10\">\n                    <p style=\"color:white\">Upload file</p>\n                    <input type=\"hidden\" asp-for=\"@Model.ID\" value=\"@Model.myID\" />\n                    <input asp-for=\"file\" class=\"form-control\" accept=\".pdf\" type=\"file\" />\n                    <span asp-validation-for=\"file\" class=\"text-white\"></span>\n                </div>\n            </div>\n            <div class=\"form-group\">\n                <div class=\"col-md-10\">\n                    <input class=\"btn btn-success\" type=\"submit\" value=\"Upload\" />\n                </div>\n            </div>\n        </form>\n    </div>\n</div>\n\n<div>\n    <a asp-page=\"Index\">Back to List</a>\n</div>\n\nAbove is the front end code.\n",
"AnswerId": "76388271",
"AnswerBody": "You can custom the error message\n[BindProperty]\n[Required(ErrorMessage =\"You must select a file before upload this form\")]\npublic IFormFile file { get; set; }\n\nAnd you also need to add Jquery validation library to your view:\n@section Scripts {\n    @{\n        await Html.RenderPartialAsync(\"_ValidationScriptsPartial\");\n    }\n}\n\nThen when user don't select any file and click the upload button, View will show error message and stop uploading the form.\n\n"
},
{
"QuestionId": "76389514",
"QuestionTitle": "Regex to detect deformed words",
"QuestionBody": "I need to detect if a string contains a specific word like \"Hello\".\n\nHello -> yes\nHhhheeeEEEElllLLLLoooOOOO -> Yes\nhell0 -> yes\nh   e l    l o / h. e .l .L . o -> Yes\nh@@$$eee///LLL!!!ooo -> yes\n\nMy attempt:\nlet string = \"h@@$$eee///LLL!!!ooo\";\n\nif (string.match(/\\bhello\\b/i)) {\n      console.log(\"Yes\");\n} else {\n      console.log(\"No\");\n}\n\n",
"AnswerId": "76389555",
"AnswerBody": "You can use .* between the chars, [o0] for o and zero and the flag i for case-insensitive matches:\n\n\n[\n  \"h@@$$eee///LLL!!!ooo\",\n  \"Hello\",\n  \"HhhheeeEEEElllLLLLoooOOOO\",\n  \"hell0\",\n  \"h   e l    l o / h. e .l .L . o\",\n  \"h@@$$eee///LLL!!!ooo\"\n].forEach(string => {\n  if (string.match(/h.*e.*l.*l.*[o0]/i)) {\n    console.log(\"Yes\");\n  } else {\n    console.log(\"No\");\n  }\n});\n\n\n\nYou can use a dynamic regular expression:\n\n\nconst input = \"Hello\";\nconst re = new RegExp(input.toLowerCase().split('').map(c => c === 'o' ? '[o0]' : c).join('.*'), 'i');\n\n[\n  \"h@@$$eee///LLL!!!ooo\",\n  \"Hello\",\n  \"HhhheeeEEEElllLLLLoooOOOO\",\n  \"hell0\",\n  \"h   e l    l o / h. e .l .L . o\",\n  \"h@@$$eee///LLL!!!ooo\"\n].forEach(string => {\n  if (string.match(re)) {\n    console.log(\"Yes\");\n  } else {\n    console.log(\"No\");\n  }\n});\n\n\n\nI used an additional toLowerCase to simplify the replacement of o => [o0].\n"
},
{
"QuestionId": "76389515",
"QuestionTitle": "Retrieve every value between an alphanumeric range in R using ifelse",
"QuestionBody": "This is my df:\ndf <- data.frame(id=as.integer(c(1:6)),\n                 code=as.character(c(\"C410\", \"D486\", \"D485\", \"D501\", \"D600\", \"D899\")))\ndf\n  id code\n1  1 C410\n2  2 D486\n3  3 D485\n4  4 D501\n5  5 D600\n6  6 D899\n\nI want to attribute causes to each id depending on the range they fall into in column 2. For this, I use a ifelse statement:\n    df$cause <- ifelse(df$code >= \"C00\" & df$code <= \"D48\", \"cause 1\", \n                       ifelse(df$code >= \"D50\" & df$code <= \"D89\", \"cause 2\", NA)) \n\nIssue: the algorithm does not capture values above the end of each range (until the maximum possible value)\ndf\n  id code   cause\n1  1 C410 cause 1\n2  2 D486    <NA>\n3  3 D485    <NA>\n4  4 D501 cause 2\n5  5 D600 cause 2\n6  6 D899    <NA>\n\nDesired output:\n df\n      id code   cause\n    1  1 C410 cause 1\n    2  2 D486 cause 1\n    3  3 D485 cause 1  \n    4  4 D501 cause 2\n    5  5 D600 cause 2\n    6  6 D899 cause 2\n\n",
"AnswerId": "76389565",
"AnswerBody": "Yo need to add a third digit:\ndf$cause <- ifelse(df$code >= \"C000\" & df$code <= \"D489\", \"cause 1\", \n                   ifelse(df$code >= \"D500\" & df$code <= \"D899\", \"cause 2\", NA))\n\n\n> df\n  id code   cause\n1  1 C410 cause 1\n2  2 D486 cause 1\n3  3 D485 cause 1\n4  4 D501 cause 2\n5  5 D600 cause 2\n6  6 D899 cause 2\n\n"
},
{
"QuestionId": "76390791",
"QuestionTitle": "When using join in a string, I get too many characters in the string",
"QuestionBody": "I am trying to join an underscore into a string, but when running the code I get 4 times the character i used\nstr = potetoBox\n\nfor indx in range (len(str)):\n    if str[indx].isupper():\n        #split before indx and input an underscore\n        str = ''.join((str[:indx],'_',str[indx:]))\n\nprint(str)\n\nI have tried to change characters and change the order of the code. I expected to get only one underscore.\n",
"AnswerId": "76390956",
"AnswerBody": "Another solution without re that doesn't build a list:\nresult = \"\"\nfor c in my_str:\n    result += \"_\" * c.isupper() + c\n\n"
},
{
"QuestionId": "76389352",
"QuestionTitle": "How to copy from byte[] to new byte[] with some changed element item?",
"QuestionBody": "I have byte[] like this, the length of byte[] is 16, and I want to change some value of an item and add this to a new byte[]. For example, the value of byte[7] is 13, I want to change this value with a new value. After that, add into a new byte, the value of byte[7] will be changed plus one more unit.\n\n\n",
"AnswerId": "76389617",
"AnswerBody": "You should perform the operations the other way round. First copy then change the value in the copied data. This way the original will stay unchanged.\nEfficient:\nvar original = new byte[]{1,2,3};\nvar result = new byte[original.Length];\n\nArray.Copy(original, result, original.Length); //first make a copy\nresult[2] = 42; //then set your new value\n//result is now [1, 2, 42]\n\nSimple with LINQ:\n//do not forget using System.Linq;\nvar original = new byte[]{1,2,3};\n\nvar result = original.ToArray(); //first copy\nresult[2] = 42; //then set your new value\n//result is now [1, 2, 42]\n\nFor small data there will be no difference in performance. For large arrays the direct copy should perform a bit better. See this answer for further alternatives regarding the copy part.\n"
},
{
"QuestionId": "76388142",
"QuestionTitle": "I am trying to remove an item from my mongoDb object which is an object with an array of nested objects. But this code is not working",
"QuestionBody": "I want to delete the object where the name is \"Sleep\".\nThe code I am using:\nconst listName = \"Holiday;\n  const item = new Item({\n    name: \"Sleep\"\n  });\n  User.updateOne({username : req.user.username}, {$pull:{\"lists.$[updateList].items\" : item}}, {\n    \"arrayFilters\": [\n      {\"updateList.name\" : listName}\n    ]\n  }).exec().then(function(){\n    console.log(\"Deleted successfully\");\n    res.redirect(\"/list-\"+listName);\n  })\n\nThe mongodb object:\n  \"_id\" : ObjectId(\"64797ebc9e84ed9d8be3ea54\"),\n  \"username\" : \"aryan@gmail.com\",\n  \"lists\" : [\n      {\n          \"name\" : \"Holiday\",\n          \"items\" : [\n              {\n                  \"name\" : \"Welcome to your todo-list!\",\n                  \"_id\" : ObjectId(\"647988267f3ddfc2982f7d77\")\n              },\n              {\n                  \"name\" : \"Click + to add another item.\",\n                  \"_id\" : ObjectId(\"647988267f3ddfc2982f7d78\")\n              },\n              {\n                  \"name\" : \"<-- Click this to delete an item.\",\n                  \"_id\" : ObjectId(\"647988267f3ddfc2982f7d79\")\n              },\n              {\n                  \"name\" : \"Sleep\",\n                  \"_id\" : ObjectId(\"64799279c3da415dc4ce7574\")\n              },\n              {\n                  \"name\" : \"WakeUp\",\n                  \"_id\" : ObjectId(\"6479930e6d49e494aad1dffa\")\n              }\n          ],\n          \"_id\" : ObjectId(\"647988357f3ddfc2982f7d85\")\n      }\n]\n}\n\nIt seems there is some problem with the updateOne and $pull: attributes but I can't figure out what.\n",
"AnswerId": "76388285",
"AnswerBody": "Try with\nconst listName = 'Holiday';\nUser.updateOne(\n  { username: req.user.username, 'lists.name': listName },\n  { $pull: { 'lists.$[].items': { name: 'Sleep ' } } }\n)\n  .exec()\n  .then(function () {\n    console.log('Deleted successfully');\n    res.redirect('/list-' + listName);\n  });\n\n"
},
{
"QuestionId": "76390964",
"QuestionTitle": "questions is undefined in useEffect",
"QuestionBody": "I'm trying to display all the questions from this data set however it's only working sometimes and then other times I receive 'questions is undefined'.\nWhy am I receiving this error?\nconst [questions, setQuestions] = useState<any>();\nconst [question, setQuestion] = useState<string>()\nconst [answers, setAnswers] = useState<[]>()\n\nuseEffect(() => {\n    fetch(\"/environment_questions\")\n      .then((response) => response.json())\n      .then((data) => setQuestions(data));\n    }, []);\n  \n    useEffect(() => {\n      if (questions.length > 0) {\n        for (let i = 0, l = questions.length; i < l; i++) {\n          setQuestion(questions[i].question)\n          setAnswers(questions[i].answers)\n        }\n      }\n    }, [questions])\nreturn (\n<p>{JSON.stringify(question)}</p>\n      <p>{JSON.stringify(answers)}</p>\n)\n}\n\nData I'm trying to access:\n[{\"id\":1,\"question\":\"...\":[{\"id\":1,\"answer\":\"...\"},{\"id\":2,\"answer\":\"...\"}]},{\"id\":2,\"question\":\"...\",\"answers\":[{\"id\":1,\"answer\":\"\"},{\"id\":2,\"answer\":\"\"},{\"id\":3,\"answer\":\"\"}]} ...}]\n",
"AnswerId": "76391015",
"AnswerBody": "import React, { useEffect, useState } from 'react'\n\nconst Component = () => {\n  const [questions, setQuestions] = useState<any>()\n  const [question, setQuestion] = useState<string>()\n  const [answers, setAnswers] = useState<[]>()\n\n  useEffect(() => {\n    fetch('/...')\n      .then(response => response.json())\n      .then(data => setQuestions(data))\n  }, [])\n\n  useEffect(() => {\n    if (questions.length > 0) {\n      for (let i = 0, l = questions.length; i < l; i++) {\n        setQuestion(questions[i].question)\n        setAnswers(questions[i].answers)\n      }\n    }\n  }, [questions])\n\n  return (\n    <>\n      <p>{JSON.stringify(question)}</p>\n      <p>{JSON.stringify(answers)}</p>\n    </>\n  )\n}\n\nexport default Component\n\n"
},
{
"QuestionId": "76389510",
"QuestionTitle": "Add a Column with a string value based on other column values R",
"QuestionBody": "I want to add one a column called \"Opt-Numbers\" to my data frame with the following values Opt-CMM and Opt-MM based on Numbers column. If the value in Numbers column are greater or equal to 4 then it should add Opt-CMM in the same row of that value or if it is less than 4 then add Opt-MM in the same row. I am also showing an example in below df.\nGiven DF.\n\n\n\n\nS.NO\nNumbers\n\n\n\n\nP1\n2\n\n\nP2\n5\n\n\nP3\n2\n\n\nP4\n2\n\n\nP5\n3\n\n\nP6\n4\n\n\n\n\nRequired DF\n\n\n\n\nS.NO\nNumbers\nOpt-Numbers\n\n\n\n\nP1\n2\nOpt-MM\n\n\nP2\n5\nOpt-CMM\n\n\nP3\n2\nOpt-MM\n\n\nP4\n2\nOpt-MM\n\n\nP5\n3\nOpt-MM\n\n\nP6\n4\nOpt-CMM\n\n\n\n",
"AnswerId": "76389660",
"AnswerBody": "We can do this with dplyr and case_when ()\nlibrary(dplyr)\n\n#example data\ndata <- structure(list(S.NO = c(\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"), Numbers = c(2, 5, 2, 2, 3, 4)), class = \"data.frame\", row.names = c(NA, -6L))\n\ncreate new column with filters\ndata <- data %>%\n          mutate(Opt-Numbers = case_when(\n                    Numbers >= 4 ~ \"Opt-CMM\",\n                    Numbers < 4 ~ \"Opt-MM\"\n          ))\n\ndata\n\n"
},
{
"QuestionId": "76387972",
"QuestionTitle": "How can I use clip-path to achieve a text effect on my SVG in the browser?",
"QuestionBody": "I want to use clip-path to implement effect like: svg with text clip-path,  but open in browser it just display an empty\nsvg.  I wrap the path with <g> tag, then it failed.\n<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"32\" height=\"32\" viewBox=\"0 0 32 32\" fill=\"none\" style=\"\n    width: 200px;\n    height:  200px;\n\">\n    <defs>\n        <clipPath id=\"text-path\">\n            <g clip-rule=\"evenodd\" fill-rule=\"evenodd\">\n                <path d=\"M0 0H14V2H2V13H22V10H24V13H32V27H24V32H0V0ZM2 30V27H22V30H2Z\"/>\n                <path d=\"M16 0L24 8H16V0Z\"/>\n                <text x=\"7.5\" y=\"23\">PDF</text>\n            </g>\n        </clipPath>\n    </defs>\n    <g clip-path=\"url(#text-path)\" fill=\"red\">\n        <path d=\"M0 0H14V2H2V13H22V10H24V13H32V27H24V32H0V0ZM2 30V27H22V30H2Z\"/>\n        <path d=\"M16 0L24 8H16V0Z\"/>\n    </g>\n\n    <style>\n        text {dominant-baseline: hanging;font-size: 8px;font-weight: bold;}\n    </style>\n</svg>\n\nit should be displayed in browser.\n",
"AnswerId": "76388288",
"AnswerBody": "In your example (above) you may remove the wrapping group around the 2 paths and the text and it would work.\n <clipPath id=\"text-path\">\n        <!-- <g clip-rule=\"evenodd\" fill-rule=\"evenodd\"> -->\n            <path d=\"M0 0H14V2H2V13H22V10H24V13H32V27H24V32H0V0ZM2 30V27H22V30H2Z\"/>\n            <path d=\"M16 0L24 8H16V0Z\"/>\n            <text x=\"7.5\" y=\"23\">PDF</text>\n        <!-- </g> -->\n </clipPath>\n\nHowever you won't see the text.\nIf what you need is to see the text as a hole in the shapes you will need a mask where the text is black and the 2 paths are white. In the case of the mask  you can use a group if you think you need it.\n\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"32\" height=\"32\" viewBox=\"0 0 32 32\" style=\"\n    width: 200px;\n    height:  200px;\n    background:silver\">\n  <mask id=\"m\">\n  <g fill=\"white\">\n    <path d=\"M0 0H14V2H2V13H22V10H24V13H32V27H24V32H0V0ZM2 30V27H22V30H2Z\" />\n    <path d=\"M16 0L24 8H16V0Z\" />\n  </g>\n    <text x=\"7.5\" y=\"23\" fill=\"black\">PDF</text>\n  </mask>\n\n  <rect width=\"32\" height=\"32\" mask=\"url(#m)\" fill=\"red\" />\n\n  <style>\n    text {\n      dominant-baseline: hanging;\n      font-size: 8px;\n      font-weight: bold;\n    }\n  </style>\n\n</svg>\n\n\n\n"
},
{
"QuestionId": "76390686",
"QuestionTitle": "Vuejs. is it possible to pass a function returned from another function to event handler?",
"QuestionBody": "<template>\n  <v-list-item v-for=\"(category, i) in categories\" :key=\"i\">\n    <v-item-group multiple @update:model-value=\"selectedChanged(category)\">\n       <v-item></v-item>\n    </v-item-group>\n  </v-list-item>\n</template>\n\n<script>\n  function selectedChanged(category) {\n    return function(items) {\n      console.log(`select ${items} from ${category}`);\n    }\n  }\n</script>\n\nI hope that, in function selectedChanged, I can know which category was selected. But it doesn't work. Vue just called selectedChanged with parameter category.\nThe reason why I want to do this is that, if I define selectedChanged as follows:\nfunction selectedChanged(items) {\n  console.log(items);\n}\n\nI don't know which category was selected.\nHow to impelement function selectedChanged so that I can know which category was selected?\n",
"AnswerId": "76391032",
"AnswerBody": "Like Estus said in the comments, it looks like what you want can probably be achieved by explicitly passing $event as one of your event handler arguments. (Here is a link to the relevant Vue 3 documentation on $event.) The code would look something like this:\n<template>\n  <v-list-item v-for=\"(category, i) in categories\" :key=\"i\">\n    <v-item-group multiple @update:model-value=\"selectedChanged(category, $event)\">\n       <v-item></v-item>\n    </v-item-group>\n  </v-list-item>\n</template>\n\n<script>\n  function selectedChanged(category, items) {\n    console.log(`select ${items} from ${category}`);\n  }\n</script>\n\nOf course, this solution assumes that the items you're looking for are emitted by the update:model-value call in (what I assume to be) Vuetify. You might need to do some destructuring or refactoring to get precisely what you want.\n"
},
{
"QuestionId": "76389651",
"QuestionTitle": "OR-TOOLS Job Shop Scheduling - stop when find first feasible solution",
"QuestionBody": "I am trying to implement Job Shop Scheduling with CP-SAT, but I have more than 20000 tasks to schedule and finding optimal solution will take too much time. I'm using solver time limit, but sometimes it gives me feasible solution in assumed time and sometimes not. Could anyone show how to limit solver to find the first feasible solution?\nhttps://developers.google.com/optimization/scheduling/job_shop\nI know that I should use SolveWithSolutionCallback, but I don't know how.\n",
"AnswerId": "76389684",
"AnswerBody": "set the parameter: stop_after_first_solution to true.\nSee the definition.\n"
},
{
"QuestionId": "76387879",
"QuestionTitle": "Is it possible to exclude certain fields using JSONATA?",
"QuestionBody": "Using JSONATA, is it possible to exclude certain fields that are nested in a deep structure without using object construction? For example, with the following object\n{\n    \"collection\": [\n        {\n            \"id\": \"ABC\",            \n            \"learningunit\": {\n                \"metadata\": {\n                    \"show\": true,\n                    \"unitType\": {\n                        \"code\": \"U\",                        \n                        \"value\": \"Unit\"\n                    }                   \n                }\n            }\n        },\n        {\n            \"id\": \"UYE\",            \n            \"learningunit\": {\n                \"metadata\": {\n                    \"show\": false,\n                    \"unitType\": {\n                        \"code\": \"C\",                        \n                        \"value\": \"COURSE\"\n                    }                   \n                }\n            }\n        }\n    ]\n}\n\ncan we exclude the field \"show\" and \"value\" in order to get the following result.\n{\n    \"collection\": [\n        {\n            \"id\": \"ABC\",            \n            \"learningunit\": {\n                \"metadata\": {                   \n                    \"unitType\": {\n                        \"code\": \"U\"                     \n                    }                   \n                }\n            }\n        },\n        {\n            \"id\": \"UYE\",            \n            \"learningunit\": {\n                \"metadata\": {                   \n                    \"unitType\": {\n                        \"code\": \"C\"                     \n                    }                   \n                }\n            }\n        }\n    ]\n}\n\nFYI, the following object construction expression does the job but it is cumbersome to write if the object is complex.\n{\"collection\":collection.\n    {\n    \"id\": id,\n    \"learningunit\": learningunit.\n        { \n            \"metadata\": metadata. \n            {\n                \"unitType\": unitType.\n                {\n                    \"code\": code\n                }\n            }\n        }\n    }\n} \n\n",
"AnswerId": "76388302",
"AnswerBody": "You can make use of the transform operator and remove all 'value' and 'show' fields from the nested structure:\n$$ ~> | ** | {}, ['show', 'value'] |\n\nSee it on the live Stedi playground: https://stedi.link/Usc1tpg\nNote that if you need to clear those on a specific path only, you can also do it more surgically:\n$$\n  ~> | *.learningunit.metadata | {}, ['show'] |\n  ~> | *.learningunit.metadata.unitType | {}, ['value'] |\n\nPlayground: https://stedi.link/Bh8cUiM\n"
},
{
"QuestionId": "76391013",
"QuestionTitle": "How to count number of consecutive Trues in a numpy array along a given axis?",
"QuestionBody": "I have for example the following np array\narray([[ True, False, False],\n       [False,  True,  True],\n       [ True,  True,  True],\n       [False,  True,  True],\n       [False,  True,  True],\n       [ True, False, False],\n       [ True,  True, False],\n       [False, False,  True]])\n\nI want to count the number of consecutive Trues along the columns, so in the above example, the first column contains 3 blocks of consecutive Trues, the second column contains 2 blocks, and the third contains 2 blocks. The output should then be\narray([3, 2, 2])\n\nI know I can do loops for each columns, like in this answer for a one-dimensional array, but what is a numpy-way for doing this on a 2-d array?\n",
"AnswerId": "76391051",
"AnswerBody": "Use boolean arithmetic to identify the True that are not followed by a True (using slicing and pad), then sum the True per column:\nout = ((a != np.pad(a[1:], ((0,1), (0,0)), constant_values=False))\n       & a).sum(axis=0)\n\nOr:\nout = (a & ~np.pad(a[1:], ((0,1), (0,0)), constant_values=False)).sum(axis=0)\n\nOutput:\narray([3, 2, 2])\n\n"
},
{
"QuestionId": "76390971",
"QuestionTitle": "Does std::set work correctly with a type that compares as std::partial_ordering?",
"QuestionBody": "I came across this when defaulting the three-way-comparison operator (spaceship operator).\nLet's consider this small example:\n#include <set>\n#include <limits>\n\nstruct A {\n    float x;\n    auto operator<=>(A const& other) const = default; // will be std::partial_ordering\n};\n\nint main()\n{\n    std::set<A>{ A{.x = std::numeric_limits<float>::quiet_NaN()}, A{.x = 1.f} };\n}\n\nHere we have a struct A that has one member of type float and defaults the <=> operator. Due tot he float member, the return type of the <=> operator will be std::partial_ordering. Partial ordering allows the category std::partial_ordering::unordered for elements that cannot be put into a specific order relative to other elements. For float this would affect nan for example. Any comparison of a float to nan will yield false.\nNow, containers like std::set order their elements for being able to do binary search. For this they basically do a < comparison. Wouldn't this be broken for any type defining a partial ordering? In the example above, I can create a set of A and it compiles just fine. This seems like a pitfall to me because I assume that as soon as an element is inserted into the set that yields std::partial_ordering::unordered, the ordering inside the set would basically be broken, and various operations on the set would just cease to work correctly. Is my assumption correct?\nNow, I know that it is possible in C++ to actually compare floats using a strong ordering. For this the function std::strong_order exists. So to fix the code, I could manually implement the three-way-comparison operator like this:\nstruct A {\n    float x;\n    auto operator<=>(A const& other) const{\n        return std::strong_order(x, other.x);\n    }\n};\n\nFor this exmaple this is easy. But for larger structs/classes we are basically back to having to manually write comparisons that check member by member. Is there any way to achieve this comparison behaviour while still being able to default the spaceship operator? (without writing a wrapper class for float that offers strong order comparison)\ntl;dr: To my understanding, set::set requires a strict weak ordering to work correctly. Still, I can construct a set using an element type that only offers a partial_ordering. This seems prone to causing bugs.\nThe example code is here, in case you're interested: https://godbolt.org/z/q4a95czTr\n",
"AnswerId": "76391062",
"AnswerBody": "\nWouldn't this be broken for any type defining a partial ordering?\n\nNo, not necessarily. I'm going to use float as the canonical example of a type with partial ordering, but the argument here applies to any partially ordered type.\nstd::set<float>, for instance, is not an inherently broken type. std::set<float>{1.f, 2.f, 3.f} will do exactly what you want, for instance. Indeed, it will do what you want for any floats you put into it... as long as they are not NaN.\nThere are really two approaches to this problem:\n\nyou could put it in the type system, requiring that <=> yields at least weak_ordering, thus rejecting std::set<float>\nyou could put it in the value system, and say it's undefined behavior if you have a partial ordering that compares as unordered. With <=>, if a <=> b is valid and yields a partial_ordering, you can assert that it's not unordered. That is, an operation is defined on a domain of values - not necessarily on every possible value in the type - and an algorithm is valid as long as the provided values are elements of the domain on which the operation is defined.\n\nRust does it the former way (which requires manually providing a comparison operation if you want to do something like sort a Vec<f32> - where that comparison probably just panics in the unordered case), and C++ has always done it the latter way - std::set<float> and sorting a std::vector<float> have always been valid in general, just with the precondition that NaN is not present in those containers (i.e. NaN is outside of the domain of the comparison).\nI'm not sure that one approach is necessary better than the other. Rust's approach requires you to explicitly handle the unordered case, which is more tedious if you just don't have NaNs. In some sense, the C++ approach is more bug prone - since the unordered case won't be typically handled by simply aborting the program (although nothing stops you from writing an equivalently-buggy comparison in the Rust model).\n"
},
{
"QuestionId": "76389516",
"QuestionTitle": "PHP form not loading password match",
"QuestionBody": "I'm trying to build a Sign In / Sign Up web server with PHP, which fills a mysql table.\nThe code is running kind of well, but when I tried to implement a control for the password to be the same, it seems like it skips the password match code and goes directly to the login form.\nHere's the code:\n<?php\n\nrequire_once('config.php');\n\n$email = $connessione->real_escape_string($_POST['email']);\n$username = $connessione->real_escape_string($_POST['username']);\n$password = $connessione->real_escape_string($_POST['password']);\n$hashed_password = password_hash($password, PASSWORD_DEFAULT);\n\n\n// Controlla se l'email esiste già nel database\n$query = \"SELECT * FROM utenti WHERE email = '$email'\";\n$result = $connessione->query($query);\n\nif ($result->num_rows > 0) {\n    echo \"L'email esiste già nel database. Si prega di utilizzare un'altra email.\";\n} else {\n    // L'email non esiste nel database, procedi con la creazione dell'account\n\n\n$passwordMatchError = '';\n\nif(isset($_POST['password']) && isset($_POST['password1'])) {\n    $password = $_POST['password'];\n    $password1 = $_POST['password1'];\n\n    if($password === $password1) {\n\n        header(\"Location: login.html\");\n        exit();\n      \n    } else {\n        $passwordMatchError = 'Le password non corrispondono.'; \n    }\n}\n\n\n    $sql = \"INSERT INTO utenti (email, username, password) VALUES ('$email', '$username', '$hashed_password')\";\n    if ($connessione->query($sql) === true) {\n        // Registrazione avvenuta con successo, reindirizza l'utente alla pagina desiderata\n        header(\"Location: login.html\");\n        exit();\n    } else {\n        echo \"Errore durante la registrazione utente: \" . $connessione->error;\n    }\n}\n\n$connessione->close();\n\n?>\n\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <link rel=\"stylesheet\" href=\"styles.css\">\n</head>\n\n<body>\n    <div>\n        <form action=\"register.php\" method=\"POST\">\n            <h2>Registrati</h2>\n            <label for=\"email\">Email</label>\n            <input type=\"text\" name=\"email\" id=\"email\" placeholder=\"Inserisci la mail\" required>\n           \n            <label for=\"username\">Username</label>\n            <input type=\"text\" name=\"username\" id=\"username\" placeholder=\"Inserisci username\" required>\n            \n            <label for=\"password\">Password</label>\n            <input type=\"password\" name=\"password\" id=\"password\" placeholder=\"Inserisci la password\" required>\n    \n            <label for=\"password1\">Conferma Password</label>\n            <input type=\"password\" name=\"password1\" id=\"password1\" placeholder=\"Conferma password\" required>\n    \n            <input type=\"submit\" value=\"Invia\">\n    \n            <?php if (isset($error)) : ?>\n                <p><?php echo $error; ?></p>\n            <?php endif; ?>\n    \n            <p>Hai già un account? <a href=\"login.html\">Accedi</a></p>\n        </form>\n    </div>\n</body>\n</html>\n\nSo far I tried to implement the register.php directly to the \"index.php\", but nothing worked. I was expecting the echo to show up when the user submits the form with two non-matching passwords, but when i click on submit it brings me directly to the login page, skipping the error. I think it brings the user directly to the login despite the password aren't matching or maybe it's skipping the pass control.\n",
"AnswerId": "76389696",
"AnswerBody": "What you're supposed to do to keep it efficient is to check if the passwords match first or not, then to check the existence of the email address, and from that point do your logic, so by that your code should look something like this:\nif (isset($_POST['password']) && isset($_POST['password1'])) {\n    $password = $_POST['password'];\n    $password1 = $_POST['password1'];\n\n    if ($password === $password1) {\n        $query = \"SELECT email ....\";\n        $result = $connessione->query($query);\n\n        if ($result->num_rows > 0) {\n            echo \"L'email ....\";\n        } else {\n            $sql = \"INSERT ....\";\n            if ($connessione->query($sql) === true) {\n                ....\n            }\n        }\n    }\n}\n\nother than that, important notes:\n\n$password = $_POST['password']; overwrites your $password = $connessione->real_escape_string($_POST['password']);, name your variables wisely.\nI highly recommend using PHP PDO to handle databases when you're working with databases, or MySQLi if you know what you're doing.\nRevise your execution plan so you don't to run queries that might not be used because of a false condition.\n\n"
},
{
"QuestionId": "76387495",
"QuestionTitle": "resolve write problem when write to Cassandra replica set",
"QuestionBody": "By design we can write to any node in the Cassandra replica set. For situation my replica set has 2 node. When I make a write operation to node A but the node is unavailable. Do I have catch exception then re-write to node B manually ?\nOn mongodb, their Driver have \"Retry-able Writes\" to auto write to another node if primary node is down. Does Cassandra have this feature ?\n",
"AnswerId": "76388317",
"AnswerBody": "When you write to Cassandra you specify the consistency level you wish to write wish - ranging from ANY which provides no guarantees, up to ALL which requests that all replicas in all DCs acknowledge back to the co-ordinator.\nThis write is sent to a single node - based on your load balancing policy - that node acts as the co-ordinator for the whole operation, and will return a single response of success / exception- your application does not have to itself individually send the write to multiple nodes, it just sends to 1 node (any node can be used) who co-ordinates the write to the replicas.\nIn a normal scenario of using local_quorum for a write with a very normal replication factor of 3 then as long as the co-ordinator has 2 of the 3 nodes providing acknowledgement of the write, the application will not get any exception - even if the 3rd node fails to write the data.\nThere is a retry policy available on the driver - which can allow for a retry in the event of a timeout, you should ensure though that the operation is idempotent when using this. (for example, appending an item to a list, retrying could result in the item being on the list twice on one of the replicas).\nWith your particular replication factor being 2 - you are currently in a position where you are lack consistency guarantees, or resilience.\n\none / local_one - only guarantees one of the nodes got the write. (Both are likely to get it but there is no guarantee provided)\nquorum / local_quorum - requires both nodes acknowledge, so you have no ability to handle a node failure.\n\nThis is because the quorum of 2 is 2 - if you used 3 nodes with an RF=3, then local_quorum requires 2 of the 3, which would allow a node to be down while providing a stronger guarantee on consistency.\n"
},
{
"QuestionId": "76391056",
"QuestionTitle": "What a vertical bar means in a PropertyGroup .csproj file",
"QuestionBody": "I have a PropertyGroup like this:\n<PropertyGroup Condition=\"'$(Configuration)|$(Platform)'=='Debug|x86'\">\n  <DefineConstants>$(DefineConstants)TRACE;X86</DefineConstants>\n</PropertyGroup>\n\nI want to know what the vertical bar (|) means when it is placed between parameters in the Condition attribute.\n",
"AnswerId": "76391077",
"AnswerBody": "It doesn't mean anything - it's just a way of separating the configuration and platform.\nNote that these aren't really parameters in a condition attribute - they're just property values which are replaced with the MSBuild property. | is unlikely to be part of a configuration or platform name, so it's a good choice as a separator.\nYou could have a condition of \"'$(Configuration)/$(Platform)'=='Debug/x86'\" just as easily, for example. | is just more conventional.\n"
},
{
"QuestionId": "76389600",
"QuestionTitle": "How do I move UIView to the back?",
"QuestionBody": "I have a prototype cell with some labels and image views, all added thru Storyboard. I am trying to add a color background view behind these elements (sort of like a bubble view behind the text that is commonly used in messengers). Trying to add this bubble view through Storyboard became a nightmare because of constraints' conflicts. So I decided to add it programmatically right in the prototypeCell class:\nlet backgroundBubble = UIView()\n\noverride func awakeFromNib() {\n    super.awakeFromNib()\n    backgroundBubble.backgroundColor = .yellow\n    backgroundBubble.translatesAutoresizingMaskIntoConstraints = false\n    addSubview(backgroundBubble)\n    let constraints = [\n        backgroundBubble.topAnchor.constraint(equalTo: Label.topAnchor, constant: 0),\n        backgroundBubble.leadingAnchor.constraint(equalTo: Label.leadingAnchor, constant: 0),\n        backgroundBubble.bottomAnchor.constraint(equalTo: Label.bottomAnchor, constant: 0),\n        backgroundBubble.trailingAnchor.constraint(equalTo: Label.trailingAnchor, constant: 0)\n    ]\n    NSLayoutConstraint.activate(constraints)\n}\n\nThe problem is that now the bubble view is sitting in front of the content:\n\nI tried to move it back with:\nsendSubviewToBack(backgroundBubble)\n\nbut then the yellow bubbleView disappears altogether.\nHow do I move the bubbleView behind the content of the prototype cell?\n",
"AnswerId": "76389698",
"AnswerBody": "The content of a cell should basically always be added to its contentView. In this case, you may use contentView.insertSubview(backgroundBubble, at: 0) to add it as the first view in the hierarchy stack\n"
},
{
"QuestionId": "76388105",
"QuestionTitle": "Efficient algorithm to calculate the most right non-zero digit of a number's factorial in Python",
"QuestionBody": "Calculate the most right non-zero digit of n factorial efficiently\nI want to calculate the right most digit of a given number's factorial and print it. What I've done so far is:\nimport math\nn = int(input())\nfact = math.factorial(n)\nprint(str(fact).rstrip('0')[-1])\n\nbut I still get time limits and I look for faster solutions.\nIt's worth noting that I must use python to solve this problem.\nAlso, I shall point out that n is from 1 to 65536, the time limit is 0.5 seconds and I have 256 megabytes of memory.\n",
"AnswerId": "76388318",
"AnswerBody": "There is a neat recursive formula you can use: let D(n) be the last non-zero digit in n!\n\nIf n<10, use a lookup table\nIf the second last digit of n is odd, D(n) = 4 * D(n//5) * D(unit digit of n)\nIf the second last digit of n is even, D(n) = 6 * D(n//5) * D(Unit digit of n)\n\nSee this math stackexchange post for a proof.\nTranslating it into code:\ndef last_nonzero_factorial_digit(n):\n    lookup = [1, 1, 2, 6, 4, 2, 2, 4, 2, 8]\n    if n < 10:\n        return lookup[n]\n\n    if ((n // 10) % 10) % 2 == 0:\n        return (6 * last_nonzero_factorial_digit(n // 5) * lookup[n % 10]) % 10\n    else:\n        return (4 * last_nonzero_factorial_digit(n // 5) * lookup[n % 10]) % 10\n\nOn my laptop, this version runs ~14,000 times faster on a 5-digit number.\n"
},
{
"QuestionId": "76390824",
"QuestionTitle": "Python Cerberus - Validating Schema with this Example",
"QuestionBody": "I am using Cerberus to validate dataframes schema. Using this sample data and code below, the  if-else statement should \"data structure is valid\", however it returns that the \"data structure is not valid\". Any insight would be appreciated.\nimport pandas as pd\nfrom cerberus import Validator\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'city': ['New York', 'Paris', 'London']\n})\n\ndata = df.to_dict()\n\nschema = {\n    'name': {'type': 'string'},\n    'age': {'type': 'integer', 'min': 18},\n    'city': {'type': 'string'}\n}\n\nvalidator = Validator(schema)\nis_valid = validator.validate(data)\n\nif is_valid:\n    print(\"Data structure is valid!\")\nelse:\n    print(\"Data structure is not valid.\")\n    print(validator.errors)\n\nWhich results:\n>>> Data structure is not valid.\n>>> {'age': ['must be of integer type'], 'city': ['must be of string type'], 'name': ['must be of string type']}\n\n",
"AnswerId": "76391078",
"AnswerBody": "It is failing because df.to_dict() returns dictionary with values ad dictionaries\ndata = df.to_dict()\nprint(data)\n>>> {'name': {0: 'Alice', 1: 'Bob', 2: 'Charlie'}, 'age': {0: 25, 1: 30, 2: 35}, 'city': {0: 'New York', 1: 'Paris', 2: 'London'}}\n\nIf you want your schema to validate this data you need to change it to:\nschema = {\n    \"name\": {\"type\": \"dict\", \"valuesrules\": {\"type\": \"string\"}},\n    \"age\": {\"type\": \"dict\", \"valuesrules\": {\"type\": \"integer\", \"min\": 18}},\n    \"city\": {\"type\": \"dict\", \"valuesrules\": {\"type\": \"string\"}},\n}\n\n"
},
{
"QuestionId": "76388981",
"QuestionTitle": "WebScraping - Parsel: XPath in python",
"QuestionBody": "I am trying to scrape medium.com\nI am using the following code:\nfrom parsel import Selector\ndef get_trending(html):\n    selector = Selector(text=html)\n\n    text = selector.xpath(\"//*[@id='root']/div/div[4]/div[1]/div/div/div/div[2]/div/div[1]/div/div/div[2]/div[2]/a/div/h2\")\n    # h2 = text.xpath(\"//h2/text()\")\n    print(text)\n\nresponse = requests.get(\"https://medium.com\")\nopponents = get_trending(response.text)\nopponents\n\nFor some reason, it is giving an empty list as a result. I tried it with another h2 and I got the result I wanted. What might be the problem?\nHere is the screenshot when I try the xpath in the inspect tool it is working as shown in the image below.\n\n",
"AnswerId": "76389717",
"AnswerBody": "Here is a way to get those elements you're looking for using BeautifulSoup instead of Parsel -- you can adapt the code to Parsel if you are so inclined, and you can edit the class content as well to suit your usecase:\nfrom bs4 import BeautifulSoup as bs\nimport requests\n\nheaders= {\n    'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'\n}\n\nr = requests.get(\"https://medium.com/\", headers=headers)\nsoup = bs(r.text, 'html.parser')\nelements = soup.select('h2[class^=\"by j\"]')\nfor x in elements:\n    print(x.text)\n\nResult in terminal:\nNo One Really Tells You The Hardest Part Of Getting Older\nA good day with Jeff\n4 Secrets of Emotionally Stable People\nThought experiment in the National Library of Thailand\nUnnatural Keys\nBusiness Model Generation & Playing to Win\nOn the nature of elegance\nIt’s Time to Re-Design How We Think\nReport from a Relationship\nThe Secret to Good Photography\nA good day with Jeff\nHow I Turned My Company’s Docs into a Searchable Database with OpenAI\nThought experiment in the National Library of Thailand\nWhat We’re Reading: Always Take a Peek at the Comments\nA Contrarian Bet Against Generative AI: The Value of Being Uniquely Human\nWhy an Engineering Manager Should Not Review Code\n\nBeautifulSoup documentation can be found here.\n"
},
{
"QuestionId": "76387742",
"QuestionTitle": "How to enable authenticator MFA for cognitio user pool created using AWS Node js API?",
"QuestionBody": "I am trying to create a AWS Cogntio user pool using AWS Node js SDK in a lambda function. Our use case requires multi factor authentication and enabling authenticator apps for MFA. Looks like the cognito console UI provides an option to specify this but the API does not provide a way to enable authenticator apps for MFA.\nScreenshot of Cognito user pool console UI showing option to enable Authenticator apps for MFA\nTried adding\n\"SoftwareTokenMfaConfiguration\": {\n    \"Enabled\": true\n  }\n\n\nfield in the params to cognitoIdentityServiceProvider.createUserPool\nAPI but the response indicates \"Error creating User Pool:\nUnexpectedParameter: Unexpected key 'SoftwareTokenMfaConfiguration'\nfound in params\"\n\nSo my code snippet looks like below:\nasync function createCognitoUserPool(poolName) {\n  const cognitoIdentityServiceProvider =\n    new AWS.CognitoIdentityServiceProvider();\n\n  // Define the parameters for creating the user pool\n  const params = {\n    PoolName: poolName,\n    Policies: {\n      PasswordPolicy: {\n        MinimumLength: 8,\n        RequireUppercase: true,\n        RequireLowercase: true,\n        RequireNumbers: true,\n        RequireSymbols: true,\n      },\n    },\n    MfaConfiguration: \"ON\",\n    SoftwareTokenMfaConfiguration: {\n      Enabled: true,\n    },\n    AutoVerifiedAttributes: [\"phone_number\"],\n    SmsConfiguration: JSON.parse(\n      process.env.COGNITO_USER_POOL_SMS_CONFIGURATION\n    ),\n  };\n\n  try {\n    // Call the CreateUserPool method\n    const response = await cognitoIdentityServiceProvider\n      .createUserPool(params)\n      .promise();\n\n    console.log(\"User Pool created successfully:\", response.UserPool.Id);\n    return response.UserPool.Id;\n  } catch (error) {\n    console.error(\"Error creating User Pool:\", error);\n    throw error;\n  }\n}\n\nLooking forward to find a solution for this. Thanks!\n",
"AnswerId": "76388326",
"AnswerBody": "You can use SetUserPoolMfaConfig method after creating the user pool.\nFrom TOTP software token MFA page.\n\nYou can activate TOTP MFA for your user pool in the Amazon Cognito console, or you can use Amazon Cognito API operations. At the user pool level, you can call SetUserPoolMfaConfig to configure MFA and enable TOTP MFA.\n\nHere are the links of API references from AWS documentation.\n\nSetUserPoolMfaConfig\nsetUserPoolMfaConfig(params = {}, callback) ⇒ AWS.Request\n\n"
},
{
"QuestionId": "76390765",
"QuestionTitle": "Count 2 different date fields in a single query",
"QuestionBody": "I have 2 different date fields, 1 when the case was created and the other when the case completed. I am trying to count total cases and total completions in say 2023.\nWhenever I run my query and set the where field, both columns return the same figure.\nSELECT COUNT(*) AS cases,\n       COUNT(IF(YEAR(tbl_lead.CompDate) = '2023', 1, NULL)) AS Completed,\n       tbl_lead.LeadSource\nFROM tbl_lead\nWHERE YEAR(tbl_lead.CompDate) = '2023'\nGROUP BY tbl_lead.LeadSource\n\nI guess what I'm trying to do is count all records for 2023 as cases, then count how many of those have completed in 2023. Is it impossible?\nIt should output as:\n\n\n\n\nCases\nCompleted\nLeadSource\n\n\n\n\n1000\n500\nGoogle\n\n\n2000\n700\nFacebook\n\n\n\n\nWhereas it currently outputs:\n\n\n\n\nCases\nCompleted\nLeadSource\n\n\n\n\n500\n500\nGoogle\n\n\n700\n700\nFacebook\n\n\n\n\nThank you\n",
"AnswerId": "76391096",
"AnswerBody": "Your current query only refers to CompDate but in your question you refer to two different date columns. Is this what you are looking for:\nSELECT SUM(CreateDate >= '2023-01-01' AND CreateDate < '2024-01-01') AS cases,\n       SUM(CompDate >= '2023-01-01' AND CompDate < '2024-01-01') AS Completed,\n       LeadSource\nFROM tbl_lead\nWHERE (CreateDate >= '2023-01-01' AND CreateDate < '2024-01-01')\n   OR (CompDate >= '2023-01-01' AND CompDate < '2024-01-01')\nGROUP BY LeadSource\n\n"
},
{
"QuestionId": "76389613",
"QuestionTitle": "R: Append matrix rows if condition is met",
"QuestionBody": "I loop through a matrix and I would like to append a matrix row to another empty matrix if a specific condition is met. How do I do this without getting problems with the different indexes?\nI had this code, but my dataset is very large, so I get problems in the implementation\nfor (i in 1:length(matrix1)) {\n    if ((substr(matrix1[i,1],6,7) == '02') == TRUE) {\n        for (j in 1:nrow(matrix2)) {\n            matrix2[j,] <- matrix1[i,]\n        }\n    }\n}\n\nIs there a more efficient solution?\ndput(matrix1[1]) is c(\"271\", \"269\", \"274\", \"278\", \"293\", \"270\", \"274\", \"274\", \"275\",  \"271\", \"2018-01-03_0445\")\nnrow(matrix1) is 400000\n",
"AnswerId": "76389735",
"AnswerBody": "You can simply extract the rows satisfying your condition:\nmatrix2 <- matrix1[substr(matrix1[, 1], 6, 7) == '02', ]\n\n"
},
{
"QuestionId": "76391004",
"QuestionTitle": "Error finding a string in another string in Python",
"QuestionBody": "I'm trying to return links that have the word \"attach\" in a list using Python on a web page. But every method I use to find that word in the link gives almost the same error.\nThis is my code and the error is received from line 16:\nfrom bs4 import BeautifulSoup\n\n# pip install requests\nimport requests\n\ndef list_image_links(url):\n    # Send a GET request to the URL\n    response = requests.get(url)\n\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    image_links = []\n    for image_links in soup.find_all('a'):\n        href = image_links.get('href')\n#if attach is in href\n        word = 'attach'\n        if word in href:\n            image_links.append(href)\n    \n    print(image_links)\n    return image_links\n\nlist_image_links('https://forum.ubuntu.ir/index.php?topic=211.0')\n\n\nError:\nTraceback (most recent call last):\n  File \"d:\\...\\main.py\", line 22, in <module>\n    list_image_links('https://forum.ubuntu.ir/index.php?topic=211.0')\n  File \"d:\\...\\main.py\", line 16, in list_image_links\n    if word in href:\n       ^^^^^^^^^^^^\nTypeError: argument of type 'NoneType' is not iterable\n\n",
"AnswerId": "76391129",
"AnswerBody": "In my perspective, the error you're encountering is due to the fact that some of the href values returned by link.get('href') may be None, and you cannot iterate over a None value. To avoid this error, you can add a condition to check if href is not None before checking if the word is in it. Here's the modified code:\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef list_image_links(url):\n    response = requests.get(url)\n\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    image_links = []\n    for image_links in soup.find_all('a'):\n        href = image_links.get('href')\n        word = 'attach'\n        \n        if href and word in href:\n            image_links.append(href)\n    \n# rest of the code...\n\nThe only change I made was adding an additional condition to the if clause, specifically if href and word in href:. I think this modification will resolve the issues.\n"
},
{
"QuestionId": "76387594",
"QuestionTitle": "Vue - show loader while computed property being computed",
"QuestionBody": "EDIT - Found that sorting is quick, real issue is performance of rendering huge list, so already answered\npls explain to me, why this does nothing:\nI have array of thousands of items, there is a button for sorting them by some prop (changes \"sortBy\" prop. Sorting items takes almost 2 seconds, at least that how long after the click does the list change. During computing (until new list displayed) i want to display some \"Loading\" element. Im not aware, byt maybe Vue has some app-wide state to tell something is being recomputed?\n<div v-if=\"loading\">Wait pliz</div>\n<div @click=\"sortBy='ctg'\">SortByCtg</div>\n<div v-for=\"item in sortedRows\">{{item.ctg}} , {{item.name}} .... </div>\n\nand the computed prop fn:\ndata: function(){ \n   return { \n    'sortby': 'name', \n    'sortbyDir': 1, \n    'loading': false,\n    'rows': [ {'name':'abc','ctg':'def'}, ...] \n  }\n},\ncomputed: {\n    sortedRows: function(){\n     this.loading = true; //  <<< should show element\n     var sortby = this.sortby;\n     var sortbyDir = this.sortbyDir;\n     var sorted = this.rows;\n     sorted = this.rows.sort(function(a, b) { \n      return sortbyDir * a[sortby].localeCompare(b[sortby]); \n     });\n    this.loading = false; //  <<< hide element\n    return sorted;\n  }\n},\n...\n\nbut the \"loading\" element never shows. May it be sort is quick, and what is taking the time is the nodes generation itself? Then can i anyhow show the loader? Maybe somehow use next tick? I tried but with no result.\n",
"AnswerId": "76388332",
"AnswerBody": "Sorting is quick (few miliseconds),\nwhat really takes time is rendering the long list\n"
},
{
"QuestionId": "76389468",
"QuestionTitle": "How to subtract values between months for each group and each year separately in R",
"QuestionBody": "i have such data example\nmydata=structure(list(month_id = c(201206L, 201206L, 201207L, 201207L, \n201306L, 201306L, 201307L, 201307L, 201406L, 201406L, 201407L, \n201407L, 201506L, 201506L, 201507L, 201507L, 201606L, 201606L, \n201607L, 201607L, 201706L, 201706L, 201707L, 201707L), MDM_Key = c(1L, \n2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, \n2L, 1L, 2L, 1L, 2L, 1L, 2L), sale_count = c(6978517L, 13957034L, \n6148636L, 12297272L, 6147466L, 12294932L, 6050044L, 12100088L, \n8127548L, 16255096L, 3341936L, 6683872L, 8995701L, 17991402L, \n6803563L, 13607126L, 7098546L, 14197092L, 7855146L, 15710292L, \n5575453L, 11150906L, 7543770L, 15087540L)), class = \"data.frame\", row.names = c(NA, \n-24L))\n\nI need for each group (mdm_key) to get the difference between the months (07-06) by sale_count Variable. The data contains histories by year. e.g. 06(june) and 07(jule) monthes for 2012,\n06 and 07 for 2013 and so on...\nFor each year and each mdm_key I need to subtract the sale_count from month 7 to month 6.\nSo that the desired result for each year and each group mdm_key looks something like this\n   year MDM_Key sale_count\n1  2012       1    -829881\n2  2013       1     -97422\n3  2014       1   -4785612\n4  2015       1   -2192138\n5  2016       1     756600\n6  2017       1    1968317\n7  2012       2   -1659762\n8  2013       2    -194844\n9  2014       2   -9571224\n10 2015       2   -4384276\n11 2016       2    1513200\n12 2017       2    3936634\n\nWhat is the easiest way to do such a subtraction?\nThanks for your any help.\n",
"AnswerId": "76389744",
"AnswerBody": "Does this work?\nlibrary(tidyverse)\nmydata %>%\n  # Filter on months 6 and 7\n  filter(str_sub(month_id, -2) %in% c(\"07\", \"06\")) %>%\n  # Sort by Key + yearmonth\n  arrange(MDM_Key, month_id) %>%\n  # Group by Key\n  group_by(MDM_Key) %>%\n  # Calculate difference between sales\n  mutate(sale_diff = sale_count - lag(sale_count)) %>%\n  # Return unique values for each Key + year\n  filter(str_sub(month_id, -2) == \"07\") %>%\n  mutate(year = as.integer(str_sub(month_id, 1, 4))) %>%\n  select(year, MDM_Key, sale_count = sale_diff)\n# A tibble: 12 x 3\n# Groups:   MDM_Key [2]\n    year MDM_Key sale_count\n   <int>   <int>      <int>\n 1  2012       1    -829881\n 2  2013       1     -97422\n 3  2014       1   -4785612\n 4  2015       1   -2192138\n 5  2016       1     756600\n 6  2017       1    1968317\n 7  2012       2   -1659762\n 8  2013       2    -194844\n 9  2014       2   -9571224\n10  2015       2   -4384276\n11  2016       2    1513200\n12  2017       2    3936634\n\n"
},
{
"QuestionId": "76391017",
"QuestionTitle": "How can I split a column in pandas",
"QuestionBody": "I have a data frame with a column that contains string and digit,\nProd_nbr| prod_name\n5   Natural chip companyseasalt175g\n66  cC Nacho cheese 172g\n61  Smiths Crinkle cut chips chicken135g\n\nMy desired output is\nProd_nbr|pack|prod_name\n5          175g  Natural chip....\n66         172g  cC Nacho cheese..\n61         135g   Smiths Crinkle...\n\nI tried the code below but I didn't get my desired output, I got\n\ndf['pack'] = df['prod_name'].str.extract(r'\\d+\\s*(\\w{,5})\\b').fillna('')[0]\n\n",
"AnswerId": "76391136",
"AnswerBody": "I would make a custom function to solve the parsing of the field, then apply it by row to the whole DataFrame. I prefer this way because most of the time you will find some unexpected string in the data, and using a function helps you with tweaking the output when needed.\nHere is a quick example.\ndef parse(row):\n    s = row.prod_name\n    matches = re.findall('\\d+g', s)\n    if matches:\n        if len(matches) == 1:\n            return matches[0] #if you have a single match\n        else:\n            return 'parsing error' #if you have multiple unexpected matches\n    return np.nan #no matches\n\n\ndf['pack'] = df.apply(parse, axis=1)\n\n"
},
{
"QuestionId": "76389471",
"QuestionTitle": "Angular retaining input value after form reset",
"QuestionBody": "I have a reactive form with two fields.First is custom input using ControlValueAccessor, and last is just regular HTML input.\nProblem is, after performing form.reset(), the value of custom input is retained event its value in reactive form is null already.\n\nAs you can see in image, the first time I input and clear the values, it is working well.\nBut, as second time and onwards, the input value is STILL retained in custom input component. While, the normal HTML input is cleared and working well regardless of how many times I click Clear Input. Can you help me, please? Did I miss to put something?\nFiles:\n\napp.component.ts/html: where the form lives\ncustom-input.component.ts/html: custom input component\n\nHere is the form:\nts file\nimport { Component } from '@angular/core';\nimport { FormBuilder, FormGroup } from '@angular/forms';\n\n@Component({\n  selector: 'my-app',\n  templateUrl: './app.component.html',\n})\nexport class AppComponent {\n  form: FormGroup;\n\n  constructor(private fb: FormBuilder) {\n    this.form = this.fb.group({\n      firstName: [{ value: '', disabled: false }],\n      lastName: [{ value: '', disabled: false }],\n    });\n  }\n\n  clearInput() {\n    this.form.reset();\n  }\n}\n\nhtml file:\n<form [formGroup]=\"form\">\n  <app-custom-input formControlName=\"firstName\"></app-custom-input>\n  <input formControlName=\"lastName\" placeholder=\"Last name\" />\n  <button (click)=\"clearInput()\">Clear Input</button>\n</form>\n\n<br />\n<pre>{{ form.value | json }}</pre>\n\nHere is the custom input file:\nts file:\nimport { Component, forwardRef } from '@angular/core';\nimport { ControlValueAccessor, NG_VALUE_ACCESSOR } from '@angular/forms';\n\n@Component({\n  selector: 'app-custom-input',\n  templateUrl: './custom-input.component.html',\n  providers: [\n    {\n      provide: NG_VALUE_ACCESSOR,\n      useExisting: forwardRef(() => CustomInputComponent),\n      multi: true,\n    },\n  ],\n})\nexport class CustomInputComponent implements ControlValueAccessor {\n  value: string;\n  changed: (value: any) => void;\n  touched: () => void;\n  isDisabled: boolean;\n\n  writeValue(value: string): void {\n    this.value = value;\n  }\n\n  registerOnChange(fn: any): void {\n    this.changed = fn;\n  }\n\n  registerOnTouched(fn: any): void {\n    this.touched = fn;\n  }\n\n  setDisabledState(isDisabled: boolean): void {\n    this.isDisabled = isDisabled;\n  }\n\n  onChange(event: Event): void {\n    const value: string = (<HTMLInputElement>event.target).value;\n\n    this.changed(value);\n  }\n}\n\nhtml file:\n<input\n  placeholder=\"First name\"\n  [disabled]=\"isDisabled\"\n  [value]=\"value\"\n  (input)=\"onChange($event)\"\n  (blur)=\"touched()\"\n/>\n\nFull working code is here\n",
"AnswerId": "76389757",
"AnswerBody": "Ok, you doing things well, but, you have to research a little bit deeper about this problem. If you go through HTML specification, you may find that the value attribute for the input html element is just an initial value. And that's why you get only first change if you push the reset button (actually you assign value there and writeValue method invokes).\nSo the solutions are several, the simplest and relative to your code style is to get the reference to the input and assign value manually:\ncustom-input.component.html\n<input\n  placeholder=\"First name\"\n  [disabled]=\"isDisabled\"\n  (input)=\"onChange($event)\"\n  (blur)=\"touched()\"\n  #inputRef\n/>\n\n\ncustom-input.component.ts\nexport class CustomInputComponent implements ControlValueAccessor {\n  @ViewChild('inputRef')\n  inputRef: ElementRef<HTMLInputElement>;\n  changed: (value: any) => void;\n  touched: () => void;\n  isDisabled: boolean;\n\n  writeValue(value: string): void {\n    if (this.inputRef) {\n      this.inputRef.nativeElement.value = value;\n    }\n  }\n\n  ...\n\nAnother solution is to use ngModel and then it can work with value property binded to the input.\n"
},
{
"QuestionId": "76388239",
"QuestionTitle": "Why does my 2 pointers approach to solve the 3 sum problem on LeetCode throw an index out of bounds error?",
"QuestionBody": "class Solution {\n    public List<List<Integer>> threeSum(int[] nums) {\n        Arrays.sort(nums);\n        List<List<Integer>> ans = new ArrayList<>();     \n        for(int i=0;i<=nums.length-3;i++){\n            if(i==0 || nums[i]!=nums[i-1]){\n                int L=i+1;\n                int R = nums.length-1;\n                int target = 0-(nums[i]);\n                while(L<R){ \n                    if(nums[L]+nums[R]==target){\n                        List<Integer> temp = new ArrayList<>();\n                        temp.add(nums[i]);\n                        temp.add(nums[L]);\n                        temp.add(nums[R]);\n                        ans.add(temp);\n                        while(L<nums.length-1 && nums[L]==nums[L+1]) L++;\n                        while(R>0 && nums[R]==nums[R-1]) R--;\n                        L++;\n                        R--;\n                    }else if(nums[L]+nums[R]<target){\n                        L+=1;\n                    }else{\n                        R+=1;\n                    }\n                }    \n            }\n        }\n    return ans;    \n    }\n# }\n\n\ntrying to solve the 3 sum problem of leetcode with 2 pointers approach . I am getting java.lang.ArrayIndexOutOfBoundsException: Index 6 out of bounds for length 6 at\nif(nums[L]+nums[R]==target){\n",
"AnswerId": "76388358",
"AnswerBody": "A error in the condition for increasing the R pointer is probably what is generating the ArrayIndexOutOfBoundsException in your code. R-=1 should be used instead of R+=1 to move the pointer to the left.\nThe updated code is as follows:\nclass Solution {\n    public List<List<Integer>> threeSum(int[] nums) {\n        Arrays.sort(nums);\n        List<List<Integer>> ans = new ArrayList<>();\n        for (int i = 0; i <= nums.length - 3; i++) {\n            if (i == 0 || nums[i] != nums[i - 1]) {\n                int L = i + 1;\n                int R = nums.length - 1;\n                int target = 0 - nums[i];\n                while (L < R) {\n                    if (nums[L] + nums[R] == target) {\n                        List<Integer> temp = new ArrayList<>();\n                        temp.add(nums[i]);\n                        temp.add(nums[L]);\n                        temp.add(nums[R]);\n                        ans.add(temp);\n                        while (L < nums.length - 1 && nums[L] == nums[L + 1]) L++;\n                        while (R > 0 && nums[R] == nums[R - 1]) R--;\n                        L++;\n                        R--;\n                    } else if (nums[L] + nums[R] < target) {\n                        L += 1;\n                    } else {\n                        R -= 1;  // Fix the typo here\n                    }\n                }\n            }\n        }\n        return ans;\n    }\n}\n\n"
},
{
"QuestionId": "76391053",
"QuestionTitle": "g++ Flag variable not seen by make",
"QuestionBody": "Folks, I need some help in understanding what's happening, I do not see how to pass an option to g++ compiler in a makefile. If you can just try to reproduce my stuff and get me some info, it would be valuable (for me).\nMakefile content:\nMYCPPFLAGS := what a surprise\n\n%.o: %.cpp %.h\n    g++ $(MYCPPFLAGS) -c $< -o $@\n\ndumpy:\n    echo $(MYCPPFLAGS)\n\nIt's not that kind of magic, isn't it???\nNow I have a c++11 file named dessiner.cpp, if you need it I'll post it, but let's skip it for the moment. Please have a look at what I get in the terminal:\ngrenx08{lc177705}hw-m2-cpp-07-dessiner: make dumpy\necho what a surprise\nwhat a surprise\ngrenx08{lc177705}hw-m2-cpp-07-dessiner: make dessiner.o\ng++    -c -o dessiner.o dessiner.cpp\ndessiner.cpp:18:13: warning: override controls (override/final) only available with -std=c++11 or -std=gnu++11 [enabled by default]\n\n[... \na series of warnings/ errors because I did not use std=c++11 option] \n\nmake: *** [dessiner.o] Error 1\n\n\nSo my question is : why can't I see anything about \"what a surprise\" in the g++ command-line, but just four blank spaces???? Is make smarter than me (LoL, of course!!!) and erasing stupid options passed to g++??? The real issue is that in this case, I cannot even give the good options...\nPlease find hereby the sware versions, quite old stuff due to a constrained working environment. Any hint appreciated.\ngrenx08{lc177705}hw-m2-cpp-07-dessiner: make -v\nGNU Make 3.82\nBuilt for x86_64-redhat-linux-gnu\nCopyright (C) 2010  Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\ngrenx08{lc177705}hw-m2-cpp-07-dessiner: g++ --version\ng++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\nEdit 1:\ngrenx08{lc177705}hw-m2-cpp-07-dessiner: make -d dessiner.o\nGNU Make 3.82\nBuilt for x86_64-redhat-linux-gnu\n[ tons of output ]\n  No need to remake target `dessiner.cpp'.\n Finished prerequisites of target file `dessiner.o'.\nMust remake target `dessiner.o'.\nInvoking builtin recipe to update target `dessiner.o'.\ng++    -c -o dessiner.o dessiner.cpp\n[ other irrelevant output ]\n\ngrenx08{lc177705}hw-m2-cpp-07-dessiner: make -r dessiner.o\nmake: *** No rule to make target `dessiner.o'.  Stop.\n\nSo it looks as my rule definition has a flaw? I have no .h file...\n",
"AnswerId": "76391162",
"AnswerBody": "This recipe:\n%.o: %.cpp %.h\n        g++ $(MYCPPFLAGS) -c $< -o $@\n\ntells make \"hey make, if you're trying to build a target that matches the pattern %.o, and if you have prerequisites that match the patterns %.cpp and %.h, then you can use this recipe to build the target\".\nNote carefully: ALL the prerequisites MUST exist, or there must be rules telling make how to build them, otherwise this rule does not match.\nIn your case, you have a file dessiner.cpp but you do not have a file dessiner.h, and so make cannot create both the prerequisites, and so your rule doesn't match and make ignores it.\nThen make looks in its built-in set of rules and it sees a %.o : %.cpp pattern rule there, and since that prerequisite exists, it matches and make runs that recipe.  That recipe doesn't know anything about your variable MYCPPFLAGS so it's not used.\n"
},
{
"QuestionId": "76389248",
"QuestionTitle": "Same height of columns for bootstrap",
"QuestionBody": "It's probably simple, but I could not figure out how to fix it.\nI use Bootstrap5.\nThe full code is here :\nhttps://www.codeply.com/p/BywuhLNUXy\nSeems codeply has some problems...\nSo I put it also on jsfiddle\nhttps://jsfiddle.net/paul_z/y7a6dnkf/1/\nMainly it's contact directory page.\nThe code structure is\n<div class=\"container\">\n<div class=\"row gy-5\">\n\n    <div class=\"col-lg-6\">\n        <div class=\"card m-b-30\">\n            <div class=\"card-body py-5\">\n                <div class=\"row\">\n                    <div class=\"col-lg-4 text-center\">            \n                    <img src=\"/static/logo.png\" alt=\"logo\" >            \n                    </div>\n                <div class=\"col-lg-8\">\n                    <h5 class=\"card-text mb-0\"><i class=\"fa-solid fa-person\"></i> user 1</h5>\n                    <p class=\"card-text\">CDD IT Informatique</p>\n                    <hr class=\"dropdown-divider\">                \n                    <p class=\"card-text\"><i class=\"fa-sharp fa-solid fa-building\"></i> ###</p>        \n                    <p class=\"card-text\"><i class=\"fa-solid fa-envelope\"></i> mail</p>        \n                    <p class=\"card-text\"><i class=\"fa-solid fa-phone\"></i> phone</p>\n               </div>\n                </div>\n              </div>\n        </div>\n    </div>\n    \n    ...\n\nOn large screens it's shown two cards by column.\nThe problem is that cards sometimes different height.\nFor example for user 2 his role change : \"Enseignant Chercheur Astrophysique Hautes Energies\" instead \"CDD IT Informatique\" so this line take two lines instead of one line. And so the card for user 2 has height different to others cards.\nHow could I fix it ?\nI don't know the cards size, so I could not fix it implicitly (and in any case it's probably not a good idea).\nP.S.: I have also the same problem if logos have different sizes. Despite playing with img-fluid, widht, max-widht, max-height etc some logos change the height of card. But I think at first I have to fix the simple height problem.\n",
"AnswerId": "76389777",
"AnswerBody": "The col elements already have the same height - Bootstrap v5's grid implementation based on flexbox already sees to that.\nAll you need to do is make the cards take 100% height of their parent:\n.card { height: 100%; }\n\n"
},
{
"QuestionId": "76389727",
"QuestionTitle": "google.script.run.function() returning null",
"QuestionBody": "On a google sheet, I have a sidebar form allowing user to add infos in another sheet.\nI have to give an ID to each line so when a user add one, generate a new id.\nexample :\nthe sidebar form has two inputs : criterion number (int) and criterion (text). when a user add these inputs, I want to put them in a sheet with 3 columns : A = ID, B = criterion number and C = criterion.\nTo generate the ID, I created a creeID() function on the server side (this function checks the last ID in the sheet and generate the next ID, works well when tested) and I have to call it when the user add a  line (\"ajouter\" button) in order to get a tab with this format [ID, criterion number, criterion] and to push this tab in the sheet with appendRow()\nI thought I could use google script run with .withSuccessHandler() like said here and I tried something based on @Tanaike's help and this video.\nEverything seems to work fine except that google.script.run.withSuccessHandler(data => {alert(\"preuve ajoutée\")}).creeID() returns null\nhere is my html file :\n<!DOCTYPE html>\n<html>\n  <head>\n    <base target=\"_top\">\n    <style>\n      ...\n    </style>\n  </head>\n  <body>\n    <p>Indicateur</p>\n    <input type=\"number\" name=\"indicateur\" id=\"indic\" value=\"\" min = \"1\" max = \"32\">\n    <p>Preuve</p>\n    <input type=\"text\" name=\"preuve\" id=\"preuve\">\n    <br>\n    <input type=\"button\" value=\"Ajouter\" onclick=\"ajouter()\">\n    <span class=\"annuler\" onclick=\"google.script.host.close()\">Annuler</span>\n\n    <script>\n      function ajouter() {\n        const inputs = document.querySelectorAll('#indic, #preuve');\n        let tab = [google.script.run.withSuccessHandler(data => {alert(\"preuve ajoutée\")}).creeID()];\n        \n\n        // Récupération des valeurs\n        for (const input of inputs) {\n          tab.push(input.value);\n        }\n\n        // Si tous les champs sont vides\n        if (tab.join('') == '') {\n          alert('Le formulaire est vide !');\n          return;\n        }\n\n        // Vider les champs\n        inputs.forEach(input => input.value = '');\n\n        // Envoi dans la feuille\n        google.script.run.ajouterLigne(tab);\n      }\n  \n    </script>\n  </body>\n</html>\n\nand the javascript code :\nfunction ajouterLigne(tab) {\n  const PREUVES = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(\"PREUVES\");\n  console.log(tab)\n  PREUVES.appendRow(tab);\n}\n\nfunction creeID() {\n  const SHEET = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(\"PREUVES\");\n  let lastRow = SHEET.getLastRow();\n  let lastIdRange = SHEET.getRange(lastRow, 1);\n  let lastId = lastIdRange.getValue(); \n  let newId;\n\n  if (lastId == \"ID\") {\n    newId = 1;\n  } else {\n    newId = lastId + 1;\n  };\n\n  return(newId)\n}\n\n",
"AnswerId": "76389822",
"AnswerBody": "In the case of your script, google.script.run.creeID() returns no value. I think that this is the reason for your current issue. From maybe I should use .withSuccessHandler() like said here but I don't know how., how about using withSuccessHandler() as follows?\nIn this case, please modify ajouter() of your Javascript as follows.\nModified script:\nfunction ajouter() {\n  const inputs = document.querySelectorAll('input[type=\"text\"]');\n  google.script.run.withSuccessHandler(tab => {\n    tab = [tab];\n    for (const input of inputs) {\n      tab.push(input.value);\n    }\n    if (tab.join('') == '') {\n      alert('Le formulaire est vide !');\n      return;\n    }\n    inputs.forEach(input => input.value = '');\n    google.script.run.ajouterLigne(tab);\n  }).creeID();\n}\n\n\nIn this modification, when a button is clicked, a value of tab is retrieved and the values of tab and the inputted values are appended to the Spreadsheet.\n\nReference:\n\nwithSuccessHandler(function)\n\n"
},
{
"QuestionId": "76388314",
"QuestionTitle": "Why does my Python function return 'None' instead of ('Paul', 29, 1.75)?",
"QuestionBody": "I am following a tutorial\nwhen he runs the code it gives  (\"Paul', 29, 1.75) but when I run it it gives me None\nI tried\n# -----Part 2------\n# name,age,height\npersons = [\n    (\"Alice\", 25, 1.6),\n    (\"Brian\", 35, 1.8),\n    (\"Paul\", 29, 1.75),\n    (\"Martin\", 32, 1.7)\n]\n\ndef get_infos(name, l):\n    for i in l:\n        if i[0] == name:\n            return i\n        return None\n    \ninfos = get_infos(\"Paul\", persons)\nprint(infos)\n\nand got:\nNone\nbut when he runed it he got:\n('Paul', 29, 1.75)\n",
"AnswerId": "76388360",
"AnswerBody": "It's an identation problem, always in the first iteration will return None, try by identing the return None one less tab, like:\n\ndef get_infos(name, l):\n    for i in l:\n        if i[0] == name:\n            return i\n    return None\n\n\n"
},
{
"QuestionId": "76390825",
"QuestionTitle": "How to group states into regions when there is no region table",
"QuestionBody": "My data set has states as a column but no region column to group the states by. I would like to group the states into standard census bureau regions to get the count of employee IDs by region:\n\nSelect COUNT(DISTINCT Empl_ID) AS Employee_Count,\nSTATE\nFROM Employee_Table\nGROUP BY STATE\n\nI tried exporting the query and then sorting in Excel but the dataset is too large for Excel.\n",
"AnswerId": "76391171",
"AnswerBody": "Create a table based on the data provided in the image:\ncreate table region_state (region varchar(30), state varchar(30));\ninsert into region_state values\n('Northen Region', 'New Jersey'),\n('Northen Region', 'New York'),\n('Midwest Region', 'Illinois')\n...;\n\nNow we can use a join query to get the region for each employee state as the following:\nSelect COUNT(DISTINCT E.Empl_ID) AS Employee_Count,\n       R.region\nFROM Employee_Table E JOIN region_state R\nON E.state = R.state\nGROUP BY R.region\n\nIf there are no duplicates in the Empl_ID column (and that is the typical case, i.e. Empl_ID is the primary key of the table) you would use COUNT(E.Empl_ID), with no need for DISTINCT.\n"
},
{
"QuestionId": "76389271",
"QuestionTitle": "Round decimals up to multiples of 5 with BigDecimal",
"QuestionBody": "I want to round BigDecimal decimal part according to the following rules:\n\n1710.10 becomes 1710.10\n1710.11 becomes 1710.15\n1710.15 becomes 1710.15\n1710.16 becomes 1710.20\n\nI tried this way new BigDecimal(\"1710.11\").setScale(2, RoundingMode.HALF_UP)), expecting to get 1710.15 but I get 1710.11. I also tried with Apache Math Utils and Decimal Format but no way to achieve this.\n",
"AnswerId": "76389823",
"AnswerBody": "Your misunderstanding\nFirst of all setting the scale on a BigDecimal only returns a BigDecimal with a different value if your current BigDecimal has a higher scale than you specified.\nFor example\nnew BigDecimal(\"1710.113\").setScale(2, RoundingMode.HALF_UP)\n\nreturns a new BigDecimal equal to new BigDecimal(\"1710.11\")\nHowever, if you already have a scale of 2 or lower in this example, the new BigDecimal stays the same (read: equal).\nHALF_UP simply means that a BigDecimal ending on a 5 will result in the higher value, e.g.\nnew BigDecimal(\"1710.115\").setScale(2, RoundingMode.HALF_UP)\n\nreturns a result equal to new BigDecimal(\"1710.12\")\nNow to your question\nSince your way of \"rounding\" doesn't actually change the scale, I doubt there is an already existing function you could use. However, doing it by hand is actually quite simple:\npublic class QuickMathz {\n\n    public static void main(String[] args) {\n        System.out.println(roundToNext5(new BigDecimal(\"1710.10\"), 2));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.11\"), 2));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.15\"), 2));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.16\"), 2));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.1135\"), 2));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.1635\"), 2));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.1675\"), 2));\n        System.out.println();\n        System.out.println(roundToNext5(new BigDecimal(\"1710.10\"), 3));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.11\"), 3));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.15\"), 3));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.16\"), 3));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.1135\"), 3));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.1635\"), 3));\n        System.out.println(roundToNext5(new BigDecimal(\"1710.1675\"), 3));\n    }\n\n    public static BigDecimal roundToNext5(BigDecimal bigDecimal, int scale) {\n        // Get the last digit we need to decide if we have to round to 0, 5 or 10\n        int lastDigit = bigDecimal\n                .movePointRight(scale)\n                .remainder(BigDecimal.TEN).intValue();\n\n        // Setting the Scale to scale - 1 to remove one more digit than we need\n        // and then increase the scale to what we want\n        BigDecimal result = bigDecimal\n                .setScale(scale - 1, RoundingMode.DOWN)\n                .setScale(scale, RoundingMode.UNNECESSARY);\n\n        if (lastDigit == 0) {\n            // Last digit is a 0 upscaling adds a 0\n            return result;\n        } else if (lastDigit <= 5) {\n            // rounding up to 5\n            return result.add(new BigDecimal(\"5\").movePointLeft(scale));\n        } else {\n            // rounding up to 10\n            return result.add(new BigDecimal(\"1\").movePointLeft(scale - 1));\n        }\n    }\n}\n\nThis class yields the output of\n1710.10\n1710.15\n1710.15\n1710.20\n1710.15\n1710.20\n1710.20\n\n1710.100\n1710.110\n1710.150\n1710.160\n1710.115\n1710.165\n1710.170\n\n(It's neither optimized nor checked for negative values, so don't use in critical environments)\n"
},
{
"QuestionId": "76389621",
"QuestionTitle": "List is not updating properly after deleting an item in flutter",
"QuestionBody": "I am working with dynamic list which add and delete items in the list. but when i delete a specific index with removeAt() method it always delete the last item, below is all code\nimport 'package:bizzsmart_web/constants/constants.dart';\nimport 'package:bizzsmart_web/model/expense_item_model.dart';\nimport 'package:flutter/cupertino.dart';\nimport 'package:flutter/material.dart';\n\nclass TestPage extends StatefulWidget {\n  const TestPage({Key? key}) : super(key: key);\n\n  @override\n  State<TestPage> createState() => _TestPageState();\n}\n\nclass _TestPageState extends State<TestPage> {\n  List<ExpenseItemModel> expenses =\n      List.generate(1, (index) => ExpenseItemModel());\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      body: Column(\n        children: [\n          sbh(150),\n          Expanded(\n            child: ListView.builder(\n              itemCount: expenses.length,\n              itemBuilder: (c, i) {\n                return Column(\n                  children: [\n                    Row(\n                      children: [\n                        IconButton(\n                          onPressed: () {\n                            if (i == expenses.length - 1 ||\n                                (expenses.length == 1)) return;\n                            expenses.removeAt(i);\n                            setState(() {});\n                          },\n                          icon: const Icon(CupertinoIcons.delete),\n                        ),\n                        Expanded(\n                          child: TextField(\n                            onChanged: (val) {\n                              if (expenses.length - 1 == i) {\n                                expenses.add(ExpenseItemModel());\n                              }\n                              setState(() {});\n                            },\n                            decoration: InputDecoration(\n                              border: border,\n                              enabledBorder: border,\n                              focusedBorder: border,\n                            ),\n                          ),\n                        ),\n                        sbw(50),\n                      ],\n                    ),\n                    sbh(10),\n                  ],\n                );\n              },\n            ),\n          ),\n        ],\n      ),\n    );\n  }\n\n  final border = OutlineInputBorder(\n    borderRadius: BorderRadius.circular(8),\n  );\n}\n\n\nand Dart pad link  :  https://dartpad.dev/?id=9f87f484c1dc201b4d0c10d504eb7d1b\nSomebody please help.\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.\n",
"AnswerId": "76389825",
"AnswerBody": "The problem is that you don't keep track on which TextField corresponds with which expense. To solve it you need to define controllers that you can give the TextFields. Like this for example:\nclass _TestPageState extends State<TestPage> {\n  List<ExpenseItemModel> expenses = [ExpenseItemModel()];\n  List<TextEditingController> controllers = [TextEditingController()];\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      body: Column(\n        children: [\n          SizedBox(height: 150),\n          Expanded(\n            child: ListView.builder(\n              itemCount: expenses.length,\n              itemBuilder: (c, i) {\n                return Column(\n                  children: [\n                    Row(\n                      children: [\n                        IconButton(\n                          onPressed: () {\n                            if (i == expenses.length - 1 ||\n                                (expenses.length == 1)) return;\n                            expenses.removeAt(i);\n                            controllers.removeAt(i);\n                            setState(() {});\n                          },\n                          icon: Icon(CupertinoIcons.delete),\n                        ),\n                        Expanded(\n                          child: TextField(\n                            controller: controllers[i],\n                            onChanged: (val) {\n                              if (expenses.length - 1 == i) {\n                                expenses.add(ExpenseItemModel());\n                                controllers.add(TextEditingController());\n                              }\n                              setState(() {});\n                            },\n                            decoration: InputDecoration(\n                              border: border,\n                              enabledBorder: border,\n                              focusedBorder: border,\n                            ),\n                          ),\n                        ),\n                        SizedBox(width: 50),\n                      ],\n                    ),\n                    SizedBox(height: 10),\n                  ],\n                );\n              },\n            ),\n          ),\n        ],\n      ),\n    );\n  }\n\n  final border = OutlineInputBorder(\n    borderRadius: BorderRadius.circular(8),\n  );\n}\n\nNote I also changed the way you initialize expenses it a more concise way.\nInstead of having two lists like this you might even want to consider making the TextEditingController part of your ExpenseItemModel and then do something like controller: expenses[i].controller,\n"
},
{
"QuestionId": "76391151",
"QuestionTitle": "how program to join 2 different tables based on which one has the highest number of rows, with tidyverse?",
"QuestionBody": "How program to join 2 different tables based on which one has the highest number of rows, with tidyverse? Now, the total_number_views_ndinstict has only 8 but in the future this may have more rows than the second total_number_views_unique_na which currently has 10 rows. I need both columns in the joined table.\nHere is the first table:\n> total_number_views_ndinstict\n    # A tibble: 8 × 2\n      app_name                    n_distinct_users\n      <chr>                                  <int>\n    1 animals_to_groups                          2\n    2 cage_randomiser                            5\n    3 combo_cor                                  1\n    4 crispr_screen_viz                         21\n    5 dep_map_bem                                4\n    6 growth_rate_explorer                       3\n    7 moprospector                               2\n    8 translatability_single_gene               17\n\nAnd the second table is\n> total_number_views_unique_na\n# A tibble: 10 × 2\n   app_name                    users_na\n   <chr>                          <int>\n 1 animals_to_groups                 21\n 2 cage_randomiser                   14\n 3 combo_cor                         14\n 4 crispr_screen_viz                  1\n 5 dep_map_bem                        0\n 6 dtp_browser_prod                   6\n 7 flat                              81\n 8 growth_rate_explorer              48\n 9 moprospector                       0\n10 translatability_single_gene        2\n\nCan someone help?\n",
"AnswerId": "76391228",
"AnswerBody": "A full join will keep theh values of both tables\nlibrary(dplyr)\nfull_join(total_number_views_ndinstict, total_number_views_unique_na)\n\n"
},
{
"QuestionId": "76388303",
"QuestionTitle": "How can I get the primary key of a selected option from a dataframe-based selectInput in Shiny?",
"QuestionBody": "I am displaying a selectInput in my shiny app and it is getting its choices from a dataframe (which is coming from a table in the database).\nthis table (dataframe) has primary key and title in it. I want to show my users the title, but when they choose an option, I want to get the Id of the selected option to use in my code.\nI managed to get the selected \"value\" but I couldn't find how to get the \"id\" from the selected option.\nbelow is a simple example of how my code is looking with test objects:\n\n\nlibrary(DT)\nlibrary(tidyverse)\nlibrary(shiny)\n\n\n\n\ntest_id <- c(1, 2, 3)\ntest_title <- c(\"a\", \"b\", \"c\")\n\ntest_df <- data.frame(test_id, test_title)\ntest_df <- column_to_rownames(test_df, var = \"test_id\")\n\n\nui <- fluidPage(\n  selectInput(\"test\", \"test\", choices = test_df),\n  \n  textOutput(\"selectedItem\")\n  \n)\n\nserver <- function(input, output, session) {\n  \n  observeEvent(input$test, {\n    output$selectedItem <- renderText(input$test)\n  })\n  \n  \n    \n}\n\nshinyApp(ui, server)\n\n\ndoes anyone have a solution to get the \"id\" of the selected option?\nI have tried this\noutput$selectedItem <- renderText(input$test)\n\nbut it is returning the value and not the Id\n",
"AnswerId": "76388370",
"AnswerBody": "You could pass a named vector or list to the choices argument.\nFrom the docs (?selectInput):\n\nIf elements of the list are named, then that name — rather than the value — is displayed to the user.\n\nlibrary(tidyverse)\nlibrary(shiny)\n\ntest_id <- c(1, 2, 3)\ntest_title <- c(\"a\", \"b\", \"c\")\n\ntest_df <- data.frame(test_id, test_title)\nchoices <- setNames(test_df$test_id, test_df$test_title)\n\nui <- fluidPage(\n  selectInput(\"test\", \"test\", choices = choices),\n  textOutput(\"selectedItem\")\n)\n\nserver <- function(input, output, session) {\n  observeEvent(input$test, {\n    output$selectedItem <- renderText(input$test)\n  })\n}\n\nshinyApp(ui, server)\n#> \n#> Listening on http://127.0.0.1:5936\n\n\n"
},
{
"QuestionId": "76389806",
"QuestionTitle": "I'm getting an error: Effect callbacks are synchronous to prevent race conditions. I'm having trouble formatting it in the way it wants",
"QuestionBody": "I'm getting this error back though this same format seems to work in examples.\n    const response = await axios.get('http://localhost:5000/get-tasks')\n\n    const dataObject = response.data\n    \n\n    const arrayOfKeys = Object.keys(dataObject)\n    const arrayOfData = Object.keys(dataObject).map((key) => dataObject[key])\n\n    console.log(arrayOfKeys)\n    console.log(arrayOfData)\n  }, [])```\n\n",
"AnswerId": "76389878",
"AnswerBody": "The useEffect function arg can't be asynchronous, but you can call an async function inside it.\nuseEffect(() => {\n  async function getTasks() {\n    const response = await axios.get('http://localhost:5000/get-tasks')\n\n    const dataObject = response.data\n\n    const arrayOfKeys = Object.keys(dataObject)\n    const arrayOfData = Object.keys(dataObject).map((key) => dataObject[key])\n\n    console.log(arrayOfKeys)\n    console.log(arrayOfData)\n  };\n\n  getTasks();\n}, []);\n\n"
},
{
"QuestionId": "76391180",
"QuestionTitle": "How to fix this postgresql error `FATAL: password authentication failed for user ?",
"QuestionBody": "I'm trying to setup a simple server using IntelliJ Community, Spring Boot and PostgreSQL.\nI was following an online tutorial and downloaded the code from this github as an initial template. It should be a template generated by this website: https://start.spring.io/.\nBellow is the error log. How do I fix it?\n2023-06-02T11:30:49.064-03:00  WARN 12340 --- [  restartedMain] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Unable to obtain connection from database: FATAL: password authentication failed for user \"fernandakipper\"\n----------------------------------------------------------------------------------------------------------\nSQL State  : 28P01\nError Code : 0\nMessage    : FATAL: password authentication failed for user \"fernandakipper\"\n\n2023-06-02T11:30:49.071-03:00  INFO 12340 --- [  restartedMain] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]\n2023-06-02T11:30:49.095-03:00  INFO 12340 --- [  restartedMain] .s.b.a.l.ConditionEvaluationReportLogger : \n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.\n2023-06-02T11:30:49.140-03:00 ERROR 12340 --- [  restartedMain] o.s.boot.SpringApplication               : Application run failed\n\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Unable to obtain connection from database: FATAL: password authentication failed for user \"fernandakipper\"\n----------------------------------------------------------------------------------------------------------\nSQL State  : 28P01\nError Code : 0\nMessage    : FATAL: password authentication failed for user \"fernandakipper\"\n\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1770) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:598) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:520) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:326) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:324) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:313) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200) ~[spring-beans-6.0.9.jar:6.0.9]\n    at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1156) ~[spring-context-6.0.9.jar:6.0.9]\n    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:931) ~[spring-context-6.0.9.jar:6.0.9]\n    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:608) ~[spring-context-6.0.9.jar:6.0.9]\n    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146) ~[spring-boot-3.1.0.jar:3.1.0]\n    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:733) ~[spring-boot-3.1.0.jar:3.1.0]\n    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:435) ~[spring-boot-3.1.0.jar:3.1.0]\n    at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) ~[spring-boot-3.1.0.jar:3.1.0]\n    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1305) ~[spring-boot-3.1.0.jar:3.1.0]\n    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1294) ~[spring-boot-3.1.0.jar:3.1.0]\n    at com.example.crud.CrudApplication.main(CrudApplication.java:10) ~[classes/:na]\n    at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104) ~[na:na]\n    at java.base/java.lang.reflect.Method.invoke(Method.java:578) ~[na:na]\n    at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) ~[spring-boot-devtools-3.1.0.jar:3.1.0]\nCaused by: org.flywaydb.core.internal.exception.FlywaySqlException: Unable to obtain connection from database: FATAL: password authentication failed for user \"fernandakipper\"\n----------------------------------------------------------------------------------------------------------\nSQL State  : 28P01\nError Code : 0\nMessage    : FATAL: password authentication failed for user \"fernandakipper\"\n\n",
"AnswerId": "76391248",
"AnswerBody": "You have to install postgresql in your local and change the properties as per your db configuration. What they had provided is dummy. You have to put the actuals to make it work as expected\n"
},
{
"QuestionId": "76388093",
"QuestionTitle": "Change this SPARQL query",
"QuestionBody": "I have a query \"change the number of publications on artificial intelligence over time.\" Can you help me change this query not only about artificial intelligence, but also about subclasses of artificial intelligence?\nSELECT ?year (COUNT(DISTINCT ?item) AS ?count)\nWHERE {\n  ?item wdt:P31 wd:Q13442814 ;\n        wdt:P921 wd:Q11660 ;\n        wdt:P577 ?date .\n  BIND(YEAR(?date) AS ?year)\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\n GROUP BY ?year\n ORDER BY ?year\n\n",
"AnswerId": "76388374",
"AnswerBody": "You have just to replace wdt:P921 with wdt:P921/wdt:P279* (see here for the new query).\nwdt:P921/wdt:P279* is called property path. Such expressions are used for concatenating more properties in a single path which must comply with a certain structure. In this case, we are saying that the object of wdt:P921 can be the subject of wdt:P279 (* stands for \"zero or more times\") and the final object of such optional (chain of) wdt:P279 must be wd:Q11660.\nCheck out SPARQL 1.1 Query Language § 9 Property Paths for deepening this topic.\n"
},
{
"QuestionId": "76391217",
"QuestionTitle": "Group table by month",
"QuestionBody": "data = pd.read_csv(\"MLs_Unit_per_day.csv\",index_col='Date')\n\n\n\n            X1      X2  X3  X4  X5      X6\nDate                        \n01/01/2023  13  0   20  5   24  14\n02/01/2023  13  0   20  5   24  15\n03/01/2023  11  0   20  6   24  15\n04/01/2023  12  0   20  6   22  16\n05/01/2023  11  0   20  6   22  16\n... ... ... ... ... ... ...\n29/05/2023  13  1   23  6   22  17\n30/05/2023  13  1   23  6   22  18\n31/05/2023  13  1   23  7   23  18\n01/06/2023  12  1   23  7   24  19\n02/06/2023  13  0   23  8   24  19\n\nI'm trying to group by month ans Sum X1, X2, etc for the hole month. how can I do?\nthank you\nI tried before without making Date as index with this\ndata.groupby(data['Date'].dt.strftime('%B'))['RO1'].sum().sort_values()\n\nbut it show me wrong time format and then wrong months\n",
"AnswerId": "76391290",
"AnswerBody": "You need to convert the date to datetime, then create a new column for month and finally use groupby\ndata = pd.read_csv(\"MLs_Unit_per_day.csv\")\ndata['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n\n# Create a separate column for year and month\ndata['YearMonth'] = data['Date'].dt.to_period('M')\n\nmonthly_data = data.groupby('YearMonth').sum()\n\nprint(monthly_data)\n\n"
},
{
"QuestionId": "76388339",
"QuestionTitle": "R data.table lost rows after order",
"QuestionBody": "I have a data.table\n> dput(data.summary)\nstructure(list(summary_type = c(\"0\", \"1\", \"2\"), count = structure(list(\n    62234441L, 5119L, 821770L), .internal.selfref = <pointer: 0x557538f028c0>)), row.names = c(NA, \n-3L), class = c(\"data.table\", \"data.frame\"), .internal.selfref = <pointer: 0x557538f028c0>)\n\ndata.summary\n   summary_type    count\n1:            0 62234441\n2:            1     5119\n3:            2   821770\n\nIts a data.table with 3 row, I want to sort it by count\ndata.summary[order(count)]\n\nBut after this, there are only have 1 row in data.table\ndata.summary[order(count)]\n   summary_type    count\n1:            0 62234441\n\n",
"AnswerId": "76388399",
"AnswerBody": "For some reason, your count column is a list.\nlibrary(data.table)\ndf <- structure(list(summary_type = c(\"0\", \"1\", \"2\"), count = structure(list(\n  62234441L, 5119L, 821770L))), row.names = c(NA, -3L), class = c(\"data.table\", \"data.frame\"))\n\ndf[count]\n#Error in `[.data.table`(df, count, ) : \n#  count is not found in calling scope but it is a column of type list.  \n\nUse unlist:\ndf[order(unlist(count))]\n\n#    summary_type    count\n# 1:            1     5119\n# 2:            2   821770\n# 3:            0 62234441\n\n"
},
{
"QuestionId": "76389918",
"QuestionTitle": "InvalidProgramException in TypedBinding when running on iPad",
"QuestionBody": "My MAUI app runs fine on the iOS Simulator in Debug mode, but when I run it on an iPad in Release mode, I get the following cryptic error when opening a certain screen:\nSystem.Reflection.TargetInvocationException: Arg_TargetInvocationException\n ---> System.InvalidProgramException\n       at Microsoft.Maui.Controls.Internals.TypedBinding`2[[OIL.ISA.ViewModels.SettingsViewModel, OIL.ISA, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null],[System.String, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].ApplyCore(Object sourceObject, BindableObject target, BindableProperty property, Boolean fromTarget)\n       at Microsoft.Maui.Controls.Internals.TypedBinding`2[[OIL.ISA.ViewModels.SettingsViewModel, OIL.ISA, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null],[System.String, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].Apply(Object context, BindableObject bindObj, BindableProperty targetProperty, Boolean fromBindingContextChanged)\n   at Microsoft.Maui.Controls.BindableObject.ApplyBindings(Boolean skipBindingContext, Boolean fromBindingContextChanged)\n       at Microsoft.Maui.Controls.BindableObject.SetInheritedBindingContext(BindableObject bindable, Object value)\n   at Microsoft.Maui.Controls.Element.SetChildInheritedBindingContext(Element child, Object context)\n       at Microsoft.Maui.Controls.Element.<OnBindingContextChanged>b__82_0(BindableObject child, Object bc)\n   at Microsoft.Maui.Controls.BindableObjectExtensions.PropagateBindingContext[Element](BindableObject self, IEnumerable`1 children, Action`2 setChildBindingContext)\n   at Microsoft.Maui.Controls.Element.OnBindingContextChanged()\n       at Microsoft.Maui.Controls.VisualElement.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.View.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.BindableObject.SetInheritedBindingContext(BindableObject bindable, Object value)\n       at Microsoft.Maui.Controls.Element.SetChildInheritedBindingContext(Element child, Object context)\n   at Microsoft.Maui.Controls.Element.<OnBindingContextChanged>b__82_0(BindableObject child, Object bc)\n       at Microsoft.Maui.Controls.BindableObjectExtensions.PropagateBindingContext[Element](BindableObject self, IEnumerable`1 children, Action`2 setChildBindingContext)\n   at Microsoft.Maui.Controls.Element.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.VisualElement.OnBindingContextChanged()\n       at Microsoft.Maui.Controls.View.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.BindableObject.SetInheritedBindingContext(BindableObject bindable, Object value)\n   at Microsoft.Maui.Controls.Element.SetChildInheritedBindingContext(Element child, Object context)\n       at Microsoft.Maui.Controls.TemplatedPage.SetChildInheritedBindingContext(Element child, Object context)\n   at Microsoft.Maui.Controls.Element.<OnBindingContextChanged>b__82_0(BindableObject child, Object bc)\n       at Microsoft.Maui.Controls.BindableObjectExtensions.PropagateBindingContext[Element](BindableObject self, IEnumerable`1 children, Action`2 setChildBindingContext)\n   at Microsoft.Maui.Controls.Element.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.VisualElement.OnBindingContextChanged()\n       at Microsoft.Maui.Controls.Page.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.ContentPage.OnBindingContextChanged()\n   at Microsoft.Maui.Controls.BindableObject.BindingContextPropertyChanged(BindableObject bindable, Object oldvalue, Object newvalue)\n       at Microsoft.Maui.Controls.BindableObject.SetValueActual(BindableProperty property, BindablePropertyContext context, Object value, Boolean currentlyApplying, SetValueFlags attributes, Boolean silent)\n       at Microsoft.Maui.Controls.BindableObject.SetValueCore(BindableProperty property, Object value, SetValueFlags attributes, SetValuePrivateFlags privateAttributes)\n   at Microsoft.Maui.Controls.BindableObject.SetValue(BindableProperty property, Object value, Boolean fromStyle, Boolean checkAccess)\n       at Microsoft.Maui.Controls.BindableObject.SetValue(BindableProperty property, Object value)\n   at Microsoft.Maui.Controls.BindableObject.set_BindingContext(Object value)\n   at OIL.ISA.Views.SettingsPage..ctor()\n       at System.Reflection.RuntimeConstructorInfo.InternalInvoke(Object , Object[] , Boolean )\n   Exception_EndOfInnerExceptionStack\n   at ObjCRuntime.Runtime.ThrowException(IntPtr )\n   at UIKit.UIApplication.UIApplicationMain(Int32 , String[] , IntPtr , IntPtr )\n       at UIKit.UIApplication.Main(String[] , Type , Type )\n   at OIL.ISA.Platforms.iOS.Program.Main(String[] args)\n    Unhandled managed exception: Arg_TargetInvocationException (System.Reflection.TargetInvocationException)\n   at ObjCRuntime.Runtime.ThrowException(IntPtr )\n   at UIKit.UIApplication.UIApplicationMain(Int32 , String[] , IntPtr , IntPtr )\n   at UIKit.UIApplication.Main(String[] , Type , Type )\n   at OIL.ISA.Platforms.iOS.Program.Main(String[] args)\n (System.InvalidProgramException)\n   at Microsoft.Maui.Controls.Internals.TypedBinding`2[[OIL.ISA.ViewModels.SettingsViewModel, OIL.ISA, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null],[System.String, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].ApplyCore(Object sourceObject, BindableObject target, BindableProperty property, Boolean fromTarget)\n   at Microsoft.Maui.Controls.Internals.TypedBinding`2[[OIL.ISA.ViewModels.SettingsViewModel, OIL.ISA, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null],[System.String, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].<…>\n\nSearching for MAUI and InvalidProgramException does not give meaningful results. What's the cause of this exception?\n\nAs requested, here are some debugging details. The view model is like this:\npublic class SettingsViewModel : MainMenuPageViewModel {\n    public SettingsViewModel(ViewModelServices services, IPushNotificationsService pushNotificationsService, IDatabaseUploader databaseUploader, ISecureStorage secureStorage) : base(services) {\n        _pushNotificationsService = pushNotificationsService;\n        _databaseUploader = databaseUploader;\n        _databaseUploader.OnProgressChanged += OnDatabaseUploadProgressChanged;\n        _secureStorage = secureStorage;\n\n        Title = BaseApp.Settings;\n        PushNotificationsEnabled = pushNotificationsService.DeviceToken != null;\n        PushNotificationsEnabledMessage = PushNotificationsEnabled ? BaseApp.PushNotificationsEnabled : BaseApp.PushNotificationsNotEnabled;\n        Logout = new Command(DoLogout);\n        SendDatabase = new Command(UploadDatabase);\n        ShowPushNotificationDetails = new Command(ShowNotificationDetails);\n\n        using var context = new Context();\n        UserInformation = BaseApp.LoggedInAs + \" \" + LocalSettings.GetUsername(context);\n        UpdateSettingsInformation();\n        Settings.OnRefresh += (sender, e) => UpdateSettingsInformation();\n    }\n\n    private void UpdateSettingsInformation() {\n        StoreInformation = Settings.Store == null ? \"\" : Settings.Store.Number + \" - \" + Settings.Store.Name;\n        OnPropertyChanged(nameof(StoreInformation));\n    }\n\n    private void OnDatabaseUploadProgressChanged(object sender, ProgressChangedEventArgs e) {\n        Progress = e.ProgressPercentage / 100f;\n    }\n\n    private readonly IPushNotificationsService _pushNotificationsService;\n    private readonly IDatabaseUploader _databaseUploader;\n    private readonly ISecureStorage _secureStorage;\n\n    public string UserInformation { get; }\n    public string StoreInformation { get; private set; }\n    public bool PushNotificationsEnabled { get; }\n    public string PushNotificationsEnabledMessage { get; }\n    public string AppVersion => AppInfo.VersionString;\n\n    public ICommand Logout { get; }\n    public ICommand SendDatabase { get; }\n    public ICommand ShowPushNotificationDetails { get; }\n\n    ...\n}\n\nand the page itself\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<ContentPage\n    xmlns=\"http://schemas.microsoft.com/dotnet/2021/maui\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"\n    xmlns:controls=\"clr-namespace:OIL.ISA.Controls\"\n    xmlns:vm=\"clr-namespace:OIL.ISA.ViewModels\"\n    xmlns:r=\"clr-namespace:OIL.ISA.Resources\"\n    x:DataType=\"vm:SettingsViewModel\"\n    x:Class=\"OIL.ISA.Views.SettingsPage\"\n    Title=\"{Binding Title}\"\n    Shell.NavBarIsVisible=\"{Binding NavBarIsVisible}\">\n    <ContentPage.Content>\n        <AbsoluteLayout HorizontalOptions=\"FillAndExpand\" VerticalOptions=\"FillAndExpand\">\n            <Image AbsoluteLayout.LayoutFlags=\"All\" AbsoluteLayout.LayoutBounds=\"0,0,1,1\"\n                   Source=\"background.jpg\" Aspect=\"AspectFill\" />\n            <StackLayout AbsoluteLayout.LayoutFlags=\"PositionProportional\" AbsoluteLayout.LayoutBounds=\".5,0\" WidthRequest=\"320\"\n                         BackgroundColor=\"#D0FFFFFF\" Spacing=\"16\" Padding=\"16\" Margin=\"0,16\">\n                <Label Text=\"{Binding UserInformation}\" HorizontalOptions=\"Center\" />\n                <Label Text=\"{Binding StoreInformation}\" HorizontalOptions=\"Center\" />\n                <Button Style=\"{StaticResource SettingsButton}\"\n                        Text=\"{x:Static r:BaseApp.LogoutButton}\"\n                        Command=\"{Binding Logout}\" />\n                <Button Style=\"{StaticResource SettingsButton}\"\n                        Text=\"{x:Static r:BaseApp.SendDatabaseButton}\"\n                        Command=\"{Binding SendDatabase}\" />\n                <StackLayout Orientation=\"Horizontal\">\n                    <StackLayout.GestureRecognizers>    \n                        <TapGestureRecognizer Command=\"{Binding ShowPushNotificationDetails}\" />\n                    </StackLayout.GestureRecognizers>\n                    <CheckBox IsChecked=\"{Binding PushNotificationsEnabled}\" VerticalOptions=\"Center\" IsEnabled=\"False\" />\n                    <Label Text=\"{Binding PushNotificationsEnabledMessage}\" VerticalOptions=\"Center\" />\n                </StackLayout>\n                <Label Text=\"{Binding Path=AppVersion, StringFormat={x:Static r:BaseApp.Version}}\"\n                       HorizontalOptions=\"Center\" />\n            </StackLayout>\n            <controls:BlockingActivityIndicator\n                AbsoluteLayout.LayoutFlags=\"All\" AbsoluteLayout.LayoutBounds=\"0,0,1,1\"\n                IsVisible=\"{Binding IsBusy}\"\n                Message=\"{Binding BusyMessage}\"\n                HasProgress=\"{Binding HasProgress}\"\n                Progress=\"{Binding Progress}\" />\n        </AbsoluteLayout>\n    </ContentPage.Content>\n</ContentPage>\n\n(but as you can see, I already found the answer, I just need to document it somewhere in case someone else runs into it. Which, believe it or not, happened to myself, two months later, in another view model in the application. This is now the third hit in Google, I hope it can be useful this way)\n",
"AnswerId": "76389919",
"AnswerBody": "It turned out that my colleague used Resharper to analyze the code, and it had detected that one of the ViewModel properties:\npublic string AppVersion => AppInfo.VersionString;\n\ncould be changed into a static property:\npublic static string AppVersion => AppInfo.VersionString;\n\nThis did not cause any problems on Android or in the iOS Simulator, but was discovered only much later when testing a distribution build on an iPad. Making it an instance property again fixed the error.\n"
},
{
"QuestionId": "76388166",
"QuestionTitle": "Invalid Syntax on community.mysql.mysql_user with Ansible AWX",
"QuestionBody": "I am trying to run a playbook through AWX where I want to create a mariadb user with permissions. The playbook works nicely when run from ansible on my local machine. However, when I try to run the job on AWX, I get the following error :\n\n\"module_stdout\": \"Traceback (most recent call last):\\r\\n  File \"/home/ansible/.ansible/tmp/ansible-tmp-1685691063.0199862-220-69171919718447/AnsiballZ_mysql_user.py\", line 107, in \\r\\n    _ansiballz_main()\\r\\n  File \"/home/ansible/.ansible/tmp/ansible-tmp-1685691063.0199862-220-69171919718447/AnsiballZ_mysql_user.py\", line 99, in _ansiballz_main\\r\\n    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)\\r\\n  File \"/home/ansible/.ansible/tmp/ansible-tmp-1685691063.0199862-220-69171919718447/AnsiballZ_mysql_user.py\", line 48, in invoke_module\\r\\n    run_name='main', alter_sys=True)\\r\\n  File \"/usr/lib/python3.5/runpy.py\", line 205, in run_module\\r\\n    return _run_module_code(code, init_globals, run_name, mod_spec)\\r\\n  File \"/usr/lib/python3.5/runpy.py\", line 96, in _run_module_code\\r\\n    mod_name, mod_spec, pkg_name, script_name)\\r\\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\\r\\n    exec(code, run_globals)\\r\\n  File \"/tmp/ansible_community.mysql.mysql_user_payload_r3e02o87/ansible_community.mysql.mysql_user_payload.zip/ansible_collections/community/mysql/plugins/modules/mysql_user.py\", line 352, in \\r\\n  File \"\", line 969, in _find_and_load\\r\\n  File \"\", line 958, in _find_and_load_unlocked\\r\\n  File \"\", line 664, in _load_unlocked\\r\\n  File \"\", line 634, in _load_backward_compatible\\r\\n  File \"/tmp/ansible_community.mysql.mysql_user_payload_r3e02o87/ansible_community.mysql.mysql_user_payload.zip/ansible_collections/community/mysql/plugins/module_utils/mysql.py\", line 22, in \\r\\n  File \"/usr/local/lib/python3.5/dist-packages/pymysql/init.py\", line 59, in \\r\\n    from . import connections  # noqa: E402\\r\\n  File \"/usr/local/lib/python3.5/dist-packages/pymysql/connections.py\", line 206\\r\\n    ):\\r\\n    ^\\r\\nSyntaxError: invalid syntax\\r\\n\"\n\nHere's the task for creating the user :\n- name : Create mariadb user\n  community.mysql.mysql_user:\n    login_user: root\n    login_password: \"{{ root_password }}\"\n    name: user\n    password: \"{{ mariadb_user_pw }}\"\n    priv: \"*.*:PROCESS,SELECT,CREATE,CREATE TABLESPACE,INSERT\"\n    state: present\n\n",
"AnswerId": "76388426",
"AnswerBody": "Ensure the hosts have the correct package installed.\nInclude this in your playbook:\n- name: ensure mysql package for the mysql api is installed\n  pip:\n    name: pymysql\n    executable: pip3\n\n--\nyou should check your awx container.\neither by logging in to the container itself, and check stuff manually, or you can do this w ansible as well.\n- shell: locate ansible-galaxy\n  delegate_to: localhost\n  register: check_galaxy\n\n- debug:\n    msg: \"{{ check_galaxy.stdout }}\"\n  delegate_to: localhost\n\nThen, once you have the output, simply check the installed roles and it versions\n- shell: ansible-galaxy collection list\n  delegate_to: localhost\n  register: check_collection\n\n- debug:\n    msg: \"{{ check_collection }}\"\n  delegate_to: localhost\n\n"
},
{
"QuestionId": "76390844",
"QuestionTitle": "The difference between UserDetailsService and the class that implements it",
"QuestionBody": "Does it make sense to create your own class that implements the UserDetailsService interface? In many examples, I see how the UserDetailsService is embedded in the security configuration class, and not the class that implements it. What's the difference?\nAnd why, when I enter the wrong username and password, I don't get the error message that I registered in PersonDetailsService? \"Bad credentials\" is coming out. I'm a beginner and just started learning spring security\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfig {\n    private final PersonDetailsService personDetailsService;\n\n    @Autowired\n    public SecurityConfig(PersonDetailsService personDetailsService) {\n        this.personDetailsService = personDetailsService;\n    }\n\n    @Autowired\n    void configure(AuthenticationManagerBuilder builder) throws Exception {\n        builder.userDetailsService(personDetailsService);\n    }\n\n    @Bean\n    public PasswordEncoder getPasswordEncoder() {\n        return NoOpPasswordEncoder.getInstance();\n    }\n\n}\n\n\n@Service\npublic class PersonDetailsService implements UserDetailsService {\n    private final PeopleRepository peopleRepository;\n\n    @Autowired\n    public PersonDetailsService(PeopleRepository peopleRepository) {\n        this.peopleRepository = peopleRepository;\n    }\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\n        Optional<Person> person = peopleRepository.findByUsername(username);\n\n        if (person.isEmpty())\n            throw new UsernameNotFoundException(\"User not found\");\n\n        return new PersonDetails(person.get());\n    }\n}\n\n\n",
"AnswerId": "76391301",
"AnswerBody": "For your first question you spring security can authenticate multiple ways such as in memory and DB . in UserdetailsService and loadUserByUsername method you can customize how to authenticate users . and if you want DB mode you have multiple tables is DB and you can tell spring for finding username and password which table and columns must be check . for your second question put break point on your if statement and check what is person found . I think if it doesn't return username you have to use this if :\nif(person.get()==null)\n   throw new UsernameNotFoundException(\"User not found\");\n\n"
},
{
"QuestionId": "76389703",
"QuestionTitle": "User Document ID is the same as User ID in Firestore",
"QuestionBody": "I try to store users inside collection in Firestore as documents and want to make every User ID is same as Document ID..\nI tried but it still gives me another ID for the user:\nFuture<void> userSetupDone() async {\nCollectionReference users = FirebaseFirestore.instance.collection('Users');\n\nfinal docUser = FirebaseFirestore.instance.collection('Users').doc();\n\nFirebaseAuth auth = FirebaseAuth.instance;\nString? uid = docUser.id;\n// String? uid = auth.currentUser?.uid.toString();\nString? email = auth.currentUser?.email.toString();\nString? phone = auth.currentUser?.phoneNumber.toString();\nString? displayName = auth.currentUser?.displayName.toString();\n\nusers.add({'Uid': uid, \"Email\": email, \"Phone\": phone, \"Name\": displayName});\nreturn;\n}\n\n\n",
"AnswerId": "76389923",
"AnswerBody": "You have to update uid immediately after adding data to the database. Because you can not get id before adding that data from the Firestore Database.\nYou will get it by following code:\n Future<void> userSetupDone() async {\n    CollectionReference users = FirebaseFirestore.instance.collection('Users');\n    \n    final docUser = FirebaseFirestore.instance.collection('Users').doc();\n    \n    FirebaseAuth auth = FirebaseAuth.instance;\n\n    String? email = auth.currentUser?.email.toString();\n    String? phone = auth.currentUser?.phoneNumber.toString();\n    String? displayName = auth.currentUser?.displayName.toString();\n    \n    DocumentReference reference= await users.add({'Uid': '', \"Email\": email, \"Phone\": phone, \"Name\": displayName});\n    await reference.update({\"Uid\": reference.id});\n    return;\n}\n\n"
},
{
"QuestionId": "76381567",
"QuestionTitle": "How can I resolve the 'Could not find a valid Docker environment' error when using Testcontainers with Quarkus?",
"QuestionBody": "I try to use Testcontainers (v1.18.0) for tests in a Quarkus (v2.16.4.Final, java: Amazon Corretto 17) application. When I start it up I get the following stack trace:\n2023-06-01 13:11:10,326 INFO  [org.tes.uti.ImageNameSubstitutor] (main) Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')\n2023-06-01 13:11:10,502 INFO  [org.tes.doc.DockerClientProviderStrategy] (pool-3-thread-1) Loaded org.testcontainers.dockerclient.NpipeSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first\n2023-06-01 13:11:10,599 INFO  [org.tes.doc.DockerMachineClientProviderStrategy] (pool-3-thread-1) docker-machine executable was not found on PATH ([C:\\Python311\\Scripts\\, C:\\Python311\\, C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin, C:\\WINDOWS\\system32, C:\\WINDOWS, C:\\WINDOWS\\System32\\Wbem, C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\, C:\\WINDOWS\\System32\\OpenSSH\\, C:\\ProgramData\\chocolatey\\bin, C:\\Program Files\\Azure Data Studio\\bin, C:\\Program Files\\Microsoft\\Azure Functions Core Tools\\, C:\\Program Files\\PuTTY\\, C:\\Program Files\\TortoiseGit\\bin, C:\\Program Files\\Java\\jdk17.0.4_8\\bin, C:\\Program Files\\Java\\scripts, C:\\Program Files\\nodejs\\, C:\\Program Files\\dotnet\\, C:\\Program Files\\TortoiseSVN\\bin, C:\\Program Files\\Git\\cmd, C:\\Program Files\\Maven\\apache-maven-3.8.6\\bin, , C:\\Program Files\\Docker\\Docker\\resources\\bin, C:\\Users\\***\\AppData\\Local\\Microsoft\\WindowsApps, C:\\Program Files\\Azure Data Studio\\bin, C:\\Users\\***\\AppData\\Local\\Programs\\Microsoft VS Code\\bin, C:\\Users\\***\\AppData\\Roaming\\npm, C:\\Program Files\\Java\\jdk11.0.16_8\\bin, C:\\Users\\***\\.dotnet\\tools, C:\\Users\\***\\AppData\\Local\\JetBrains\\Toolbox\\scripts, C:\\Users\\***\\.azure-kubelogin, C:\\Users\\***\\AppData\\Local\\Microsoft\\WindowsApps, C:\\Program Files\\Docker\\Docker\\resources\\bin])\n2023-06-01 13:11:10,601 ERROR [org.tes.doc.DockerClientProviderStrategy] (pool-3-thread-1) Could not find a valid Docker environment. Please check configuration. Attempted configurations were:\n    NpipeSocketClientProviderStrategy: failed with exception NoClassDefFoundError (com/github/dockerjava/api/command/LoadImageAsyncCmd). Root cause ClassNotFoundException (com.github.dockerjava.api.command.LoadImageAsyncCmd)As no valid configuration was found, execution cannot continue.\nSee https://www.testcontainers.org/on_failure.html for more details.\n\njava.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n\n    at io.quarkus.test.junit.QuarkusTestExtension.throwBootFailureException(QuarkusTestExtension.java:625)\n    at io.quarkus.test.junit.QuarkusTestExtension.interceptTestClassConstructor(QuarkusTestExtension.java:696)\n    at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n    at org.junit.jupiter.api.extension.InvocationInterceptor.interceptTestClassConstructor(InvocationInterceptor.java:73)\n    at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n    at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n    at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:62)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestClassConstructor(ClassBasedTestDescriptor.java:363)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateTestClass(ClassBasedTestDescriptor.java:310)\n    at org.junit.jupiter.engine.descriptor.ClassTestDescriptor.instantiateTestClass(ClassTestDescriptor.java:79)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:286)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:278)\n    at java.base/java.util.Optional.orElseGet(Optional.java:364)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:277)\n    at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:31)\n    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:105)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:104)\n    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:68)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)\n    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\n    at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n    at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\n    at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)\n    at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)\n    at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)\n    at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)\n    at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)\n    at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)\n    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\n    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\n    at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\n    at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)\n    at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:57)\n    at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)\n    at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)\n    at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)\n    at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)\n    at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)\nCaused by: java.lang.reflect.InvocationTargetException\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.base/java.lang.reflect.Method.invoke(Method.java:568)\n    at io.quarkus.test.junit.QuarkusTestExtension.doJavaStart(QuarkusTestExtension.java:237)\n    at io.quarkus.test.junit.QuarkusTestExtension.ensureStarted(QuarkusTestExtension.java:592)\n    at io.quarkus.test.junit.QuarkusTestExtension.beforeAll(QuarkusTestExtension.java:640)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllCallbacks$12(ClassBasedTestDescriptor.java:395)\n    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllCallbacks(ClassBasedTestDescriptor.java:395)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:211)\n    at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:84)\n    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)\n    ... 36 more\nCaused by: java.util.concurrent.CompletionException: java.lang.RuntimeException: Unable to start Quarkus test resource class com.***.locref.DatabaseResource\n    at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:315)\n    at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:320)\n    at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1807)\n    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    at java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.RuntimeException: Unable to start Quarkus test resource class com.***.locref.DatabaseResource\n    at io.quarkus.test.common.TestResourceManager$TestResourceEntryRunnable.run(TestResourceManager.java:487)\n    at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)\n    ... 3 more\nCaused by: java.lang.IllegalStateException: Could not find a valid Docker environment. Please see logs and check configuration\n    at org.testcontainers.dockerclient.DockerClientProviderStrategy.lambda$getFirstValidStrategy$7(DockerClientProviderStrategy.java:256)\n    at java.base/java.util.Optional.orElseThrow(Optional.java:403)\n    at org.testcontainers.dockerclient.DockerClientProviderStrategy.getFirstValidStrategy(DockerClientProviderStrategy.java:247)\n    at org.testcontainers.DockerClientFactory.getOrInitializeStrategy(DockerClientFactory.java:150)\n    at org.testcontainers.DockerClientFactory.client(DockerClientFactory.java:186)\n    at org.testcontainers.DockerClientFactory$1.getDockerClient(DockerClientFactory.java:104)\n    at com.github.dockerjava.api.DockerClientDelegate.authConfig(DockerClientDelegate.java:108)\n    at org.testcontainers.containers.GenericContainer.start(GenericContainer.java:321)\n    at com.***.locref.DatabaseResource.start(DatabaseResource.java:28)\n    at io.quarkus.test.common.TestResourceManager$TestResourceEntryRunnable.run(TestResourceManager.java:481)\n    ... 4 more\n\nI have a class that implements QuarkusTestResourceLifecycleManager and starts a PostgreSQLContainer. I add it to a Test class annotated with @QuarkusTest and @QuarkusTestResource.\nI used a very similar setup in a plain Java application without any problems. Problems only arise when Quarkus appears in the loop. I researched all exceptions related to the docker runtime and the NpipeSocketClientProviderStrategy but was not able to find a solution.\n",
"AnswerId": "76388484",
"AnswerBody": "The versions of Quarkus and Testcontainers were incompatible. Resolving the version of Testcontainers via quarkus-bom in maven dependencyManagement resulted in 1.17.6 which works as expected.\n"
},
{
"QuestionId": "76391249",
"QuestionTitle": "Is there a way to maintain C++ array formatting when using VScode's default formatter upon saving?",
"QuestionBody": "When using the default VScode formatter for c++. I want to keep format on save but I don't want the array to be changed this drastically.\nIt changes an array from this\n    const int level[] =\n    {\n        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n        1, 1, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3,\n        0, 1, 0, 0, 2, 0, 3, 3, 3, 0, 1, 1, 1, 0, 0, 0,\n        0, 1, 1, 0, 3, 3, 3, 0, 0, 0, 1, 1, 1, 2, 0, 0,\n        0, 0, 1, 0, 3, 0, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0,\n        2, 0, 1, 0, 3, 0, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1,\n        0, 0, 1, 0, 3, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1,\n    };\n\n\nto this\n    const int level[] = {\n        0,\n        0,\n        0,\n        0,\n        0,\n        0,\n        1,\n        1,\n        1,\n        1,\n        1,\n        1,\n        1,\n        1,\n        1,\n        1,\n        0,\n        1,\n        1,\n        1,\n        1,\n        1,\n        1,\n        ...\n\n    };\n\nI want to keep format on save but I don't want the array to be changed this drastically.\n",
"AnswerId": "76391358",
"AnswerBody": "Not sure if you are trying to keep using the default formatting engine for some reason, I can't find an option to change this behavior using the default, but this behavior is not present when setting the option  C_Cpp:Formatting (Extensions > C/C++ > Formatting > C_Cpp: Formatting) to vcFormat. If you just want format on save to not elongate your arrays Id use that engine option.\n"
},
{
"QuestionId": "76389050",
"QuestionTitle": "Cleaning data in R by using a reference date",
"QuestionBody": "Consider the following dataset\nmydata<-data.frame(id = c(\"R007\", \"R008\", \"R008\", \"R009\", \"R009\"),\n                   statenumber= c(1, 2, 3, 4, 5),\n                   startdate = c(20080101, 20080101, 20120301,20120101, 20121001),\n                   enddate = c(20121201, 20120301, 20121201, 20121001, 20121201))\n\n#if necessary we can write the dates as dates\nmydata$startdate<-as.Date(as.character(mydata$startdate), \"%Y%m%d\")\nmydata$enddate<-as.Date(as.character(mydata$enddate), \"%Y%m%d\")\n\nThe explanation of the dataset is as follows. A person with id number R007 lives during 2008 and 2012 at the same address. Person R008 lives during 2008 and 2012 at two addresses (state number). So for the years 2008-2011, he lives at address 2, and for the year 2012 he lives at address 3. Person R009 is only available in the file since 2012. During the first year of 2012 he lives at address 4 and in the last two months he lives at address 5.\nNow I want to rearrange this dataset such that I have one address line per person per year. I would like to do this by making use of a reference month (say June). In other words, if a person lives in June at a particular address, I assign that address to him for the entire year. The dataset would then look as follows\nendresult<-data.frame(id = c(\"R007\", \"R007\",\"R007\",\"R007\",\"R007\",\n                             \"R008\", \"R008\", \"R008\", \"R008\",\"R008\", \"R009\"),\n                      statenumber = c(1,1,1,1,1,2,2,2,2,3,4),\n                      year = c(2008, 2009, 2010, 2011, 2012,\n                               2008,2009,2010,2011,2012, 2012))\n\nDoes anyone know how to get to this endresult dataset? I appreciate any help.\n",
"AnswerId": "76389929",
"AnswerBody": "Two basic approaches: (1) do a yearly sequence, conditioning on whether the start is before and if the end is after June (06), used in the base R approach; (2) do a monthly sequence, conditioning (group-filtering) each year on whether \"06\" is in one of the months. They both work, which you choose depends on comfort/preference.\nbase R\nSince this example uses \"sequence by year\", I'll use the fact that POSIXlt (notice the l, as opposed to the more common POSIXct) is really a list with elements for year, month, etc:\ndput(as.POSIXlt(Sys.time()))\n# structure(list(sec = 21.7977600097656, min = 30L, hour = 8L, \n#     mday = 2L, mon = 5L, year = 123L, wday = 5L, yday = 152L, \n#     isdst = 1L, zone = \"EDT\", gmtoff = -14400L), class = c(\"POSIXlt\", \n# \"POSIXt\"), tzone = c(\"\", \"EST\", \"EDT\"))\n\nWith that, we can easily $-index the list and compare the month as a value. NOTE: ?POSIXlt shows that mon is ‘mon’ 0-11: months after the first of the year, meaning that June is 5 in 0-based months. (Ergo the use of 5 below.)\nfun <- function(sd, ed) {\n  sdlt <- as.POSIXlt(sd)\n  edlt <- as.POSIXlt(ed)\n  if (sdlt$mon > 5) sdlt$year <- sdlt$year+1\n  if (edlt$mon < 5) edlt$year <- edlt$year-1\n  if (sdlt <= edlt) unique(format(seq.Date(as.Date(sdlt), as.Date(edlt), by = \"year\"), format=\"%Y\"))\n}\nyears <- Map(fun, mydata$startdate, mydata$enddate)\nstr(years)\n# List of 5\n#  $ : chr [1:5] \"2008\" \"2009\" \"2010\" \"2011\" ...\n#  $ : chr [1:4] \"2008\" \"2009\" \"2010\" \"2011\"\n#  $ : chr \"2012\"\n#  $ : chr \"2012\"\n#  $ : NULL\nout <- data.frame(\n  id = rep(mydata$id, lengths(years)), \n  statenumber = rep(mydata$statenumber, lengths(years)), \n  year = unlist(years))\nout\n#      id statenumber year\n# 1  R007           1 2008\n# 2  R007           1 2009\n# 3  R007           1 2010\n# 4  R007           1 2011\n# 5  R007           1 2012\n# 6  R008           2 2008\n# 7  R008           2 2009\n# 8  R008           2 2010\n# 9  R008           2 2011\n# 10 R008           3 2012\n# 11 R009           4 2012\n\nIf there's a chance to have duplicates (repeated states for an id that gap within the same year), then you can use unique(out).\nMap just \"zips\" the data together. The individual calls to fun unrolled would look like this:\nlist(\n  fun(mydata$startdate[1], mydata$enddate[1]),\n  fun(mydata$startdate[2], mydata$enddate[2]),\n  fun(mydata$startdate[3], mydata$enddate[3]),\n  fun(mydata$startdate[4], mydata$enddate[4]),\n  fun(mydata$startdate[5], mydata$enddate[5])\n)\n\nThe inclusion of ed on the end of c(seq.Date(..), ed) is to guard against the fact that seq may not include the year of the enddate. In this case, it ensures that R008 in state 2 sees 2012.\ndplyr\nIn this (and the data.table) section, we'll use the monthly sequence instead, using format=\"%m\" as the month. Dissimilar from POSIXlt above (June is 5), reading ?%strptime for the %-codes defines %m as ‘%m’ Month as decimal number (01-12), so June is back to \"06\".\nlibrary(dplyr)\nmydata %>%\n  rowwise() %>%\n  summarize(\n    id, statenumber, \n    dates = seq(startdate, enddate, by = \"month\"), \n    year = format(dates, format = \"%Y\")) %>%\n  group_by(id, statenumber, year) %>%\n  filter(any(format(dates, format = \"%m\") == \"06\")) %>%\n  distinct(id, statenumber, year) %>%\n  ungroup()\n# # A tibble: 11 × 3\n#    id    statenumber year \n#    <chr>       <dbl> <chr>\n#  1 R007            1 2008 \n#  2 R007            1 2009 \n#  3 R007            1 2010 \n#  4 R007            1 2011 \n#  5 R007            1 2012 \n#  6 R008            2 2008 \n#  7 R008            2 2009 \n#  8 R008            2 2010 \n#  9 R008            2 2011 \n# 10 R008            3 2012 \n# 11 R009            4 2012 \n\nI generally try to avoid rowwise when able, but this problem does need to be executed one row at a time (which is effectively what Map is doing in the base R solution above).\ndata.table\nlibrary(data.table)\nas.data.table(mydata)[, .(id, statenumber, dates = seq(startdate, enddate, by = \"month\")), by = .(seq(nrow(mydata)))\n  ][, year := format(dates, format=\"%Y\")\n  ][, .SD[any(format(dates, format=\"%m\") == \"06\"),], by = .(id, statenumber, year)\n  ][, c(\"seq\", \"dates\") := NULL\n  ][, unique(.SD)]\n#         id statenumber   year\n#     <char>       <num> <char>\n#  1:   R007           1   2008\n#  2:   R007           1   2009\n#  3:   R007           1   2010\n#  4:   R007           1   2011\n#  5:   R007           1   2012\n#  6:   R008           2   2008\n#  7:   R008           2   2009\n#  8:   R008           2   2010\n#  9:   R008           2   2011\n# 10:   R008           3   2012\n# 11:   R009           4   2012\n\n"
},
{
"QuestionId": "76388250",
"QuestionTitle": "Repeat a formula in google sheet within a single cell using different values",
"QuestionBody": "So to summarize what i want:\nLet's say i have\n   A         B\n1 \"Tommy\"    \"1,2,3\"\n2 \"Berry\"    \"3,4,5\"\n3 \"Hank\"     \"1,4,5\"\n4\n5\n6 \"1\"        \n7 \"5\"\n\nI would like B6 to show \"Tommy Hank\" and B7 to show \"Berry Hank\"\nIf have managed to create this formula;\n=IF(ISERROR(MATCH($A6,SPLIT(B1, \",\" , 1,1),0)),\"\",A1)\n\nThis formula will give me back the value \"Tommy\" but not Hank.\nI want to list all corresponding A values for every B cell that contains the value \"1\".\nI tried some things with arrayformula like =IF(ISERROR(MATCH($A6,SPLIT(B1:B3, \",\" , 1,1),0)),\"\",A1:A3) but i don't really understand what i'm doing here.\n",
"AnswerId": "76388539",
"AnswerBody": "I was going to suggest\n=ArrayFormula(\n   textjoin(\" \",,\n     query(\n       {A$1:A$3,\",\"&B$1:B$3&\",\"},\n       \"select Col1 \n        where Col2 contains'\"&\",\"&A6&\",\"&\"'\"\n     )\n   )\n )\n\n\n"
},
{
"QuestionId": "76391142",
"QuestionTitle": "FutureProvider does not return data to UI",
"QuestionBody": "I'm new using Riverpod and its providers. I have 2 almost identical futureProviders but one of them does not return data to UI even though API returns data.\nHere is UI part\n\nclass ProductDetailSimilarProductsWidget extends ConsumerWidget {\n  const ProductDetailSimilarProductsWidget(this.product, {super.key});\n\n  final ProductDetailModel product;\n\n  @override\n  Widget build(BuildContext context, WidgetRef ref) {\n    var value = ref.watch(getSimilarProductsFutureProvider([product.Id, product.KategoriId]));\n    return Container(\n      height: MediaQuery.of(context).size.height * 0.5,\n      width: MediaQuery.of(context).size.width,\n      child: value.when(\n        data: (data) {\n          print(\"data length:${data.length}\");\n          return ListView.builder(\n            itemCount: data.length,\n            shrinkWrap: true,\n            scrollDirection: Axis.horizontal,\n            itemBuilder: (context, index) {\n              return Padding(\n                padding: EdgeInsets.only(left: AppTheme.mediumPadding, right: AppTheme.mediumPadding),\n                child: ProductGridContainerWidget(product: data[index]),\n              );\n            },\n          );\n        },\n        error: (err, trace) {\n          return Text(err.toString());\n        },\n        loading: () => AppTheme.spinkit,\n      ),\n    );\n  }\n}\n\nHere is futureProvider object\n\nfinal getSimilarProductsFutureProvider = FutureProvider.family<List<Products>, List<dynamic>>((ref, value) async {\n  var result = await ProductDetailData().getSimilarProducts(productId: value[0], categoryId: value[1]);\n  print(\"result: ${result.length}\");\n  return result;\n});\n\nFinally, the method does API call\n    var service = ApiService();\n    var sharedPreferencesManager = SharedPreferencesManager();\n    await sharedPreferencesManager.init();\n    var langId = await sharedPreferencesManager.getLanguageId();\n    var countryId = await sharedPreferencesManager.getCountryId();\n    var result =\n        await service.getRequest(subUrl: \"${ApiRoutes.getSimilarProducts}?productId=$productId&langId=$langId&countryId=$countryId&categoryId=$categoryId\");\n    List<Products> products = [];\n    var elements = json.decode(result.body);\n    await Future.forEach(elements, (element) => products.add(Products.fromMap(element as Map<String, dynamic>)));\n    return products;\n\nInside provider object, result.length variable prints 10 and it is expected. But inside the UI part, widget stucks on loading part and does not print data.length variable.\nIs there something wrong in my codes? Also API works fine and successfully returns data.\n",
"AnswerId": "76391393",
"AnswerBody": "Your mistake is probably using the list as an argument for .family.\n\nIdeally, the parameter should either be a primitive (bool/int/double/String), a constant (providers), or an immutable object that overrides == and hashCode.\n\nTry using Records or create an immutable object with the two required fields.\n"
},
{
"QuestionId": "76389061",
"QuestionTitle": "Non-Repeating Random Numbers for Multiple Variables",
"QuestionBody": "I am trying to create a function that applies random values to a range of parameters that are used in another function where the random sequence does not repeat.\nThe reason: used for random hyper parameter tuning and to cut down on processing by not repeating sequence.\nExample Code:\n\nnum_evals = 2500\n\nparameters = {\n        'n_parameter_1': range(2,100),\n        'n_parameter_2': range(1,20),\n        'n_parameter_3': range(2,150),\n              }  \n\nfor i in range(num_evals):\n        n_parameter_1 = random.choice(parameters['n_parameter_1'])\n        n_parameter_2 = random.choice(parameters['n_parameter_2'])\n        n_parameter_3 = random.choice(parameters['n_parameter_3'])\n\n\nThe results then get populated to a file with the random parameters used to generate.\nI need help with the second bit.\nAs this function runs over time, you start getting sequences that look like this:\nn_parameter_1 = 54, n_parameter_2 = 15, n_parameter_3 = 120\nn_parameter_1 = 10, n_parameter_2 = 12, n_parameter_3 = 89\nn_parameter_1 = 54, n_parameter_2 = 15, n_parameter_3 = 120\nI want to avoid the last sequence by either capturing the sequences in a list or dataframe etc. (already saving the sequences) that the function checks and then generates a new/different sequence if there is a duplicate sequence in the list.\nThanks for the help in advance.\n",
"AnswerId": "76389938",
"AnswerBody": "You can store sequences in a set and then check if a sequence is already in the set.\nnum_evals = 2500\ni = 0\n\nparameters = {\n        'n_parameter_1': range(2,100),\n        'n_parameter_2': range(1,20),\n        'n_parameter_3': range(2,150),\n              }  \n\nsequences = set()\n\nwhile i < num_evals:\n        n_parameter_1 = random.choice(parameters['n_parameter_1'])\n        n_parameter_2 = random.choice(parameters['n_parameter_2'])\n        n_parameter_3 = random.choice(parameters['n_parameter_3'])\n        sequence = (n_parameter_1, n_parameter_2, n_parameter_3)\n        if sequence not in sequences:\n            sequences.add(sequence)\n            i += 1\n\nThe for loop has been changed to a while loop to allow for the conditional increment.\n"
},
{
"QuestionId": "76389663",
"QuestionTitle": "Algorithm to list all combinations from a table where data is present or NULL",
"QuestionBody": "I have an Excel file (which can optionally be loaded into a database, and into an array of arrays of course) with values such as:\n\n\n\n\nA\nB\nC\n\n\n\n\nNULL\nNULL\nzxy\n\n\nxyz\nxzy\nNULL\n\n\nxyz\nxzy\nxyy\n\n\nyzy\nyyx\nyxy\n\n\nNULL\nNULL\nxyx\n\n\nxyz\nNULL\nyxx\n\n\n\n\nand so on.\nThere are thousands of values.\nIs there any known algorithm to come up with all possible combinations of rows where values are not \"NULL\"?\nFor example for the table above the result would be:\n\n\n\n\nA\nB\nC\nNumber of occurrences\n\n\n\n\nNULL\nNULL\n*\n2\n\n\n*\n*\nNULL\n1\n\n\n*\n*\n*\n2\n\n\n*\nNULL\n*\n1\n\n\n\n\nI feel like it is a typical task, but cannot find the algorithm anywhere. Would appreciate your help a lot.\n",
"AnswerId": "76389956",
"AnswerBody": "If you are tempted to use pandas :\n#pip install pandas\nimport pandas as pd\n\ndf = pd.read_excel(\"file.xlsx\")\n\nout = (\n    df.replace(\".+\", \"*\", regex=True).fillna(\"NULL\")\n        .groupby(list(df), group_keys=False, sort=False)\n        .size().reset_index(name=\"Number of occurrences\")\n)\n\nOutput :\nprint(out)\n    \n      A     B     C  Number of occurrences\n0  NULL  NULL     *                      2\n1     *     *  NULL                      1\n2     *     *     *                      2\n3     *  NULL     *                      1\n\n"
},
{
"QuestionId": "76388396",
"QuestionTitle": "Unable to extract id from json response in jmeter",
"QuestionBody": "My am calling POST on an API. The response has\n{\n  \"id\" : \"1234”,\n---\n}\n\nI have following regular expression extractor:\n\nHowever in the DELETE HTTP Request on API/${id}, I am getting API/NOT FOUND.\nPlease suggest whats the issue with my regular expression ?\n",
"AnswerId": "76388560",
"AnswerBody": "JSON is not a regular language hence using regular expressions for it is not the best idea\nConsider using JSON Extractor instead, the relevant JSONPath expression is just id\nDemo:\n\n"
},
{
"QuestionId": "76391063",
"QuestionTitle": "ESLint error: Failed to load 'eslint-plugin-jsdoc' in IntelliJ on Ubuntu - troubleshooting tips?",
"QuestionBody": "I am struggling with ESLint not being able to load in IntelliJ 2023.1 on Ubuntu 22.04.\nIt seems like there are several syntax errors in the libraries, but I just could not belive that.\nWhat could I do?\nBest regards\nPeter\nPS: error in detail:\n\n\nIf I correct this specific one (yes, I should not overwrite libraries, especially when I'm not an expert on that stuff), a new syntax error comes again.\n",
"AnswerId": "76391398",
"AnswerBody": "What Node.js version do you have? Looks like it doesn't support the nullish coalescing operator; please make sure that the interpreter set up in Settings | Languages & Frameworks | Node.js is v. 14 or higher, see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing#browser_compatibility\n"
},
{
"QuestionId": "76384879",
"QuestionTitle": "Can't access localhost sites anymore",
"QuestionBody": "No access to localhost sites anymore.\nI have IIS 6.0 running on a Windows 7 64 bit PC where I work on local websites.\nI have 4 sites that were working until yesterday and now give me a 404 error when I try to access. I have tried IE, Chrome, Brave and Firefox.\nOne of the sites I'm working on for our karate club is a login for weekend courses where the member's card is checked by a webcam in a box to allow them to log in. It was working (they all were), but I needed this site to be HTTPS as the javascripts for the camera must be downloaded using this protocol. The location of the course may not have internet access so these must be loaded from the localhost site.\nI was messing about trying creating self signed certificates for localhost which I managed to do, but i could not get the site to work using https. I then removed the certificates but the sites would not then access normally (http).\nI cleared the cache of each browser and have reset IIS and restarted the pc. I also went through and disabled the world wide services, restarted the PC and restarted WWS.\nNothing has helped.\nAny advice/pointers would be a great help.\nThanks in Advance,\nAndy\n",
"AnswerId": "76389984",
"AnswerBody": "I solved the problem myself by doing a system restore to the point just before i installed the IIS toolkit. My sites are now back to working using http again.\nI'm guessing that it was something in the toolkit that caused the problem.\nThanks for the advice anyway.\nRegards,\nAndy\n"
},
{
"QuestionId": "76388415",
"QuestionTitle": "Why is data.posts undefined when accessing using subscriber method in redux?",
"QuestionBody": "How can I access complete state in redux?\nconst { createStore } = require(\"redux\");\n\nconst initialState = {\n  posts: [\n    { id: 1, title: \"Post one\" },\n    { id: 2, title: \"Post two\" },\n  ],\n};\n\nMy Posts Reducer\nconst PostsReducer = (state = initialState, action) => {\n  switch (action.type) {\n    case \"add_post\":\n      return {\n        ...state,\n        posts: [...state.posts, action.payload],\n      };\n\n    case \"delete_post\":\n      return {\n        ...state,\n        posts: state.posts.filter((post) => post.id !== action.payload),\n      };\n\n    case \"get_all_posts\":\n      return state.posts;\n\n    default:\n      return state;\n  }\n};\n\nconst store = createStore(PostsReducer);\n\nMy Action Creators:\nconst GetAllPosts = () => {\n  return {\n    type: \"get_all_posts\",\n  };\n};\n\nconst AddPost = (payload) => {\n  return { type: \"add_post\", payload };\n};\n\nconst removePost = (payload) => {\n  return { type: \"delete_post\", payload };\n};\n\nAccessing Store data:\nstore.subscribe(() => {\n  const data = store.getState();\n  console.log(data.posts);\n});\n\nstore.dispatch(GetAllPosts());\n\nWhile I am console logging data.posts it returns undefined.\nI am accessing using subscriber method:\nstore.subscribe(() => {\n  const data = store.getState();\n  console.log(data.posts);\n});\n\nstore.dispatch(GetAllPosts());\n\nNote:\nI am Using Redux(4.2.1)\nBy using GetAllPosts(), I am able to access data, but I cannot get data.posts in console.\n",
"AnswerId": "76388571",
"AnswerBody": "The get_all_posts case is returning the state.posts array directly instead of setting a state object with a posts property.\ncase \"get_all_posts\":\n  return state.posts; // <-- just the posts array\n\nUpdate get_all_posts case to return the correct state invariant, likely the initial state value with all the posts included.\nExample:\nconst initialState = {\n  posts: [\n    { id: 1, title: \"Post one\" },\n    { id: 2, title: \"Post two\" },\n  ],\n};\n\nconst PostsReducer = (state = initialState, action) => {\n  switch (action.type) {\n    case \"add_post\":\n      return {\n        ...state,\n        posts: [...state.posts, action.payload],\n      };\n\n    case \"delete_post\":\n      return {\n        ...state,\n        posts: state.posts.filter((post) => post.id !== action.payload),\n      };\n\n    case \"get_all_posts\":\n      return { ...initialState };\n\n    default:\n      return state;\n  }\n};\n\n"
},
{
"QuestionId": "76390677",
"QuestionTitle": "Why does my reactjs project on hostinger give a 404 error when opening a new tab or refreshing the page?",
"QuestionBody": "I have deployed reactjs project on hostinger where i open any new tab or refresh the page it give error 404\ni have used latest version of react router dom\nIndex.js\n<Browserrouter>\n<App/>\n<Browserrouter/>\n\n\nApp.js\n\n<Routes>\n<Route path=\"/\" element={<Home/>}/>\n        <Route path=\"/about-us\" element={<Aboutus/>}/>\n        <Route path=\"/contact-us\" element={<Contactus/>}/>\n        <Route path=\"/career\" element={<Career/>}/>\n        <Route path=\"/work\" element={<Work/>}/> \n        <Route path=\"/services\" element={<ServicesMain/>}/>\n\n<Routes/>\n\n",
"AnswerId": "76391409",
"AnswerBody": "The issue is not with the React but your hosting config. You need to add rewrite rules by adding .htaccess file inside your 'public' folder with the following code.\n<IfModule mod_rewrite.c>\n  RewriteEngine On\n  RewriteBase /\n  RewriteRule ^index\\.html$ - [L]\n  RewriteCond %{REQUEST_FILENAME} !-f\n  RewriteCond %{REQUEST_FILENAME} !-d\n  RewriteCond %{REQUEST_FILENAME} !-l\n  RewriteRule . /index.html [L]\n</IfModule>\n\n"
},
{
"QuestionId": "76389787",
"QuestionTitle": "Passing variables to a variable in bash",
"QuestionBody": "I'm writing custom logging for the bash:\n#!/usr/bin/env bash\n\nset -e +x\n\nSCRIPT_LOG_NAME='[MYSCRIPT]'\nSCRIPT_LOG_DATETIME_FORMAT=\"+%Y-%m-%d %H:%M:%S\"\nSCRIPT_LOG_LEVEL_INFO='INFO'\nSCRIPT_LOG_PATTERN=\"${SCRIPT_LOG_NAME} $(date \"${SCRIPT_LOG_DATETIME_FORMAT}\") $1 : $2\"\n\nlog_general() {\n  ...\n}\n\nlog_info() {\n  log_general \"$SCRIPT_LOG_LEVEL_INFO\" \"$1\"\n}\n\nAnd I want to pass variables $SCRIPT_LOG_LEVEL_INFO and \"$1\" as parameters to the function log_general(). And use this parameters in the $SCRIPT_LOG_PATTERN to achive output: \n[MYSCRIPT] 2023-01-01 10:10:10 INFO : Something logged\nI tried something like:\nlog_general() {\n  echo -e \"$SCRIPT_LOG_PATTERN\" \"$1\" \"$2\"\n}\n\nOr\nSCRIPT_LOG_LEVEL=''\nSCRIPT_LOG_PATTERN=\"${SCRIPT_LOG_NAME} $(date \"${SCRIPT_LOG_DATETIME_FORMAT}\") ${SCRIPT_LOG_LEVEL} : \"\n\nlog_general() {\n  SCRIPT_LOG_LEVEL=$SCRIPT_LOG_LEVEL_INFO\n  echo -e \"${SCRIPT_LOG_PATTERN}${1}\"\n}\n\nlog_info() {\n  log_general \"$1\"\n}\n\nBut I could not achieve the desired result. Can you help me, please?\n",
"AnswerId": "76389989",
"AnswerBody": "If you'd like to use ${SCRIPT_LOG_PATTERN} as a global variable and later on substitute the ${1} and ${2} you would have to escape the $ sign and then evaluate the string later on in log_general.\nThis would look something like this:\n#!/bin/bash\n\nset -e +x\n\nSCRIPT_LOG_NAME='[MYSCRIPT]'\nSCRIPT_LOG_DATETIME_FORMAT=\"+%Y-%m-%d %H:%M:%S\"\nSCRIPT_LOG_LEVEL_INFO='INFO'\nSCRIPT_LOG_PATTERN=\"${SCRIPT_LOG_NAME} $(date \"${SCRIPT_LOG_DATETIME_FORMAT}\") \\$1 : \\$2\"\n\nlog_general() {\n        eval echo \"${SCRIPT_LOG_PATTERN}\"\n}\n\nlog_info() {\n        log_general \"${SCRIPT_LOG_LEVEL_INFO}\" \"${1}\"\n}\n\nUsage:\n$ source logging_test.sh\n$ log_info \"my custom message\"\n[MYSCRIPT] 2023-06-02 14:03:27 INFO : my custom message\n\n\nI'd also recommend escaping the date command since otherwise the date will be parsed once, here is what I mean:\n$ log_info \"asdads\"; sleep 5; log_info \"asdsad\"\n[MYSCRIPT] 2023-06-02 14:06:28 INFO : asdads\n[MYSCRIPT] 2023-06-02 14:06:28 INFO : asdsad\n\nAs you can see the time does not change even with 5 seconds of sleep.\nTo fix this escape the date as well like this:\nSCRIPT_LOG_PATTERN=\"${SCRIPT_LOG_NAME} \\$(date '${SCRIPT_LOG_DATETIME_FORMAT}') \\$1 : \\$2\"\n\nOutput now:\n$ log_info \"asdads\"; sleep 5; log_info \"asdsad\"\n[MYSCRIPT] 2023-06-02 14:09:19 INFO : asdads\n[MYSCRIPT] 2023-06-02 14:09:25 INFO : asdsad\n\n"
},
{
"QuestionId": "76388237",
"QuestionTitle": "Is there an equivalent of Vue's `v-show` in Angular so that the component is hidden, but still in DOM?",
"QuestionBody": "There are some situations where it's better to keep a hidden component in DOM. In Vue there the v-show in addition to the v-if. But in Angular I didn't find an equivalent? So the best solution is to use s.th. like [ngStyle]=\"{ 'display': showMe ? 'block' : 'none' }\"?\nEDIT: I also could set the hidden attribute, which should have a very similar effect, e.g. [hidden]=\"!showMe\".\nIs there actually a reason why Vue.js did include v-show instead of simply using :hidden?\n",
"AnswerId": "76388580",
"AnswerBody": "v-show is simply sugar syntax for adding style=\"display: none\". While I'm not aware of anything like that built into angular, it's trivial to build your own directive that will achieve the same result (code not tested):\n@Directive({\n  selector: 'appHidden',\n})\nclass HiddenDirective {\n @Input('appHidden')\n isHidden: boolean = false;\n\n @HostBinding('style.display')\n get displayStyle() {\n   return this.isHidden ? 'none' : undefined;\n }\n}\n\nUsage:\n<div [appHidden]=\"shouldBeHidden\"></div>\n\n"
},
{
"QuestionId": "76390978",
"QuestionTitle": "Spring Boot custom constraint validator with multiple values",
"QuestionBody": "I want to add 2 values for my custom constraint validator because I have 2 feature flags:\n @JsonProperty(value = \"name\")\n    @BlockedWithoutEnabledFeatureFlag(feature = FeatureFlag.AAA, values = {\"aaa\", \"bbb\"})\n    @BlockedWithoutEnabledFeatureFlag(feature = FeatureFlag.BBB, values = {\"ccc\", \"ddd\"})\n    private String parameter;\n\nwhere:\n@Constraint(validatedBy = {BlockedWithoutEnabledFeatureFlagValidator.class})\n@Target({FIELD, PARAMETER})\n@Retention(RetentionPolicy.RUNTIME)\n@ReportAsSingleViolation\npublic @interface BlockedWithoutEnabledFeatureFlag {\n\n    String message() default \"{validation.constraints.BlockedWithoutEnabledFeatureFlag.message}\";\n\n    Class<?>[] groups() default {};\n\n    Class<? extends Payload>[] payload() default {};\n\n    FeatureFlag feature();\n\n    String[] values() default {};\n}\n\nand implementation:\npublic class BlockedWithoutEnabledFeatureFlagValidator implements ConstraintValidator<BlockedWithoutEnabledFeatureFlag, Object> {\n    private final FeatureFlagService featureFlagService;\n\n    private List<String> blocked;\n    private FeatureFlag feature;\n\n    @Override\n    public void initialize(BlockedWithoutEnabledFeatureFlag constraintAnnotation) {\n        blocked = Arrays.asList(constraintAnnotation.values());\n        feature = constraintAnnotation.feature();\n    }\n\n@Override\n    public boolean isValid(Object value, ConstraintValidatorContext context) {\n\n\nBut now I get compilation error \"Duplicate annotation\". How to do that?\n",
"AnswerId": "76391418",
"AnswerBody": "You should make your BlockedWithoutEnabledFeatureFlag repeatable. To do this:\n\nCreate a new \"top-level\" annotation:\n\n@Target({ ElementType.FIELD })\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface RepeatableBlockedWithoutEnabledFeatureFlag {\n    BlockedWithoutEnabledFeatureFlag[] value();\n}\n\n\nAdd @Repeatable to your BlockedWithoutEnabledFeatureFlag annotation\n\n...\n@Repeatable(RepeatableBlockedWithoutEnabledFeatureFlag.class)\npublic @interface BlockedWithoutEnabledFeatureFlag {\n...\n\nThen you should be able to add more than one @BlockedWithoutEnabledFeatureFlag annotation.\n"
},
{
"QuestionId": "76388242",
"QuestionTitle": "Typescript/Angular: Wait for sequentially delayed async tasks to be completed",
"QuestionBody": "Even though there's multiple similar questions here on StackOverflow, I haven't been able to solve this, please bear with me:\nIn an Angular 16 application I have a functionality to batch rename hundreds of users. Thus, I have an array of RenameUser objects, each one having an async method .executeRename() performing an API call to rename a user. To not overwhelm the API, these should be triggered with a 200ms delay between them. Once all users have been renamed, I would like to run other tasks.\nSummarized: Trigger a bunch of async operations with a 200ms delay between them, do something when all are complete.\nI have managed to delay the calls, and I do not care how long a single call takes to finish, but I need to know when all tasks have finished.\nThis is the solution I came up with, I would run the triggerRenameProcess() method to start the process.\nasync triggerRenameProcess(users: RenameUser[]) {\n  try {\n    await this.renameUsersWithDelay(users, 200);\n    console.log('All users renamed');\n  } catch (error) {\n    console.error('Exception while renaming users: ', error);\n  }\n}\n\nrenameUsersWithDelay(users: RenameUser[], delay: number): Promise<void> {\n  return new Promise<void>((resolve) => {\n    let currentIndex = 0;\n    const executeNext = () => {\n      if (currentIndex < users.length) {\n        const user = users[currentIndex];\n        user.executeRename().then(() => {\n          currentIndex++;\n          setTimeout(executeNext, delay);\n        });\n      } else {\n        resolve();\n      }\n    };\n  });\n}\n\nI kind of understand what the problem is, the renameUsersWithDelay() returns a Promise that can be awaited, but that will happen once all requests have been triggered - it is not waiting for the longest running one to complete. I can make it wait for every single one and run them sequentially, but that's not what it is supposed to do...\nI did some research and found this question or this one, but they seem not to address the same issue - and frankly, I am not too familiar with JavaScript - I feel more at home in .NET where I just would use something like .WaitAll() (and probably use a more sophisticated throttling pattern), but I'm not sure how to achieve the same thing in TypeScript.\n",
"AnswerId": "76388621",
"AnswerBody": "Whenever you've got an asynchronous data flow manipulation that isn't trivial, you can assume that observables will help you a lot.\nHere's the feature you're trying to achieve with observables:\nfunction renameUsersWithDelay(\n  users: RenameUser[],\n  delayMs: number = 200\n): Observable<any> {\n  const usersWithDelay = users.map((user, i) =>\n    of(user).pipe(delay(delayMs * i), switchMap(executeRename))\n  );\n\n  return forkJoin(usersWithDelay);\n}\n\nHere's how it works:\n\nwe loop on the users array with a map to create a new array out of it\nfor each user, we put the user into an observable using of\nwe then apply a delay relative to the index we're at so they're all shifted\nonce the delay resolves, we use a switchMap to make make the http call, which will effectively subscribe to the observable returned by executeRename\nbecause observables are cold by nature, nothing that we just created here is triggered yet. Which is fantastic because it lets you build up all your instructions without triggering them straight away\nfinally, we use forkJoin to subscribe to each observables that we just created\n\nI've created a live demo with mocked data so you can see it behaves as expected.\nI wanted to give you exactly what you asked for, which is what I did so far. But my advice would be to go for a different approach where you still don't DDOS your backend while being more efficient, by having a limited pool of running calls. For example you could say, up until there's nothing left to proceed, I want to have 3 ongoing rename calls and as soon as 1 finishes in that current pool, another one is taken from the queue and ran straight away. This is IMO more efficient.\nHere's how you could implemented this:\nconst renameUsersWithDelay = (users: RenameUser[]): Observable<any> =>\n  from(users.map((user) => of(user).pipe(switchMap(executeRename)))).pipe(\n    mergeAll(3)\n  );\n\nLive demo\n"
},
{
"QuestionId": "76389697",
"QuestionTitle": "clean data in r from image",
"QuestionBody": "I am trying to scan a text from an Ocr and clean it, I got a character that is divided to few lines, however I would like to have the text in similar to the way it is in the image\nthe code :\nheraclitus<-\"greek.png\"\nlibrary(tidyverse)\nlibrary(tesseract)\nlibrary(magick)\n\nimage_greek<-image_read(heraclitus)\n\nimage_greek<-image_greek %>% image_scale(\"600\") %>% \n  image_crop(\"600x400+220+150\") %>% \n  image_convert(type = 'Grayscale') %>% \n  image_contrast(sharpen = 1) %>% \n  image_write(format=\"jpg\")\n\nheraclitus_sentences<-magick::image_read(image_greek)%>% \n  ocr() %>% str_split(\"\\n\")\n\nAs you can see from the output, I have white spaces and sentences that are divided to two lines. I would like to have it in a vector or a list, that each element will be a sentence\n\n\n",
"AnswerId": "76390000",
"AnswerBody": "You need to split on \\n\\n (not \\n) then replace the middle \\n values:\nmagick::image_read(image_greek) %>% \n  ocr() %>% \n  str_split(\"\\n\\n\") %>%\n  unlist() %>%\n  str_replace_all(\"\\n\", \" \")\n\nOutput:\n[1] \"© Much learning does not teach understanding.\"                                                       \n[2] \"© The road up and the road down is one and the same.\"                                                \n[3] \"© Our envy always lasts longer than the happiness of those we envy.\"                                 \n[4] \"© No man ever steps in the same river twice, for it's not the same river and he's not the same man. \"\n\n"
},
{
"QuestionId": "76388633",
"QuestionTitle": "Join values of two string lists to new string list and add characters in VB.NET using LINQ",
"QuestionBody": "In VB.NET i would like to create a list of string from the values of two given lists of string.\nE.g.\n        Dim varNames As New List(Of String)({\"var1\", \"var2\"})\n        Dim varValues As New List(Of String)({\"value1\", \"value2\"})\n        Dim finalList As List(Of String) = .....\n        'Output should be:\n        'finalList(0) -> \"[var1] = 'value1'\"\n        'finalList(1) -> \"[var2] = 'value2'\"\n\nI would like to do this in on line of code using LINQ. (I know how to do this using for loops)\n",
"AnswerId": "76388649",
"AnswerBody": "Use Zip to \"concat\" two lists via index:\nDim finalList As List(Of String) = varNames.\n    Zip(varValues, Function(s1, s2) $\"[{s1}] = '{s2}'\").\n    ToList()\n\n"
},
{
"QuestionId": "76388555",
"QuestionTitle": "Why is my Python code not inserting data into PostgreSQL database from a JSON file?",
"QuestionBody": "I'm trying desing and implement database model in python from a json file but my python code seems like is not inserting data into table and i'm not sure where is the problem in my code\nimport json\nimport psycopg2\n\n\nclass Policy:\n    def __init__(self, type, name, rule_exists):\n        self.type = type\n        self.name = name\n        self.rule_exists = rule_exists\n\n\n# load json data from the file\nwith open(\"demo_data.json\", 'r') as file:\n    policy_data = json.load(file)\n    first_level = policy_data[\"uniconfig-topology:configuration\"]\n    second_level = first_level[\"Cisco-IOS-XR-infra-policymgr-cfg:policy-manager\"]\n    third_level = second_level[\"policy-maps\"]\n    forth_level = third_level[\"policy-map\"]\n\ntable_of_policies = []\nfor item in forth_level:\n    if \"policy-map\" in item:\n    # forth_level = item\n        type = forth_level['type']\n        name = forth_level['name']\n        rule_exists = 'policy-map-rule' in forth_level\n        policy_map = Policy(type, name, rule_exists)\n        table_of_policies.append(policy_map)\n    #print(forth_level)\n\n\nconn = psycopg2.connect(\n    host=\"localhost\",\n    database=\"postgres\",\n    user=\"postgres\",\n    password=\"postgres\",\n    port=\"5432\"\n)\n\n\ncursor = conn.cursor()\ncursor.execute(\"DROP TABLE IF EXISTS policy_map\")\ncursor.execute('''create table policy_map\n( type VARCHAR(255),\n  name VARCHAR(255),\n  rule_exists BOOLEAN)\n''')\n\nfor policy_map in table_of_policies:\n    insert_data = \"INSERT INTO policy_map (type, name, rule_exists) VALUES (%s, %s, %s)\"\n    cursor.execute(insert_data, (policy_map.type,\n                   policy_map.name, policy_map.rule_exists))\n\n\nconn.commit()\n\n\nI tried several different approach for dict in json file to be sure im on right level of dict but it never append any data to my list. Would like to know whats wrong with my code\n",
"AnswerId": "76388668",
"AnswerBody": "type is a built-in python function that returns the type of a variable. Overwriting it might cause your code to work unexpectedly.\nYou can check the documentation , avoid using build-in function names for variables.\nRegarding table column naming you can refer to this question.\nApart from these you're looping over forth_level but not using the item:\ntype = forth_level['type']\nname = forth_level['name']\n\nI would expect this code to continue like:\n    if \"policy-map\" in item:\n    type = item['type']\n    name = item['name']\n    rule_exists = 'policy-map-rule' in item\n    policy_map = Policy(type, name, rule_exists)\n    table_of_policies.append(policy_map)\n\nBut without seeing the JSON I cannot tell for sure.\n"
},
{
"QuestionId": "76391208",
"QuestionTitle": "Undefined variable $patients",
"QuestionBody": "this is my [tag:doctor.write_medical.blade.php]. i try to get patient name from patient database that i created in migration file and fill in some form so that i can save the medical records with patient_id as foreign key. but when i try to open the page, it shows Undefined variable $patients. i dont know why it become like this it shows error at\n @foreach($patients as $patient)\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  @include('doctor.css')\n</head>\n<body>\n\n<header>\n    <div class=\"topbar\">\n      <div class=\"container\">\n        <div class=\"row\">\n          <div class=\"col-sm-8 text-sm\">\n            <div class=\"site-info\">\n              <a href=\"#\"><span class=\"mai-call text-primary\"></span> 0105739057</a>\n              <span class=\"divider\">|</span>\n              <a href=\"#\"><span class=\"mai-mail text-primary\"></span> afiqaqil@gmail.com</a>\n            </div>\n          </div>\n          <div class=\"col-sm-4 text-right text-sm\">\n            <div class=\"social-mini-button\">\n              <a href=\"#\"><span class=\"mai-logo-facebook-f\"></span></a>\n              <a href=\"#\"><span class=\"mai-logo-twitter\"></span></a>\n              <a href=\"#\"><span class=\"mai-logo-dribbble\"></span></a>\n              <a href=\"#\"><span class=\"mai-logo-instagram\"></span></a>\n            </div>\n          </div>\n        </div> <!-- .row -->\n      </div> <!-- .container -->\n    </div> <!-- .topbar -->\n\n    <nav class=\"navbar navbar-expand-lg navbar-light shadow-sm\">\n      <div class=\"container\">\n        <a class=\"navbar-brand\" href=\"#\"><span class=\"text-primary\">MyHealthCare</span>System</a>\n\n\n        <div class=\"collapse navbar-collapse\" id=\"navbarSupport\">\n          <ul class=\"navbar-nav ml-auto\">\n            <li class=\"nav-item\">\n              <a class=\"nav-link\" href=\"#\">Request Access</a>\n            </li>\n            <li class=\"nav-item active\">\n              <a class=\"nav-link\" href=\"index.html\">Home</a>\n            </li>\n            <li class=\"nav-item\">\n              <a class=\"nav-link\" href=\"about.html\">About Us</a>\n            </li>\n            <li class=\"nav-item\">\n              <a class=\"nav-link\" href=\"contact.html\">Contact</a>\n            </li>\n\n            @if(Route::has('login'))\n            @auth\n\n            <x-app-layout>\n                </x-app-layout>\n\n            @else\n            <li class=\"nav-item\">\n              <a class=\"btn btn-primary ml-lg-3\" href=\"{{route('login')}}\">Login</a>\n            </li>\n            <li class=\"nav-item\">\n              <a class=\"btn btn-primary ml-lg-3\" href=\"{{route('register')}}\">Register</a>\n            </li>\n            @endauth\n            @endif\n          </ul>\n        </div> <!-- .navbar-collapse -->\n      </div> <!-- .container -->\n    </nav>\n  </header>\n\n<div class=\"container-fluid page-body-wrapper\">\n  <div class=\"row\">\n    <div class=\"col-md-2\">\n      <div class=\"sidebar-sticky\">\n        <ul class=\"nav flex-column\">\n          <li class=\"nav-item active\">\n            <a class=\"nav-link\" href=\"{{route('doctor.home')}}\">\n              <i class=\"mdi mdi-account-search\"></i>\n              Add Patient\n            </a>\n          </li>\n          <li class=\"nav-item\">\n            <a class=\"nav-link\" href=\"{{ route('write_medical') }}\">\n              <i class=\"mdi mdi-download\"></i>\n              Write Medical Description\n            </a>\n          </li>\n          <li class=\"nav-item menu-items\">\n            <a class=\"nav-link\" data-toggle=\"collapse\" href=\"#doctors\" aria-expanded=\"false\" aria-controls=\"doctors\">\n              <span class=\"menu-icon\">\n                <i class=\"mdi mdi-doctor\"></i>\n              </span>\n              <span class=\"menu-title\">View Patients</span>\n              <i class=\"menu-arrow\"></i>\n            </a>\n            <div class=\"collapse\" id=\"doctors\">\n              <ul class=\"nav flex-column sub-menu\">\n              <li class=\"nav-item\">\n                <a class=\"nav-link\" href=\"{{ route('patient_1') }}\">Patient 1</a>\n                </li>\n\n                <li class=\"nav-item\">\n                  <a class=\"nav-link\" href=\"{{ route('add_doctor_view') }}\">Patient 2</a>\n                </li>\n              </ul>\n            </div>\n          </li>\n          <li class=\"nav-item\">\n            <a class=\"nav-link\" href=\"#\">\n              <i class=\"mdi mdi-chat\"></i>\n              Chat with Patients\n            </a>\n          </li>\n        </ul>\n      </div>\n    </div>\n\n    <div class=\"col-md-10\">\n      <div class=\"content-wrapper\">\n        <div class=\"container-fluid\">\n          <div class=\"row\">\n            <div class=\"col-md-12\">\n              <div class=\"form-container\">\n              @if (session('success'))\n        <div class=\"alert alert-success\">\n            {{ session('success') }}\n        </div>\n    @endif\n                  <form action=\"{{ route('save_medical') }}\" method=\"POST\">\n                  @csrf\n\n                  <div class=\"form-group\">\n                      <label for=\"patient\">Patient</label>\n                      <select class=\"form-control\" id=\"patients\" name=\"patients\" required>\n                          @foreach($patients as $patient)\n                              <option value=\"{{ $patient->patient_id }}\">{{ $patient->patient_name }}</option>\n                          @endforeach\n                      </select>\n                  </div>\n\n                  <div class=\"form-group\">\n                    <label for=\"date\">Date</label>\n                    <input type=\"text\" class=\"form-control\" id=\"date\" value=\"{{ date('Y-m-d') }}\" readonly>\n                  </div>\n                  <div class=\"form-group\">\n                    <label for=\"symptoms\">Symptoms</label>\n                    <textarea class=\"form-control\" id=\"symptoms\" name=\"symptoms\" rows=\"4\" required></textarea>\n                  </div>\n                  <div class=\"form-group\">\n                    <label for=\"treatment\">Simplified Treatment</label>\n                    <textarea class=\"form-control\" id=\"treatment\" name=\"treatment\" rows=\"4\" required></textarea>\n                  </div>\n                  <div class=\"form-group\">\n                    <label for=\"medication\">Medication</label>\n                    <textarea class=\"form-control\" id=\"medication\" name=\"medication\" rows=\"4\" required></textarea>\n                  </div>\n                  <button type=\"submit\" class=\"btn btn-primary\">Submit</button>\n                </form>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  </div>\n</div>\n\n<footer class=\"page-footer\">\n    <div class=\"container\">\n      <div class=\"row px-md-3\">\n        <div class=\"col-sm-6 col-lg-3 py-3\">\n          <h5>Company</h5>\n          <ul class=\"footer-menu\">\n            <li><a href=\"#\">About Us</a></li>\n            <li><a href=\"#\">Career</a></li>\n            <li><a href=\"#\">Editorial Team</a></li>\n            <li><a href=\"#\">Protection</a></li>\n          </ul>\n        </div>\n        <div class=\"col-sm-6 col-lg-3 py-3\">\n          <h5>More</h5>\n          <ul class=\"footer-menu\">\n            <li><a href=\"#\">Terms & Condition</a></li>\n            <li><a href=\"#\">Privacy</a></li>\n            <li><a href=\"#\">Advertise</a></li>\n            <li><a href=\"#\">Join as Doctors</a></li>\n          </ul>\n        </div>\n        <div class=\"col-sm-6 col-lg-3 py-3\">\n          <h5>Our partner</h5>\n          <ul class=\"footer-menu\">\n            <li><a href=\"#\">One-Fitness</a></li>\n            <li><a href=\"#\">One-Drugs</a></li>\n            <li><a href=\"#\">One-Live</a></li>\n          </ul>\n        </div>\n        <div class=\"col-sm-6 col-lg-3 py-3\">\n          <h5>Contact</h5>\n          <p class=\"footer-link mt-2\">351 Willow Street Franklin, MA 02038</p>\n          <a href=\"#\" class=\"footer-link\">701-573-7582</a>\n          <a href=\"#\" class=\"footer-link\">healthcare@temporary.net</a>\n\n          <h5 class=\"mt-3\">Social Media</h5>\n          <div class=\"footer-sosmed mt-3\">\n            <a href=\"#\" target=\"_blank\"><span class=\"mai-logo-facebook-f\"></span></a>\n            <a href=\"#\" target=\"_blank\"><span class=\"mai-logo-twitter\"></span></a>\n            <a href=\"#\" target=\"_blank\"><span class=\"mai-logo-google-plus-g\"></span></a>\n            <a href=\"#\" target=\"_blank\"><span class=\"mai-logo-instagram\"></span></a>\n            <a href=\"#\" target=\"_blank\"><span class=\"mai-logo-linkedin\"></span></a>\n          </div>\n        </div>\n      </div>\n\n      <hr>\n\n      <p id=\"copyright\">Copyright &copy; 2020 <a href=\"https://macodeid.com/\" target=\"_blank\">MACode ID</a>. All right reserved</p>\n    </div>\n  </footer>\n\n@include('doctor.script')\n  \n</body>\n</html>\n\n\nthis is my route web.php\n<?php\n\nuse Illuminate\\Support\\Facades\\Route;\nuse App\\Http\\Controllers\\HomeController;\nuse App\\Http\\Controllers\\AdminController;\nuse App\\Http\\Controllers\\RegisterController;\nuse App\\Http\\Controllers\\Admin\\DataRequestorController;\nuse App\\Http\\Controllers\\DoctorController;\nuse App\\Http\\Controllers\\PatientController;\nuse App\\Http\\Controllers\\AccessRequestController;\nuse App\\Http\\Controllers\\WriteMedicalController;\n\n\n\n\nRoute::get('access-request/create', [AccessRequestController::class, 'create'])->name('access-request.create');\nRoute::post('access-request', [AccessRequestController::class, 'store'])->name('access-request.store');\n\nRoute::get('/get-doctors-count', [DoctorController::class, 'getDoctorsCount'])->name('get_doctors_count');\nRoute::post('/add-patient', [PatientController::class, 'addPatient'])->name('add.patient');\n\nRoute::get('/write-medical', [WriteMedicalController::class, 'writeMedical'])->name('write_medical');\nRoute::post('/save-medical', [WriteMedicalController::class, 'saveMedical'])->name('save_medical');\n\nRoute::get('/admin/data-requestors/{requestor}/accept', [DataRequestorController::class, 'accept'])->name('admin.data-requestors.accept');\nRoute::get('/admin/data-requestors/{requestor}/decline', [DataRequestorController::class, 'decline'])->name('admin.data-requestors.decline');\nRoute::get('/admin/data-requestors/{requestor}', [DataRequestorController::class, 'show'])->name('admin.data-requestors.show');\nRoute::get('/admin/data-requestors', [DataRequestorController::class, 'index'])->name('admin.data-requestors.index');\n\nRoute::get('/', [HomeController::class, 'index']);\nRoute::get('/home', [HomeController::class, 'redirect'])->name('home.redirect');\nRoute::get('/doctor/home', [HomeController::class, 'doctorHome'])->name('doctor.home');\nRoute::get('/user/home', [HomeController::class, 'userHome'])->name('user.home');\n\nRoute::middleware([\n    'auth:sanctum',\n    config('jetstream.auth_session'),\n    'verified'\n])->group(function () {\n    Route::get('/dashboard', function () {\n        return view('dashboard');\n    })->name('dashboard');\n});\n\nRoute::get('/write-medical', function () {\n    return view('doctor.write_medical');\n})->name('write_medical');\n\nRoute::get('/patient_1', function () {\n    return view('doctor.patient_1');\n})->name('patient_1');\n\nRoute::get('/add_doctor_view', [AdminController::class, 'addview'])->name('add_doctor_view');\nRoute::post('/register_doctor', [AdminController::class, 'registerDoctor'])->name('register.doctor');\nRoute::get('/viewDoctors', [AdminController::class, 'viewDoctors'])->name('viewDoctors');\nRoute::delete('/delete_doctor/{doctor}', [AdminController::class, 'deleteDoctor'])->name('admin.doctors.delete');\n\nand this is my writemedicalcontroller\n<?php\n\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\nuse App\\MedicalDescription;\nuse App\\Models\\Patient;\nuse App\\Models\\Doctor;\n\nclass WriteMedicalController extends Controller\n{\n    public function writeMedical()\n    {\n        $patients = Patient::all();\n\n        return view('doctor.write_medical',  compact('patients'));\n    }\n\n    public function saveMedical(Request $request)\n    {\n        $validatedData = $request->validate([\n            'patient' => 'required|exists:patients,patient_id',\n            'symptoms' => 'required',\n            'treatment' => 'required',\n            'medication' => 'required',\n        ]);        \n\n        $medicalDescription = new MedicalDescription();\n        $medicalDescription->patient_id = $validatedData['patient'];\n        $medicalDescription->date = date('Y-m-d');\n        $medicalDescription->symptoms = $validatedData['symptoms'];\n        $medicalDescription->treatment = $validatedData['treatment'];\n        $medicalDescription->medication = $validatedData['medication'];\n        $medicalDescription->save();\n\n        return redirect()->back()->with('success', 'Medical description saved successfully.');\n    }\n}\n\nthis is my medicaldescription model\n",
"AnswerId": "76391517",
"AnswerBody": "Your route web.php file has two definitions of the route /write-medical, so Laravel is using the last definition:\nRoute::get('/write-medical', function () {\n    return view('doctor.write_medical');\n})->name('write_medical');\n\nRemove that and I think it will work as you expect because your first definition is calling the controller WriteMedicalController::writeMedical as you expect.\n"
},
{
"QuestionId": "76388273",
"QuestionTitle": "Repeating and looping API calls in Karate framework",
"QuestionBody": "I am new to Karate framework and have written the following working code to run few sample API tests.\nFeature: Sample API Tests\n\n  Background:\n    * def request_headers = {apikey: \"#(apikey)\", Content-Type: 'application/json'}\n    * configure headers = request_headers\n\n  Scenario: Create Customer\n\n    * def requestPayload = read('classpath:payload/customerdetails.json')\n    * def RandomDataGenerator = Java.type('utils.RandomDataGenerator')\n\n    Given url testurl+'/customers'\n    And request requestPayload\n    * requestPayload.firstName = RandomDataGenerator.generateRandomFirstName()\n    * requestPayload.lastName = RandomDataGenerator.generateRandomLastName()\n    * requestPayload.mobileNumber = RandomDataGenerator.generateRandomMobileNumber()\n    * requestPayload.emailAddress = RandomDataGenerator.generateRandomEmailAddress()\n    When method post\n    Then status 200\n\n    And def customerId = response.id\n    \n    # Create An Account for the customer\n    * def createAccountPayload = read('classpath:payload/accountdetails.json')\n\n    Given url testurl+'/accounts/createCreditAccount'\n    And request createAccountPayload\n    * createAccountPayload.customerId = customerId\n    When method post\n    Then status 200\n\n    And def accountId = response.id\n\n  # Perform a Transaction\n    * def debitTransactionPayload = read('classpath:payload/transaction.json')\n\n    Given url testurl+'/accounts/createDebitTransaction'\n    And request debitTransactionPayload\n    * debitTransactionPayload.accountId = accountId\n    When method post\n    Then status 200\n    \n\nNow I want to run a test where I would:\n\nCreate 100 customers (and in turn 100 accounts).\nDo 500 transactions (5 transactions each for a given customer).\n\nHow do I achieve this?\nI tried using repeat and looping options, but I believe I am missing something basic. Can someone please help ?\n",
"AnswerId": "76388683",
"AnswerBody": "Here is a Karate test that uses a JS function as a data-source to create 10 JSON payloads. You should be easily able to modify this to do what you want:\nFeature:\n\n  @setup\n  Scenario:\n    * def generator = \n    \"\"\"\n    function(i){ \n        if (i == 10) return null; \n        return { name: `cat${i}`, age: i };\n    }\n    \"\"\"\n\n  Scenario Outline:\n    * print __row\n\n    Examples:\n        | karate.setup().generator |\n\nHow this works is explained here: https://github.com/karatelabs/karate#json-function-data-source\nAlso refer: https://stackoverflow.com/a/75394445/143475\n"
},
{
"QuestionId": "76389982",
"QuestionTitle": "POST request to /api/notes/addnote endpoint returning 404 Not Found error",
"QuestionBody": "I'm encountering an issue when making a POST request to the /api/notes/addnote endpoint. The server responds with a 404 Not Found error. I have checked the server-side code and verified that the endpoint is correctly defined. Here are the details of my setup:\nServer-side:\nFramework/Language: Express.js\nCode snippet handling the /api/notes/addnote endpoint:\nrouter.post('/addnote', fetchUser, [\n    body('tittle', 'Tittle cannot be blank').exists(),\n    body('description', 'Description must be atleast 5 characters').isLength({ min: 5 })\n], async (req, res) => {\n    // If there are any errors in the validation of an express request, return status 400 and the errors\n    const errors = validationResult(req);\n    if (!errors.isEmpty()) {\n        return res.status(400).json({ errors: errors.array() });\n    } \n\n    // Creating a new note in the database and saving it\n    const { tittle, description, tag } = req.body;\n    const note = await Notes.create({\n        tittle,\n        description,\n        tag,\n        user: req.id\n    });\n\n    // Sending the note as a response\n    res.json(note);\n});\n\nmodule.exports = router;\n\nmain.js file code:\nconst connectToMongo = require('./Db');\nconst express = require('express');\n\nconnectToMongo();\n\nconst app = express()\nconst port = 3000\n\napp.use(express.json());\n\napp.use('/api/notes/addnote', require('./Routes/notes'));\n\napp.listen(port, () => {\n  console.log(`Example app listening on port ${port}`)\n})\n\nClient-side:\nCode snippet for making the POST request:\n\nThe server is running and accessible at localhost:3000\nI have successfully tested other endpoints on the same server, and they are working correctly.\nI have confirmed the URL for the POST request: http://localhost:3000/api/notes/addnote.\nI have already attempted the following troubleshooting steps:\n\nDouble-checked the server-side code and endpoint spelling.\n\nTested the POST request using different HTTP clients (e.g., Postman) with the same result.\n\nReviewed the server logs for any error messages related to the /api/notes/addnote endpoint.\n\n\nDespite these efforts, I'm still receiving a 404 Not Found error. Any guidance or suggestions on how to resolve this issue would be greatly appreciated. Thank you!\n",
"AnswerId": "76390015",
"AnswerBody": "The URL while setting the Router to the appliction is the same as you have mentioned.\napp.use('/api/notes', require('./Routes/notes'));\n\nThe problem here is:\napp.use('/api/notes/addnote', require('./Routes/notes'));\nrouter.post('/addnote');\n\nNow the route works for /api/notes/addnote/addnote.\n"
},
{
"QuestionId": "76389927",
"QuestionTitle": "Android RequestMultiplePermissions(): one of the permission's status is never true, even after allowing it",
"QuestionBody": "I want to ask for the SEND_SMS and READ_SMS runtime permissions, if they are not given. This is my code:\nprivate ActivityResultLauncher<String[]> mRequestPermissionsLauncher;\nString[] PERMISSIONS = {\n    Manifest.permission.SEND_SMS,\n    Manifest.permission.READ_SMS\n};\n@Override\nprotected void onCreate(Bundle savedInstanceState) {\n\n    mRequestPermissionsLauncher = registerForActivityResult(new ActivityResultContracts.RequestMultiplePermissions(), result -> {\n         Log.d(\"DEBUG\",result.toString());\n    });\n\n    if (!hasPermissions(this, PERMISSIONS)) {\n         if(shouldShowRequestPermissionRationale(Manifest.permission.SEND_SMS) || shouldShowRequestPermissionRationale(Manifest.permission.READ_SMS)){\n              new AlertDialog.Builder(this)\n                   .setTitle(\"Permission Needed\")\n                   .setMessage(\"Please press OK to allow the permissions\")\n                   .setCancelable(false)\n                   .setPositiveButton(\"OK\", (dialog, which) -> mRequestPermissionsLauncher.launch(PERMISSIONS)).create().show();\n         }\n         else{\n             mRequestPermissionsLauncher.launch(PERMISSIONS);\n         }\n    }\n}\npublic static boolean hasPermissions(Context context, String... permissions) {\n    if (context != null && permissions != null) {\n        for (String permission : permissions) {\n            if (ActivityCompat.checkSelfPermission(context, permission) != PackageManager.PERMISSION_GRANTED) {\n                return false;\n            }\n         }\n    }\n    return true;\n}\n\n\nAfter I allow the permissions and debug the result, it keeps showing:\n{android.permission.SEND_SMS=true, android.permission.READ_SMS=false}\n\nWhy is my READ_SMS permission false?\nEDIT: Never mind, the issue is resolved. I forgot to declare the READ_SMS permission in the manifest file. Silly me :p\n",
"AnswerId": "76390042",
"AnswerBody": "You can't and that's by design - to prevent abuse.\nYou're better of following the official guidelines.\nThe only way to request permissions again, is to navigate the user to app info, where the user has to manually allow it:\nfun launchPermissionSettings(context: Context) {\n    Intent().apply {\n        action = Settings.ACTION_APPLICATION_DETAILS_SETTINGS\n        data = Uri.fromParts(\"package\", context.packageName, null)\n\n        addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)\n        addFlags(Intent.FLAG_ACTIVITY_NO_HISTORY)\n        addFlags(Intent.FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS)\n\n        context.startActivity(this)\n    }\n}\n\nstatic void launchPermissionSettings(Context context) {\n    Intent intent = new Intent();\n    intent.setAction(Settings.ACTION_APPLICATION_DETAILS_SETTINGS);\n    intent.setData(Uri.fromParts(\"package\", context.getPackageName(), null));\n\n    intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);\n    intent.addFlags(Intent.FLAG_ACTIVITY_NO_HISTORY);\n    intent.addFlags(Intent.FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS);\n\n    context.startActivity(intent);\n}\n\nYou're also using a deprecated way of requesting permissions. Consider using ActivityResultContracts.RequestMultiplePermissions():\nclass MyFragment: Fragment() {\n    private lateinit var mRequestPermissionsLauncher: ActivityResultLauncher<Array<String>>\n\n    override fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n\n        mRequestPermissionsLauncher = registerForActivityResult(ActivityResultContracts.RequestMultiplePermissions()) { result: Map<String, Boolean> ->\n            //Handle result here\n        }\n\n        //Request permissions like this:\n        mRequestPermissionsLauncher.launch(arrayOf(\n            Manifest.permission.SEND_SMS,\n            Manifest.permission.READ_SMS,\n        ))\n    }\n}\n\nclass MyFragment extends Fragment {\n    private ActivityResultLauncher<String[]> mRequestPermissionsLauncher;\n\n    @Override\n    public void onCreate(@Nullable Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n\n        mRequestPermissionsLauncher = registerForActivityResult(new ActivityResultContracts.RequestMultiplePermissions(), result -> {\n            //Handle activity result here\n        });\n\n        //Request permissions like this:\n        String[] PERMISSIONS = {\n            Manifest.permission.SEND_SMS,\n            Manifest.permission.READ_SMS,\n        };\n        mRequestPermissionsLauncher.launch(PERMISSIONS);\n    }\n}\n\n"
},
{
"QuestionId": "76390997",
"QuestionTitle": "Not able to submit message to Azure service bus Topic using MassTransit",
"QuestionBody": "I am trying to submit a message to a Azure Service Bus Topic and it keeps complaining about\nMassTransit.ConfigurationException: The message type Contracts.ClassName entity name was already evaluated: Contracts/ClassName\nI have checked my registration and can't seem to figure out what is missing?\nHere is my code for submitting a message to a Topic\nvar bus = Bus.Factory.CreateUsingAzureServiceBus(cfg =>\n        {\n            cfg.Message<ClassName>(x =>\n            {\n                x.SetEntityName(\"topicName\");\n            });\n        });\n        \ntry\n   {\n       await bus.Publish(new ClassName\n       {\n            Status = status,\n            User = user,                \n            });\n            _logger.LogInformation($\"Topic Message Sent Successfully.\");\n        }\n        catch (Exception ex)\n        {\n            _logger.LogError($\"Failed to Send Message!\\n{ex.Message} to Topic\");\n        }\n\nRegistration\nservices.AddMassTransit(x =>\n{\n     x.AddConsumer<TestConsumer>();\n     x.UsingAzureServiceBus((ctx, cfg) =>\n     {\n           cfg.ClearMessageDeserializers();\n           cfg.UseRawJsonSerializer();\n\n           cfg.Host(_busConfiguration.ServiceBus.ConnectionString);\n\n           cfg.ReceiveEndpoint(_busConfiguration.ServiceBus.QueueName, ec =>\n           {\n                 ec.ConfigureConsumeTopology = false;\n                 ctx.ConfigureConsumer<TestConsumer>(ec);\n            });\n        });\n     });                    \n\n",
"AnswerId": "76391529",
"AnswerBody": "You should configure everything at once, the separate bus configuration is a really bad idea.\nservices.AddMassTransit(x =>\n{\n  x.AddConsumer<TestConsumer>();\n\n  x.UsingAzureServiceBus((ctx, cfg) =>\n  {\n    cfg.Message<ClassName>(x =>\n    {\n      x.SetEntityName(\"topicName\");\n    });\n\n    cfg.UseRawJsonSerializer(isDefault: true);\n\n    cfg.Host(_busConfiguration.ServiceBus.ConnectionString);\n\n    cfg.ReceiveEndpoint(_busConfiguration.ServiceBus.QueueName, ec =>\n    {\n          ec.ConfigureConsumeTopology = false;\n          ec.ConfigureConsumer<TestConsumer>(ctx);\n    });\n  });\n});\n\n\n"
},
{
"QuestionId": "76389933",
"QuestionTitle": "monkey patch without the need to intitalise",
"QuestionBody": "I would like to money patch a function without the requirement to initialize using pd.DataFrame.function = function\nFor example, if I have a dataframe df and I call df.unique() I do not have to run pd.DataFrame.unique = unique prior to running as this appears to be built in. Is there a way I can do the same for my own functions without the need to initialise every time?\n",
"AnswerId": "76390050",
"AnswerBody": "Patching an existing class, e.g. pd.DataFrame, so that all instances have a patched method is not trivial, IMO.\nWhat about simply subclassing pd.DataFrame?\nimport pandas as pd\n\n\nclass MyDataFrame(pd.DataFrame):\n    def my_func(self):\n        print(\"yey\")\n\ndf = MyDataFrame()\ndf.my_func()\n\n# Outputs:\n# yey\n\n"
},
{
"QuestionId": "76388645",
"QuestionTitle": "Trying to sort a selectListItem alphabetically not by ID",
"QuestionBody": "I have the below code that populates a selectListItem with information from my database.\nI am trying to sort this by name rather than by ID like how it is in the database.\nI tried adding Vendors.OrderBy(x => x.VendorName); but it didn't seem to do anything at all, not sure if I have it in the wrong place or something.\npublic IList<Data.Vendor> Vendors { get; set; }\npublic void OnGet()\n        {\n             List<SelectListItem> test = new List<SelectListItem>();\n             Vendors = _context.Vendors.ToList();\n                         foreach (var item in Vendors)\n            //foreach item In the vendors list\n            {\n                test.Add(new SelectListItem { Text = item.VendorName, Value = item.Id.ToString() });\n                //Add the current item i3n the loop to the selectListItem\n            }\n            ViewData[\"demo\"] = test;\n            Vendors.OrderBy(x => x.VendorName);\n}\n\nThis is the front end code:\n@page\n@model PurchaseOrdersModel\n@{\n    ViewData[\"Title\"] = \"Home page\";\n}\n<style>\n    body {\n        background-image: url(\"http://10.48.1.215/PORTAL/hero-range-1.jpg\");\n        height: 100%;\n        background-position: center;\n        background-repeat: no-repeat;\n        background-size: cover;\n    }\n\n    #myInput {\n        /*background-image: url('/css/searchicon.png'); /* Add a search icon to input */\n        /*        background-position: 10px 12px; /* Position the search icon */\n        /*        background-repeat: no-repeat; /* Do not repeat the icon image **/\n        width: 100%; /* Full-width */\n        font-size: 16px; /* Increase font-size */\n        /*padding: 12px 20px 12px 40px; /* Add some padding */\n        border: 1px solid #ddd; /* Add a grey border */\n        margin-bottom: 12px; /* Add some space below the input */\n    }\n\n</style>\n@*\n<select asp-for=\"Files.VendorId.Value\" asp-items=\"@((List<SelectListItem>)ViewData[\"demo\"])\"></select>*@\n\n\n<h1 style=\"color: white\">Purchase Orders</h1>\n<p>\n    <a asp-page=\"Create\" style=\"color:white\">Create File</a>\n</p>\n<div class=\"row\">\n    <div class=\"col-sm-12\">\n        <div class=\"form-check-inline pull-right\">\n            <label style=\"color:white\">Search</label>\n            <input type=\"text\" class=\"form-control\" id=\"myInput\" placeholder=\"Search Purchase Orders...\" onkeyup=\"myFunction()\" />\n        </div>\n        <select asp-items=\"@((List<SelectListItem>)ViewData[\"test\"])\" id=\"vendor\" onchange=\"myFunctionThree()\">\n            <option value=\"\" disabled selected>Select a Vendor</option>\n        </select>\n        <input class=\"btn btn-light\" value=\"Clear All Filters\" onclick=\"history.go(0)\" style=\"float: right\">\n        <table class=\"table\" style=\"background-color: white\" id=\"myTable\">\n            <thead>\n                <tr class=\"header\">\n                    <th>\n                        PO No.\n                    </th>\n                    @*            <th>\n                    @Html.DisplayNameFor(model => model.Files[0].Date)\n                    </th>\n                    <th>\n                    @Html.DisplayNameFor(model => model.Files[0].Value)\n                    </th>*@\n                    <th>\n                        Haulier\n                    </th>\n                    <th>\n                        Comments\n                    </th>\n                    <th>\n                        Vendor\n                    </th>\n                    <th>\n                        Upload\n                    </th>\n                    <th>\n                        Date Uploaded\n                    </th>\n                    <th>Download</th>\n                    <th>Delete Attachment</th>\n                    <th>Notify</th>\n                    <th>Sent</th>\n                    <th>\n\n                    </th>\n                </tr>\n            </thead>\n            <tbody>\n\n                @foreach (var item in Model.Files)\n                {\n                    if (item.FileType == \"Purchase Order\")\n                    {\n                        <tr>\n                            <td>\n                                @Html.DisplayFor(modelItem => item.Number)\n                            </td>\n\n                            @*<td>\n                    @Html.DisplayFor(modelItem => item.FileType)\n                    </td>*@\n                            <td>\n                                @Html.DisplayFor(modelItem => item.Haulier)\n                            </td>\n                            <td>\n                                @Html.DisplayFor(modelItem => item.Comments)\n                            </td>\n                            <td>\n                                @Html.DisplayFor(modeItem => item.Vendor.VendorName)\n                            </td>\n                            <td>\n                                <a asp-page=\"Upload\" asp-route-id=\"@item.Id\">Upload File Attachment</a>\n                            </td>\n                            <td>\n                                @Html.DisplayFor(modelItem => item.UploadDate)\n                            </td>\n                            <td>\n                                @if (item.Attachment != null)\n                                {\n                                    <form asp-page-handler=\"Download\" method=\"post\" asp-route-id=\"@item.Id\">\n                                        <input type=\"submit\" class=\"btn btn-dark\" value=\"Download\">\n                                    </form>\n                                }\n                            </td>\n                            <td>\n                                @if (item.Attachment != null)\n                                {\n                                    <form asp-page-handler=\"Delete\" method=\"post\" asp-route-id=\"@item.Id\">\n                                        <input type=\"submit\" class=\"btn btn-danger\" value=\"Delete Attachment\">\n                                    </form>\n                                }\n                            </td>\n                            <td>\n                                @if (item.Attachment != null)\n                                {\n                                    <form asp-page-handler=\"Email\" method=\"post\" asp-route-id=\"@item.Id\">\n                                        <input type=\"submit\" class=\"btn btn-danger\" value=\"Notify Vendor\">\n                                    </form>\n                                }\n                            </td>\n                            <td>\n                                @Html.DisplayFor(modelItem => item.EmailSent)\n                            </td>\n                            <td>\n                                <a asp-page=\"/Admin/Details\" asp-route-id=\"@item.Id\">Details</a>\n                            </td>\n                        </tr>\n                    }\n\n                }\n            </tbody>\n        </table>\n    </div>\n</div>\n\n\n<script>\n\n    //function for search bar\n    function myFunction() {\n        // Declare variables\n        var input, filter, table, tr, td, i, txtValue, dropdownValue, dropdownInput, dtd;\n        input = document.getElementById(\"myInput\");\n        filter = input.value.toUpperCase();\n        table = document.getElementById(\"myTable\");\n        tr = table.getElementsByTagName(\"tr\");\n        dropdownInput = document.getElementById(\"vendor\");\n        dropdownValue = dropdownInput.value.toUpperCase();\n\n        // Loop through all table rows, and hide those who don't match the search query\n        for (i = 0; i < tr.length; i++) {\n            td = tr[i].getElementsByTagName(\"td\")[0];\n            dtd = tr[i].getElementsByTagName(\"td\")[3];\n            if (td) {\n                    txtValue = td.textContent || td.innerText;\n                    dropTxtValue = dtd.textContent || dtd.innerText;\n                    if(dropdownValue == \"\"){\n                        if (txtValue.toUpperCase().indexOf(filter) > -1) {\n                            tr[i].style.display = \"\";\n                        } else {\n                            tr[i].style.display = \"none\";\n                        }\n                    }\n                    else{\n                        if((txtValue.toUpperCase().indexOf(filter) > -1) && (dropTxtValue.toUpperCase().indexOf(dropdownValue) > -1)){\n                            tr[i].style.display = \"\";\n                        }else{\n                            tr[i].style.display = \"none\";\n                        }\n                    }\n            }\n        }\n    }\n\n    //function for dropdown menu\n    function myFunctionThree()\n    {\n        // Declare variables\n        var input, filter, table, tr, td, i, txtValue;\n        input = document.getElementById(\"vendor\");\n        filter = input.value.toUpperCase();\n        table = document.getElementById(\"myTable\");\n        tr = table.getElementsByTagName(\"tr\");\n\n        // Loop through all table rows, and hide those who don't match the search query\n        for (i = 0; i < tr.length; i++) {\n            td = tr[i].getElementsByTagName(\"td\")[3];\n            if (td) {\n                txtValue = td.textContent || td.innerText;\n                if (txtValue.toUpperCase().indexOf(filter) > -1) {\n                    tr[i].style.display = \"\";\n                } else {\n                    tr[i].style.display = \"none\";\n                }\n            }\n        }\n    }\n\n</script>\n\nI want to sort it A-Z by Vendor Name instead of by the Vendor ID.\n",
"AnswerId": "76388706",
"AnswerBody": "OrderBy creates IEnumerable that \"executes\" when used in foreach or when .ToList() is invoked. Try this:\nVendors = _context.Vendors.OrderBy(x => x.VendorName).ToList();\n\n"
},
{
"QuestionId": "76390761",
"QuestionTitle": "Pass a value to another component using Services when a change in value (dropdown selection) happens in the parent component - Angular",
"QuestionBody": "I'm trying to pass a value (year_value) from a parent component to a child component using services, whenever there is a change in the value (dropdown selection).  Also I'm using Angular routing (<router-outlet>) for navigation to child component, since I will be adding more charts later which are separate components.\napp.component.html\n<mat-toolbar class=\"toolbar2\">\n        <div>\n            <button mat-button (click)=\"getChartType('bar')\" [routerLink]=\"'/bar-chart'\" matTooltip=\"Bar Chart\">\n                <img src=\"assets/images/column.svg\">\n            </button>\n        </div>\n        <div>\n          <mat-form-field>\n            <mat-label>Select year</mat-label>\n            <mat-select placeholder=\"{{initialValue}}\" (selectionChange)=\"selectByYear($event)\"\n                [(ngModel)]=\"year_value\">\n                <mat-option *ngFor=\"let year of years\" [value]=\"year.value\">\n                    {{year.viewValue}}\n                </mat-option>\n            </mat-select>\n          </mat-form-field>\n        </div>\n    </mat-toolbar>\n\n    <mat-divider></mat-divider>\n\n    <div class=\"container-fluid\">\n        <div class=\"col1\"></div>\n        <div class=\"col2\">\n          <div class=\"col2-row1 charts-area\">\n            <router-outlet>\n              <div class=\"card\" id=\"container\"></div>\n            </router-outlet>\n          </div>\n          <div class=\"col2-row2\"></div>\n        </div>\n    </div>\n\n<mat-select> is the dropdown and when selecting a value, the selectByYear updates the year property.\napp.component.ts\n  export class AppComponent implements OnInit {\n\n  constructor(private commonActions: CommonActionsService) {}\n\n  beData = this.commonActions.getData();\n\n  canvas: any;\n  ctx: any;\n  header: any;\n  xValues: string[] = [];\n  dataValues: any[] = [];\n  yValues: number[] = [];\n  year: string = '';\n  initialValue: any;\n  year_value;\n  years: any[] = [];\n  bgColors: string[] = [];\n  buttons = ['Status', 'Auditor', 'ISOScheme'];\n  numbers = ['Audits'];\n  chart_yfield: string[] = [];\n  chart_xfield: string[] = [];\n  chartType;\n  activity: any;\n  xData: any;\n  label: any;\n  options: any;\n  currentYear: any;\n\n  ngOnInit() {\n    this.selectYear();\n    this.year_value = 2022;\n    this.chart_xfield.push('Status');\n    this.chart_yfield.push('Audits');\n    const index: number = this.buttons.indexOf('Status');\n    if (index !== -1) {\n      this.buttons.splice(index, 1);\n    }\n    this.numbers = []\n    this.header = this.chart_xfield[0]\n    this.getChartType('bar');\n  }\n\n  selectYear() {\n    this.currentYear = 2022;\n    let earliestYear = this.currentYear - 5;\n    while (this.currentYear >= earliestYear) {\n      let dateOption = {\n        \"viewValue\": this.currentYear + ' ' + '-' + ' ' + (this.currentYear + 1),\n        \"value\": this.currentYear\n      };\n      this.years.push(dateOption);\n      this.currentYear -= 1;\n    }\n    this.initialValue = this.years[0].viewValue;\n    this.selectByYear(this.years[0]);\n  }\n\n  selectByYear(event) {\n    this.year = event.value;\n    this.getChartType(this.chartType);\n\n    this.commonActions.setYearValue(this.year);\n  }\n\n  getChartType(type: string) {\n    if (this.chart_yfield.length != 0 && this.header != '') {\n      if (!this.year) {\n        return;\n      }\n      this.chartType = type;\n      this.isHighChart = true;\n      this.dataValues = [];\n      this.xValues = [];\n      this.yValues = [];\n      this.lineData = [];\n      this.beData[this.year][this.header].forEach((entry) => {\n        this.dataValues.push([entry.name, entry.value]);\n      });\n      this.beData[this.year][this.header].forEach((entry) => {\n        this.xValues.push(entry.name);\n      });\n      this.beData[this.year][this.header].forEach((entry) => {\n        this.yValues.push(entry.value);\n      });\n      this.beData[this.year][this.header].forEach((entry) => {\n        this.bgColors.push(entry.color);\n      });\n      console.log(this.xValues, this.yValues, this.header, this.year);\n\n    }\n  }\n\n}\n\nSo inside the selectByYear() I'm setting the year. After the value of year gets updated I'm updating the same in the CommonActionsService also.\ncommon-actions.service.ts\nexport class CommonActionsService {\n\n  year_value: string;\n\n  constructor() { }\n\n  setYearValue(year: string) {\n    this.year_value = year;\n  }\n\n  getYearValue() {\n    return this.year_value;\n  }\n\n}\n\nNow in the bar-chart component, I call the get method. But nothing is displaying in the console.\nbar-chart.component.ts\nexport class BarChartComponent implements OnInit {\n\n  year_value: string;\n\n  constructor(private commonActions: CommonActionsService) {}\n\n  ngOnInit() {\n    this.year_value = this.commonActions.getYearValue();\n    console.log(\"Year Value from Bar Chart: \", this.year_value);\n  }\n\n}\n\nI want to get the value of this.year inside the selectByYear() in app.component.ts, inside bar-chart.component.ts whenever the year updates.\nOr is there any other way other than using services?\nI'm adding my full code here - https://stackblitz.com/edit/stackblitz-starters-k2touo?file=src%2Fmain.ts , but I'm not able to compile it online.\n",
"AnswerId": "76391534",
"AnswerBody": "Using services is the right way to share information accross component if they're not parent-child.\nHere it is a matter of concurrency: you are calling getYearValue before it has been setted in the other component (both event are being called OnInit, and maybe one component is being initialized before the other).\nMy suggestion is to use Subject and Observablein order to create streams so that they'll always be up to date.\nHere there is a simple example of how you could structure it (I couldn't directly use your code since it was not compiling)\n"
},
{
"QuestionId": "76389485",
"QuestionTitle": "How to Print numbers in sequential manner using TPL multiple tasks",
"QuestionBody": "What is the problem with the following code?\nI am trying to print numbers in sequence. One Task is for printing odd numbers and the other task is for printing even numbers.\nCould somebody help me how to introduce the synchronization, so that I can get sequenced numbers from 0-10?\nCode :\n    using System.Threading.Tasks;\n\nTask.Run(() =>{\n\n        var printNumbers = new PrintNumbers();\n\n\n        for(var i =0; i<10; i++)\n        {                \n                if(i % 2 == 0)\n                    Console.WriteLine(i);                \n        }\n})\n\n\nTask.Run(() =>{\n\n        var printNumbers = new PrintNumbers();\n\n        for(var i =0; i<10; i++)\n        {                \n                if(i % 2 != 0)\n                    Console.WriteLine(i);                \n        }\n    }\n})\n\n\n\n oddTask.Start();\nevenTask.Start();\n\nTask.WhenAll(new Task[] { oddTask, evenTask});\n\npublic class PrintNumbers\n{\n    private static object seqNumbers = new object();    \n\n    public void PrintOddNumber(int number)\n    {\n        lock(seqNumbers)\n        {\n            Console.WriteLine(number);\n        }\n    }\n\n    public void PrintEvenNumber(int number)\n    {\n        lock(seqNumbers)\n        {\n            Console.WriteLine(number);\n        }\n    }\n}\n\nNote: I am using Visual Studio Code.\n",
"AnswerId": "76390066",
"AnswerBody": "\nWhat is the problem with the following code?\n\nobject seqNumbers = new object();\nTask.Run((seqNumbers) =>{   // 1. Task.Run does not allow to pass arguments\n        for(var i =0; i<10; i++)\n        {\n            lock(seqNumbers)  // 2. Using `lock` in here is problematic : \n                              //    you cannot enforce a toggle with a single one.\n            {\n                if(i % 2 == 0)\n                    Console.WriteLine(i);\n            }\n        }\n})\n.Wait(); // 3. This will block until the Task is completed\n\nTask.Run((seqNumbers) =>{\n    lock(seqNumbers)\n    {\n        for(var i =0; i<10; i++)\n        {\n            lock(seqNumbers)\n            {\n                if(i % 2 != 0)\n                    Console.WriteLine(i);\n            }\n        }\n    }\n})\n.Wait();\n\nSo, you see: The locking here is actually futile, because both Tasks run in sequence to each other. If you want Tasks to run in parallel (potentially), you need to start both and then await both.\nIf you need sequential output without utilizing intermediate data storage of results, then you have to do something awkward like this:\nusing System;\nusing System.Threading;\nusing System.Threading.Tasks;\n                    \npublic class Program\n{\n    public static async Task Main()\n    {\n        var oddsem = new SemaphoreSlim(1,1);\n        var evensem = new SemaphoreSlim(0,1);\n        \n        await Task.WhenAll(\n            Task.Run(async () => {\n                for(int i = 0; i < 10; i++){\n                    await oddsem.WaitAsync();\n                    try{\n                        if( i % 2 == 0 ) Console.WriteLine(\"A: {0}\",i);\n                    }\n                    finally{evensem.Release();}\n                }\n            }), \n            Task.Run(async () => {\n                for(int i = 0; i < 10; i++){\n                    await evensem.WaitAsync();\n                    try{\n                        if( i % 2 == 1 ) Console.WriteLine(\"B: {0}\",i);\n                    }\n                    finally{oddsem.Release();}\n                }\n            })\n        );\n    }\n}\n\nOutput:\n\nA: 0\nB: 1\nA: 2\nB: 3\nA: 4\nB: 5\nA: 6\nB: 7\nA: 8\nB: 9\n\nSee Fiddle.\nWhich defeats all the benefits of making this parallel in the first place.\n"
},
{
"QuestionId": "76388235",
"QuestionTitle": "Multi-Factor Authentication : FirebaseError: Firebase: Error (auth/code-expired)",
"QuestionBody": "I've tried integrating Firebase multi-factor authentication to your web app and have followed their documentation:https://firebase.google.com/docs/auth/web/multi-factor\nEverything works fine until i get to sms verification. After i get a code and instantly type it in i keep getting FirebaseError: Firebase: Error (auth/code-expired) and i can't figure out why. Keep in mind this is my firste time working with firebase.\nHere is my code.(I Change the number to xxxxxxx on purpose for showing you my code). Thanks for your help and help in advanced\n    signInWithEmailAndPassword(auth, email, password)\n  .then((userCredential) => {\n    console.log('Sign in Success');\n    navigate(\"/Search\");\n  })\n  .catch(function (error) {\n    if (error.code === 'auth/multi-factor-auth-required') {\n      console.log('MFA required');\n      const resolver = getMultiFactorResolver(auth, error);\n      const selectedIndex = 0;\n      if (resolver.hints[selectedIndex].factorId === PhoneMultiFactorGenerator.FACTOR_ID) {\n        console.log(resolver.hints[selectedIndex].factorId);\n        const phoneNumber = \"XXXXXXXX\";\n        console.log(resolver.session);\n        const phoneInfoOptions = {\n          multiFactorHint: resolver.hints[selectedIndex],\n          session: resolver.session\n        };\n\n        const phoneAuthProvider = new PhoneAuthProvider(auth);\n\n        console.log(phoneAuthProvider);\n        // Create recaptchaVerifier instance\n        const recaptchaVerifier = new RecaptchaVerifier(\n          \"recaptcha-container\",\n          {\n            size: \"normal\",\n            callback: function (response) {\n              // reCAPTCHA resolved, continue with phone verification\n              phoneAuthProvider.verifyPhoneNumber(phoneNumber, recaptchaVerifier, {\n                // Set the code expiration duration to 60 seconds\n                codeTime: 60000\n              })\n                .then(function (verificationId) {\n                  // Ask user for the SMS verification code. Then:\n                  const verificationCode = prompt(\"Enter the verification code\");\n                  const cred = PhoneAuthProvider.credential(verificationId, verificationCode);\n                  console.log(cred)\n                  const multiFactorAssertion = PhoneMultiFactorGenerator.assertion(cred);\n                  // Complete sign-in.\n                  return resolver.resolveSignIn(multiFactorAssertion);\n                })\n                .then(function (userCredential) {\n                    navigate(\"/Search\");\n                })\n                .catch(function (error) {\n                  console.log(error)\n                });\n            },\n            \"expired-callback\": function () {\n              // Response expired. Ask user to solve reCAPTCHA again.\n              // ...\n            },\n          },\n          auth\n        );\n\n        recaptchaVerifier.render().then(function (widgetId) {\n          window.recaptchaWidgetId = widgetId;\n        });\n      }\n    }\n  });\n\n",
"AnswerId": "76388723",
"AnswerBody": "Try changing phoneInfoOptions to phoneNumber in:\nphoneAuthProvider.verifyPhoneNumber(phoneInfoOptions, recaptchaVerifier, {\n// Set the code expiration duration to 60 seconds\ncodeTime: 60000\n})\n\n"
},
{
"QuestionId": "76391385",
"QuestionTitle": "Is Compile-time Polymorphism in C++ Templates Possible?",
"QuestionBody": "Consider the following code snippet:\n#include <iostream>\n#include <typeinfo>\n\n\ntemplate<typename T>\nclass TypePrinter{\n    public:\n    void print_type() {\n        std::cout << typeid(T).name() << std::endl;\n    }\n}; // end class TypePrinter\n\n\nclass Base{\n    public:\n    TypePrinter<Base> createTypePrinter(){ // TODO replace \"Base\" with the class of the instance.\n        return TypePrinter<Base>();\n    }\n}; // end Base\n\nclass Derived: public Base{\n};\n\nint main() {\n    // Create a derived instance and try to create a TypePrinter for it\n    Derived d;\n    auto tp = d.createTypePrinter();\n    tp.print_type(); // prints \"4Base\".\n    return 0;\n} // end main\n\nIn the example above, I have\n\na class with a typename template parameter (TypePrinter) and\nanother class that instantiate it, using its type as a parameter (Base)\n\nHow can the code above be rewritten so that the inherited derived_instance.createTypePrinter() method can create a TypePrinter<Derived> rather than a TypePrinter<Base>?\nIn other words, what modifications could allow d.createTypePrinter().print_type() to print \"Derived\"?\n",
"AnswerId": "76391547",
"AnswerBody": "As noted in the comments, this can be implemented with the Curiously Recurring Template Pattern.\n#include <iostream>\n#include <typeinfo>\n\n\ntemplate<typename T>\nclass TypePrinter{\n    public:\n    void print_type() {\n        std::cout << typeid(T).name() << std::endl;\n    }\n}; // end class TypePrinter\n\ntemplate<typename T> // Base is now a template class. \n                     // Subclasses set T to their type\nclass Base{\n    public:\n    TypePrinter<T> createTypePrinter(){\n        return TypePrinter<T>();\n    }\n}; // end Base\n\nclass Derived: public Base<Derived>{\n};\n\nint main() {\n    // Create a derived instance and try to create a TypePrinter for it\n    Derived d;\n    auto tp = d.createTypePrinter();\n    tp.print_type(); // Now this prints \"7Derived\"\n    return 0;\n} // end main\n\n\n"
},
{
"QuestionId": "76388608",
"QuestionTitle": "NuGet Compatible vs Computed Framework (Xamarin and .NET 6)",
"QuestionBody": "We are currently looking at migrating existing Xamarin.Android and Xamarin.iOS applications to .NET 6 (we aren't at this stage going to use MAUI).\nA big part of this process is understanding which NuGet packages we need to update or replace.\nWe're just trying to understand the difference between a package being compatible with a framework, and a framework being an additionally computed framework.\nWe can see for some of the packages we are using that net6.0-ios and net6.0-android are additionally computed frameworks rather than being compatible. What does this mean in terms of whether or not a net6.0-ios or net6.0-android app could consume the package?\n",
"AnswerId": "76388726",
"AnswerBody": "It really depends.\nLets say you are trying to consume a package that only targets netstandard1.0 or above. That package will be totally fine to consume.\nHowever, if you are attempting to consume a package that has multiple targets, lets say\n\nnetstandard1.0\nXamarin.iOS\nmonoandroid13.0\n\nThat package will only partially work. The netstandard stuff will definitely work. monoandroid13.0 will most likely work. However, since there are breaking changes between Xamarin.iOS and net6.0-ios then that part won't work.\nMost preferably, for packages that target a specific platform, that should at least be net6.0-android or net6.0-ios, otherwise you will encounter issues.\n"
},
{
"QuestionId": "76391254",
"QuestionTitle": "Safety of using and approach to \"floating\" promises",
"QuestionBody": "In the MDN Docs it explains,\n\nImportant: Always return results, otherwise callbacks won't catch the result of a previous promise (with arrow functions, () => x is short for () => { return x; }). If the previous handler started a promise but did not return it, there's no way to track its settlement anymore, and the promise is said to be \"floating\".\n\nWith this little json file:\n{\n  \"ingredients\": \"flour,sugar,butter,chocolate\"\n}\n\nconst listOfIngredients = [];\nconsole.clear();\nfunction doSomething() {\n  fetch('http://127.0.0.1:4000/test.json')\n  .then((res) => res.json())\n  .then((data) => {\n    data.ingredients.split(',').forEach(i => listOfIngredients.push(i)); \n  // doesn't return\n  })\n  .then((nothing) => {\n    console.log(nothing); // undefined, of course\n    console.log(listOfIngredients);\n    return \"and coconut\";\n  })\n  .then((something) => {\n    listOfIngredients.push(something);\n    console.log(listOfIngredients);\n  });\n}\ndoSomething();\n\nResult:\nundefined\n['flour', 'sugar', 'butter', 'chocolate']\n['flour', 'sugar', 'butter', 'chocolate', 'and coconut']\n\nSo, I think that the result of the success callback, (data) => {...} is (said to be) \"floating\", but that since in this case, the promise returns immediately, the chained (nothing) => {...} and (something) => {...} callbacks succeed.\nIf I update the (nothing) callback to contain another fetch, that fetch does need to be returned ((nothing) => { return fetch...  otherwise we get ['flour', 'sugar', 'butter', 'chocolate', undefined]. Makes sense.\nSo, in promise chains, do you only need to return from the callbacks for promise objects that handle asynchronous operations?\n",
"AnswerId": "76391581",
"AnswerBody": "\nSo, in promise chains, do you only need to return from the callbacks for promise objects that handle asynchronous operations?\n\nYou are correct. From the mdn doc you provided:\n\nIf the previous handler started a promise but did not return it, there's no way to track its settlement anymore, and the promise is said to be \"floating\".\n\nNotice in this one:\n.then((data) => {\n    data.ingredients.split(',').forEach(i => listOfIngredients.push(i)); \n  // doesn't return\n  })\n\nyou aren't starting a promise so there is no issue.\nFloating promises have nothing to do with returning the data but rather returning when the promise resolves you could do something like this for instance:\n.then(async res => {\n    window.myGlobal = await res.json();\n}).then(nothing => /* ... continue */ undefined);\n\neven though we aren't returning the data directly the function provided only resolves when res.json() has finished so we don't have any hanging promises.\nIncidentally your example does have a hanging promise: the doSomething function. the doSomething function should be returning the fetch call as in:\nfunction doSomething() {\n  return fetch('http://127.0.0.1:4000/test.json')\n  /* ... */\n}\n\nNote that if you didn't want to return the fetch for some reason you could still avoid the hanging promise by using async/await like:\nasync function doSomething() {\n  await fetch('http://127.0.0.1:4000/test.json')\n  /* ... */\n}\n\nthis is functionally equivalent to the following however:\nfunction doSomething() {\n  return fetch('http://127.0.0.1:4000/test.json')\n      /* ... your existing .then chain goes here */\n      .then(() => undefined)\n  }\n}\n\nAlso note that as mentioned in the comments you are probably doing something really bad if you are writing code this way (not returning the results of asyncronous operations but still wanting to do things after they complete)\n"
},
{
"QuestionId": "76388587",
"QuestionTitle": "How to change the separator of a C# TextBox when I double click to select a word?",
"QuestionBody": "When I use a C# TextBox as an input box, I found it hard to quickly select a word by doubleclicking on then text, because it sometimes selects brackets and other characters.\nFor example, when I double click on var3, it selects  and what I want is .\nI tried adding doubleclick callback, but it seems be handled after default handler, and I don't know where user actually clicked, this also messes up the dragging operation after doubleclick to select multiple words.\nIs there a easy way to redefine the separator chars for word selection?\n",
"AnswerId": "76388739",
"AnswerBody": "You can handle the DoubleClick event and modify the SelectionStart and SelectionLength properties accordingly. Trim the delimiters at the start and end:\nprivate static readonly char[] Delimiters = { ' ', '(', ')', ',', ';', '.', '-', ':', '[', ']' }; // and so on...\n\nprivate void textBox1_DoubleClick(object sender, EventArgs e)\n{\n    TextBox txt = (TextBox)sender;\n    string selectedText = txt.SelectedText;\n    int selectStartOld = txt.SelectionStart;\n    int selectLengthOld = txt.SelectionLength;\n    int selectStartNew = selectStartOld;\n    int selectLengthNew = selectLengthOld;\n    bool inText = false;\n\n    for (int i = 0; i < selectedText.Length; i++)\n    {\n        if (!inText && Delimiters.Contains(selectedText[i]))\n        {\n            // TrimStart\n            selectStartNew++;\n            selectLengthNew--;\n        }\n        else if (inText && Delimiters.Contains(selectedText[i]))\n        {\n            // TrimEnd\n            selectLengthNew--;\n        }\n        else\n        {\n            inText = true;\n        }\n    }\n\n    txt.SelectionStart = selectStartNew;\n    txt.SelectionLength = selectLengthNew;\n} \n\n"
},
{
"QuestionId": "76389849",
"QuestionTitle": "Pandas drop_duplicates with a tolerance value for duplicates",
"QuestionBody": "What I have is two Pandas dataframes of coordinates in xyz-format. One of these contains points that should be masked in the other one, but the values are slightly offset from each other, meaning a direct match with drop_duplicates is not possible. My idea was to round the values to the nearest significant number, but this also does not always work, since if some values are rounded to different numbers, they won't match and won't be removed. For example, if one point lies at x = 149 and another at x = 151, rounding them to the nearest hundred gives different values. My code looks something like this:\nimport pandas as pd\nimport numpy as np\ndf_test_1 = pd.DataFrame(np.array([[123, 449, 756.102], [406, 523, 543.089], [140, 856, 657.24], [151, 242, 124.42]]), columns = ['x', 'y', 'z'])\n\ndf_test_2 = pd.DataFrame(np.array([[123, 451, 756.099], [404, 521, 543.090], [139, 859, 657.23], [633, 176, 875.76]]), columns = ['x', 'y', 'z'])\n\ndf_test_3 = pd.concat([df_test_1, df_test_2])\n\ndf_test_3['xr'] = df_test_3.x.round(-2)\ndf_test_3['yr'] = df_test_3.y.round(-2)\ndf_test_3['zr'] = df_test_3.z.round(1)\n\ndf_test_3 = df_test_3.drop_duplicates(subset=['xr', 'yr', 'zr'], keep=False)\n\nWhat I want is to remove duplicates if the columns 'xr' and 'yr' are duplicates +-100 and 'zr' duplicates +-0.1. For example, if two coordinates are rounded to (100, 300, 756.2) and (200, 400, 756.1), they should be considered duplicates and should be removed. Any ideas are appreciated, thanks!\n",
"AnswerId": "76390106",
"AnswerBody": "You can numpy broadcasting:\n# Convert to numpy\nvals1 = df_test_1.values\nvals2 = df_test_2.values\n\n# Remove from df_test_1\narr1 = np.abs(vals1 - vals2[:, None])\nmsk1 = ~np.any(np.all(arr1 < [100, 100, 0.1], axis=2), axis=1)\n\n# Remove from df_test_2\narr2 = np.abs(vals2 - vals1[:, None])\nmsk2 = ~np.any(np.all(arr1 < [100, 100, 0.1], axis=2), axis=1)\n\nout = pd.concat([df_test_1[msk1], df_test_2[msk2]], ignore_index=True)\n\nOutput:\n>>> out\n       x      y       z\n0  151.0  242.0  124.42\n1  633.0  176.0  875.76\n\nComment of @James\n\nThis removes left vs right and right vs left, but not duplicates within left vs left or right vs right.\n\nIn this case:\ndf_test_3 = pd.concat([df_test_1, df_test_2])\n\narr = df_test_3.values\nmsk = np.abs(arr - arr[:, None]) < [100, 100, 0.1]\nout = df_test_3[np.sum(np.all(msk, axis=2), axis=1) == 1]\nprint(out)\n\n# Output\n       x      y       z\n3  151.0  242.0  124.42\n3  633.0  176.0  875.76\n\n"
},
{
"QuestionId": "76391597",
"QuestionTitle": "Publishing a .Net Core 6 Windows Application Will Not Run",
"QuestionBody": "I thought the idea of .Net Core was that I did not have to install a Run-Time, it was included in the published code. However, when I run my App nothing happens. The Application Event Log says...\"Message: You must install .NET to run this application.\" When I look for .NET Core Runtimes, I only find SDK's. Where are the run-times? What is the published \"Runtimes\" folder for?\n",
"AnswerId": "76391645",
"AnswerBody": ".NET Core is just a smaller runtime, mostly split into separate libraries, but it certainly DOES require a runtime, just like normal .NET programs. At build time you could bundle it in the exe or you can depend on an external installed library, but ultimately it's still a dependency, much like with the real .NET Framework.\nYou can find the runtimes in the Microsoft website. Ror example, here is the .NET Core 6 runtimes download webpage, containing the SDKs, ASP libraries and the standalone runtime.\nhttps://dotnet.microsoft.com/es-es/download/dotnet/6.0\n"
},
{
"QuestionId": "76388686",
"QuestionTitle": "getting a problem where the radio button selections are getting reset to the first radio option",
"QuestionBody": "I am a beigner.And i dont know why the gender radio input is getting reset when i click anywhere on the screen below the rdio buttons section.Can anyone help me with this.This below is my code⬇️⬇️⬇️⬇️⬇️\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n</head>\n<body>\n    <h2>Sign Up Form</h2>\n    <br><br>\n    <form method=GET action=\"./pages mine/thank you.html\">\n        <input type=\"text\" placeholder=\"First name\"><br><br>\n        \n        <input type=\"text\" placeholder=\"Last name\"><br><br>\n    \n        <input type=\"email\" placeholder=\"Last name\"><br><br>\n    \n        <input type=\"password\" placeholder=\"Last name\" minlength=\"5\"><br><br>\n<!--gender selection-->\n        <label><h3>Select Gender<h3></label><br>\n        \n        <label for=\"male\">male</label>\n        <input type=\"radio\"  value=\"male\" id=\"male\" name=\"gender\" required/><br>\n        \n        <label for=\"female\">female</label>\n        <input type=\"radio\" value=\"female\" id=\"female\" name=\"gender\" required/><br>\n        \n        <label for=\"other\">other</label>\n        <input type=\"radio\" value=\"other\" id=\"other\" name=\"gender\"  required/><br><br>\n<!--when i click on the screen anywhr after this the gender selection is getting reset-->        \n        <label for=\"nation\">Country</label>\n        <select id=\"nation\" >\n            \n            <option value=\"india\" name=\"nation\">INDIA</option>\n            <option value=\"usa\" name=\"nation\">USA</option>\n            <option value=\"other\" name=\"nation\">OTHER</option>\n        </select><br><br>\n        <p>Write about yourself below</p><br>\n        <input type=\"textbox\" placeholder=\"type here\"><br>\n        <input type=\"submit\" placeholder=\"Sign in\">\n    </form>\n    \n</body>\n</html>\n\ni was trying the make radio buttons for gender selection but the selection is getting reset on click any where on the screen after the radio buttons section.\n",
"AnswerId": "76388767",
"AnswerBody": "There is a lot of things going wrong in this code.\nBut for your radio button issue, i think this is caused by <label><h3>Select Gender<h3></label><br>. Your <h3>node is not closed. It should be :\n<h3>Select Gender</h3>\nAlso you don't need a labelaround that.\nHere is a refactored version of your code :\nhttps://jsfiddle.net/dzt8ja6n/\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n</head>\n<body>\n    <h2>Sign Up Form</h2>\n    <br><br>\n    <form method=\"GET\" action=\"./pages mine/thank you.html\">\n        <input type=\"text\" placeholder=\"First name\"><br><br>\n        \n        <input type=\"text\" placeholder=\"Last name\"><br><br>\n    \n        <input type=\"email\" placeholder=\"Email\"><br><br>\n    \n        <input type=\"password\" placeholder=\"Password\" minlength=\"5\"><br><br>\n\n        <!-- Gender selection -->\n        <label for=\"gender\"><h3>Select Gender</h3></label><br>\n        \n        <label for=\"male\">Male</label>\n        <input type=\"radio\" value=\"male\" id=\"male\" name=\"gender\" required><br>\n        \n        <label for=\"female\">Female</label>\n        <input type=\"radio\" value=\"female\" id=\"female\" name=\"gender\" required><br>\n        \n        <label for=\"other\">Other</label>\n        <input type=\"radio\" value=\"other\" id=\"other\" name=\"gender\" required><br><br>\n        \n        <label for=\"nation\">Country</label>\n        <select id=\"nation\" name=\"nation\">\n            <option value=\"india\">INDIA</option>\n            <option value=\"usa\">USA</option>\n            <option value=\"other\">OTHER</option>\n        </select><br><br>\n        \n        <p>Write about yourself below</p><br>\n        <textarea placeholder=\"Type here\"></textarea><br>\n        \n        <input type=\"submit\" value=\"Sign in\">\n    </form>\n</body>\n</html>\n\n"
},
{
"QuestionId": "76388597",
"QuestionTitle": "  issue when in html attribute",
"QuestionBody": "Code first.\n<div data-a=\"a b\" data-b=\"a&nbsp;b\" id=\"test\"></div>\n<div data-a=\"a<b\" data-b=\"a&lt;b\" id=\"test2\"></div>\n\nvar test1= document.getElementById('test');\n\nvar test1_a= test.getAttribute('data-a');\nvar test1_b=test.getAttribute('data-b');\n\n// data-a=\"a b\" data-b=\"a&nbsp;b\"\nconsole.log('1:',test1_a===test1_b); // got false;\n\n\n\nvar test2= document.getElementById('test2');\n\nvar test2_a= test2.getAttribute('data-a');\nvar test2_b=test2.getAttribute('data-b');\n// data-a=\"a<b\" data-b=\"a&lt;b\"\nconsole.log('2:',test2_a===test2_b); // got true;\n\n\nQuestion: why &nbsp; and &lt; are different in html attribute?\nOnline run able example.\nhttps://codepen.io/qinbx/pen/eYPqBGQ\n",
"AnswerId": "76388771",
"AnswerBody": "In your case, the problem comes from the data-a attribute, not the HTML Entities.\nThe 'space' character is different from the 'non-breaking space' character.\nSee this list of HTML entities and note that the space character can be written using its entity number &#32;.\nI updated your example using the 'non breaking space' character (alt + 255) :\n\n\nvar test1= document.getElementById('test');\n\nvar test1_a= test.getAttribute('data-a');\nvar test1_b=test.getAttribute('data-b');\n\nconsole.log('1:',test1_a===test1_b);\n\nvar test2= document.getElementById('test2');\n\nvar test2_a= test2.getAttribute('data-a');\nvar test2_b=test2.getAttribute('data-b');\n\nconsole.log('2:',test2_a===test2_b);\n<!-- a space b -->\n<div data-a=\"a b\" data-b=\"a&#32;b\" id=\"test\"></div>\n<!-- a non-breaking space b (alt + 255) -->\n<div data-a=\"a b\" data-b=\"a&nbsp;b\" id=\"test2\"></div>\n\n\n\n"
},
{
"QuestionId": "76390067",
"QuestionTitle": "How do I align prefixIcon with text on textFormField?",
"QuestionBody": "I have the following code for my textFormField:\n Container(\n                  alignment: Alignment.centerLeft,\n                  height: media.height * 0.12,\n                  decoration: txtFieldBoxDecoration,\n                  child: TextFormField(\n                    textAlignVertical: TextAlignVertical.center,\n                    keyboardType: TextInputType.emailAddress,\n                    style: const TextStyle(\n                      color: Colors.white,\n                      fontSize: 26,\n                    ),\n                    decoration: InputDecoration(\n                      border: InputBorder.none,\n                      contentPadding: const EdgeInsets.only(top: 14),\n                      prefixIcon: const Icon(\n                        Icons.email,\n                        color: Colors.white,\n                        size: 28,\n                      ),\n                      hintText: 'Insira seu E-mail',\n                      hintStyle: GoogleFonts.openSans(\n                          color: Colors.white54, fontSize: 26),\n                    ),\n                    onChanged: (value) {},\n                  ),\n                ),\n\nAnd I'm getting the following result: \nHow do I align the prefix Icon and the hintText like this: \n",
"AnswerId": "76390118",
"AnswerBody": "For align the prefix Icon and the hintText,\nYou have to remove below code from InputDecoration\ncontentPadding: const EdgeInsets.only(top: 14),\n"
},
{
"QuestionId": "76391041",
"QuestionTitle": "How to write a Makefile to test multiple Unittest targets?",
"QuestionBody": "I am trying to write a generic Makefile that can run multiple different unit tests based on a second term in the make command.\nBasically I would like to write something like:\nmake test target1 # runs unit tests for target 1\nmake test target2 # runs unit tests for target 2\n      :\n      :\n      :\nmake test all     # runs all unit tests\n\nbut I can't find any documentation on how to do this. What I have right now is:\n.PHONY: clean test\ntest-target1:\n        pytest --cov-report term-missing --cov=a .\\target1\\\ntest-target2:\n        pytest --cov-report term-missing --cov=b .\\target2\\\ntest-all:\n        ### I don't know what to put here ###\n\nbut this syntax requires you to use make test-target1 with the hyphen included.\nEDIT:\nBased on some really good advice I now have the updated Makefile:\na: # ...\n    pytest --cov-report term-missing --cov=a.\\UnitTest\\a\n\n.PHONY: test\ntest : $(RUN_ARGS)\n    @echo \"Running unittests for $(RUN_ARGS)...\"\n\nbut running make test a returns\nRunning unittests for ...\nmake: 'a' is up to date.\n\nand if I change a to a1 then make test a1 will run the actual unittests. Why is the a RUN_ARGS not allowed?\nFor reference, the structure of the code is:\nsrc/a\nsrc/b\nsrc/UnitTest\nsrc/UnitTest/a\nsrc/UnitTest/b\n\n",
"AnswerId": "76391662",
"AnswerBody": "Thanks to all the help I received, I was able to solve both parts of my question by creating the following Makefile:\nall: a b c\n\na: \n    pytest --cov-report term-missing --cov=a .\\UnitTest\\a\\\n\nb: \n    pytest --cov-report term-missing --cov=b .\\UnitTest\\b\\\n\nc: \n    pytest --cov-report term-missing --cov=c .\\UnitTest\\c\\\n\n.PHONY: test a b c\n\ntest : $(RUN_ARGS)\n    @echo \"Running unittests...\"\n\n"
},
{
"QuestionId": "76388755",
"QuestionTitle": "pd.to_datetime with multiple format",
"QuestionBody": "I need to get a timestamp out of multiple time-formats like:\ndf['date'] = [29.05.2023 01:00:00, \n              29.05.2023, \n              28.05.2023 23:00:00]\n\nAt 00:00:00 on every day the time is missing and only the date has been logged.\nI need the timestamp to look like this:\ndf['date'] = [29.05.2023 01:00:00, \n              29.05.2023 00:00:00, \n              28.05.2023 23:00:00]\n\n",
"AnswerId": "76388787",
"AnswerBody": "Use to_datetime with dayfirst=True parameter, for final ouput DD.MM.YYYY HH:MM:SS use Series.dt.strftime:\ndf = pd.DataFrame({'date':['29.05.2023 01:00:00', \n                           '29.05.2023', \n                           '28.05.2023 23:00:00',\n                           '4.10.2023']})\n\n\ndf['date'] = pd.to_datetime(df['date'], dayfirst=True).dt.strftime('%d.%m.%Y %H:%M:%S')\nprint (df)\n                  date\n0  29.05.2023 01:00:00\n1  29.05.2023 00:00:00\n2  28.05.2023 23:00:00\n3  04.10.2023 00:00:00\n\n"
},
{
"QuestionId": "76390099",
"QuestionTitle": "The elasticsearch html_strip character filter doesn't work as expected with query_search query",
"QuestionBody": "The behaviour of html_strip character filter looks different with the search query using \"query_string\" and \"match\" query.\n\nCreated index with \"description\" field using my_analyzer having html_strip char filter\n\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"char_filter\": [\n            \"html_strip\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"description\": {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\"\n      }\n    }\n  }\n}\n\n\nIndexed as below with sample html content\n\nPUT test_index/_doc/001\n{\n  \"description\": \"<html><body>Hello world</body></html>\"\n}\n\ndocument created.\n\nsearch using <html> :\n\n\nGET /test_index/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"<html>\"\n    }\n  }\n}\n\nExpecting no hits as the html contents would be stripped out internally when using html_strip character filter as per the document (https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-htmlstrip-charfilter.html) but got the result,\nresult:\n{\n    \"took\": 2,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 1,\n        \"successful\": 1,\n        \"skipped\": 0,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": {\n            \"value\": 1,\n            \"relation\": \"eq\"\n        },\n        \"max_score\": 0.2876821,\n        \"hits\": [\n            {\n                \"_index\": \"test_index\",\n                \"_type\": \"_doc\",\n                \"_id\": \"001\",\n                \"_score\": 0.2876821,\n                \"fields\": {\n                    \"description\": [\n                        \"<html><body>Hello world</body></html>\"\n                    ]\n                }\n            }\n        ]\n    }\n}\n\nReturns the record (ideally it should not).\n\nLet's search using \"match\" query:\n\nWhen match query is used it could not find a record when searched using <html> or <body>. whereas it returns record when searched using \"Hello\" which seems to be the right behaviour of html_strip char filter.\nGET /test_index/_search\n{\n    \"query\": {\n    \"match\": {\n      \"description\": \"<html>\"\n    }\n  },\n  \"fields\": [\n    \"description\"\n  ],\n   \"_source\": false\n}\n\nResult:\n{\n    \"took\": 2,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 1,\n        \"successful\": 1,\n        \"skipped\": 0,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": {\n            \"value\": 0,\n            \"relation\": \"eq\"\n        },\n        \"max_score\": null,\n        \"hits\": []\n    }\n}\n\nthe above query doesn't return any result and looks like the html_strip character filter is working fine with \"match\" query.\nAny suggestions why html_strip character filter is not working as expected with \"query_string\" query and working with \"match\" query?\nAm I missing anything here?\n",
"AnswerId": "76390137",
"AnswerBody": "You didn't define any field in your query. By default, it hits all fields include description, and description.keyword.\nWhen you trying with match query you are defining the fields :).\nUpdate query like the following\nGET /test_html_strip/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"<html>\",\n      \"fields\": [\"description\"]\n    }\n  }\n}\n\n"
},
{
"QuestionId": "76391406",
"QuestionTitle": "How to extract blob data from websocket response",
"QuestionBody": "I'm trying to get market data from bingx websocket API but once my connection stablished i recieve blob data and i dont know how can i read candlestick data from that blob response with javascript does any one know how can i extract data?\nhere is my Js code :\nvar ws = new WebSocket('wss://open-ws-swap.bingbon.pro/ws');\n\n    ws.onopen = (event) => {\n        const msg = {\n            id: \"548\",\n            reqType:\"sub\",\n            dataType: \"market.kline.BTC-USDT.1min\",\n        }\n        ws.send(JSON.stringify(msg));\n        console.log('connection stablished!')\n    }\n\n\n    // Listen for messages\n    ws.onmessage = function(event) {\n        console.log(event.data);\n    }\n\n    ws.onclose = function(event) {\n        console.log(event)\n    };\n\n    ws.onerror = function(error) {\n        console.log(error);\n    };\n\nAnd here is the result in console:\n\nI tried this answer bot not working:\ntext\n",
"AnswerId": "76391673",
"AnswerBody": "From the docs ->\n\nAll response data from Websocket server are compressed into GZIP\nformat. Clients have to decompress them for further use\n\nSo using this information we can use DecompressionStream -> https://developer.mozilla.org/en-US/docs/Web/API/DecompressionStream  to uncompress the data, and then use TextDecoder to convert that into to text, finally JSON.parse to convert into an object.\nFinally you will want to watch for the Ping message, as the API will disconnect if you don't send a Pong.\neg.\n\n\nvar ws = new WebSocket('wss://open-ws-swap.bingbon.pro/ws');\n\n\nasync function decompressBlob(blob) {\n  const ds = new DecompressionStream(\"gzip\");\n  const decompressedStream = blob.stream().pipeThrough(ds);\n  return await new Response(decompressedStream).blob();\n}\n\n\n\n\nws.onopen = (event) => {\n   const msg = {\n      id: \"548\",\n      reqType:\"sub\",\n      dataType: \"market.kline.BTC-USDT.1min\",\n   }\n   ws.send(JSON.stringify(msg));\n   console.log('connection stablished!')\n}\n\n// Listen for messages\nws.onmessage = async function(event) {\n   const data = await decompressBlob(event.data);\n   const txt = new TextDecoder().decode(await data.arrayBuffer());\n   if (txt === 'Ping') {\n     //this keeps the api open\n     ws.send('Pong');\n   } else {\n     console.log(JSON.parse(txt));\n   }\n}\n\nws.onclose = function(event) {\n   console.log(event)\n};\n\nws.onerror = function(error) {\n   console.log(error);\n};\n\n\n\n"
},
{
"QuestionId": "76389592",
"QuestionTitle": "Rspec confused when I run the tests on the rspec with the --pattern and --exclude-patternn flags",
"QuestionBody": "I need to run all the tests from the \"spec/workers/**\" folder, but I don't want to run the tests in a specific folder that is inside the \"spec/workers/\". I'm using the --pattern flags to say what I want and --exclude--pattern to say what I don't want to run. and it still does what is described in --exclude-pattern.\nEg:\nbundle exec rspec --pattern \"spec/workers/**/*_spec.rb\" --exclude-pattern \"spec/workers/study_workers/*_spec.rb\"\n\n",
"AnswerId": "76390142",
"AnswerBody": "This is not a bug but expected behavior.\nWhen there are two filters defined, one to include a specific files and another to exclude the same specific files, then excluding pattern has a lower priority and therefore the file is included.\nPlease see the discussion in this GitHub issue.\n"
},
{
"QuestionId": "76388276",
"QuestionTitle": "How can I make flutter 2 finger zoom?",
"QuestionBody": "There is a datatable in a page in Flutter, I want to zoom in and out of this table or page with two fingers. Can anyone offer a solution ?\nMy main goal here is just to zoom in and out. Is there a widget for this? I couldn't find a way, what can I do? Can you help me ?\nThere is a video in the link\nI have specified all my table codes below. You can review and have details\nhere are my codes\nListView(children: <Widget>[\n              SizedBox(\n                width: double.infinity,\n                child: Padding(\n                  padding: EdgeInsets.fromLTRB(size.width * 0.03,\n                      size.width * 0.1, size.width * 0.03, size.width * 0.00),\n                  child: TextField(\n                    cursorColor: BaseData.vadenHomeSiyah,\n                    controller: txtPaletNo,\n                    // focusNode: unitCodeCtrlFocusNode,\n                    textAlign: TextAlign.center,\n                    decoration: InputDecoration(\n                        focusedBorder: OutlineInputBorder(\n                          borderSide: const BorderSide(\n                              color: Color.fromARGB(255, 0, 0, 0), width: 2.0),\n                          borderRadius: BorderRadius.circular(25.0),\n                        ),\n                        border: UnderlineInputBorder(),\n                        labelText: 'Palet No',\n                        labelStyle: TextStyle(\n                            color: Colors.black, fontSize: size.width * 0.05),\n                        filled: true,\n                        isDense: true,\n                        fillColor: Colors.white.withOpacity(0.2)),\n\n                    //işlemler\n                    onSubmitted: (value) {\n                      setState(() {\n                        paletRaporYuklendimi = true;\n                      });\n                      seciliPaletRaporGetir();\n                    },\n                    onChanged: (text) {},\n                  ),\n                  // TextField(\n                  //   controller: searchController,\n                  //   decoration: const InputDecoration(\n                  //     hintText: 'Ara...',\n                  //     border: OutlineInputBorder(),\n                  //   ),\n                  //   onChanged: _onSearchTextChanged,\n                  // ),\n                ),\n              ),\n              Padding(\n                padding: EdgeInsets.fromLTRB(size.width * 0.00,\n                    size.width * 0.08, size.width * 0.00, size.width * 0.00),\n                child: SizedBox(\n                  width: MediaQuery.of(context).size.width,\n                  child: FittedBox(\n                    child: paletRaporYuklendimi\n                        ? Center(\n                            child: Padding(\n                              padding: EdgeInsets.all(size.width * 0.2),\n                              child: const CircularProgressIndicator(\n                                color: Colors.black,\n                              ),\n                            ),\n                          )\n                        : DataTable(\n                            dataRowHeight: size.width * 0.4,\n                            columns: const <DataColumn>[\n                              DataColumn(\n                                label: Text(\n                                  'Palet No',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                              DataColumn(\n                                label: Text(\n                                  'Paket No',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                              DataColumn(\n                                label: Text(\n                                  'Tarih',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                              DataColumn(\n                                label: Text(\n                                  'Hareket Tip',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                              DataColumn(\n                                label: Text(\n                                  'Hücre Kodu',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                              DataColumn(\n                                label: Text(\n                                  'Hareket Turu',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                              DataColumn(\n                                label: Text(\n                                  'Cari Isim',\n                                  style: TextStyle(\n                                      fontWeight: FontWeight.w900,\n                                      fontSize: 30),\n                                ),\n                              ),\n                            ],\n                            rows: List.generate(filterList.length, (index) {\n                              final item = filterList[index];\n                              return DataRow(\n                                cells: [\n                                  DataCell(Text(\n                                    item.PALETNO ?? \"\",\n                                    style: const TextStyle(\n                                        fontWeight: FontWeight.w900,\n                                        fontSize: 30),\n                                  )),\n                                  DataCell(Text(\n                                    item.PAKETNO.toString(),\n                                    style: const TextStyle(\n                                        fontWeight: FontWeight.w900,\n                                        fontSize: 30),\n                                  )),\n                                  DataCell(Text(\n                                    item.TARIH ?? \"\",\n                                    style: const TextStyle(\n                                        fontWeight: FontWeight.w900,\n                                        fontSize: 30),\n                                  )),\n                                  DataCell(item.HAREKETTIPI == \"G\"\n                                      ? Text(\n                                          item.HAREKETTIPI ?? \"\",\n                                          style: const TextStyle(\n                                              fontWeight: FontWeight.w900,\n                                              fontSize: 30,\n                                              color: Colors.green),\n                                        )\n                                      : Text(\n                                          item.HAREKETTIPI ?? \"\",\n                                          style: const TextStyle(\n                                              fontWeight: FontWeight.w900,\n                                              fontSize: 30,\n                                              color: Colors.red),\n                                        )),\n                                  DataCell(Text(\n                                    item.HUCREKODU ?? \"\",\n                                    style: const TextStyle(\n                                        fontWeight: FontWeight.w900,\n                                        fontSize: 30),\n                                  )),\n                                  DataCell(Text(\n                                    item.HAREKETTURU ?? \"\",\n                                    style: const TextStyle(\n                                        fontWeight: FontWeight.w900,\n                                        fontSize: 30),\n                                  )),\n                                  DataCell(Text(\n                                    item.CARIISIM ?? \"\",\n                                    style: const TextStyle(\n                                        fontWeight: FontWeight.w900,`your text`\n                                        fontSize: 30),\n                                  )),\n                                ],\n                              );\n                            }),\n                          ),\n                  ),\n                ),\n              ),\n               if (filterList.length > 0)\n                  Padding(\n                    padding:  EdgeInsets.all(size.width * 0.03),\n                    child:  Text(\n                     \"Listelenen Kayıt Sayısı: \" +\n                          filterList.length.toString(),\n                      textAlign: TextAlign.right,style: TextStyle(color: Colors.green,fontWeight: FontWeight.bold),\n                    ),\n                  )\n                else\n                  Text(\"\")\n            ]),\n             \n\n",
"AnswerId": "76388832",
"AnswerBody": "Use InteractiveViewer and wrap the widget you want to zoom in or out, you can specify the max and min zoom with fields minScale and maxScale, and, what is also very nice, you can use a TransformationController, like this one below, for example, and apply it to your InteractiveViewer Widget and enable also zooming in and out by controls:\nfinal zoomTransformationController = TransformationController();\n\n void _zoomIn(){\n   zoomTransformationController.value.scale(2);\n }\n void _zoomOut(){\n   zoomTransformationController.value.scale(0.9);\n }\n\n\nclass InteractiveViewerExampleApp extends StatelessWidget {\n  const InteractiveViewerExampleApp({super.key});\n\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      home: Scaffold(\n        body: const InteractiveViewerExample(),\n      ),\n    );\n  }\n}\n\nclass InteractiveViewerExample extends StatelessWidget {\n  const InteractiveViewerExample({super.key});\n\n  @override\n  Widget build(BuildContext context) {\n    return Center(\n      child: InteractiveViewer(\n        boundaryMargin: const EdgeInsets.all(20.0),\n        minScale: 0.1,\n        maxScale: 2,\n transformationController: zoomTransformationController,\n        child: Container(\n          ...\n        ),\n      ),\n    );\n  }\n}\n\n"
},
{
"QuestionId": "76391704",
"QuestionTitle": "to_timesamp converting month to different month",
"QuestionBody": "Any idea why snowflake to_timestamp is converting February month to January?\n    SELECT to_timestamp(to_char('2022-02-02 08:01:29 AM'),'YYYY-MM-DD HH12:MM:SS AM');\n    -- 2022-01-02 08:00:29.000\n\n",
"AnswerId": "76391757",
"AnswerBody": "MM represent month when you convert to char , you should use MI for minute in snowflake, I assume the issue comes from there :\nSELECT to_timestamp(to_char('2022-02-02 08:01:29 AM','YYYY-MM-DD HH12:MI:SS AM'));\n\n"
},
{
"QuestionId": "76389885",
"QuestionTitle": "Parent variable in Vue 3 not updated when using update-emit on prop",
"QuestionBody": "I've the following very simple Vue 3 component:\n<template lang=\"pug\">\nb-modal(v-model=\"dshow\")\n  template(v-slot:default) test\n</template>\n\n<script>\nexport default {\n  props: {\n    show: {\n      type: Boolean,\n      default: false\n    }\n  },\n  data() {\n    return {\n      dshow: false\n    }\n  },\n  watch: {\n    show: function () {\n      this.dshow = this.show\n    },\n    dshow: function () {\n      this.$emit('update:show', this.dshow)\n    }\n  }\n}\n</script>\n\nIn my parent component, I'm using this as following:\nimport demo from 'mymodal.vue'\n\n<template lang=\"pug\">\nbutton.btn.btn-primary.hstack.gap-2(@click=\"showModal= true\") Show Modal!\ndemo(:show.sync=\"showModal\")\n</template>\n\n<script>\nexport default {\n  components: {\n    demo\n  },\n  data() {\n    return {\n      showModal: false\n    }\n  }\n}\n</script>\n\nNow, when I click on my button in the parent, the modal appears and when I close / hide the dialog, the callback for my watched variable dshow is also called. But unfortunately, my parent component isn't informed about the update. So when I click on my button next time, nothing happens, because the showModal hasn't been updated. this.$emit('update:show', this.dshow) is emitted, but the parent value isn't updated.\nAny idea on this? I run completely out of ideas on this :-(\n",
"AnswerId": "76390146",
"AnswerBody": "In Vue 3, the .sync modifier has been removed in favor of arguments to v-model (see migration guide)\nSo\n:show.sync=\"showModal\"\n\nnow has to be\nv-model:show=\"showModal\"\n\n"
},
{
"QuestionId": "76388667",
"QuestionTitle": "Enable clear-text local traffic on iOS not working in .NET MAUI",
"QuestionBody": "I'm trying to connect to http in my .net MAUI app and I disabled the Apple Transport Security (ATS) following Microsoft documentation (from here) by adding below configuration in the info.plist file:\n<key>NSAppTransportSecurity</key>    \n<dict>\n    <key>NSAllowsLocalNetworking</key>\n    <true/>\n</dict>\n\nHowever, I'm still getting below error message when attempting to communicate with the API using http:\n[0:] An error occurred: 'Error Domain=NSURLErrorDomain Code=-1022 \"The resource could not be loaded because the App Transport Security policy requires the use of a secure connection.\" UserInfo={NSLocalizedDescription=The resource could not be loaded because the App Transport Security policy requires the use of a secure connection., NSErrorFailingURLStringKey=http://restapi.adequateshop.com/api/Tourist, NSErrorFailingURLKey=http://restapi.adequateshop.com/api/Tourist, _NSURLErrorRelatedURLSessionTaskErrorKey=(\n    \"LocalDataTask <27DB8D6A-2EB6-41FE-953E-6FA2BFDBEDDC>.<1>\"\n), _NSURLErrorFailingURLSessionTaskErrorKey=LocalDataTask <27DB8D6A-2EB6-41FE-953E-6FA2BFDBEDDC>.<1>, NSUnderlyingError=0x280b9b330 {Error Domain=kCFErrorDomainCFNetwork Code=-1022 \"(null)\"}}'. Callstack: ''\n\nAny idea how to resolve this? Thank you in advance.\n",
"AnswerId": "76388836",
"AnswerBody": "The key that is specified in that documentation page only works for local addresses like IP addresses or addresses that end in .local as you can see in the Apple documentation.\nFrom your error message it seems that you are trying to reach a regular web address. In that case the key you need is: NSAllowsArbitraryLoads so that it opts out of ATS altogether.\nYour full entry will then look like this:\n<key>NSAppTransportSecurity</key>    \n<dict>\n    <key>NSAllowsArbitraryLoads</key>\n    <true/>\n</dict>\n\nHowever, I would not recommend doing this. Please try to get your endpoints on HTTPS. It should not be expensive anymore nowadays and this way your users and you will be at risk.\nIf you really can't add HTTPS, try to limit the unsafe connections made for your app to a single domain. How that is done can be found here in the Apple documentation.\nBasically, your info.plist entry should now look something like this:\n<key>NSAppTransportSecurity</key>\n<dict>\n  <key>NSAllowsArbitraryLoads</key>\n  <false/>\n  <key>NSExceptionDomains</key>\n  <dict>\n    <key>adequateshop.com</key>\n    <dict>\n      <key>NSIncludesSubdomains</key>\n      <true/>\n      <key>NSExceptionAllowsInsecureHTTPLoads</key>\n      <true/>\n    </dict>\n  </dict>\n</dict>\n\nBut again, I would recommend fixing the server to be secure above all.\n"
},
{
"QuestionId": "76391598",
"QuestionTitle": "How to extract specific records from a JSON file that all have the same value in a specified field with python?",
"QuestionBody": "I have a json file that has over 1000 records in it all similar to the one below:\n[{\"id\":0,\"occupation\":\"teacher\",\"county\":\"Santa Rosa\",\"grade\":\"3rd\",\"workID\":\"147767\"},\n\nI want to extract all the records that have a certain occupation, in this case I want to return the records where the occupations are teacher.\nThis is what I have tried:\nspecified_occ = {}\nfor o in data:\n    specified_occ[o[\"occupation\"]] = o\nspecOcc = (specified_occ['teacher'])  \n\nbut it only returns the first instance rather than all of them that match.\nMy dataset has 50 records where the occupation is 'teacher' I want every record returned.\n",
"AnswerId": "76391769",
"AnswerBody": "You can use a list comprehension to filter over your data and only select the needed elements. In general a list comprehension looks like this\nfiltered_list = [element for element in original_list if element == requirement]\n\nHere you only select the elements from the original list if the elements match some requirement.\nFor this specific problem you would use\nfiltered_data = [person for person in data if person['occupation'] == 'teacher']\n\nThis is syntactically equivalent to\nspeccified_o = []\nfor o in data:\n    if o['occupation'] == 'teacher':\n        speccified_o.append(o)\n\n"
},
{
"QuestionId": "76389800",
"QuestionTitle": "Why is my C++ string erase-remove-idiom implementation causing an infinite loop with conditional statements?",
"QuestionBody": "index is going out of bound it's not triggering while(i<str.length()) break; i tried to implement this line differently\nstring delStr(string s, int sIdx, int nChar) {\n  string ans = \"\";\n  int i = 0;\n  int n = s.length()-1;\n  while(n--){\n    \n    if(i==sIdx){\n      i += nChar;\n    }\n\n    if(n<0) break;\n    ans.push_back(s[i]);\n    i++;\n  }\n}\n\n\nTrying to implement string erase method.\n",
"AnswerId": "76390151",
"AnswerBody": "You should be sure to post a minimal, reproducible example when you ask a question. This will help people provide an answer.\nIf I understand the function correctly, I believe it is supposed to return a new std::string with the characters from sIdx to sIdx + nChar removed. If that is the case, there is a logic error that I can't quite follow. You can compare the posted code to the sample below and maybe that will help you correct it.\nIn the sample code, I show two different solutions. The first uses the standard library algorithms and the second just iterates over the characters similar to the posted code. The advantage of using the algorithms is that they are well-tested for correctness, have efficient implementations, and serve as a common language among developers.\nSample Code\n#include <iostream>\n\nusing std::cout, std::endl;\n\nstd::string delete_substr(const std::string& str, int sIdx, int nChar) {\n    std::string answer;\n    std::copy(str.begin(), str.begin() + sIdx, std::back_inserter(answer));\n    std::copy(str.begin() + sIdx + nChar, str.end(), std::back_inserter(answer));\n    return answer;\n}\n\nstd::string delStr(const std::string& str, int sIdx, int nChar) {\n    std::string answer;\n    int i{};\n    while (i < str.size()) {\n        if (i == sIdx)\n            i += nChar;\n        else\n            answer.push_back(str[i++]);\n    }\n    return answer;\n}\n\nint main(int argc, const char *argv[]) {\n    std::string s0 = \"abcdefghi\";\n    cout << delete_substr(s0, 3, 3) << endl;\n    cout << delStr(s0, 3, 3) << endl;\n    return 0;\n}\n\nOutput\nabcghi\nabcghi\n\n"
},
{
"QuestionId": "76387893",
"QuestionTitle": "How to fix dynamically generated runner files importing from 'cucumber.api' in Cucumber/Junit parallel testing?",
"QuestionBody": "I was trying to achieve parallel testing using cucumber with Junit. When I am trying to run the feature file parallely the runner file generated is importing from cucumber.api instead of io.cucumber. I want to know why it is dynamically taking from cucumber.api and also how can i fix that.Dynamic generated runner file\nTried Adding latest version of cucumber and junit but didint worked\n",
"AnswerId": "76388837",
"AnswerBody": "You're using a more modern version of Cucumber then the code generator you're using was written for.\nYou don't need the code generator anymore because Cucumber supports parallel execution now.\nYou can use the cucumber-java-skeleton to get started. The cucumber-junit-platform-engine docs should explain everything else.\n"
},
{
"QuestionId": "76390027",
"QuestionTitle": "SQL ORACLE, How to subtract sysdate?",
"QuestionBody": "How can I subtract the system date from the created task date in SQL ORACLE to get the difference in days, hours, minutes?\nI tried this code but i get wrong values:\nTO_CHAR(TO_DATE('1970-01-01 00:00:00','yyyy-mm-dd hh24:mi:ss') + (sysdate - a.CREATE_DATE_PL ), 'dd:hh24:mi:ss')  AS TT_LIFETIME\nMy results is below (the report has been generated 02.06  14:05\nenter image description here\n",
"AnswerId": "76390173",
"AnswerBody": "Difference of two DATE datatype values is number of days between them, so you have to do some arithmetic to extract days/hours/minutes, or - another option - to try extract with numtodsinterval.\nFor example:\nSQL> WITH\n  2     test (create_date_pl)\n  3     AS\n  4        (SELECT TO_DATE ('01.06.2023 08:10', 'dd.mm.yyyy hh24:mi') FROM DUAL)\n  5  SELECT SYSDATE,\n  6         create_date_pl,\n  7         --\n  8         SYSDATE - create_date_pl diff,\n  9         NUMTODSINTERVAL (SYSDATE - create_date_pl, 'day') c1,\n 10         EXTRACT (DAY FROM NUMTODSINTERVAL (SYSDATE - create_date_pl, 'day')) cd,\n 11         EXTRACT (HOUR FROM NUMTODSINTERVAL (SYSDATE - create_date_pl, 'day')) ch,\n 12         EXTRACT (MINUTE FROM NUMTODSINTERVAL (SYSDATE - create_date_pl, 'day')) cm\n 13    FROM test;\n\nSYSDATE          CREATE_DATE_PL         DIFF C1                                               CD         CH         CM\n---------------- ---------------- ---------- ---------------------------------------- ---------- ---------- ----------\n02.06.2023 14:29 01.06.2023 08:10 1,26333333 +000000001 06:19:12.000000000                     1          6         19\n\nSQL>\n\nWhen I ran that code, it was 2th of June 2023 at 14:29. Date to be subtracted was 1st of June 2023 (yesterday) at 08:10.\n\ndiff represents number of days between those two values\nc1 is what numtodsinterval returns\ncd, ch and cm contain extracted number of days/hours/minutes, i.e. difference is 1 day, 6 hours and 19 minutes\n\n"
},
{
"QuestionId": "76391760",
"QuestionTitle": "dependency injection in Angular when extending a class",
"QuestionBody": "I am a Java guy learning Angular.\nI have a service and I would like to have injected that service into my object. This doc explains well how to do it in a normal case. As I understand the concept, in the example we use constructor dependency injection.\nBut in my case, this is not possible because I am extending a class that has its own constructor with 3 parameters and I am not allowed to modify the parent constructor. So I can not add a 4th parameter to my constructor to have injected the service.\nThis code does not work because the last constructor param is invalid.\nmy code:\nexport class ChildComponent extends ParentComponent {\n\n  constructor(readonly service1: Service1,\n              readonly service2: Service2,\n              el?: ElementRef | null,\n              readonly service3: Service3) { <-- invalid param\n    super(service1, service2, el);\n  }\n\nWhat is the alternative dependency injection if the constructor injection is not an option?\n",
"AnswerId": "76391774",
"AnswerBody": "Instead of injecting the service through the constructor, you can declare a property in your child component and annotate it with the @Inject decorator to specify the service you want to inject.\n"
},
{
"QuestionId": "76388653",
"QuestionTitle": "Spring Security with Spring Boot 3 - Get JWT token from Security Context Holder",
"QuestionBody": "After migrating to spring boot 3 ,\nextends ResourceServerConfigurerAdapter is deprecrated.\n\nHence , unable to use the overrriden method\n   @Override\npublic void configure(ResourceServerSecurityConfigurer config) {\n    config.tokenServices(tokenServices());\n}\n\nI am able to replace this with\n@Bean\npublic SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n    http.csrf().disable();\n    http.authorizeHttpRequests(auth->auth.\n            requestMatchers(whitelistedEndPoints()).permitAll()\n            .anyRequest()\n            .anonymous())\n            .httpBasic().disable();\n    return http.build();\n}\n\nI have an existing code to get jwt token from OAuth as\n public String getJwtTokenFromAuth() {\n    OAuth2Authentication auth =(OAuth2Authentication) SecurityContextHolder.getContext().getAuthentication();\n  \n    OAuth2AuthenticationDetails oauth2AuthenticationDetails = (OAuth2AuthenticationDetails) auth.getDetails();\n    return oauth2AuthenticationDetails.getTokenValue();\n}\n\nHowever,\n\nOAuth2Authentication and OAuth2AuthenticationDetails are not available\n\nHow can i replace this code/functionality with new spring security module of spring boot 3.\nBelow is the pom dependencies , please suggest if i need to add/remove any ?\n  <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-security</artifactId>\n    </dependency>\n\n    <dependency>\n        <groupId>org.springframework.security</groupId>\n        <artifactId>spring-security-oauth2-resource-server</artifactId>\n    </dependency>\n\n",
"AnswerId": "76388845",
"AnswerBody": "Spring Security OAuth2 is deprecated and removed for a while. The replacement is built in Spring Security itself and the dependencies to use are exactly what you already know:\nthe required dependencies are:\n<dependency>\n <groupId>org.springframework.boot</groupId>\n <artifactId>spring-boot-starter-security</artifactId>\n</dependency>\n\n\n<dependency>\n    <groupId>org.springframework.security</groupId>\n    <artifactId>spring-security-oauth2-resource-server</artifactId>\n</dependency>\n\nIn order to gain the token value in a resource server you can do something like this\nclass PrincipalIntrospector {\n    \n    public String token() {\n        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();\n        JwtAuthenticationToken oauthToken = (JwtAuthenticationToken) authentication;\n        return oauthToken.getToken().getTokenValue();\n    }\n    \n}\n\nin order to make sure to have the role properly configured in your principal you can have something like below:\n@Bean\npublic JwtAuthenticationConverter jwtAuthenticationConverter() {\n    JwtAuthenticationConverter jwtAuthenticationConverter = new JwtAuthenticationConverter();\n    jwtAuthenticationConverter.setJwtGrantedAuthoritiesConverter(jwt -> {\n        List<String> authorities = jwt.getClaim(\"authorities\");\n        return authorities.stream().map(SimpleGrantedAuthority::new).collect(toList());\n    });\n\n    return jwtAuthenticationConverter;\n}\n\nin order to decode and make to spring to validate your jwt you can configure something like below:\n// used in case of public key\n@Bean\npublic JwtDecoder jwtDecoder() {\n    return NimbusJwtDecoder.withPublicKey(this.key).build();\n}\n// used in case of the private key\n@Bean\npublic JwtDecoder jwtDecoder() {\n    return NimbusJwtDecoder.withSecretKey(this.key).build();\n}\n\nThe spring security pipeline can look like below:\n@Bean\npublic SecurityFilterChain filterChain(\n        JwtDecoder  decoder,\n        JwtAuthenticationConverter converter,\n        HttpSecurity http) throws Exception {\n    http.csrf().disable();\n    http.authorizeHttpRequests(auth->auth.\n                    requestMatchers(whitelistedEndPoints()).permitAll()\n                    .anyRequest()\n                    .authenticated())\n            .oauth2ResourceServer().jwt().decoder(decoder).jwtAuthenticationConverter(converter);\n    return http.build();\n}\n\n"
},
{
"QuestionId": "76389421",
"QuestionTitle": "Can't connect to outside from the docker container managed by ECS on EC2",
"QuestionBody": "I have ECS which uses EC2 and EC2 has a contianer.\nFrom EC2 node I can access the outside with this command.\n[ec2-user@ip-172-31-23-50 ~]$ curl google.com\n<HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n<TITLE>301 Moved</TITLE></HEAD><BODY>\n<H1>301 Moved</H1>\nThe document has moved\n<A HREF=\"http://www.google.com/\">here</A>.\n</BODY></HTML>\n\nThen I login container running on this node, docker exec -it container-name /bin/bash\n root@ip-172-31-24-234:/# curl google.com\n\nI can't access(nothing appears).\nSo, I check the security group of ECS Service.\nHowever all outbound connection is allowed\n\nTest\non EC2 node I try to run another container (Becasue I wanted to test the container which is not managed by ECS service).\n`docker run -it ubuntu`\n\nthen install curl and try curl in the this ubuntu containaer,I can connect to the outside from the container.\nSo the problem happens only in ECS managed container,\nMy task difinition is made by CDK, maybe this Network mode is related....??\nconst adminTaskDefinition = new ecs.Ec2TaskDefinition(this, 'AdminTaskDefinition', {\n  networkMode: ecs.NetworkMode.AWS_VPC,\n})\n\n",
"AnswerId": "76390179",
"AnswerBody": "Perhaps set your Network Mode = host in your task definition.\n"
},
{
"QuestionId": "76391141",
"QuestionTitle": "Creating a new column in SQL Oracle with a subquery - any suggestions?",
"QuestionBody": "I have the columns Yearmonth, code, type and clntamount in my table. I want to derive column clntamount_der.\nTable view\n\nI want the 110 value in clntamount with the type = Total to be in the column clntamount_der where the type = base and the rest two rows(adj and total) as zero.\nPlease help with the logic.\nI tried case statemnt but it didnt work maybe a subquery will work\n",
"AnswerId": "76391779",
"AnswerBody": "You may use the conditional max window function as the following:\nselect t.*, \n  case \n    when TYPE = 'BASE' \n       then max(case when TYPE = 'TOTAL' then CLNTAMOUNT end) over\n               (partition by YearMonth, Code)\n       else 0\n    end as clntamount_der\nfrom tbl t\norder by \n  YearMonth, Code,\n  case TYPE\n    when 'BASE' then 1\n    when 'ADJUST' then 2\n    when 'TOTAL' then 3\n  end\n\ndemo\nAlso, it seems that the TOTAL is the sum of other types (BASE, ADJUST), in this case, it would be better to calculate the TOTAL on the fly (and not store it as a separate row) to avoid data inconsistency. i.e. when you update the CLNTAMOUNT value where type = 'BASE' how would you reflect this to the value where type = 'TOTAL'?\nconsider the following without having the TOTAL type stored in the table.\nselect d.*\n  from\n(\n  select t.YearMonth, t.Code, t.Type, t.CLNTAMOUNT,\n    case \n      when TYPE = 'BASE' \n         then sum(t.CLNTAMOUNT) over (partition by t.YearMonth, t.Code)\n         else 0\n      end as clntamount_der\n  from tbl t\n  \n  union all\n  \n  select t.YearMonth, t.Code, 'TOTAL',\n          sum(t.CLNTAMOUNT), 0 \n  from tbl t\n  group by t.YearMonth, t.Code\n) d\norder by \n  d.YearMonth, d.Code,\n  case d.TYPE\n    when 'BASE' then 1\n    when 'ADJUST' then 2\n    when 'TOTAL' then 3\n  end\n\ndemo\n"
},
{
"QuestionId": "76391738",
"QuestionTitle": "Assign new values later to the underlying object of the interface in go",
"QuestionBody": "I am trying to assign new values to the underlying structure of an interface in code below. But it keeps the older values. Below is the example code.\npackage main\n\nimport (\n    \"fmt\"\n    \"math\"\n)\n\ntype Shape interface {\n    Area() float64\n}\n\ntype Circle struct {\n    Radius float64\n    Name   string\n}\n\nfunc (c Circle) Area() float64 {\n    return math.Pi * c.Radius * c.Radius\n}\n\ntype Rectangle struct {\n    Length float64\n    Width  float64\n    Name   string\n}\n\nfunc (r Rectangle) Area() float64 {\n    return r.Length * r.Width\n}\n\nfunc assignRadius(s Shape, radius float64, name string) {\n    switch s := s.(type) {\n    case Circle:\n        s.Radius = radius\n        s.Name = name\n    case Rectangle:\n        s.Length = radius\n        s.Name = name\n    }\n}\n\nfunc main() {\n    var s Shape\n    c := Circle{Radius: 0, Name: \"My Circle\"}\n    s = c\n    fmt.Println(s.Area())\n    fmt.Println(c.Radius)\n    fmt.Println(c.Name)\n    assignRadius(s, 10, \"My New Circle\")\n    fmt.Println(c.Radius)\n    fmt.Println(c.Name)\n}\n\nThe type of Shape isn't known beforehand in the assignRadius. I know it has something to do with the pointers. But can't figure it out.\n",
"AnswerId": "76391785",
"AnswerBody": "The interface variable s contains a copy of the shape value. To modify it like you attempted to do, it has to contain a pointer to that shape:\nvar s Shape\nc := Circle{Radius: 0, Name: \"My Circle\"}\ns = &c\n\nand in the function modifying them, you have to type-assert the pointer value:\nfunc assignRadius(s Shape, radius float64, name string) {\n    switch s := s.(type) {\n    case *Circle:\n        s.Radius = radius\n        s.Name = name\n    case *Rectangle:\n        s.Length = radius\n        s.Name = name\n    }\n\n\n\n"
},
{
"QuestionId": "76389675",
"QuestionTitle": "Active UITextView moving in UIScrollView",
"QuestionBody": "I have a large scrolling canvas that is 2000 pixels wide, with an unlimited length, inside of which is a single large UIView.\nYou can interact with the UIView to add objects (lines, shapes, text boxes, images, pdfs etc).\nWhen you add a text box, I create a subclass of UITextView that is configured to auto-grow with text - limited to 600px wide and unlimited length (you can force it wider). Key point - UITextViews never scroll internally.\nThe problem I am having is moving the UIscrollview (i.e. the big canvas) to keep the cursor of the active text box visible. When you are on a limited width display (such as an iPhone), you should be able to click on a text box and start typing. The scroll view should move around to keep your current cursor (text entry point) on the screen, even when the UITextView is very wide.\nThis is not too hard - I have a UITextViewDelegate with a \"DidChangeSelection:\" function. When the selection moves and the delegate method gets called - I find the current cursor (SelectedTextRange), convert that into a rect (GetFirstRectForRange), then convert from UITextView coordinates to the UIView coordinates (ConvertRectToView), then request the UIScrollView being that rect into view (ScrollRectToVisible).\nWhat is weird is that even though my rect is correct - the UITextView is always aligning so the far right hand edge is visible. So if the UITextView is 1000px wide, and the visible part of the UIScrollView is only 500px wide, then only ½ of the UITextView can be seen. No matter where the cursor is, the UIScrollView scrolls so that the right hand side of the UITextView is always visible.\nThe UITextView seems to be trying to make itself visible when it is the active control, but it seems to always attempt to \"ScrollToRect\" to its full width, and if the  UITextView is wider than the visible area, the UIScrollView always seems to show the right hand side. I know this because I can turn off my delegate, and the UITextView does scroll into view, but only the right hand side.\nIs this standard behaviour? Ideally I want to turn off whatever mechanism is automatically scrolling the active UITextView into view so that my correct ScrollToRect call will be used instead.\nThanks for any advice you can give.\nCheers.\n",
"AnswerId": "76390184",
"AnswerBody": "Couple options to try...\nFirst, subclass UIScrollView:\nclass MyScrollView: UIScrollView {\n    override func scrollRectToVisible(_ rect: CGRect, animated: Bool) {\n        // don't do anything\n    }\n}\n\nThis will prevent the built-in \"auto-scroll\" when the text view is active.\nSecond option:\n\nEmbed the text view in a \"container scroll view\"\ndisable scrolling of that scroll view\nconstrain the text view to that scroll view's .frameLayoutGuide, so the text view controls the size of the container scroll view\nadd that container scroll view as a subview of your \"content\" view\n\nNow, when the text view is \"active,\" its \"container\" scroll view will receive the auto-scroll messages instead of the \"main\" scroll view.\nIn either case, of course, your code will be responsible for managing any horizontal / vertical scrolling needed to keep the insertion point visible.\n\nEdit\nQuick example for Second Option:\nclass ViewController: UIViewController {\n    \n    override func viewDidLoad() {\n        super.viewDidLoad()\n        \n        let tv = UITextView()\n        let tvsv = UIScrollView()\n        let cv = UIView()\n        let sv = UIScrollView()\n        \n        [tv, tvsv, cv, sv].forEach { v in\n            v.translatesAutoresizingMaskIntoConstraints = false\n        }\n        tvsv.addSubview(tv)\n        cv.addSubview(tvsv)\n        sv.addSubview(cv)\n        view.addSubview(sv)\n        \n        let g = view.safeAreaLayoutGuide\n        let cg = sv.contentLayoutGuide\n        let fg = sv.frameLayoutGuide\n        \n        let tsfg = tvsv.frameLayoutGuide\n        \n        NSLayoutConstraint.activate([\n            \n            tv.topAnchor.constraint(equalTo: tsfg.topAnchor, constant: 0.0),\n            tv.leadingAnchor.constraint(equalTo: tsfg.leadingAnchor, constant: 0.0),\n            tv.trailingAnchor.constraint(equalTo: tsfg.trailingAnchor, constant: 0.0),\n            tv.bottomAnchor.constraint(lessThanOrEqualTo: tsfg.bottomAnchor, constant: 0.0),\n            \n            tv.widthAnchor.constraint(equalToConstant: 600.0),\n\n            tvsv.topAnchor.constraint(equalTo: cv.topAnchor, constant: 20.0),\n            tvsv.leadingAnchor.constraint(equalTo: cv.leadingAnchor, constant: 20.0),\n            tvsv.bottomAnchor.constraint(lessThanOrEqualTo: cv.bottomAnchor, constant: -20.0),\n            \n            tv.widthAnchor.constraint(equalToConstant: 600.0),\n            \n\n            cv.topAnchor.constraint(equalTo: cg.topAnchor, constant: 20.0),\n            cv.leadingAnchor.constraint(equalTo: cg.leadingAnchor, constant: 20.0),\n            cv.trailingAnchor.constraint(equalTo: cg.trailingAnchor, constant: -20.0),\n            cv.bottomAnchor.constraint(equalTo: cg.bottomAnchor, constant: -20.0),\n            \n            cv.widthAnchor.constraint(equalToConstant: 1000.0),\n            \n            sv.topAnchor.constraint(equalTo: g.topAnchor, constant: 20.0),\n            sv.leadingAnchor.constraint(equalTo: g.leadingAnchor, constant: 20.0),\n            sv.trailingAnchor.constraint(equalTo: g.trailingAnchor, constant: -20.0),\n            sv.bottomAnchor.constraint(equalTo: g.bottomAnchor, constant: -20.0),\n            \n        ])\n        \n        tv.isScrollEnabled = false\n        tvsv.isScrollEnabled = false\n\n        // so we can see the framing\n        tv.backgroundColor = .yellow\n        cv.backgroundColor = .systemBlue\n        sv.backgroundColor = .systemRed\n        view.backgroundColor = .systemYellow\n        \n    }\n    \n}\n\nNote: I have not implemented any code for manually handling the scroll view's content offset, which would be needed to keep the insertion point visible. However, this will demonstrate that the \"auto-scroll\" is no longer in effect.\n"
},
{
"QuestionId": "76388754",
"QuestionTitle": "How to get a List of valid currencies from Stripe",
"QuestionBody": "We provide to a bunch of customers a website so that their customers can make a booking and purchase services online using Stripe. I am in the process of Internationalizing but I have hit a barrier where some currencies are not valid for Stripe and we don't find out until we attempt to make the payment. I have tried to find a way of retrieving a list of valid currencies from Stripe so that our software can check against it before offering the option to purchase services and I can't find anything like that.\nDoes anybody know of a solution for automating the process?\nI am curious to hear how other people have tackled this problem.\n",
"AnswerId": "76388863",
"AnswerBody": "You can use country_specs endpoint - https://stripe.com/docs/api/country_specs\nCountrySpecService is available in Stripe.NET and returns this kind of objects (see model below). I think you are looking for SupportedBankAccountCurrencies or SupportedPaymentCurrencies\n// File generated from our OpenAPI spec\nnamespace Stripe\n{\n    using System.Collections.Generic;\n    using Newtonsoft.Json;\n\n    /// <summary>\n    /// Stripe needs to collect certain pieces of information about each account created. These\n    /// requirements can differ depending on the account's country. The Country Specs API makes\n    /// these rules available to your integration.\n    ///\n    /// You can also view the information from this API call as <a\n    /// href=\"https://stripe.com/docs/connect/required-verification-information\">an online\n    /// guide</a>.\n    /// </summary>\n    public class CountrySpec : StripeEntity<CountrySpec>, IHasId, IHasObject\n    {\n        /// <summary>\n        /// Unique identifier for the object. Represented as the ISO country code for this country.\n        /// </summary>\n        [JsonProperty(\"id\")]\n        public string Id { get; set; }\n\n        /// <summary>\n        /// String representing the object's type. Objects of the same type share the same value.\n        /// </summary>\n        [JsonProperty(\"object\")]\n        public string Object { get; set; }\n\n        /// <summary>\n        /// The default currency for this country. This applies to both payment methods and bank\n        /// accounts.\n        /// </summary>\n        [JsonProperty(\"default_currency\")]\n        public string DefaultCurrency { get; set; }\n\n        /// <summary>\n        /// Currencies that can be accepted in the specific country (for transfers).\n        /// </summary>\n        [JsonProperty(\"supported_bank_account_currencies\")]\n        public Dictionary<string, List<string>> SupportedBankAccountCurrencies { get; set; }\n\n        /// <summary>\n        /// Currencies that can be accepted in the specified country (for payments).\n        /// </summary>\n        [JsonProperty(\"supported_payment_currencies\")]\n        public List<string> SupportedPaymentCurrencies { get; set; }\n\n        /// <summary>\n        /// Payment methods available in the specified country. You may need to enable some payment\n        /// methods (e.g., <a href=\"https://stripe.com/docs/ach\">ACH</a>) on your account before\n        /// they appear in this list. The <c>stripe</c> payment method refers to <a\n        /// href=\"https://stripe.com/docs/connect/destination-charges\">charging through your\n        /// platform</a>.\n        /// </summary>\n        [JsonProperty(\"supported_payment_methods\")]\n        public List<string> SupportedPaymentMethods { get; set; }\n\n        /// <summary>\n        /// Countries that can accept transfers from the specified country.\n        /// </summary>\n        [JsonProperty(\"supported_transfer_countries\")]\n        public List<string> SupportedTransferCountries { get; set; }\n\n        [JsonProperty(\"verification_fields\")]\n        public Dictionary<string, Dictionary<string, List<string>>> VerificationFields { get; set; }\n    }\n}\n\nSource: https://github.com/stripe/stripe-dotnet/blob/3d8d1150c9136f3d5b78e8b9b803e858cda5fe53/src/Stripe.net/Entities/CountrySpecs/CountrySpec.cs\n"
},
{
"QuestionId": "76391714",
"QuestionTitle": "symbols in paths in React Router v6",
"QuestionBody": "I'm migrating from v5 to v6. It v6 it seems you can't use regexp anymore. Is there a quick workaround for a path like this? The problem is the dash, of course.\n<Route path=\"/doc/:id-:version\" />\n\n",
"AnswerId": "76391787",
"AnswerBody": "You can't use partial dynamic segments, it's all or nothing. Use a single param and then apply string splitting logic on it in the component.\nExample:\n<Route path=\"/doc/:idVersion\" element={....} />\n\nconst { idVersion } = useParams();\n\nconst [id, version] = idVersion.split(\"-\");\n\nSee Dynamic Segments for more information.\n"
},
{
"QuestionId": "76390107",
"QuestionTitle": "How do you declare that a type belongs to a marker interface?",
"QuestionBody": "If I have these types:\ntype Orange struct {\n  Size float32\n}\n\ntype Lemon struct {\n   Color string\n}\n\ntype Wood struct {\n   Variety string\n}\n\nAnd that interface:\ntype Fruit interface {\n}\n\nHow do I declare that Orange and Lemon are Fruit,\nso that, elsewhere, a function may return only things who are of kind Fruit?\n(Fruit being a marker interface).\n",
"AnswerId": "76390190",
"AnswerBody": "To declare that a type belongs to a marker interface in Go, you need to explicitly state that the type implements the interface. In your case, to declare that Orange and Lemon types are of kind Fruit, you can do the following:\ntype Fruit interface {\n\n}\ntype Orange struct {\nSize float32\n}\nfunc (o Orange) MethodOfFruit() {\n// Implement any methods of Fruit interface if required\n\n}\ntype Lemon struct {\nColor string\n\n}\nfunc (l Lemon) MethodOfFruit()\n{\n// Implement any methods of Fruit interface if required\n\n}\n"
},
{
"QuestionId": "76391509",
"QuestionTitle": "API Mocking - How do I implement request forward while using a Javascript mock?",
"QuestionBody": "I am aware that in a mock server feature file, it is possible to forward requests to a specific endpoint using karate.proceed(): https://karatelabs.github.io/karate/karate-netty/#karateproceed.\nWe recently decided to opt for Javascript mocks, as they enable us to write more complex business logic for simulating the API we consume. Is there out-of-the-box functionality equivalent to karate.proceed() that I can use in a JS mock? Is there a way I can invoke karate.proceed() within this mock? Or is one expected to write Javascript code to enable this functionality?\n",
"AnswerId": "76391791",
"AnswerBody": "Great question, and yes there is no context.proceed(). You need to use context.http() and manually create a new request and handle the response. All the data you need will be on the request object. For example request.method will give you the HTTP method as a string.\nThis is indeed an un-documented part of Karate, yet to become \"mainstream\". Feel free to add a feature request for a context.proceed() that will auto-use the request in scope, that does sound useful. If you could contribute a PR or two that would be awesome :)\n"
},
{
"QuestionId": "76380583",
"QuestionTitle": "vue styling in view does not apply to html",
"QuestionBody": "I have set up a new project with vue3. I started working with some package implementations but then I realized my CSS written in component is not applied in HTML. Here is a very simple view example\n<template>\n  <div>\n    <p class=\"asd\">Hello</p>\n  </div>\n</template>\n\n<style>\n.asd {\n  color: purple;\n}\n</style>\n\nIn the result, the text is not purple.\nI have checked if it is overridden by some other css but no, it does not event show up in the styles screen of dev tools:\n\nWhat I have tried and checked:\n\nI have tried writing style as \"p.asd {...\" and adding an !important in the end. No change.\nI have checked if I am working on the correct page by changing the text from \"Hello\" to \"Hello World\" and it changes, so I am working on the correct page.\nI got a production build if it is a dev env issue, but no, got the same result from the built html.\nI have tried moving CSS to App.vue instead, and surprisingly styling written there works but not in the views.\nI have tried on a new browser for caching issues, no change.\nI have tried adding scoped, no change.\nI have tried adding script tags, no change. Script tags work fine, console.log script works, but still no styling update.\nI have tried inline CSS and it works.\n\nHere is my package.json:\n  \"name\": \"new-project\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"preview\": \"vite preview\",\n    \"lint\": \"eslint . --ext .vue,.js,.jsx,.cjs,.mjs --fix --ignore-path .gitignore\",\n    \"format\": \"prettier --write src/\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"firebase\": \"^9.22.1\",\n    \"pinia\": \"^2.0.36\",\n    \"vue\": \"^3.3.2\",\n    \"vue-router\": \"^4.2.0\",\n    \"vue-tel-input\": \"^8.1.1\"\n  },\n  \"devDependencies\": {\n    \"@rushstack/eslint-patch\": \"^1.2.0\",\n    \"@vitejs/plugin-vue\": \"^4.2.3\",\n    \"@vue/eslint-config-prettier\": \"^7.1.0\",\n    \"eslint\": \"^8.39.0\",\n    \"eslint-plugin-vue\": \"^9.11.0\",\n    \"prettier\": \"^2.8.8\",\n    \"vite\": \"^4.3.5\",\n    \"vite-plugin-webfont-dl\": \"^3.7.4\"\n  }\n}\n\ncodesandbox example: https://codesandbox.io/p/sandbox/github/ihsanser/vue-vite-style-bug/tree/master\nI don't know if I am missing something very simple, but I could not figure out the reason for hours now.\n",
"AnswerId": "76388872",
"AnswerBody": "The space character used in .asd { is not an actual space. It is a NBSP 1.\nReplace it with an actual space and everything will work as expected. This is not related to Vue, the behavior would be the same in React, Angular, Svelte or vanilla.\nSee it working.\nAs a side-note, this shows how important a runnable mcve is. In your question, you posted the code with a space. Not sure if this is due to the NBSP > Space conversion made by the browser when rendering the current page's HTML or if you simply didn't copy/paste the code in question.\nI suspect it's the first.\n\n1 - encoding NBSP outputs %C2%A0, whereas encoding a normal space outputs %20\n"
},
{
"QuestionId": "76390181",
"QuestionTitle": "How to control what classes can extend my class in Java",
"QuestionBody": "So I was asked this question in interview that if I have a class A how do I restrict which classes will be able to extend A. For example if I want only class C and E to be able to extend A and classes B and D should not be able to do so. I mentioned about bounded wildcards in generics but I think that didn't answer the question. I am not aware about any new feature added in newer versions of Java. Please let me know what is the correct answer to that.\n",
"AnswerId": "76390195",
"AnswerBody": "Sealed classes seems to be one method to restrict which classes can extend another. This feature is available since Java 17.\nContraints:\n\nAll permitted subclasses must belong to the same module as the sealed class.\nEvery permitted subclass must explicitly extend the sealed class.\nEvery permitted subclass must define a modifier: final, sealed, or non-sealed.\n\nExample:\npublic abstract sealed class Vehicle permits Car, Truck {...}\n\nThis restricts that only classes Car or Truck can extend Vehicle.\n"
},
{
"QuestionId": "76391528",
"QuestionTitle": "PostgreSQL - Aggregate attributes from different columns recursively",
"QuestionBody": "\n\n\n\nid_start\nid_end\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n4\n\n\n\n\nI want to collect elements who are \"connected\" like [1, 2, 3, 4]. (in an array for example)\nI tried a recursive query like:\nWITH RECURSIVE q_rec AS (\n    SELECT id_start,\n           id_end\n    FROM my_table\n    UNION\n    SELECT t.id_start\n           t.id_end\n    FROM       my_table t\n    INNER JOIN q_rec r ON r.id_start = t.id_end\n) \nSELECT *\nFROM q_rec;\n\nBut how can I aggregate them in an array despite they are not in the same column ?\n",
"AnswerId": "76391798",
"AnswerBody": "Another approach gathers all ids in the recursive query, as a table. Then applies aggregation.\nWITH RECURSIVE cte AS (\n  SELECT id_start AS first_id, \n         id_start AS id\n  FROM tab t1\n  WHERE NOT EXISTS(SELECT 1 FROM tab t2 WHERE t1.id_start = t2.id_end)\n\n  UNION ALL\n\n  SELECT cte.first_id,\n         tab.id_end\n  FROM       cte\n  INNER JOIN tab\n          ON cte.id = tab.id_start\n)\nSELECT first_id, \n       ARRAY_AGG(id) AS ids\nFROM cte\nGROUP BY first_id\n\nOutput:\n\n\n\n\nfirst_id\nids\n\n\n\n\n1\n[1,2,3,4]\n\n\n\n\nCheck the demo here.\n"
},
{
"QuestionId": "76388802",
"QuestionTitle": "Does overloading the new operator in C++ redefine the operator?",
"QuestionBody": "When overloading the new operator in a global scope in C++, are we just redefining the original functionality? From what I understand operator and function overloading works when the overloads have different signatures, however when overloading new operator using\nvoid* operator new(size_t n){\n    return malloc(n);\n}\n\nwe change the underlying functionality itself and whenever we call new this new overload is called? Does this not violate the idea of overloads having different and unique signatures?\nI tried overloading the new array operator with extra parameters and how that works is consistent with my current understanding of operator/function overloads. However overloading the new operator and new array operator with just one parameter is where I'm confused.\n",
"AnswerId": "76388888",
"AnswerBody": "operator new is replacable (from cppreference, same link):\n\nThe versions (1-4) are implicitly declared in each translation unit even if the  header is not included. Versions (1-8) are replaceable: a user-provided non-member function with the same signature defined anywhere in the program, in any source file, replaces the default version. Its declaration does not need to be visible.\n\nThis is not the usual function overloading. You cannot overload a function with same signature. Overloads must be distinguishable by their arguments. Nevertheless, colloquially one often talks about \"overloading the new operator\" which is ok in the wider sense of \"overloading\", but in strict c++ terminology not right.\n"
},
{
"QuestionId": "76389588",
"QuestionTitle": "Oracle partition / archive strategy for type 2 dimension table",
"QuestionBody": "I have a really wide table in Oracle that's at type 2 dimension.\nRecords have from_dates and to_dates with the latest 'current' records having a high end date of 31st Dec 9999.  There are currently two partitions on the table, one for the 'current' records and one for 'history' records.\nThere's a new requirement to only keep the last 12 months of records in the 'history' partition. I interpret this as keeping records that were valid in the last 12 months i.e. where the record's to_date < (this month- 11 months).\nNormally if I wanted to get rid of records I'd just drop a partition, but in this case that wouldn't work as I need to retain some of the records in the existing 'history' partition.\nIs there any partitioning strategy that could support this or am I barking up the wrong tree?\n",
"AnswerId": "76390201",
"AnswerBody": "You aren't accomplishing much with merely two partitions, \"current\" and \"history\". You need to repartition this by month. Then you can implement a rolling partition drop of partitions older than 12 months, which will require a bit of scripting.\nNormally we use interval partitioning INTERVAL(NUMTOYMINTERVAL(1,'MONTH')) so we don't have to maintain partition adds manually or through scripting. However, unfortunately in your case you won't be able to because of your use of the special date 12/31/9999. This is the maximum date allowable in Oracle. Interval partitioning will internally add the interval to date values when determining whether a new partition is needed or not, and that will overflow the maximum date value allowed and raise an error. The use of this special date essentially disables the use of interval partitioning.\nYou have no choice but to either change your special \"eternity\" date to something less than one interval away from 12/31/9999 (anything less than 12/01/9999 would permit monthly interval partitioning, or anything less than 12/31/9998 would permit yearly interval partitioning). Or, as usually happens because code would have to be changed to accommodate these solutions, you have to manually build out partitions ahead of time or create a scheduled script that does it for you.\n"
},
{
"QuestionId": "76391632",
"QuestionTitle": "How to find the matching element in a list from different list? in C#",
"QuestionBody": "How to find the matching element in array from different array? in  C#\nI have different varities of products and dynamically created attributes of every variety\npublic class SingleVariety\n    {\n        [JsonProperty(\"varietyId\")]\n        public int VarietyId { get; set; }\n\n        [JsonProperty(\"varietyName\")]\n        public string VarietyName { get; set; }\n\n        [JsonProperty(\"sku\")]\n        public string Sku { get; set; }\n\n        public List<SingleAttribute> Attributes { get; set; }= new List<SingleAttribute>();\n\n    }\n\n   public class SingleAttribute\n    {\n\n        [JsonProperty(\"attributeName\")]\n        public string AttributeName { get; set; }\n\n        [JsonProperty(\"attributeValue\")]\n        public string AttributeValue { get; set; }\n\n        [JsonProperty(\"varietyId\")]\n        public int VarietyId { get; set; }\n\n    }\n\n\nand I have a filter array and trying to determine the selected variety based on the selection of attributes\nsample variety model\n\n var varities = new List<SingleVariety>() { \n                new SingleVariety { \n                    Sku=\"testsku\", VarietyId=1, VarietyName=\"test 1\", \n                Attributes = new List<SingleAttribute> \n                { new SingleAttribute { AttributeName = \"Size\", AttributeValue=\"Large\" },\n                    new SingleAttribute{ AttributeName = \"Color\", AttributeValue = \"Red\"} \n                }},\n                new SingleVariety {\n                    Sku=\"testsku2\", VarietyId=2, VarietyName=\"test 2\",\n                Attributes = new List<SingleAttribute>\n                { new SingleAttribute { AttributeName = \"Size\", AttributeValue=\"Small\" },\n                    new SingleAttribute{ AttributeName = \"Color\", AttributeValue = \"Red\"}\n                }},\n                new SingleVariety {\n                    Sku=\"testsku3\", VarietyId=3, VarietyName=\"test 3\",\n                Attributes = new List<SingleAttribute>\n                { new SingleAttribute { AttributeName = \"Size\", AttributeValue=\"Very Large\" },\n                    new SingleAttribute{ AttributeName = \"Color\", AttributeValue = \"Black\"}\n                }}\n\n            };\n\n\nsample filter array\n var filterObject = new List<SingleAttribute> { \n                new SingleAttribute { AttributeName = \"Size\", AttributeValue=\"Large\" },\n            new SingleAttribute{ AttributeName = \"Color\", AttributeValue = \"Red\"} \n            };\n\nvariety with variety id 1 should be found because the filter object contains size=large, and color=red anyone can help me this?\nI have used predicates, linq but I was not successfull\n",
"AnswerId": "76391801",
"AnswerBody": "One (flexible) way of doing this would be to chain your queries:\n//Start with the whole set\nvar results = (IEnumerable<SingleVariety>)varities;\n\nfor (int i = 0; i < filterObject.Count; i++)\n{\n    var filter = filterObject[i];\n    //Refine with each attribute match\n    results = results.Where(i => i.Attributes.FirstOrDefault(a => a.AttributeName == filter.AttributeName)?.AttributeValue == filter.AttributeValue);\n}\n\nIf we inspect the output:\nConsole.WriteLine($\"Count: {results.Count()}\");\nforeach (var result in results)\n{\n    Console.WriteLine($\"Name: {result.VarietyName}, Id: {result.VarietyId}\");\n}\n\nWe get the following:\nCount: 1\nName: test 1, Id: 1\n\nWe cast it to the IEnumerable<SingleVariety> interface so that the chaining can work since the Linq methods will return that type.\nA couple of things worth noting is that this will support any number of filters but it will be an and operation.\nTechnically, you don't need the filter variable. You could just do it inline but I like to write code this way for clarity.\n"
},
{
"QuestionId": "76389895",
"QuestionTitle": "The UI theme state is not updating until I resave the code while using flutter_riverpod stateprovider",
"QuestionBody": "I need to change the Theme using stateprovider of flutter riverpod ,I dont understand what i did wrong here\nvoid main() {\n  WidgetsFlutterBinding.ensureInitialized();\n  runApp(const ProviderScope(child: MyApp()));\n}\n\nclass MyApp extends ConsumerWidget {\n  const MyApp({super.key});\n  @override\n  Widget build(BuildContext context, WidgetRef ref) {\n    final isDarkTheme = ref.watch(isDarkThemeProvider.notifier).state;\n\n    return GestureDetector(\n      onTap: () {\n        FocusScope.of(context).unfocus();\n      },\n      child: ScreenUtilInit(\n        designSize: const Size(360, 690),\n        minTextAdapt: true,\n        splitScreenMode: true,\n        builder: (context, child) {\n          return MaterialApp(\n              builder: FToastBuilder(),\n              debugShowCheckedModeBanner: false,\n              title: 'code',\n              theme: isDarkTheme ? Themes().darkTheme : Themes().lightTheme,\n              onGenerateRoute: onAppGenerateRoute(),\n              routes: appRoutes(),\n              initialRoute: SplashPage.route);\n        },\n      ),\n    );\n  }\n}\n\nthis is my theme  class and theme stateprovider\nimport 'package:flutter/material.dart';\nimport 'package:flutter_riverpod/flutter_riverpod.dart';\nimport 'package:tr_qr_code/utils/colors.dart';\n\nclass Themes {\n  final ThemeData lightTheme = ThemeData(\n    scaffoldBackgroundColor: colorWhite,\n    splashColor: Colors.transparent,\n    highlightColor: Colors.transparent,\n    appBarTheme: const AppBarTheme(color: colorWhite),\n    fontFamily: 'OpenSans',\n    useMaterial3: true,\n  );\n\n  final ThemeData darkTheme = ThemeData(\n    scaffoldBackgroundColor: colorBlack,\n    splashColor: Colors.transparent,\n    highlightColor: Colors.transparent,\n    appBarTheme: const AppBarTheme(color: colorBlack),\n    fontFamily: 'OpenSans',\n    useMaterial3: true,\n  );\n}\n\nfinal isDarkThemeProvider = StateProvider<bool>((ref) => false);\n\non the toggle switch inside the onTap the below code is used to update the state\nonTap: () {\n    \n              ref.read(isDarkThemeProvider.notifier).update(\n                  (state) => !ref.read(isDarkThemeProvider.notifier).state);\n            },\n\ni tried flutter clean, flutter pub upgrade etc ..\n",
"AnswerId": "76390260",
"AnswerBody": "Inside of MyApp class it should be\nfinal isDarkTheme = ref.watch(isDarkThemeProvider);\nAnd alternatively, inside your onTap you can toggle value like this:\nonTap: () {\n                ref\n                    .read(isDarkThemeProvider.notifier)\n                    .update((state) => !state);\n          },\n\n"
},
{
"QuestionId": "76388828",
"QuestionTitle": "Why does initializing a negatively-sized array cause an overflow exception?",
"QuestionBody": "I was unit testing in C#, and I found the following code gives an overflow exception:\nusing System;\n                    \npublic class Program\n{\n    public static void Main()\n    {\n        int i = 0;\n        Console.WriteLine(new float[i - 1]);\n        // System.OverflowException: Arithmetic operation resulted in an overflow.\n    }\n}\n\nhttps://dotnetfiddle.net/clbgZ3\nHowever, if you explicitly attempt to initialize a negative array, you get the following error:\nConsole.WriteLine(new float[-1]);\n// Compilation error: Cannot create an array with a negative size\n\nWhy does initializing a negatively-sized array cause an overflow exception, and not a different type of error?\n",
"AnswerId": "76388921",
"AnswerBody": "This behaviour is explicitly specified in C# language specification, section 12.8.16.5\n\nThe result of evaluating an array creation expression is classified as\na value, namely a reference to the newly allocated array instance. The\nrun-time processing of an array creation expression consists of the\nfollowing steps:\n(...)\n\nThe computed values for the dimension lengths are validated, as follows: If one or more of the values are less than zero, a\nSystem.OverflowException is thrown and no further steps are executed.\n\n\n(emphasis mine)\n"
},
{
"QuestionId": "76390204",
"QuestionTitle": "how to use min-height, aspect-ratio, ... with container queries?",
"QuestionBody": "I am currently struggling with container queries. As long as I just use min-width and max-width everything is fine and works well. As soon as I try to use logic operators like and/or it doesn´t work anymore.\n\n\n.wrapper {\n  width: 300px;\n  container-name: wrapper;\n  container-type: inline-size;\n}\n\n.box {\n  background-color: #0000ff;\n  color: #ffffff;\n  width: 100px;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n@container wrapper (min-width: 300px) {\n  .box {\n    background-color: #00ff00;\n  }\n}\n\n@container wrapper (min-width: 300px) and (min-height: 0px) {\n  .box {\n    background-color: #ff0000;\n  }\n}\n<div class=\"wrapper\">\n  <div class=\"box\">\n    <span>test</span>\n  </div>\n</div>\n\n\n\nSee the codepen here: https://codepen.io/Resolver1412/pen/dygxWKY\nI would expect that the box would become red instead of green. Since the last container query would overwrite the previous one.\nAnyone knows whats wrong or what might have happened? I currently use this chrome version: Version 112.0.5615.121\n",
"AnswerId": "76390266",
"AnswerBody": "According to the docs:\n\nThe inline-size CSS property defines the horizontal or vertical size\nof an element's block, depending on its writing mode. It corresponds\nto either the width or the height property, depending on the value of\nwriting-mode.\n– inline-size | MDN Web Docs\n\nIn your example, since writing-mode has the default value of horizontal-tb, only width is usable in @container queries.\nYou can switch to container-type: size to use both inline and block size in queries:\n.wrapper {\n  width: 300px;\n  height: 60px;\n  container-name: wrapper;\n  container-type: size;\n}\n\n@container wrapper (width >= 300px) and (height >= 0px) {\n  .box {\n    background-color: #ff0000;\n  }\n}\n\nTry it:\n\n\n.wrapper {\n  width: 300px;\n  height: 60px;\n  container-name: wrapper;\n  container-type: size;\n}\n\n.box {\n  background-color: #0000ff;\n  color: #ffffff;\n  width: 100px;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n@container wrapper (width >= 300px) {\n  .box {\n    background-color: #00ff00;\n  }\n}\n\n@container wrapper (width >= 300px) and (height >= 0px) {\n  .box {\n    background-color: #ff0000;\n  }\n}\n<div class=\"wrapper\">\n  <div class=\"box\">\n    <span>test</span>\n  </div>\n</div>\n\n\n\nOr, you can use aspect-ratio instead of width and height:\n@container wrapper (aspect-ratio > 1 / 2) {\n  .box {\n    background-color: #ff0000;\n  }\n}\n\nTry it:\n\n\n.wrapper {\n  container-name: wrapper;\n  container-type: size;\n}\n\n.box {\n  background-color: #0000ff;\n  color: #ffffff;\n  width: 100px;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n@container wrapper (width >= 300px) {\n  .box {\n    background-color: #00ff00;\n  }\n}\n\n@container wrapper (aspect-ratio > 1 / 2) {\n  .box {\n    background-color: #ff0000;\n  }\n}\n<div class=\"wrapper\">\n  <div class=\"box\">\n    <span>test</span>\n  </div>\n</div>\n\n\n\n"
},
{
"QuestionId": "76391160",
"QuestionTitle": "Does it make a difference to pass a pointer to a pointer as an argument or simply pass the first pointer?",
"QuestionBody": "I'm sorry if this sounds vague or idiotic, but consider the following:\nif I have a main function like so:\nint main(void)\n{\n   int red_wins = 0;\n  game_loop(&red_wins); \n  // code \n  printf(\"red has %d wins\\n\", red_wins); \n} \n\nthen have a a game_loop function which calls another function that uses red_wins:\nvoid game_loop(int *red_wins)\n{\n  // code \n  particle_move(red_wins);\n}\n\nand then another function called particle_move which uses this red_wins variable:\nvoid particle_move(int *red_wins) \n{\n  // code \n  if (such and such)\n  {\n    *red_wins+= 10; \n  } \n}\n\nwhere red_wins is only modified in the particle_move function and particle_move is only called from the game_loop function, would it be better to do it as shown above or by passing a pointer to a pointer in the particle_move function? Or, but I've been told it's bad practice, by using a global variable red_wins? Or is there another, better, way that I've overlooked?\n",
"AnswerId": "76391823",
"AnswerBody": "You only need to pass a pointer to pointer in the following situations:\n\nWhere the called function is updating the pointer value, not the thing being pointed to:void update( T **p )\n{\n  *p = new_TStar_value();\n}\nint main( void )\n{\n  T *var;\n  update( &var ); // updates var\n}\n\nWhere the pointer is pointing to the first in a sequence of pointers:void foo( int **p )\n{\n  // do something interesting\n}\nint main( void )\n{\n  int **p = malloc( sizeof *p * ROWS );\n  if ( p )\n  {\n    for ( size_t i = 0; i < ROWS; i++ )\n      p[i] = malloc( sizeof *p[i] * COLS )\n  }\n  foo( p );\n  return 0;\n}\n\nIn your case, particle_move is updating the same thing that game_loop is updating, so you don't need to add another layer of indirection.  You're doing it right, here.\n"
},
{
"QuestionId": "76388620",
"QuestionTitle": "Connect 2 Docker images for label-studio",
"QuestionBody": "I'm on Windows, I try to run label-studio on a docker-img and enable automatic annotations with a tesseract machine learning model provided from label-studio-ml-backend on another docker-img. (I'm discovering docker these days...)\nSet up:\nSo far I was able to launch a docker with label-studio, and a docker with tesseract:\n# Run the label-studio\ndocker run --name lbl-studio -it -p 8080:8080 -v label-studio-data:/label-studio/data/ heartexlabs/label-studio:latest label-studio\n\n# DL and run tesseract image\ngit clone https://github.com/heartexlabs/label-studio-ml-backend\ncd label-studio-ml-backend/label_studio_ml/examples/tesseract/\ndocker-compose up\n\nAt this point I have 2 images running on docker (or 3/4, I don't really know how to interpret the 'tesseract' image)\n\nNetwork:\nHere are some network info I could gather, I don't know how bas is the fact that lbl-studio is on 172.17 and the two others on 172.18...\n\n# Get ips of images \ndocker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' server # 172.18.0.3\ndocker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' redis  # 172.18.0.2\ndocker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' lbl-studio  # 172.17.0.2\n# server: 172.18.0.3\n# redis: 172.18.0.2\n# lbl-studio: 172.17.0.2\n\nso far redis can ping server but can't ping lbl-studio\nProblem:\nBut, when I go to http://127.0.0.1:8080/, create a project, and try to link the machine learning wizard (http://127.0.0.1:8080/projects/1/settings/ml > add model), I'm not able to connect the tesseract server to the lbl-studio.\nThe urls I tried to connect are:\n\nhttp://127.0.0.1:9090/\nhttp://172.18.0.3:9090/\n\nGoing Further:\nI tried to dig deepper and ping the server from lbl-studio, but nothing happened\ndocker exec -it --user root lbl-studio /bin/bash\napt update\napt install iputils-ping\nping 127.18.0.3  # Nothing happening: 100% packet loss ;)\n\nQuestion:\nHow can I connect lbl-studio to the server ?\nThank you for your help :)\n",
"AnswerId": "76388953",
"AnswerBody": "Add lbl-studio to tesseract's docker-compose file as third service. For connect from computer to services use http://127.0.0.1:9090 and http://127.0.0.1:9090. To connect between tesseract and lbl-studio use services name:  http://lbl-studio:8080 and http://server:9090. Example:\nversion: \"3.8\"\n\nservices:\n  redis:\n    image: redis:alpine\n    container_name: redis\n    hostname: redis\n    volumes:\n      - \"./data/redis:/data\"\n    expose:\n      - 6379\n  server:\n    container_name: server\n    build: .\n    environment:\n      - MODEL_DIR=/data/models\n      - RQ_QUEUE_NAME=default\n      - REDIS_HOST=redis\n      - REDIS_PORT=6379\n    ports:\n      - 9090:9090\n    depends_on:\n      - redis\n    links:\n      - redis\n    volumes:\n      - \"./data/server:/data\"\n      - \"./logs:/tmp\"\n\n  lbl-studio:\n   image: heartexlabs/label-studio:latest\n   ports:\n    - 8080:8080\n   volumes: \n    - label-studio-data:/label-studio/data/\n\nvolumes:\n  label-studio-data:\n\n"
},
{
"QuestionId": "76391465",
"QuestionTitle": "How to start from example diverging REST interface?",
"QuestionBody": "In the uvicorn exmaple, one writes uvicorn filename:attributename and by that start the server. However, the interface I have generated has no such method attributename in filename. Therefore, I am unsure what to pass as attributename.\nGenerated code in main.py\n\"\"\"\n    Somename\n\n    Specification for REST-API of somename.\n\n    The version of the OpenAPI document: 1.0.0\n    Generated by: https://openapi-generator.tech\n\"\"\"\nfrom fastapi import FastAPI\nfrom openapi_server.apis.some_api import router as SomeApiRouter\n\napp = FastAPI(\n    title=\"SomeName\",\n    description=\"Specification for REST-API of somename\",\n    version=\"1.0.0\",\n)\n\napp.include_router(SomeApiRouter)\n\n",
"AnswerId": "76391838",
"AnswerBody": "The attribute name that you should specify is the name of the variable that holds your FastAPI instance. As they say in the docs:\n\nThe ASGI application should be specified in the form path.to.module:instance.path.\n\nIn this case for you, it would be uvicorn main:app where main.py is the file your code is in and app is the name of the variable in that file that holds your FastAPI instance.\n"
},
{
"QuestionId": "76390244",
"QuestionTitle": "Trying to clear kivymd MDList",
"QuestionBody": "Trying to clear an MDList\nNew and trying to learn :)\nI have a simple gui using kivy and kivymd.\none button adds a list of TwoLineListItem's\nand i would like the other button to clear the previously generated list.\nthe idea is for one button to add the list, the other button to clear it\nso i can populate the list and clear it over and over but by clicking the relevant buttons.\n.py file code -\nfrom kivy.app import App\nfrom kivymd.app import MDApp\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.widget import Widget\nfrom kivy.properties import ObjectProperty\nfrom kivy.lang import Builder\nfrom kivy.uix.gridlayout import GridLayout\nfrom kivymd.uix.list import TwoLineListItem\n\n#designate our kv design file\nBuilder.load_file('shd_proto_kv_cfg.kv')\n\n\nclass Search(TwoLineListItem):\n    pass\n\n\nclass MyLayout(BoxLayout):\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def add_entries(self):\n        for x in range(0, 10):\n            item = Search()\n            self.ids.List.add_widget(item)\n\n    def rem_entries(self):\n        self.ids.List.remove_widget()\n        pass\n\n\nclass ShdApp(MDApp):\n    def build(self):\n        return MyLayout()\n\n\nif __name__ == '__main__':\n    ShdApp().run()\n\n.kv file code -\n<Search>:\n    text: \"Title\"\n    secondary_text: \"Description\"\n\n<MyLayout>:\n    orientation: \"horizontal\"\n    padding: 25\n    spacing: 10\n\n    BoxLayout:\n        orientation: \"vertical\"\n\n\n\n        Label:\n            text: \"Marker01\"\n            font_size: 25\n            background_color: (196/255, 140/255, 96/255, 1)\n            canvas.before:\n                Color:\n                    rgba: self.background_color\n                Rectangle:\n                    size: self.size\n                    pos: self.pos\n\n        Button:\n            text: \"add em\"\n            on_press: root.add_entries()\n\n        Button:\n            text: \"clear em\"\n            on_press: root.rem_entries()\n\n    BoxLayout:\n        orientation: \"vertical\"\n        cols: 1\n\n        ScrollView:\n            MDList:\n                id: List\n\nthe error i get from running the above code -\nTypeError: Layout.remove_widget() missing 1 required positional argument: 'widget'\nas mentioned i would like to populate with one button and clear with the other\nand be able to populate, clear, populate, clear.\nim stuck on this and i do feel its my lack of understanding as a learner thats holding me back\ncan someone please help me with this code so i can get it working and play around to understand it better?\neventually i will repurpose it into my first project but i need some help understanding where im going wrong here lol\nThanks!\n",
"AnswerId": "76390337",
"AnswerBody": "Use:\nself.ids.List.clear_widgets()\n\ninstead of:\nself.ids.List.remove_widget()\n\nThe clear_widgets() method removes all the children of the object. The remove_widget() method removes just one child (and that child must be specified).\n"
},
{
"QuestionId": "76390299",
"QuestionTitle": "R tapply : how to use INDEX names as a FUN additional argument?",
"QuestionBody": "I would like to use the names of the INDEX factor in my FUN function in tapply.\nMy data and function are more complex but here is a simple reproducible example :\ndata <- data.frame(x <- c(4,5,6,2,3,5,8,1), \n                   name = c(\"A\",\"B\",\"A\",\"B\",\"A\",\"A\",\"B\",\"B\"))\nmyfun <- function(x){paste(\"The mean of NAME is \", mean(x))}\ntapply(data$x, data$name, myfun)\n\nResult :\n                         A                          B \n\"The mean of NAME is  4.5\"   \"The mean of NAME is  4\" \n\nWhere I would like NAME to be A or B.\n",
"AnswerId": "76390358",
"AnswerBody": "One option would be to pass both the value and and the index column to your function:\ndata <- data.frame(\n  x = c(4, 5, 6, 2, 3, 5, 8, 1),\n  name = c(\"A\", \"B\", \"A\", \"B\", \"A\", \"A\", \"B\", \"B\")\n)\n\nmyfun <- function(x) {\n  sprintf(\"The mean of %s is %f\", unique(x[[2]]), mean(x[[1]]))\n}\n\ntapply(data[c(\"x\", \"name\")], data$name, myfun)\n#>                           A                           B \n#> \"The mean of A is 4.500000\" \"The mean of B is 4.000000\"\n\n"
},
{
"QuestionId": "76388795",
"QuestionTitle": "Incrementing/Decrementing a number using checkbox",
"QuestionBody": "In my code, I need to add the value of the specific checkbox that has been checked to the span element. The problem is it's first clicks of the checkbox, the calculation goes wrong.\nAs you can see, if you click a checkbox for the first time, it substract the value instead of adding it. Is there something I forgot to add? My code is listed below. Thank you in advance\n\n\nconst s = document.querySelectorAll('#enroll-subject');\n        const cue = document.getElementById('cu');\n        let cu = parseInt(cue.textContent.replace('Current Units: ', '').trim());\n        s.forEach(cb => {\n          cb.addEventListener('change', updateTotalUnits);\n        });\n        function updateTotalUnits() {\n          let totalUnits = cu;\n          s.forEach(cb => {\n            if (cb.checked) {\n              console.log(\"checked\");\n              totalUnits += parseInt(cb.value);\n            } else {\n              console.log(\"not checked\");\n              totalUnits -= parseInt(cb.value);\n            }\n          });\n          cue.innerHTML = `Current Units: ${totalUnits}`;\n        }\n    <div class=\"irreg-container\" style=\"display:flex; flex-direction:column; text-align: center;\">\n      <div class=\"header\" style=\"display:flex; flex-direction:column;\">\n        <span style=\"padding: 1em;\" id=\"cu\">Current Units: 15</span>\n        <span style=\"padding: .7em;font-size:1.3em;\">Checkboxes</span>\n      </div>\n      <div class=\"subjects\" style=\"display:flex; flex-direction: column;\">\n\n      <table>\n        <tbody>\n          <tr>\n            <td style=\"width: 100%;\">Checkbox 1</td>\n            <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n            </td>\n          </tr>\n          <tr>\n            <td style=\"width: 100%;\">Checkbox 2</td>\n            <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n            </td>\n         </tr>\n         <tr>\n           <td style=\"width: 100%;\">Checkbox 3</td>\n           <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n           </td>\n         </tr>\n         <tr>\n           <td style=\"width: 100%;\">Checkbox 4</td>\n           <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n         </td>\n         </tr>\n       </tbody>\n     </table>\n     <div class=\"button-container\" style=\"text-align: center;\">\n       <button class=\"submit\"> Submit </button>\n     </div>\n   </div>\n </div>\n\n\n\n",
"AnswerId": "76388962",
"AnswerBody": "It makes no sense that you are looping over all checkboxes each time, and then subtract the value of those that are not checked - because you never added the values of those in the first place.\nJust keep working with the current cu value, and then either add or subtract the value of the currently changed checkbox only.\n\n\nconst s = document.querySelectorAll('#enroll-subject');\nconst cue = document.getElementById('cu');\nlet cu = parseInt(cue.textContent.replace('Current Units: ', '').trim());\ns.forEach(cb => {\n  cb.addEventListener('change', updateTotalUnits);\n});\n\nfunction updateTotalUnits() {\n  if (this.checked) {\n    console.log(\"checked\");\n    cu += parseInt(this.value);\n  } else {\n    console.log(\"not checked\");\n    cu -= parseInt(this.value);\n  }\n  cue.innerHTML = `Current Units: ${cu}`;\n}\n<div class=\"irreg-container\" style=\"display:flex; flex-direction:column; text-align: center;\">\n  <div class=\"header\" style=\"display:flex; flex-direction:column;\">\n    <span style=\"padding: 1em;\" id=\"cu\">Current Units: 15</span>\n    <span style=\"padding: .7em;font-size:1.3em;\">Checkboxes</span>\n  </div>\n  <div class=\"subjects\" style=\"display:flex; flex-direction: column;\">\n\n    <table>\n      <tbody>\n        <tr>\n          <td style=\"width: 100%;\">Checkbox 1</td>\n          <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n          </td>\n        </tr>\n        <tr>\n          <td style=\"width: 100%;\">Checkbox 2</td>\n          <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n          </td>\n        </tr>\n        <tr>\n          <td style=\"width: 100%;\">Checkbox 3</td>\n          <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n          </td>\n        </tr>\n        <tr>\n          <td style=\"width: 100%;\">Checkbox 4</td>\n          <td style=\"width: 100%;\"><input class=\"sbj-checkbox\" type=\"checkbox\" name=\"enroll-subject\" value=\"4\" id=\"enroll-subject\">\n          </td>\n        </tr>\n      </tbody>\n    </table>\n    <div class=\"button-container\" style=\"text-align: center;\">\n      <button class=\"submit\"> Submit </button>\n    </div>\n  </div>\n</div>\n\n\n\n"
},
{
"QuestionId": "76391373",
"QuestionTitle": "SQL window function and (date+interval) as a border of range",
"QuestionBody": "Is there any way to use hard borders for RANGE?\nThe correct code is:\nSELECT user_id,\n       created_at,\n       COUNT(*) OVER (ORDER BY created_at \n                      RANGE BETWEEN '30 days' PRECEDING \n                                AND '30 days' FOLLOWING) AS qty_in_period\n\nBut this sample is wrong:\nSELECT user_id,\n       created_at,\n       COUNT(*) OVER (ORDER BY created_at \n                      RANGE BETWEEN UNBOUNDED PRECEDING \n                                AND (reg_date+interval) FOLLOWING) AS qty_in_period\n\nreg_date is timestamp type, interval is '1 month'.\nI know, it can be done with WHERE construction but I need to check possibility to do it via window function.\nPlease help.\n",
"AnswerId": "76391893",
"AnswerBody": "\nIs there any way to use hard borders for RANGE?\n\nNo. The documentation is explicit about it:\n\nIn the offset PRECEDING and offset FOLLOWING frame options, the offset must be an expression not containing any variables, aggregate functions, or window functions.\n\nAttempting to use such syntax raises the following error:\n\nERROR:  argument of RANGE must not contain variables\n\nOne alternative uses a correlated subquery, or lateral join. The last query in your example could be written as:\nselect user_id, created_at, x.*\nfrom mytable t\ncross join lateral (\n    select count(*) qty_in_period\n    from mytable t1\n    where t1.created_at <= t.created_at + t.intval\n) x\n\n"
},
{
"QuestionId": "76390309",
"QuestionTitle": "Algorithm question - Stack and Queue - easy",
"QuestionBody": "Here's an easy algorithm question about stack and queue, could anyone please help me to look at what's wrong with my code?\nImplement a queue with two stacks. The declaration of the queue is as follows. Implement its two functions appendTail and deleteHead, which perform the functions of inserting an integer at the end of the queue and deleting an integer at the head of the queue, respectively. (If there are no elements in the queue, the deleteHead operation returns -1 )\ntext\nclass CQueue(object):\n\n    def __init__(self) -> None:\n        self.__stackA = [] \n        self.__stackB = [] \n\n    def appendTail(self, val: int) -> None:\n        self.__stackA.append(val)\n    \n    def deleteHead(self) -> int:\n        if self.__stackB == 0:\n            if self.__stackA == 0:\n                return -1\n            else:\n                self.__stackB.append(self.__stackA.pop())\n                return self.__stackB.pop()\n        else:\n            return self.__stackB.pop()\n\nMy code is above. I tried to separate the situation into: 1) B = 0, A = 0 (returns -1); 2) B = 0, A != 0 (transferring the elements from A to B), and 3) B != 0 (directly popping the front element)\nThe correct input and output should be:\ninput:\n[\"CQueue\",\"appendTail\",\"deleteHead\",\"deleteHead\",\"deleteHead\"] [[],[3],[],[],[]]\noutput:\n[null,null,3,-1,-1]\nThank you for paying attention to the question and would be appreciated if you could help.\n",
"AnswerId": "76390403",
"AnswerBody": "There are two issues:\n\nComparing a list with 0 is not really useful, as that will never be true. To test whether a list is empty, you can use the not self.__stackA or len(self.__stackA) == 0, or a combination of the two.\n\nWhen stack B is empty, but stack A has values, you should not transfer one element from the top of stack A to stack B, but should transfer all its elements, so that the element that was at the bottom of stack A gets to be the top element of stack B.\n\n\nWith those two remarks taken care of, your code would look like this:\nclass CQueue(object):\n\n    def __init__(self) -> None:\n        self.__stackA = [] \n        self.__stackB = [] \n\n    def appendTail(self, val: int) -> None:\n        self.__stackA.append(val)\n    \n    def deleteHead(self) -> int:\n        if not self.__stackB:  # don't compare with 0\n            if not self.__stackA:\n                return -1\n            else:\n                while self.__stackA:  # Transfer ALL elements\n                    self.__stackB.append(self.__stackA.pop())\n                return self.__stackB.pop()\n        else:\n            return self.__stackB.pop()\n\nYou can also avoid some duplication of code:\n    def deleteHead(self) -> int:\n        if not self.__stackB:\n            while self.__stackA:\n                self.__stackB.append(self.__stackA.pop())\n            if not self.__stackB:  # Still nothing there...\n                return -1\n        return self.__stackB.pop()  # Common action when there is data\n\nRemark: I would have expected the stacks to be created with a specific class, because when you create them as standard lists, there is no reason why you could do non-stacky things with them, like reversing them, etc, which obviously is not to be allowed in this challenge.\n"
},
{
"QuestionId": "76389693",
"QuestionTitle": "Apply effect of button as per the attached screemshot on hover",
"QuestionBody": "Here i attached the screenshot of the button when on hover take a effect like.\nhttps://prnt.sc/xJSqNRU-IqdQ\nI am try with skew effect but it doesnt work. I am also trying with skew effect but this doesn't work with button here. Let me provide the solution here.\n\n\n.skew-button {\n  display: inline-block;\n  padding: 10px 20px;\n  background-color: #333;\n  color: #fff;\n  border: none;\n  font-size: 16px;\n  transition: all 0.3s;\n  position: relative;\n  overflow: hidden;\n}\n\n.skew-button:before {\n  content: \"\";\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  background-color: red;\n  transform-origin: top left;\n  transform: skewX(-20deg);\n  transition: all 0.3s;\n  z-index: -1;\n  opacity: 0;\n}\n\n.skew-button:hover {\n  background-color: red;\n}\n\n.skew-button:hover:before {\n  left: -100%;\n  opacity: 1;\n  transform-origin: top right;\n  transform: skewX(0deg);\n}\n<button class=\"skew-button\">Hover Me</button>\n\n\n\n",
"AnswerId": "76390406",
"AnswerBody": "The easiest way to do this, that I can think of, is the following. There are explanatory comments in the code:\n\n\n/* simple reset to remove default margins and padding, and to\n   force all browsers to use the same algorithm for sizing\n   elements: */\n*,\n::before,\n::after {\n  box-sizing: border-box;\n  margin: 0;\n  padding: 0;\n}\n\nbody {\n  background-image: radial-gradient(circle at 0 0, currentColor, slategray);\n  block-size: 100vh;\n}\n\nmain {\n  /* to take all available space on the block-axis: */\n  block-size: 100%;\n  /* just an easy means of centering the content\n     visually, in both the block and inline axes: */\n  display: grid;\n  place-content: center;\n}\n\nbutton {\n  /* overriding the default background-color of the\n     <button> element: */\n  background-color: transparent;\n  /* removing the default border: */\n  border: 0 none transparent;\n  font-size: 2rem;\n  /* creates a stacking context so that the pseudo-\n     elements are positioned \"within\" this element\n     and can't be positioned \"behind,\" or lower-than,\n     the <button>: */\n  isolation: isolate;\n  padding-block: 1em;\n  padding-inline: 2em;\n  /* in order to position the pseudo-elements in\n     relation to this element: */\n  position: relative;\n}\n\nbutton::before,\nbutton::after {\n  /* custom CSS property for consistency across\n     the demo: */\n  --offset: 2em;\n  /* setting the background-color of both\n     pseudo-elements to the --background CSS\n     custom property (this is declared later)\n     or to the default color of white (#fff): */\n  background-color: var(--background, #fff);\n  /* required in order to render the pseudo-elements\n     to the page: */\n  content: '';\n  /* using clip-path to control the shape, rather\n     than using transforms; this is the initial state,\n     the simple rectangle: */\n  clip-path: polygon(0 0, 100% 0, 100% 100%, 0 100%);\n  position: absolute;\n  /* using inset to position the pseudo-elements with\n     an offset of 0 on the top, right, bottom and left;\n     this means the element takes all available space: */\n  inset: 0;\n  /* transitioning the clip-path: */\n  transition: clip-path 0.3s linear;\n}\n\nbutton::before {\n  /* declaring the custom --background property: */\n  --background: red;\n  /* positioning the element lower down the 'stack'\n     than the parent element (the use of isolation: isolate\n     was to keep the pseudo-elements in front of any\n     background-color property that might be set on\n     the <button>, despite a lower z-index): */\n  z-index: -1;\n}\n\nbutton::after {\n  --background: yellow;\n  z-index: -2;\n}\n\n/* here we update the clip-path, using the --offset variable,\n   var() and calc(), to set the clipping to create the\n   parallelogram shape */\nbutton:hover::before {\n  clip-path: polygon( var(--offset) 0, 100% 0, calc(100% - var(--offset)) 100%, 0 100%);\n}\n\nbutton:hover::after {\n  clip-path: polygon( 0 0, calc(100% - var(--offset)) 0, 100% 100%, var(--offset) 100%);\n}\n<main>\n  <button>Some generic text</button>\n</main>\n\n\n\nJS Fiddle demo.\nReferences:\n\nbackground-color.\nborder.\nbox-sizing.\nblock-size.\ncalc().\ncontent.\nclip-path.\ndisplay.\nfont-size.\ninline-size.\ninset.\nisolation.\nmargin.\npadding.\npadding-block.\npadding-inline.\nplace-content.\nposition.\ntransition.\nvar().\nz-index.\n\n"
},
{
"QuestionId": "76391827",
"QuestionTitle": "How to keep WAR files running in Tomcat while I'm using IntelliJ?",
"QuestionBody": "There are two WAR files that rarely change and it should be running in my machine.\nThe tomcat path is /Users/myuser/Downloads/apache-tomcat-9.0.53 and the tomcat server in IntelliJ configuration use it also.\nIf I deploy the WARs in webapps directory, run another Java project that uses Tomcat in IntelliJ then I can't access these WARs. It seems like these wars are missing but there are in webapp path.\nAfter stop tomcat server in IntelliJ I got these WARs available again.\nIn order to solve the problem, my current project configuration builds and deploys these WARs every time but it takes more time. How can I solve this?\nTomcat Server\nRunning\nMy project [local]\nsec-web-services:war exploded [Republish] (first war file that rarely changes)\ndocuments-web-services:war exploded [Republish] (second war file that rarely changes)\napi-web-services:war exploded [Republish]\nproject-webapp:war exploded [Republish]\n\nTomcat Server Config in IntelliJ\nTomcat Home /Users/myuser/Downloads/apache-tomcat-9.0.53\nTomcat base directory /Users/myuser/Downloads/apache-tomcat-9.0.53\n\n",
"AnswerId": "76391909",
"AnswerBody": "IntelliJ IDEA Tomcat run configuration has an option to deploy applications already present in webapps directory:\n\n"
},
{
"QuestionId": "76391039",
"QuestionTitle": "Excel Macro for changing references with numbers separated by a dash into the full set of references",
"QuestionBody": "I have been dealing with customer bill of materials that contains references with numbers that are separated by a dash, rather than the full sequence of references spelled out, e.g. C1-4 instead of C1, C2, C3, C4 or C1 C2 C3 C4\nSome customers will use a comma to separate references, some only space, sometimes there is a mix of the two, which also complicates things. Here is an example:\n   R161-169\n \n   R2 R5, R7 R11\n\n   R103-7\n   \n   R26 R28-30 R42, R45-46, R62-65, R70-71, R92-102, R113-114\n   \n   R31-35 R40-41 R56-61 R72-79 R86-91\n   \n   R36, R38-39\n\nI'm trying to make a macro that will generate the full set of references automatically for only the selected portion of the references column, and generate that full set of references in the column next to it.\nSometimes customers leave a blank line between sections of references. Empty cells should remain empty in the output.\nI found one place online that had asked a very similar question - https://www.mrexcel.com/board/threads/splitting-out-numbers-separated-by-dash.679290/ but I did not understand the code there and it did not work for what I've been trying to do.\nI am not great with VBS, but I got the below code running without throwing any errors so far, but it doesn't generate the full set of references. It just copies them as they are, and I do not know where I went wrong.\nSub SplitReferences()\n'June 1, 2023\nDim inputRange As Range\nDim outputCell As Range\nDim inputArea As Range\nDim inputCell As Range\nDim startNum As Long\nDim endNum As Long\nDim i As Long\nDim outputString As String\n\n' Set the input range where your values are\nSet inputRange = Selection ' Use the selected range as input\n\n' Set the output range where you want the split references\nSet outputCell = inputRange.Offset(0, 1).Cells(1) ' Output in the column next to the input\n\n' Loop through each area in the input range\nFor Each inputArea In inputRange.Areas\n    ' Loop through each cell in the area\n    For Each inputCell In inputArea\n        ' Split the value by dash\n        Dim parts() As String\n        parts = Split(inputCell.Value, \"-\")\n\n        ' Check if there is a dash in the value\n        If UBound(parts) > 0 Then\n            ' Extract the start and end numbers\n            startNum = Val(parts(0))\n            endNum = Val(parts(1))\n        Else\n            ' If there is no dash, treat it as a single value\n            startNum = Val(parts(0))\n            endNum = Val(parts(0))\n        End If\n\n        ' Loop through the numbers and add them to the output range\n        For i = startNum To endNum\n            outputCell.Value = inputCell.Offset(i - startNum).Value\n            Set outputCell = outputCell.Offset(1) ' Move to the next row\n        Next i\n    Next inputCell\nNext inputArea\nEnd Sub\n\n",
"AnswerId": "76391910",
"AnswerBody": "Another approach:\nSub Tester()\n    Dim c As Range, arr, el, txt As String, rv As String, sep As String\n    \n    For Each c In Selection.Cells 'loop selected range\n        txt = Trim(c.Value)\n        If Len(txt) > 0 Then      'cell has a value?\n            arr = Split(Normalize(txt), \" \")\n            rv = \"\"\n            sep = \"\"\n            For Each el In arr\n                'convert to sequence if value has a dash\n                If InStr(el, \"-\") > 0 Then el = Sequence(CStr(el), \" \")\n                If Len(el) > 0 Then rv = rv & sep & el\n                sep = \" \"\n            Next el\n            With c.Offset(0, 1)\n                .WrapText = True\n                .Value = rv\n                .EntireRow.AutoFit\n            End With\n        End If 'has content\n    Next c\nEnd Sub\n\n'Normalize the input to replace unwanted characters with spaces\n'  Remove runs of >1 space, and spaces around \"-\"\nFunction Normalize(ByVal txt As String)\n    Dim arr, el\n    arr = Array(vbLf, vbCr, Chr(160), \",\", \";\", \":\") 'replace these with a space\n    For Each el In arr\n        txt = Replace(txt, el, \" \")\n    Next el\n    Do While InStr(1, txt, \"  \") > 0  'remove any multi-space runs\n        txt = Replace(txt, \"  \", \" \")\n    Loop\n    txt = Replace(txt, \" -\", \"-\") 'remove any spaces next to dashes\n    txt = Replace(txt, \"- \", \"-\")\n    Normalize = txt\nEnd Function\n\n'Return a sequence from a pattern like [letter][number1]-[number2],\n'  separated by `sep`\nFunction Sequence(txt As String, sep As String)\n    Dim prefix, rv As String, sp, arr, v1, v2, i As Long\n    prefix = GetPrefix(txt) 'extract leading non-numeric character(s)\n    arr = Split(txt, \"-\")\n    v1 = NumberOnly(arr(0))\n    v2 = NumberOnly(arr(1))\n    If Len(v1) > 0 And Len(v2) > 0 Then\n        'handle case like R102-4, R102-24\n        If Len(v2) < Len(v1) Then v2 = Left(v1, Len(v1) - Len(v2)) & v2\n        v1 = CLng(v1)\n        v2 = CLng(v2)\n        For i = v1 To v2 'assumes V2 > v1...\n            rv = rv & sp & prefix & i\n            sp = sep\n        Next i\n    End If\n    Sequence = rv\nEnd Function\n\n'return the first [whole] number found in `txt`\nFunction NumberOnly(txt)\n    Dim i As Long, c, rv\n    For i = 1 To Len(txt)\n        c = Mid(txt, i, 1)\n        If c Like \"#\" Then\n            NumberOnly = NumberOnly & c\n        Else\n            If Len(NumberOnly) > 0 Then Exit Function\n        End If\n    Next i\nEnd Function\n\n'Return leading non-numeric character(s)\nFunction GetPrefix(txt As String)\n    Dim i As Long, c As String, rv\n    For i = 1 To Len(txt)\n        c = Mid(txt, i, 1)\n        If c Like \"#\" Then Exit For\n        rv = rv & c\n    Next i\n    GetPrefix = rv\nEnd Function\n\n"
},
{
"QuestionId": "76388622",
"QuestionTitle": "Understanding NuGet Package dependecies from Nuget.org",
"QuestionBody": "I am a bit confused as how to interpret the dependencies list available on nuget.org and in the NuGet Package Manager in Visual Studio...\nSometimes, the list contains frameworks and a sub-list of dependencies per framework. Sometimes it does not contain the framework I have targeted for a particular project at all, how do I interpret this?\nFor example, this package's latest stable version is 7.0.5. I have chosen to only update my version to 6.0.16 because that is the latest version which mentions net6 as a dependency.\n\nVersions 7 and above only mention net7.0 with dependencies, hence why I only dare to update to latest 6.X.X. Is my interpretation correct? Should I only update to the latest version mentioning net6 in the dependecy list (when my project targets net6), or can I update to the 7.X.X versions anyway?\n",
"AnswerId": "76388983",
"AnswerBody": "A package author can choose what target framework monikers (TFMs) to support; this can be diverse or ultra-specific. In this case (Microsoft.AspNetCore.Diagnostics.EntityFrameworkCore), they have gone \"specific\", with the v6 versions of the library only targeting net6, v7 versions of the library only targeting net7, etc; so yes, your interpretation is correct and 6.0.16 looks to be the latest you can use with .net 6; if you attempt to install a v7 version of the lib, it should fail to install the package and/or build, because something targeting net7 could be using APIs that simply do not exist in net6, giving runtime failures - the package system attempts to protect you from that.\nNow, it might be that the package could work on net6, but targeting multiple frameworks is effort that requires testing, and may involve code changes (in particular #if sections or similar, to use better approaches when available, or fallback approaches when not). It is not unreasonable for authors to say, more simply:\n\nThe vOlder version is what it is - we may supply out-of-band updates for security fixes or bugs that cross a certain threshold, and you can keep using vOlder with your netOlder applications, but if you want newer features you'll need to use vNewer on netNewer.\n\nThis is on a per-package basis, and many packages are far more diverse in what they target, either by having a wide range of TFMs, or by having wide-reaching targets such as netstandard2.0 (which in theory works on a wide range of platforms, by virtue of only consuming a common intersection of APIs).\n"
},
{
"QuestionId": "76388773",
"QuestionTitle": "Xpath: evaluate condition at parent node along with filtering duplicate entries",
"QuestionBody": "Need an Input on the below XPath requirement:\nXML:\n<component>\n    <Bundle>\n        <entry>\n            <resource>\n                <Condition>\n                    <id value=\"123456\"/>\n                </Condition>\n            </resource>\n            <search>\n                <mode value=\"match\"/>\n            </search>\n        </entry>\n        <entry>\n            <resource>\n                <Condition>\n                    <id value=\"123456\"/>\n                </Condition>\n            </resource>\n            <search>\n                <mode value=\"match\"/>\n            </search>\n        </entry>\n        <entry>\n            <resource>\n                <Condition>\n                    <id value=\"654321\"/>\n                </Condition>\n            </resource>\n            <search>\n                <mode value=\"include\"/>\n            </search>\n        </entry>        \n    </Bundle>   \n</component>\n\nXSLT:\n<xsl:with-param name=\"entries\" select=\"//Bundle/entry/resource/Condition[not(id/@value=following::Condition/id/@value)]\"/>\n\nCurrently it is eliminating duplicate condition entries. Now need to enhance it to\nconsider <entry> with <mode value=\"match\"/> and its respective conditions only.\ntried with different approaches likes //Bundle/entry[<<expression>>]/resource/Condition[not(id/@value=following::Condition/id/@value)] and //Bundle/entry/resource/Condition[not(id/@value=following::Condition/id/@value) and ../../<<expression>>]\nNot giving expected result. Any input will be helpful.\nexpected output:\n<Condition>\n    <id value=\"123456\"/>\n</Condition>\n\nwant only conditions which are not duplicates as well as matching <mode value=\"match\"/> only.\n",
"AnswerId": "76389015",
"AnswerBody": "Consider the following example of Muenchian grouping:\nXSLT 1.0\n<xsl:stylesheet version=\"1.0\" \nxmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n<xsl:output method=\"xml\" version=\"1.0\" encoding=\"UTF-8\" indent=\"yes\"/>\n<xsl:strip-space elements=\"*\"/>\n\n<xsl:key name=\"k1\" match=\"entry[search/mode/@value='match']\" use=\"resource/Condition/id/@value\" />\n\n<xsl:template match=\"/component\">\n    <output>\n        <xsl:copy-of select=\"Bundle/entry[search/mode/@value='match'][count(. | key('k1', resource/Condition/id/@value)[1]) = 1]/resource/Condition\"/>\n    </output>\n</xsl:template>\n\n</xsl:stylesheet>\n\nApplied to your input example, this will return:\nResult\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<output>\n  <Condition>\n    <id value=\"123456\"/>\n  </Condition>\n</output>\n\n\nIn XSLT 2.0 or higher, you could reduce this to:\n<xsl:stylesheet version=\"2.0\" \nxmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n<xsl:output method=\"xml\" version=\"1.0\" encoding=\"UTF-8\" indent=\"yes\"/>\n\n<xsl:template match=\"/component\">\n    <output>\n        <xsl:for-each select=\"distinct-values(Bundle/entry[search/mode/@value='match']/resource/Condition/id/@value)\">\n            <Condition>\n                <id value=\"{.}\"/>\n            </Condition>\n        </xsl:for-each> \n    </output>\n</xsl:template>\n\n</xsl:stylesheet>\n\n"
},
{
"QuestionId": "76390149",
"QuestionTitle": "Android room: Don't override properties with null",
"QuestionBody": "class ArticleResponse(\n    val id: Int,\n    val previewContent: String\n)\n\nfun ArticleResponse.mapToEntity() = Article(\n    id = id,\n    previewContent = previewContent,\n    content = null\n)\n\nclass SingleArticleResponse(\n    val id: Int,\n    val content: String\n)\n\nfun SingleArticleResponse.mapToEntity() = Article(\n    id = id,\n    previewContent = null,\n    content = content\n)\n\n@Entity(tableName = \"articles\")\nclass Article(\n    @PrimaryKey\n    @ColumnInfo(name = \"id\")\n    val id: Int,\n\n    @ColumnInfo(name = \"preview_content\")\n    val previewContent: String?,\n\n    @ColumnInfo(name = \"content\")\n    val content: String?\n)\n\nExplanation: \nWhen you look at the code, you have to know that a call to API-Endpoint X gives me a list of ArticleResponse. This response doesn't give me the content property.\nWhen I then want to view the article, I call API-Endpoint Y, which gives my SingleArticleResponse as a Response. This response doesn't give me the previewContent property.\nProblem: \nNo matter what I do, one of the properties content or previewContent will always be null in my local database.\nQuestion: \nHow can I tell Room, that it should not override the property with null, if it previously has not been null? Is this possible?\n",
"AnswerId": "76390411",
"AnswerBody": "I think the easiest and most robust way to do this is to have 6 separate update queries and run them all inside a transaction.\n@Dao\ninterface ArticleDAO {\n    @Query(\"UPDATE Article SET content = :content WHERE id = :id\")\n    suspend fun updateContent(id: Int, content: String)\n\n    @Query(\"UPDATE Article SET previewContent = :previewContent WHERE id = :id\")\n    suspend fun updatePreviewContent(id: Int, previewContent: String)\n\n    //Other update queries here\n}\n\nfun updateArticle(article: Article) {\n    database.withTransaction {\n        if(article.content != null) {\n            articleDao.updateContent(article.id, article.content)\n        }\n        if(article.previewContent != null) {\n            articleDao.updatePreviewContent(article.id, article.previewContent)\n        }\n\n        //Other updates here ...\n    }\n}\n\nLet me know if this answers your question.\n"
},
{
"QuestionId": "76390317",
"QuestionTitle": "systemd-run memory limit is not shown in /proc/meminfo, is there another way?",
"QuestionBody": "I'm trying to write a program that waits when it sees it's memory is becoming full. It finds out what the current available memory is using /proc/meminfo. Now I'm trying to test it by running systemd-run --scope -p MemoryMax=100M -p MemorySwapMax=0 but /proc/meminfo is still returning the old values (which I kind of get why it does that).\nIs there another place or way I can retrieve the available memory that does look at the limits set by systemd-run?.\nThanks in advance!\n",
"AnswerId": "76390432",
"AnswerBody": "Systemd uses cgroups.\n$ systemd-run -P --user -p MemoryMax=10240000 -p MemorySwapMax=0 bash -c 'd=/sys/fs/cgroup/$(cut -d: -f3 /proc/self/cgroup); tail $d/memory{.swap,}.max'\nRunning as unit: run-u923.service\n==> /sys/fs/cgroup//user.slice/user-1000.slice/user@1000.service/app.slice/run-u923.service/memory.swap.max <==\n0\n\n==> /sys/fs/cgroup//user.slice/user-1000.slice/user@1000.service/app.slice/run-u923.service/memory.max <==\n10240000\n\n"
},
{
"QuestionId": "76388859",
"QuestionTitle": "How to render a subroute and trigger react router parents loader?",
"QuestionBody": "I have this router:\nconst router = createBrowserRouter(\n  [\n    {\n      path: '/',\n      element: <Navigate to={'/dashboards'}/>\n    },\n    {\n      path: '/dashboards',\n      element: <Dashboards/>,\n      loader: () => store.dispatch(retrieveWarehouses()),\n      children: [\n        {\n          path: ':warehouse',\n          element: <Dashboard/>,\n          loader: ({ params }) => store.dispatch(monitorWarehouse(params.warehouse))\n        }\n      ]\n    }\n  ]\n)\n\nDefined as is, the <Dashboard/> component is not rendered, only its parent dashboard list (Dashboards, notice the plural). The loader of the child Dashboard is still triggered though.\nIf I don't use a nested route:\nconst router = createBrowserRouter(\n  [\n    {\n      path: '/',\n      element: <Navigate to={'/dashboards'}/>\n    },\n    {\n      path: '/dashboards',\n      element: <Dashboards/>,\n      loader: () => store.dispatch(retrieveWarehouses()),\n    },\n    {\n      path: '/dashboards/:warehouse',\n      element: <Dashboard/>,\n      loader: ({ params }) => store.dispatch(monitorWarehouse(params.warehouse))\n    }\n  ]\n)\n\nThe child component Dashboard is rendered properly, but the loader of the parent is not triggered.\nHere are the components:\nDashboards\nconst Dashboards: React.FC<any> = () => {\n  const {\n    warehouses,\n    loading\n  } = useAppSelector(selectWarehouseListState)\n\n  if (loading) {\n    return (\n      <div className={'warehouse-list'}>\n        <h1>Select warehouse</h1>\n        <Spinner/>\n      </div>\n    )\n  }\n\n  return (\n    <div className={'warehouse-list'}>\n      <h1>Select warehouse</h1>\n      {\n        warehouses.map((wh: Warehouse) => (\n          <NavLink to={`/dashboards/${wh.name}`} key={wh.name}>\n            <div className={'selectable-warehouse container'}>\n              {wh.name}\n            </div>\n          </NavLink>\n        ))\n      }\n    </div>\n  )\n}\n\nDashboard\nconst Dashboard: React.FC<any> = () => {\n  const { loading } = useAppSelector(selectWarehouseState)\n  const { warehouse } = useParams()\n  const dispatch = useAppDispatch()\n\n  useEffect(() => {\n    return () => {\n      dispatch(stopMonitorWarehouse(warehouse))\n    }\n  }, [dispatch])\n\n  if (loading) {\n    return (\n      <div className={'dashboard loading shrinkable'}>\n        <div className={'header'}>\n          <NavLink to={'/dashboards'} className={'nav-back'}>\n            <ArrowBack/>\n          </NavLink>\n          <div className={'selected-warehouse-name'}>{warehouse}</div>\n        </div>\n        <div className={'status connecting'}>status: connecting</div>\n        <Spinner/>\n      </div>\n    )\n  }\n\n  return (\n    <div className={'dashboard active shrinkable'}>\n      <div className={'header'}>\n        <NavLink to={'/dashboards'} className={'nav-back'}>\n          <ArrowBack/>\n        </NavLink>\n        <div className={'selected-warehouse-name'}>{warehouse}</div>\n      </div>\n      <div className={'status connected'}>status: connected</div>\n      <div className={'logs-metrics'}>\n        <Logs/>\n      </div>\n    </div>\n  )\n}\n\nHow can I access /dashboards/foo and trigger both loaders ?\n",
"AnswerId": "76389025",
"AnswerBody": "If the Dashboards component is rendered as a layout route then it necessarily should render an Outlet for its nested routes to render their content into.\nExample:\nimport { Outlet } from 'react-router-dom';\n\nconst Dashboards: React.FC<any> = () => {\n  const {\n    warehouses,\n    loading\n  } = useAppSelector(selectWarehouseListState)\n\n  return (\n    <div className={'warehouse-list'}>\n      <h1>Select warehouse</h1>\n      {loading ? (\n        <Spinner />\n      ) : (\n        <>\n          {warehouses.map((wh: Warehouse) => (\n            <NavLink to={`/dashboards/${wh.name}`} key={wh.name}>\n              <div className={'selectable-warehouse container'}>\n                {wh.name}\n              </div>\n            </NavLink>\n          ))}\n          <Outlet />\n        </>\n      )}\n    </div>\n  );\n};\n\n\nHowever in my use case I don't want both components to be rendered, the\nlatter should take precedence of the other.\n\nIf I understand this part you want the Dashboards and Dashboard components rendered independently, but the Dashboards's loader function to still be called even while on a nested route. For this you'll render Dashboards as a nested index route where the loader function is on the parent layout route.\nExample:\nconst router = createBrowserRouter(\n  [\n    {\n      path: '/',\n      element: <Navigate to=\"/dashboards\" />\n    },\n    {\n      path: '/dashboards',\n      loader: () => store.dispatch(retrieveWarehouses()),\n      children: [\n        {\n          index: true,\n          element: <Dashboards />,\n        },\n        {\n          path: ':warehouse',\n          element: <Dashboard />,\n          loader: ({ params }) => {\n            store.dispatch(monitorWarehouse(params.warehouse));\n          },\n        }\n      ]\n    }\n  ]\n);\n\nThe \"/dashboards\" route will render an Outlet by default when no element is specified, and the Dashboards component will be rendered when the parent route is matched. No changes to the Dashboards component would be required.\n"
},
{
"QuestionId": "76390643",
"QuestionTitle": "Is Mapstruct capable of passing a source object to an @AfterMapping method?",
"QuestionBody": "Consider this code\n@Mapper\n@RequiredArgsConstructor\npublic abstract class QuestionCommentMapper {\n    protected final QuestionService questionService;\n\n    public abstract QuestionComment dtoAndAuthenticationToQuestionComment(QuestionCommentRequestDto dto,\n                                                                          @Context Authentication auth);\n\n    @AfterMapping\n    protected void enrichWithOwner(@MappingTarget QuestionComment questionComment, @Context Authentication auth) {\n        Account owner = AuthenticationProcessor.extractAccount(auth);\n        questionComment.setOwner(owner);\n    }\n\n    @AfterMapping\n    protected void enrichWithQuestion(@MappingTarget QuestionComment questionComment,\n                                      @Context QuestionCommentRequestDto dto) {\n        Long questionId = dto.questionId();\n        Question question = questionService.getById(questionId);\n        questionComment.setQuestion(question);\n    }\n}\n\nWould Mapstruct pass a QuestionCommentRequestDto object to the enrichWithQuestion() method which is a source in the original mapping method? If not, how can I perform that second \"enriching\" without forgoing Mapstruct's code generation? If I write anything in the mapping method (e.g. use the QuestionCommentRequestDto instance to set QuestionComment's Question field, as in my enrichWithQuestion() method), Mapstruct won't generate anything, and I'll have to basically write everything manually\n",
"AnswerId": "76391915",
"AnswerBody": "Mapstruct is capable of that with no extra code needed. Here's the generated method\n@Override\n    public QuestionComment dtoAndAuthenticationToQuestionComment(QuestionCommentRequestDto dto, Authentication auth) {\n        if ( dto == null ) {\n            return null;\n        }\n\n        QuestionComment questionComment = new QuestionComment();\n\n        questionComment.setText( dto.text() );\n\n        enrichWithOwner( questionComment, auth );\n        enrichWithQuestion( questionComment, dto ); // ← look at it\n\n        return questionComment;\n    }\n\nWhat made me post this question was largely the fact that a chat bot said Mapstruct wouldn't pass the source object because\n\nAny source parameters used in the regular mapping method are not passed to the @AfterMapping method, as they are not needed for any further mapping operations at that point.\n\nIt appears the chat bot was mistaken on that\n"
},
{
"QuestionId": "76388819",
"QuestionTitle": "Firebase firestore db orderBy document id",
"QuestionBody": "I need to retrieve a big amount of data.\nI'm trying to order by 'id'. But the query returns an empty collection. if remove orderBy('id') it works properly.\nHow to sort by document id?\nmQuery = docRef.orderBy('id')\n              .limit(bulk_size)\n                .get();\n\n",
"AnswerId": "76389035",
"AnswerBody": "When you call .orderBy('id') it means that you trying to order the documents that you get from Firestore according to a field called id. If you want to order the documents according to the document ID, then please use:\nmQuery = docRef.orderBy(firebase.firestore.FieldPath.documentId())\n               .limit(bulk_size)\n               .get();\n\n"
},
{
"QuestionId": "76390160",
"QuestionTitle": "DJANGO Get First, Second and Third most found Value in a Model",
"QuestionBody": "I got a Dashboard model that is filled by a schduled Job.\ndashboard model\nclass dashboard(models.Model):\n    topvul1=models.IntegerField(default=0)\n    topvul2=models.IntegerField(default=0)\n    topvul3=models.IntegerField(default=0)\n\n\nI want to show the most found, second most found and third most found VID from the clientvul model. And fill it once per Day to my dashboard model.\nclientvul model\nclass clientvul(models.Model):\n    \n    client= models.ForeignKey(client, on_delete=models.CASCADE)\n    vid=models.ForeignKey(vul, on_delete=models.CASCADE)\n    path=models.CharField(max_length=1000)\n    product=models.CharField(max_length=1000)\n    isactive=models.BooleanField(default=True)\n    class Meta:\n        constraints = [\n            models.UniqueConstraint(\n               fields=['client', 'VID'], name='unique_migration_host_combination' # legt client und VID als Primarykey fest\n            )\n        ]\n\n",
"AnswerId": "76390445",
"AnswerBody": "You can count the number of clientvuls for each vul and then order and return the first three:\nfrom django.db.models import Count\n\nvul.objects.alias(\n    num_client=Count('clientvul_set')\n).order_by('-num_client')[:3]\n\nthere is no need to make a model for this. Unless we are talking about billions of records, such queries run in milliseconds, and are more robust since it will also change the order in case a clientvul is removed for example.\n"
},
{
"QuestionId": "76390300",
"QuestionTitle": "Give the CLANG compiler a loop length assertion",
"QuestionBody": "I have a loop that loads two float* arrays into __m256 vectors and processes them. Following this loop, I have code that loads the balance of values into the vectors and then processes them. So there is no alignment requirement on the function.\nHere is the code that loads the balance of the data into the vectors:\nsize_t constexpr            FLOATS_IN_M128              = sizeof(__m128) / sizeof(float);\nsize_t constexpr            FLOATS_IN_M256              = FLOATS_IN_M128 * 2;\n\n...\nassert(bal < FLOATS_IN_M256);\n\nfloat ary[FLOATS_IN_M256 * 2];    \nauto v256f_q = _mm256_setzero_ps();\n_mm256_storeu_ps(ary, v256f_q);\n_mm256_storeu_ps(&ary[FLOATS_IN_M256], v256f_q);   \nfloat *dest = ary;\nsize_t offset{};\n\nwhile (bal--)\n{\n    dest[offset] = p_q_n[pos];\n    dest[offset + FLOATS_IN_M256] = p_val_n[pos];\n    offset++;\n    pos++;\n}\n\n// the two vectors that will be processed\nv256f_q = _mm256_loadu_ps(ary);\nv256f_val = _mm256_loadu_ps(&ary[FLOATS_IN_M256]);    \n\nWhen I use Compiler Explorer, set to \"x86-64 clang 16.0.0 -march=x86-64-v3 -O3\" the compiler unrolls the loop when the assert(bal < FLOATS_IN_M256); line is present. However, assert() is ignored in RELEASE mode, meaning the loop won't be vectorized and unrolled.\nTo test, I defined NDEBUG and the loop is vectorized and unrolled.\nI have tried adding the following in the appropriate places, but they don't work:\n#pragma clang loop vectorize(enable)\n#pragma unroll\n#undef NDEBUG\n\nThe compiler should be able to see from the code before the snippet above that bal < 8 but it doesn't. How can I tell it this assertion is true when not in DEBUG mode?\n",
"AnswerId": "76390453",
"AnswerBody": "You can use __builtin_assume to give the compiler constraint information that is not explicitly in the code. This should work for gcc and clang.\nIn the posted code, just replace the assert with __builtin_assume(bal < FLOATS_IN_M256).\n"
},
{
"QuestionId": "76391255",
"QuestionTitle": "Date Validation in Pyspark",
"QuestionBody": "I have a data file having multiple date fields coming in string data type. I am trying to validate the date field and discard the records having wrong date format. Data looks like below.\nschema = StructType([StructField(\"id\",StringType(),True), \\\nStructField(\"dt1\",StringType(),True), \\\nStructField(\"dt2\",StringType(),True)])\ndf = spark.createDataFrame([(1, \"01/22/2010\",\"03/25/2012\"), (2, \"01/12/2014\",None),(3,\"04/09/2011\",\"12/23\"),(5,None,\"01/22/2010\"),(6,\"2005/12/04\",\"2000/12/04\"),(7,\"01/01/2020\",\"30/12/2019\"),(8,\"12/1999/21\",\"05/01/2021\"),(9,\"12/2013/21\",None),(9,None,None)], schema=schema)\n\nOnly the two date formats \"M/d/y\", \"M/yy\" are allowed to be passed in the validation. Records that do not pass the validation will be loaded in the error table.\n\nThis is a sample data. In actual file there are n numbers of date fields present. I am trying to get a function which can do this validation on all the date fields.\n",
"AnswerId": "76391923",
"AnswerBody": "I think you can try to parse the date and then filter rows with None values, you can have a list of date columns to be more generic\nfrom pyspark.sql.functions import coalesce, to_date, col\nfrom pyspark.sql.types import StructField, StructType, StringType\n\nschema = StructType([StructField(\"id\",StringType(),True), \\\nStructField(\"dt1\",StringType(),True), \\\nStructField(\"dt2\",StringType(),True)])\ndf = spark.createDataFrame([(1, \"01/22/2010\",\"03/25/2012\"), (2, \"01/12/2014\",None),(3,\"04/09/2011\",\"12/23\"),(5,None,\"01/22/2010\"),(6,\"2005/12/04\",\"2000/12/04\"),(7,\"01/01/2020\",\"30/12/2019\"),(8,\"12/1999/21\",\"05/01/2021\"),(9,\"12/2013/21\",None),(9,None,None)], schema=schema)\n\n\ndef custom_to_date(col):\n    formats = (\"M/d/y\", \"M/yy\")\n    return coalesce(*[to_date(col, f) for f in formats])\n\n# Set CORRECTED mode to deal with invalid dates as None\nspark.sql(\"set spark.sql.legacy.timeParserPolicy=CORRECTED\")\n\ndf.cache()\n\ndate_columns = [\"dt1\", \"dt2\"]\n\nvalid_df = df\nfor c in date_columns:\n    valid_df = valid_df.filter(custom_to_date(col(c)).isNotNull())\n\nerror_df = df.subtract(valid_df)\n\nerror_df.show()\n+---+----------+----------+\n| id|       dt1|       dt2|\n+---+----------+----------+\n|  2|01/12/2014|      null|\n|  5|      null|01/22/2010|\n|  6|2005/12/04|2000/12/04|\n|  7|01/01/2020|30/12/2019|\n|  8|12/1999/21|05/01/2021|\n|  9|12/2013/21|      null|\n|  9|      null|      null|\n+---+----------+----------+\n\nvalid_df.show()\n+---+----------+----------+                                                     \n| id|       dt1|       dt2|\n+---+----------+----------+\n|  1|01/22/2010|03/25/2012|\n|  3|04/09/2011|     12/23|\n+---+----------+----------+\n\nUpdate: If we need to replace the String columns as well with the parsed dates then we can do something like this:\nfrom pyspark.sql.functions import coalesce, to_date, col\nfrom pyspark.sql.types import StructField, StructType, StringType\n\nschema = StructType([StructField(\"id\",StringType(),True), \\\nStructField(\"dt1\",StringType(),True), \\\nStructField(\"dt2\",StringType(),True)])\ndf = spark.createDataFrame([(1, \"01/22/2010\",\"03/25/2012\"), (2, \"01/12/2014\",None),(3,\"04/09/2011\",\"12/23\"),(5,None,\"01/22/2010\"),(6,\"2005/12/04\",\"2000/12/04\"),(7,\"01/01/2020\",\"30/12/2019\"),(8,\"12/1999/21\",\"05/01/2021\"),(9,\"12/2013/21\",None),(9,None,None)], schema=schema)\n\n\ndef custom_to_date(col):\n    formats = (\"M/d/y\", \"M/yy\")\n    return coalesce(*[to_date(col, f) for f in formats])\n\n# Set CORRECTED mode to deal with invalid dates as None\nspark.sql(\"set spark.sql.legacy.timeParserPolicy=CORRECTED\")\n\ndf.cache()\n\ndate_columns = [\"dt1\", \"dt2\"]\n\n\nfor c in date_columns:\n    df = df.withColumn(c, custom_to_date(col(c)))\n\nvalid_df = df\nfor c in date_columns:\n    valid_df = valid_df.filter(col(c).isNotNull())\n\nerror_df = df.subtract(valid_df)\n\n>>> valid_df.show()\n+---+----------+----------+\n| id|       dt1|       dt2|\n+---+----------+----------+\n|  1|2010-01-22|2012-03-25|\n|  3|2011-04-09|2023-12-01|\n+---+----------+----------+\n\n>>> error_df.show()\n+---+----------+----------+\n| id|       dt1|       dt2|\n+---+----------+----------+\n|  2|2014-01-12|      null|\n|  5|      null|2010-01-22|\n|  6|      null|      null|\n|  7|2020-01-01|      null|\n|  8|      null|2021-05-01|\n|  9|      null|      null|\n+---+----------+----------+\n\n"
},
{
"QuestionId": "76388794",
"QuestionTitle": "ListView Item - Generate column value based on criteria not part of Item's class",
"QuestionBody": "Suppose I've a simple model class:\npublic class Car\n{\n    public string Make { get; init; }\n    public string Model { get; init; }\n    public string Year { get; init; }\n}\n\nIn my ViewModel, I've two lists:\npublic class ViewModel\n{\n    public ObservableCollection<Car> Cars { get; }\n    public List<Car> CanBeSold { get; }\n\n    public ViewModel()\n    {\n        Car car1 = new() { Make = \"Toyota\", Model = \"Corolla\", Year = \"2020\" };\n        Car car2 = new() { Make = \"Honda\", Model = \"Civic\", Year = \"2021\" };\n        Car car3 = new() { Make = \"Mitsubishi\", Model = \"Lancer\", Year = \"2017\" };\n\n        Cars = new();\n        CanBeSold = new();\n\n        Cars.Add(car1);\n        Cars.Add(car2);\n        Cars.Add(car3);\n\n        CanBeSold.Add(car2);\n    }\n}\n\nIn my view, I'm bidining a ListView to the Cars collection:\n<ListView ItemsSource=\"{Binding Cars}\">\n    <ListView.View>\n        <GridView>\n            <GridViewColumn Header=\"Make\" DisplayMemberBinding=\"{Binding Path=Make}\"/>\n            <GridViewColumn Header=\"Model\" DisplayMemberBinding=\"{Binding Path=Model}\"/>\n            <GridViewColumn Header=\"Year\" DisplayMemberBinding=\"{Binding Path=Year}\"/>\n            <GridViewColumn Header=\"Can Be Sold\"/>\n        </GridView>\n    </ListView.View>\n</ListView>\n\nHow can I also show a Yes/No based on if the Car is in the list CanBeSold?\n\nThanks for any help.\n",
"AnswerId": "76389049",
"AnswerBody": "You may use a MultiBinding that contains a Binding to the CanBeSold property of the parent view model and a Binding to the current Car element.\n<GridViewColumn Header=\"Can Be Sold\">\n    <GridViewColumn.DisplayMemberBinding>\n        <MultiBinding>\n            <MultiBinding.Converter>\n                <local:ListElementConverter/>\n            </MultiBinding.Converter>\n            <Binding Path=\"DataContext.CanBeSold\"\n                     RelativeSource=\"{RelativeSource AncestorType=ListView}\"/>\n            <Binding />\n        </MultiBinding>\n    </GridViewColumn.DisplayMemberBinding>\n</GridViewColumn>\n\nThe Binding Converter checks if the element is contained in the list:\npublic class ListElementConverter : IMultiValueConverter\n{\n    public object Convert(\n        object[] values, Type targetType, object parameter, CultureInfo culture)\n    {\n        return values.Length == 2 &&\n            values[0] is IList list &&\n            list.Contains(values[1])\n            ? \"Yes\"\n            : \"No\";\n    }\n\n    public object[] ConvertBack(\n        object value, Type[] targetTypes, object parameter, CultureInfo culture)\n    {\n        throw new NotSupportedException();\n    }\n}\n\n"
},
{
"QuestionId": "76389832",
"QuestionTitle": "Polars - How to add two series that contain lists as elements",
"QuestionBody": "Trying to add, subtract, two Series that contains datatype List[i64]. The operation seems to be not supported.\na = pl.Series(\"a\",[[1,2],[2,3]])\nb = pl.Series(\"b\",[[4,5],[6,7]])\nc = a+b\n\nthis gives the error:\nPanicException: `add` operation not supported for dtype `list[i64]`\n\nI would expect a element-wise sum, like would happen with numpy array for example:\nc = [[5,7],[8,10]]\n\nWhat's the correct syntax to add two series of lists?\n",
"AnswerId": "76390470",
"AnswerBody": "you can do the following:\n\nc = (a.explode() + b.explode()).reshape((2,-1)).alias('c')\n\nshape: (2,)\nSeries: 'a' [list[i64]]\n[\n    [5, 7]\n    [8, 10]\n]\n\nFinal thoughts: if your list has a fixed size, then you might consider using the new Polars Array datatype.\n"
},
{
"QuestionId": "76383169",
"QuestionTitle": "Is there a secure way to provide users with Shared Access Signature Tokens for Azure Storage containers?",
"QuestionBody": "My API allows users to upload and download files to my Azure Storage account. To do this, they need a SAS token with permissions based on if they want to download or upload a file. I was wondering if there was a secure method to provide users with these tokens, other than sending it through more unsecure methods such as email.\nEdit for Clarification:\nI plan on having hundreds of users accessing my Azure Storage account. I was planning on generating my token through Azure itself but I have been considering generating the SAS token inside of the API or in a separate Azure Function. My API uses an Azure Function with NodeJS.\n",
"AnswerId": "76391967",
"AnswerBody": "Proposal 1: You can create a new Azure function as a proxy on your storage account for uploading/downloading. Thanks to managed identity, you won't have to provide a SAS token. User authorization on the Azure Function will ensure that the permission is removed when the user is no longer authorized.\nProposal 2: You can create a SAS token with an Azure Function and send it to the user inside your application (can be transparent to the user). This will enable you to create a SAS token with a short lifetime. If communication between clients and server uses TLS, it will guarantee secure transmission of your token.\n"
},
{
"QuestionId": "76387974",
"QuestionTitle": "Migration from RestEasy to RestEasyReactive with ResteasyContext and ContainerRequestFilter",
"QuestionBody": "I'm migrating old Quarkus project from RestEasy to ResteasyReactive and I have some difficulties migrating ResteasyContext.pushContext since there is no real 1:1 alternative in rest easy.\nI'm using the ResteasyContext.pushContext in my ContainerRequestFilter to push some custom object to Context and later retrieve it using @Context.\nSomething like in this minimal example i provided.\nFilter:\npackage org.acme.filter;\n\nimport org.acme.pojo.CustomHttpRequest;\nimport org.jboss.resteasy.core.ResteasyContext;\n\nimport javax.enterprise.context.ApplicationScoped;\nimport javax.ws.rs.container.ContainerRequestContext;\nimport javax.ws.rs.container.ContainerRequestFilter;\nimport javax.ws.rs.ext.Provider;\nimport java.time.LocalDateTime;\nimport java.util.Random;\n\n@Provider\n@ApplicationScoped\npublic class HttpRequestFilter implements ContainerRequestFilter {\n\n    @Override\n    public void filter(ContainerRequestContext requestContext) {\n        CustomHttpRequest request = CustomHttpRequest.builder()\n                .headers(requestContext.getHeaders())\n                .dateTime(LocalDateTime.now())\n                .text(\"Some random text for example \" + new Random().nextInt(100))\n                .build();\n        ResteasyContext.pushContext(CustomHttpRequest.class, request);\n    }\n}\n\nCustom object I want to push to context:\npackage org.acme.pojo;\n\nimport lombok.Builder;\nimport lombok.Getter;\nimport lombok.ToString;\n\nimport javax.ws.rs.core.MultivaluedMap;\nimport java.time.LocalDateTime;\n\n@Getter\n@Builder\n@ToString\npublic class CustomHttpRequest {\n\n    private String text;\n    private LocalDateTime dateTime;\n    private MultivaluedMap<String, String> headers;\n    private boolean secured;\n}\n\nAnd the later read it from context in my rest endpoint:\npackage org.acme;\n\nimport org.acme.pojo.CustomHttpRequest;\nimport org.acme.pojo.ResponseData;\n\nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\nimport javax.ws.rs.Produces;\nimport javax.ws.rs.core.Context;\nimport javax.ws.rs.core.MediaType;\n\n@Path(\"/hello\")\npublic class GreetingResource {\n\n    @GET\n    @Path(\"{pathText}\")\n    @Produces(MediaType.APPLICATION_JSON)\n    public ResponseData testContext(@Context CustomHttpRequest httpRequest,\n                                    @PathParam(\"pathText\") String queryText) {\n\n       return ResponseData.builder()\n                .queryText(queryText)\n                .httpRequestText(httpRequest.getText())\n                .secured(httpRequest.isSecured())\n                .build();\n    }\n}\n\nHere is the full example on GitHub: https://github.com/pkristja/resteasy_context/tree/main\nI have found some alternatives that work with RestEasyReactive like using ContainerRequestContext and setting the data using setProperty.\nBuild file changes:\nChanged from implementation(\"io.quarkus:quarkus-resteasy-jackson\") to implementation(\"io.quarkus:quarkus-resteasy-reactive-jackson\")\nFilter for setting oblect to context:\npackage org.acme.filter;\n\nimport org.acme.pojo.CustomHttpRequest;\n\nimport javax.enterprise.context.ApplicationScoped;\nimport javax.ws.rs.container.ContainerRequestContext;\nimport javax.ws.rs.container.ContainerRequestFilter;\nimport javax.ws.rs.core.Context;\nimport javax.ws.rs.ext.Provider;\nimport java.time.LocalDateTime;\nimport java.util.Random;\n\n@Provider\n@ApplicationScoped\npublic class HttpRequestFilter implements ContainerRequestFilter {\n\n    @Context\n    ContainerRequestContext crContext;\n\n    @Override\n    public void filter(ContainerRequestContext requestContext) {\n        CustomHttpRequest request = CustomHttpRequest.builder()\n                .headers(requestContext.getHeaders())\n                .dateTime(LocalDateTime.now())\n                .text(\"Some random text for example \" + new Random().nextInt(100))\n                .build();\n\n        crContext.setProperty(\"customHttpRequest\", request);\n    }\n}\n\nRetrieving object from context:\npackage org.acme;\n\nimport org.acme.pojo.CustomHttpRequest;\nimport org.acme.pojo.ResponseData;\n\nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\nimport javax.ws.rs.Produces;\nimport javax.ws.rs.container.ContainerRequestContext;\nimport javax.ws.rs.core.Context;\nimport javax.ws.rs.core.MediaType;\n\n@Path(\"/hello\")\npublic class GreetingResource {\n\n    @GET\n    @Path(\"{pathText}\")\n    @Produces(MediaType.APPLICATION_JSON)\n    public ResponseData testContext(@Context ContainerRequestContext crContext,\n                                    @PathParam(\"pathText\") String queryText) {\n\n        CustomHttpRequest httpRequest = (CustomHttpRequest) crContext.getProperty(\"customHttpRequest\");\n\n       return ResponseData.builder()\n                .queryText(queryText)\n                .httpRequestText(httpRequest.getText())\n                .secured(httpRequest.isSecured())\n                .build();\n    }\n}\n\nIs there any way to get same functionality in RestEasyReactive like you had in RestEasy using ResteasyContext.pushContext because it's really verbose and inefficient to retrieve each object from context and cast it because in my real example I have multiple custom objects pushed to context with ResteasyContext.pushContext.\nThank you!\n",
"AnswerId": "76389074",
"AnswerBody": "When using RESTEasy Reactive, there is a far easier way of doing things like this: just use a CDI request scoped bean.\nSomething like the following should be just fine:\n@Singleton\npublic class CustomHttpRequestProducer {\n\n    @RequestScoped\n    @Unremovable\n    public CustomHttpRequest produce(HttpHeaders headers) {\n        return new CustomHttpRequest(headers.getRequestHeaders(), LocalDateTime.now(), \"dummy\");\n    }\n}\n\nThen you would use it in your JAX-RS Resource as easily as:\n@GET\n@Produces(MediaType.TEXT_PLAIN)\npublic String hello(@Context CustomHttpRequest customHttpRequest) {\n    return customHttpRequest.getText();\n}\n\nNote that @Unremovable is only needed if you use CustomHttpRequest  as method parameter.\nIf you however inject it as a field, @Unremovable is unnecessary.\nUPDATE\nAfter https://github.com/quarkusio/quarkus/pull/33793 becomes part of Quarkus (likely in 3.2) then @Unremovable will no longer be necessary even for the method parameter\n"
},
{
"QuestionId": "76391970",
"QuestionTitle": "How to find an index of the ArrayList from the starting index in Java?",
"QuestionBody": "I want to search for an index of the element in the ArrayList but I want to start searching from starting index different than 0.\nI tried like this:\nimport java.util.*;\n\npublic class Test{\n    public static void main(String[] args) {\n        ArrayList<String> bricks = new ArrayList<String>(List.of(\"BBBB\",\"CCCC\",\"DDDD\"));\n        System.out.println(bricks.subList(1, bricks.size()).indexOf(\"CCCC\"));\n    }\n}\n\nOutput:\n0\n\nExpected output:\n1\n\nI want to start searching for \"CCCC\" in \"bricks\" from the starting index \"1\" not from \"0\"\n",
"AnswerId": "76392001",
"AnswerBody": "Your code finds the index within the sublist.\nTo find the index within the original list, add the index used to create the sublist to the result:\nSystem.out.println(bricks.subList(1, bricks.size()).indexOf(\"CCCC\") + 1);\n\nSome refactoring makes this clearer:\npublic static <T> int indexOfAfter(List<T> list, T item, int from) {\n    int result = list.subList(from, list.size()).indexOf(item);\n    return result == -1 ? -1 : (from + result);\n}\n\n"
},
{
"QuestionId": "76388533",
"QuestionTitle": "How do I create a single slicer from a group of columns",
"QuestionBody": "I have a data loaded into Power Bi that look like this:\n\n\n\n\nID\nTYPE\nProduct 1\nProduct 2\nProduct 3\n\n\n\n\n1\nA\n1\n1\n0\n\n\n1\nB\n0\n0\n1\n\n\n2\nA\n0\n1\n1\n\n\n2\nB\n1\n0\n1\n\n\n3\nA\n1\n0\n0\n\n\n\n\nSo every column besides the \"ID\" and \"TYPE\" columns, is a binary 0/1 column, that indicates whether certain person acquire given product.\nWhat I want to do, is to create a single dropdown slicer with Product 1, Product 2 and Product 3 values, that will filter only certain persons which acquire selected Product.\n",
"AnswerId": "76389099",
"AnswerBody": "If you cant get a table with one product column before you connect to Power-BI and everything else fails you can to the following:\nIn the query editor create a new query and refer it to your table above\n= YourTableName\nSo you get the table 3 times. Now for table one delete the columns 4 & 5, for table two delete columns 3 & 5 and for table three delete column 3 & 4. Then rename all columns identical ID, Type, Product.\nIn the last step you under Home > Append Queries you can append all three tables. Now you got your final table with just one Product column.\n"
},
{
"QuestionId": "76391852",
"QuestionTitle": "Recreate hist() binning in ggplot2 with geom_histogram()",
"QuestionBody": "(if you are only interested in the problem, then go to \"What if in short?\")\nWhat kind of stupid question?\nI'm doing work and before that I built all graphics with x and I don't want to change the style.\nAnd now I need a histogram, but it does not suit me with ggplot2.\nWhat do I mean?\nI took the width of the column from hist(), so there will be the same number of them\n(which can be seen from the graphs),\nbut in hist() and as I want,\nthe bars do NOT cross the important/magic number 0.0012,\nand in `geom_histogramm' intersects.\nAnd if it's short?\nHow to \"shift\" histogram bars with ggplot2 so that they do not cross a certain number (0.0012)?\nOr, how to make a histogram shorter with \"data\" from hist() and design with ggplot2?\nHere is my code:\n# check bin width\n  standart_hist <- hist(my_vector, plot = F)\n  bw <- standart_hist$breaks[2] - standart_hist$breaks[1]\n  \n  # create hist with ggplot and bw from standart hist\n  gghist <- ggplot(mapping = aes(my_vector)) +\n    geom_histogram(\n      binwidth = bw,\n      color = \"black\",\n      fill = \"white\"\n    ) \n\nand result:\n\nmy hist\n\n\n\nstandard hist\n\n\nFIX:\nfrom joran --- instead of geom_histogram() use stat_bin() as here:\nstat_bin(geom = 'bar',breaks = <breaks vector from hist() output>)\n\nMy data:\nmy_vector <- (0.001201367, 0.001199250, 0.001198337, 0.001199200, 0.001199353, 0.001198439, 0.001202447, 0.001205639, 0.001207056, 0.001209714, 0.001204478, 0.001200064, 0.001199386, 0.001199976, 0.001200569, 0.001204738, 0.001208508, 0.001201491, 0.001200995, 0.001199861, 0.001200242, 0.001196367, 0.001200365, 0.001201807, 0.001194364, 0.001197196, 0.001192705, 0.001196178, 0.001192991, 0.001189777, 0.001194227, 0.001197158, 0.001204336, 0.001201081, 0.001201100, 0.001204755, 0.001198810, 0.001202090, 0.001194370, 0.001188529, 0.001191450, 0.001193616, 0.001195733, 0.001198886, 0.001201353, 0.001206878, 0.001201262, 0.001194806, 0.001196192, 0.001193215, 0.001195030, 0.001198202, 0.001184351, 0.001191890, 0.001192882, 0.001194621, 0.001203256, 0.001204150, 0.001197425, 0.001198002, 0.001196185, 0.001194915, 0.001198281, 0.001201858, 0.001195349, 0.001196401, 0.001205476, 0.001201740, 0.001197276, 0.001189442, 0.001192760, 0.001196846, 0.001201342, 0.001204854, 0.001202979, 0.001203136, 0.001199926, 0.001197398, 0.001199905, 0.001199252, 0.001198486, 0.001197114, 0.001196829, 0.001200228, 0.001199666, 0.001194918, 0.001204005, 0.001201363, 0.001204183, 0.001205889, 0.001204553, 0.001202369, 0.001203922, 0.001197001, 0.001200020, 0.001202672, 0.001201746, 0.001203532, 0.001198699, 0.001200975, 0.001202635, 0.001203121, 0.001190614, 0.001199029, 0.001200372, 0.001193731, 0.001193428, 0.001200259, 0.001195203, 0.001194854, 0.001193173, 0.001198266, 0.001195362, 0.001195252, 0.001201008, 0.001199291, 0.001196653, 0.001200357, 0.001201623, 0.001207463, 0.001199381, 0.001198047, 0.001196305, 0.001200419, 0.001208689, 0.001197434, 0.001193885, 0.001198708, 0.001204741, 0.001204281, 0.001193663, 0.001200234, 0.001203809, 0.001199003, 0.001195127, 0.001192189, 0.001187610, 0.001191390, 0.001200602, 0.001197817, 0.001202045, 0.001203998, 0.001205508, 0.001201051, 0.001202057, 0.001208911, 0.001203928, 0.001202267, 0.001201434, 0.001202647, 0.001210024, 0.001210509, 0.001207881, 0.001206928, 0.001206128, 0.001203866, 0.001202204, 0.001204511, 0.001202310, 0.001197504, 0.001199019, 0.001200713, 0.001204197, 0.001204649, 0.001207965, 0.001201847, 0.001200585, 0.001203446, 0.001195972, 0.001202405, 0.001197182, 0.001191603, 0.001197663, 0.001202259, 0.001201008, 0.001200354, 0.001198090, 0.001193479, 0.001202457, 0.001201156, 0.001196038, 0.001201092, 0.001205488, 0.001212173, 0.001203497, 0.001208846, 0.001198349, 0.001200047, 0.001200799, 0.001206939, 0.001207142, 0.001201970, 0.001202742, 0.001204795, 0.001198463, 0.001201559, 0.001201344, 0.001206085, 0.001205526, 0.001197508)\n\n",
"AnswerId": "76392026",
"AnswerBody": "Using your data, I believe this does what you want:\nh <- hist(my_vector)\n\nggplot(data = data.frame(x = my_vector),aes(x = x)) + \n  stat_bin(geom = 'bar',breaks = h$breaks)\n\n"
},
{
"QuestionId": "76388593",
"QuestionTitle": "Jackson ignore unrecognized property and collect the errors",
"QuestionBody": "There are a lot of topics around how can we configure the Jackson to ignore additional properties during the un-marshaller process. But I didn't find any answer how can we ignore it but also collect the unrecognized properties.\nOur flow is: We would like to ignore them but collect all of the unrecognized properties in order to be aware of these properties and fix them.\nSomebody knows how can I achieve this?\n",
"AnswerId": "76389100",
"AnswerBody": "Using override DeserializationProblemHandler.handleUnknownProperty get unknown property name?\npublic class IgnoreUnknownPropertiesHandler extends DeserializationProblemHandler {\n            @Override\n            public boolean handleUnknownProperty(DeserializationContext ctxt, JsonParser p, JsonDeserializer<?> deserializer, Object beanOrClass, String propertyName) throws IOException {\n                // print ignored property\n                System.out.println(\"Ignored property: \" + propertyName);\n                return true;\n            }\n        }\n        \nObjectMapper objectMapper = new ObjectMapper();\nobjectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);\nobjectMapper.addHandler(new IgnoreUnknownPropertiesHandler());\n\n"
},
{
"QuestionId": "76390394",
"QuestionTitle": "Why nvim (vim) adds \\< and \\> to search pattern and what they means?",
"QuestionBody": "I use the * command to fill the search register (/) with the current word (under cursor) so I don't have to paste it into the substitute command.\nTo do a find and replace I can do it quickly like so:\n:%s//MyNewValue/g\n\ninstead of\n:%s/MyOldValue/MyNewValue/g\n\nBut sometimes I just want to change one character in the word (like a typo). So after I used * on the word, I do the following:\n:%s//<c-r>//g\n\nBut I get this:\n:%s//\\<MyOldValue\\>/g\n\nbecause the / register contains \\<MyOldValue\\>.\nSo, here's my question:\nHow can I get rid of these \\< and \\>? Or is there a better way to edit all occurrences of a word in vim?\nThe only way I found, it's to yank the word and paste it twice in the substitute pattern.\nyiw\n:%s/<c-r>\"/<c-r>\"/g\n\nAlso, what do \\< and \\> mean and what are they use for?\n",
"AnswerId": "76390482",
"AnswerBody": "The \\< and \\> are word boundaries, see :help \\< or :help \\>.\nThis is similar to the \"match whole word\" checkbox in the search dialog of graphical editors.\nFor example, it will do the following:\nPut the cursor on \"foo\" and press star.\nIt will match foo in this line.\nBut not foobar in this one.\n\nIf you don't want this, use g* instead of *. It will not add the word boundaries.\nIf you're using the :substitute command, you may as well use Ctrl+RCtrl+W (Ctrl+RCtrl+A for words-with-non-word-characters) to add the word under your cursor to the command line. In Vim, one would write it like this:\n:%s/<C-R><C-W>/MyNewValue/\n\n"
},
{
"QuestionId": "76388334",
"QuestionTitle": "Firestore save data in strange formation using Flutter",
"QuestionBody": "I try to save data on Firebase but the data is stored in strange way although the value is string like this:\nDescription\n\"TextEditingController#d9024(TextEditingValue(text: ┤├, selection: \nTextSelection.invalid, composing: TextRange(start: -1, end: -1)))\"\nPrice\n\"TextEditingController#c11e0(TextEditingValue(text: ┤├, selection: \nTextSelection.invalid, composing: TextRange(start: -1, end: -1)))\"\nTitle\n\"TextEditingController#dcebb(TextEditingValue(text: ┤├, selection: \nTextSelection.invalid, composing: TextRange(start: -1, end: -1)))\"\nUID\n\"gWYqXqsvTdVI1Sfa8MP4SrFTEmB2\"\n\nhere is my code:\nfinal adTitleController = TextEditingController();\nfinal priceController = TextEditingController();\nfinal adDescription = TextEditingController();\n\nFuture<void> createAds() async {\nCollectionReference ads = FirebaseFirestore.instance.collection('Ads');\n\nString? adid = ads.id.toString();\n\nString? title = adTitleController.toString();\nString? desc = adDescription.toString();\nString? price = priceController.toString();\nString? userId;\nString? adId;\nads.add({\n  \"UID\": FirebaseAuth.instance.currentUser?.uid,\n  \"AdId\": adId,\n  \"Title\": title,\n  \"Description\": desc,\n  \"Price\": price,\n});\n}\n\n",
"AnswerId": "76389142",
"AnswerBody": "In order to get a text from the controller you need to use text property of TextEditingController\nString? title = adTitleController.text.toString();\nString? desc = adDescription.text.toString();\nString? price = priceController.text.toString();\n\n"
},
{
"QuestionId": "76391687",
"QuestionTitle": "Struggling to type a TypeScript function",
"QuestionBody": "I've got this TypeScript error and I don't fully understand what's going on:\nsrc/helpers.ts:11:14 - error TS2322: Type '<T extends \"horizontal\" | \"vertical\" | undefined, U extends AriaRole | undefined>(ariaOrientation: T, role: U) => \"horizontal\" | \"vertical\" | NonNullable<T> | \"both\"' is not assignable to type 'ResolveOrientationFunction'.\n  Type '\"horizontal\" | \"vertical\" | NonNullable<T> | \"both\"' is not assignable to type 'NonNullable<T> | \"both\"'.\n    Type '\"horizontal\"' is not assignable to type 'NonNullable<T> | \"both\"'.\n\nHere is my function:\nimport { type HTMLAttributes } from \"react\";\n\ntype ResolveOrientationFunction = <\n  T extends HTMLAttributes<HTMLElement>[\"aria-orientation\"],\n  U extends HTMLAttributes<HTMLElement>[\"role\"]\n>(\n  ariaOrientation: T,\n  role: U\n) => \"both\" | NonNullable<T>;\n\nexport const resolveOrientation: ResolveOrientationFunction = (ariaOrientation, role) => {\n  if (ariaOrientation === undefined) {\n    switch (role) {\n      case \"menubar\":\n      case \"slider\":\n      case \"tablist\":\n      case \"toolbar\": {\n        return \"horizontal\";\n      }\n\n      case \"listbox\":\n      case \"menu\":\n      case \"scrollbar\":\n      case \"tree\": {\n        return \"vertical\";\n      }\n    }\n  }\n\n  return ariaOrientation ?? \"both\";\n};\n\nThe function is supposed to return \"both\" | \"horizontal\" | \"vertical\".\nHTMLAttributes<HTMLElement>[\"aria-orientation\"] is actually \"horizontal\" | \"vertical\" | undefined and HTMLAttributes<HTMLElement>[\"role\"] is React.AriaRole | undefined.\nI'm actually trying to make this function match the type \"both\" | NonNullable<HTMLAttributes<HTMLElement>[\"aria-orientation\"]>.\n",
"AnswerId": "76392032",
"AnswerBody": "Your ResolveOrientationFunction type definition,\ntype ResolveOrientationFunction = <\n  T extends HTMLAttributes<HTMLElement>[\"aria-orientation\"],\n  U extends HTMLAttributes<HTMLElement>[\"role\"]\n>(\n  ariaOrientation: T,\n  role: U\n) => \"both\" | NonNullable<T>;\n\nis generic in both T, the type of ariaOrientation, and U, the type of role.  It returns a value of type \"both\" | NonNullable<T>.  So if T is undefined because ariaOrientation is undefined, then the function must return \"both\" | NonNullable<undefined> which is \"both\".  But your implementation doesn't do that.  It can instead return \"horizontal\" or \"vertical\" depending on role.\nSo your resolveOrientation function is not a valid ResolveOrientation.\n\nIt's not clear that you need the function to be generic at all.  Certainly the U type parameter isn't useful as written, since it has no effect on the return type.  And you don't really want the T type parameter to be reflected directly in the output type either.  It seems like your return type should just be \"both\" | \"vertical\" | \"horizontal\" without reference to T or U.  And if you have a generic function where there's no obvious dependency on the type parameters, then you might not want a generic function in the first place.\nIf you change the generics to specific types like this:\ntype AriaOrientation = HTMLAttributes<HTMLElement>[\"aria-orientation\"];\ntype AriaRole = HTMLAttributes<HTMLElement>[\"role\"]\ntype ResolveOrientationFunction =\n    (ariaOrientation: AriaOrientation, role: AriaRole) => \n    \"both\" | NonNullable<AriaOrientation>;\n\nThen your function compiles cleanly:\nexport const resolveOrientation: ResolveOrientationFunction = (ariaOrientation, role) => {\n    if (ariaOrientation === undefined) {\n        switch (role) {\n            case \"menubar\":\n            case \"slider\":\n            case \"tablist\":\n            case \"toolbar\": {\n                return \"horizontal\";\n            }\n\n            case \"listbox\":\n            case \"menu\":\n            case \"scrollbar\":\n            case \"tree\": {\n                return \"vertical\";\n            }\n        }\n    }\n\n    return ariaOrientation ?? \"both\";\n};\n\nPlayground link to code\n"
},
{
"QuestionId": "76390348",
"QuestionTitle": "Is there a way to make Google wait until all data is loaded for my React website hosted on Firebase with a DB from Firebase before indexing?",
"QuestionBody": "I created a Website for my Wife's Blog in React and am hosting it on Firebase. I also use DB from firebase.\nAfter the site release I found out that Google is not waiting until all data is finally loaded from the site to index the final site, but is trying to index a loading site.\nFor now I solved the issue with prerender with the following package (as per simple implementation in our site):\nhttps://github.com/egoist/presite\nThe Issue of it is it prerenders only the English (default) site and not any other languages so indexing is mostly done on English sites (other languages are ignored) and as the site is prerendered Google sometimes loses the index of the site because of it.\nI also checked multiple other prerender options but currently no other has the simplicity of implementation and support of dynamic site (some sites --> each recipe has a template site that is loaded from DB and rendered on the client).\nAny Ideas how to solve these issue? Possible to use without prerender and get Google wait on loading data for the site?\nFor Information/check the site itself: https://fromapot.com/\n",
"AnswerId": "76390491",
"AnswerBody": "SEO is known problem of SPA websites built with front-end frameworks/libraries. The only options are to: prerender or use SSR (Server Side Rendering).\nFor your case, I would suggest using the second option since you want to have dynamic indexing depending on language.\nWhen using SSR, you typically need a NodeJS server that listens to requests and creates the initial layout based on the requested route on the server. This layout is then sent to the front-end along with some additional information, which allows the rest of the website to function properly.\nMost easy and powerful way to do that is NextJS framework, but depending on your build system, you may have other options. For example, for Vite, there is a simple plugin which enables SSR with almost zero effort.\nThere is no way to configure that Google waits for dynamic front-end render because it will require Google to support JS runtime which is too heavy for indexing engine which visits probably millions of websites each day.\n"
},
{
"QuestionId": "76388160",
"QuestionTitle": "search method optimization for searching field area in odoo15",
"QuestionBody": "I have a function\n    def test(self):\n        tech_line = self.env['tech_line']\n        allocated_technician = self.env['allocated_technician']\n        users = self.env['res.users']\n        tech_line = tech_line.search(\n            [('service_type_id', '=', self.service_type_id.id)])\n        al_a6 = self.env['tech_line'].filtered(lambda rec: rec.service_type_id.id == self.service_type_id.id)\n\n        area = []\n        area_new = []\n        for tec in tech_line:\n            territory = self.env['territory']\n            territories = territory.search(\n                [('technicians', 'in', tec.technician_allociated_id.user_id.id)])\n\n            territories_lam = self.env['territory'].filtered(\n                lambda t_lam: t_lam.technicians.id in tec.technician_allociated_id.user_id.id)\n\n            for territory in territories:\n                area.append(territory.id)\n            for tet in territories_lam:\n                area_new.append(tet.id)\n\n        print('##################33', len(area))\n        print('%%%%%%%%%%%%%%%%%%%%', len(area_new))\n        \n        print('$$$$$$$$$$$$$$$$$$$', tech_line)\n        print('***************8***', al_a6)\n\nthis method when executed screen gets loading and I need to optimize this method, please do share your thoughts on how to optimize this code\nI cannot limit the value which is generated from the search method as we need all of its value so instead of that I thought to use filtered instead of search method, but when I use filtered it gives an empty recordset. need help with that\n",
"AnswerId": "76389158",
"AnswerBody": "You can avoid searching in the for loop by using a search on all users:\ndef test(self):\n    tech_line = self.env['tech_line']\n    tech_lines = tech_line.search(\n        [('service_type_id', '=', self.service_type_id.id)])\n    # get all users to avoid search in a for loop\n    users = tech_lines.mapped(\"technician_allociated_id.user_id\")\n    # search territories\n    territories = territory.search([('technicians', 'in', users.ids)])\n    \n    area = territories.ids\n\n"
},
{
"QuestionId": "76391751",
"QuestionTitle": "if match between column ID in two different datasets, then create a new dataset with the difference of other columns r",
"QuestionBody": "I have two datasets using r:\ndf_100= data.frame(siteid=c(seq(1,5,1),conflu=c(3,2,4,5,6),diflu=c(9,2,30,2,5))\ndf_full= data.frame(siteid=c(seq(1,10,2),conflu=c(6,3,5,2,3),diflu=c(5,9,2,30,7))\n\nIf the siteid is the same between df_100 and df_full, I want to take the difference between the conflu columns of each data frame and the same with the diflu columns. I also want that output to be put into a new dataframe, where the siteid is retained and the difference between the columns creates a new column. For example:\ndf_difference=data.frame(siteid=c(1,3,5), diff_con=c(3,1,-3), diff_dif=c(-4,-18,2))\n\n",
"AnswerId": "76392039",
"AnswerBody": "I don't follow the calculations to get what you have as the sample output, but based on your description:\nlibrary(dplyr)\n\ndf_100 <- data.frame(siteid= seq(1,5,1),conflu=c(3,2,4,5,6),diflu=c(9,2,30,2,5))\n\ndf_full <- data.frame(siteid = seq(1,10,2),conflu=c(6,3,5,2,3),diflu=c(5,9,2,30,7))\n\ndf_difference <- df_100 |> \n  inner_join(df_full, by = \"siteid\", suffix = c(\"_100\", \"_full\")) |> \n  mutate(\n    diff_con = conflu_full - conflu_100,\n    diff_dif = diflu_full - diflu_100\n  ) |> \n  select(siteid, diff_con, diff_dif)\n\ninner_join will match and keep only the rows with same \"siteid\". Then use mutate to do the calculations and select the columns you want.\n"
},
{
"QuestionId": "76391960",
"QuestionTitle": "R Studio add_row with dynamic field name",
"QuestionBody": "I have a function here, where my intent is to add a record to the table.  The column name is dynamically defined based on the firstCharVar variable.\nThe dataframe tblname is a blank table.  The first character field in that table is called myvar.  There are other columns in that table, and they should remain blank.\n#update tables if no records\nNoData = function(tblname) {\n  if (nrow(tblname) == 0) {\n\n  #get column name of first character field\n  allColumns = data.frame(\n    colName = colnames(tblname),\n    colIndex = 1:ncol(tblname),\n    colClass = sapply(tblname, class)\n  )\n  charVars     = allColumns[allColumns$colClass == 'character', ]\n  firstCharVar = unfactor(charVars$colName[1])\n\n  #run insert statement\n  #this doesn't work\n  #Error: unexpected '=' in \"tblname = tblname %>% add_row(!!firstCharVar =\"\n  #tblname = add_row(tblname, !!firstCharVar = 'No Data Found')\n\n  #but this does\n  tblname = add_row(tblname, myvar = 'No Data Found')\n\n  \n  #clean up stuff used in function\n  #rm(allColumns, charVars, firstCharVar)\n}}\n\ntemp2 = NoData(temp2)\n\n",
"AnswerId": "76392049",
"AnswerBody": "As in other dpylr verbs you could assign values to dynamically created LHS names by using the walrus operator := and !!sym(col) or glue syntax \"{col}\".\nUsing a minimal reproducible example based on mtcars:\nlibrary(dplyr, warn=FALSE)\n\ncol <- \"cyl\"\nmtcars |> \n  head() |> \n  add_row(cyl = 1) |> \n  add_row(\"{col}\" := 2) |> \n  add_row(!!sym(col) := 3)\n#>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n#> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n#> ...7                NA   1   NA  NA   NA    NA    NA NA NA   NA   NA\n#> ...8                NA   2   NA  NA   NA    NA    NA NA NA   NA   NA\n#> ...9                NA   3   NA  NA   NA    NA    NA NA NA   NA   NA\n\n"
},
{
"QuestionId": "76390325",
"QuestionTitle": "Change rgb color of text on overlap",
"QuestionBody": "I'm using mix-blend-mode to change the background color of an image. The problem I'm facing is that I've a grey-ish text which overlaps the background image intentionally when shown on a mobile device. This makes however the text unreadable. I've tried all variations of mix-blend-modes and believe my only option is to entirely change the color of the text when it's overlapping.\nHow can I change the color of a text when it's overlapping another element?\nHere is the fiddle:\nhttps://jsfiddle.net/zr8men95/\nRelevant portion:\n.promo__text {\n  grid-area: text;\n  z-index: 1;\n  margin-left: 1rem;\n  margin-right: 1rem;\n  color: #6B7F92;\n  text-shadow: 0 0 0 black;\n}\n\n",
"AnswerId": "76390505",
"AnswerBody": "I believe your best shot would be to change the text color when you are on an mobile device. I've read your fiddle and you already have some @media zone defined. We can take advantage of that to add some CSS to change the text color whilst in mobile mode.\nThis block of code:\n@media (min-width: 640px) and (max-width: 1024px) {\n  .promos {\n    display: grid;\n    grid-template-columns: 1fr 1fr;\n    grid-gap: 1rem;\n  }\n}\n\nWill change for this:\n@media (min-width: 640px) and (max-width: 1024px) {\n  .promos {\n    display: grid;\n    grid-template-columns: 1fr 1fr;\n    grid-gap: 1rem;\n  }\n  \n  .promo__text {\n    color: white; // You can change the color to whatever fits your need\n  }\n}\n\nHope that help!\n"
},
{
"QuestionId": "76391983",
"QuestionTitle": "How to only get _source fields of elasticsearch using Spring Data Elastic?",
"QuestionBody": "I am using Spring Boot and Spring Data Elastic. I have an accounts index data like below\n\npublic interface AccountsRepository extends ElasticsearchRepository<Accounts, Long> {\n    \n    List<Accounts> findByLastname(String lastname);\n    \n    List<Accounts> findByAge(Integer age);\n}\n\nI am getting below error when perform findAll(). How to fix the below issue?\n@Service\npublic class AccountsService {\n    @Autowired\n    private AccountsRepository repository;\n\n    public List<Accounts> findAllAccounts(){\n        return (List<Accounts>) repository.findAll();\n    }\n}\n\nModel\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\n@Document(indexName = \"accounts\", createIndex = false)\npublic class Accounts {\n    @Id\n    private Long account_number;\n    private Long balance;\n    private String firstname;\n    private String lastname;\n    private Integer age;\n    private String gender;\n    private String address;\n    private String employer;\n    private String email;\n    private String city;\n    private String state;\n}\n\nError:\n2023-06-02 21:23:23.784  WARN 44796 --- [nio-8080-exec-1] org.elasticsearch.client.RestClient      : request [POST http://localhost:9200/accounts/_search?typed_keys=true&max_concurrent_shard_requests=5&search_type=query_then_fetch&batched_reduce_size=512] returned 1 warnings: [299 Elasticsearch-7.15.0-79d65f6e357953a5b3cbcc5e2c7c21073d89aa29 \"Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\"]\n2023-06-02 21:23:23.878  WARN 44796 --- [nio-8080-exec-1] org.elasticsearch.client.RestClient      : request [POST http://localhost:9200/accounts/_search?typed_keys=true&max_concurrent_shard_requests=5&search_type=query_then_fetch&batched_reduce_size=512] returned 1 warnings: [299 Elasticsearch-7.15.0-79d65f6e357953a5b3cbcc5e2c7c21073d89aa29 \"Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\"]\n2023-06-02 21:23:24.170 ERROR 44796 --- [nio-8080-exec-1] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type [java.lang.String] to type [java.lang.Long] for value 'KH-9fIgBhfTLJt8QzMP_'; nested exception is java.lang.NumberFormatException: For input string: \"KH-9fIgBhfTLJt8QzMP_\"] with root cause\n\njava.lang.NumberFormatException: For input string: \"KH-9fIgBhfTLJt8QzMP_\"\n    at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ~[na:na]\n    at java.base/java.lang.Long.parseLong(Long.java:692) ~[na:na]\n    at java.base/java.lang.Long.valueOf(Long.java:1144) ~[na:na]\n    at org.springframework.util.NumberUtils.parseNumber(NumberUtils.java:214) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.core.convert.support.StringToNumberConverterFactory$StringToNumber.convert(StringToNumberConverterFactory.java:64) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.core.convert.support.StringToNumberConverterFactory$StringToNumber.convert(StringToNumberConverterFactory.java:50) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.core.convert.support.GenericConversionService$ConverterFactoryAdapter.convert(GenericConversionService.java:437) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:41) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:192) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:175) ~[spring-core-5.3.21.jar:5.3.21]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.getPotentiallyConvertedSimpleRead(MappingElasticsearchConverter.java:562) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.readValue(MappingElasticsearchConverter.java:460) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.readValue(MappingElasticsearchConverter.java:442) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader$ElasticsearchPropertyValueProvider.getPropertyValue(MappingElasticsearchConverter.java:621) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.readProperties(MappingElasticsearchConverter.java:404) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.readEntity(MappingElasticsearchConverter.java:327) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.read(MappingElasticsearchConverter.java:258) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter$Reader.read(MappingElasticsearchConverter.java:217) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter.read(MappingElasticsearchConverter.java:161) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.convert.MappingElasticsearchConverter.read(MappingElasticsearchConverter.java:83) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.AbstractElasticsearchTemplate$ReadDocumentCallback.doWith(AbstractElasticsearchTemplate.java:745) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ~[na:na]\n    at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ~[na:na]\n    at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ~[na:na]\n    at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ~[na:na]\n    at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ~[na:na]\n    at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:na]\n    at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ~[na:na]\n    at org.springframework.data.elasticsearch.core.AbstractElasticsearchTemplate$ReadSearchDocumentResponseCallback.doWith(AbstractElasticsearchTemplate.java:778) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.AbstractElasticsearchTemplate$ReadSearchDocumentResponseCallback.doWith(AbstractElasticsearchTemplate.java:763) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.core.ElasticsearchRestTemplate.search(ElasticsearchRestTemplate.java:404) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.repository.support.SimpleElasticsearchRepository.lambda$findAll$1(SimpleElasticsearchRepository.java:123) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.repository.support.SimpleElasticsearchRepository.execute(SimpleElasticsearchRepository.java:355) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.repository.support.SimpleElasticsearchRepository.findAll(SimpleElasticsearchRepository.java:123) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at org.springframework.data.elasticsearch.repository.support.SimpleElasticsearchRepository.findAll(SimpleElasticsearchRepository.java:112) ~[spring-data-elasticsearch-4.4.1.jar:4.4.1]\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\n    at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]\n    at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.21.jar:5.3.21]\n    at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.1.jar:2.7.1]\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.21.jar:5.3.21]\n    at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.21.jar:5.3.21]\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.21.jar:5.3.21]\n    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215) ~[spring-aop-5.3.21.jar:5.3.21]\n    at com.sun.proxy.$Proxy59.findAll(Unknown Source) ~[na:na]\n    at com.example.service.AccountsService.findAllAccounts(AccountsService.java:16) ~[classes/:na]\n    at com.example.controller.AccountsController.findAllAccounts(AccountsController.java:19) ~[classes/:na]\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\n    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\n    at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:655) ~[tomcat-embed-core-9.0.64.jar:4.0.FR]\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.21.jar:5.3.21]\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) ~[tomcat-embed-core-9.0.64.jar:4.0.FR]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.21.jar:5.3.21]\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1787) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.64.jar:9.0.64]\n    at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]\n\n",
"AnswerId": "76392056",
"AnswerBody": "You marked the property account_number of your entity, which is a Long, as the @Id. But the id in your index is a String (here with the value \"KH-9fIgBhfTLJt8QzMP_\").\nAdd proper id property:\n@Id\nprivate String id;\n\nEdit: 03.06.2023:\nAs for the error\n\njava.lang.ClassCastException: class org.springframework.data.domain.PageImpl cannot be cast to class java.util.List (org.springframework.data.domain.PageImpl\n\nfindAll() is defined to return an Iterable, which is an interface. The actual returned objects is of type PageImpl which implements Page which extends Iterable.\nYou cannot cast a Page implementation to a List<Accounts>.\n"
},
{
"QuestionId": "76388624",
"QuestionTitle": "How can I filter differences of datasets in a table",
"QuestionBody": "I am relativly new to SQL and I have a short question. I already searched for similar questions in stackOverflow but I couldn't find anything.I have created some Views. These Views change from one Version to antother. To make migration easier for the customer, I want to filter differences in data_types of columns between two versions. Currently I'm working PostgreSQL Version 11.16\nI have table that looks like this:\n\n\n\n\nversionsnummer\ninstall_timestamp\ncolumn_name\ndata_type\n\n\n\n\nD1\n2023-06-02 06:42:14.531588\nt0801_01\ninteger\n\n\nD1\n2023-06-02 06:42:14.531588\nt0801_04\ncharacter varying\n\n\nD2\n2023-07-02 06:42:14.531588\nt0801_01\ninteger\n\n\nD2\n2023-07-02 06:42:14.531588\nt0801_04\ninteger\n\n\n\n\nNow I want to find all rows where the value of the column data_type has changed between two versions.\nSo I'm expecting the following result:\n\n\n\n\nversionsnummer\ninstall_timestamp\ncolumn_name\ndata_type\n\n\n\n\nD1\n2023-06-02 06:42:14.531588\nt0801_04\ncharacter varying\n\n\nD2\n2023-06-02 06:42:14.531588\nt0801_04\ninteger\n\n\n\n\nWhat I've tried is this:\nSELECT DISTINCT ON (column_name, data_type) column_name, data_type FROM mytable WHERE versionsnummer = 'D1' OR versionsnummer = 'D2';\nUnfortunately I didn't get the expectes Result with this query. Could you please tell me waht i'm doing wrong here?\nThank you very much :)\n",
"AnswerId": "76389229",
"AnswerBody": "I think you can achieve this via \"SELF JOIN\". Join the tables with itself on \"column_name\" column.\nHere is the code:\nSELCT t1.versionsnummer, t1.install_timestamp, t1.column_name, t1.data_type\nFROM [your_table_name] t1\nJOIN [your_table_name] t2 ON t1.column_name = t2.column_name\nWHERE t1.data_type <> t2.data_type;\n\nExample: If you select all columns from the table, you will get:\n\n\n\n\nversionsnummer\ninstall_timestamp\ncolumn_name\ndata_type\n\n\n\n\nD1\n2023-06-02 06:42:14.531\nt0801_04\ncharacter_varing\n\n\nD2\n2023-07-02 06:42:14.531\nt0801_04\ninteger\n\n\n\n\nTested here:\n\n*Don't forget to change table name in this query!\n"
},
{
"QuestionId": "76390367",
"QuestionTitle": "Defining an emacs minor mode",
"QuestionBody": "Have coded an emacs minor mode with the definition shown below.\nWould it be possible to simplify this, to perhaps call a function instead?  Or is it not such a big deal having a minor-mode defined in this way ?\nWhat would be the general way to set a minor-mode in terms of functionality (e.g. enable, disable, ...) ?\n(defcustom komis-luna-signal t\n  \"todo\"\n  :group 'komis-luna)\n\n;;;###autoload\n(define-minor-mode komis-luna-minor-mode\n  \"Uses large geometric shapes for displaying heading levels.\"\n  nil nil nil\n\n  (let*\n      (($keyword\n        `((\"^\\\\*+ \"\n           (0 (let* ( ($kondor\n                         (- (match-end 0) (match-beginning 0) 1))\n                      ($inline-task\n                         (and (boundp 'org-inlinetask-min-level)\n                              (>= $kondor org-inlinetask-min-level))) )\n                ;;--------------------------------------\n                (compose-region (- (match-end 0) 2)\n                                (- (match-end 0) 1)\n                                (komis-luna-shape-select $kondor))\n               ;;---------------------------------------\n               (when $inline-task\n                  (compose-region (- (match-end 0) 3)\n                                  (- (match-end 0) 2)\n                                  (komis-luna-shape-select $kondor)))\n               ;;---------------------------------------\n               (when (facep komis-luna-typeface)\n                  (put-text-property\n                     (- (match-end 0) (if $inline-task 3 2))\n                     (- (match-end 0) 1)\n                     'face komis-luna-typeface))\n               ;;---------------------------------------\n               (put-text-property\n                  (match-beginning 0)\n                  (- (match-end 0) 2)\n                  'face (list :foreground\n                        (face-attribute 'default :background)))\n               ;;---------------------------------------\n               (put-text-property (match-beginning 0)\n                                  (match-end 0)\n                                  'keymap komis-luna-mouse-sweep)\n               ;;---------------------------------------\n               nil )) ))))\n\n    (if komis-luna-signal\n\n        (progn\n          (font-lock-add-keywords nil $keyword)\n          (font-lock-fontify-buffer))\n\n      (save-excursion\n        (goto-char (point-min))\n        (font-lock-remove-keywords nil $keyword)\n        (while (re-search-forward \"^\\\\*+ \" nil t)\n          (decompose-region (match-beginning 0) (match-end 0)) )\n        (font-lock-fontify-buffer)) ) ))\n\n",
"AnswerId": "76390507",
"AnswerBody": "I think you did it the proper way.\nNext would be to toggle your minor mode in your emacs configuration file .emacs.d/init.el with a hook probably like this :\n(add-hook 'org-mode-hook 'komis-luna-minor-mode)\n\nIf you want your minor mode to be enable when entering org-mode.\nFor further and more specifics questions and problems, you should probably take this post to Emacs Stack Exchange.\n"
},
{
"QuestionId": "76391607",
"QuestionTitle": "How to pass array to Ansible URI module",
"QuestionBody": "I'm trying to pass an array using extravars to the Ansible URI module.\n% ansible-playbook someplaybook.yml -e '{ \"letters\": [ \"aa\", \"ab\", \"ac\", \"ad\", \"ae\" ] }'\n\nWhen I run it through the URI module, I'm getting [ \"['aa', 'ab', 'ac', 'ad', 'ae']\" ] in the response. How do I send the entire array without the brackets and quotes. I've tried \"{{ letters | replace(\"[\", \"\") | replace(\"]\", \"\") }}\" but that doesn't get rid of the exterior quotes.\n  - name: Create a letter job\n    uri:\n      url: 'http://localhost:8000/api/app'\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: '{ \"letters\": [ \"{{ letters }}\" ] }'\n      body_format: json\n      return_content: yes\n    register: response\n\nCurrent Output:\n\"response\": {\n    \"id\": 2796831356421,\n    \"letters\": [\n      \"['aa', 'ab', 'ac', 'ad', 'ae']\"\n    ],\n    \"lastError\": null\n}\n\nDesired Output:\n\"response\": {\n    \"id\": 2796831356421,\n    \"letters\": [\n      'aa', 'ab', 'ac', 'ad', 'ae'\n    ],\n    \"lastError\": null\n}\n\n",
"AnswerId": "76392057",
"AnswerBody": "Your letters variable is a list, but when you write:\n\"{{ letters }}\"\n\nYou are asking -- explicitly -- to render it as a simple string. You don't want that; you want to maintain the structure of the data. You can do that like this:\n- name: Create a letter job\n  uri:\n    url: 'http://localhost:8000/api/app'\n    method: POST\n    headers:\n      Content-Type: application/json\n    body: '{{ { \"letters\": letters } }}'\n    body_format: json\n    return_content: yes\n  register: response\n\nHere, we're using a Jinja template ({{ ... }}) to create dictionary with a single key, letters, whose value is the content of your letters variable.\nUsing this sample application:\nfrom pydantic import BaseModel\nfrom fastapi import FastAPI\n\n\nclass Letters(BaseModel):\n    letters: list[str]\n\n\napp = FastAPI()\n\n\n@app.post(\"/api/app\")\ndef echo(letters: Letters) -> Letters:\n    return letters\n\nAnd the following playbook:\n- hosts: localhost\n  gather_facts: false\n  tasks:\n    - name: Create a letter job\n      uri:\n        url: 'http://localhost:8000/api/app'\n        method: POST\n        headers:\n          Content-Type: application/json\n        body: '{{ { \"letters\": letters } }}'\n        body_format: json\n        return_content: yes\n      register: response\n\n    - debug:\n        var: response\n\nWe see as output:\nTASK [debug] ********************************************************************************************\nok: [localhost] => {\n    \"response\": {\n        \"changed\": false,\n        \"connection\": \"close\",\n        \"content\": \"{\\\"letters\\\":[\\\"aa\\\",\\\"ab\\\",\\\"ac\\\",\\\"ad\\\",\\\"ae\\\"]}\",\n        \"content_length\": \"38\",\n        \"content_type\": \"application/json\",\n        \"cookies\": {},\n        \"cookies_string\": \"\",\n        \"date\": \"Fri, 02 Jun 2023 16:42:50 GMT\",\n        \"elapsed\": 0,\n        \"failed\": false,\n        \"json\": {\n            \"letters\": [\n                \"aa\",\n                \"ab\",\n                \"ac\",\n                \"ad\",\n                \"ae\"\n            ]\n        },\n        \"msg\": \"OK (38 bytes)\",\n        \"redirected\": false,\n        \"server\": \"uvicorn\",\n        \"status\": 200,\n        \"url\": \"http://localhost:8000/api/app\"\n    }\n}\n\n...which I think is exactly what you were after.\n"
},
{
"QuestionId": "76388538",
"QuestionTitle": "Cannot write a paragraph to a pdf file using iText pdf",
"QuestionBody": "I am using Java 17 and the iText pdf library (5.5.4), I'm currently attempting to write a paragraph on an existing pdf file inside a rectangular area, however I seem to have a NullPointerExeption when invoking the go() method, I'm not sure exactly why. I have included my code, any help would be appreciated.\npublic class Main {\n    public static void main(String[] args) {\n        try {\n\n            PdfReader reader = new PdfReader(\"src/main/resources/test_file.pdf\");\n\n\n            PdfStamper stamper = new PdfStamper(reader, new FileOutputStream(\"src/main/resources/output.pdf\"));\n\n            PdfContentByte cb = stamper.getOverContent(1);\n            ColumnText ct = new ColumnText(cb);\n            ct.setSimpleColumn(new Rectangle(36, 600, 200, 800));\n            ct.addElement(new Paragraph(\"I want to add this text in a rectangle defined by the coordinates llx = 36, lly = 600, urx = 200, ury = 800\"));\n            int status = ct.go();\n\n\n\n        } catch (DocumentException | IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n}\n\nException in thread \"main\" java.lang.NullPointerException: Cannot invoke \"com.itextpdf.text.pdf.PdfStructureElement.getAttribute(com.itextpdf.text.pdf.PdfName)\" because \"this.parent\" is null\n",
"AnswerId": "76389242",
"AnswerBody": "I could reproduce your issue using your example file with iText 5.5.4. Then I tried again with the current 5.5.13.3. There was no issue. Thus, please update.\nComparing the 5.5.4 code (where the exception occurs) with the corrsponding 5.5.13.3 code, one sees that there indeed was an unconditional call of a method of a parent object but that now there is a call to a helper method that first checks the parent and only calls its method if it isn't null.\nThis fix has been applied in early 2015, the commit comment was \"Fixed NPE when modifying content of TaggedPDF document.\".\n"
},
{
"QuestionId": "76380856",
"QuestionTitle": "How can I replace matches in a Python regex with a modified version of the match?",
"QuestionBody": "I wrote this code to search a specific folder's text files for word matches and to specify them:\nimport re, os, sys\nfrom pathlib import Path\n\n#Usage: regs directory\ntry:\n    if len(sys.argv) == 2:\n        folder = sys.argv[1]\n        fList = os.listdir(folder)\n        uInput = input('input a regex: ')\n        regObj = re.compile(f'''{uInput}''')\n        wordReg = re.compile(r'''([A-Za-z0-9]+|\\s+|[^\\w\\s]+)''')\n        matches = []\n        print(fList)\n\n        for file in fList:\n            if not os.path.isdir(Path(folder)/Path(file)):\n                currentFileObj = open(f'{folder}/{file}')\n                content = currentFileObj.readlines()\n                currentFileObj.seek(0)\n                text = currentFileObj.read()\n                words = wordReg.findall(text)\n                matches = list(filter(regObj.match, words))\n                instances = 0\n                print(f\"matches in ({file}):\\n'\", end='')\n                for word in words:\n                    if word in matches:\n                        print(\"\\u0333\".join(f\"{word} \"), end='')\n                    else:\n                        print(word, end='')\n                print(\"'\")\n                for line in content:\n                    matches = regObj.findall(line)\n                    for match in matches:\n                        print(\"\\u0333\".join(f\"{match} \"), end=' ')\n                        print(f\"in line number {content.index(line)+1}\")\n                        if match != '':\n                            instances = instances + 1\n                print(f'number of instances found: {instances}\\n')\n            else:\n                continue\n    else:\n        print('Usage: regs directory')\nexcept FileNotFoundError:\n    print(\"that file doesn't exist.\")\nexcept PermissionError:\n    print(\"you don't have permission to search that folder.\")\n\nit works for the most part except for a few regular expressions, if the regular expression has punctuation or a white space character next to other characters it wouldn't underline it, it may work if i find out a way to substitute matches with a modified version of the match (replacing the match with an underlined version)\nAnyone knows a fix ?\nhere's what it looks like for any other regex.\nyou can see in the first text file it doesn't underline the match (out.)\ni tried looking for functions that would substitute matches with a modification of said match, doesn't appear like there's any ?\nalso there's the minor problems of it not being able to underline whitespaces and punctuation properly, and the underline character doesn't appear in the windows7 command prompt, maybe a different character other than the underline can work ?\n",
"AnswerId": "76389538",
"AnswerBody": "I've figured out the answer:\nusing a lambda function as a repl= variable with re.sub i was capable of modifying the matches and then using them to substitute.\n    import re, os, sys\n    from pathlib import Path\n\n    #Usage:regs directory\n    try:\n        if len(sys.argv) == 2:\n            folder = sys.argv[1]\n            fList = os.listdir(folder)\n            print(\"folder contents: \", end=' ')\n            for f in fList:\n                if not f == fList[-1]:\n                    print(f, end=', ')\n                else:\n                    print(f, end='.\\n\\n')\n            uInput = input('input a regex: ')\n            print()\n            regObj = re.compile(f'''{uInput}''')\n            wordReg = re.compile(r'''([A-Za-z0-9]+|\\s+|[^\\w\\s]+)''')\n            matches = []\n            \n            for file in fList:\n                if os.path.isfile(Path(folder)/Path(file)):\n                    currentFileObj = open(f'{folder}/{file}')\n                    lines = currentFileObj.readlines()\n                    currentFileObj.seek(0)\n                    text = currentFileObj.read()\n                    words = wordReg.findall(text)\n                    matches = list(filter(regObj.match, words))\n                    instances = 0\n                    print(f\"matches in ({file}):\\n'\", end='')\n                    print(regObj.sub(lambda match: \"(\" + match.group() + \")\", text)+\"'\")\n                    for line in lines:\n                        matches = regObj.findall(line)\n                        for match in matches:\n                            print((f\"({match})\"), end=' ')\n                            print(f\"in line number {lines.index(line)+1}\")\n                            if match != '':\n                                instances = instances + 1\n                    print(f'number of instances found: {instances}\\n')\n                else:\n                    continue\n        else:\n            print('Usage:regs directory')\n    except FileNotFoundError:\n        print(\"that file doesn't exist.\")\n    except PermissionError:\n        print(\"you don't have permission to search that folder.\")\n\ninstead of having a loop that goes over the list of the string's words, it just prints the match group between parenthesis like so:\n            print(regObj.sub(lambda match: \"(\" + match.group() + \")\", text)+\"'\")\n\nThe output now looks like this.\nit also prints the folder contents now.\n"
},
{
"QuestionId": "76389533",
"QuestionTitle": "Kafka consumer unique cluster ID?",
"QuestionBody": "Does a Kafka cluster have some unique ID that I can get programmatically out of a Kafka consumer? I checked for message headers, but it looks like there's no metadata in them by default and I don't see any methods in a KafkaConsumer or ConsumerRecord for retrieving such a value either.\n",
"AnswerId": "76390559",
"AnswerBody": "You can use AdminClient to get the cluster id, but generally, there's no reason for clients to know internal server information\n"
},
{
"QuestionId": "76390462",
"QuestionTitle": "How to return 0 for all time intervals instead of nothing when counting",
"QuestionBody": "I have a query for deployment table. There is no data for hotfix column now. I want to show all change count without hotfix and with hotfix for time intervals.\nTable data:\n\n\n\n\ndeployTime\nchangeno\nhotfix\n\n\n\n\n2022-08\naaa\n\n\n\n2022-08\nbbb\n\n\n\n2022-11\nccc\n\n\n\n2023-01\nddd\n\n\n\n\n\nFirst attempted query:\nSELECT deployTime               AS times ,   \n       COUNT(DISTINCT changeno) AS \"Change Count\" \nFROM deployments \nWHERE hotfix = ''\nGROUP BY deployTime \n\nwhich returns all dates with Change count:\n\n\n\n\ntimes\nChangeCount\n\n\n\n\n2022-08\n2\n\n\n2022-11\n1\n\n\n2023-01\n1\n\n\n\n\nSecond attempted query:\nSELECT deployTime               AS times ,   \n       COUNT(DISTINCT changeno) AS \"Change Count\" \nFROM deployments \nWHERE hotfix != ''\nGROUP BY deployTime \n\nwhich returns no records if there's no record with hotfix != ''.\nHow we can get 0 count for every date instead of nothing?\n\n\n\n\ntimes\nHotfixCount\n\n\n\n\n2022-08\n0\n\n\n2022-11\n0\n\n\n2023-01\n0\n\n\n\n\nThanks\n",
"AnswerId": "76390585",
"AnswerBody": "The problem with your query is that you're using a WHERE clause, that removes records. What you should do instead, is apply conditional aggregation on presence/absence of hotfix values:\nSELECT deployTime AS times ,   \n       COUNT(DISTINCT changeno) FILTER(WHERE hotfix = '') AS \"Change Count\" \nFROM deployments \nGROUP BY deployTime \n\nAnd change it to WHERE NOT hotfix = '' conversely to obtain zeroes.\nCheck the demo here.\nNote: It's better to have NULL values instead of empty strings, when you need to indicate missing data.\n"
},
{
"QuestionId": "76392054",
"QuestionTitle": "How do I break down data that I am grouping by?",
"QuestionBody": "I have a table where each instance in the table is a sold ticket and tickets can have different ticket types. Looking something like this:\n\n\n\n\nEvent\nTicket Type\n\n\n\n\nEvent 1\na\n\n\nEvent 2\na\n\n\nEvent 1\nb\n\n\nEvent 2\na\n\n\nEvent 1\na\n\n\n\n\nI want it to be grouped by the event but displaying both the total tickets for that event as well as breaking down the number of each ticket type.\n\n\n\n\nEvent\nTotal Tickets\nTicket Type a\nTicket Type b\n\n\n\n\nEvent 1\n3\n2\n1\n\n\nEvent 2\n2\n2\n0\n\n\n\n\nI have tried a few different queries but nothing that is showing me the results I'm looking for. Is this possible in one query?\n",
"AnswerId": "76392081",
"AnswerBody": "Yes, it is possible by using GROUP BY to group the event data and then calculating the totals. The following query works by counting the number of tickets, then counting the number of tickets for each type \"a\" and \"b\".\nSELECT \n    Event,\n    COUNT(*) AS 'Total Tickets',\n    COUNT(CASE WHEN TicketType = 'a' THEN 1 END) AS 'Ticket Type a',\n    COUNT(CASE WHEN TicketType = 'b' THEN 1 END) AS 'Ticket Type b'\nFROM\n    Tickets\nGROUP BY\n    Event;\n\n"
},
{
"QuestionId": "76389631",
"QuestionTitle": "Polymorphic serialization of property",
"QuestionBody": "I'm trying to create a Client library that will allow users to push serialized data to a service.\nso I created a class\npublic class Data\n{\n   public string Prop1 {get; set;}\n   public SubData Prop2 {get; set;}\n}\n\npublic abstract class SubData\n{\n   public string Prop3 {get; set;}\n}\n\nI would like to allow users to extend that SubData to add custom properties. but I'm having issues in my Serialization, it doesn't serialize the properties of the extended inner object\nJsonSerializer.Serialize(data) \n\nI know that I could decorate my SubData class with JsonDerivedType attribute, but my problem is that SubData is in a package, and it doesn't know about who will extend it and with what (and it doesn't care)\nI don't know if I'm clear what my problem is so here is a full test to replicate:\nusing System.Text.Json;\n\npublic class Data\n{\n    public string Prop1 { get; set; }\n    public SubData SubData { get; set; }\n}\n\npublic abstract class SubData\n{\n    public string Prop2 { get; set; }\n}\n\npublic class ExtendedSubData : SubData\n{\n    public string Prop3 { get; set; }\n\n}\n\nvar data = new Data\n{\n    Prop1 = \"1\",\n    SubData = new ExtendedSubData\n    {\n        Prop2 = \"2\",\n        Prop3 = \"3\"\n    }\n};\n\nSerializData(data);\n\nvoid SerializData(Data data)\n{\n    var serialized = JsonSerializer.Serialize<object>(data);\n    // serialized at this point doesn't contain Prop3 of \n    // ExtendedSubData\n}\n\n",
"AnswerId": "76390588",
"AnswerBody": "As an alternative to the custom JsonConverter, you can replace the SubData property with generic\npublic class Data<TSubData>\n    where TSubData : SubData\n{\n    public string Prop1 { get; set; }\n    public TSubData SubData { get; set; }\n}\n\nstring SerializData<TSubData>(Data<TSubData> data)\n    where TSubData : SubData\n{\n    return JsonSerializer.Serialize<object>(data);\n}\n\nTest it on dotnetfiddle:\nhttps://dotnetfiddle.net/lkOM0Z\n"
},
{
"QuestionId": "76388586",
"QuestionTitle": "How to sign dylib file which can be replaced?",
"QuestionBody": "I have poor understanding in this question. The major step to distribute any application is the code signing, it signs application with dependant dynamic library. As I understand OS will check signed application during installation and subsequent calls. If application or dynamic library was changed then os rejects the launch. Many dylib files are supplied to conform LGPL license and therefore dylib files can be potentially substituted by user later. But it will break the launch of application (because signed dylib was replaced). Are my assumptions correct? Maybe there is comprehensive book/guide which covers this topic? I found apple documentation pretty bad\n",
"AnswerId": "76389618",
"AnswerBody": "That's not how this works.\nThe signature of the library isn't going to matter if the entire library will be replaced. What matters is the signature of the main executable of the process, specifically whether it enforces library validation. But even if you disable library validation, that is likely only going to work for dlopen() scenarios.\nThe problem is that app bundles are signed as a whole. Even non-executable resource files within the bundle are hashed, and then this list of hashes is hashed again and stored in the code signature of the main binary. While it looks syntactically possible to exclude files from this, I don't know whether Gatekeeper would accept this, and I don't know whether it would work for dylibs in particular.\nBut even if you found a combination that works, it will likely only be a matter of time before Apple breaks it, because the whole point of codesigning is that only pre-approved binaries are allowed to be executed.\nThe simple solution is: if you replace the library, you re-sign the entire bundle.\n"
},
{
"QuestionId": "76392070",
"QuestionTitle": "Cannot run updated file from terminal of VSC, for Python",
"QuestionBody": "So to make it very simple.\nIf I write print(\"Hello World\") and run it on the RUN icon on top right corner it works perfectly fine.\nAnd only then if I type in terminal   python hello.py   executes again just fine.\nBut if I change program to print(\"Hello to everybody\") and I type in terminal   python hello.py   it executes the previous program and giving me Hello World on screen. But then again if I click on run icon and after correct execution repeat in terminal python hello.py, now it runs correctly.\nWell I tried CTRL,SHift P, to change terminal and like select interpreter but couldn't figure out from which file is it trying to start program. And why is it correct after I use run icon.\n",
"AnswerId": "76392085",
"AnswerBody": "Are you saving the file after changing it? The Run button will run the code that is currently in the editor, while running it via python in the command line will run it from the saved file.\n"
},
{
"QuestionId": "76391253",
"QuestionTitle": "Vue 3: Mount component onto existing app instance",
"QuestionBody": "I have a plugin written in Vue 2 that programmatically mounts a component onto existing app instance.\nexport default {\n  install (Vue) {\n    const component = new (Vue.extend(Component))()\n    const vm = component.$mount()\n    document.body.appendChild(vm.$el)\n  }\n}\n\nTrying to migrate this to Vue 3 and this is the closest I've got.\nexport default {\n  install (app) {\n    const component = defineComponent(Component)\n    const container = document.createElement('div')\n    document.body.appendChild(container)\n    const vm = createApp(component).mount(container)\n  }\n}\n\nThe problem is that createApp creates a new app instance, while Vue.extend created only a subclass. I need to have all globally available components in the main app, available in plugin's component as well. Creating a new app instance prevents this.\nComponent needs to be programatically mounted. Manually inserting it into template is not an option.\nPlease help.\n",
"AnswerId": "76392089",
"AnswerBody": "Interesting problem! There is a discussion on the Vue GitHub and they created a module that you can use: mount-vue-component. I found it very helpful to look at the module's code, it does exactly what you want to do.\nTo instantiate the component, you have to create a VNode, which you can do with createVNode() (which is the same as h()). To get access to the app's context, including global components, you have to set the appContext property. Finally, the render() function mounts the component instance to an HTML Element.\nSo for you example, that gives you:\nexport default {\n  install (app) {\n    const container = document.createElement('div')\n    document.body.appendChild(container)\n\n    const vNode = createVNode(component)\n    vNode.appContext = app._context\n    render(vNode, container)\n  }\n}\n\n\nHere it is in a snippet:\n\n\nconst { createApp, createVNode, ref, render  } = Vue;\n\nconst App = {\n  data() {\n    return {\n      msg: ref('Hello from app!')\n    }  \n  }\n}\nconst app = createApp(App)\n\napp.component('inner-component', {\n  template:  '<div style=\"color: green;\">This is a global component in app</div>'\n})\napp.mount('#app')\n\n\nconst component = {\n  props: ['color'],\n  template: '<span :style=\"{color: color}\">Hello from mounted component!</span><inner-component></inner-component>'\n}\nconst el = document.getElementById('leComponent')\nconst vNode = createVNode(component, {color: 'blue'}, [])\nvNode.appContext = app._context\nrender(vNode, el)\ndiv{\n  margin: 4px;\n  padding: 4px;\n  border: 1px solid #333;\n}\n<div id=\"app\">\n  {{msg}}\n  <inner-component></inner-component>\n</div>\n<div id=\"leComponent\"></div>\n<script src=\"https://unpkg.com/vue@3/dist/vue.global.js\"></script>\n\n\n\n"
},
{
"QuestionId": "76390122",
"QuestionTitle": "Matrix Circuit Analysis using Algorithms",
"QuestionBody": "spsolve is then - sometimes - unable to find a solution.\nOur teacher gave us test cases that we have to satisfy however I passed all of them but seems to fail the hidden test cases.\nMy code checks for the following: If they share a node and only those two resistors are connected then print SERIES else NEITHER. If their previous resistor is in series, then its is in SERIES (see test case no 2). If the resistor's ends are connected to the same nodes then print Parallel.\nCan you suggest some inputs or any possible scenarios that a code wouldn't be able to answer correctly? or maybe a suggestion on what type of algorithm I should use for this problem\nAs I am performing nodal analysis, a singular matrix is expected since the position of the ground potential is generally not well-defined. However, before the update, a solution was found in 99% of the cases, maybe more. Now, I'm at 10% for large systems at best. I have not changed the algorithm and for a few tests, I have used identical code as before. Here is how I set up my calculation:\nI generate a random three-dimensional network of resistors (I realize that I could accidentally create unsolvable networks but the percentages above should not change that drastically). The only SciPy/NumPy functions used here is np.random\nI create a sparse lil-matrix which I fill with conductance values extracted from my resistor network. I also create a solution vector which is not sparse.\nI convert the conductance matrix to csr-format and use the spsolve method. This is where my code lately fails.\n",
"AnswerId": "76390602",
"AnswerBody": "Electron travel between Vdd and ground.  The Dijkstra algorithm ( google it ) finds these routes.  If two resisters are on the same route, they are in series.\nSetup\n\nLOOP over every pair of resisters\n\nIF the ends of the two resistor are connected to the same nodes\n- mark as parallel\n\n\nCreate adjacency list for resisters, combining parallels together into one edge.\n\nTo check if R1 and R2 are in series:\n\nIF R1 and R2 are marked parallel return PARALLEL\nUse Dijkstra to find all routes from Vdd to R1\nIF no route return NO\nUse Dijkstra to find all route from R1 to GND\nIF no route return NO\nIF R2 itself, or as part of a parallel, on any routes found return SERIES\n\nNote that this will return YES for R3 and R4 in sample input 1.  I do not understand why R3 and R4 are not in series - electricity will flow through R3 and then R4 to reach ground.\nObviously, I do not understand your definition of \"in series\".  Please provide this definition.  In particular:\nR1 Vdd a\nR2 a b\nR3 a b\nR4 b GND\n\nAre R1 and R4 in series or not?\n"
},
{
"QuestionId": "76390958",
"QuestionTitle": "Does a StatefulSet pod, when deleted or failed, get redeployed on the same worker node, or is it deployed on another available worker node?",
"QuestionBody": "Does a StatefulSet pod, when deleted or failed, get redeployed on the same worker node, or is it deployed on another available worker node?\nSeeking clarification on the default behavior of StatefulSet pods in Kubernetes when they are deleted or failed whether they are rescheduled on the same worker node or on different worker nodes.\n",
"AnswerId": "76392099",
"AnswerBody": "By default, k8s will schedule a new pod on any 1 of the nodes which has sufficient CPU and memory resources available. If you specified any special conditions like Pod affinity, Pod affinity or Node affinity, k8s will follow them accordingly. Please check out this official document\n"
},
{
"QuestionId": "76387953",
"QuestionTitle": "Image duplicated when using fig.canvas.tostring_rgb()",
"QuestionBody": "I am plotting 3D data using matplotlib==3.3.4:\nfig = plt.figure(figsize=(15, 10))\nax = fig.gca(projection=\"3d\")\nax.view_init(30, 0)\n\n# facecolors is a 3D volume with some processing\nax.voxels(\n    x, y, z, facecolors[:, :, :, -1] != 0, facecolors=facecolors, shade=False\n)\nfig.canvas.draw()\nimage_flat = np.frombuffer(fig.canvas.tostring_rgb(), dtype=\"uint8\")\nimage_shape = (*fig.canvas.get_width_height(), 3)  # (1500, 1000, 3)\nax.imshow(image_flat.reshape(*image_shape))\nplt.show()\n\n(I am making some improvements on BraTS20_3dUnet_3dAutoEncoder with inspiration from Figure to image as a numpy array).\nHowever, when I actually plot the image, there are two copies:\n\nWhat am I doing wrong?  I can't figure out where the second image is coming from.\n",
"AnswerId": "76389700",
"AnswerBody": "The NumPy array ordering is (rows, cols, ch). The code image_shape = (*fig.canvas.get_width_height(), 3) switches rows and cols, which leads to the output image being incorrectly shaped, which looks like two copies.\n\nReplace image_shape = (*fig.canvas.get_width_height(), 3) with:\nimage_shape = (*fig.canvas.get_width_height()[::-1], 3)\n\n\nFor avoiding confusion, we better use two lines of code:\ncols, rows = fig.canvas.get_width_height()\nimage_shape = (rows, cols, 3)\n\n\nReproducible example (using data from here):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure(figsize=(15, 10))\nax = fig.gca(projection=\"3d\")\nax.view_init(30, 0)\n\n# https://stackoverflow.com/questions/76387953/image-duplicated-when-using-matplotlib-fig-canvas-tostring-rgb\n# prepare some coordinates\nx, y, z = np.indices((8, 8, 8))\n\n# draw cuboids in the top left and bottom right corners, and a link between\n# them\ncube1 = (x < 3) & (y < 3) & (z < 3)\ncube2 = (x >= 5) & (y >= 5) & (z >= 5)\nlink = abs(x - y) + abs(y - z) + abs(z - x) <= 2\n\n# combine the objects into a single boolean array\nvoxelarray = cube1 | cube2 | link\n\n# set the colors of each object\ncolors = np.empty(voxelarray.shape, dtype=object)\ncolors[link] = 'red'\ncolors[cube1] = 'blue'\ncolors[cube2] = 'green'\n\n# and plot everything\n#ax = plt.figure().add_subplot(projection='3d')\nax.voxels(voxelarray, facecolors=colors, edgecolor='k')\n\nfig.canvas.draw()\nimage_flat = np.frombuffer(fig.canvas.tostring_rgb(), dtype=\"uint8\")\n#image_shape = (*fig.canvas.get_width_height(), 3)  # (1500, 1000, 3)\n#image_shape = (*fig.canvas.get_width_height()[::-1], 3)  # It should be (1000, 1500, 3) instead of (1500, 1000, 3)\ncols, rows = fig.canvas.get_width_height()\nimage_shape = (rows, cols, 3)\nimg = image_flat.reshape(*image_shape)\n\nplt.figure()\nplt.imshow(img)\nplt.show()\n\n\nOutput image before fixing the code:\n\nOutput image after fixing the code:\n\n"
},
{
"QuestionId": "76389973",
"QuestionTitle": "Are there any default value tricks / Elvis Operator in Ocaml?",
"QuestionBody": "Are there any elvis like operator in Ocaml ?\nAny sort of optional chaining that return the right value when the left one is empty, a default value operator, like the |> operator with opposite effect.\nIf not what are the good practices ?\nAs an example of a use case :\nlet get_val val_1 val_2 = \n  if (val_1) then (val_1) else (val_2);;\n\nAre there any syntactic sugar ?\n",
"AnswerId": "76390614",
"AnswerBody": "First, in OCaml if ... then ... else ...  is an expression and thus there is no needs to have a distinct ternary operator.\nSecond, OCaml has optional arguments.\nIf I guess correctly the supposed semantics of your get_val function, it can be written:\nlet default = []\nlet get_val ?(val_1=default) () = val_1\n\nwhich gives you [] as the default value when the named argument val_1 is absent\nlet () =\n  assert ([] = get_val ())\n\nor the val_1 argument otherwise:\nlet () = \n  assert ([2;3;4] = get_val ~val_1:[2;3;4] ())\n\n"
},
{
"QuestionId": "76388435",
"QuestionTitle": "send a get http request by axios on react to laravel 10 backend on localhost",
"QuestionBody": "i am using axios on react to send http request to laravel backend. but cors prevent laravel to answer my request. i catch below error:\np://localhost/todo/laravel/public/api/test' from origin 'http://localhost:3000' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.\nmy react code:\n    axios.get('http://localhost/todo/laravel/public/api/test', { withCredentials: true })\n        .then(function (response) {\n            // handle success\n            console.log(response);\n        })\n        .catch(function (error) {\n            // handle error\n            console.log(error);\n        })\n        .then(function () {\n            // always executed\n        });\n\nmy laravel code:\npublic function all(): bool|string\n{\n    $todos = Todo::all();\n    return json_encode($todos);\n}\n\nmy cors config:\n<?php\n\nreturn [\n\n/*\n|--------------------------------------------------------------------------\n| Cross-Origin Resource Sharing (CORS) Configuration\n|--------------------------------------------------------------------------\n|\n| Here you may configure your settings for cross-origin resource sharing\n| or \"CORS\". This determines what cross-origin operations may execute\n| in web browsers. You are free to adjust these settings as needed.\n|\n| To learn more: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\n|\n*/\n'paths' => ['*'],\n\n'allowed_methods' => ['*'],\n\n'allowed_origins' => ['*'],\n\n'allowed_origins_patterns' => [],\n\n'allowed_headers' => ['*'],\n\n'exposed_headers' => false,\n\n'max_age' => false,\n\n'supports_credentials' => false,\n];\n\nwhat is problem?\n",
"AnswerId": "76389815",
"AnswerBody": "try\n'paths' => ['todo/*'],\nI' not sure, that ['*'] is allowed\n"
},
{
"QuestionId": "76387968",
"QuestionTitle": "Sometimes, in a Data JPA environment, when three queries occur in one method, one query does not work normally in DB",
"QuestionBody": "Sometimes, in a Data JPA environment, when three queries occur in one method, one query does not work normally in DB.\n@Transactional\npublic void method1(Log log){\n        Long userId = log.getUserId();\n        User user = userRepository.findById(userId).orElseThrow(RuntimeException::new)\n\n        BigDecimal point = BigDecimal.valueOf(100L);\n        user.minusPoint(point);\n        log.minusPoint(point);\n        logRepository.save(new Log(point));\n}\n\nIt works normally for one case.\nHowever, I ran it on several occasions, and one did not work properly.\nex) logList.forEach(log-> a.method1(log));\ndid not work \"log.minusPoint(point);\" in all cases.\nThe data in the DB has not changed about log.\nBut the new log data was inserted and the user data has been changed.\nIt was confirmed that the update, insert query was created successfully in the test environment.\n",
"AnswerId": "76389842",
"AnswerBody": "You can enable SQL logging and check what data is actually passed to the database.\nOne of the reason can be: @Transactional annotation doesn't work. You need to get a service from the Spring Context to allow Spring to wrap method1() with a proxy method to do dirty checking and save data.\n@Transactional annotation is a bit messy. It is primary not about transactions, but about dirty checking and Hibernate session control.\nWhen you do\nlogRepository.save(new Log(point));\n\ndata is saved because logRepository.save() has it is own @Transactional annotation and does explicit call to save the data.\nlog.minusPoint(point) could work, if @Transactional works correctly. A Spring proxy could open Hibernate session (Persistent Context) before method1() call and close it in the end. During closing session Hibernate does dirty checking — checks, if any of objects in session were changed and saves such objects.\nAnother reason can be that you load log in a method without @Transactional or in a method with own @Transactional. Different @Transactional means different Persistent Context.\nOne exception — when @Transactional of method1() is wrapped with another @Transactional that is used for a method that calls method1().\nIt is bad practice to solve all issues with putting @Transactional everywhere. You can just do\nlogRepository.save(log)\n\n"
},
{
"QuestionId": "76392047",
"QuestionTitle": "How can I count over multiple fields in mongo?",
"QuestionBody": "I am trying to write a mongo query to help produce a report from the data.\nThe documents look something like this:\n[{\n    \"DeviceType\" : \"A\",\n    \"DeviceStatus\" : \"On\"\n},\n{\n    \"Device Type\" : \"B\",\n    \"Device Status\" : \"On\"\n},\n{\n    \"DeviceType\" : \"A\",\n    \"DeviceStatus\" : \"Off\"\n},\n{\n    \"DeviceType\" : \"A\",\n    \"DeviceStatus\" : \"On\"\n}]\n\nThe DeviceType field can take any string value and the DeviceStatus field can be any one of On, Off or InRepair. I want to write a mongo query that displays DeviceStatus count for each one of the devices. The result should be something like this:\n[{\n    \"DeviceType\" : \"A\",\n    \"DeviceStatusOnCount\" : \"15\",\n    \"DeviceStatusOffCount\" : \"13\",\n    \"DeviceStatusInRepairCount\" : \"12\",\n},\n{\n    \"DeviceType\" : \"B\",\n    \"DeviceStatusOnCount\" : \"6\",\n    \"DeviceStatusOffCount\" : \"14\",\n    \"DeviceStatusInRepairCount\" : \"2\",\n}]\n\nHow can I achieve this in mongo?\nMy current query can only group based on the DeviceType:\ndb.Collection_Name.aggregate([\n    { $group: { _id: \"$DeviceType\", count: { $sum: 1 } } }\n])\n\n",
"AnswerId": "76392103",
"AnswerBody": "You can use $cond + $eq to return either 1 or 0 to $sum operator:\ndb.collection.aggregate([\n  {\n    $group: {\n      _id: \"$DeviceType\",\n      DeviceStatusOnCount: { $sum: { $cond: [ { $eq: [ \"$DeviceStatus\", \"On\" ] }, 1, 0 ] } },\n      DeviceStatusOffCount: { $sum: { $cond: [ { $eq: [ \"$DeviceStatus\", \"Off\" ] }, 1, 0 ] } },\n      DeviceStatusInRepairCount: { $sum: { $cond: [ { $eq: [ \"$DeviceStatus\", \"InRepair\" ] }, 1, 0 ] } }\n    }\n  },\n  {$addFields: {DeviceType: '$_id'}}, {$project: {_id:0}}\n])\n\nTest: mongoplayground\n"
},
{
"QuestionId": "76390575",
"QuestionTitle": "How to remove the \"locked\" flag (programmatically)",
"QuestionBody": "(MacOS Monterey):\nI have external hard disks with files written under Windows, using Cygwin rsync.\nThe files are perfectly readable under MacOS, but when I want to delete/overwrite them, quite some appear \"locked\" (operation not permitted when doing a rm) on MacOS. Using the Finder, I can remove the lock by getting the context menu on the file, choose \"GetInfo\", and unchecked the Locked property.\nBut there are too many of them to do it by hand. I would like to run recursively over the file tree and uncheck the \"locked\" attribute programmatically. Of course the problem is not the traversal of the directory tree (can done by find for instance), but the change of the attribute from the command line.\nchmod does not help here (as the files are 0777). Any other command I can use?\n",
"AnswerId": "76390615",
"AnswerBody": "I just found the command to do so:\nchflags nouchg FILENAME\n\nThe command is described here\n"
},
{
"QuestionId": "76388274",
"QuestionTitle": "Updating web redirect uri of Azure AD app registration",
"QuestionBody": "I have a scenario where my pipeline should update the app registration with an additional redirectUrl.\nI have managed to extract the current web.redirectUris with the following:\n existing_urls=$(az ad app show --id '<client-id>' --query \"[web.redirectUris]\" --output tsv)\nI would like to achieve something like this\nexisting_urls=$(az ad app show --id '<client-id>' --query \"[web.redirectUris]\" --output tsv)\naz ad app update --id '<client-id>' --web-redirect-uris \"$existing_urls https://hostname.com/newCallback\"\n\nI have tried updating the web.redirectUris in two ways and both of them have failed when I pass multiple redirect URIs.\nAttempt 1\naz ad app update --id '<client-id>' --web-redirect-uris \"https://hostname.com/callbackx https://hostname.com/callbacky\"\n\nOne or more properties contains invalid values.\n\nHowever when having only one uri this worked fine\naz ad app update --id '<client-id>' --web-redirect-uris \"https://hostname.com/callbackx\"\n\nAttempt 2\nThis one fails regardless of number of redirectUris that are passed\naz ad app update --id '<client-id>' --set \"web.redirectUris=['https://hostname.com/callbackx', 'https://hostname.com/callbacky']\"\n\nCouldn't find 'web' in ''. Available options: []\n\n",
"AnswerId": "76389975",
"AnswerBody": "Tried as shown :But got the same error:\naz ad app show --id 1e7bxxx7830\n\nexisting_urls=$(az ad app show --id 1e7b8fxxxx830 --query \"[web.redirectUris]\")\n\naz ad app update --id 1e7xxx0a7830 --web-redirect-uris \"$existing_urls https://hostname.com/newCallback\"\n\n$updated_urls=\"$existing_urls https://hostname.com/newCallback\"\n\naz ad app update --id 1e7b8xxx0a7830  --set \"web.redirectUris='$updated_urls'\"\n\naz ad app update --id 1e7b8fxxxd0a7830  --set \"web.redirectUris='$updated_urls'\"\n\nError:\nCouldn't find 'web' in ''. Available options: []\n\n\nFollowing command worked foe me in azure cli in updating multiple Redirect Urls:\naz ad app update --id '1e7bxxxa7830' --web-redirect-uris \"https://hostname.com/callback\"  \"https://jwt.ms\" \"https://myexampleapp.com\"\nhere --id is clientId .\n\nSo  give the command with required urls as\naz ad app update --id '1e7bxxxa7830' --web-redirect-uris \"<url1>\"  \"<url2>\" \"<url3>\"\nupon az ad app show --id 1e7b8xxxx830\n\n"
},
{
"QuestionId": "76390603",
"QuestionTitle": "I'm trying to find the closest value in a reference data frame but it is not outputting the correct row. Where am I going wrong?",
"QuestionBody": "I'm trying to find the closest value in a reference data frame but it is not outputting the correct row.\nI am using the below data frame which is then used to find the relevant row corresponding to the closest value in column 'P' to a defined variable. For example if p = 0.22222 then the code should output row 2.\nDF:\n      P   n1      n2      n3      n4      n5      n6      n7      n8      n9   \n0   NaN  0.0  0.2000  0.4000  0.6000  0.8000  1.0000  1.2000  1.4000  1.6000\n1   0.0  1.0  0.8039  0.6286  0.4855  0.3753  0.2929  0.2318  0.1863  0.1520   \n2   0.2  1.0  0.7983  0.6201  0.4771  0.3683  0.2876  0.2279  0.1835  0.1500   \n3   0.4  1.0  0.7789  0.5924  0.4508  0.3473  0.2720  0.2167  0.1754  0.1442   \n4   0.6  1.0  0.7349  0.5377  0.4043  0.3124  0.2470  0.1989  0.1628  0.1351   \n5   0.8  1.0  0.6301  0.4433  0.3368  0.2658  0.2147  0.1762  0.1465  0.1234   \n6   1.0  0.5  0.3828  0.3105  0.2559  0.2130  0.1787  0.1510  0.1286  0.1102   \n7   1.2  0.0  0.1544  0.1871  0.1795  0.1621  0.1433  0.1257  0.1103  0.0965   \n8   1.4  0.0  0.0717  0.1101  0.1216  0.1197  0.1120  0.1024  0.0925  0.0831   \n9   1.6  0.0  0.0400  0.0682  0.0829  0.0876  0.0865  0.0824  0.0765  0.0707   \n10  1.8  0.0  0.0249  0.0449  0.0580  0.0647  0.0668  0.0659  0.0633  0.0597   \n11  2.0  0.0  0.0168  0.0312  0.0418  0.0485  0.0519  0.0528  0.0520  0.0502   \n12  3.0  0.0  0.0042  0.0082  0.0118  0.0149  0.0174  0.0193  0.0207  0.0216\n\nThe function I am using however outputs the incorrect value:\np = 0.2020202\nclosest_p = df.iloc[(df['P']-p).abs().argsort()[:1]]\n\nExpected output:\n      P   n1      n2      n3      n4      n5      n6      n7      n8      n9   \n2   0.2  1.0  0.7983  0.6201  0.4771  0.3683  0.2876  0.2279  0.1835  0.1500\n\nHowever it is only outputting the last row -\n      P   n1      n2      n3      n4      n5      n6      n7      n8      n9   \n12  3.0  0.0  0.0042  0.0082  0.0118  0.0149  0.0174  0.0193  0.0207  0.0216\n\nWhere am i going wrong????\n",
"AnswerId": "76390619",
"AnswerBody": "You need to use idxmin:\nclosest_p = (df['P']-p).abs().idxmin()\n\nOutput: 2\nFor the row: df.loc[(df['P']-p).abs().idxmin()]\nA fix of your approach would have been to use sort_values (but it's less efficient):\nclosest_p = df.loc[(df['P']-p).abs().sort_values().index[0]]\n\n"
},
{
"QuestionId": "76391811",
"QuestionTitle": "Unused parameter warning in templated function with if constexpr",
"QuestionBody": "In this code\n#include <type_traits>\n#include <iostream>\n\ntemplate <class T>\nvoid func(const T& a)\n{\n    if constexpr(std::is_same_v<T,int>)\n    {\n        static_cast<void>(a);\n    }\n    else if constexpr(std::is_same_v<T,double>)\n    {\n        // oops forgot to use it here   \n    }\n    else\n    {\n        \n    }\n}\n\nint main() {\n    func(4);\n    func(\"this\");\n}\n\nwhy doesn't the compiler warn about unused variable in the else-s()? (with -Wall)\nMy understanding is that logically the instantiations of the method are completely different. If the argument is not being used in one of the instantiations of the template, isn't it an unused variable?\nOr does the language/compiler not interpret it like that.\n",
"AnswerId": "76392128",
"AnswerBody": "We can say that the parameter a is not fully unused, it's conditionally unused.\nThe C++ standard requires to generate diagnostic messages for ill-formed programs. Your program is not ill-formed. The C++ standard does not require compilers to generate other warnings at all. So it's up to the compiler vendor to decide how to implement that.\nWhile I personally would like to be warned about conditionally unused variables (your example is a good demo why), no compiler vendor has implemented that. Why? They test new version of compilers on large code bases to see whether new C++ features will cause breaking changes. Likely, during those tests, a lot of warnings were generated for code like yours, but the code was considered totally fine by C++ experts. So the warnings were adapted to not occur in such situations. That's to ensure that code with 0 warnings is possible.\n"
},
{
"QuestionId": "76391083",
"QuestionTitle": "Trouble with undefined symbols in Rust's ffi when using a C/Fortran library",
"QuestionBody": "I have a library, namely pfapack (1), that I want to use in rust. So the initial code is written in Fortran, but a C interface exists and works well. I want to make a Rust crate (2) that ships this code so I can use it in any other Rust project (3). Doing so, (3) gives an undefined symbol error.\nI have written a build script in (2) that calls (1)'s build method. I then use cc to combine the object files and link the needed libraries. I then used bindgen to generate bindings for the functions I need. I would expect that (3) would be able to see the object that were compiled at (2) build time, but it can't.\nThe exact step taken are:\n\nNew crate with (1)'s source code.\n(2) build.rs\n\nuse std::process::Command;\n\nfn main() {\n// This makefile call a custom root makefile that only calls the two\n// makefiles in c_interface/ and fortran/\n    Command::new(\"make\").output() \n        .expect(\"Failed to make\");\n\n    println!(\"cargo:rustc-link-search=c_interface\");\n    println!(\"cargo:rustc-link-search=fortran\");\n    println!(\"cargo:rustc-link-lib=static=pfapack\");\n    println!(\"cargo:rustc-link-lib=static=cpfapack\");\n    println!(\"cargo:rustc-link-lib=gfortran\");\n\n}\n\n\n(3) build.rs\n\nfn main() {\n    println!(\"cargo:rustc-link-lib=lapack\");\n    println!(\"cargo:rustc-link-lib=blas\");\n}\n\nOriginal example compilation to use pfapack\ngcc -O3 -I c_interface/ foo.c -o foo.out c_interface/libcpfapack.a fortran/libpfapack.a -lm -lblas -llapack -lgfortran\n\nThe command used to generate bindings came from https://github.com/blas-lapack-rs/lapack-sys/blob/master/bin/generate.sh as it uses the same naming convention:\ngenerate.sh\n#!/bin/bash\nset -eux\n\nbindgen --allowlist-function='^.*_$' --use-core pfapack.h \\\n  | sed -e 's/::std::os::raw:://g' \\\n  | sed -e '/__darwin_size_t/d' \\\n  > pfapack.rs\n\nrustfmt pfapack.rs\n\nCompiling (3) gives this error https://pastebin.com/4FubsYx9\nIgnoring a big blob of flags, the error:\n  = note: /usr/bin/ld: /home/dumbo/Documents/test_pfapack/target/debug/deps/test_pfapack-d08bc25fe63b6ef8.ka29pyd46xgunxk.rcgu.o: in function `pfapack_sys::dskpfa':\n          /home/dumbo/Documents/pfapack-sys/src/pfapack-bind.rs:249: undefined reference to `dskpfa'\n          collect2: error: ld returned 1 exit status\n \n  = note: some `extern` functions couldn't be found; some native libraries may need to be installed or have their path specified\n  = note: use the `-l` flag to specify native libraries to link\n  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo (see https://doc.rust-lang.org/cargo/reference/build-scripts.html#cargorustc-link-libkindname)\n \nerror: could not compile `test_pfapack` due to previous error\n\n(2) Cargo.toml\n[package]\nname = \"pfapack-sys\"\nversion = \"0.1.0\"\nedition = \"2021\"\nlinks = \"pfapack\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\nlibc = \"0.2\"\n\n[dependencies.num-complex]\nversion = \"0.4\"\ndefault-features = false\n\n[lib]\nname = \"pfapack_sys\"\n\n[build-dependencies]\ncc = \"1.0.79\"\n\n",
"AnswerId": "76392133",
"AnswerBody": "The solution was quite simple and right under my nose. Note that the symbol not found does not have an ending underscore, as pfapack functions do after mangling. This was because I tried to do the bindings to the C interface and the pretty Rust functions in the same crate. Looking at the Rust book, https://doc.rust-lang.org/cargo/reference/build-scripts.html#-sys-packages, the convention is to have a *-sys crate that just does the binding, and have another crate named * that does the pretty functions. Thus, I needed to update the build script.\nHere is the updated (2) build.rs\n// build script\nuse std::process::Command;\n\nfn main() {\n    Command::new(\"make\").output()\n        .expect(\"Failed to make\");\n\n    println!(\"cargo:rustc-link-search=c_interface\");\n    println!(\"cargo:rustc-link-search=fortran\");\n    println!(\"cargo:rustc-link-lib=static=pfapack\");\n    println!(\"cargo:rustc-link-lib=static=cpfapack\");\n    println!(\"cargo:rustc-link-lib=gfortran\");\n    println!(\"cargo:rustc-link-lib=lapack\");\n    println!(\"cargo:rustc-link-lib=blas\");\n}\n\nI renamed this package pfapack-sys. Created a new crate named pfapack(4) that depends on pfapack-sys. Now, update Cargo.toml(3) to depend on (4). Now works out of the box.\n"
},
{
"QuestionId": "76390438",
"QuestionTitle": "Why metadata is written at the end of the file in Apache Parquet?",
"QuestionBody": "I wonder why Apache Parquet writes metadata at the end of the file instead of the beginning?\nIn the official documentation of Apache Parquet, I found that Metadata is written after the data to allow for single pass writing.. Is the metadata written at the end to ensure the integrity of the file? I don't understand what this sentence really means, if someone could explain it to me, I'd appreciate it.\n",
"AnswerId": "76390623",
"AnswerBody": "I think the main reason is so you can write bigger than memory data to the same file.\nThe meta data contains information about the schema of the data (type of the columns) and its shape (number of row groups, size of each row groups).\nSo in order to generate the metadata you need to know what the data is made of. This can be a problem if your data doesn't fit in memory.\nIn this case, you should still be able to split your data in manageable row groups (that fit in memory) and append them to the file one by one, keeping track of the meta data, and appending the meta data at the end.\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\n\nschema = pa.schema([pa.field(\"col1\", pa.int32())])\n\nwith pq.ParquetWriter(\"table.parquet\", schema=schema) as file:\n    for i in range(0, 10):\n        file.write(pa.table({\"col1\": [i] * 10}, schema=schema))\n\nIf you're looking for an alternative where the data can be streamed, with the meta data being written at the beginning, you should look at the arrow IPC format.\n"
},
{
"QuestionId": "76387965",
"QuestionTitle": "NewRelic Not working with multiple workers Fast API Uvicorn",
"QuestionBody": "We are trying to integrate NewRelic with our Fast API Service. It works fine when we are not providing numbers of worker in uvicorn config\nif __name__ == \"__main__\":\n    # newrelic.agent.register_application()\n    import newrelic.agent\n\n    newrelic.agent.initialize()\n    print(\"api key \", os.environ.get(\"NEW_RELIC_LICENSE_KEY\", 1))\n    print(\"app name \", os.environ.get(\"NEW_RELIC_APP_NAME\", 1))\n    # printing to make sure licence key and app name are defined in env variables.\n    uvicorn.run(app, host='0.0.0.0', port=5600)\n\n\nBut when we are defining numbers of workers in the uvicorn config, NewRelic does not show any data in dashboard.\nif __name__ == \"__main__\":\n    # newrelic.agent.register_application()\n    import newrelic.agent\n\n    newrelic.agent.initialize()\n    print(\"api key \", os.environ.get(\"NEW_RELIC_LICENSE_KEY\", 1))\n    print(\"app name \", os.environ.get(\"NEW_RELIC_APP_NAME\", 1))\n    # printing to make sure licence key and app name are defined in env variables.\n    uvicorn.run(\"new_relic_test:app\", host='0.0.0.0', port=5600, workers=15)\n\n\nIs that due to multiple server process being created by uvicorn workers?\nI tried removing workers and it worked fine. But with numbers of workers it does not work\n",
"AnswerId": "76390012",
"AnswerBody": "The reason is the following: when you run uvicorn.run with only one process, it will start the server as a normal Python function. But, when you run with workers=n, uvicorn will start n new processes, and the original Python process will remain as an orchestrator between these. In these new processes, it will not start your code with a different entrypoint, meaning the if __name__ == \"__main__\" will not run (this is also why you must specify your app as a string instead of the Python instance when running more than one worker, since uvicorn needs to know where to import your app from). So in your case, newrelic.agent.initialize() is not run.\nI would suggest moving everything except uvicorn.run out of the if __name__ == \"__main__\" block and put it in the same file as where you define your app.\n"
},
{
"QuestionId": "76392029",
"QuestionTitle": "How can I open a C-file in Python using 'subprocess' without triggering an Exception?",
"QuestionBody": "I am trying to open a C-file in Python by using the \"subprocess\"-module.\nI cannot execute the program without triggering a 'FileNotFoundError', and if I put in the full path of the file, I get an 'Exec format error'.\nI don't necessarily need to use the 'subprocess'-module, I just don't know of any other method.\nThe Python-Skript:\n#!/usr/bin/env python\nimport subprocess\n\nshellcode_file = \"shellcode.bin\"\n\ntry:\n    with open(shellcode_file, \"rb\") as f:\n        shellcode = f.read();\n    \n    subprocess.call([\"script.c\", shellcode])\nexcept FileNotFoundError as e:\n    print(e, \"not found.\")\n\nI am pretty sure that I am opening the File wrong but I couldn't find a way to fix it.\n",
"AnswerId": "76392136",
"AnswerBody": "You are passing the C source file itself, not the compiled executable (*.exe).\nFor further info if needed, C is not an interpreted/scripted language, so it cannot be run through its code file like other scripting languages (e.g. Python, Batch). It's a compiled language, meaning that it has to be run through a compiler to generate a separate file (almost always a .exe file) that you can then run your program with.\nCompile your C program first and pass the executable file.\n    subprocess.call([\"script.exe\", shellcode])\n\n"
},
{
"QuestionId": "76390211",
"QuestionTitle": "WebScraping - BeautifulSoup Python",
"QuestionBody": "I am trying to scrape the medium website. Here is my code.\nimport requests\nfrom bs4 import BeautifulSoup as bs\n\nclass Publication:\n    def __init__(self, publication):\n        self.publication = publication\n        self.headers = {'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}# mimics a browser's request\n    def get_articles(self):\n        \"Get the articles of the user/publication which was given as input\"\n        publication = self.publication\n        r = requests.get(f\"https://{publication}.com/\", headers=self.headers)\n        soup = bs(r.text, 'lxml')\n        elements = soup.find_all('h2')\n        for x in elements:\n            print(x.text)\n\npublication = Publication('towardsdatascience')\npublication.get_articles()\n\nIt is working somewhat good but it is not scraping all the titles. It is only getting the some of the articles from the top of the page. I want it to get all the article names from the page. It also getting the side bar stuff like who to follow and all. I dont want that. How do I do that?\nHere is the output of my code:\nHow to Rewrite and Optimize Your SQL Queries to Pandas in 5 Simple Examples\nStorytelling with Charts\nSimplify Your Data Preparation with These Four Lesser-Known Scikit-Learn Classes\nNon-Parametric Tests for Beginners (Part 1: Rank and Sign Tests)\nBigQuery Best Practices: Unleash the Full Potential of Your Data Warehouse\nHow to Test Your Python Code with Pytest\n7 Signs You’ve Become an Advanced Sklearn User Without Even Realizing It\nHow Data Scientists Save Time\nMLOps: What is Operational Tempo?\nFinding Your Dream Master’s Program in AI\nEditors\nTDS Editors\nBen Huberman\nCaitlin Kindig\nSign up for The Variable\n\n",
"AnswerId": "76390625",
"AnswerBody": "As Barry the Platipus mentions in a comment, the content you want is loaded via Javascript. A complicating factor is that this content is only loaded when you scroll the page, so even a naive Selenium-based solution like this will still return only the same set of results as your existing code:\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\n\n\noptions = Options()\noptions.add_argument(\"--headless\")\ndriver = webdriver.Chrome(options=options)\n\n\nclass Publication:\n    def __init__(self, publication):\n        self.publication = publication\n\n    def get_articles(self):\n        \"Get the articles of the user/publication which was given as input\"\n        publication = self.publication\n        driver.get(f\"https://{publication}.com/\")\n        elements = driver.find_elements(By.CSS_SELECTOR, \"h2\")\n        for x in elements:\n            print(x.text)\n\n\npublication = Publication(\"towardsdatascience\")\npublication.get_articles()\n\nTo get more than the initial set of articles, we need to scroll the page. For example, if we add a simple loop to scroll the page a few times before querying for h2 elements, like this:\n    def get_articles(self):\n        \"Get the articles of the user/publication which was given as input\"\n        publication = self.publication\n        driver.get(f\"https://{publication}.com/\")\n        for x in range(3):\n            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n\n            # The sleep here is to give the page time to respond.\n            time.sleep(0.2)\n        elements = driver.find_elements(By.CSS_SELECTOR, \"h2\")\n        for x in elements:\n            print(x.text)\n\nThen the output of the code is:\nLarge Language Models in Molecular Biology\nHow to Rewrite and Optimize Your SQL Queries to Pandas in 5 Simple Examples\nStorytelling with Charts\nSimplify Your Data Preparation with These Four Lesser-Known Scikit-Learn Classes\nNon-Parametric Tests for Beginners (Part 1: Rank and Sign Tests)\nBigQuery Best Practices: Unleash the Full Potential of Your Data Warehouse\nHow to Test Your Python Code with Pytest\n7 Signs You’ve Become an Advanced Sklearn User Without Even Realizing It\nHow Data Scientists Save Time\nMLOps: What is Operational Tempo?\nFinding Your Dream Master’s Program in AI\nTemporary Variables in Python: Readability versus Performance\nNaive Bayes Classification\nPredicting the Functionality of Water Pumps with XGBoost\nDetection of Credit Card Fraud with an Autoencoder\n4 Reasons Why I Won’t Sign the “Existential Risk” New Statement\nThe Data-centric AI Concepts in Segment Anything\n3D Deep Learning Python Tutorial: PointNet Data Preparation\nWhy Trust and Safety in Enterprise AI Is (Relatively) Easy\nThe Principles of a Modern Computer Scientist\n\nThat page appears to be an \"infinite scroll\" style of page, so you probably want to set a limit on how many times you scroll to find new content.\n"
},
{
"QuestionId": "76390552",
"QuestionTitle": "Python show output of remote SSH command in web page in Django",
"QuestionBody": "I have a simple Django app to show the output of an SSH remote command.\nviews.py:\nfrom django.http import HttpResponse\nfrom subprocess import *\n\ndef index(request):\n    with open('/home/python/django/cron/sites.txt', 'r') as file:\n        for site in file:\n            # out = getoutput(f\"ssh -o StrictHostKeyChecking=accept-new -p1994 root@{site} crontab -l\")\n            out = run([\"ssh\", \"-o StrictHostKeyChecking=accept-new\", \"-p1994\", f\"root@{site}\".strip(), \"crontab\", \"-l\"])\n    return HttpResponse(out)\n\nurls.py:\nfrom django.contrib import admin\nfrom django.urls import path\n# imported views\nfrom cron import views\n\nurlpatterns = [\n    path('admin/', admin.site.urls),\n    # configured the url\n    path('',views.index, name=\"homepage\")\n]\n\nsites.txt:\n1.1.1.1\n2.2.2.2\n3.3.3.3\n\nThe issue is when I run localhost:5000, I see this:\nCompletedProcess(args=['ssh', '-o StrictHostKeyChecking=accept-new', '-p1994', 'root@3.3.3.3', 'crontab', '-l'], returncode=0)\n\nWhile I should see something like this:\n* * * * * ls\n* * * * * date\n* * * * * pwd\n\nI tried with both run and getoutput, but they either don't connect or the output is shown in terminal only.\nHow can I run this and show the output in the webpage?\n",
"AnswerId": "76390629",
"AnswerBody": "You're returning the CompletedProcess object instead of its output.\nTry updating the run command to capture output by adding the optional parameter\nout = run([...], capture_output=True)\n\nAND changing the output to show the stdout instead of the object\nreturn HttpResponse(out.stdout)\n\n"
},
{
"QuestionId": "76392117",
"QuestionTitle": "Can I pass a variable string into the \"Value\" attribute for a HTML input tag?",
"QuestionBody": "sorry if this is a simplistic question or demonstrates some misunderstanding of HTML, this is my first time using it. If there's any missing info or stuff I should have included in the question, I'm happy to provide it.\nI have a python program, app.py, and it calls and renders an HTML page. That HTML page contains a few inputs and I understand how to place a given string as the default value for the input with the Value attribute.\nThis is the html:\n<form action=\"/new\" method=\"post\">\n    <label for=\"qty_wheels\">Number of wheels:</label>\n    \n    <input type=\"text\" name=\"qty_wheels\" value = \"Qty_Wheels\"     />\n    <label for=\"flag_color\">Colour of flag:</label>\n    <input type=\"text\" name=\"flag_color\" />\n    <input type=\"submit\" class=\"button\">\n</form>\n\nWhere \"Qty_Wheels\" is written though, I want to place a string I've passed in from the python end.\nThis is the python call for this html page:\nreturn render_template(\"buggy-form.html\", Qty_Wheels = given_qty)\n\nI've passed in the Qty_Wheels string here, and I want to print the value of that in the input. Is this possible and how can I do it? I've tried a lot of different syntax variants, but I can't find how I get it to interpret it as a string and print the content.\n",
"AnswerId": "76392146",
"AnswerBody": "Flask's templates use the {{ val }} syntax:\nPut the double curly brackets around Qty_Wheels:\n<form action=\"/new\" method=\"post\">\n    <label for=\"qty_wheels\">Number of wheels:</label>\n    \n    <input type=\"text\" name=\"qty_wheels\" value = \"{{ Qty_Wheels }}\"     />\n    <label for=\"flag_color\">Colour of flag:</label>\n    <input type=\"text\" name=\"flag_color\" />\n    <input type=\"submit\" class=\"button\">\n</form>\n\nFor more on Flask templates see: https://flask.palletsprojects.com/en/2.3.x/tutorial/templates/\n"
},
{
"QuestionId": "76388849",
"QuestionTitle": "Why does Tailwind declare CSS variables multiple times?",
"QuestionBody": "I am working on a react project with the tailwind. I checked the inspection of Chrome and saw the same tailwinds variables multiple times. I thought maybe something is not working properly in our project and checked Shopify and it was the same, I wonder why it is working in this way?\nScreenshots are taken from first page of Shopify\n\n\n",
"AnswerId": "76390020",
"AnswerBody": "There are Tailwind CSS default variables defined for ::backdrop in a separate rule from the *, ::before, ::after rule for two reasons:\n\nThe *, ::before, ::after selector does not cover ::backdrop. As per tailwindlabs/tailwindcss#8526:\n\nThis PR adds the ::backdrop pseudo-element to our universal default rules, which fixes an issue where utilities like backdrop:backdrop-blur would not work because the variables that rule depended on were not defined.\n\n\nAs for why it is in a separate rule, it could be due to browser support. According to MDN, the last major web browser to support ::backdrop was Safari 15.4 which was released on March 14th 2022. The aforementioned pull request tailwindlabs/tailwindcss#8526 was merged on June 6th 2022 and released with v3.1.0 on June 8th 2022.\nThis means at that time, only very recent Safari browsers would have support for the ::backdrop element. If ::backdrop would be with the *, ::before, ::after rule selector as *, ::before, ::after, ::backdrop, this would break sites on older Safari browsers, since the *, ::before, ::after, ::backdrop rule would not apply since one of the components were not supported. This could be a major regression so they separated out the ::backdrop selector into its own rule in pull request #8567 that was released in v3.1.1.\n\n\n"
},
{
"QuestionId": "76389558",
"QuestionTitle": "In Strapi V4, How should I register a middleware to alter the responses returned by /user or /user/:id?",
"QuestionBody": "I've started to play with middlewares, it's great !\nHere's an example of how I can inject a middleware when calling endpoints /api/playlists or /api/playlists/:id (I edited the file src/api/playlist/routes/playlist.js).\nmodule.exports = createCoreRouter('api::playlist.playlist', {\n config: {\n   find: {\n     middlewares: ['api::playlist.playlist.find']\n   },\n   findOne: {\n     middlewares: ['api::playlist.playlist.find-one']\n   },\n },\n})\n\nOf course, I also created my middlewares in src/api/playlist/middlewares/find.js and src/api/playlist/middlewares/find-one.js)\nBut know, I want to add another middleware to update the responses returned by the API when calling /api/users or /api/users/:id.\nSince there is no directory src/api/user in the filetree, how should I register a middleware for this ?\nThanks\n",
"AnswerId": "76390634",
"AnswerBody": "I finally found out :\n\ncreate the file src/extensions/user-permissions/strapi-server.js\n\nThis is mine. It registers a middleware for each of those endpoints:\n\nGET /users/me : plugin::spiff-api.user-me\n\nGET /users : plugin::spiff-api.user-find\n\nGET /users/:id : plugin::spiff-api.user-find-one\n(\"use strict\");\n\nmodule.exports = (plugin) => {\n  //if you see this, the configuration do loads:\n  console.log(\"Custom strapi-server.js for user-permissions\");\n\n  //get api routes for 'user-permissions'\n  const apiRoutes = plugin.routes['content-api'].routes;\n\n  //add middleware for GET /users/me\n  apiRoutes\n    .filter(route => route.handler === 'user.me')\n    .map(route => {\n      route.config.middlewares = [\n        ...(route.config.middlewares || []),\n        'plugin::spiff-api.user-me'//middleware name\n      ];\n      return route;\n    });\n\n    //add middleware for GET /users/:id\n    apiRoutes\n      .filter(route => route.handler === 'user.findOne')\n      .map(route => {\n        route.config.middlewares = [\n          ...(route.config.middlewares || []),\n          'plugin::spiff-api.user-find-one'//middleware name\n        ];\n        return route;\n      });\n\n  //add middleware for GET /users\n  apiRoutes\n    .filter(route => route.handler === 'user.find')\n    .map(route => {\n      console.log(route)\n      route.config.middlewares = [\n        ...(route.config.middlewares || []),\n        'plugin::spiff-api.user-find'//middleware name\n      ];\n      return route;\n    });\n\nreturn plugin;\n};\n\n\n\nThen, create your middlewares middleware, eg.\n    export default (config, { strapi })=> {\n      return async (ctx, next) => {\n        console.info(\"running middleware 'user-find-one.js'\");\n        console.log();\n\n        //update your query here if needed\n        //eg. populate 'favoritePosts'\n        ctx.query.populate = {\n          ...ctx.query.populate ?? {},\n          favoritePosts: {}\n        }\n\n        const controller = strapi.plugin('users-permissions').controller('user');\n        await controller.findOne(ctx);//this populates ctx.body\n        const response = ctx.body;\n\n        //update your response here if needed\n\n        ctx.body = response;\n        \n        await next();//not sure why this stands for\n\n      }\n    }\n\n"
},
{
"QuestionId": "76392112",
"QuestionTitle": "Input validation with regular expression not working",
"QuestionBody": "I'm trying to create a game in which, Starting of the game I have to ask the user for 'How many times he wants to play' and the user input must be an integer.\nSo I write the code I shared below. But it doesn't work as I expected.\nIf anyone can help me to figure out what I did wrong it will be helpful to me.\nThanks in advance.\n\n\nlet playCount = 0;\nlet regxNum = /^[0-9]+$/g; //Regular Expression to select all numbers between 0-9.\nlet checkPlayCount = 0;\nlet askPlayCount = () => { //Function to get game play count.\n  checkPlayCount = 0;\n  playCount = Number(prompt(\"How many times you want to play: \")); //Gets play count and convert into number;\n  checkPlayCount = Array.from(String(playCount), Number); //Converts number into array\n}\n\naskPlayCount();\n\n//Code for validating input : must be number.\nfor(let i = 0; i < checkPlayCount.length; i++){\n  if(checkPlayCount[i] != regxNum){\n    console.log(\"Please enter valid input\");\n    askPlayCount();\n  }\n}\n\n\n\n",
"AnswerId": "76392173",
"AnswerBody": "The problem is you convert the number into the array, while you simply can do this by directly checking the input against regex. Here is my version of the problem\n\n\nlet playCount = 0;\nlet regxNum = /^[0-9]+$/; // Regular Expression to match all numbers between 0-9\n\nlet askPlayCount = () => {\n  playCount = Number(prompt(\"How many times do you want to play: \"));\n}\n\naskPlayCount();\n\n// Code for validating input: must be a number.\nwhile (!regxNum.test(playCount)) {\n  console.log(\"Please enter a valid input\");\n  askPlayCount();\n}\n\n\n\n"
},
{
"QuestionId": "76392174",
"QuestionTitle": "Java and Python return different values when converting the hexadecimal to long",
"QuestionBody": "I noticed this difference when comparing xxhash implementations in both Python and Java languages. Calculated hashes by xxhash library is the same as hexadecimal string, but they are different when I try to get calculated hash as an integer(or long) value.\nI am sure that this is some kind of \"endian\" problem but I couldn't find how to get the same integer values for both languages.\nAny ideas how and why this is happening?\nJava Code:\nString hexString = \"d24ec4f1a98c6e5b\";\nSystem.out.println(new BigInteger(hexString,16).longValue());\n// printed value -> -3292477735350538661\n\nPython Code:\nhexString = \"d24ec4f1a98c6e5b\"\nprint(int(hexString, 16))\n# printed value -> 15154266338359012955\n\n",
"AnswerId": "76392197",
"AnswerBody": "You converted the BigInteger to long which is the reason for the difference. Because long is a signed 64-bits integer it overflows to a negative. If you just print the BigInteger as it is it gives the same result.\n      System.out.println(new BigInteger(hexString,16));\n# 15154266338359012955\n\n"
},
{
"QuestionId": "76388858",
"QuestionTitle": "change the size and orientation of legend title while plotting raster",
"QuestionBody": "library(terra)\nlibrary(RColorBrewer)\n\n# sample polygon\np <- system.file(\"ex/lux.shp\", package=\"terra\")\np <- terra::vect(p)\n\n# sample raster\nr <- system.file(\"ex/elev.tif\", package=\"terra\")\nr <- terra::rast(r)\nr <- terra::crop(r, p , snap = \"out\", mask = T)\n\nterra::plot(r,\n           col = brewer.pal(9, \"pastel1\"),\n           cex.main = 2,\n           smooth = T,\n           legend = T,\n           plg = list(title = \"Score\"),\n           axes = TRUE,\n           mar=c(3,3,3,6))\nplot(p, add = T)\n\nHow do I change the size and orientation of the legend title 'Score'.\nI want to orient the title so that it is vertical and follows along the\nlegend and also change the size of the legend title?\n",
"AnswerId": "76390104",
"AnswerBody": "You can add text whereever you want. For example\nlibrary(terra)\np <- terra::vect(system.file(\"ex/lux.shp\", package=\"terra\"))\nr <- terra::rast(system.file(\"ex/elev.tif\", package=\"terra\"))\n\nplot(r, mar=c(3,3,3,6))\ntext(x=6.77, y=49.95, \"Score\", srt=-90, cex=2, xpd=NA, pos=4)\nlines(p)\n\n\n"
},
{
"QuestionId": "76392129",
"QuestionTitle": "Why is babel home page different from the editor in the online tool",
"QuestionBody": "When I learned React to build virtual DOM，I use the editor on babel's website，Why are the two editors turning different code?\n\n\nWhy are the two editors turning different code?\n",
"AnswerId": "76392209",
"AnswerBody": "In the editor tool screenshot we can see that the selected option for the \"React Runtime\" configuration is \"Automatic\", while Babel's website editor looks like it's using the \"Classic\" option.\nThe difference between both is documented in https://babeljs.io/docs/babel-plugin-transform-react-jsx\nThere is also this blog post on React's blog, which explains the reasons behind.\n"
},
{
"QuestionId": "76389865",
"QuestionTitle": "How to register custom Spring validator and have automatic dependency injection?",
"QuestionBody": "When working with ConstraintValidators, we just need to define the class and constraint and Spring is able to detect the validators and instantiate them automatically, injecting any beans we ask for in the constructor.\nHow do I add my custom Spring Validators (https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/validation/Validator.html) in the same manner?\n",
"AnswerId": "76390685",
"AnswerBody": "You have to let the controller to know which validator will validate your request. I use following code to find supported validators:\n@ControllerAdvice\n@AllArgsConstructor\npublic class ControllerAdvisor {\n\n    private final List<Validator> validators;\n\n    @InitBinder\n    public void initBinder(@NonNull final WebDataBinder binder) {\n        final Object request= binder.getTarget();\n        if (request== null) {\n            return;\n        }\n        this.validators.stream()\n            .filter(validator -> validator.supports(request.getClass()))\n            .forEach(binder::addValidators);\n    }\n\n}\n\n\nNote that you have to create those validators as beans. Therefore, you should annotate those validators with @Component. Hope this help you.\n"
},
{
"QuestionId": "76388494",
"QuestionTitle": "Python3 - Kivy RecycleView's data Dictionary succefully updated, but not phisically the Widget",
"QuestionBody": "In a Kivy form i set 2 Recycleviews(A and B). I would add the item clicked in Recycleview A, to the RecycleView B, using a Python3 script:\nfrom functools import partial\nfrom kivy.app import App\nfrom kivy.lang.builder import Builder\nfrom kivy.uix.recycleview import RecycleView\nclass B(RecycleView):\n    def __init__(self,**kwargs):\n        super(B, self).__init__(**kwargs)\n    def doet(self,x):\n        self.data.append({'text':x})\n        print(self.data) #it prints correctly, so why doesn't update?\nclass A(RecycleView):\n    def __init__(self,**kwargs):\n        super(A, self).__init__(**kwargs)\n        self.data=[{'text':'FROM HERE','on_press':partial(app.b.doet,'TO HERE')}]\nclass app(App):\n    b=B()\n    def build(self):\n        return Builder.load_file('lab.kv')\napp().run()\n\n'lab.kv':\nBoxLayout:\n    A:\n        viewclass:'Button'\n        RecycleBoxLayout:\n            default_size: None, dp(56)\n            default_size_hint: 1, None\n            size_hint_y: None\n            height: self.minimum_height\n            orientation: 'vertical'\n    B:\n        viewclass:'Button'\n        RecycleBoxLayout:\n            default_size: None, dp(56)\n            default_size_hint: 1, None\n            size_hint_y: None\n            height: self.minimum_height\n            orientation: 'vertical'\n\nMy script correctly updates the Data's Dictionary, as I can see by printing it, but in RecycleView 'B' no items are phisically added.\n",
"AnswerId": "76390287",
"AnswerBody": "The main problem with your code is that the line:\nb=B()\n\nis creating a new instance of B that is unrelated to the instance of B that is created in your kv. So anything done to that new instance of B will have no effect on what you see on the screen.\nThere are many possible approaches to do what you want. Here is one:\nFirst, add an id to the B in your kv:\nB:\n    id: b\n\nThen, add a modify the App class:\nclass app(App):\n    def build(self):\n        root = Builder.load_file('lab.kv')\n        self.b = root.ids.b\n        return root\n\n    def doit(self, x):\n        self.b.doet(x)\n\nThe above build() method uses the new id to get a reference to the correct B instance, and saves that reference. The doit() method is just an intermediary to direct the call to the correct instance of B.\nThen modify the A class to use this:\nclass A(RecycleView):\n    def __init__(self,**kwargs):\n        super(A, self).__init__(**kwargs)\n        self.data=[{'text':'FROM HERE','on_press':partial(App.get_running_app().doit,'TO HERE')}]\n\n"
},
{
"QuestionId": "76390793",
"QuestionTitle": "How to export results from Query Summary from Kusto Explorer",
"QuestionBody": "I am trying to compare different where statements in my Kusto query using Kusto Explorer app, so I would like to export the result from the Query Summary tab.\nIn case has a query or a way to export this manually, it would be awesome.\nIs it possible?\n\n",
"AnswerId": "76392258",
"AnswerBody": "In Kusto.Explorer, if you switch to the QueryCompletionInformation tab in the result set, you can see & copy the QueryResourceConsumption payload\n\n"
},
{
"QuestionId": "76390320",
"QuestionTitle": "How do I include GitHub secrets in a python script?",
"QuestionBody": "I am trying to move my bot written using discord.py/pycord to github for easier access, and I accidentally pushed my bot tokn to the hub, thankfully discord reset it for me and nothing hapened.\nNow i want to use GitHub repository secrets to prevent this from happening, but i am having some trouble when trying to import the token into my code.\nHere I've made a simple repo to experiment with this:\ntest.py:\nimport os\nSECRET = os.environ['SECRET']\nif SECRET == \"TrustNo1\":\n    print(\"No one can be trusted\")\nprint(SECRET)\n\nworkflow.yml:\nname: build bot.py\non: [push]\n\njobs:\n    build:\n        runs-on: ubuntu-latest\n        steps:\n            - name: load content\n              uses: actions/checkout@v2\n              \n            - name: load python\n              uses: actions/setup-python@v4\n              with:\n                python-version: '3.10' # install the python version needed\n\n            - name: start bot\n              env:\n                TOKEN: ${{ secrets.SECRET }}\n              run: python test.py\n\nThe following error occurs at the \"start bot\" step in the workflow:\nTraceback (most recent call last):\n  File \"/home/runner/work/test-repo/test-repo/test.py\", line 2, in <module>\n    SECRET = os.environ['SECRET']\n  File \"/opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/os.py\", line 680, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'SECRET'\nError: Process completed with exit code 1.\n\nIf i try to echo the SECRET in the workflow.yml i get ***, so it has has acces to the token, but when it imports to python it all breaks down.\nI'm still quite new to git and GitHub, so please don't use advanced terms.\n",
"AnswerId": "76390714",
"AnswerBody": "            - name: start bot\n              env:\n                TOKEN: ${{ secrets.SECRET }}\n\nIn the GitHub Action you named the variable secrets.SECRET but in environment variables you named it TOKEN. Either change the name of the environment variable to SECRET:\n            - name: start bot\n              env:\n                SECRET: ${{ secrets.SECRET }}\n\nor change your code:\n    SECRET = os.environ['TOKEN']\n\n"
},
{
"QuestionId": "76381802",
"QuestionTitle": "Pyscript color input - triggers to soon",
"QuestionBody": "I'm using this html to have the user choose a color:\n<input type=\"color\" id=\"main-color\" name=\"head\" value=\"#15347d\"\">\nThen I'm using a button to call my python function\nbutton py-click=\"generate_color_schemes(False)\" id=\"button-submit\">Update!</button>\nWorks well. (generate_color_schemes() examines the Element(\"main-color\").value to get the hex color.)\nBut I'd like to combine the two, so clicking on the input - opens a picker and fires the python function as the user clicks inside the color picker as well as when they leave.\nBut (as expected) adding py-click fires my function when the input is first clicked and not when the color chooser popup closes or as the user clicks inside the color picker.\nI think I want pyclick to be triggering on the oninput event as well as the onchange event.\nIs there a way to combine the input type='color' with py-click to get this behaviour ?\n",
"AnswerId": "76390352",
"AnswerBody": "As you say, you've got the right syntax but the wrong event(s). Rather than listening for the click event, you can listen to the input event (which is dispatched every time the value of an input changes) or the change event (which is dispatched, in this case, when the color picker closes). To do this in PyScript (or to listen to any event), the HTML attribute is py-[event] where [event] is the type of the event. In this case, you'll use the py-input and py-change attributes.\nHere's a working example in the current release of PyScript (2023.03.1), which I mention in case the events API changes in the future. The MDN docs have a longer example in JavaScript.\n<!-- Written for PyScript 2023.03.1 -->\n<input type=\"color\" id=\"main-color\" py-input=\"do_something_with_color()\" py-change=\"do_something_else()\">\n\n<py-script>\n    import js\n    def do_something_with_color():\n        elem = js.document.getElementById(\"main-color\")\n        value = elem.value\n        print(f'Chosen color: {value}') # do something here\n\n    def do_something_else():\n        elem = js.document.getElementById(\"main-color\")\n        value = elem.value\n        print(f'The final color chosen was: {value}') # do something here\n</py-script>\n\n"
},
{
"QuestionId": "76389003",
"QuestionTitle": "How to synchronize a draw call with a dispatch call as late as possible?",
"QuestionBody": "I have a compute shader which updates a storage image which is later sampled by a fragment shader within a render pass.\nFrom khronos vulkan synchronization examples I know I can insert a pipeline barrier before the render pass to make sure the fragment shader samples the image without hazards. Note the example is modified slightly to include more draw calls.\nvkCmdDispatch(...); // update the image\n\nVkImageMemoryBarrier2KHR imageMemoryBarrier = {\n  ...\n  .srcStageMask = VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT_KHR,\n  .srcAccessMask = VK_ACCESS_2_SHADER_WRITE_BIT_KHR,\n  .dstStageMask = VK_PIPELINE_STAGE_2_FRAGMENT_SHADER_BIT_KHR,\n  .dstAccessMask = VK_ACCESS_2_SHADER_READ_BIT_KHR,\n  .oldLayout = VK_IMAGE_LAYOUT_GENERAL,\n  .newLayout = VK_IMAGE_LAYOUT_READ_ONLY_OPTIMAL\n  /* .image and .subresourceRange should identify image subresource accessed */};\n\nVkDependencyInfoKHR dependencyInfo = {\n    ...\n    1,                      // imageMemoryBarrierCount\n    &imageMemoryBarrier,    // pImageMemoryBarriers\n    ...\n}\n\nvkCmdPipelineBarrier2KHR(commandBuffer, &dependencyInfo);\n\n... // Render pass setup etc.\n\nvkCmdDraw(...); // does not sample the image\nvkCmdDraw(...); // does not sample the image\nvkCmdDraw(...); // does not sample the image\n\n...\n\nvkCmdDraw(...); // sample the image written by the compute shader, synchronized.\n\nIn the example, I have a bunch of draw calls within the same render pass that do not need the synchronization with the compute shader. They merely render a static geometry / textures which do not update dynamically. Yet in this configuration they must wait for the compute shader.\nIdeally, I would like the independent draw calls between the vkCmdDispatch call and last vkCmdDraw to be able to run concurrently.\nIf I understand the spec correctly, I can't put the same pipeline barrier within the render pass.\nAnother alternative I considered is to use external subpass dependencies and record the draw call which samples the texture in a second subpass. But I don't know if this is a valid approach, and in any case it will be hard to maintain as this configuration is hard coded into the renderpass object.\nSo Is there a different synchronization approach that can achieve better concurrency?\n",
"AnswerId": "76390723",
"AnswerBody": "You should put that in a subpass external dependency for the subpass you need to use it within. However, unless the rendering commands you want to overlap with the compute shader are in a prior subpass in the dependency graph, this probably won't give you any greater performance.\nNote that not even dynamic rendering helps you here, as vkCmdBeginRendering starts a render pass instance. This means that you still can't have pipeline barriers or events within them.\nEssentially, collective rendering operations (either the render pass as a whole or subpasses within it) defines an inflexible synchronization boundary between themselves as a group and the outside world. You can put synchronization around them, but not within them.\nThat being said, since rendering and compute operations are both eating up the same resources (shader stages), you probably weren't going to get too much overlap anyway.\n"
},
{
"QuestionId": "76392154",
"QuestionTitle": "Find BFS best path array",
"QuestionBody": "Description:\nI have a problem very similar to https://leetcode.com/problems/jump-game-ii/description/.\nApart from discovering the minimum steps to reach the end, I need to retrieve the winning path array.\nThe winning path that is needed for my problem must satisfy the rule that given path A like [0,2,4,7] there are not any other paths with the same price (steps to the end, 3 in this case) whose nodes starting from the path's end has lower indexes.\nThe single step from i to i+1 has not price equal to 1 but is 0 <= x <= 2^32-1.\nAn example:\n\n[0,2,4,5,7] is the winner\n[0,1,4,6,7] is not the winner because 6 > 5 at index 3\n\nThis has to work also in reverse:\n\n[7,6,3,1,0] is the winner\n[7,5,4,2,0] is not the winner because 2 > 1 at index 3\n\nNote that this rule is applied from right to left.\nClearly, I can produce all the paths with BFS and hence compare them but is there a more efficient way?\n",
"AnswerId": "76392264",
"AnswerBody": "\nThe winning path that is needed for my problem must satisfy the rule that given path A like [0,2,4,7] there are not any other paths with the same price (steps to the end, 3 in this case) whose nodes starting from the path's end has lower indexes.\n\n\nI can produce all the paths with BFS and hence compare them but is there a more efficient way?\n\nYes.\nSearch backwards, from end to start, in BFS fashion.  When you enqueue each node's unvisited successors, do it in increasing order by index. The first path you discover will then be the reverse of the path you're looking for.\n"
},
{
"QuestionId": "76390601",
"QuestionTitle": "spring boot application not working bean error",
"QuestionBody": "I am new to Spring Boot and I'm getting the following error when writing a login validationAPI:\nField userservice in com.Productwebsite.controller.UserController required a bean of type 'com.Productwebsite.service.UserService' that could not be found.\nThe injection point has the following annotations:\n- @org.springframework.beans.factory.annotation.Autowired(required=true)\nController class:\npackage com.Productwebsite.controller;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport com.Productwebsite.service.UserService;\n\n@RestController\npublic class UserController {\n    \n    @Autowired\n    private UserService userservice;\n    \n    @GetMapping(\"user/{username}/{password}\")\n    public int UserLogin(@PathVariable(\"username\")String username1, @PathVariable(\"password\")String password1) {\n        int flag = userservice.loginValidation(username1, password1);\n        if (flag == 0) {\n            return 0;\n        }\n        return flag;\n    }\n}\n\nModelclass:\npackage com.Productwebsite.model;\n\npublic class users {\n    String username;\n    String password;\n\n    public String getUsername() {\n        return username;\n    }\n\n    public void setUsername(String username) {\n        this.username = username;\n    }\n\n    public String getPassword() {\n        return password;\n    }\n\n    public void setPassword(String password) {\n        this.password = password;\n    }\n    \n    @Override\n    public String toString() {\n        return \"users [username=\" + username + \", password=\" + password + \"]\";\n    }\n\n    public users(String username, String password) {\n        super();\n        this.username = username;\n        this.password = password;\n    }\n\n    public users() {\n        super();\n        // TODO Auto-generated constructor stub\n    }\n}\n\nService interfface:\npackage com.Productwebsite.service;\n\nimport org.springframework.stereotype.Repository;\n\n@Repository\npublic interface UserService {\n    \n    public int loginValidation(String username,String password);\n}\n\nServiceimplementation class:\npackage com.Productwebsite.serviceImp;\n\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\n\nimport org.springframework.stereotype.Service;\n\nimport com.Productwebsite.Dbutil.dbutil;\nimport com.Productwebsite.service.UserService;\n\n@Service\npublic class ServiceImp implements UserService {\n    Connection connection;\n    int flag = 0;\n\n    public ServiceImp() throws SQLException {\n        connection = dbutil.getConnection();\n    }\n\n    @Override\n    public int loginValidation(String username, String password) {\n        try {\n            PreparedStatement statement \n = connection.prepareStatement(\"SELECT * FROM users WHERE username='\"+username+\"'\"); \n            ResultSet rs=statement.executeQuery();\n            \n            while(rs.next()) {\n                if (rs.getString(1).equals(username)&&rs.getString(2).equals(password)) {\n                    flag=1;\n                }\n                else {\n                    System.out.println(\"Invalid username/password\");\n                }\n            }\n        } catch (SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n        return flag;\n    }\n}\n\n",
"AnswerId": "76390737",
"AnswerBody": "Add @ComponentScan to com.Productwebsite and restart the app.\n@ComponentScan(basePackages = \"com.Productwebsite\")\n@SpringBootApplication\npublic class YourMainClass{\n  ...\n}\n\n\nTry the following, if the above changes do not work:\nChange annotation by adding the bean name:\n@Repository(\"userservice\")\n\n"
},
{
"QuestionId": "76388789",
"QuestionTitle": "How to hide/show specific Cell in Grid",
"QuestionBody": "Im using renderer function as below and want to hide/show specific checkcolumn-cells depending on variable record.data.hidden in my gridview.\n{\n   xtype: 'checkcolumn',\n   renderer: function(value, metaData, record, rowIndex, colIndex, store, view) {\n       /*\n       if (record.data.hidden === true) {\n           // checkbox hidden\n       } else {\n           // checkbox shown\n       }\n       */\n    },\n    itemId: 'mycheck',\n    bind: {\n        text: '{warranty}'\n    }\n}\n\nHow do i do this?\n",
"AnswerId": "76390508",
"AnswerBody": "You can use the metaData passed to the renderer function to apply styling to the cell element, see the documentation here.\nOne easy way is to set the display CSS property depending on your criteria. This will be applied to the HTML <td> element created by Ext JS for the cell.\nTry this:\n{\n   xtype: 'checkcolumn',\n   renderer: function(value, metaData, record, rowIndex, colIndex, store, view) {\n       if (record.data.hidden === true) {\n           metaData.tdStyle = 'display: none;';\n       } else {\n           metaData.tdStyle = 'display: table-cell;';\n       }\n       return value;\n    },\n    itemId: 'mycheck',\n    bind: {\n        text: '{warranty}'\n    }\n}\n\n(I am not sure about the right syntax, maybe you don't need the semicolon after none and table-cell, and maybe you have to use quotations somewhere. Try it.)\nBut you create a CSS style and use tdCls as well, and perhaps also tdAttr but I am not sure about the latest.\n"
},
{
"QuestionId": "76392232",
"QuestionTitle": "Generic Component in React - Type is not assignable to type 'ReactNode'. But no error with JSON.stringify()",
"QuestionBody": "I'm trying to create a generic component in React TypeScript. Here is the code\ninterface Props<T> {\n    name: T;\n}\n\nfunction CheckChild<T>(props: Props<T>) {\n    return <div>My name is {props.name}</div>;\n}\n\nexport default function Check() {\n    const name = \"Alex\";\n\n    return (\n        <div>\n            <CheckChild name={name} />\n        </div>\n    );\n}\n\nVS code gives me a type error about props.name:\nType 'T' is not assignable to type 'ReactNode'.\n  Type 'T' is not assignable to type 'ReactPortal'.ts(2322)\nCheck2.tsx(7, 21): This type parameter might need an `extends React.ReactPortal` constraint.\nCheck2.tsx(7, 21): This type parameter might need an `extends React.ReactNode` constraint.\n\nBut if I wrap props.name in JSON.stringify() - type error disappears.\nreturn <div>My name is {JSON.stringify(props.name)}</div>;\n\nWhy does this happen?\nThis topic does not answer my question. I am interested in \"Why JSON.stringify removes error\"?\n",
"AnswerId": "76392265",
"AnswerBody": "The reason why the type error disappears when you wrap props.name in JSON.stringify() is because JSON.stringify() converts the value to a string representation. In TypeScript, the type ReactNode represents the type of a valid React node, which can be a string, a number, a React component, an array, etc.\nWhen you directly use props.name without JSON.stringify(), the TypeScript compiler assumes that the type of props.name should be compatible with ReactNode. However, in your code, you have a generic type T for the name property in the Props interface. The compiler doesn't have enough information to determine the actual type of T, so it gives a type error.\nBy using JSON.stringify(props.name), you explicitly convert the value to a string, which satisfies the ReactNode type requirement. This makes the type error disappear because JSON.stringify() always returns a string, and a string is a valid type for ReactNode.\nIf you want to avoid using JSON.stringify(), you can provide a more specific type constraint for the T generic in the Props interface. For example, if you know that props.name will always be a string, you can update the Props interface like this:\ninterface Props<T extends string> {\n   name: T;\n}\n\n"
},
{
"QuestionId": "76388077",
"QuestionTitle": "Fetch data Firestore Flutter",
"QuestionBody": "I want to get the data where I marked. But since I made the side collection a custom name (as you can see in the picture TbarRow and latpuldown), I cannot fetch the last data I want to reach. Actually, when I write the name of the collection by hand, I reach it, but I don't know how to fetch that name without writing it myself.\n\nI created an array with the name of gunharaketisimleri of the documentation (4 documents Karın bacak itiş çekiş) and tried to fetch the data from there.\n\nand try it like this:\nFuture<void> fetchData() async {\n  try {\n    var snapshot = await FirebaseFirestore.instance\n        .collection(\"günler\")\n        .doc(currentUserID + \" GUN\")\n        .collection(\"gün\")\n        .doc(\"itiş\")\n        .get();\n    snapshot.data()!.forEach((key, value) {\n      List<dynamic> favorites1 = [];\n      favorites1.add(value);\n      print(favorites1);\n    });\n  } catch (e) {\n    // Handle any errors\n    print(e.toString());\n  }\n}\n\nand output:\n\nI/flutter (24013): [[TbarRow, latpuldown]]\n\n\nI/flutter (24013): [itiş]\n\n\nI/flutter (24013): [null]\n\n\nI/flutter (24013):[gdc0mIEbwmdVFqZoLDC0gnIFCAy2]\n\nI tried to reach it this way and got stuck here. Can you suggest another method or how should the continuation be from the final version?\n",
"AnswerId": "76390533",
"AnswerBody": "To get the array from the document, would be something like:\nvar array = snapshot.get('gunharaketisimleri') as List;\n\nThen you can loop over the list to get the individual values.\n"
},
{
"QuestionId": "76389459",
"QuestionTitle": "Stubbing Models contained within an Object",
"QuestionBody": "I am having real issues stubbing one particular thing using sinon.  I have a simple function I am testing\nconst floatAPIModels = require(\"models/float/floatAPIModels\");\n\nconst insertFloatData = async (databaseConnection, endpoint, endpointData) => {\n  try {\n    const floatModel = floatAPIModels(databaseConnection);\n    await databaseConnection.sync();\n\n    if (endpoint === \"people\") {\n      endpointData.forEach(async (record) => {\n        await floatModel.Person.upsert(record);\n      });\n    }\n\n    return true;\n  } catch (error) {\n    console.log(\"Unable to insert data into the database:\", error);\n    return error;\n  }\n};\n\nThe problem is with floatAPIModels being an Object that returns things.  My implementation is this\nconst { DataTypes } = require(\"sequelize\");\n\nconst floatAPIModels = (sequelize) => {\n  const Person = sequelize.define(\n    \"Person\",\n    {\n      people_id: { type: DataTypes.INTEGER, primaryKey: true },\n      job_title: { type: DataTypes.STRING(200), allowNull: true },\n      employee_type: { type: DataTypes.BOOLEAN, allowNull: true },\n      active: { type: DataTypes.BOOLEAN, allowNull: true },\n      start_date: { type: DataTypes.DATE, allowNull: true },\n      end_date: { type: DataTypes.DATE, allowNull: true },\n      department_name: { type: DataTypes.STRING, allowNull: true },\n      default_hourly_rate: { type: DataTypes.FLOAT, allowNull: true },\n      created: { type: DataTypes.DATE, allowNull: true },\n      modified: { type: DataTypes.DATE, allowNull: true },\n    },\n    {\n      timestamps: true,\n      tableName: \"Person\",\n    }\n  );\n\n  return {\n    Person,\n  };\n};\n\nmodule.exports = floatAPIModels;\n\nI have removed some things to cut down on code.  At the moment I am doing something like this\nconst { expect } = require(\"chai\");\nconst sinon = require(\"sinon\");\nconst floatAPIModels = require(\"src/models/float/floatAPIModels\");\nconst floatService = require(\"src/services/float/floatService\");\n\ndescribe(\"insertFloatData\", () => {\n  let databaseConnection;\n  let floatModelMock;\n\n  beforeEach(() => {\n    databaseConnection = {};\n\n    floatModelMock = {\n      Person: { upsert: sinon.stub().resolves() },\n    };\n\n    sinon.stub(floatAPIModels, \"Person\").returns(floatModelMock.Person);\n  });\n\n  afterEach(() => {\n    sinon.restore();\n  });\n\n  it(\"should insert endpointData into the 'people' endpoint\", async () => {\n    const endpoint = \"people\";\n    const endpointData = [{ record: \"data\" }];\n\n    await floatService.insertFloatData(databaseConnection, endpoint, endpointData);\n\n    expect(floatModelMock.Person.upsert.calledOnce).to.be.true;\n    expect(floatModelMock.Person.upsert.firstCall.args[0]).to.deep.equal(endpointData[0]);\n  });\n});\n\nWith the above, I get\nTypeError: Cannot stub non-existent property Person\n\nBut I have tried default, and a lot of other ways, but none of them seems to work.\nHow can I properly stub this and get the unit test working?\nThanks\n",
"AnswerId": "76390741",
"AnswerBody": "floatAPIModels is a function that returns { Person } object. There is no Person property on this function. That's why you got the error.\nIn order to stub the floatAPIModels function, I will use the proxyquire module to do this.\nE.g.\nmodel.js:\nconst { DataTypes } = require(\"sequelize\");\n\nconst floatAPIModels = (sequelize) => {\n  const Person = sequelize.define(\n    \"Person\",\n    {\n      people_id: { type: DataTypes.INTEGER, primaryKey: true },\n      // rest fields, don't matter for this test\n      // ...\n    },\n    { timestamps: true, tableName: \"Person\", }\n  );\n\n  return {\n    Person,\n  };\n};\n\nmodule.exports = floatAPIModels;\n\nservice.js:\nconst floatAPIModels = require(\"./model\");\n\nconst insertFloatData = async (databaseConnection, endpoint, endpointData) => {\n  try {\n    const floatModel = floatAPIModels(databaseConnection);\n    await databaseConnection.sync();\n    if (endpoint === \"people\") {\n      endpointData.forEach(async (record) => {\n        await floatModel.Person.upsert(record);\n      });\n    }\n    return true;\n  } catch (error) {\n    console.log(\"Unable to insert data into the database:\", error);\n    return error;\n  }\n};\n\nmodule.exports = { insertFloatData }\n\nservice.test.js:\nconst sinon = require(\"sinon\");\nconst proxyquire = require('proxyquire');\n\ndescribe(\"insertFloatData\", () => {\n  let databaseConnection;\n\n  beforeEach(() => {\n    databaseConnection = {\n      define: sinon.stub(),\n      sync: sinon.stub()\n    };\n  });\n\n  afterEach(() => {\n    sinon.restore();\n  });\n\n  it(\"should insert endpointData into the 'people' endpoint\", async () => {\n    const endpoint = \"people\";\n    const endpointData = [{ record: \"data\" }];\n    const PersonStub = {\n      upsert: sinon.stub()\n    }\n    const floatAPIModelsStub = sinon.stub().returns({ Person: PersonStub })\n    const floatService = proxyquire('./service', {\n      './model': floatAPIModelsStub\n    })\n\n    await floatService.insertFloatData(databaseConnection, endpoint, endpointData);\n\n    sinon.assert.calledOnce(PersonStub.upsert)\n    sinon.assert.match(PersonStub.upsert.firstCall.args[0], endpointData[0])\n  });\n});\n\nTest result:\n  insertFloatData\n    ✓ should insert endpointData into the 'people' endpoint (4168ms)\n\n\n  1 passing (4s)\n\n------------|---------|----------|---------|---------|-------------------\nFile        | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s \n------------|---------|----------|---------|---------|-------------------\nAll files   |   76.47 |       50 |   66.67 |   76.47 |                   \n model.js   |      60 |      100 |       0 |      60 | 4-24              \n service.js |   83.33 |       50 |     100 |   83.33 | 14-15             \n------------|---------|----------|---------|---------|-------------------\n\n"
},
{
"QuestionId": "76391788",
"QuestionTitle": "How do I resolve the time limit?",
"QuestionBody": "Write a program that determines for two nodes of a tree whether the first one is a parent of another.\nInput data\nThe first line contains the number of vertices n (1 ≤ n ≤ 10^5) in a tree. The second line contains n numbers, the i-th one gives the vertex number of direct ancestor for the vertex i. If this value is zero, then the vertex is a root of a tree.\nThe third line contains the number of queries m (1 ≤ m ≤ 10^5). Each of the next m lines contains two different numbers a and b (1 ≤ a, b ≤ n).\nOutput data\nFor each of the m queries print on a separate line number 1, if the vertex a is one of the parents of a vertex b, and 0 otherwise.\n\nInput example #1\n6\n0 1 1 2 3 3\n5\n4 1\n1 4\n3 6\n2 6\n6 5\nOutput example #1\n0\n1\n1\n0\n0\nProblem\nHow can I fix the time limit?\nI also tried with <stdio.h>(scanf();printf()).\nBut problem gives time limit.\nIt gives time limit for input(many input things)\nMy solution:\n#include<iostream>\n#include<vector>\n#include<algorithm>\nusing namespace std;\nvector<vector<int>> g;\nvector<int> time_in,time_out;\nint Time=0;\nvoid dfs(int node,int parent){\n    time_in[node]=++Time;\n    for(int &to:g[node]){\n        if(to!=parent){\n                dfs(to,node);\n        }\n    }\n    time_out[node]=++Time;// or  time_out[node]=Time;\n}\nbool isAnchestor(int anch,int node){\n    return time_in[anch]<=time_in[node] and time_out[anch]>=time_out[node];\n}\nvoid readInt(int &n){\n    char ch;\n    int sign = 1;\n    while(ch = getchar(), isspace(ch)){//getchar()-->getchar_unlocked()\n\n    };\n    n = 0;\n    if(ch == '-')\n        sign = -1;\n    else n = ch - '0';\n    while(ch = getchar(), isdigit(ch))\n        n = (n << 3) + (n << 1) + ch - '0';\n    n *= sign;\n}\nint main(){\n    ios_base::sync_with_stdio(0);\n    //cin.tie(0);\n    cout.tie(0);\n    int n,start;\n    readInt(n);\n    time_in.resize(n+1);\n    time_out.resize(n+1);\n    g.resize(n+1);\n    vector<int> anchestors(n+2);\n    for(int i=1; i<=n; ++i){// I am thinking: the anchestors is sorted.\n            readInt(anchestors[i]);\n            if(anchestors[i] != 0) {\n\n\n        g[anchestors[i]].push_back(i);\n        g[i].push_back(anchestors[i]);\n        g[anchestors[i]].push_back(i);\n    }else{\n    start=i;\n    }\n    }\n    dfs(start,1);\n    int q,u,v;\n    readInt(q);\n    while(q--){\n        readInt(u),readInt(v);\n        cout<<isAnchestor(u,v)<<'\\n';// The anchestor of v is u. //(u,v)-->(a,b)\n    }\n    return 0;\n}\n\n\n",
"AnswerId": "76392266",
"AnswerBody": "Your approach using a depth first search is inefficient. This in general will look at more than just the path from b to a though the \"parent pointers\" or to the root, if b is not a descendant of a.\nInstead start the search at b and go to the parent node repeatedly until you find the root or a. This will only consider the path from b to the root node. You don't need to consider any alternative paths, but you always know the edge to traverse.\n#include <iostream>\n#include <vector>\n\nint main()\n{\n    constexpr int RootParent = -1;\n\n    int n;\n    std::cin >> n;\n    std::vector<int> parents;\n    parents.reserve(n);\n    for (int i = 0; i != n; ++i)\n    {\n        int v;\n        std::cin >> v;\n        parents.push_back(v - 1); // note: storing 0-based indices of parents here (root's parent becomes -1)\n    }\n\n    int queryCount;\n    for(std::cin >> queryCount; queryCount > 0; --queryCount)\n    {\n        int searchedAncestor;\n        int descendant;\n        std::cin >> searchedAncestor >> descendant;\n        \n        // inputs are still 1-based, so we need to decrement here\n        --searchedAncestor;\n        --descendant;\n\n        // repeatedly go to the parent node until we reach the root or the ancestor to attempt to find\n        while ((searchedAncestor != descendant) && (descendant != RootParent))\n        {\n            descendant = parents[descendant];\n        }\n        std::cout << (searchedAncestor == descendant) << '\\n';\n    }\n}\n\nDemo on godbolt\n"
},
{
"QuestionId": "76387967",
"QuestionTitle": "How to print as PDF all pages in HTML?",
"QuestionBody": "I have this html/JS code that generates N tables based on user input. I'm trying to separate the content in pages of \"A4\" size and with no more that 6 tables within each page in order to give the option to print as PDF.\nI'm using the built-in JS function window.print(). The issue is that when the browser opens up the printing preview window, only detects 2 pages and only first page content appears correct, the rest appears empty.\nYou can try for example to generate 24 tables (that would be 4 pages) and when click on print, only 2 pages are detected.\nBasically I'm using this to convert as PDF the content generated by the other 2 JS codes.\n<button onclick=\"printPDF()\">Print PDF</button>\n\n    function printPDF() {\n        window.print();\n    }\n\nHow to fix this, in order to print all pages? Thanks\n",
"AnswerId": "76390557",
"AnswerBody": "One problem is the hidden page overspill\nso simply remove that such that all contents are eligible for printing. Note you may want to move hidden to just the button at print time.\nAnd the 2nd is you may need a page-break-after: always;\nwhen the table container blocks reach 6 to a page limit, so try add that in. Note even with all 6 it will not add a blank page unless the table is too close to the edge so it overspills, hence the 7th (13th ... etc.) triggers the page break.\nLater Edit I seems that an auto page-break is added in the fiddle so may not be needed? However I also had issues with FireFox assessment of page height so for my MS printing had to reduce between 3-6mm to not trigger an extra page!\n\nhttps://jsfiddle.net/61qshzvc/\n"
},
{
"QuestionId": "76390332",
"QuestionTitle": "Fixed Output sequence for selectOutput5",
"QuestionBody": "Problem statement:\nI want to experiment with different sequences for the routing through the selectOutput5 block.\nExample:\nRandom (all 5 Outputs can be choosen by probability 0.2) (thats the easy part that i solved)\nFixed: (Output1: 6 agents, after those six agents, Output2: six agents and so on...\nDo you have an idea on how i can do this based on expressions or conditions?\nThank you very much and have a great weekend\n",
"AnswerId": "76390748",
"AnswerBody": "Set the \"Use:\" property in your SelectOutput5 block to \"Exit number\". Then you can define which exit to use.\nFor your example, I would create an int type variable named currExit and set the initial value to 1. Set the value of \"Exit number [1..5]:\" in your SelectOutput5 block to currExit and write this code to the \"On enter:\" property:\nif (self.in.count()%6==0) {\n    currExit++;\n    if (currExit>5) currExit=1;\n}\n\nThis switches to the next exit for every 6th agent (self.in.count() returns the number of agents that have entered the block so far).\n"
},
{
"QuestionId": "76388627",
"QuestionTitle": "Exception when executing JDBC query - Illegal instant due to time zone offset transition with Logstash",
"QuestionBody": "I have the following JDBC input:\ninput {\n  jdbc {\n    id => \"mypipeline\"\n    jdbc_driver_class => \"com.mysql.jdbc.Driver\"\n    jdbc_driver_library => \"/usr/share/logstash/drivers/mysql-connector-j-8.0.32.jar\"\n    jdbc_connection_string => \"my-connection-string\"\n    jdbc_password => \"my-user\"\n    jdbc_user => \"my-pass\"\n    jdbc_fetch_size => 5000\n    schedule => \"*/5 * * * *\"\n    statement => \"SELECT l.id, l.name, l.log_date FROM logs l WHERE l.created_at >= :sql_last_value\"\n  }\n}\n\nThe log_date column is as follows:\nlog_date DATE NULL DEFAULT NULL,\n\nWarning; created_at and log_date are not the same column. The query that's being executed is as follows:\nSELECT l.id, l.name, l.log_date FROM logs l WHERE l.created_at >= '1970-01-01 02:00:00'\n\nwhich is wrong, since Istanbul does not go into DST, should be '1970-01-01 03:00:00' For values such as 1949-04-10 for log_date, I am receiving this error:\n[2023-06-02T11:50:30,470][WARN ][logstash.inputs.jdbc     ][main][mypipeline] Exception when executing JDBC query {:exception=>Sequel::DatabaseError, :message=>\"Java::OrgJodaTime::IllegalInstantException: Illegal instant due to time zone offset transition (daylight savings time 'gap'): 1949-04-10T00:00:00.000 (Europe/Istanbul)\", :cause=>\"#<Java::OrgJodaTime::IllegalInstantException: Illegal instant due to time zone offset transition (daylight savings time 'gap'): 1949-04-10T00:00:00.000 (Europe/Istanbul)>\"}\n\nHow do I resolve this?\n",
"AnswerId": "76390717",
"AnswerBody": "\"Illegal instant due to time zone offset transition\" - Istanbul does not currently change between daylight saving time and standard time, but it has done in the past.\nIt is currently observing what is effectively DST year-round - and has done so since March 27th 2016, when the clocks moved forward by 1 hour from a UCT timezone offset of +2 hours to +3 hours.\n\nMore specifically regarding the \"Illegal instant\" error: In 1949 on 10th April at midnight, the clocks moved forward by 1 hour - so the local time of 1949-04-10  00:00 never actually happened. That is why it is a \"gap\" value, as noted in the error message.\nThis time zone data is captured in the IANA Time Zone Database (TZDB), which I assume is what your application uses, behind the scenes (e.g. if you are using Joda-Time).\nYou can use an online tool such as this one (and probaby others):\n\nWARNING - I cannot vouch for the accuracy of the data on this web site, but it does match the TZDB rule for this specific example, which I extracted as follows using Java (which uses TZDB data):\n - on 1949-04-10 at 00:00\n - the clocks moved forward by 1 hr (daylight saving)\n - from TZ offset +02:00 to offset +03:00\n\n\nRegarding your comment:\n\n\"should be '1970-01-01 03:00:00'\"\n\nFor 1970, the TZDB indicates that there were no adjustments made. So, the effective offset from UTC was the one previously made in 1964:\n - on 1964-10-01 at 00:00\n - the clocks moved back by 1 hr\n - from TZ offset +03:00 to offset +02:00\n\nAnd that +02:00 is what you are (correctly) seeing in your data for that 1970 datetime.\n\nIf you want to avoid using a datetime which falls into one of these gaps (caused by the clocks moving forward), then you can do that programmatically - for example:\n\nAssuming Java (since you mention Joda-Time): java.time discovering I'm in the daylight savings \"gap\"\n\nOther mainstream languages should have similar capabilities.\n\nAlso, since you mentioned Joda, maybe you can consider using Java's java.time classes now (if you have a suitable version of Java), instead of using Joda-Time:\n\nNote that from Java SE 8 onwards, users are asked to migrate to java.time (JSR-310) - a core part of the JDK which replaces this project.\n\n\nSpecific solution to the case with Logstash\nAdding jdbc_default_timezone => \"GMT\" to Logstash configuration and altering the timezone of the host machine will make Logstash to query the database without getting this error.\n"
},
{
"QuestionId": "76389709",
"QuestionTitle": "Clean column with different time records in powerbi",
"QuestionBody": "I have a Power BI table with a column called \"hours\". It can have different time records with  following different formats:\nPT5H15M{YearMonthDayTime}, PT0S{YearMonthDayTime}, PT5H15M, PT10H, etc.\nHow can I clean them up so that the hours are represented as numbers, for example, PT5H15M{YearMonthDayTime} would be 5,25 and PT3H30M would be 3,5.\nCan't find any easy way to filter the column since some rows have {YearMonthDayTime} ending and others doesn't. I don't want to transform every record manually.\nThanks already!\n",
"AnswerId": "76390777",
"AnswerBody": "You can achieve this in power query\nSteps followed in Power Query\n\nExtract Text between delimiters PT and H to populate Hours column. Change type to decimal\nExtract Text between delimiters H and M to populate Minutes column. Change type to decimal\nReplace Errors with zero. Replace all null values with zero.\nDevide Minutes column by 60 to convert into hours.\nAdd Hours column in step 1) to hours column in step 4)\nConvert result column type to Text\nIn result column: Replace . with , using Transform -> Replace Values\n\nM code:\nlet\n    Source = Excel.Workbook(File.Contents(\"C:\\Ashok\\Power BI\\Stack Overflow\\Data_02_jun2_2023.xlsx\"), null, true),\n    Data_Sheet = Source{[Item=\"Data\",Kind=\"Sheet\"]}[Data],\n    #\"Changed Type\" = Table.TransformColumnTypes(Data_Sheet,{{\"Column1\", type text}}),\n    #\"Promoted Headers\" = Table.PromoteHeaders(#\"Changed Type\", [PromoteAllScalars=true]),\n    #\"Changed Type1\" = Table.TransformColumnTypes(#\"Promoted Headers\",{{\"Hours\", type text}}),\n    #\"Inserted Text Between Delimiters\" = Table.AddColumn(#\"Changed Type1\", \"Text Between Delimiters\", each Text.BetweenDelimiters([Hours], \"PT\", \"H\"), type text),\n    #\"Inserted Text Between Delimiters1\" = Table.AddColumn(#\"Inserted Text Between Delimiters\", \"Text Between Delimiters.1\", each Text.BetweenDelimiters([Hours], \"H\", \"M\"), type text),\n    #\"Changed Type2\" = Table.TransformColumnTypes(#\"Inserted Text Between Delimiters1\",{{\"Text Between Delimiters.1\", type number}}),\n    #\"Inserted Division\" = Table.AddColumn(#\"Changed Type2\", \"Division\", each [Text Between Delimiters.1] / 60, type number),\n    #\"Changed Type3\" = Table.TransformColumnTypes(#\"Inserted Division\",{{\"Text Between Delimiters\", type number}}),\n    #\"Replaced Errors\" = Table.ReplaceErrorValues(#\"Changed Type3\", {{\"Text Between Delimiters\", 0}}),\n    #\"xyz\" = Table.TransformColumns(#\"Replaced Errors\", {{\"Text Between Delimiters\", each if _ is null then 0 else _}, \n                                                        {\"Text Between Delimiters.1\", each if _ is null then 0 else _}, {\"Division\", each if _ is null then 0 else _}}),\n    #\"Changed Type4\" = Table.TransformColumnTypes(xyz,{{\"Text Between Delimiters\", type number}, {\"Division\", type number}}),\n    #\"Inserted Addition\" = Table.AddColumn(#\"Changed Type4\", \"Addition\", each [Text Between Delimiters] + [Division], type number),\n    #\"Changed Type5\" = Table.TransformColumnTypes(#\"Inserted Addition\",{{\"Addition\", type text}}),\n    #\"Replaced Value\" = Table.ReplaceValue(#\"Changed Type5\",\".\",\",\",Replacer.ReplaceText,{\"Addition\"})\nin\n    #\"Replaced Value\"\n\n\n"
},
{
"QuestionId": "76391920",
"QuestionTitle": "Write a Python program to remove duplicates from a list of integers, preserving order",
"QuestionBody": "So this was the question and I implemented it using python language but there is error in code and I am not able to fix it so please help. I am attaching code also.\ndef delete23(a):\n    for i in range(0, len(a) - 1):\n        for j in range(0, len(a) - 1):\n            if a[i] == a[j] and i != j:\n                a.pop(j)\n    print(a)\n\n\na = [1, 2, 3, 4, 4, 1, 7]\nprint(len(a))\ndelete23(a)\n\n\n",
"AnswerId": "76392279",
"AnswerBody": "To filter duplicates while preserving the order, a set of seen values is used quite often. The logic is very simple: if a value is not present yet in seen, the value is encountered for the first time.\nlst = [1, 2, 3, 4, 4, 1, 7]\n\nseen = set()\nlst2 = []\nfor x in lst:\n    if x not in seen:\n        seen.add(x)\n        lst2.append(x)\n    \nprint(lst2)\n\nWith a little trick, this can be shortened:\nseen = set()\nlst2 = [(seen.add(x) or x) for x in lst if x not in seen]\n\nprint(lst2)\n\nTo explain the expression inside (...): set.add returns None and (None or VALUE) is evaluated to VALUE\n\nWarning: ALL solutions using a set or a dict require that all values are hashable.\n"
},
{
"QuestionId": "76388344",
"QuestionTitle": "Apply a weighting to a 4 parameter regression curvefit",
"QuestionBody": "The below code generates a plot and 4PL curve fit, but the fit is poor at lower values. This error can usually be addressed by ading a 1/y^2 weighting, but I dont know how to do it in this instance. Adding sigma=1/Y_data**2 to the fit just makes it worse.\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\n\ndef fourPL(x, A, B, C, D):\n    return ((A-D) / (1.0 + np.power(x / C, B))) + D\n\nX_data = np.array([700,200,44,11,3,0.7,0.2,0])\nY_data = np.array([600000,140000,30000,8000,2100,800,500,60])\n\n\npopt, pcov = curve_fit(fourPL, X_data, Y_data)\n\nfig, ax = plt.subplots()    \nax.scatter(X_data, Y_data, label='Data')\nX_curve = np.linspace(min(X_data[np.nonzero(X_data)]), max(X_data), 5000)\nY_curve = fourPL(X_curve, *popt)\nax.plot(X_curve, Y_curve)\n\nax.set_xscale('log')\nax.set_yscale('log')\n\nplt.show()\n\n\n",
"AnswerId": "76390724",
"AnswerBody": "Don't add inverse square weights; fit in the log domain. Always add bounds. And in this case, curve_fit doesn't do a very good job; consider instead minimize.\nimport numpy as np\nfrom scipy.optimize import curve_fit, minimize\nimport matplotlib.pyplot as plt\n\n\ndef fourPL(x: np.ndarray, a: float, b: float, c: float, d: float) -> np.ndarray:\n    return (a - d)/(1 + (x / c)**b) + d\n\n\ndef estimated(x: np.ndarray, a: float, b: float, c: float, d: float) -> np.ndarray:\n    return np.log(fourPL(x, a, b, c, d))\n\n\ndef sqerror(abcd: np.ndarray) -> float:\n    y = np.log(fourPL(x_data, *abcd)) - np.log(y_data)\n    return y.dot(y)\n\n\nx_data = np.array([700, 200, 44, 11, 3, 0.7, 0.2, 0])\ny_data = np.array([600000, 140000, 30000, 8000, 2100, 800, 500, 60])\nguess = (500, 1.05, 1e6, 1e9)\nbounds = np.array((\n    (1, 0.1, 1, 0),\n    (np.inf, 10, np.inf, np.inf),\n))\n\npopt, _ = curve_fit(\n    f=estimated, xdata=x_data, ydata=np.log(y_data), p0=guess,\n    bounds=bounds,\n)\nprint('popt:', popt)\nresult = minimize(\n    fun=sqerror, x0=guess, bounds=bounds.T, tol=1e-9,\n)\nassert result.success\nprint('minimize x:', result.x)\n\nx_curve = 10**np.linspace(-1, 3, 1000)\n\nfig, ax = plt.subplots()\nax.scatter(x_data, y_data, label='Data')\nax.plot(x_curve, fourPL(x_curve, *popt), label='curve_fit')\nax.plot(x_curve, fourPL(x_curve, *result.x), label='minimize')\nax.plot(x_curve, fourPL(x_curve, *guess), label='guess')\nax.set_xscale('log')\nax.set_yscale('log')\nax.legend()\nplt.show()\n\n\n"
},
{
"QuestionId": "76392252",
"QuestionTitle": "Multithreading with std::future in C++: Accessing shared data",
"QuestionBody": "I am currently developing a multi-threaded application in C++ where different threads are expected to process data from a shared data structure. I'm aware that the standard library provides std::future and std::async to easily handle asynchronous operations, and I'm trying to use these in my application.\nHere's a simplified sketch of my code:\n#include <vector>\n#include <future>\n\nstd::vector<int> shared_data;\n\n// Some function to be executed asynchronously\nvoid process_data(size_t start, size_t end) {\n    for (size_t i = start; i < end; ++i) {\n        // Do something with shared_data[i]\n    }\n}\n\nint main() {\n    std::future<void> fut1 = std::async(std::launch::async, process_data, 0, 10);\n    std::future<void> fut2 = std::async(std::launch::async, process_data, 10, 20);\n\n    // Other operations...\n\n    return 0;\n}\n\nI have the following questions regarding this code:\nSince shared_data is being accessed by multiple threads, do I need to protect it with a std::mutex or other synchronization primitives?\nIs there a way to pass std::future objects to other functions or store them in a data structure, and what would be the potential implications of doing so?\nHow can I handle exceptions thrown by the process_data function and propagated through the std::future objects?\nAny guidance or best practices related to the usage of std::future in multithreaded scenarios would be greatly appreciated.\nIn order to make the shared data access thread-safe, I attempted to introduce an std::mutex and lock it using std::lock_guard in the process_data function like so:\nstd::mutex mtx;\n\nvoid process_data(size_t start, size_t end) {\n    std::lock_guard<std::mutex> lock(mtx);\n    for (size_t i = start; i < end; ++i) {\n        // Do something with shared_data[i]\n    }\n}\n\nI also attempted to store std::future objects in a std::vector for later use, and tried to handle exceptions using a try/catch block around the get() function of std::future.\nI was expecting that locking the std::mutex would ensure that only one thread can access the shared data at a time, preventing race conditions. I also expected that I would be able to easily store the std::future objects in a vector and handle exceptions from the asynchronous tasks.\nHowever, I'm unsure if these methods are the most efficient or even correct, given the lack of detailed examples or guidelines on these topics in the documentation and tutorials I've found. I'm particularly interested in understanding the correct way to use std::future and std::async in more complex scenarios, and how to handle exceptions properly in this context.\n",
"AnswerId": "76392286",
"AnswerBody": "If the data is readonly (and its not too much, just copy it).\nOtherwise make a shared_ptr to your data (and using a lambda expression) you can capture the shared_ptr by value (! not reference!!!) This will extend the lifetime of the data to the lifetime of the thread that uses it longest. So something like this :\nstd::shared_ptr<SharedData> data; auto future = std::async(std::launch::async( [data]{ process_data(data); };\nIf the data is read/write then add a mutex or some other synchronization mechanism to your data class and use getters/setters with lock to update/read the values in the data.\n"
},
{
"QuestionId": "76390268",
"QuestionTitle": "How can I correctly check the type of a Redis key in Lua scripting?",
"QuestionBody": "Correct way to check redis key's type in lua script.\nI'm trying to wrap my head around redis lua scripting and I can't find the correct way to check what type the key has.\nHere is what I've tried:\n127.0.0.1:6379> SET test_key test_value\nOK\n127.0.0.1:6379> GET test_key\n\"test_value\"\n127.0.0.1:6379> EVAL 'local type = redis.call(\"TYPE\", KEYS[1]); return type' 1 test_key\nstring\n\nSo I see that the type = \"string\", but:\n127.0.0.1:6379> EVAL 'local type = redis.call(\"TYPE\", KEYS[1]); local res; if type == string then res = \"ok\" else res = \"not ok\" end return res' 1 test_key\n\"not ok\"\n127.0.0.1:6379> EVAL 'local type = redis.call(\"TYPE\", KEYS[1]); local res; if type == string then res = \"ok\" else res = \"not ok\" end return res' 1 \"test_key\"\n\"not ok\"\n127.0.0.1:6379> EVAL 'local type = redis.call(\"TYPE\", KEYS[1]); local res; if type == \"string\" then res = \"ok\" else res = \"not ok\" end return res' 1 \"test_key\"\n\"not ok\"\n127.0.0.1:6379> EVAL 'local type = redis.call(\"TYPE\", KEYS[1]); local res; if type == \"string\" then res = \"ok\" else res = \"not ok\" end return res' 1 test_key\n\"not ok\"\n\n",
"AnswerId": "76390820",
"AnswerBody": "I've found the answer here: Using the TYPE command inside a Redis / Lua Script\nShort answer is that in lua scripts redis.call(\"TYPE\", key) returns not string but lua table with key \"ok\" which holds string value of the type.\nSo to check the type of the key you should compare like this:\nif redis.call(\"TYPE\", key)[\"ok\"] == \"string\"\n\nfor example:\n127.0.0.1:6379> EVAL 'local type = redis.call(\"TYPE\", KEYS[1])[\"ok\"]; local res; if type == \"string\" then res = \"ok\" else res = \"not ok\" end return res' 1 test_key\n\"ok\"\n\n"
},
{
"QuestionId": "76392221",
"QuestionTitle": "How can I prioritize dimensions in a Redis vector similarity search?",
"QuestionBody": "I am currently using Redis as a vector database and was able to get a similarity search going with 3 dimensions (the dimensions being latitude, longitude, and timestamp). The similarity search is working but I would like to weigh certain dimensions differently when conducting the search. Namely, I would like the similarity search to prioritize the timestamp dimension when conducting the search.\nHow would I go about this? Redis does not seem to have any built-in feature that does this.\nI turn each set of lat, long, and time coordinates into bytes that can be put into the vector database with the following code. Note that vector_dict stores all the sets of lat, long, and timestamp:\np = client.pipeline(transaction=False)\nfor index in data:\n        # create hash key\n        key = keys[index]\n\n        # create hash values\n        item_metadata = data[index] # copy all metadata\n        item_key_vector = np.array(vector_dict[index]).astype(np.float32).tobytes() # convert vector to bytes\n        p.hset(key, mapping=item_metadata) # add item to redis using hash key and metadata\n\nI then conduct the similarity search using the HNSW index here:\ndef create_hnsw_index(redis_conn, vector_field_name, number_of_vectors, vector_dimensions=3, distance_metric='L2', M=100, EF=100):\n    redis_conn.ft().create_index([\n        VectorField(vector_field_name, \"HNSW\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric, \"INITIAL_CAP\": number_of_vectors, \"M\": M, \"EF_CONSTRUCTION\": EF})\n    ])\n\nI talked with others and they said it is a math problem that deals with vector normalization. I'm unsure how to get started with this though in code and would like some guidance.\n",
"AnswerId": "76392309",
"AnswerBody": "You can re-weight the vector to make certain dimensions longer than others. You're using an L2 distance metric. That uses the standard Pythagorean theorem to calculate distance:\ndist = sqrt((x1-x2)**2 + (y1-y2)**2 + (z1-z2)**2)\n\nImagine you multiplied every Y value, in both your query and your database, by 10. That would also multiply the difference between Y values by a factor of 10.\nThe new distance function would effectively be this:\ndist = sqrt((x1-x2)**2 + (10*(y1-y2))**2 + (z1-z2)**2)\n\ndist = sqrt((x1-x2)**2 + 100*(y1-y2)**2 + (z1-z2)**2)\n\n...which makes the Y dimension matter 100 times more than the other dimensions.\nSo if you want the dimension in position 2 to matter more, you could do this:\nitem_key_vector = np.array(vector_dict[index])\nitem_key_vector[2] *= 10\nitem_key_vector_bytes = item_key_vector.astype(np.float32).tobytes()\n\nThe specific amount to multiply by depends on how much you want the timestamp to matter. Remember that you need to multiply your query vector by the same amount.\n"
},
{
"QuestionId": "76388796",
"QuestionTitle": "Why pybind11 can not recognize PyObject* as a Python object and how to fix it?",
"QuestionBody": "I am trying to build a library using this C++ code:\n#include <pybind11/pybind11.h>\n\nnamespace py = pybind11;\n\nPyObject* func() {\n    return Py_BuildValue(\"iii\", 1, 2, 3);\n}\n\nPYBIND11_MODULE(example, m) {\n    m.def(\"func\", &func);\n}\n\nBut when I tried to run this Python 3 code:\nimport example\nprint(example.func())\n\nIt gives me following error:\nTypeError: Unregistered type : _object\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nTypeError: Unable to convert function return value to a Python type! The signature was\n        () -> _object\n\nWhy it is happening and how to fix it?\n",
"AnswerId": "76390832",
"AnswerBody": "So, first off, what are you trying to do with your function? Making a raw python API call (Py_BuildValue, https://docs.python.org/3/c-api/arg.html#c.Py_BuildValue) is strongly discouraged, that is why you are using PyBind11, to handle that for you.\nWhat are you trying to do with this line?\nPy_BuildValue(\"iii\", 1, 2, 3)\n\nIt looks like you are trying to return a tuple of 3 ints. Perhaps something like this would work instead:\npy::tuple func() {\n    return py::make_tuple(1, 2, 3);\n}\n\nWith that said, I think the error is from Python not understanding what a PyObject* is. So you will need to expose the PyObject to Python using a py::class. I'm not sure if that makes sense though, I would need to test this.\nFrom the docs I linked, it looks like Py_BuildValue might return a tuple. In which case I can suggest wrapping the return value in a py::tuple.\n"
},
{
"QuestionId": "76391978",
"QuestionTitle": "How to get time from datetime into a string/number for a colormap",
"QuestionBody": "I'm trying to shade a scatter plot based on time of day, but my data is in datetime format. Getting either time of day or hours past 00:00 would work. I tried to get just the time from datetime, but I got the following error.\n\nTypeError: float() argument must be a string or a number, not 'datetime.time'\n\nIdeally, I'll have a scatterplot shaded based on time of day.\nI initially tried this (also added .values to the end of the dt.time to see if it would help. It didn't).\nx = dfbelow[1:].wind_speed.values\ny = above_aligned[\"WS\"].values\nplt.scatter(x, y, s=20, c=above_aligned[\"timestamp\"].dt.time, cmap='YlOrBr')\n\nplt.xlabel(\"Below Canopy Wind Speed (m/s)\")\nplt.ylabel(\"Above Canopy Wind Speed (m/s)\")\nplt.title(\"Above vs. Below Canopy Wind Speeds (m/s)\")\nplt.colorbar(label=\"Below Canopy Wind Direction\")\nplt.show\n\nBut it understandably can't shade based off of a datetime form.\n",
"AnswerId": "76392317",
"AnswerBody": "I figured it out and it was actually very simple. Instead of above_aligned[\"timestamp\"].dt.time, I just used above_aligned[\"timestamp\"].dt.hour.\n"
},
{
"QuestionId": "76390504",
"QuestionTitle": "AWS ECS Task on private subnet connectivity",
"QuestionBody": "Is it possible to access a public domain e.g. foo.bar.com from an AWS ECS task running on a private subnet? It is convenient for me that the task is running on a private subnet since it can be easily accessible from other ECS tasks running on the same private subnet (same AZ, VPC and region).\nI am reading different contradicting opinions:\n\nSome say that this is not possible and I must configure a NAT Gateway or NAT instance\nOthers say that this is possible as long as you specify the right outbound rules for your security groups. But outbound rules can only be configured using IP ranges and not specific domains.\n\nWhat is actually the case here?\n",
"AnswerId": "76390835",
"AnswerBody": "You have to create a NAT Gateway and add a route in the route table for your subnet. Without a NAT Gateway (or NAT instance, but those are considered obsolete), you cannot connect to the public internet from your private subnets.\n"
},
{
"QuestionId": "76391183",
"QuestionTitle": "compare two PowerShell arrays only if they both contain values",
"QuestionBody": "In the following PowerShell code, functions hour00_numbers and hour01_numbers create two arrays, that contain numbers matching a specific regex.\nfunction hour00_numbers {\n    foreach ($event in $filter00) {\n        $hour00Numbers = @()\n        $hour00Numbers += [regex]::Matches($event.Source.Summary -replace ' ', '9 *[45679]( *[0-9]){6}').Value\n        $hour00Numbers\n    }\n}\n    \nfunction hour01_numbers {\n    foreach ($event in $filter01) {\n        $hour01Numbers = @()\n        $hour01Numbers += [regex]::Matches($event.Source.Summary -replace ' ', '9 *[45679]( *[0-9]){6}').Value\n        $hour01Numbers\n    }\n}\n\nI then check if both arrays are not empty, and if they are not, I check to see if they contain matching numbers.\nfunction matching_numbers01 {\n    if ($null -ne $(hour00_numbers) -and $null -ne $(hour01_numbers)) {\n        $script:matchingNumbers01 = Compare-Object $(hour00_numbers) $(hour01_numbers) -IncludeEqual | Where-Object { $_.SideIndicator -eq '==' } | Select-Object -ExpandProperty InputObject\n    }\n    else {\n        $matchingNumbers01 = $null\n    }\n\n    if ($null -ne $(hour00_numbers)) {\n        Write-Host \"hour00 numbers: $(hour00_numbers)\" -ForegroundColor Green\n    }\n    else {\n        Write-Host \"hour00 is empty\" -ForegroundColor Yellow\n    }\n\n    if ($null -ne $(hour01_numbers)) {\n        Write-Host \"hour01 numbers: $(hour01_numbers)\" -ForegroundColor Green\n    }\n    else {\n        Write-Host \"hour01 is empty\" -ForegroundColor Yellow\n    }\n\n    if ($null -ne $matchingNumbers01) {\n        Write-Host \"matching numbers are: $matchingNumbers01\" -ForegroundColor Yellow\n    }\n    else {\n        Write-Host \"no matching numbers found\" -ForegroundColor Green\n    }\n}\n\nI'm doing something wrong here though, because I will frequently get a message saying\nCannot bind argument to parameter 'ReferenceObject' because it is null\n\nIf either of the two arrays is empty, it shouldn't compare anything. It should only compare the arrays if both are not empty.\nWhat I'm I doing wrong here?\n",
"AnswerId": "76392333",
"AnswerBody": "Aside from the problem you've reported, your code has a few other issues:\n\nUse of global variables to pass values into (and out of) functions - e.g. $filter00, $filter01 and $matchingNumbers01. It's hard to reason about these in isolation because they depend on program state that exists outside their scope.\n\nDuplication of code as a result - e.g. the functions hour00_numbers and hour01_numbers are identical except for which global variable they reference - this makes maintenance harder.\n\nPerformance issues / race condition by repeatedly calling the hour00_numbers and hour01_numbers functions inside matching_numbers01 instead of caching the results into internal variables.\n\n\nSo, here's a refactor that uses function parameters and output streams to address these problems. It also uses some of the feedback in the comments, and it might just accidentally fix your root problem as a side-effect as well...\n# define a function to filter the events, give it a meaningful name, and pass\n# the raw event list as a parameter so we only need one version of the function\nfunction Get-HourEvents {\n    param( $Events )\n    foreach($event in $Events) {\n        [regex]::Matches($event.Source.Summary -replace ' ', '9 *[45679]( *[0-9]){6}').Value\n    }\n}\n\n# pass the filtered events in as parameters '$Left' and '$Right',\n# and return the results in the output stream so we don't need to\n# read global variables. this makes it easier to reason about, and\n# a lot easier to test with frameworks like pester\nfunction Get-MatchingEvents {\n    param( $Left, $Right )\n\n    if ($null -eq $Left) {\n        Write-Host \"Left is empty\" -ForegroundColor Yellow\n    }\n    else {\n        Write-Host \"Left numbers: $Left\" -ForegroundColor Green\n    }\n\n    if ($null -eq $Right) {\n        Write-Host \"Right is empty\" -ForegroundColor Yellow\n    }\n    else {\n        Write-Host \"hour01 numbers: $Right\" -ForegroundColor Green\n    }\n\n    if (($null -eq $Left) -or ($null -eq $Right) {\n        $results = $null\n    }\n    else {\n        $results = Compare-Object $Left $Right -IncludeEqual | Where-Object { $_.SideIndicator -eq '==' } | Select-Object -ExpandProperty InputObject\n    }\n\n    if ($null -eq $results) {\n        Write-Host \"no matching numbers found\" -ForegroundColor Green\n    }\n    else {\n        Write-Host \"matching numbers are: $results\" -ForegroundColor Yellow\n        $results\n    }\n\n}\n\n# use the functions like this:\n\n# get the filtered event lists\n$hour00Events = Get-HourEvents -Events $filter00\n$hour01Events = Get-HourEvents -Events $filter01\n\n# match the event lists and assign the result to a variable\n$matchingNumbers01 = Get-MatchingEvents -Left $hour00Events -Right $hour01Events\n\nI also took the liberty of inverting some of your if( ... -ne ... ) { ... } else { ... } as I find it easier to think about when the else will trigger if the if uses a \"positive\" expression otherwise the else condition becomes a double-negative, but that's just personal style - ymmv.\nIf you're still seeing the same issue with this version of your code feel free to post a comment below...\n"
},
{
"QuestionId": "76388777",
"QuestionTitle": "PHP function file_get_contents($url) returns special characters",
"QuestionBody": "I am trying to retrieve the meta data for a given links (url). I have implemented the following steps:\n$url = \"url is here\";\n$html = file_get_contents($url);\n$crawler = new Crawler($html); // Symfony library\n$description = $crawler->filterXPath(\"//meta[@name='description']\")->extract(['content']);\n\nDoing so, I manage to retrieve the meta data for some urls but not for all.\nSome urls, the file_get_contents($url) function returns special characters like (x1F‹\\x08\\x00\\x00\\x00\\x00\\x00\\x04\\x03ì½}{ãÆ‘/ú÷øSÀœ'\\x1E)! ‘z§¬qlÇI..........) that is why I could not retrieve the meta data.\nNotice that, I am using the same website for $url values but passing different slugs (different blog urls like https://www.example.com/blog-1).\nAttempts:\n\nI used these functions  mb_convert_encoding and mb_detect_encoding\nI made sure all urls I have passed are accessible through the browser.\n\nAny thought, why I am getting special characters when I am calling file_get_contents function, and some time getting correct html format?\n\n",
"AnswerId": "76390883",
"AnswerBody": "I have solved the issue by adding the following parameters to file_get_contents functions:\nprivate const EMBED_URL_APPEND = '?tab=3&object=%s&type=subgroup';\n      \nprivate const EMBED_URL_ENCODE= 'CM_949A11_1534_1603_DAG_DST_50_ÖVRIGT_1_1';\n            \n$urlEncoded= sprintf($url.self::EMBED_URL_APPEND, rawurlencode(self::EMBED_URL_ENCODE));\n            \n$html =  file_get_contents($urlEncoded);\n\n"
},
{
"QuestionId": "76390329",
"QuestionTitle": "Change x or y position of density plot",
"QuestionBody": "I have data plotted as points and would like to add density plots to the graph. The marginal plot solutions from ggExtra or other packages are not giving the freedom that I'd like and so want to generate the density plot at the same time as the ggplot.\ndf = data.frame(x = rnorm(50, mean = 10), \n                y = runif(50, min = 10, max = 20), \n                id = rep(LETTERS[1:5], each = 10))\nggppp = ggplot(data = df, mapping = aes(x, y, color = id)) + \n  geom_point() + theme_bw()\n\nggppp + \n  geom_density(mapping = aes(y = y, \n                             col = id),\n               inherit.aes = FALSE, bounds = c(-Inf, Inf)) +\n  geom_density(mapping = aes(x = x,\n                             col = id),\n               inherit.aes = FALSE, ) \n\n\nIs there a way to move the density plots to other values of x or y position (like moving the density lines to the tip of the arrow in the image below)?\n",
"AnswerId": "76390859",
"AnswerBody": "you can shift the position with position_nudge:\n## using your example objects:\nggppp + \n  geom_density(mapping = aes(y = y , col = id),\n               position = position_nudge(x = 12),\n               inherit.aes = FALSE\n               ) +\n  geom_density(mapping = aes(x = x, col = id),\n               position = position_nudge(y = 20),\n               inherit.aes = FALSE\n)\n\n"
},
{
"QuestionId": "76391826",
"QuestionTitle": "Lambda expression returns parent method",
"QuestionBody": "I'm trying to create a Snackbar in my Android Java application. It has an action, displayed as Cancel, that should stop (or return) the parent method.\nI tried this:\nsnackbar.setAction(\"Cancel\", v -> { return; });\n\nBut Android Studio told me that\n\n'return' is unnecessary as the last statement in a 'void' method\n\nshowing me that this was returning from the lambda expression, not it's parent method.\nI also tried super.return;, but that caused a whole lot of errors.\n",
"AnswerId": "76392344",
"AnswerBody": "NB: This answer applies generally to UI frameworks/java, not android in particular.\nWhat you want to do here makes fundamentally no sense.\nThe setAction method is telling the snackbar object: Hey, whenever the \"Cancel\" event occurs, run this code. Don't run it now, run it later. Maybe a year later, when the user bothers to click that cancel button, when this method is long gone - this method where I am informing you what to do when the user clicks that Cancel button, NOT actually doing the act that must be done when the user clicks that, maybe they never click it, after all!\nHence, 'return from this method' is fundamentally nonsensical. How? That method's probably already done ages ago.\nAfter telling the object referred to by the snackbar variable what to do when the user presses cancel (which is a near instant operation, of course, and requires no user interaction or anything else that would take more than nanoseconds), this method will keep going.\nIt sounds like you are a bit confused about how to set up these actions.\nTaking a bit of a guess on how this works, there are in broad strokes two obvious things you might do:\nHave a dialog with OK and Cancel buttons\nNothing should happen until a user clicks one of the two buttons. Once they do, it happens and they can no longer stop that short of hard-killing your app or force-shutting down the phone.\nIn this case, you should have one call to .setAction(\"Cancel\", ...) and one call to .setAction(\"OK\", ....) and that's that. The cancel button just needs to dismiss the dialog and do nothing else.\nHave a dialog with perhaps a progress bar and a cancel button\nAs in, the act occurs right now but will take a while, and you want to offer the user a button to tell your application to abort what it is doing. The dialog is explaining (via a progress bar, spinner, or simply with text) that the act is occurring now and whatever that act may be (say, send an email), once it is done, this dialog dismisses itself (and it is at that point no longer possible to cancel it; possibly it can be undone, but that'd be a separate UI action).\nIn this case: You can't just 'kill' a thread mid-stride in java. After all, just hard-killing one process of an app can (and often will) leave stuff in undefined state. Create some concurrency-capable mechanism (in basis, reading the same field from 2 different threads is just broken, because CPUs are mostly self-contained units and forcing them to communicate every change across all cores means there is pretty much no point to multiple cores in the first place, hence, software does not guarantee that writes to a field are seen by other threads unless you explicitly spell it out). Then use that to communicate to the running code that it should abort. that code should then dismiss the dialog.\nThe general process for the 'cancel' action code is:\n\nDisable the button, both actually (it should no longer invoke the cancel handler), and visually (so the user knows their click is now being handled).\nSet the concurrency capable flag. Might take the form of interrupting a thread, or setting some AtomicBoolean.\nthat's it. Do nothing else. Leave the dialog up as normal.\n\nThe code that does the slow thing (say, sending mail) should:\n\nSet up a system that listens to that flag to abort as soon as it can. How to do this is tricky and depends on what, precisely, you are doing.\nOnce it sees that flag being up / catches InterruptedException, aborts the act, undoes whatever half-work it has done if it can, and it dismisses the dialog entirely. This then lets the user know the act of aborting it has succeeded.\n\n"
},
{
"QuestionId": "76380894",
"QuestionTitle": "FullCalendar in GWT : How to refresh calendar while keeping events",
"QuestionBody": "I'm working on a GWT application using Domino/UI, Nalukit and the Javascript plugin FullCalendar v6.\nI made a custom popup to modify and delete an event but when I validate the form, my calendar refreshes and all the event in my week view disappear.\nDemo of the app running\nI used the native function gotoDate to change to view of the calendar to the event's modified date.\nHere's a sample from my controller's render and refreshCalendar methods :\n    @Override\n    public void render() {\n\n        // Styling related lines omitted\n\n        FcOptionOverrides mainOptions = new FcOptionOverrides();\n        mainOptions.locale = \"fr\";\n        mainOptions.initialView = \"timeGridWeek\";\n        mainOptions.views = new FcViewOptions();\n        mainOptions.views.timeGridWeek = new FcView();\n        mainOptions.views.timeGridWeek.weekends = true;\n        mainOptions.views.timeGridWeek.slotMinTime = \"07:00:00\";\n        mainOptions.views.timeGridWeek.slotMaxTime = \"22:00:00\";\n        mainOptions.eventSources = new FcEventSources();\n        mainOptions.eventSources.events = this.getController()::onEventNeedMain;\n        mainOptions.datesSet = this::onDatesSet;\n        \n        mainOptions.eventDidMount = this::onEventDidMount;\n        mainOptions.dateClick = this::onBigCalendarDateClick;\n\n        mainCalendar = new FcCalendar(mainAgendaContainer, mainOptions);\n\n        FcOptionOverrides smallOptions = new FcOptionOverrides();\n        smallOptions.locale = \"fr\";\n        smallOptions.initialView = \"dayGridMonth\";\n        smallOptions.height = \"330px\";\n        smallOptions.aspectRatio = 1.0f;\n        smallOptions.eventSources = new FcEventSources();\n        smallOptions.eventSources.events = this.getController()::onEventNeedSmall;\n\n        smallOptions.dateClick = this::onSmallCalendarDateClick;\n\n        smallCalendar = new FcCalendar(smallAgendaContainer, smallOptions);\n\n        // radio button for displaying week-ends\n        RayflexRadio displayWeekendRadio = new RayflexRadio(\"weekends\", \"Week-ends\", \"Afficher\", \"Masquer\");\n        displayWeekendRadio.style(\"position:absolute; top:18px; right:230px;\");\n        displayWeekendRadio.addChangeHandler(event -> {\n\n            if (displayWeekendRadio.getValue()) {\n\n                DominoElement.of(mainAgendaContainer).removeCss(RxResource.INSTANCE.gss().calendar_main_no_weekends());\n                DominoElement.of(mainAgendaContainer).css(RxResource.INSTANCE.gss().calendar_main());\n\n            } else {\n\n                DominoElement.of(mainAgendaContainer).removeCss(RxResource.INSTANCE.gss().calendar_main());\n                DominoElement.of(mainAgendaContainer).css(RxResource.INSTANCE.gss().calendar_main_no_weekends());\n\n            }\n            displayWeekEnds = displayWeekendRadio.getValue();\n            refreshCalendar();\n\n        });\n\n        displayWeekendRadio.setValue(displayWeekEnds);\n\n        card.getBody().appendChild(displayWeekendRadio.element());\n\n        initElement(card.element());\n    }\n\n @Override\n    public void refreshCalendar() {\n\n        if (lastModifiedEvent != null) {\n            \n            Date beginDate = lastModifiedEvent.getBeginDate();\n            JsDate jsDate = new JsDate(1900 + beginDate.getYear(), beginDate.getMonth(), beginDate.getDate());\n\n            mainCalendar.gotoDate(jsDate);\n            smallCalendar.gotoDate(jsDate);\n        }\n        \n        mainCalendar.refetchEvents();\n    }\n\nHere's my wrapper class for FullCalendar's JS functions :\npackage com.alara.rayflex.ui.client.calendar;\n\nimport elemental2.core.JsDate;\nimport elemental2.dom.Element;\nimport jsinterop.annotations.JsType;\n\n@JsType(isNative = true, namespace = \"FullCalendar\", name=\"Calendar\")\npublic class FcCalendar {\n\n    public FcCalendar(Element root) {}\n    \n    public FcCalendar(Element root, FcOptionOverrides optionOverrides) {}\n    \n    public native void render();\n    public native void updateSize();\n    \n    public native void gotoDate(JsDate start);\n    public native JsDate getDate();\n    \n    public native void setOption(String name, String value);\n    public native void setOption(String name, int value);\n    \n    public native void select(JsDate date);\n    \n    public native void refetchEvents();\n    \n    public native void addEventSource(FcOnEventNeed needEvent);\n    \n    public native void changeView(String viewName, JsDate dateOrRange);\n}\n\n\nI tried to force the native javascript functions refetchEvents with gotoDate but I got the same result. Then I tried using addEventSource to restore my events but still no success there.\nI'm expecting to rerender my calendar with the events of the week which the event has been modified.\n",
"AnswerId": "76391234",
"AnswerBody": "Solved my issue by loading the events in a callback and refetching them in my refreshCalendar method :\n@Override\npublic void refreshCalendar() {\n\n    if (lastModifiedEvent != null)\n        \n        moveToLastEventModifiedDate();\n\n    else\n    \n        mainCalendar.refetchEvents();         \n}\n\n/**\n * Use the last modified event to move the calendar to its begin date\n * then fetch the events to load them again in the calendar component \n */\npublic void moveToLastEventModifiedDate() {\n    \n    Date eventDate = lastModifiedEvent.getBeginDate();\n    JsDate jsEventDate = new JsDate(1900 + eventDate.getYear(), eventDate.getMonth(), eventDate.getDate());\n    \n    Date previousMonday = DateUtils.getPreviousMonday(eventDate);\n    Date nextMonday = DateUtils.getNextMonday(eventDate);\n\n    JsDate jsDateBegin = new JsDate(1900 + previousMonday.getYear(), previousMonday.getMonth(), previousMonday.getDate());\n    JsDate jsDateEnd = new JsDate(1900 + nextMonday.getYear(), nextMonday.getMonth(), nextMonday.getDate());\n\n    mainCalendar.gotoDate(jsEventDate);\n    smallCalendar.select(jsEventDate);\n\n    FcEventFetchInfo info = new FcEventFetchInfo();\n    info.start = jsDateBegin;\n    info.end = jsDateEnd;\n    \n    this.getController().onEventNeedMain(info, success -> {\n        mainCalendar.setOption(\"events\", fcOnEventNeed);\n        mainCalendar.refetchEvents();\n        \n    }, failure -> {\n        \n        ErrorManager.displayServerError(\"event.list\", failure.message, getController().getEventBus());\n    });\n\n    lastModifiedEvent = null;\n}\n\n"
},
{
"QuestionId": "76390427",
"QuestionTitle": "Can SymPy Lambdify translate core functions like Add and Mul?",
"QuestionBody": "My goal is to evaluate a basic symbolic equation such as ad(b + c) with my own custom implementaions of multiply and addition.\nI'm trying to use lambdify to translate the two core SymPy functions (Add and Mul) with my own functions, but I cant get them recognised.\nAt this stage I'm just trying to get Add working. The code I have is below.\nfrom sympy import *\nimport numpy as np\nx, y = symbols('x y')\nA = [1,1]\nB = [2,2]\n\ndef addVectors(inA, inB):\n    print(\"running addVectors\")\n    return np.add(inA, inB)\n\n# Test vector addition\nprint(addVectors(A,B))\n\n# Now using lambdify\nf = lambdify([x, y], x + y, {\"add\":addVectors})\nprint(f(A, B)) # <------- expect [3,3] and addVectors to be run a second time\n\n# but I get the same as this\nprint(A + B)\n\nwhich yields\nrunning addVectors\n[3 3]\n[1, 1, 2, 2]\n[1, 1, 2, 2]\n\nI was expecting the + operator in the expression to be evaluated using the custom addVectors function. Which would mean the results looks like this.\nrunning addVectors\n[3 3]\nrunning addVectors\n[3 3]\n[1, 1, 2, 2]\n\nI tried several different configurations of the lambdify line and these all give the same original result.\nf = lambdify([x, y], x + y, {\"add\":addVectors})\nf = lambdify([x, y], x + y, {\"Add\":addVectors})\nf = lambdify([x, y], x + y, {\"+\":addVectors})\nf = lambdify([x, y], Add(x,y), {\"Add\":addVectors})\nf = lambdify([x, y], x + y)\n\nTo confirm I have the syntax correct I used an example closer to the documentation and replaced the symbolic cos function with a sin implementation.\nfrom sympy import *\nimport numpy as np\nx = symbols('x')\n    \ndef mysin(x):\n    print('taking the sin of', x)\n    return np.sin(x)\n\nprint(mysin(1))\n\nf = lambdify(x, cos(x), {'cos': mysin})\nf(1)\n\nwhich works as expected and yields\ntaking the sin of 1\n0.8414709848078965\ntaking the sin of 1\n0.8414709848078965\n\nIs it even possible to implement my own Add and Mul functions using lambdify?\nI suspect my trouble is Add (and Mul) are not SymPy 'functions'. The documentation refers to them as an 'expression' and that somehow means they dont get recognised for substitution in the lambdify process.\nSome links that I've been reading:\nSymPy cos\nSymPy Add\nSymPy Lambdify\nAny pointers would be appreciated. Thanks for reading this far.\nEDIT: Got a more general case working\nThis uses a combination of the lambdify and replace functions to replace Add and Mul. This example then evaluates an expression in the form ad(b + c), which was the goal.\nfrom sympy import *\nimport numpy as np\n \nw, x, y, z = symbols('w x y z')\nA = [3,3]\nB = [2,2]\nC = [1,1]\nD = [4,4]\n \ndef addVectors(*args):\n    result = args[0]\n    for arg in args[1:]:\n        result = np.add(result, arg)\n    return result\n \ndef mulVectors(*args):\n    result = args[0]\n    for arg in args[1:]:\n        result = np.multiply(result, arg)\n    return result\n \nexpr = w*z*(x + y)\nprint(expr)\nexpr = expr.replace(Add, lambda *args: lerchphi(*args))\nexpr = expr.replace(Mul, lambda *args: Max(*args))\nprint(expr)\n \nf = lambdify([w, x, y, z], expr, {\"lerchphi\":addVectors, \"Max\":mulVectors})\nprint(f(A, B, C, D))\n \nprint(mulVectors(A,D,addVectors(B,C)))\n\nwhich yields\nw*z*(x + y)\nMax(w, z, lerchphi(x, y))\n[36 36]\n[36 36]\n\nA few things to note with this solution:\n\nUsing the replace function you can replace a type with a function (type -> func). See the docs.\nThe function I replace the types with have to accept multiple inputs because each type in the expression may have more than two arguments (like multiply in the example above). I only found 3 functions that accept *args as an input. These were Min, Max and lerchphi.\nSymPy simplifies Min and Max functions since Max(x, Min(x, y)) = x. That meant I couldn't use Min and Max together. So I used lerchphi and Max. These functions are arbitary as I'll be translating their implementation to a custom function in the next step. However, this means I can only replace two.\nFinal step was to translate lerchphi and Max to the custom functions.\n\n",
"AnswerId": "76390861",
"AnswerBody": "With sympy, addition is an operation. Hence, I'm not sure if it's possible to achieve your goal by passing in custom modules...\nHowever, at the heart of lambdify there is the printing module. Essentially, lambdify uses some printer to generate a string representation of the expression to be evaluated. If you look at lambdify's signature, you'll see that it's possible to pass a custom printer.\nGiven a printer class, the addition with + is performed by the _print_Add method. One way to achieve your goal is to modify this method of the NumPyPrinter.\nfrom sympy.printing.lambdarepr import NumPyPrinter\nimport inspect\n\nclass MyNumPyPrinter(NumPyPrinter):\n    def _print_Add(self, expr, **kwargs):\n        str_args = [self.doprint(t) for t in expr.args]\n        return \"add(*[%s])\" % \", \".join(str_args)\n\nf = lambdify([x, y], x + y, printer=MyNumPyPrinter)\nprint(inspect.getsource(f))\n# def _lambdifygenerated(x, y):\n#    return add(*[x, y])\n\nprint(f(A, B))\n# [3 3]\n\nNote that I've no idea what implication this might creates. That's for you to find out...\n"
},
{
"QuestionId": "76388602",
"QuestionTitle": "Why am I unable to retrieve a Xero item by identifier with a valid access token from Postman?",
"QuestionBody": "xero developer api not authorizing\ni generated the access_token from the endpoint postman screen shot for access token when i try to get xero item i am getting screen shot for item end point this endpoint should give the item with identifier 96d14376-4b75-4b4a-8fd3-b1caab075ab3 in the response also when i try this one in xero api explorer after login its working fine\n",
"AnswerId": "76391241",
"AnswerBody": "Looking at the logs relating to the instance id in the error screen shot, the\naccess token does not include the accounting.settings scope.\nPlease can you go through the OAuth 2.0 process from the very beginning, making sure the scope is in the authorisation call.\nWhen you add a new scope to a call you need to go through the whole authorisation process from scratch to update the access token.\nWhen you get a new access token you can decode it to check the scopes before you use it to make sure that you have the scopes you need. You can use jwt.io to check this if you wish\n"
},
{
"QuestionId": "76388769",
"QuestionTitle": "Call Different Method in reactive pipeline",
"QuestionBody": "I have a use case where I have to call two different methods in a reactive pipeline Java 8 on a post-API call.\n1st Method:\nwill insert data in a master table and will return the pk of that table insertion.\n2nd Method:\nthis method will insert data in the mapping table which will use the pk received from 1st method.\nI try to do that Mono.zip, but that did not work as Zip is calling both methods simultaneously and is not able to pass method 1 output to 2nd method input.\n",
"AnswerId": "76391245",
"AnswerBody": "You can easily do it using the map or flatMap operator, depending on what type of repository you have - reactive or not reactive.\nHere is examples for both cases:\npublic class YourService {\n    private final YourRepository repository;\n    private final YourReactiveRepository reactiveRepository;\n\n    void doAction() {\n        Mono.fromCallable(() -> repository.saveToMainTable(\"main data\"))\n            .map(mainTableId -> repository.saveToSecondaryTable(mainTableId, \"secondary data\"))\n            .subscribeOn(Schedulers.boundedElastic())\n            .subscribe();\n    }\n\n    void doActionWithReactiveRepository() {\n        reactiveRepository.saveToMainTable(\"main data\")\n            .flatMap(mainTableId -> reactiveRepository.saveToSecondaryTable(mainTableId, \"secondary data\"))\n            .subscribe();\n    }\n\n    interface YourRepository {\n        int saveToMainTable(String someData);\n        boolean saveToSecondaryTable(int mainTableId, String someData);\n    }\n\n    interface YourReactiveRepository {\n        Mono<Integer> saveToMainTable(String someData);\n        Mono<Boolean> saveToSecondaryTable(int mainTableId, String someData);\n    }\n}\n\nYou can read more about map here and about flatMap here\n"
},
{
"QuestionId": "76384653",
"QuestionTitle": "Sort pandas dataframe columns on second row order",
"QuestionBody": "I need to sort a dataframe based on the order of the second row.  For example:\nimport pandas as pd\n\ndata = {'1a': ['C', 3, 1], '2b': ['B', 2, 3], '3c': ['A', 5, 2]}\ndf = pd.DataFrame(data)\ndf\n\nOutput:\n  1a 2b 3c\n0  C  B  A\n1  3  2  5\n2  1  3  2\n\nDesired output:\n  3c 2b 1a\n0  A  B  C\n1  5  2  3\n2  2  3  1\n\nSo the columns have been order based on the zero index row, on the A, B, C.\nHave tried many sorting options without success.\nHaving a quick way to accomplish this would be beneficial, but having granular control to both order the elements and move a specific column to the first position would be even better.  For example move \"C\" to the first column.\nSomething like make a list, sort, move and reorder on list.\nmylist = ['B', 'A', 'C']\nmylist.sort()\nmylist.insert(0, mylist.pop(mylist.index('C')))\n\nThen sorting the dataframe on ['C', 'A', 'B'] outputting\n  1a 3c 2b\n0  C  A  B\n1  3  5  2\n2  1  2  3\n\n",
"AnswerId": "76390867",
"AnswerBody": "With the help of pyjedy and Stingher, I was able to resolve this issue. One of the problems was due to my input. The input consisted of lists instead of dictionaries, so I needed to transform it. As a result, I had indexes for rows and across the top for columns. Consequently, selecting elements from the list required obtaining the index.\nimport pandas as pd\n\ndef search_list_for_pattern(lst, pattern):\n    for idx, item in enumerate(lst):\n        if pattern in item:\n            break\n    return idx\n\ndata = [['1a', 'B', 2, 3], ['2b', 'C', 3, 1], ['3c', 'A', 5, 2]]\ndf = pd.DataFrame(data).transpose()\nprint(df)\n\n#     0   1   2\n# 0  1a  2b  3c\n# 1   B   C   A\n# 2   2   3   5\n# 3   3   1   2\n\n# Get the second row and convert it to a list\nsecond_row = df.iloc[1, :].tolist()\nprint(second_row)\n\n# ['B', 'C', 'A']\n\n# Find the index of the column you want to move to the first position\ntarget_column = search_list_for_pattern(second_row, \"C\")\nprint(target_column)\n\n# 1\n\n# Sort the list\nsorted_columns = sorted(range(len(second_row)), key=lambda k: second_row[k])\nprint(sorted_columns)\n\n# [2, 0, 1]\n\n# Move the target column to the first position\nsorted_columns.remove(df.columns.get_loc(target_column))\nsorted_columns.insert(0, df.columns.get_loc(target_column))\n\n# Reorder the columns of the DataFrame based on the sorted list\ndf = df.iloc[:, sorted_columns]\nprint(df)\n\n#     1   2   0\n# 0  2b  3c  1a\n# 1   C   A   B\n# 2   3   5   2\n# 3   1   2   3\n\ndf.to_excel('ordered.xlsx', sheet_name='Sheet1', index=False, header=False)\n\n\n"
},
{
"QuestionId": "76392302",
"QuestionTitle": "Combine list of lists of tuples with different lengths",
"QuestionBody": "I'm having a problem to combine list of lists of tuples, and the main problem comes from different sizes of those tuples. I'm also trying to do it \"pythonic\" way, which isn't very easy.\nWhat I actually have is a list of objects, having coordinates given in tuple.\nObjects (let's say: lines) always have start and end as (x1,y1) and (x2,y2), they also usually have some \"path\". The problem is that \"path\" is sometimes empty and in general number of points on the path is different.\nstart=[ (3,5), (23,50), (5,12), (51,33), (43,1)]\nend = [(23,19), (7,2), (34,4),  (8,30), (20,10)]\npath=[[(10,7),(14,9),(18,15)],\n      [],\n      [(15,7)],\n      [(42,32),(20,31)],\n      [(30,7)]]\n\nExpected result should look like this:\nwhole_path = [[(3,5),(10,7),(14,9),(18,15),(23,19)],\n              [(23,50),(7,2)],\n              [(5,12),(15,7),(34,4)],\n              [(51,33),(42,32),(20,31),(8,30)],\n              [(43,1),(30,7),(20,10)]]\n\nI was trying to use zip - it works well for similar size items in start/end/paths lists but not with their differences.\nPromising solutions might come with use path.insert(0,start) and path.extend([end]), but I couldn't make that working, there is also an option to put that into two loops, but it doesn't look well and... it's not very \"pythonic\".\nSo: any suggestions would be nice.\n",
"AnswerId": "76392348",
"AnswerBody": "A solution with zip and *-unpacking of the variable-length path element is reasonably clean:\nfrom pprint import pprint\n\nstart=[ (3,5), (23,50), (5,12), (51,33), (43,1)]\nend = [(23,19), (7,2), (34,4),  (8,30), (20,10)]\npath=[[(10,7),(14,9),(18,15)],\n      [],\n      [(15,7)],\n      [(42,32),(20,31)],\n      [(30,7)]]\n\nwhole_path = [[s, *p, e] for s, p, e in zip(start, path, end)]\npprint(whole_path)\n\ngiving the required:\n[[(3, 5), (10, 7), (14, 9), (18, 15), (23, 19)],\n [(23, 50), (7, 2)],\n [(5, 12), (15, 7), (34, 4)],\n [(51, 33), (42, 32), (20, 31), (8, 30)],\n [(43, 1), (30, 7), (20, 10)]]\n\n"
},
{
"QuestionId": "76382247",
"QuestionTitle": "Blade: anonymous component doesn't show when passing data",
"QuestionBody": "I'm new to Blade and tried to use anonymous components for sections that I will use frequently.\nThe problem is that when I'm trying to pass down data to the component, it won't show anything.\nHere is my Code:\nController:\npublic function edit(Workingtime $workingtime)\n    {\n      $user = User::find(Auth::id());\n      $workingtime_array = $user->getWorkingtimesOfThisDay($workingtime->id);\n            \n      return view('workingtime-edit', compact('workingtime_array', 'workingtime'));     \n    }\n\nworkingtime-edit.blade.php:\n<p>Overview of Workingtimes</p>\n\n@if(count($workingtime_array) > 0)\n    <x-workingtime-timeline :workingtimeArray = \"$workingtime_array\"/>\n@endif\n\n\nworkingtime-timeline.blade.php (component):\n@props(['workingtimeArray']) \n\n@php\n\n    if(isset($workingtimeArray) AND count ($workingtimeArray) > 0){\n        $start = strtotime($workingtimeArray[0]->time_begin);\n        $end = strtotime($workingtimeArray[count($workingtimeArray)-1]->time_end);\n    } \n\n@endphp\n\n@foreach ($workingtimeArray as $worktime)\n\n    <p>Start: {{ $worktime->time_begin }} </p>\n    <p>End: {{ $worktime->time_end }} </p>\n\n@endforeach;\n\nWhen I don't use variables and @props, it shows me the content of the component.\nI tried to change the <x-workingtime-timeline :workingtimeArray = \"$workingtime_array\"/> line but nothing worked.\nThings I tried:\n<x-workingtime-timeline :workingtimeArray = \"$workingtime_array\"> </x-workingtime-timeline>\n<x-workingtime-timeline workingtimeArray = \"$workingtime_array\"/>\n",
"AnswerId": "76392356",
"AnswerBody": "In workingtime-edit.blade.php you need to remove the spaces around the = for the attribute you are setting:\n<x-workingtime-timeline :workingtimeArray=\"$workingtime_array\"/>\n\nI think this is a limitation of Laravel's parsing of component attributes, since this is not a general requirement of HTML attributes.\n"
},
{
"QuestionId": "76388523",
"QuestionTitle": "How can I prevent existing categories from disappearing when I add a new category to an email item using Exchange Web Services in C#?",
"QuestionBody": "I am trying to add a new category to an email item using Exchange WEB Services but when I run the code, existing categories disappear and the category I added becomes the only category.\nFor example an email has categories X and Y and after I add my category Z to this mail item, X and Y disappears and only category for the mail becomes Z\nAny help is much appreciated.\nThanks in advance\nPlease note that I am running this code inside a software called Blue Prism a low code no code scripting software and it is near impossible to implement third party libraries etc due to corporate chain of approvals and stuff\nWhen I do it manually on the outlook 2019 it works the way I intended\nHere is the method I am using\nThe DLL That uses this code is Microsoft.Exchange.WebServices.dll\n//Here I initialize exchange object and authenticate\nExchangeService exchange = null;\n\nvoid ConnectEWS(string ewsURL, string _exchangeVersion, string username, string password)\n{\n    ServicePointManager.ServerCertificateValidationCallback = delegate {return true;} ;\n    try\n    {\n        exchange                = new ExchangeService();\n        exchange.Url            = new Uri(ewsURL);\n        exchange.Credentials    = new WebCredentials(username,password);\n    }\n    catch (Exception ex)\n    {\n        throw new Exception(\"failed to initialize exchange object!!=\"+ex.Message);\n    }   \n}\n//here is my void method that adds a new category to an email item\nvoid addCategoryToMail(string msgid, string category)\n{\n    if(exchange==null)\n    {\n        throw new Exception(\"exchange object is null!!\");\n    }   \n    EmailMessage message = EmailMessage.Bind(exchange,msgid, BasePropertySet.IdOnly );\n    if(message.Categories.Contains(category)==false)\n    {\n        message.Categories.Add(category);\n        //message.Update(ConflictResolutionMode.AlwaysOverwrite);\n        message.Update(ConflictResolutionMode.AutoResolve);\n    }\n}\n\n",
"AnswerId": "76391330",
"AnswerBody": "The line\nEmailMessage message = EmailMessage.Bind(exchange,msgid, BasePropertySet.IdOnly );\n\nonly requests the message id. You need to request categories. See if BasePropertySet.FirstClassProperties brings categories in. If not, explicitly request categories.\n"
},
{
"QuestionId": "76389988",
"QuestionTitle": "npm run does not work as expected on a docker container",
"QuestionBody": "I'm building a react app with vite and I'm deploying it with docker.\nWhen deploying the container, npm run build runs but does nothing, even doing it inside the container manually won't work.\nI get this output but the actual build does not happen:\n$ npm run build\n\n> frontend@0.0.0 build\n> tsc && vite build\n\n$\n\nThing is if I run tsc && vite build it works just fine.\nSame goes with npm run dev or any other script.\nHere's more info:\n\nTried with both Node Alpine and Debian (I'm actively developing in Alpine).\nTried creating the Node user and setting permissions accordingly since I read that npm might behave weird if ran by the root user.\n\n$ npm config get ignore-scripts\nfalse\n\n\n\nThese are my docker files\nFROM node:20-bullseye\nWORKDIR /app/frontend/\nCOPY package.json package-lock.json* /app/frontend/\nRUN npm install\nRUN npm install -g vite\nRUN npm install -g typescript\n\nCOPY . .\nRUN chown -R node:node /app/frontend/\n\nUSER node\n\nCMD [\"npm\", \"run\", \"build\"]\n\ndocker-compose.yaml:\nversion: \"3.4\"\nname: fisy-prod\nservices:\n  backend:\n    volumes:\n      - static:/static\n    env_file:\n      - ./.env\n    build:\n      context: ./backend\n      dockerfile: Dockerfile.prod\n    ports:\n      - \"8000:8000\"\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile.prod\n    volumes:\n      - frontend:/app/frontend/dist\n  nginx:\n    build:\n      context: ./nginx\n    volumes:\n      - static:/static\n      - frontend:/var/www/frontend\n    ports:\n      - \"5173:80\"\n    depends_on:\n      - backend\n      - frontend\nvolumes:\n  static:\n  frontend:\n\nI scouted the web all morning without really finding anything that might point to the issue. Would appreciate it if someone that has experienced this could help.\n",
"AnswerId": "76390898",
"AnswerBody": "Your Compose file has volumes: blocks that replace all of the image content with content from named volumes.  This apparently works the first time you run the container, since Docker copies content from the image into an empty volume; but if you rebuild your application, the volume will not get updated, and the old content in the volume will replace your image content.\nOne important part of this problem is that your frontend container doesn't really do anything.  Its CMD is to build the application, but that will immediately exit.  This doesn't need to be a long-running container and it doesn't need to be listed in your Compose file.\nWhat I'd do here is to use a multi-stage build to compile the frontend, then COPY all of the content into an Nginx-based image.  For example:\nFROM node:20-bullseye AS frontend\nWORKDIR /app/frontend/\n# Note, run with the project root as the build context\nCOPY frontend/package.json frontend/package-lock.json ./\n...\nRUN npm run build\n\nFROM nginx:1.25\nCOPY nginx/default.conf.tmpl /etc/nginx/default.conf.tmpl\nCOPY backend/static/ /static/\nCOPY --from=frontend /app/frontend/dist/ /var/www/frontend/\n\nNow the final image contains all of the pieces you need, so you don't need to try to share files between containers; that means you can remove all of the volumes:.  The final image build also encapsulates the front-end build, so you don't need a separate frontend build-only container.  This leaves you with a Compose file\nversion: \"3.8\"\nservices:\n  backend:\n    env_file:\n      - ./.env\n    build:\n      context: ./backend\n      dockerfile: Dockerfile.prod\n    ports:\n      - \"8000:8000\"\n  nginx:\n    build:\n      context: .  # needed to COPY files from subdirectories\n      dockerfile: nginx/Dockerfile\n    ports:\n      - \"5173:80\"\n    depends_on:\n      - backend\n\n"
},
{
"QuestionId": "76387981",
"QuestionTitle": "How to read and translate a filename.z.json file",
"QuestionBody": "My file has a .z.json-extension and can be found here.\nThe content of the file is\n\"7ZQ7a8MwFIX/i2Yn3IekK3nv3EIztCkdQslgSpySuFPwf6+USMZZbiGzFyODPs7RuY+LeTmeu6E79qb9uJhNd9ifh93hx7SGgHgFbkVhg7Z10kJcB+YAIFvTmKd+OHX7s2kvBvPnddgNv+nXPPeb0+7rO115M+1KPGFj3vMJbTptTeuAx8aQAnkrcIMi51OGMENWg4TjDQrRuwJRghBUqTBJoZ9T2qu8g6IVyVOhJFOaw5QF1SwYZlmg18OoWkw4dxgUipArVJSszalrWQgGW/yJDUUJM6VmIVCoCBhmxSK1xN75SoU7inWt0k1RarXoSqmdYf2UYOCi5TMlao1j1UKZ584P9bvVHbrq8NpZk0PnVIdUe5dcHROXKK9nyK7Oyd1wiZqG5ykNmlNBn5PaUSnDML1rHJt/dg3CGoTFW1p2zbJrll2z7JrHd83n+Ac=\"\n\nApparently, the most common type of file that contains the .z-file extension is compressed Unix files.\nHow do I translate / uncompress this file to its human-understandable version? I have no additional information.\n",
"AnswerId": "76391438",
"AnswerBody": "That is Base-64 encoded raw deflate data. You need to decode the Base-64 to binary, and then use zlib to inflate it. The result is 2278 bytes of json.\n"
},
{
"QuestionId": "76391843",
"QuestionTitle": "Cast pandas series containing list elements to a 2d numpy array",
"QuestionBody": "Take the following series:\nimport pandas as pd\n\ns = pd.Series([1, 3, 2, [1, 3, 7, 8], [6, 6, 10, 4], 5])\n\nI want to convert this series into the following array:\nnp.array([\n    [ 1.,  1.,  1.,  1.],\n    [ 3.,  3.,  3.,  3.],\n    [ 2.,  2.,  2.,  2.],\n    [ 1.,  3.,  7.,  8.],\n    [ 6.,  6., 10.,  4.],\n    [ 5.,  5.,  5.,  5.]\n])\n\nCurrently, I am using this logic:\nimport numpy as np\nimport pandas as pd\nfrom itertools import zip_longest\n\n# Convert series and each element in series into list\nls = list(map(lambda v: v if isinstance(v, list) else [v], s.to_list()))\n# Cast list elements to 2d numpy array with longest list element as column number\na = np.array(list(zip_longest(*ls, fillvalue=np.nan))).T\n# Convert to DataFrame, apply 'ffill' row-wise and re-convert to numpy array\na = pd.DataFrame(a).fillna(method=\"ffill\", axis=1).values\n\nMy solution is not really satisfying me, especially the last line where I convert my array to a DataFrame and then back to an array again. Does anyone know a better alternative? You can assume that all list elements have the same length.\n",
"AnswerId": "76392387",
"AnswerBody": "Assuming all list elements have the same length (as indicated), what about using masks and numpy.repeat?\ns2 = pd.to_numeric(s, errors='coerce')\nm = s2.isna()\n\nout = np.repeat(s2.to_numpy()[:, None], 4, axis=1)\nout[m] = np.array(s[m].tolist())\n\nOutput:\narray([[ 1,  1,  1,  1],\n       [ 3,  3,  3,  3],\n       [ 2,  2,  2,  2],\n       [ 1,  3,  7,  8],\n       [ 6,  6, 10,  4],\n       [ 5,  5,  5,  5]])\n\n"
},
{
"QuestionId": "76385124",
"QuestionTitle": "ONNX performance compared to sklearn",
"QuestionBody": "I have converted a sklearn logistic regression model object to an ONNX model object and noticed that ONNX scoring takes significantly longer to score compared to the sklearn.predict() method. I feel like I must be doing something wrong b/c ONNX is billed as an optimized prediction solution. I notice that the difference is more noticeable with larger data sets so I created X_large_dataset as as proxy.\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport datetime\nfrom sklearn.linear_model import LogisticRegression\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\nimport numpy as np\nimport onnxruntime as rt\n\n# create training data\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# fit model to logistic regression\nclr = LogisticRegression()\nclr.fit(X_train, y_train)\n\n# convert to onnx format\ninitial_type = [('float_input', FloatTensorType([None, 4]))]\nonx = convert_sklearn(clr, initial_types=initial_type)\nwith open(\"logreg_iris.onnx\", \"wb\") as f:\n    f.write(onx.SerializeToString())\n    \n# create inference session from onnx object\nsess = rt.InferenceSession(\n    \"logreg_iris.onnx\", providers=rt.get_available_providers())\ninput_name = sess.get_inputs()[0].name\n\n# create a larger dataset as a proxy for large batch processing\nX_large_dataset = np.array([[1, 2, 3, 4]]*10_000_000)\nstart = datetime.datetime.now()\npred_onx = sess.run(None, {input_name: X_large_dataset.astype(np.float32)})[0]\nend = datetime.datetime.now()\nprint(\"onnx scoring time:\", end - start)\n\n# compare to scoring directly with model object\nstart = datetime.datetime.now()\npred_sk = clr.predict(X_large_dataset)\nend = datetime.datetime.now()\nprint(\"sklearn scoring time:\", end - start)\n\nThis code snippet on my machine shows that sklearn predict runs in less than a second and ONNX runs in 18 seconds.\n",
"AnswerId": "76390930",
"AnswerBody": "Simply converting a model to ONNX does not mean that it will automatically have a better performance. During conversion, ONNX tries to optimize the computational graph for example by removing calculations which do not contribute to the output, or by fusing separate layers into a single operator. For a generic neural network consisting of convolution, normalization and nonlinearity layers, these optimizations often result in a higher throughput and better performance.\nSo considering you are exporting just LogisticRegression, most likely both sklearn and the corresponding onnx implementations are already very optimized and the conversion will not lead to any performance gain.\nAs to why the InferenceSession.run is 20x slower than sklearn.predict\n\nX_large_dataset is a np.int64 array over 300 MB in size. Casting it with astype when creating the input dictionary inside of run creates a new 150 MB array to which everything is copied. This obviously shouldn't be counted towards the model execution time.\nonnxruntime has quite a bit of memory management overhead when executing models with dynamic inputs for the first time. Subsequent calls to run with inputs of the same shape should finish a lot faster.\n\n"
},
{
"QuestionId": "76392330",
"QuestionTitle": "How can I make sure a SQL record's column doesn't refer to its own primary key?",
"QuestionBody": "I have a Node table with a ParentID column, which refers to a NodeID that is its parent. I want to make sure no Node can refers to itself (i.e. a Node's ParentID cannot its own NodeID), so I tried adding a check constraint CHECK(NodeID != ParentID).\nHowever, I got this error: Error Code: 3818. Check constraint 'node_chk_1' cannot refer to an auto-increment column.\nI also couldn't add the ParentID as a foreign key of Node.\nUsing MySQL, How can I make sure that there are no new records where NodeID = ParentID?\n",
"AnswerId": "76392389",
"AnswerBody": "Use a trigger:\nmysql> create table node ( \n  id int auto_increment primary key, \n  parentid int, \n  foreign key (parentid) references node (id)\n);\n\nmysql> delimiter ;;\n\nmysql> create trigger no_self_ref after insert on node for each row begin\nif NEW.parentid = NEW.id then\n  signal sqlstate '45000' message_text = 'no self-referencing hierarchies';\nend if;\nend;;\n\nmysql> delimiter ;\n\nNote that it must be an AFTER trigger, because the auto-increment id has not yet been generated in a BEFORE trigger.\nDemo:\nmysql> insert into node values (1, null);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> insert into node values (2, 2);\nERROR 1644 (45000): no self-referencing hierarchies\n\nmysql> insert into node values (2, 1);\nQuery OK, 1 row affected (0.01 sec)\n\nYou will also need a similar AFTER UPDATE trigger, if you want to prevent users from updating the row and setting the parentid to the same value as the id in the same row.\n\nAn alternative solution would be to make the primary key non-auto-increment. You will have to specify every id value in your INSERT statements, instead of letting them be auto-incremented. But this will allow you to use a CHECK constraint.\n"
},
{
"QuestionId": "76380833",
"QuestionTitle": "Android PhotoPicker returns NULL URI",
"QuestionBody": "ActivityResultLauncher<PickVisualMediaRequest> pickImage = registerForActivityResult(new ActivityResultContracts.PickVisualMedia(), uri -> {\n\n        if(uri==null) {\n            //URI always NULL here\n        } else {\n            //Never reached\n        }\n\n\n    });\n\npickImage.launch(new PickVisualMediaRequest.Builder()\n                        .setMediaType(ActivityResultContracts.PickVisualMedia.ImageOnly.INSTANCE)\n                        .build());\n\n\nI have tried the same code in a new project and it is returning a valid URI. But PhotoPicker returns a NULL URI in my project. Any idea what could be the issue here?\n",
"AnswerId": "76391584",
"AnswerBody": "Apparently, PhotoPicker (or ActivityResultLauncher in general) fails if onActivityResult() is also Overridden in the Activity. I removed that and now PhotoPicker is returning a valid URI.\n"
},
{
"QuestionId": "76384047",
"QuestionTitle": "host not found in upstream with nginx docker compose",
"QuestionBody": "I know this question has been asked many times however, none of the solutions have worked for me.\nI am trying to dockerize my angular app and node js backend using nginx.\nWhat I have done is that I have created a docker-compose file.\nIt has three services and nginx.\n1: space-frontend\n2: space-api\n3: mongodb\nI am calling frontend and backend by their service name in nginx conf file like http://space-frontend:80 and http://space-api:3000 but I am getting a error in logs\n\n[emerg] 1#1: host not found in upstream \"space-api\" in /etc/nginx/nginx.conf:23\n\nand frontend is working fine.\nI am unable to understand where I am missing something.\nFor reference,\nMy frontend docker file\nFROM node:16-alpine AS builder\nWORKDIR /app\nCOPY . .\nRUN npm i && npm run build --prod\nFROM nginx:alpine\nRUN mkdir /app\nCOPY --from=builder /app/dist/Space-Locator/browser /app\nCOPY nginx.conf /etc/nginx/nginx.conf\n\nMy frontend nginx conf\nevents {\nworker_connections 1024;\n}\nhttp {\ninclude /etc/nginx/mime.types;\n\nserver {\nlisten       80;\nserver_name  localhost;\nroot /app;\n\nlocation / {\n    index  index.html;\n    try_files $uri $uri/ /index.html;\n}\n\nerror_page   500 502 503 504  /50x.html;\nlocation = /50x.html {\n    root   /usr/share/nginx/html;\n}\n}\n}\n\nBackend api docker file\nFROM node:14-alpine as build-step\nRUN mkdir -p /usr/app\nWORKDIR /usr/app\nCOPY package.*json /usr/app/\nRUN npm install\nCOPY . /usr/app/\nEXPOSE 3000\nCMD [ \"npm\", \"start\" ]\n\nmy docker-compose file\n    version: \"3.8\"\nservices:\n  reverse_proxy:\n    image: nginx:1.17.10\n    container_name: reverse_proxy\n    depends_on:\n      - space-frontend\n      - space-api\n      - database\n    volumes:\n      - ./reverse_proxy/nginx.conf:/etc/nginx/nginx.conf  \n    ports:\n      - 80:80\n  space-frontend:\n    container_name: space-frontend\n    image: space-frontend\n    build: \n      context: ./space-frontend\n    ports:\n      - 4000:80\n  space-api:\n    container_name: space-api\n    hostname: space-api\n    image: space-api\n    build: \n      context: ./space-api\n    ports:\n      - 3000:3000\n    links:\n      - database  \n    environment:\n      MONGO_INITDB_DATABASE: spaceLocator \n      MONGODB_URI: mongodb://db:27017\n    depends_on:\n      - database\n    volumes:\n      - ./db-data/mongo/:/data/database\n    networks:\n      - node-network\n  database:\n    container_name: db\n    image: mongo\n    restart: on-failure\n    ports:\n      - 27017:27017\n    volumes:\n      - ./mongodb:/data/database\n    networks:\n      - node-network  \nvolumes:\n  dbdata6:\nnetworks:\n  node-network:\n    external: true\n    driver: bridge  \n\nand my nginx.conf file for reverse proxy\n   events {\n    worker_connections 1024;\n}\nhttp {\n\n  server {\n        listen 80;\n        server_name  127.0.0.1;\n\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n        \n        location ~* \\.(eot|ttf|woff|woff2)$ {\n        add_header Access-Control-Allow-Origin *;\n        }\n\n        location / {\n          proxy_pass http://space-frontend:80;\n          proxy_set_header X-Forwarded-For $remote_addr;\n        }\n\n        location /api {\n            proxy_pass http://space-api:3000;\n            proxy_set_header X-Forwarded-For $remote_addr;\n        }\n    }\n}\n\nCan somebody please point to the direction where I am doing wrong?\nI have tried adding hostname but they are as same as container-name.\n",
"AnswerId": "76390948",
"AnswerBody": "So guys problem was that we have to run every container on same network.\n  networks:\n\n  - node-network  \n\nI had to define this in my every service. Then it ran without any problem.\nThank you for everyone who helped :)\n"
},
{
"QuestionId": "76389362",
"QuestionTitle": "How can I update the master Username and password of and existing AWS RDS cluster using the serverless-framework?",
"QuestionBody": "Can't update username of existing RDS cluster\nUpdating the masterUsername and masterUserPassword in the serverless.yml file for my postgresql database results in the password being updated but not the username.\ni.e. I can only access the db with the old username and new password.\nI am using the serverless framework to manage aws assests.\nIt's an RDS cluster.\nEverything builds successfully and I can access the data (using the old username).\nWaiting for over 30 minutes doesn't have an effect.\n",
"AnswerId": "76390959",
"AnswerBody": "I understand you want to update the MasterUsername property on an existing RDS instance that you created with Serverless Framework.\nServerless Framework uses AWS CloudFormation. According to the AWS CF docs, the MasterUsername property cannot be updated on an existing RDS instance. Any attempt will result in a resource replacement.\nIf you still want to update the MasterUsername, your only option is to destroy the RDS instance and create a new one.\n"
},
{
"QuestionId": "76392138",
"QuestionTitle": "How do I modify a font and save it with Rust 'write-fonts'?",
"QuestionBody": "I would like to open a font file and modify eg the usWeightClass and save it in a different location – using Rust: https://github.com/googlefonts/fontations\nI am already able to load a file, read data from the font, but I am not able to modify and save it.\nI expect, that it should work somehow with WriteFont (but I don't know how):\nhttps://docs.rs/write-fonts/0.5.0/write_fonts/trait.FontWrite.html#\nAny help would be much appreciated.\nThanks a lot in advance,\nOlli\nCargo.toml\n[dependencies]\nwrite-fonts = \"0.5.0\"\nread-fonts = \"0.3.0\"\nfont-types = \"0.1.8\"\n\nmain.rs\nuse read_fonts::{FontRef, TableProvider};\n\nfn main() {\n    pub static FONT_DATA: &[u8] = include_bytes!(\"/path/to/a/font/somefont.ttf\");\n    let font = FontRef::new(FONT_DATA).unwrap();\n\n    let mut os2 = font.os2().expect(\"missing OS/2 table\");\n    println!(\"os2.version: {}\", os2.version());\n    println!(\"os2.us_weight_class: {}\", os2.us_weight_class());\n\n    let mut name = font.name().expect(\"missing name table\");\n\n    for item in name.name_record() {\n        println!(\"name_id: {:?}\", item.name_id);\n        println!(\"language_id: {:?}\", item.language_id);\n        let data = item.string(name.string_data()).unwrap();\n        println!(\"String entry: {:?}\", data.chars().collect::<String>());\n    };\n}\n\n",
"AnswerId": "76392427",
"AnswerBody": "I haven't worked with this library or with fonts in general yet, but after a little digging in the documentation, this seems to work:\nuse read_fonts::{FontRead, FontRef, TableProvider, TopLevelTable};\nuse write_fonts::{dump_table, tables::os2::Os2, FontBuilder};\n\nfn main() {\n    {\n        let font_data = std::fs::read(\"Roboto-Regular.ttf\").unwrap();\n        let font = FontRef::new(&font_data).unwrap();\n\n        let os2 = font.os2().expect(\"missing OS/2 table\");\n        println!(\"os2.us_weight_class: {}\", os2.us_weight_class());\n\n        // Create a new font builder\n        let mut builder = FontBuilder::default();\n\n        // Iterate over tables and add them to the builder\n        for table in font.table_directory.table_records() {\n            let tag = table.tag();\n\n            println!(\"    Adding table {tag} ...\");\n\n            let font_data = font\n                .table_data(tag)\n                .expect(&format!(\"Table {tag} not found!\"));\n\n            let mut raw_data = font_data.as_ref().to_owned();\n\n            // Modify the OS2 tag\n            if tag == Os2::TAG {\n                let mut os2 = Os2::read(font_data).unwrap();\n                os2.us_weight_class = 420;\n                raw_data = dump_table(&os2).unwrap();\n            }\n\n            builder.add_table(tag, raw_data);\n        }\n\n        // Build the font\n        let data = builder.build();\n        std::fs::write(\"Roboto-Regular-modified.ttf\", data).unwrap();\n    }\n\n    {\n        // Load the font again and check if it got modified\n        let font_data = std::fs::read(\"Roboto-Regular-modified.ttf\").unwrap();\n        let font = FontRef::new(&font_data).unwrap();\n\n        let os2 = font.os2().expect(\"missing OS/2 table\");\n        println!(\"os2.us_weight_class: {}\", os2.us_weight_class());\n    }\n}\n\nos2.us_weight_class: 400\n    Adding table GDEF ...\n    Adding table GPOS ...\n    Adding table GSUB ...\n    Adding table OS/2 ...\n    Adding table cmap ...\n    Adding table cvt  ...\n    Adding table fpgm ...\n    Adding table gasp ...\n    Adding table glyf ...\n    Adding table hdmx ...\n    Adding table head ...\n    Adding table hhea ...\n    Adding table hmtx ...\n    Adding table loca ...\n    Adding table maxp ...\n    Adding table name ...\n    Adding table post ...\n    Adding table prep ...\nos2.us_weight_class: 420\n\n"
},
{
"QuestionId": "76392283",
"QuestionTitle": "List comprehension in Python for if, elif, pass?",
"QuestionBody": "I see syntax for if pass but not finding syntax for if elif pass: List comprehension with else pass\nBasically\nif condition:\n    something\nelif condition\n    something\nelse\n    pass\n\n",
"AnswerId": "76392432",
"AnswerBody": "Use an if at the end of the list comprehension (a filter) in order to completely exclude an item from the list.  For example, if you wanted to do this as a list comprehension:\nresult = []\nfor i in range(10):\n    if i % 2:\n        result.append(\"two\")\n    elif i % 3:\n        result.append(\"three\")\n    else:\n        pass  # note that you do not actually need this \"else\" at all\n\nyou could do:\nresult = [\"two\" if i % 2 else \"three\" for i in range(10) if i % 2 or i % 3]\n\n"
},
{
"QuestionId": "76390270",
"QuestionTitle": "how do temporarily turn of vs-code error highlighting",
"QuestionBody": "VS Code error hi-lighting can offer quite a bit of clutter during code edits with its squiggles and colorization. It is a useful horn but once the problem is noticed it can become a nuisance that even makes it difficult to perceive the text and fix the problem. I don't think this feature was intended to get in the way.\nIs there a convenient way to toggle VSCode error hi-lighting on and off without going through settings.json and playing with a bunch of flags?\nConclusion...\n\nFeature does not exist.\n\nWork around is to install and use the When_File VSCode extension to mask the error noise with less visible colors when the file has unsaved edits, as clarified below.\n\n\n",
"AnswerId": "76391014",
"AnswerBody": "you can use the extension When File\nAdd this setting to your workspace settings.json\n  \"whenFile.change\": {\n    \"byLanguageId\": {\n      \"rust\": {\n        \"whenDirty\": {\n          \"editorError.foreground\": \"#ff000020\",\n          \"editorWarning.foreground\": \"#ff000020\",\n          \"editorInfo.foreground\": \"#ff000020\"\n        }\n      }\n    }\n  }\n\n"
},
{
"QuestionId": "76388820",
"QuestionTitle": "How can the ASP.NET built-in DI read dependencies from a file at runtime?",
"QuestionBody": "As you can see in C# Unity container, we can configure a container (a list of dependency and object creation policy) from a file, and it is very good when, I want change a dependency (backend for interface) in the runtime environment without need to upload my project again, or in a dockerise paradigm, I do not need to build the Docker image again.\nAt now, I want to migrate to the ASP.NET 6 built-in DI, How can I provide the same functionality in the built-in DI?\nFor example, something like\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<configuration>\n  <configSections>\n    <section name=\"unity\" type=\"Microsoft.Practices.Unity.Configuration.UnityConfigurationSection, Unity.Configuration\"/>\n  </configSections>\n  <unity xmlns=\"http://schemas.microsoft.com/practices/2010/unity\">\n    <alias alias=\"IProductService\" type=\"UnityExample.Service.IProductService, UnityExample.Service\" />\n    <containers>\n      <container name=\"Service\">\n        <register type=\"IProductService\" mapTo=\"ProductService\"/>\n      </container>\n    </containers>\n  </unity>\n</configuration>\n\n",
"AnswerId": "76391781",
"AnswerBody": "While you could have a hard time making the new service provider compatible with Unity, consider switching to Autofac. Autofac can replace the builtin .NET Core's container  and also it supports loading configuration from a file.\n"
},
{
"QuestionId": "76392223",
"QuestionTitle": "How can I XOR wchar_t input, write it to a file, and read it back in C?",
"QuestionBody": "I have problem working with unicode strings, wchar_t type.\nIn my program I'm getting input as wchar_t and I'm supposed to XOR it and write it to file and read it back and print it to command line.\nThis is my code,\nconst unsigned int XORKey = 0xff;\n\n\n\nsize_t XORit(const wchar_t* value, wchar_t* xorred)\n{\n    size_t length = wcslen(value);\n    for (int i = 0; i < length; i++)\n        xorred[i] = ((char)(value[i] ^ XORKey));\n\n    return length;\n}\n\n\nint main()\n{\n    setlocale(LC_ALL, \"en_US.UTF-8\");\n    // XOR it\n    wchar_t sample[] = { L\"TEST1自己人\" };\n    int samplelen = wcslen(sample);\n    printf(\"%ls\", sample);\n    printf(\"\\n\");\n\n    printf(\"Plain:\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%02X \", sample[i]);\n    }\n    printf(\"\\n\");\n\n\n\n    wchar_t* xorred = (wchar_t*)malloc(samplelen);\n    if (xorred == NULL) return -1;\n    memset(xorred, 0, samplelen);\n    XORit(sample, xorred);\n    printf(\"XOR'ed\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%02X \", xorred[i]);\n    }\n    printf(\"\\n\");\n\n    // Write to file\n    FILE* fpW = _wfopen(L\"logon.bin\", L\"wb\");\n    fwrite(xorred, sizeof(wchar_t), samplelen, fpW);\n    fclose(fpW);\n\n\n    // Read from file\n    FILE* fpR = fopen(\"logon.bin\", \"rb\");\n    fseek(fpR, 0, SEEK_END);\n    int filesize = ftell(fpR);\n    wchar_t* unxorred = (wchar_t*)malloc(filesize + sizeof(wchar_t));\n    if (unxorred == NULL) return -1;\n\n    rewind(fpR);\n\n    fread(unxorred, sizeof(wchar_t), filesize, fpW);\n    fclose(fpW);\n\n    printf(\"Reading\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%02X \", unxorred[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"Un-XOR'ed\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%02X \", unxorred[i] ^ XORKey);\n    }\n    printf(\"\\n\");\n    printf(\"%ls\", unxorred);\n\n    return 0;\n}\n\nThe values I'm reading back from the file doesn't match to what I wrote! :(\nI'm new to C programming, I did my best to get this right, please forgive any noob mistakes in my understanding of the issue and implementing it.\nThanks in advance\nI fixed the code based on the comments,\nconst unsigned int XORKey = 0xff;\n\n\n\nsize_t XORit(const wchar_t* value, wchar_t* xorred)\n{\n    size_t length = wcslen(value);\n    for (int i = 0; i < length; i++)\n        xorred[i] = (value[i] ^ XORKey);\n\n    return length;\n}\n\n\nint main()\n{\n    setlocale(LC_ALL, \"en_US.UTF-8\");\n    // XOR it\n    wchar_t sample[] = { L\"Test1自己人自己人A\" };\n    int samplelen = wcslen(sample);\n    printf(\"%ls\", sample);\n    printf(\"\\n\");\n\n    printf(\"Plain:\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%0*X \", (int)sizeof(wchar_t), (unsigned int)sample[i]);\n    }\n    printf(\"\\n\");\n\n\n\n    wchar_t* xorred = (wchar_t*)malloc(samplelen);\n    if (xorred == NULL) return -1;\n    memset(xorred, 0, samplelen);\n    XORit(sample, xorred);\n    printf(\"XOR'ed\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%0*X \", (int)sizeof(wchar_t), (unsigned int)xorred[i]);\n    }\n    printf(\"\\n\");\n\n    // Write to file\n    FILE* fpW = _wfopen(L\"logon.bin\", L\"wb\");\n    fwrite(xorred, sizeof(wchar_t), samplelen, fpW);\n    fclose(fpW);\n\n\n    // Read from file\n    FILE* fpR = fopen(\"logon.bin\", \"rb\");\n    fseek(fpR, 0, SEEK_END);\n    int filesize = ftell(fpR);\n    int whattoread = (filesize / sizeof(wchar_t));\n    wchar_t* ReadXOR = (wchar_t*)malloc(filesize + 1);\n    if (ReadXOR == NULL) return -1;\n    memset(ReadXOR, 0, filesize + 1);\n\n    rewind(fpR);\n\n    fread(ReadXOR, sizeof(wchar_t), whattoread, fpR);\n    fclose(fpW);\n\n    printf(\"Reading\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%0*X \", (int)sizeof(wchar_t), (unsigned int)ReadXOR[i]);\n    }\n    printf(\"\\n\");\n\n\n    wchar_t* unxorred = (wchar_t*)malloc(whattoread);\n    if (unxorred == NULL) return -1;\n    memset(unxorred, 0, whattoread);\n    printf(\"Un-XOR'ed\\n\\t\");\n    for (int i = 0; i < whattoread; i++)\n    {\n        unxorred[i] = ReadXOR[i] ^ 0xff;\n        printf(\"%0*X \", (int)sizeof(wchar_t), (unsigned int)unxorred[i]);\n    }\n    printf(\"\\n\");\n    printf(\"%ls\\n\", unxorred);\n    printf(\"%ls\\n\", sample);\n    \n\n    return 0;\n\nThe output looks like below,\nTest1自己人自己人A\nPlain:\n        54 65 73 74 31 81EA 5DF1 4EBA 81EA 5DF1 4EBA 41\nXOR'ed\n        AB 9A 8C 8B CE 8115 5D0E 4E45 8115 5D0E 4E45 BE\nReading\n        AB 9A 8C 8B CE 8115 5D0E 4E45 8115 5D0E 4E45 BE\nUn-XOR'ed\n        54 65 73 74 31 81EA 5DF1 4EBA 81EA 5DF1 4EBA 41\nTest1自己人自己人A粘蹊?言?萉?\nTest1自己人自己人A\n\nWhen I modified the unicode string I got wrong text in the output!\n",
"AnswerId": "76392509",
"AnswerBody": "Here ...\n    printf(\"Un-XOR'ed\\n\\t\");\n    for (int i = 0; i < samplelen; i++)\n    {\n        printf(\"%02X \", unxorred[i] ^ XORKey);\n    }\n    printf(\"\\n\");\n\n... you print out the decoded values without storing them.\nWhen you then ...\n    printf(\"%ls\", unxorred);\n\n... you are printing the data as read back from the file, not the decoded string corresponding to the previously-printed code sequence.\nAdditionally,\n\nhere ...\n    int filesize = ftell(fpR);\n    wchar_t* unxorred = (wchar_t*)malloc(filesize);\n    if (unxorred == NULL) return -1;\n\n    rewind(fpR);\n\n    fread(unxorred, sizeof(wchar_t), filesize, fpW);\n\n... you are attempting to read back sizeof(wchar_t) * filesize bytes from the file, which is more than it actually contains or that you have allocated for (unless sizeof(wchar_t) is 1, which is possible, but unlikely, and is anyway not your case).\n\nYou do not allocate space for a (wide) string terminator or add one to the read-back data, yet you pass it to printf() is if it were a wide string.  This is erroneous.\n\nYour approach to printing out the bytes of the wide strings is flawed.  The conversion specifier X requires a corresponding unsigned int argument, and wchar_t might neither be the same as unsigned int nor promote to unsigned int via the default argument promotions.  Additionally, you get varying-length outputs because your wchar_t is at least 16 bits wide, and your 02 only guarantees 2 hex digits.  Better would be, for example:\nfor (int i = 0; i < samplelen; i++) {\n    printf(\"%0*X \", (int) sizeof(wchar_t), (unsigned int) xorred[i]);\n}\n\nThe * for a width says that the minimum field width will be passed as an argument of type int.  The casts match the arguments to the types required by the format.\n\n\n"
},
{
"QuestionId": "76390597",
"QuestionTitle": "What's the idiomatic way to add a calculated column to multiple data frames?",
"QuestionBody": "I have a few dataframes, let's call them rates, sensors with \"session_start\", \"value_timestamp\" (timestamps) and \"value\" (float) columns. I want to add an \"elapsed\" column, which I've done successfully using the following code:\ndef add_elapsed_min(df):\n  df[\"elapsed\"] = (\n    df[\"value_timestamp\"] - df[\"session_start\"].min()\n  ).dt.total_seconds() / 60.0\n\nfor df in [rates, sensors]:\n  add_elapsed_min(df)\n\nNow, this code does work, and the elapsed column is correct. The minor problem is that I keep getting the SettingWithCopyWarning. I've tried changing the code as suggested by the warning, tried adding a contextlib.suppress, but can't seem to remove this warning. This makes me think I must be breaking some idiomatic way to do this. So I'm wondering: If you want to add a calculated column to many dataframes at once, how are you supposed to do this?\n",
"AnswerId": "76391091",
"AnswerBody": "Although I cannot create your warning in Pandas 1.5.3 and considering using .loc does not suppress the warning for you, one other option is to use df.insert instead.\ndef add_elapsed_min(df):\n  elapsed = (df[\"value_timestamp\"] - df[\"session_start\"].min()) / 60.0\n  df.insert(df.shape[1], 'elapsed', elapsed)\n\nfor df in [rates, sensors]:\n  add_elapsed_min(df)\n\n"
},
{
"QuestionId": "76388425",
"QuestionTitle": "Javascript plugin and environment variables",
"QuestionBody": "I was reading the documentation here https://developer.shopware.com/docs/guides/plugins/plugins/storefront/add-custom-javascript but cannot find a mention on how to make usage of environment variables in a  javascript plugin.\nCurrently I tried to put a .env file at the root of my plugin in custom/apps/MyPlugin/.env and to capture them via process.env but it fallbacks to my default values...\nIs there a way to handle a .env file when you run bash bin/build-storefront.sh?\nThanks.\n",
"AnswerId": "76392087",
"AnswerBody": "Here's one way to do it...\nFirst create a custom webpack.config.js at src/Resources/app/storefront/build. Also in that build directory run npm install dotenv, as you will need it to parse your .env file.\nYour webpack.config.js could then look like this:\nconst fs = require('fs');\nconst dotenv = require(`${__dirname}/node_modules/dotenv/lib/main.js`);\n\nmodule.exports = () => {\n    // given you `.env` is located directly in your plugin root dir\n    const contents = fs.readFileSync(`${__dirname}/../../../../../.env`);\n    const config = dotenv.parse(contents);\n\n    return {\n        externals: {\n            myPluginEnv: JSON.stringify(config),\n        }\n    };\n};\n\nThen inside your sources you can import myPluginEnv.\nimport * as myPluginEnv from 'myPluginEnv';\n\n/*\n * Example .env content:\n * FOO=1\n * BAR=1\n */\n\nconsole.log(myPluginEnv);\n// {FOO: '1', BAR: '1'}\n\n"
},
{
"QuestionId": "76388652",
"QuestionTitle": "Different scales for PyQtGraph chart axis in PyQt5",
"QuestionBody": "I have an interface on PyQt5, in which, by pressing the Start button, a graph is built, which I made using PyQtGraph. Three lines are drawn on the chart. Green and blue have a y-axis range of 0 to 200, while red has a range of 0 to 0.5. How can I make different scales for different lines, as well as designate two value scales on the Y-axis - from 0 to 200 and from 0 to 0.5?\n\nfrom pyqtgraph import PlotWidget\nimport pyqtgraph\nfrom PyQt5 import QtCore\nfrom PyQt5.QtCore import Qt, QThread, QTimer, QObject, pyqtSignal, QTimer\nfrom PyQt5.QtWidgets import QHBoxLayout, QMainWindow,  QPushButton, QVBoxLayout, QWidget, QApplication\nimport sys\nimport random\nimport numpy as np\n\n\ndef get_kl_test():\n    choices = [50, 50, 50, 51, 51, 51, 52, 52, 52]\n    list = [random.choice(choices) for i in range(11)]\n    return list\n\n\ndef get_iopd_test():\n    choices = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n    return random.choice(choices)\n\n\nclass Graph(PlotWidget):\n    def __init__(self):\n        super().__init__()\n        self.setBackground('white')\n        self.addLegend()\n        self.showGrid(x=True, y=True)\n        self.setYRange(0, 255, padding=0)\n\n\nclass ReadingWorker(QObject):\n    update_graph = pyqtSignal(list, list, list, list)\n\n    def __init__(self):\n        super().__init__()\n        self.time_from_start = 0\n        self.time_values = []\n        self.green_values = []\n        self.blue_values = []\n        self.red_values = []\n\n    def run(self):\n        self.read()\n        self.update_time()\n\n    def read(self):\n        ipd_values = get_kl_test()\n        iopd_value = get_iopd_test()\n\n        self.green_values.append(ipd_values[0])\n        self.blue_values.append(ipd_values[1])\n        self.red_values.append(iopd_value)\n        self.time_values.append(self.time_from_start)\n\n        self.update_graph.emit(\n            self.green_values, self.blue_values, self.red_values, self.time_values)\n        QTimer.singleShot(1000, self.read)\n\n    def update_time(self):\n        self.time_from_start += 1\n        QTimer.singleShot(1000, self.update_time)\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n        self.central_widget = QWidget(self)\n        self.setGeometry(50, 50, 1300, 700)\n        self.setCentralWidget(self.central_widget)\n        self.layout_main_window = QVBoxLayout()\n        self.central_widget.setLayout(self.layout_main_window)\n\n        self.layout_toolbar = QHBoxLayout()\n        self.layout_toolbar.addStretch(1)\n        self.btn_start = QPushButton(\"Старт\")\n        self.btn_start.clicked.connect(self.start)\n        self.layout_toolbar.addWidget(self.btn_start)\n        self.layout_main_window.addLayout(self.layout_toolbar)\n\n        self.graph = Graph()\n        self.layout_main_window.addWidget(self.graph)\n\n        self.setup_graphs()\n        self.window_size = 50\n\n    def start(self):\n        self.reading_thread = QThread(parent=self)\n        self.reading_widget = ReadingWorker()\n        self.reading_widget.moveToThread(self.reading_thread)\n        self.reading_widget.update_graph.connect(self.draw_graph)\n        self.reading_thread.started.connect(self.reading_widget.run)\n        self.reading_thread.start()\n\n    def setup_graphs(self):\n        pen_ipd_1 = pyqtgraph.mkPen(color='green', width=4)\n        pen_ipd_2 = pyqtgraph.mkPen(color='blue', width=4, style=Qt.DashDotLine)\n        pen_iopd = pyqtgraph.mkPen(color='red', width=4, style=Qt.DashLine)\n        self.line_ipd_1 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_1, name='1')\n        self.line_ipd_2 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_2, name='2')\n        self.line_iopd = pyqtgraph.PlotCurveItem([], [], pen=pen_iopd, name='3')\n        self.graph.plotItem.addItem(self.line_ipd_1)\n        self.graph.plotItem.addItem(self.line_ipd_2)\n        self.graph.plotItem.addItem(self.line_iopd)\n\n    @QtCore.pyqtSlot(list, list, list, list)\n    def draw_graph(self, ipd_1_values, ipd_2_values, iopd_values, time_values):\n        x, y = self.line_ipd_1.getData()\n        x = np.append(x, time_values[-1])\n        self.line_ipd_1.setData(y=np.append(y, ipd_1_values[-1]), x=x)\n        _, y = self.line_ipd_2.getData()\n        self.line_ipd_2.setData(y=np.append(y, ipd_2_values[-1]), x=x)\n        _, y = self.line_iopd.getData()\n        self.line_iopd.setData(y=np.append(y, iopd_values[-1]), x=x)\n        if (len(x) > 0 and x[-1] -x [0] > self.window_size):\n            self.graph.plotItem.setXRange(x[-1]-self.window_size, x[-1])\n\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    app.setStyle('Fusion')\n    main_window = MainWindow()\n    main_window.show()\n    sys.exit(app.exec_())\n\n\n",
"AnswerId": "76392101",
"AnswerBody": "Check out the MultiplePlotAxes.py example.\nTo add another axis on the right change the setup_graphs function and add update_views:\n    def setup_graphs(self):\n        pen_ipd_1 = pyqtgraph.mkPen(color='green', width=4)\n        pen_ipd_2 = pyqtgraph.mkPen(color='blue', width=4, style=Qt.DashDotLine)\n        pen_iopd = pyqtgraph.mkPen(color='red', width=4, style=Qt.DashLine)\n        self.line_ipd_1 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_1, name='1')\n        self.line_ipd_2 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_2, name='2')\n        self.line_iopd = pyqtgraph.PlotCurveItem([], [], pen=pen_iopd, name='3')\n        self.graph.plotItem.addItem(self.line_ipd_1)\n        self.graph.plotItem.addItem(self.line_ipd_2)\n\n        self.vb = pyqtgraph.ViewBox()\n        self.pi = self.graph.plotItem\n        self.pi.showAxis('right')\n        self.pi.scene().addItem(self.vb)\n        self.pi.getAxis('right').linkToView(self.vb)\n        self.vb.setXLink(self.pi)\n\n        self.update_views()\n        self.pi.vb.sigResized.connect(self.update_views)\n        self.vb.addItem(self.line_iopd)\n\n        self.pi.setYRange(0,200)\n        self.vb.setYRange(0,0.5)\n        self.graph.plotItem.legend.addItem(self.line_iopd, self.line_iopd.name())\n\n    def update_views(self):\n        self.vb.setGeometry(self.pi.vb.sceneBoundingRect())\n        self.vb.linkedViewChanged(self.pi.vb, self.vb.XAxis)\n\nResult:\n\nEdit to simulatiously scale both y-axes (there might also be something build in, padding is really annoing here):\n    def setup_graphs(self):\n        pen_ipd_1 = pyqtgraph.mkPen(color='green', width=4)\n        pen_ipd_2 = pyqtgraph.mkPen(color='blue', width=4, style=Qt.DashDotLine)\n        pen_iopd = pyqtgraph.mkPen(color='red', width=4, style=Qt.DashLine)\n        self.line_ipd_1 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_1, name='1')\n        self.line_ipd_2 = pyqtgraph.PlotCurveItem([], [], pen=pen_ipd_2, name='2')\n        self.line_iopd = pyqtgraph.PlotCurveItem([], [], pen=pen_iopd, name='3')\n        self.graph.plotItem.addItem(self.line_ipd_1)\n        self.graph.plotItem.addItem(self.line_ipd_2)\n\n        self.vb = pyqtgraph.ViewBox()\n        self.pi = self.graph.plotItem\n        self.pi.showAxis('right')\n        self.pi.scene().addItem(self.vb)\n        self.pi.getAxis('right').linkToView(self.vb)\n        self.vb.setXLink(self.pi)\n\n        self.update_views()\n        self.pi.vb.sigResized.connect(self.update_views)\n        self.vb.addItem(self.line_iopd)\n\n        self.pi.setYRange(0,255, padding=0)\n        self.vb.setYRange(0,0.5, padding=0)\n\n        self.align = None\n        self.update_secondary()\n        self.pi.vb.sigYRangeChanged.connect(self.update_secondary)\n\n        self.graph.plotItem.legend.addItem(self.line_iopd, self.line_iopd.name())\n\n    def update_views(self):\n        self.vb.setGeometry(self.pi.vb.sceneBoundingRect())\n        self.vb.linkedViewChanged(self.pi.vb, self.vb.XAxis)\n\n    def update_secondary(self):\n        if self.align is None:\n            self.align = [self.pi.getAxis('left').range, self.pi.getAxis('right').range]\n        factor = (self.align[1][1]-self.align[1][0])/(self.align[0][1]-self.align[0][0])\n        newRangeLeft = self.pi.getAxis('left').range\n        newRangeRightMin = self.align[1][0]-(self.align[0][0]-newRangeLeft[0])*factor\n        newRangeRightMax = self.align[1][1]+(newRangeLeft[1]-self.align[0][1])*factor\n        self.vb.setYRange(newRangeRightMin, newRangeRightMax, padding=0)\n\n"
},
{
"QuestionId": "76389456",
"QuestionTitle": "Finding keys with the minimum values in each group in a dictionary with jumps (Python)",
"QuestionBody": "I have a dictionary where jumps happen in its keys. How can I find the key in between each group where the value is minimum?\nFor example, I have\nmyDict = {\n        0.98:0.001,\n        1.0:0.002,\n        1.02: 0.0001,\n        3.52:0.01,\n        3.57:0.004,\n        3.98: 0.005,\n        4.01: 0.02,\n        6.87: 0.01,\n        6.90:0.02,\n        6.98:0.001,\n        7.0: 0.02\n}\n\nMy desired output would be 1.02, 3.57, 6.98.\nThe actual dictionary I'm working with has over 1000 items.\n",
"AnswerId": "76391095",
"AnswerBody": "Here is a solution, supposing the dictionary is sorted in ascending order according to key (explanations in the comments of the code):\ndef main():\n    d = {\n        0.98: 0.001, 1.0: 0.002, 1.02: 0.0001,\n        3.52: 0.01, 3.57: 0.004, 3.98: 0.005, 4.01: 0.02,\n        6.87: 0.01, 6.90: 0.02, 6.98: 0.001, 7.0: 0.02\n    }\n\n    all_groups = []  # list to store the groups\n    minimums = []  # list to store all mins\n    # initializing holders for minimum key and value\n    min_k = 1000\n    min_v = 0\n\n    for k, v in d.items():\n        # an if-statement just to add the first group with key inside\n        if len(all_groups) == 0:\n            all_groups.append([k])\n            min_k = k\n            min_v = d.get(k)\n        else:\n            # check if the difference is less or equal to 1\n            if k - all_groups[-1][-1] <= 1.0:\n                all_groups[-1].append(k)\n\n                # each time we add a key to a group, we check if it is the minimum\n                if d.get(k) < min_v:\n                    min_k = k\n                    min_v = d.get(k)\n            else:\n                minimums.append((min_k, min_v))\n\n                # we append a new list with the new key inside to `all_groups`\n                # in which we will store the next elements\n                all_groups.append([k])\n                min_k = k\n                min_v = d.get(k)\n\n    minimums.append((min_k, min_v))  # adding last minimums because for loop ends without adding them\n\n    for i in minimums:\n        print(i[0])  # 1.02, 3.57, 6.98\n\n\nif __name__ == \"__main__\":\n    main()\n\n"
},
{
"QuestionId": "76391230",
"QuestionTitle": "Change the font size of the output of python code chunk",
"QuestionBody": "Consider the following quarto document:\n---\ntitle: \"Untitled\"\nformat: pdf\n---\n\n```{python}\n#|echo: false\n#|result: 'asis'\n\nimport pandas as pd\n\ndf = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'],\n    'B': ['one', 'one', 'two', 'two', 'one', 'one'],\n    'C': ['dull', 'dull', 'shiny', 'shiny', 'dull', 'dull'],\n    'D': [1, 3, 2, 5, 4, 1]})\n\nprint(df)\n```\n\nHow to scale down the output of the python chunk, say, to 50%. Is that possible?\n",
"AnswerId": "76392528",
"AnswerBody": "I can suggest two approaches to do this, use whatever suits you!\nOption 01\nCode chunk outputs are wrapped inside the verbatim environment. So to change the font size for a single code chunk, one option could be redefining the verbatim environment to have a smaller font size just before that code chunk and then again redefining the verbatim environment to get the default font size for later code chunk outputs.\n---\ntitle: \"Untitled\"\nformat: pdf\n---\n\n\\let\\oldvrbtm\\verbatim\n\\let\\endoldvrbtm\\endverbatim\n\n<!-- % redefine the verbatim environment -->\n\\renewenvironment{verbatim}{\\tiny\\oldvrbtm}{\\endoldvrbtm}\n\n```{python}\n#|echo: false\n#|result: 'asis'\n\nimport pandas as pd\n\ndf = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'],\n    'B': ['one', 'one', 'two', 'two', 'one', 'one'],\n    'C': ['dull', 'dull', 'shiny', 'shiny', 'dull', 'dull'],\n    'D': [1, 3, 2, 5, 4, 1]})\n\nprint(df)\n```\n\n<!-- % redefine the environment back to normal -->\n\\renewenvironment{verbatim}{\\oldvrbtm}{\\endoldvrbtm}\n\n```{python}\n#|echo: false\n#|result: 'asis'\n\nprint(df)\n```\n\nOption 02\nThis idea actually is actually taken from this answer on TeXStackExchange. Here A command is defined to control the verbatim font size. So change the font sizes as needed.\n---\ntitle: \"Untitled\"\nformat: pdf\ninclude-in-header: \n  text: |\n    \\makeatletter\n    \\newcommand{\\verbatimfont}[1]{\\renewcommand{\\verbatim@font}{\\ttfamily#1}}\n    \\makeatother\n---\n\n\\verbatimfont{\\tiny}\n\n```{python}\n#|echo: false\n#|result: 'asis'\n\nimport pandas as pd\n\ndf = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'],\n    'B': ['one', 'one', 'two', 'two', 'one', 'one'],\n    'C': ['dull', 'dull', 'shiny', 'shiny', 'dull', 'dull'],\n    'D': [1, 3, 2, 5, 4, 1]})\n\nprint(df)\n```\n\n\\verbatimfont{\\normalsize}\n\n```{python}\n#|echo: false\n#|result: 'asis'\n\nprint(df)\n```\n\nNote: The predefined font sizes that you can use in both of the above options are, \\Huge, \\huge, \\LARGE, \\Large, \\large, \\normalsize, \\small, \\footnotesize, \\scriptsize, \\tiny\n\n\n"
},
{
"QuestionId": "76387093",
"QuestionTitle": "Why does Vue.js not update variables inside data",
"QuestionBody": "Can't update variables inside data in Vue\nI'm creating a project using Vue 3 as frontend.\nIn Dashboard.vue, a GET request will be sent to backend with token in header, in order to let the backend identify user's identity, then Vue will receive the response with a json including info like this: {'uid': 'xxx', 'username': 'xxx'}.\nMy Dashboard.vue:\n<script>\nimport axios from 'axios';\n\nexport default {\n    data() {\n        return {\n            uid: '',\n            username: '',\n            temp: {},\n            loaded: false\n        }\n    },\n    methods: {\n        require_get(url) {\n            var token = localStorage.getItem('token');\n            var config = {\n                headers: {\n                    'token': token,\n                }\n            };\n            var _url = 'user/dashboard/' + url;\n            axios.get(_url, config)\n            .then(response => {\n                this.temp = response.data;\n            })\n        },\n        get_user_info() {\n            this.require_get('info');\n            this.uid = this.temp['username']; \n            this.username = this.temp['username'];\n        }\n    },\n\n    mounted() {\n        this.get_user_info();\n    }\n}\n</script>\n\nIn this way, uid and username cannot be updated correctly.\nFor debugging, when I add console.log(this.uid) at the end of get_user_info() like this:\n//...\nthis.require_get('info');\nthis.uid = this.temp['username']; \nthis.username = this.temp['username'];\nconsole.log(this.temp['uid']);\n\nI get a undefined. But when I add console.log(this.uid) at the end of require.get() like this:\n//...\n.then(response => {\n                this.temp = response.data;\n                console.log(this.temp['uid]);\n            })\n\nThe output shows that variable uid has already been updated at this moment.\nAfter testing, I found that I can correctly update uid and username as long as I put\nthis.uid = this.temp['username']; \nthis.username = this.temp['username'];\n\ninside require_get().\nWhy is that? And how can I manage to update these variables with these two codes staying in get_user_info()?\nUpdate\nI changed my codes into\"\n    methods: {\n        async require_get(url) {\n            var token = localStorage.getItem('token');\n            var config = {\n                headers: {\n                    'token': token,\n                }\n            };\n            var _url = 'user/dashboard/' + url;\n            axios.get(_url, config)\n            .then(response => {\n                return response.data;\n            })\n        },\n        async get_user_info() {\n            let info = await this.require_get('info');\n            console.log(info);\n            this.uid = info['username']; \n            this.username = info['username'];\n        }\n    },\n\n    mounted() {\n        this.get_user_info('info');\n    }\n\nand the output of console.log(info) is still undefined, now I don't understand...\n",
"AnswerId": "76392720",
"AnswerBody": "The issue is asynchronous execution.\nIn require_get, you update this.temp in the .then() callback, which is only called when the Promise has resolved. In get_user_info, you are calling require_get and then immediately (synchronously) trying to read the data. Because it is fetched and set asynchronously, it is not yet present and you get undefined.\nTo fix it, make require_get an async function and return the data instead of using this.temp. Then make get_user_info an async function as well, await the call of require_get, and assign this.uid and this.username to the returned data.\nYou could also use .then() if you prefer that to async/await. I have included examples for both.\nI assume that this.uid = data['username'] was meant to be this.uid = data['uid'], so changed that too.\nWith async/await\nimport axios from 'axios';\n\nexport default {\n    data() {\n        return {\n            uid: '',\n            username: '',\n            loaded: false\n        }\n    },\n    methods: {\n        async require_get(url) {\n            var token = localStorage.getItem('token');\n            var config = {\n                headers: {\n                    'token': token,\n                }\n            };\n            var _url = 'user/dashboard/' + url;\n            var response = await axios.get(_url, config);\n            return response.data;\n        },\n        async get_user_info() {\n            var data = await this.require_get('info');\n            this.uid = data['uid']; \n            this.username = data['username'];\n        }\n    },\n\n    mounted() {\n        this.get_user_info();\n    }\n}\n\nWith .then()\nimport axios from 'axios';\n\nexport default {\n    data() {\n        return {\n            uid: '',\n            username: '',\n            loaded: false\n        }\n    },\n    methods: {\n        require_get(url) {\n            var token = localStorage.getItem('token');\n            var config = {\n                headers: {\n                    'token': token,\n                }\n            };\n            var _url = 'user/dashboard/' + url;\n            return axios.get(_url, config).then((response) => response.data);\n        },\n        get_user_info() {\n            this.require_get('info').then((data) => {\n                this.uid = data['uid']; \n                this.username = data['username'];\n            });\n        }\n    },\n\n    mounted() {\n        this.get_user_info();\n    }\n}\n\n"
},
{
"QuestionId": "76387206",
"QuestionTitle": "Resolving a library projects SASS files from an application in the same workspace?",
"QuestionBody": "Is it possible to resolve SASS contained in a workspace library using an approach that is similar to resolving ts files from an application within the same workspace?  For context I'll setup a real workspace as follows:\nng new theme-workspace --create-application=false\ncd theme-workspace\nng g library theme\nmkdir projects/theme/src/lib/styles\ntouch projects/theme/src/lib/styles/index.scss\nng g application playground\n\nWithin the directory projects/theme/src/lib/styles we will add the following content to index.scss.\n$color: red;\n\nAnd in order to include the style assets we need to update ng-package.json with an asset block like this:\n  \"assets\": [\n    { \"input\": \"src/lib/styles\", \"glob\": \"**/*.scss\", \"output\": \"styles\" }\n  ]\n\nIf we build this project library like this:\nng build theme\n\nWe see that dist/theme/styles contains index.scss.\nWe can access the generated ts component ThemeComponent like this from the playground.\nimport { ThemeComponent } from 'theme';\n\n\nWhen using @use to import the SASS index.scss module is it possible to use a similar namespace?\nFor example if we try this from the playground styles.scss module it fails:\n@use `theme/styles` as t;\n\nThis is the error.\nSassError: Can't find stylesheet to import.\n  ╷\n2 │ @use 'theme/styles' as t;\n\nNow we could resolve by using a relative file import, but I'm curious whether there's a \"Shorthand\" way of doing it that uses the library name space?\n",
"AnswerId": "76392909",
"AnswerBody": "Currently this is not supported, but there is a feature request for it.\n"
},
{
"QuestionId": "76389947",
"QuestionTitle": "How to increase the compression ratio of a JPEG2000 file with \"avenc_jpeg2000\" GStreamer encoder?",
"QuestionBody": "I'm using the plugin avenc_jpeg2000, from gst-libav module, combined with videotestsrc and  filesink plugins for encoding a raw picture to a JPEG2000 picture:\ngst-launch-1.0 videotestsrc num-buffers=1 ! avenc_jpeg2000 ! filesink location=/tmp/picture-ref.jp2\n\nThis pipeline works and produce a 31.85 KiB (32,616) file.\nenter image description here\nNow, I want to divide the size of my output file by two by increasing the compression ratio of the encoder avenc_jpeg2000. To achieve this, I want to minimize the number of bits required to represent the image with an allowable level of distortion. I know JPEG2000 standard support lossless and lossy compression mode. For my use case, the lossy compression mode is acceptable.\nHow should I proceed to increase the compression of my output file ? What encoder's properties should I play with for doing that ?\nMy test configuration:\n\ni.MX 8M Plus\n\nGStreamer 1.18.0\n\nlibav 1.18.0 (Release date: 2020-09-08)\n\n\nI tried to play with \"bitrate\" and \"bitrate-tolerance\" properties, but it seems to have no effect on the size of the output file:\ngst-launch-1.0 videotestsrc num-buffers=1 ! avenc_jpeg2000 bitrate=100000 bitrate-tolerance=10000 ! filesink location=/tmp/picture-test-01.jp2\n\nI compare files by doing a checksum with sha224sum command :\nd0da9118a9c93a0420d6d62f104e0d99fe6e50cda5e87a46cef126f9  /tmp/picture-ref.jp2\n\nd0da9118a9c93a0420d6d62f104e0d99fe6e50cda5e87a46cef126f9  /tmp/picture-test-01.jp2\n\n",
"AnswerId": "76391113",
"AnswerBody": "For lossy compression, you can increase the value of the quantization.\nFirst, set the encoding type of the encoder to \"Constant Quantizer\" and then, find an appropriated quantizer value.\nIn my case, to produce a 15 KiB file, I used the following pipeline:\ngst-launch-1.0 videotestsrc num-buffers=1 ! avenc_jpeg2000 pass=2 quantizer=10  ! filesink location=/tmp/picture-test-02.jp2\n\n"
},
{
"QuestionId": "76392182",
"QuestionTitle": "How to execute code every time a Composable is shown (and execute only once)",
"QuestionBody": "I am creating a Composable which is responsible for showing notifications to users. Every time the user goes to that Composable, I want to execute a query which will clear the notification count. I only want to execute that query when the Composable has appeared, not every time the Composable is recomposed due to configuration change and anything.\nEssentially I am looking for an equivalent of https://developer.apple.com/documentation/swiftui/view/onappear(perform:).\nIs there any method I can use in Jetpack Compose?\n",
"AnswerId": "76392541",
"AnswerBody": "Use LaunchedEffect (link)\nLaunchedEffect(Unit) {\n    // Actions to perform when LaunchedEffect enters the Composition \n}\n\nIt takes one or more key parameters that are used to cancel the running effect and start a new one. Since you need to execute your code only once use something immutable as a key like Unit or true.\n"
},
{
"QuestionId": "76387490",
"QuestionTitle": "What needs to be done to make the Bootstrap 5.3.0 Collapsible button show in this simple web page?",
"QuestionBody": "I've tried to create a simple web page that uses the Bootstrap (version 5.3.0) Collapsible and I cannot get it to work no matter what I try.\nAll I want is a Collapsible that 'holds' a few links in it which are shown when you click it.\nBut when that didn't work I simplified it to just a list of strings (code shown below) but the problem is still there.\nThe problem is that the Collapsible button does not show no matter what I try.\nThe <span class=\"navbar-toggler-icon\"></span> is not visible. I've added 'X' to both sides\nof it just so there is an indication where that invisible button is.\nAnyone knows how to fix that, make the Collapsible button visible?\nThanks.\nHere's the code:\n\n\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\">\n<script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n\n<header class=\"bg-primary text-white text-center py-3\">\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col-md-4\">\n        <div class=\"left-header\">\n          <h3>Left Header</h3>\n        </div>\n      </div>\n      <div class=\"col-md-4\">\n        <div class=\"central-header\">\n          <h3>Central Header</h3>\n        </div>\n      </div>\n      <div class=\"col-md-4\">\n        <div class=\"right-header\">\n          <button class=\"navbar-toggler\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#collapsibleNav\">\n              X<span class=\"navbar-toggler-icon\"></span>X\n            </button>\n        </div>\n        <div class=\"collapse\" id=\"collapsibleNav\">\n          <div class=\"card card-body\">\n            <ul class=\"nav\">\n              <li class=\"nav-item\">Item 1</li>\n              <li class=\"nav-item\">Item 2</li>\n            </ul>\n          </div>\n        </div>\n      </div>\n    </div>\n  </div>\n</header>\n\n<main class=\"container mt-4\">\n  <h2>Main Content</h2>\n  <p>This is the main content of the page.</p>\n</main>\n\n\n\n",
"AnswerId": "76393307",
"AnswerBody": "Try adding .navbar selector to the parent container: right-header navbar, because it's actually coming from that class (--bs-navbar-toggler-icon-bg), not the icon, the hamburger is actually a variable defined in .navbar, so by adding it to the parent it becomes accessible:\n.navbar-toggler-icon {\n    background-image: var(--bs-navbar-toggler-icon-bg);\n}\n\n.navbar {\n--bs-navbar-toggler-icon-bg: url(\"data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'%3e%3cpath stroke='rgba%2833, 37, 41, 0.75%29' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e\");\n}\n\n\n\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\">\n<script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n\n<header class=\"bg-primary text-white text-center py-3\">\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col-md-4\">\n        <div class=\"left-header\">\n          <h3>Left Header</h3>\n        </div>\n      </div>\n      <div class=\"col-md-4\">\n        <div class=\"central-header\">\n          <h3>Central Header</h3>\n        </div>\n      </div>\n      <div class=\"col-md-4\">\n        <div class=\"right-header navbar\">\n          <button class=\"navbar-toggler mx-auto\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#collapsibleNav\">\n              X<span class=\"navbar-toggler-icon\"></span>X\n            </button>\n        </div>\n        <div class=\"collapse\" id=\"collapsibleNav\">\n          <div class=\"card\">\n            <ul class=\"nav card-body\">\n              <li class=\"nav-item\">Item 1</li>\n              <li class=\"nav-item\">Item 2</li>\n            </ul>\n          </div>\n        </div>\n      </div>\n    </div>\n  </div>\n</header>\n\n<main class=\"container mt-4\">\n  <h2>Main Content</h2>\n  <p>This is the main content of the page.</p>\n</main>\n\n\n\n"
},
{
"QuestionId": "76389994",
"QuestionTitle": "I have a Blazor server app with windows authentication. But the username and password dialog is just coming when page is opened from the server side",
"QuestionBody": "I have a Blazor server app (.Net6) with windows authentication on a Win 2019 Server with IIS. But the username and password dialog is just coming when I open the web page from the google chrome browser directly on the server where the Blazor app is running. When I try to open the page from another PC in the same domain (Chrome, Firefox...), then the page is opening directly without asking username and password.\nWhat could be the reason for that?\n",
"AnswerId": "76391123",
"AnswerBody": "The reason you are not prompted for a username and password when accessing the Blazor server app from another PC in the same domain is likely due to the integrated Windows authentication and the Single Sign-On (SSO) capabilities of the browser and the server. Here's a brief explanation of how this works:\n\nIntegrated Windows Authentication: When using integrated Windows authentication, the browser automatically sends the user's Windows credentials (username and password) to the server without prompting the user for them. This is possible because the browser and the server negotiate the authentication process using various protocols like Kerberos or NTLM.\nSingle Sign-On (SSO): SSO allows users to authenticate once and then access multiple resources without being prompted for credentials again. In your case, since the client PC and the server are in the same domain, and integrated Windows authentication is enabled, the user's credentials from the client PC's Windows session are automatically passed to the server without requiring a separate prompt.\n\nTo ensure that the username and password prompt appears consistently, you can try the following:\n\nCheck Browser Settings: Make sure that the browser settings on the client PC are configured to send Windows credentials. In Chrome, go to Settings > Privacy and Security > Site Settings > Additional permissions > Manage permissions. Ensure that the server's URL is listed and set to \"Allow\" or \"Automatic.\"\nVerify IIS Settings: Ensure that the IIS configuration on the server is set up correctly for integrated Windows authentication. Open IIS Manager, select the Blazor server app, and go to the Authentication settings. Make sure that only Windows Authentication is enabled, and other authentication methods like Anonymous Authentication are disabled.\nCross-Domain Considerations: If the Blazor server app is hosted on a different domain, you may encounter additional challenges with SSO due to browser security restrictions. In such cases, you may need to configure your server and browser settings to enable cross-domain SSO.\nClear Browser Cache: Clear the cache and cookies in the browser on the client PC to ensure that any cached credentials or settings are not causing unexpected behavior.\n\nBy checking these settings and ensuring that integrated Windows authentication is correctly configured on the server and the client PC, you should be able to consistently prompt for a username and password when accessing the Blazor server app.\n"
},
{
"QuestionId": "76392367",
"QuestionTitle": "Write to Google sheet skipping 1st row",
"QuestionBody": "When using the package googlesheets4 is there any method for writing data to a sheet skipping the first row so that the data being written to a sheet starts at row 2? I am hoping to leverage something similar to when you read a sheet and utilize ex. skip = 2 to read data starting at the 3rd row\nI have tried the following which does not work\nwrite_sheet(data = df, ss = \"google_sheet_url\", skip = 1, sheet = \"test\")\n\n",
"AnswerId": "76392557",
"AnswerBody": "skip=n is only for read_excel()\nin the googlesheets4 library to start at a specified range, you'd use range_write(). This is similar to the startRow=n in the xlsx library.\nrange_write(ss = \"google_sheet_url\", data = df, range = \"B1\", sheet = \"test\")\n\n"
},
{
"QuestionId": "76382024",
"QuestionTitle": "TypeScript is unable to infer type properly from a typed string variable",
"QuestionBody": "I am trying to use a \"freely\" created string as a key for an object.\ninterface CatState {\n    name: string,\n    selected: boolean,\n    color: string,\n    height: number\n}\n\ninterface DogState{\n    name: string,\n    selected: boolean,\n    race: string,\n    age: number,\n    eyeColor: string\n}\n\nexport interface Animals {\n    animals: {\n        cat: {\n            cats: CatState[],\n            allSelected: boolean,\n        },\n        dog: {\n            dogs: DogState[],\n            allSelected: boolean,\n        },\n    }\n};\n\nconst selectAnimal = (allAnimals: Animals, animal: keyof Animals['animals'], index:number) => {\n    const animalPlural = `${animal}s` as keyof Animals['animals'][typeof animal]\n    allAnimals.animals[animal][animalPlural][index].selected= true\n}\n\nThis highlights .selected with the message\n\nProperty 'selected' does not exist on type 'boolean'.\n\nHere is a Playground. Is there a workaround for this, or is this simply not possible?\n",
"AnswerId": "76393367",
"AnswerBody": "In order for this to work you need to make selectAnimal generic.\nYou might think it should be able to deal with an animal input of a union type, but the compiler isn't able to properly type check a single block of code that uses multiple expressions that depend on the same union type.  It loses track of the correlation between `${animal}s` and allAnimals.animals[animal].  The formers is of type \"cats\" | \"dogs\" and the latter is of a type like {cats: CatState[]} | {dogs: DogState[]}, and you can't generally index into the latter with the former, because \"what if you've got {cats: CatState[]} and you're indexing with \"dogs\"?\"  That can't happen, but the compiler is unable to see it.  TypeScript can't directly deal with correlated unions this way.  That's the subject of microsoft/TypeScript#30581.\nIf you want a single code block to work for multiple cases, the types need to be refactored to use generics instead, as described in microsoft/TypeScript#47109.  Here's how it might look for your example:\ninterface AnimalStateMap {\n    cat: CatState,\n    dog: DogState\n}\n\ntype AnimalData<K extends keyof AnimalStateMap> =\n    { [P in `${K}s`]: AnimalStateMap[K][] & { allSelected: boolean } }\n\nexport interface Animals {\n    animals: { [K in keyof AnimalStateMap]: AnimalData<K> };\n};\n    \n\nconst selectAnimal = <K extends keyof AnimalStateMap>(\n    allAnimals: Animals, animal: K, index: number) => {\n    const animalPlural = `${animal}s` as const;\n    // const animalPlural: `${K}s`\n    const animalData: AnimalData<K> = allAnimals.animals[animal]\n    animalData[animalPlural][index].selected = true;\n}\n\nThe AnimalStateMap is a basic key-value type representing the underlying relationship in your data structure.  Then AnimalData<K> is a mapped type that encodes as a template literal type the concatenation of s onto the type of the keys (giving such plurals as gooses and fishs 🤷‍♂️) and that the value type is of the expected animal array.  And that there's an allSelected property.\nThen your Animals type explicitly written as a mapped type over keyof AnimalStateMap, which will help the compiler see the correlation when we index into it.\nFinally, selectAnimal is generic in K extends keyof AnimalStateMap and the body type checks because animalPlural is of just the right generic type `${K}s` which is known to be a key of animalData, which is AnimalData<K>.\nPlayground link to code\n"
},
{
"QuestionId": "76390577",
"QuestionTitle": "Kubernetes: Frequently unable to communicate with kublet api (connection refused)",
"QuestionBody": "I'm deploying a new kubernetes cluster on a single node (Ubuntu 22.04)\nThe problem is I frequently get this error when running any kubectl commands (hostnames changed)\nThe connection to the server k8cluster.example.com:6443 was refused - did you specify the right host or port?\nAfter I installed kubernetes (via apt install -y kubelet kubeadm kubectl) everything was stable, but obviously the node was not in a ready state. The problems started as soon as i deployed the Flannel container network, which I did as follows:\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\nPods in the kube-system name space are frequently restarting\nroot@k8cluster:~/.ssh# kubectl get all -A\nNAMESPACE      NAME                                                 READY   STATUS             RESTARTS         AGE\nkube-flannel   pod/kube-flannel-ds-6h6zq                            1/1     Running            25 (46s ago)     98m\nkube-system    pod/coredns-5d78c9869d-gmdpv                         0/1     CrashLoopBackOff   18 (4m40s ago)   130m\nkube-system    pod/coredns-5d78c9869d-zhvxk                         1/1     Running            19 (14m ago)     130m\nkube-system    pod/etcd-k8cluster.example.com                       1/1     Running            31 (7m21s ago)   130m\nkube-system    pod/kube-apiserver-k8cluster.example.com            1/1     Running            37 (5m40s ago)   131m\nkube-system    pod/kube-controller-manager-k8cluster.example.com    0/1     Running            46 (5m10s ago)   130m\nkube-system    pod/kube-proxy-nvnkf                                 0/1     CrashLoopBackOff   41 (100s ago)    130m\nkube-system    pod/kube-scheduler-k8cluster.example.com             0/1     CrashLoopBackOff   44 (4m43s ago)   129m\n\nNAMESPACE     NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\ndefault       service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP                  132m\nkube-system   service/kube-dns     ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   132m\n\nNAMESPACE      NAME                             DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\nkube-flannel   daemonset.apps/kube-flannel-ds   1         1         1       1            1           <none>                   98m\nkube-system    daemonset.apps/kube-proxy        1         1         1       1            1           kubernetes.io/os=linux   132m\n\nNAMESPACE     NAME                      READY   UP-TO-DATE   AVAILABLE   AGE\nkube-system   deployment.apps/coredns   2/2     2            2           132m\n\nNAMESPACE     NAME                                 DESIRED   CURRENT   READY   AGE\nkube-system   replicaset.apps/coredns-5d78c9869d   2         2         2       130m\n\nI'm seeing these errors when running journalctl -u kubelet\nJun 02 13:16:21 k8cluster.example.com kubelet[19340]: I0602 13:16:21.848785   19340 scope.go:115] \"RemoveContainer\" containerID=\"4da5cc966a4dcf61001cbdbad36c47917fdfeb05bd7c4c985b2f362efa92f464\"\nJun 02 13:16:21 k8cluster.example.com kubelet[19340]: I0602 13:16:21.849006   19340 status_manager.go:809] \"Failed to get status for pod\" podUID=aae126ec9b57a8789f7682f92e81bd7a pod=\"kube-system/etcd-k8cluster.example.com\" err=\"Get \\\"https://k8cluster.example.com:6443/api/v1/namespaces/kube-system/pods/etcd-k8cluster.example.com\\\": dial tcp 172.31.37.108:6443: connect: connection refused\"\nJun 02 13:16:21 k8cluster.example.com kubelet[19340]: E0602 13:16:21.849262   19340 pod_workers.go:1294] \"Error syncing pod, skipping\" err=\"failed to \\\"StartContainer\\\" for \\\"kube-apiserver\\\" with CrashLoopBackOff: \\\"back-off 2m40s restarting failed container=kube-apiserver pod=kube-apiserver-spotcluster.infdev.org_kube-system(ccdffaba21456689fa71a8f7b182fb0c)\\\"\" pod=\"kube-system/kube-apiserver-k8cluster.example.com\" podUID=ccdffaba21456689fa71a8f7b182fb0c\nJun 02 13:16:21 k8cluster.example.com kubelet[19340]: I0602 13:16:21.849317   19340 status_manager.go:809] \"Failed to get status for pod\" podUID=ccdffaba21456689fa71a8f7b182fb0c pod=\"kube-system/kube-apiserver-k8cluster.example.com\" err=\"Get \\\"https://k8cluster.example.com:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-k8cluster.example.com\\\": dial tcp 172.31.37.108:6443: connect: connection refused\"\nJun 02 13:16:21 k8cluster.example.com kubelet[19340]: I0602 13:16:21.866932   19340 scope.go:115] \"RemoveContainer\" containerID=\"46f9e127efbd2506f390486c2590232e76b0617561c7c440d94c470a4164448f\"\nJun 02 13:16:21 k8cluster.example.com kubelet[19340]: E0602 13:16:21.867259   19340 pod_workers.go:1294] \"Error syncing pod, skipping\" err=\"failed to \\\"StartContainer\\\" for \\\"coredns\\\" with CrashLoopBackOff: \\\"back-off 5m0s restarting failed container=coredns pod=coredns-5d78c9869d-gmdpv_kube-system(ddf0658a-260b-41d1-a0a0-595de4991ec6)\\\"\" pod=\"kube-system/coredns-5d78c9869d-gmdpv\" podUID=ddf0658a-260b-41d1-a0a0-595de4991ec6\nJun 02 13:16:22 k8cluster.example.com kubelet[19340]: I0602 13:16:22.850577   19340 scope.go:115] \"RemoveContainer\" containerID=\"4da5cc966a4dcf61001cbdbad36c47917fdfeb05bd7c4c985b2f362efa92f464\"\n\nAlso dmesg is showing these messages:\n\n[Fri Jun  2 13:02:11 2023] IPv6: ADDRCONF(NETDEV_CHANGE): veth11eea1b5: link becomes ready\n[Fri Jun  2 13:02:11 2023] cni0: port 1(veth11eea1b5) entered blocking state\n[Fri Jun  2 13:02:11 2023] cni0: port 1(veth11eea1b5) entered forwarding state\n[Fri Jun  2 13:11:54 2023] cni0: port 2(veth92694dfb) entered disabled state\n[Fri Jun  2 13:11:54 2023] device veth92694dfb left promiscuous mode\n[Fri Jun  2 13:11:54 2023] cni0: port 2(veth92694dfb) entered disabled state\n[Fri Jun  2 13:11:55 2023] cni0: port 2(veth29e5e0d3) entered blocking state\n[Fri Jun  2 13:11:55 2023] cni0: port 2(veth29e5e0d3) entered disabled state\n[Fri Jun  2 13:11:55 2023] device veth29e5e0d3 entered promiscuous mode\n[Fri Jun  2 13:11:55 2023] cni0: port 2(veth29e5e0d3) entered blocking state\n[Fri Jun  2 13:11:55 2023] cni0: port 2(veth29e5e0d3) entered forwarding state\n[Fri Jun  2 13:11:55 2023] IPv6: ADDRCONF(NETDEV_CHANGE): veth29e5e0d3: link becomes ready\n[Fri Jun  2 13:13:19 2023] cni0: port 1(veth11eea1b5) entered disabled state\n[Fri Jun  2 13:13:19 2023] device veth11eea1b5 left promiscuous mode\n[Fri Jun  2 13:13:19 2023] cni0: port 1(veth11eea1b5) entered disabled state\n[Fri Jun  2 13:13:20 2023] cni0: port 1(veth1f7fb9e0) entered blocking state\n[Fri Jun  2 13:13:20 2023] cni0: port 1(veth1f7fb9e0) entered disabled state\n[Fri Jun  2 13:13:20 2023] device veth1f7fb9e0 entered promiscuous mode\n[Fri Jun  2 13:13:20 2023] cni0: port 1(veth1f7fb9e0) entered blocking state\n[Fri Jun  2 13:13:20 2023] cni0: port 1(veth1f7fb9e0) entered forwarding state\n[Fri Jun  2 13:13:20 2023] IPv6: ADDRCONF(NETDEV_CHANGE): veth1f7fb9e0: link becomes ready\n\nIf I look at the logs for the kube-apiserver pod I see this repeating itself.\n Err: connection error: desc = \"transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused\"\nW0602 13:21:03.884015       1 logging.go:59] [core] [Channel #148 SubChannel #149] grpc: addrConn.createTransport failed to connect to {\n  \"Addr\": \"127.0.0.1:2379\",\n  \"ServerName\": \"127.0.0.1\",\n  \"Attributes\": null,\n  \"BalancerAttributes\": null,\n  \"Type\": 0,\n  \"Metadata\": null\n\nAny ideas?\n",
"AnswerId": "76391128",
"AnswerBody": "It seems I was having the same problem as mentioned in this question\nUnable to bring up kubernetes API server\nThe solution here worked for me\ncontainerd config default | tee /etc/containerd/config.toml\nsed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml  \nservice containerd restart\nservice kubelet restart\n\n"
},
{
"QuestionId": "76392163",
"QuestionTitle": "How can I create a stamina meter that depletes as I sprint and recharges after waiting in Unity using C#?",
"QuestionBody": "I'm trying to make a stamina meter for my game that depletes as you sprint and once it hits zero you have to wait for it to charge up again before sprinting, I don't know what I should do to fix the code and don't know where I went wrong, thanks.\nfloat moveSpeed = 5f;\n    float sprintSpeed = 8f;\n    float maxStamina = 5f;\n    float currentStamina = 0f;\n    private void Movement()\n    {\n       float movementX = Input.GetAxis(\"Horizontal\");\n       float movementZ = Input.GetAxis(\"Vertical\");`\n\n       Vector3 moveDirection = new Vector3(movementX, 0f, movementZ);\n       moveDirection = camera.forward * movementZ + camera.right * movementX;\n       if (Input.GetKey(KeyCode.LeftShift) && currentStamina != maxStamina)\n       {\n          transform.position += (moveDirection).normalized * sprintSpeed * Time.deltaTime;\n          currentStamina += Time.deltaTime;\n\n          if (currentStamina >= maxStamina)\n          {\n             transform.position += (moveDirection).normalized * moveSpeed * Time.deltaTime;\n             new WaitForSeconds(5f);\n             currentStamina = 0f;\n          }\n       }\n       transform.position += (moveDirection).normalized * moveSpeed * Time.deltaTime;\n     }\n\nwhole script just in case:\nprivate Transform transform;\n    private Rigidbody rb;\n    [SerializeField] private Transform camera;\n\n    float moveSpeed = 5f;\n    float sprintSpeed = 8f;\n    float maxStamina = 5f;\n    float currentStamina = 0f;\n    float increaseStaminaPerSecond = 1f;\n    void Start()\n    {\n        transform = GetComponent<Transform>();\n        rb = GetComponent<Rigidbody>();\n        rb.freezeRotation = true;\n        currentStamina = maxStamina;\n    }\n    void Update()\n    {\n        Movement();\n    }\n    private void Movement()\n    {\n        float movementX = Input.GetAxis(\"Horizontal\");\n        float movementZ = Input.GetAxis(\"Vertical\");\n\n        Vector3 moveDirection = new Vector3(movementX, 0f, movementZ);\n        moveDirection = camera.forward * movementZ + camera.right * movementX;\n        if (Input.GetKey(KeyCode.LeftShift) && currentStamina != maxStamina)\n        {\n            transform.position += (moveDirection).normalized * sprintSpeed * Time.deltaTime;\n            currentStamina += Time.deltaTime;\n\n            if (currentStamina >= maxStamina)\n            {\n                transform.position += (moveDirection).normalized * moveSpeed * Time.deltaTime;\n                new WaitForSeconds(5f);\n                currentStamina = 0f;\n            }\n        }\n\n\n        transform.position += (moveDirection).normalized * moveSpeed * Time.deltaTime;\n    }\n\n",
"AnswerId": "76392619",
"AnswerBody": "Encapsulate and simplify your logic so its easier to read and to maintain.\nYou need to introduce a few variables that will help you keep things clean and more readable.\nAdditionally, when unsure, write things as if you would talk in a conversation so that they make sense. For example, you wouldn't be able to sprint if you had no stamina, and not if your stamina wasn't \"full\", so write that in code if (currentStamina > 0) canSprint, etc.\nprivate Transform transform;\nprivate Rigidbody rb;\n[SerializeField] private Transform camera;\n\nfloat moveSpeed = 5f;\nfloat normalSpeed = 5f; // add this\nfloat sprintSpeed = 8f;\nfloat maxStamina = 5f;\nfloat currentStamina = 0f;\nfloat increaseStaminaPerSecond = 1f;\n\nbool isSprinting = false; // add this to check if player is sprinting\nbool canSprint = true; // add this to check if player can sprint\n\nvoid Start()\n{\n    transform = GetComponent<Transform>();\n    rb = GetComponent<Rigidbody>();\n    rb.freezeRotation = true;\n    currentStamina = maxStamina;\n}\nvoid Update()\n{\n    UpdateStamina();\n    Sprint();\n    Movement();\n}\n\n// simplify logic to do one thing\nprivate void Movement()\n{\n    Vector3 movementInput = GetMovementInput();\n    Vector3 moveDirection = camera.forward * movementInput.z + camera.right * movementInput.y;\n    transform.position += moveDirection.normalized * moveSpeed * Time.deltaTime; // apply movement only once\n}\n\n// separate sprinting logic\nprivate void Sprint()\n{\n    if (Input.GetKey(KeyCode.LeftShift) && canSprint && currentStamina > 0)\n    {\n        moveSpeed = sprintSpeed;\n        isSprinting = true;\n    }\n    else\n    {\n        moveSpeed = normalSpeed;\n        isSprinting = false;\n    }\n}\n\nprivate void UpdateStamina()\n{\n    float staminaToAdd = isSprinting ? -Time.deltaTime : Time.deltaTime; // if sprinting, decrease stamina by Time.deltaTime, otherwise increase\n    currentStamina = Mathf.Clamp(currentStamina + staminaToAdd, 0, maxStamina); // prevent from going below 0 and over maxStamina\n\n    if (currentStamina <= 0 && canSprint) // if no more stamina but could sprint up to this point\n    {\n        StartCoroutine(SprintCooldownRoutine()); // start cooldown\n    }\n}\n\nprivate Vector3 GetMovementInput()\n{\n    float movementX = Input.GetAxis(\"Horizontal\");\n    float movementZ = Input.GetAxis(\"Vertical\");\n\n    return new Vector3(movementX, 0f, movementZ);\n}\n\nprivate IEnumerator SprintCooldownRoutine()\n{\n    canSprint = false; // disable sprinting\n\n    while (currentStamina < maxStamina)\n    {\n        currentStamina += Time.deltaTime; // this will increase stamina twice as fast, because we're already increasing it inside UpdateStamina. Remove this line if you wish to \"just wait for stamina to refresh\"\n        yield return null;\n    }\n    \n    canSprint = true;\n}\n\n"
},
{
"QuestionId": "76381814",
"QuestionTitle": "How to share a variable in Cypress from one test (it) to another when the domains are different?",
"QuestionBody": "How to share a variable from one test (it) to another when the domains are different?\nI've tried in countless ways, with Alias, Closure, Environment Variable, Local Storage, even with Event Listener, but when the next test is executed, these variables are cleared from memory.\nThe point is that I need to obtain the ID of an open protocol in a Web application, go to the backoffice that is in another domain to validate if that protocol was really opened.\nHere is the last version after giving up...\n/// <reference types=\"cypress\" />\n\ndescribe(\"Testar abertura de protocolo no fale conosco\", () => {\n    it(\"Deve acessar o FaleConosco, abrir um protocolo e depois validar no backoffice a abertura correta do mesmo\", () => {\n        cy.visit(`${Cypress.env('FALE_CONOSCO_URL')}`)\n        cy.get(\"#BotaoCriarNovoChamado\").click()\n        \n        cy.get('#InputLabelCpfCnpj').type(\"99999999999\")\n        cy.get('#InputLabelEmail').type(\"email@email.com\")\n        cy.get('#InputLabelTelefone').type(\"99999999999\")\n        cy.get('#InputLabelAssunto').type(\"Assunto de teste\")\n        cy.get('#InputLabelDescricao').type(\"Essa aqui e uma descrição bem detalhada, confia\")\n        cy.get('#BotaoEnviar').click()\n\n        cy.get('#spanNumeroDoChamado').should('contain', 'Número do chamado')\n        cy.get('#divNumeroDoChamado').then($div => {\n            const numero_do_chamado = $div.text().split(' ')[3].replace(/^#/, \"\");\n            // cy.wrap(numero_do_chamado).as(\"minhaVariavel\");\n\n            // Enviar o valor do alias para o segundo domínio usando postMessage\n            cy.window().then((win) => {\n                win.postMessage({ type: \"aliasValue\", value: numero_do_chamado }, \"*\");\n            });\n            // Cypress.env('numero_do_chamado', numero_do_chamado);\n            // cy.log(\"numero_do_chamado  -  \" + Cypress.env('numero_do_chamado'));\n            // cy.window().then(win => {\n            // win.localStorage.setItem('numero_do_chamado', numero_do_chamado);\n            // });\n        });\n\n\n        // cy.get('#divNumeroDoChamado').invoke(\"text\").as(\"minhaVariavel\")\n        // // ($div => {\n        // //     const numero_do_chamado = $div.text().split(' ')[3].replace(/^#/, \"\");\n        // //     cy.wrap(numero_do_chamado).as(\"minhaVariavel\");\n\n        // // Enviar o valor do alias para o segundo domínio usando postMessage\n        // cy.window().then((win) => {\n        //     win.postMessage({ type: \"aliasValue\", value: cy.get(\"@minhaVariavel\") }, \"*\");\n        // });\n        // //     // Cypress.env('numero_do_chamado', numero_do_chamado);\n        // //     // cy.log(\"numero_do_chamado  -  \" + Cypress.env('numero_do_chamado'));\n        // //     // cy.window().then(win => {\n        // //     // win.localStorage.setItem('numero_do_chamado', numero_do_chamado);\n        // //     // });\n        // // });\n\n    });\n\n    it(\"Deve acessar o Conecta e validar a abertura correta protocolo\", () => {\n        cy.visit(`${Cypress.env('URL')}`);\n\n        // Receber a mensagem contendo o valor do alias enviado pelo primeiro domínio\n        cy.window().then((win) => {\n            win.addEventListener(\"message\", (event) => {\n                const message = event.data;\n\n                // Verificar se a mensagem contém o valor do alias\n                if (message.type === \"aliasValue\") {\n                const aliasValue = message.value;\n                cy.wrap(aliasValue).as(\"meuAliasCompartilhado\");\n                }\n            });\n        });\n\n        // Fazer algo com o alias compartilhado no segundo domínio\n        cy.get(\"@meuAliasCompartilhado\").then((valor) => {\n            // Faça algo com o valor do alias compartilhado\n            cy.log(\"Valor do alias compartilhado:\", valor);\n            cy.login();\n            cy.visit(`${Cypress.env('URL')}/ticket-container/${Cypress.env('valor')}`)\n\n        });\n\n    });\n\n})\n\n",
"AnswerId": "76393564",
"AnswerBody": "When the test runner changes domains the whole browser object is reset, so any variables written to browser memory are lost\n\nclosure variables\naliases\nenv var (Cypress.env).\n\nThat leaves you with fixture (disk storage) or task-related pseudo data store (see bahmutov/cypress-data-session).\nFor fixture, the code would be\nit(\"Deve acessar o FaleConosco...\", () => {\n  cy.visit(`${Cypress.env('FALE_CONOSCO_URL')}`)\n  ...\n    const numero_do_chamado = $div.text().split(' ')[3].replace(/^#/, \"\")\n    cy.writeFile('cypress/fixtures/numero_do_chamado.json', numero_do_chamado)\n    ...\n})\n\nit(\"Deve acessar o Conecta...\", () => {\n  cy.visit(`${Cypress.env('URL')}`)\n  ...\n  const numero_do_chamado = cy.readFile('cypress/fixtures/numero_do_chamado.json')\n  ...\n})\n\nDon't use cy.fixture() command as there is caching involved internally. Not a problem for your current scenario, but may cause unexpected errors when your test pattern changes.\n"
},
{
"QuestionId": "76389708",
"QuestionTitle": "spark DF multiple Iterations on Rows",
"QuestionBody": "From the below data- col5 is holding the no of fruits to be distributed among plates from col1 to col4(4plates). Each time find the min from the plates(col1 to col4) add 1 fruit and reduce the fruit from col5 and repeat this process till col5(fruits becomes zero). Below is some sample code to find the min and add 1 fruit there. but how to do this recursively in spark - Scala.\nExpected output:\n\n  plate1 plate2 plate3  plate4  fruits  \n  1 2   3   4   3   \n  6 7   8   1   2   \n  2 4   6   8   5   \n\nIteration 1:\n  2 2   3   4   2   \n  6 7   8   2   1   \n  3 4   6   8   4   \n\nIteration 2:\n  3 2   3   4   1   (If 2 plates has the same min value , left precedence)\n  6 7   8   3   0   \n  4 4   6   8   3   \n\nIteration 3:\n  3 3   3   4   0   \n  6 7   8   3   0   \n  5 4   6   8   2   \n\nIteration 4:\n  3 3   3   4   0   \n  6 7   8   3   0   \n  5 5   6   8   1   \n\nIteration 5:\n  3 3   3   4   0   \n  6 7   8   3   0   \n  6 5   6   8   0   \n\ncode for first iteration:\n      val data = Seq(\n        (1.0, 2.0, 3.0, 4.0, 3.0),\n        (6.0, 7.0, 8.0, 1.0, 2.0),\n        (2.0, 4.0, 6.0, 8.0, 5.0)\n      )\n      val columns = List(\"col1\", \"col2\", \"col3\", \"col4\", \"col5\")\n      val df = spark.createDataFrame(data).toDF(columns: _*)\n\n      val updatedColumns = columns.map { colName =>\n        functions.when(col(colName) === functions.least(columns.map(col): _*), col(colName) + 1).otherwise(col(colName)).alias(colName)\n      }\n\n      val updatedDF = df.select(updatedColumns: _*)\n      updatedDF.show()\n\n",
"AnswerId": "76391170",
"AnswerBody": "Since each row is independent, then I think it is easier to iterate within the mapping function of each row until you get the final result, so that you don't have to iterate over the whole df multiple times.\nimport spark.implicits._\n\nval data = Seq(\n        (1, 2, 3, 4, 3),\n        (6, 7, 8, 1, 2),\n        (2, 4, 6, 8, 5)\n      )\n\nval columns = List(\"col1\", \"col2\", \"col3\", \"col4\", \"col5\")\nval arrayDf = spark.sparkContext.parallelize(data).map(row =>  {\n    var plates: List[Int] = row.productIterator.toList.map {case i: Int => i}\n    var store: Int = plates.last // Assuming last column is the store \n    plates = plates.dropRight(1) // remove the store column\n    (0 until store).toList.foreach(i => {\n        val min = plates.min\n        val index = plates.indexOf(min)\n        store -=1\n        plates = plates.updated(index, min + 1)\n    })\n    plates :+ store // Add the store at the end (which is always 0) \n}).toDF(Seq(\"result\"): _*)\n\n// Convert the list of result into columns again\nval df = arrayDf.select(columns.zipWithIndex.map{case (name, idx) => arrayDf(\"result\")(idx).alias(name)}: _*)\n\ndf.show()\n\n+----+----+----+----+----+\n|col1|col2|col3|col4|col5|\n+----+----+----+----+----+\n|   3|   3|   3|   4|   0|\n|   6|   7|   8|   3|   0|\n|   6|   5|   6|   8|   0|\n+----+----+----+----+----+\n\n"
},
{
"QuestionId": "76391470",
"QuestionTitle": "Powershell: -ErrorAction SilentlyContinue not working with Invoke-Expression",
"QuestionBody": "I am running this script\nInvoke-Expression $expression -ErrorAction SilentlyContinue\nThe variable $expression may not  have a value sometimes. When It's empty, I get the error\n\nCannot bind argument to parameter 'Command' because it is null.\n\nHow can I avoid seeing the error? I want to execute Invoke-Expression regardless of $expression being empty, so an if statement checking that $expression has a value wouldn't work.\n\n",
"AnswerId": "76392625",
"AnswerBody": "\nFirst, the obligatory warning:\n\nInvoke-Expression  (iex) should generally be avoided and used only as a last resort, due to its inherent security risks. Superior alternatives are usually available. If there truly is no alternative, only ever use it on input you either provided yourself or fully trust - see this answer.\n\n\nTo add to Mathias' helpful answer and zett42's simpler alternative mentioned in a comment on the question (Invoke-Expression \"$expression \"):\nThese solutions silence only the case where $null or an empty string is passed to Invoke-Expression - which may well be your intent.\nTo also cover the case where all error output should be silenced - whether due to invalid input or due to valid input causing errors during execution - the following variation is needed:\n# Silences *all* errors.\ntry { Invoke-Expression $expression 2>$null } catch { }\n\n# Alternative:\n# Silences *all* errors and additionally *ignores* all *non-terminating* errors, \n# i.e. not only silences them, but also prevents their recording in $Error.\n# By executing inside & { ... }, the effect of setting $ErrorActionPreference is \n# transitory due to executing in a *child scope*.\n# Note that this also means that $expression is evaluated in the child scope.\n& { $ErrorActionPreference = 'Ignore'; Invoke-Expression $expression }\n\nNote:\n\nFirst command:\n\nThe common -ErrorAction parameter fundamentally only acts on non-terminating errors, whereas terminating ones (both statement- and script-terminating ones) must be handled with a try / catch / finally statement.\n\nPassing $null or the empty string to Invoke-Expression causes an error during parameter binding (that is the, cmdlet itself is never invoked, because invalid arguments were passed), which in effect is a statement-terminating error - hence the need for try / catch.\n\nThe try / catch with the empty catch block additionally prevents script-terminating errors that result from the Invoke-Expression call from terminating your script too (e.g, if $expression contained something like 'throw \"Fatal Error\"'\n\n\n\nNote that -ErrorAction SilentlyContinue was replaced with 2>$null in order to silence non-terminating errors (e.g., the error resulting from Get-ChildItem NoSuchDir), because - inexplicably - -ErrorAction is not effective with Invoke-Expression (even though the -ErrorVariable common parameter does work, for instance). See GitHub issue #19734.\n\n\n\nSecond command:\n\nSetting the $ErrorActionPreference preference variable to Ignore causes all errors to be silenced, and additionally - for non-terminating errors only - prevents their recording in the automatic $Error variable.\n\nIf -ErrorAction worked in this case, -ErrorAction would have the same effect, but would act solely on non-terminating errors, as noted.  (This asymmetry between what should be equivalent mechanisms - preference variable vs. per-call common parameter, is one of the pitfalls of PowerShell's error handling - see GitHub issue #14819).\n\n\nUnfortunately, (caught) terminating errors are invariably recorded in $Error as of PowerShell 7.3.4. From what I can tell, changing this in a future version has been green-lit a while ago, but is yet to be implemented:  see GitHub issue #3768\n\nUsing &, the call operator with a script block { ... } executes the enclosed statements in a child scope.\n\nThis causes $ErrorActionPreference = 'Ignore' to create a local copy of the preference variable, which automatically goes out of scope when the script block is exited, thereby implicitly restoring the previous value of $ErrorActionPreference.\n\nHowever, this also means that the code executed by Invoke-Expression executes in that child scope.\nIf that is undesired, forgo the & { ... } enclosure and save and restore the previous $ErrorActionPreference value.\n\n\n\n\n"
},
{
"QuestionId": "76390816",
"QuestionTitle": "VBA Selenium Dynamic ID (Wildcard)",
"QuestionBody": "Is there a possibility to find an element by ID with an wildcard?\nI have something like this:\nstat = GC.FindElementByXPath(\"//*[@id='C29_W88_V90_V94_admin_status']\").Value\nstat = GC.FindElementByXPath(\"//*[@id='C26_W88_V90_V94_admin_status']\").Value\nstat = GC.FindElementByXPath(\"//*[@id='C29_W88_V12_V94_admin_status']\").Value\n\nThe admin_status part won't change but the values before.\nSometimes I have the same problem with another element with values around it. So the best thing would be to find the element with some wildcard like this:\nstat = GC.FindElementByXPath(\"//*[@id='*admin_status*']\").Value\n\n",
"AnswerId": "76392656",
"AnswerBody": "This code is tested in Excel VBA using Selenium.\nOption Explicit\nSub sbXPathContains()\n    Dim driver As ChromeDriver\n    Set driver = New ChromeDriver\n    Dim sURL As String\n    sURL = \"https://davetallett26.github.io/table.html\"\n    Call driver.Start(\"edge\")\n    driver.get (sURL)\n    driver.Window.Maximize\n    sbDelay (100000)\n    MsgBox driver.FindElementByXPath(\"//*[contains(@id, 'ctl03_txtCash')]\").Attribute(\"outerHTML\")\n    '                                 //* = any element  contains  @id = within id  'ctl03_txtCash' = string to find   .Attribute(\"outerHTML\") = return HTML of the element\n    sbDelay (100000)\n    driver.Quit\nEnd Sub\n\nSub sbDelay(delay As Long): Dim i As Long: For i = 1 To delay:  DoEvents: Next i: End Sub\n\n"
},
{
"QuestionId": "76390331",
"QuestionTitle": "Firebase Firestore Indexes issue: Oops, indexes failed to load",
"QuestionBody": "When I visit the Firebase Firestore Index page, it shows an issue as \"Oops, indexes failed to load!\". I inspect the error and it shows 429. When I view indexes through GCP, it shows as Failed to load indexes: Request throttled at the client by AdaptiveThrottler. We're in the Firebase Blaze plan and I do not see any quota limit reached. This particular account has 5 projects and all of the projects indicate this same issue. What would be the issue?\n\n",
"AnswerId": "76391176",
"AnswerBody": "firebase here\nThat looks off indeed. I can't reproduce myself, but I asked around and will post an update here when I hear back.\n\n7:57 AM PT: Engineering has acknowledged the problem, and is identifying potential causes.\n\n8:12 AM PT: The problem may be isolated to databases in Europe.\n\n9:23 AM PT: This only affects index creation and listing operations. It does not affect the ability read data from or write to the database. Sorry for not mentioning that earlier, as it was the first thing we determined when the problem was reported.\n\n9:29 AM PT: We've identified the root cause, which was a resource exhaustion issue in region eur3, and have increased resources in the region to mitigate.\n\n9:49 AM PT: This issue has been mitigated now. If you are still seeing this problem, please reach out to Firebase support for personalized help in troubleshooting.\nThe engineering team is planning work to prevent this problem from reoccurring in the future.\n\n\n"
},
{
"QuestionId": "76388475",
"QuestionTitle": "Ada2012: Assertion_Policy",
"QuestionBody": "According Ada2012 RM Assertion_Policy:\n\n10.2/3    A pragma Assertion_Policy applies to the named assertion aspects in a specific region, and applies to all assertion expressions\nspecified in that region. A pragma Assertion_Policy given in a\ndeclarative_part or immediately within a package_specification applies\nfrom the place of the pragma to the end of the innermost enclosing\ndeclarative region. The region for a pragma Assertion_Policy given as\na configuration pragma is the declarative region for the entire\ncompilation unit (or units) to which it applies.\n\nThis means that if I have a package hierarchy as per the following example:\n└───Root\n    ├───Child1\n    ├───Child2\n    │   └───GrandSon\n    └───Child3\n\nAnd if I define the pragma Assertion_Policy at Root package specification, it will affect to the whole package hierarchy right?\n",
"AnswerId": "76393618",
"AnswerBody": "\nAnd if I define the pragma Assertion_Policy at Root package\nspecification, it will affect to the whole package hierarchy right?\n\nNo.\nWhat your bolded text means is that (a) the pragma is placed immediately in a specification, like so:\nPragme Ada_2012;                -- Placed \"immediately\".\nPragma Assertion_Policy(Check); -- Also \"immediately\".\n\nPackage Some_Spec is --... and so on.\n\nor (b) in a declarative part:\nProcedure Outer_Scope is\n   Pragma Assertion_Polucy( Ignore ); -- Declarative region.\n   X : Some_Type:= Possibly_Assertion_Failing_Operation;\n   Package Inner_Scope is\n    -- the stuff in here would ALSO ignore assertions.\n   End Inner_Scope;\n   Package Body Inner_Scope is Separate;\nBegin\n  if X'Valid then\n    Null; -- Do things on the valid value of X.\n  end if; -- Because we're ignoring the invalid case.\nEnd Outer_Scope;\n\nSo, they apply not to children, but to the spec/body/declarative-region itself.\n"
},
{
"QuestionId": "76391482",
"QuestionTitle": "in ggplot2, print an expression in the facet_wrap",
"QuestionBody": "I want to plot some functions with their gradients using the ggplot2 package in r.\np = 3\nn0 = 100\nz0 = seq(0.01, 0.99, length = n0)\nAB0 = matrix(rbeta(600,4,1), nrow = n0)\n\nlibrary(ggplot2)\nab.names=c(paste(\"g\",1:p,sep=\"\"),paste(\"g' \",1:p,sep=\"\"))\npl0=ggplot(data.frame(ab = c(AB0), ID = rep(ab.names, each = n0), Z = z0),\n           aes(x = Z, y = ab)) +\n  geom_point() +\n  facet_wrap(~ID, scales = \"free\",nrow = 2, ncol = p) + theme_bw() +\n  ggtitle(\"Unpenalized VCM\",expression(nabla~\"g  and  \"~\"g\")) + ylab(\"\")\n\nI want to switch the rows and add the nabla symbol in the title of the plots in the 1st row before switching them to the second row. To be clear, the 1st row is for the functions, and the 2nd row is for the gradients where the nabla symbol should appear in the title.\nHere is a screenshot of the outcome\n\n",
"AnswerId": "76392685",
"AnswerBody": "the labeller argument to facet_wrap might come in handy, if you set it to \"label_parsed\". Example:\nd <- data.frame(x = rnorm(2),\n                y = rnorm(2),\n                ID = c(paste0('g~', 1:2),\n                       paste0('g~nabla~', 1:2)\n                       )\n                )\n\n\nd |>\n    ggplot(aes(x, y)) +\n    geom_point() +\n    facet_wrap(. ~ ID, \n               labeller = label_parsed,\n               nrow = 2\n               )\n\n\n"
},
{
"QuestionId": "76389930",
"QuestionTitle": "Easy to read scientific notation on Rails console",
"QuestionBody": "I have a Postgresql table column which's type is numeric(20,4). When I play with the data through rails console, ActiveRecord display the values in scientific notation.\nAll I can think of adding attribute :column_name, :float to the related modal, but not sure if there will be any side effects because of it.\nSo the question is; does anyone one if there is anything I can do to make it easier for reading the data on rails console and do not have any side effects on the app itself?\n",
"AnswerId": "76391235",
"AnswerBody": "You can monkeypatch specifically BigDecimal class specifically for console\ndevelopment.rb\n  console do\n    class BigDecimal\n      def inspect\n        to_f\n      end\n    end\n  end\n\n"
},
{
"QuestionId": "76389774",
"QuestionTitle": "Laravel auth()->id() not working in prod server",
"QuestionBody": "I have one seperate database for saving logs\nI have middleware that saves every request with response\n public function handle($request, Closure $next, $logType)\n    {\n        $response = $next($request);\n        CreateLog::dispatch($request, $response, $logType)->onQueue(config('queue.queues.logging'));\n        return $response;\n    }\n\nEverything related to auth progress works after every work complated. beacuse u used         $response = $next($request);\n'user_id' => auth()->id(),\n\nTrying to save user_id like that. Everything is working perfect\nBut in prod server user_id is being null\nIn prod server project running using docker\n",
"AnswerId": "76391268",
"AnswerBody": "you need to double check multiple things:\n\nwhat session driver are you using?\nwhat is the queue driver are you using?\nis your middleware runs after session and auth middleware runs ( based on the configuration in kernal.php )\n\nbased on your question and the problem is happening only on production so probably your issue is communication, your queue handler can't access session data which is usually the case if you separate them into different modules and connections to improve performance so to achieve this you need to pass the information you need from one module to another so in your case\npublic function handle($request, Closure $next, $logType)\n    {\n        $response = $next($request);\n        $userID = auth()->id();\n        CreateLog::dispatch($request, $response, $logType, $userID)->onQueue(config('queue.queues.logging'));\n        return $response;\n    }\n\nand in your CreateLog you store this userID and use it instead of depending on the auth\n"
},
{
"QuestionId": "76394054",
"QuestionTitle": "How can I get the maximum bid value in a blind auction?",
"QuestionBody": "I'm trying to create a blind auction as part of my class, and I'm trying to get the max value.\nHere is the code, I tried to use the max() function but I get this error:\nFile \"Day_9_Blind_Auction.py\", line 30, in <module>print(max(data))TypeError: '>' not supported between instances of 'dict' and 'dict'\n\nimport os\n\ndata = [\n    \n    \n    \n    ]\nwhile True:\n    name = input(\"What is your name?: \")\n    bid = input(\"What is your bid: $\")\n\n    other_user = input(\"Are there any other bidders? Type Yes or No.\\n\")\n    \n    if other_user in ['yes', 'Yes']:\n        os.system('cls')\n \n    def new_user(name, bid):\n        brandnew_user = {\n            name: bid\n            \n            },\n        \n        data.append(brandnew_user)\n        \n    new_user(name, bid)\n\n    \n    \n    if other_user in ['no', 'No']:\n        print(max(data))\n        break\n\nI tried to remove the max() and it prints the output totally fine.  But then I need to get the max value, which is I don't know how to do it.\nthis is the output if I removed the max() function:\n[({'George': '87'},), ({'Josh': '74'},), ({'Eduardo': '89'},)]\n\n",
"AnswerId": "76394106",
"AnswerBody": "You are trying to apply the max() function to a list of dictionaries.   The error message is telling you that you haven't specified how to tell when one dictionary is \"greater than\" another.\nIt is possible to add a definition for the '>' operator that would allow it to compare dictionaries, but it's probably better if you rethink the data structures you're using. A list of dictionaries, with only one key/value pair per dictionary, is kind of an awkward construction. Why not use one list for the names, another list for the bids, then use max() and indexof() to find the largest bid and get the corresponding name from the other list?\n"
},
{
"QuestionId": "76389312",
"QuestionTitle": "How can I securely manage my client's PayPal merchant account as a web developer freelancer?",
"QuestionBody": "Currently, when i need to access my customer's PayPal merchant account (to manage IPNs or to update notifications preferences for examples), i login to the account using his credentials and his 2FA (asking him the SMS code).\nIs there a feature similar to Stripe Team which allows team members to access a PayPal merchant dashboard with their own credentials? Right here i am talking about the account dashboard, not the developer dashboard, but my question applies to both!\nAll of this doesn't seem very efficient and secure, is there another way?\nAm i supposed to use my credentials only to develop the website (on developer.paypal.com) and never connect to the actual merchant's PayPal account? And ask the customer to do every manipulation on his account himself telling him the way?\n",
"AnswerId": "76391303",
"AnswerBody": "Typically you should only need to obtain API credentials to integrate with, which for current solutions are in the developer dashboard. Other account settings and operations in the account are not something web developers need access to, other than maybe some initial setup tweaks to the website preferences page. To the extent other settings matter, it is likely you are making wrong integration choices or using old legacy PayPal products (not good--for instance, you tagged the above with IPN -- what year is it? why would you be using IPN in 2023?)\nAnyway, it is possible to create and manage user access within a PayPal account. This is usually only used for in-house staff, not a vendor/contractor since you should not need it, but in theory it can be used for what you're asking.\n"
},
{
"QuestionId": "76391544",
"QuestionTitle": "import.meta.env.PROD runs in development mode",
"QuestionBody": "why below code run in the development mode? it should only run in production mode\nHere is the running scripts in package.json\n\"build-watch-dev\": \"vite build --mode development --watch\",\nimport { useStore } from '@/store';\nimport { register } from 'register-service-worker';\n\nexport function registerSW() {\n    if (import.meta.env.PROD) {\n        register(`${import.meta.env.BASE_URL}service-worker.js`, {\n            ready() {\n                console.log(\n                    'App is being served from cache by a service worker.\\n' +\n                    'For more details, visit \n                )\n            },\n            registered() {\n                console.log('Service worker has been registered.')\n            },\n            cached() {\n                console.log('Content has been cached for offline use.')\n            },\n            updatefound() {\n                console.log('New content is downloading.')\n            },\n            updated() {\n                console.log('New content is available; please refresh.');\n                const $store = useStore();\n                $store.serviceWorkerUpdate = true;\n            },\n            offline() {\n                console.log('No internet connection found. App is running in offline mode.')\n            },\n            error(error) {\n                const $store = useStore();\n                if ($store.isOnline) {\n                    console.error('Error during service worker registration:', error)\n                }\n            }\n        })\n    }\n}\n\n",
"AnswerId": "76392695",
"AnswerBody": "The --mode flag overrides the value of import.meta.env.MODE.\nimport.meta.env.PROD is effectively a boolean result of process.env.NODE_ENV === 'production'\nYou could try changing your conditional to something like:\nif (import.meta.env.MODE !== 'development') {\n\nOr you could look at setting NODE_ENV to development.\n"
},
{
"QuestionId": "76394111",
"QuestionTitle": "Typescript class made up of an array of other classes gives an error",
"QuestionBody": "So im trying to make a typescript file for a network and there are three files involved.\na _Node.ts, Edge.ts, and a Graph.ts\nThese three files look like so:\n_Node.ts\ninterface _Node {\n  data: any;\n  neighbours: number[];\n}\n\nclass _Node {\n  constructor(data) {\n    // this data is an arbitrary thing with which I can create any object\n    this.data = { ...data };\n    // the neighbours bit is explicity set from the code outside\n    this.neighbours = [];\n  }\n}\n\nexport { _Node };\n\nEdge.ts\ninterface Edge {\n  start: number;\n  end: number;\n  data: any;\n}\n\nclass Edge {\n  constructor(start, end, data) {\n    this.start = start;\n    this.end = end;\n    this.data = { ...data };\n  }\n}\n\nexport { Edge };\n\nGraph.ts\nimport { _Node } from \"./_Node\";\nimport { Edge } from \"./Edge\";\n\ninterface Graph {\n  nodes: _Node[];\n  edges: Edge[];\n}\n\nclass Graph {\n  constructor(nodes, edges) {\n    this.nodes = nodes;\n    this.edges = edges;\n    // execute Internal methods\n    // this.printData();\n  }\n\n  // test function\n  printData() {\n    const message =\n      \"This is a graph with \" +\n      this.nodes.size + // this gives an error \"Property size doesn't exist on nodes\"\n      \" nodes and \" +\n      this.edges.size +\n      \" edges\";\n    console.log(message);\n  }\n}\n\n\nThe last line of node.size and edges .size give a VS code error of something like the property size doesn't exist on them despite me declaring them as arrays of the nodes and things - is there a way to fix it?\n",
"AnswerId": "76394119",
"AnswerBody": "You're looking for\nthis.edges.length\nas specified by\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/length\nsize is not a valid property or function\n"
},
{
"QuestionId": "76384590",
"QuestionTitle": "Sqlalchemy count of records in the relation of one to many",
"QuestionBody": "Help me figure out what I'm doing wrong?\nI need to get the number of comments in 24 hours in the relation one-to-many table.\nclass Comment(Base):\n    __tablename__ = 'comments'\n    id = Column(Integer, primary_key=True)\n    task_id = Column(Integer(), ForeignKey('tasks.id'), nullable=False)\n    post_link = Column(String, nullable=False)\n    date = Column(DateTime, default=datetime.datetime.utcnow())\n\n    def __init__(self, task_id: int, post_link: str):\n        super().__init__()\n        self.task_id = task_id\n        self.post_link = post_link\n\n    def __repr__(self):\n        return f'id - {self.id} | task_id - {self.task_id} | date - {self.date}'\n\nclass Task(Base):\n    __tablename__ = 'tasks'\n    id = Column(Integer, primary_key=True)\n    name = Column(String, nullable=False)\n\n    comments = relationship('Comment', backref='tasks', lazy=True)\n\n    def __init__(self, name: str):\n        super().__init__()\n        self.name = name\n\n    def __repr__(self):\n        return f'id - {self.id} | name - {self.name}'\n\n\nI don't know if the query works correctly or if it even outputs the number of records.\nHere's the request itself:\nasync def get_comments_for_day():\n    start_day = datetime.utcnow() - timedelta(hours=23, minutes=50)\n    async with get_async_session() as session:\n        stmt = select(Comment.task_id, func.count(Comment.task_id).label('comments_found'))\\\n            .where(Comment.date >= start_day).subquery()\n        main_stmt = select(Task, stmt.c.comments_found).outerjoin(stmt, Task.id == stmt.c.task_id)\n        results = await session.execute(main_stmt)\n        return results.scalars().all()\n\nasync def main():\n    tasks = await get_comments_for_day()\n    for task, comments_found in tasks:\n        print(task.name, comments_found)\n\nI get this error:\n    for task, comments_found in tasks:\nTypeError: cannot unpack non-iterable Task object\n\n",
"AnswerId": "76391320",
"AnswerBody": "async def get_comments_for_day():\n    start_day = datetime.utcnow() - timedelta(hours=24)\n    async with get_async_session() as session:\n        stmt = (\n            select(func.count(Comment.id), Task)\n            .select_from(Task)\n            .join(Comment, Task.id == Comment.task_id, isouter=True)\n            .where(Comment.date >= start_day)\n            .group_by(Task.id, Task.name)\n        )\n        results = await session.execute(stmt)\n        return results.all()\n\nIf you're interested, I found a solution to the problem, which was to write return results.all() instead of return results.execute().all().\n"
},
{
"QuestionId": "76389324",
"QuestionTitle": "How to change the tag column selection option",
"QuestionBody": "I have a tag column in the active admin index page like\ntag_column :result, interactive: true, sortable: false\n\nin my model I have a enum for result as\n enum result: { winner: 0, first_runner_up: 1, second_runner_up: 2}\n\nIn the index page when I click on drop down the selection options are being dispalyed as\nwinner\nfirst_runner_up\nsecond_runner_up\nHow can we display them as\nWinner\nFirst Runner Up\nSecond Runner Up\nCan someone please help...\nThank you in advance\n",
"AnswerId": "76391414",
"AnswerBody": "I suggest you break the rules out to a hash.. then you will be free to validate against them later\nWINNER_OPTIONS = {\n  winner: {\n    title: \"Winner\"\n  },\n  second: {\n    title: \"First Runner Up\"\n  },\n  third: {\n    title: \"Second Runner Up\"\n  }\n\nRESULT_ENUMS = WINNER_OPTIONS\n  .keys\n  .with_index\n  .to_h\n\nenum result: RESULT_ENUMS\n\ntag_column :result, WINNER_OPTIONS.values.map{|e| e[:title]}.with_index.to_h\n\n"
},
{
"QuestionId": "76390202",
"QuestionTitle": "How can I move specific values from one field in a JSON column to another in PostgreSQL?",
"QuestionBody": "Let's assume I have a table users with a JSON column \"foo\". Values of that column look like this:\n\"{ field1: ['bar', 'bar2', 'bar3'], field2: ['baz', 'baz2', 'baz3'] }\"\n\nwhere field1 and field2 are optional, so column value may look like this: \"{}\"\nI want to move values 'bar2' and 'bar3' from field1 to field2 for all records in this table.\nSample Output:\n\"{ field1: ['bar'], field2: ['baz', 'baz2', 'baz3', 'bar2', 'bar3']}\"\n\nMore examples:\n\"{ field1: ['bar3'], field2: ['baz', 'baz2', 'baz3'] }\"\n\nshould be transformed into\n\"{ field1: [], field2: ['baz', 'baz2', 'baz3', 'bar3'] }\"\n\netc.\nIs there any way to do this?\nUnfortunately I have no idea how to approach this problem.\n",
"AnswerId": "76391507",
"AnswerBody": "Using a series of subqueries with jsonb_array_elements\nselect jsonb_build_object('field1', coalesce((select jsonb_agg(v.value) \n       from jsonb_array_elements(u.foo -> 'field1') v \n       where v.value#>>'{}' not in ('bar2', 'bar3')), '[]'::jsonb),\n   'field2', (u.foo -> 'field2') || (select jsonb_agg(v.value) \n       from jsonb_array_elements(u.foo -> 'field1') v \n       where v.value#>>'{}' in ('bar2', 'bar3'))) \nfrom users u \nwhere u.foo ? 'field1' and u.foo ? 'field2'\n\nSee fiddle\n"
},
{
"QuestionId": "76391464",
"QuestionTitle": "How to add a list of specific object in a configuration file for a WorkerService",
"QuestionBody": "As far as what I understand:\n\nWorkerService is the new way to define a Windows Service (app that run as as service).\nBy default, using the contextual menu on the project, the type of configuration file associated to a WorkerService is stil a xaml file: \"App.config\". See: How to: Add an application configuration file to a C# project\nAccording to Microsoft documentation, I understand that I should use the section <appsettings>.\n\nappSettings is a dictionary of key value pair. But I can't find how to add a list of item as the value. Also, I would like to add my own object as the value if possible.\nIs there a way to add a List of MyConfigObject (List<MyConfigObject>)into a config file? If yes, how? Should I use another section or should I use another type of config file (json, yaml) to have the simplest way to read/write settings?\n",
"AnswerId": "76392770",
"AnswerBody": "Yes, you can, Like this:\nappsettings.json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Microsoft\": \"Warning\",\n      \"Microsoft.Hosting.Lifetime\": \"Information\"\n    }\n  },\n  \"AllowedHosts\": \"*\",\n  \"MyConfigObject\": [\n    {\n      \"Prop1\": \"1\",\n      \"Prop2\": \"2\"\n    },\n    {\n      \"Prop1\": \"1\",\n      \"Prop2\": \"2\"\n    }\n  ]\n}\n\nMyConfigObject Class\npublic class MyConfigObject\n{\n    public string Prop1 { get; set; }\n    public string Prop2 { get; set; }\n}\n\nIn Startup, register the Configuration with the type MyConfigObject. Like this:\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddControllersWithViews();\n        services.Configure<List<MyConfigObject>>(Configuration.GetSection(\"MyConfigObject\"));\n    }\n\nNow you can use it in any service or controller, like this:\npublic class HomeController : Controller\n    {\n        private readonly ILogger<HomeController> _logger;\n        private readonly List<MyConfigObject> myConfig;\n        public HomeController(IOptions<List<MyConfigObject>> myConfig, ILogger<HomeController> logger)\n        {\n            _logger = logger;\n            this.myConfig = myConfig.Value;\n        }\n\n        public IActionResult Index()\n        {\n            return View();\n        }\n}\n\n"
},
{
"QuestionId": "76391280",
"QuestionTitle": "redux tookit when using a middleware builder function, an array of middleware must be returned",
"QuestionBody": "So I'm getting Uncaught Error: when using a middleware builder function, an array of middleware must be returned\nThis is my code\nimport {\n  configureStore,\n  compose,\n  combineReducers,\n  applyMiddleware\n} from \"@reduxjs/toolkit\";\nimport thunk from \"redux-thunk\";\n\nconst rootReducer = combineReducers({});\n\nconst middleware = applyMiddleware(thunk);\nconst composeWithDevTools = \n  window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ || compose;\nconst composedMiddleWare = composeWithDevTools(middleware)\n\nconst store = configureStore({\n  reducer: rootReducer,\n  middleware: composedMiddleWare,\n  devTools: \n    window.__REDUX_DEVTOOLS_EXTENSION__ && window.__REDUX_DEVTOOLS_EXTENSION__()\n})\n\nexport default store;\n\nI have no idea what's wrong and searching doesn't seem to be returning any useful result.\n",
"AnswerId": "76392775",
"AnswerBody": "configureStore from redux-toolkit (RTK) works differently from the redux createStore function. The middleware property accepts an array of middleware to install and RTK handles applying them.\nSee configureStore\n\n/**\n * An array of Redux middleware to install. If not supplied, defaults to\n * the set of middleware returned by `getDefaultMiddleware()`.\n */\nmiddleware?: ((getDefaultMiddleware: CurriedGetDefaultMiddleware<S>) => M) | M\n\n\nNote that while applyMiddleware is re-exported from redux that\n\nYou should not need to use this directly.\n\nThe following would be the code you'd use:\nimport { configureStore, combineReducers } from \"@reduxjs/toolkit\";\nimport thunk from \"redux-thunk\";\n\nconst rootReducer = combineReducers({});\n\nconst store = configureStore({\n  reducer: rootReducer,\n  middleware: [thunk], // <-- array of middlewares to install/apply\n  devTools: window.__REDUX_DEVTOOLS_EXTENSION__ && window.__REDUX_DEVTOOLS_EXTENSION__()\n});\n\nexport default store;\n\nRTK also ships with opinionated optimizations:\n\nThe devTools are enabled by default, you'll only use this if you have custom needs.\n\nThunk middleware is also already included with the default middleware, e.g. if no middleware property is provided, then getDefaultMiddleware is provided and returns the following middleware value, which includes the thunk middleware:\nconst middleware = [\n  actionCreatorInvariant,\n  immutableStateInvariant,\n  thunk, // <-- included thunk middleware!\n  serializableStateInvariant,\n]\n\nAgain, you'll really only need to specify the middleware property if you need to customize the immutability or serialization middlewares.\n\n\nYour store configuration can be reduced to the following:\nimport { configureStore, combineReducers } from \"@reduxjs/toolkit\";\n\nconst rootReducer = combineReducers({});\n\nconst store = configureStore({\n  reducer: rootReducer,\n});\n\nexport default store;\n\nBoth the thunk middleware and dev tools will be active and working.\n"
},
{
"QuestionId": "76390228",
"QuestionTitle": "upsert_item into cosmosdb via python",
"QuestionBody": "I have a this code:\nimport logging\nimport json\nimport os\nfrom azure.cosmos import CosmosClient\nimport azure.functions as func\n\nurl = os.environ[\"ACCOUNT_URI\"]\nkey = os.environ[\"ACCOUNT_KEY\"]\nclient1 = CosmosClient(url, key)\nclient = CosmosClient.from_connection_string(os.environ[\"CosmosDBConnStr\"])\n\ndatabase_name = \"dmdb\"\ncontainer_name = \"DataContract\"\n\ndatabase = client.get_database_client(database_name)\ncontainer = database.get_container_client(container_name)\n\nlogging.info(f\"container: {url}\")\ndef main(myblob: func.InputStream, doc: func.Out[func.Document]):\n    logging.info(f\"Python blob trigger function processed blob \\n\"\n                 f\"Name: {myblob.name}\\n\")\n    #reading file from blob\n    contract_data=myblob.read()  \n    \n    try:\n        logging.info(f\"contract data: {contract_data}\")\n        contract_json = json.loads(contract_data)       \n        version = contract_json.get(\"version\")\n        name = contract_json.get(\"name\")\n        title = contract_json.get(\"title\")\n        logging.info(f\"contract json: {contract_json}\")\n        query = \"SELECT c.version,c.name,c.title,c.Theme,c.description,c['data owner'],c.confidentiality,c.table1 FROM c \"\n      \n       \n        items = list(container.query_items(\n            query=query,\n            enable_cross_partition_query=True\n        ))\n        logging.info(f\"item: {items[0]}\")\n        for item in items:\n            if item[\"name\"] == name and item[\"version\"] == version:\n                if item[\"title\"] == title:\n                    logging.info(f\"Skipping, item already exists: {item}\")\n                    return  # Skip saving the document\n                \n                container.upsert_item(body=contract_json,pre_trigger_include = \n                None,post_trigger_include= None)\n                return\n\n        doc.set(func.Document.from_json(contract_data))\n                       \n    except Exception as e:\n            logging.info(f\"Error: {e}\")\n\nI added one document in my cosmosdb, I would like to replace same document has different title. but i could not do that i am getting  Code: BadRequest\nMessage: Message: {\"Errors\":[\"One of the specified inputs is invalid\"]}\nthis is an example of item from my query:\n{'version': 'V1', 'name': 'demo_contract2', 'title': 'title122', 'Theme': 'Theme12', 'description': 'test data contract management2', 'data owner': 'j.jansen@amsterdam.nl', 'confidentiality': 'open', 'table1': {'description:': 'testen', 'attribute_1': {'type': 'int', 'description:': 'testen', 'identifiability': 'identifiable'}}}\n\nthis is an example of contract_json from my file:\n{'version': 'V1', 'name': 'demo_contrac1', 'title': 'title1', 'Theme': 'Theme1', 'description': 'test data contract management2', 'data owner': 'j.jansen@amsterdam.nl', 'confidentiality': 'open', 'table1': {'description:': 'testen', 'attribute_1': {'type': 'int', 'description:': 'testen', 'identifiability': 'identifiable'}}}\n\nthey are matching. How should I regulate my upsert_item function in my code?\n",
"AnswerId": "76391647",
"AnswerBody": "You are missing the id in the Upsert content. A document's identity is defined by the combination of id and Partition Key value, if you don't specify the id then Upsert will always behave as a Create operation.\nBecause you are getting the items through a query, just add the id:\nquery = \"SELECT c.id, c.version,c.name,c.title,c.Theme,c.description,c['data owner'],c.confidentiality,c.table1 FROM c \"\n     \n\nYou can now get the id from item[\"id\"] to use if needed. The body of the Upsert operation should contain id, and if that matches with an existing document, then the document will get updated.\n"
},
{
"QuestionId": "76381180",
"QuestionTitle": "Different intercept values for linear regression using statsmodels and numpy polyfit",
"QuestionBody": "I get two different intercept values from using the statsmodels regression fit and the numpy polyfit. The model is a simple linear regression with a single variable.\nFrom the statsmodels regression I use:\nresults1 = smf.ols('np.log(NON_UND) ~ (np.log(Food_consumption))', data=Data2).fit()\n\nWhere I recieve the following results:\n                               coef    std err          t      P>|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------------\nIntercept                    5.4433      0.270     20.154      0.000       4.911       5.976\nnp.log(Food_consumption)     1.1128      0.026     42.922      0.000       1.062       1.164\n\nWhen plotting the data and adding a trendline using numpy polyfit, I recieve a different intercept value:\nx = np.array((np.log(Data2.Food_consumption)))\ny = np.array((np.log(Data2.NON_UND)*100))\n\nz = np.polyfit(x, y, 1)\n\narray([ 1.11278898, 10.04846693])\n\nHow come I get two different values for the intercept?\nThanks in advance!\n",
"AnswerId": "76394128",
"AnswerBody": "This is because you are using different linear models in the first and second regressions. In the first regression, you take logs of both the dependent and independent variables, while in the second regression, you are not, and additionally, you are multiplying y by 100.\nIn order to get the same results as the first regression in the second specification, you need to make sure the regression model is exactly the same as the first one. I suggest you do this:\nx = np.log(np.array(((Data2.Food_consumption))))\ny = np.log(np.array(((Data2.NON_UND))))\n\nz = np.polyfit(x, y, 1)\n\nAnd then the output you get with the second function should be the same as the one you get in the first one.\n"
},
{
"QuestionId": "76390103",
"QuestionTitle": "I want get documents using ObjectId, but it's not getting that document",
"QuestionBody": "I am new to MongoDB and trying to get multiple documents using ObjectId\nBelow I have mentioned the demo data format.\ndb={\n\"store\": [\n{\n  \"_id\": ObjectId(\"63da2f1f7662144569f78ddd\"),\n  \"name\": \"bat\",\n  \"price\": 56,\n  \n},\n{\n  \"id\": ObjectId(\"63da2f1f7662144569f78ddc\"),\n  \"name\": \"ball\",\n  \"price\": 58,\n  \n},\n{\n  \"id\": ObjectId(\"63da2f1f7662144569f78ddb\"),\n  \"name\": \"cap\",\n  \"price\": 100,\n  \n},\n{\n  \"id\": ObjectId(\"63da2f1f7662144569f78dda\"),\n  \"name\": \"red\",\n  \"price\": 50,\n  \n},\n\n]}\n\nand my query is this\ndb.store.aggregate([\n{\n$match: {\n  id: {\n    $in: [\n      ObjectId(\"63da2f1f7662144569f78ddd\"),\n      ObjectId(\"63da2f1f7662144569f78ddb\"),\n      ObjectId(\"63da2f1f7662144569f78dda\")\n    ]\n  }\n}\n},\n{\n$group: {\n  _id: null,\n  totalPrice: {\n    $sum: \"$price\"\n  }\n}\n},\n{\n$project: {\n  _id: 0,\n  \n}\n}\n])\n\nand output is\n[\n{\n\"totalPrice\": 150\n}\n]\n\nbut I'm getting objectid like this\n{\n  \"ids\": \n  [\"63da2f1f7662144569f78ddd\",\"63da2f1f7662144569f78ddb\",\"63da2f1f7662144569f78dda\"]\n}\n\nif I pass this array it's not getting any documents. How can I pass this array in place of objectids????\n",
"AnswerId": "76391730",
"AnswerBody": "For your case, you can simply wrap the payload from client in a $map to convert them into ObjectIds with $toObjectId\ndb.store.aggregate([\n  {\n    $match: {\n      $expr: {\n        \"$in\": [\n          \"$id\",\n          {\n            \"$map\": {\n              // your payload from client here\n              \"input\": [\n                \"63da2f1f7662144569f78ddd\",\n                \"63da2f1f7662144569f78ddb\",\n                \"63da2f1f7662144569f78dda\"\n              ],\n              \"as\": \"id\",\n              \"in\": {\n                \"$toObjectId\": \"$$id\"\n              }\n            }\n          }\n        ]\n      }\n    }\n  },\n  {\n    $group: {\n      _id: null,\n      totalPrice: {\n        $sum: \"$price\"\n      }\n    }\n  },\n  {\n    $project: {\n      _id: 0,\n      \n    }\n  }\n])\n\nMongo Playground\n"
},
{
"QuestionId": "76392245",
"QuestionTitle": "PHP Issue with array not printing the first element of the array",
"QuestionBody": "I have an issue I cannot seem to fix. I have a function that takes a file and converts it to an array using the first row as the keys:\nfunction parseCSVToArray($filePath)\n{\n    $csvData = [];\n\n    if (($handle = fopen($filePath, \"r\")) !== false) {\n        $keys = fgetcsv($handle); // Get the first row as keys\n\n        while (($data = fgetcsv($handle)) !== false) {\n            $rowData = array();\n            foreach ($keys as $index => $key) {\n                $rowData[$key] = $data[$index] ?? ''; // Assign each value to its corresponding key\n            }\n            $csvData[] = $rowData;\n        }\n\n        fclose($handle);\n    }\n    return $csvData;\n}\n\nEverything works as normal and creates the array as expected:\n$getTheRecords = parseCSVToArray('Data/records.csv');\n\n// File contents\nrecord,subdomain,hub_knows,domain,type,value,action,rationale\nmail.sub.domain.com.,sub.domain.com,Hub knows about this,domain.com,CNAME,dispatch.domain.com.,DELETE,Dispatch links can go\n\nArray\n(\n    [record] => mail.sub.domain.com\n    [subdomain] => sub.domain.com\n    [hub_knows] => Hub knows about this\n    [domain] => domain.com\n    [type] => CNAME\n    [value] => dispatch.domain.com.\n    [action] => DELETE\n    [rationale] => Dispatch links can go\n)\n\nNow the issue is when I go to use or print the data. When I loop through the array using:\nforeach($getTheRecords as $element)\n{\n    echo \"<div style='margin-bottom: 20px'>\";\n    echo($element['subdomain']); // This will print the subdomain as expected.\n    echo \"</div>\";\n}\n\nIf I change 'subdomain' to 'record' it prints nothing. However, every other 'key' prints the results just fine.\nThank you in advance for your help!\nI have tried changing the name of the first key to 'mainrecord' or anything and it still will not print out.\nIside loop var_dmup():\narray(8) {\n  [\"record\"]=>\n  string(31) \"mail.0lemonade.starchapter.com.\"\n  [\"subdomain\"]=>\n  string(25) \"0lemonade.starchapter.com\"\n  [\"hub_knows\"]=>\n  string(20) \"Hub knows about this\"\n  [\"domain\"]=>\n  string(17) \"scdomaintest3.com\"\n  [\"type\"]=>\n  string(5) \"CNAME\"\n  [\"value\"]=>\n  string(22) \"dispatch.scnetops.com.\"\n  [\"action\"]=>\n  string(6) \"DELETE\"\n  [\"rationale\"]=>\n  string(21) \"Dispatch links can go\"\n}\n\n",
"AnswerId": "76392789",
"AnswerBody": "Your file likely has a UTF8 Byte Order Mark [BOM] at the beginning which is throwing off the first key. While a BOM isn't necessary at all for UTF8, some programs still add it as a \"hint\" that the file is UTF8.\nIf you var_dump($keys[0], bin2hex($keys[0]) you'll likely see that the first key's is longer than what is visible, and the hex output will show it prefixed with EFBBBF which is the BOM.\nTry replacing:\n$keys = fgetcsv($handle);\n\nWith:\n$keys = str_getcsv(preg_replace(\"/^\\xef\\xbb\\xbf/\", \"\", fgets($handle))); \n\nWhich will trim off the BOM, if it exists.\nEdit: A bit more broadly-applicable code.\nfunction stream_skip_bom($stream_handle) {\n    if( ! stream_get_meta_data($stream_handle)['seekable'] ) {\n        throw new \\Exception('Specified stream is not seekable, and cannot be rewound.');\n    }\n    \n    $pos = ftell($stream_handle);\n    $test = fread($stream_handle, 3);\n    \n    if( $test !== \"\\xef\\xbb\\xbf\" ) {\n        fseek($stream_handle, $pos);\n    }\n}\n\nso after opening $handle you would call simply:\nstream_skip_bom($handle);\n\n"
},
{
"QuestionId": "76392254",
"QuestionTitle": "Firestore subscribed document change type",
"QuestionBody": "Whenever I subscribe to a collection of documents, I'm able to extract the changes to the documents, given that the listener returns DocumentChange. This way I can understand whether a given doc was created, modified or deleted.\nHow to get the DocumentChange when subscribing to a single document in the collection? The issue appears to be that this time the listener returns DocumentSnapshot instead of DocumentChange.\n",
"AnswerId": "76392834",
"AnswerBody": "The DocumentSnapshot contains everything you need to know about that one document.  Either it exists() with data, or it does not.  You can check this state with each new snapshot for that one document, and react to that any way you like.  Since you are not performing a query with variable set of results, there is no need for more information.\n"
},
{
"QuestionId": "76394114",
"QuestionTitle": "Is it possible to deselect a ttk.Radiobutton?",
"QuestionBody": "These are the ttk.radiobuttons I am using:\n    def radioButtonGen(self):\n        self.var = tk.IntVar()\n        self.arithButton = ttk.Radiobutton(self, text = \"Arithmetic Series\", variable = self.var, value = 1, command = lambda: self.buttons.seqChoice(\"arithmetic\"))\n        self.geomButton = ttk.Radiobutton(self, text = \"Geometric Series\", variable = self.var, value = 2, command = lambda: self.buttons.seqChoice(\"geometric\"))\n\nI have attempted to deselect them with deselect() but it only works for tk.radiobuttons, which don't look as good and the method still leaves them with a dash.\nI want to deselect them so they are not highlighted\n",
"AnswerId": "76394144",
"AnswerBody": "Use the associated tkinter variable to deselect them:\nself.var.set(0)\n\n"
},
{
"QuestionId": "76392055",
"QuestionTitle": "How to match multiple occurrences of strings given a start and end pattern in R?",
"QuestionBody": "library(stringr)\nstring <- string <- c(\"pat1 hello333\\n pat2 ok i mean pat1 again pat2 some more text pat1\")\n\nI want to match all strings that start with pat1 and end with pat2.\n> str_extract_all(\n  string,\n  regex(\n    \"pat1.+pat2\",\n    dotall=TRUE\n  )\n)\n[[1]]\n[1] \"pat1 hello333\\n pat2 ok i mean pat1 again pat2\"\n\nThis gives me 1 string that starts with pat1 and ends with pat2. However, my desired output is something like:\n> output\n[1] \"pat1 hello333\\n pat2\"\n[2] \"pat1 again pat2\"\n\n",
"AnswerId": "76392839",
"AnswerBody": "Change .+ to .+? to have non greedy match.\nlibrary(stringr)\nstr_extract_all(string, regex(\"pat1.+?pat2\", dotall=TRUE))[[1]]\n#[1] \"pat1 hello333\\n pat2\" \"pat1 again pat2\" \n\nYou can use gregexpr and regmatches with pat1.*?pat2 or in case they should be on a word boundary with \\\\bpat1\\\\b.*?\\\\bpat2\\\\b. Where .*? matches everything but minimal.\nregmatches(string, gregexpr(\"pat1.*?pat2\", string))[[1]]\n#[1] \"pat1 hello333\\n pat2\" \"pat1 again pat2\"     \n\nregmatches(string, gregexpr(\"\\\\bpat1\\\\b.*?\\\\bpat2\\\\b\", string))[[1]]\n#[1] \"pat1 hello333\\n pat2\" \"pat1 again pat2\"     \n\n"
},
{
"QuestionId": "76390407",
"QuestionTitle": "How can I programmatically add a tab to a GTKmm notebook in C++?",
"QuestionBody": "I'm working on a GTKmm application(a simple text editor, as an exercise), in which I have a notebook to which I want to add a tab. The notebook shows, but the newly added tab doesn't.\nI'm doing it in the following way:\nvoid MainWindow::AddTabToNotebook()\n{\n    Gtk::Box box;\n\n    notebook->append_page(box);\n\n    notebook->show_all();\n}\n\nMainWindow is a class that inherits Gtk::Window and contains a pointer to Gtk::Notebook which is loaded from a Glade file using Gtk::Builder. Whenever I click the button that calls the function I get the following message in the terminal: Gtk-CRITICAL **: gtk_notebook_get_tab_label: assertion 'list != NULL' failed. Any help is appreciated.\nMainWindow.h:\n#ifndef MAIN_WINDOW_H\n#define MAIN_WINDOW_H\n\n#include <gtkmm.h>\n\nclass MainWindow : public Gtk::Window\n{\nprotected:\n    \n    Gtk::Button* buttonOpenFile;\n    Gtk::Button* buttonSave;\n    Gtk::Button* buttonSaveAs;\n    \n    Gtk::Button *dialogButonOpen;\n    Gtk::TextView *text;\n    Gtk::MenuButton *buttonMenu;\n    Gtk::Notebook *notebook;\n\n    Gtk::FileChooserDialog *openFileDialog;\n\n    Glib::RefPtr<Gtk::Builder> builder;\n    void AddTabToNotebook();\n    void OnButtonOpenFileClick();\n    void OnButtonSaveClick();\n    void OnButtonSaveAsClick();\n    void OnFileChosen();\n    void OnDialogButtonOpenClick();\n\npublic:\n    MainWindow(BaseObjectType *cobject, const Glib::RefPtr<Gtk::Builder> &refGlade);\n    ~MainWindow();\n};\n#endif\n\nMainWindow.cpp:\n\n#include\"MainWindow.h\"\n#include<iostream>\n#include<gtkmm.h>\n\nMainWindow::MainWindow(BaseObjectType *cobject, const Glib::RefPtr<Gtk::Builder> &refGlade)\n    :Gtk::Window(cobject),\n    builder(refGlade)\n{\n    builder->get_widget(\"buttonOpenFile\", buttonOpenFile);\n    builder->get_widget(\"buttonSave\", buttonSave);\n    builder->get_widget(\"buttonSaveAs\", buttonSaveAs);\n    builder->get_widget(\"buttonMenu\", buttonMenu);\n    builder->get_widget(\"openFileDialog\", openFileDialog);\n    builder->get_widget(\"dialogButtonOpen\", dialogButonOpen);\n    builder->get_widget(\"notebook\", notebook);\n\n    buttonOpenFile->signal_clicked().connect(sigc::mem_fun(*this, &MainWindow::OnButtonOpenFileClick));\n    dialogButonOpen->signal_clicked().connect(sigc::mem_fun(*this, &MainWindow::OnDialogButtonOpenClick));\n    buttonSave->signal_clicked().connect(sigc::mem_fun(*this, &MainWindow::AddTabToNotebook));\n\n    show_all_children();\n}\nMainWindow::~MainWindow()\n{}\nvoid MainWindow::OnButtonOpenFileClick()\n{\n    if(openFileDialog)\n    {\n        openFileDialog->show();\n    }\n}\nvoid MainWindow::OnDialogButtonOpenClick()\n{\n    auto file=openFileDialog->get_file();\n    std::cout<<file->get_path();\n\n    if(openFileDialog)\n    {\n        openFileDialog->close();\n    }\n}\nvoid MainWindow::AddTabToNotebook()\n{\n    Gtk::Box box;\n    \n    notebook->append_page(box);\n\n    notebook->show_all();\n    \n}\n\nThe glade file:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- Generated with glade 3.38.2 -->\n<interface>\n  <requires lib=\"gtk+\" version=\"3.24\"/>\n  <object class=\"GtkWindow\" id=\"MainWindow\">\n    <property name=\"name\">MainWindow</property>\n    <property name=\"width-request\">800</property>\n    <property name=\"height-request\">600</property>\n    <property name=\"can-focus\">False</property>\n    <child>\n      <object class=\"GtkViewport\">\n        <property name=\"visible\">True</property>\n        <property name=\"can-focus\">False</property>\n        <child>\n          <object class=\"GtkBox\">\n            <property name=\"visible\">True</property>\n            <property name=\"can-focus\">False</property>\n            <property name=\"orientation\">vertical</property>\n            <child>\n              <object class=\"GtkBox\">\n                <property name=\"height-request\">30</property>\n                <property name=\"visible\">True</property>\n                <property name=\"can-focus\">False</property>\n                <property name=\"valign\">start</property>\n                <property name=\"hexpand\">True</property>\n                <child>\n                  <object class=\"GtkButton\" id=\"buttonOpenFile\">\n                    <property name=\"label\" translatable=\"yes\">Open file</property>\n                    <property name=\"name\">buttonOpenFile</property>\n                    <property name=\"visible\">True</property>\n                    <property name=\"can-focus\">True</property>\n                    <property name=\"receives-default\">True</property>\n                    <property name=\"tooltip-text\" translatable=\"yes\">Open a file</property>\n                    <signal name=\"clicked\" handler=\"OnButtonOpenFileClicked\" swapped=\"no\"/>\n                  </object>\n                  <packing>\n                    <property name=\"expand\">False</property>\n                    <property name=\"fill\">True</property>\n                    <property name=\"position\">0</property>\n                  </packing>\n                </child>\n                <child>\n                  <object class=\"GtkButton\" id=\"buttonSave\">\n                    <property name=\"label\" translatable=\"yes\">Save changes</property>\n                    <property name=\"name\">buttonSave</property>\n                    <property name=\"visible\">True</property>\n                    <property name=\"can-focus\">True</property>\n                    <property name=\"receives-default\">True</property>\n                    <property name=\"tooltip-text\" translatable=\"yes\">Save changes to the current document</property>\n                    <signal name=\"clicked\" handler=\"OnButtonSaveChangesClicked\" swapped=\"no\"/>\n                  </object>\n                  <packing>\n                    <property name=\"expand\">False</property>\n                    <property name=\"fill\">True</property>\n                    <property name=\"position\">1</property>\n                  </packing>\n                </child>\n                <child>\n                  <object class=\"GtkButton\" id=\"buttonSaveAs\">\n                    <property name=\"label\" translatable=\"yes\">Save As...</property>\n                    <property name=\"name\">buttonSaveAs</property>\n                    <property name=\"visible\">True</property>\n                    <property name=\"can-focus\">True</property>\n                    <property name=\"receives-default\">True</property>\n                    <signal name=\"clicked\" handler=\"OnButtonSaveAsClicked\" swapped=\"no\"/>\n                  </object>\n                  <packing>\n                    <property name=\"expand\">False</property>\n                    <property name=\"fill\">True</property>\n                    <property name=\"position\">2</property>\n                  </packing>\n                </child>\n                <child>\n                  <object class=\"GtkMenuButton\" id=\"buttonMenu\">\n                    <property name=\"name\">buttonMenu</property>\n                    <property name=\"visible\">True</property>\n                    <property name=\"can-focus\">True</property>\n                    <property name=\"focus-on-click\">False</property>\n                    <property name=\"receives-default\">True</property>\n                    <property name=\"use-popover\">False</property>\n                    <signal name=\"toggled\" handler=\"OnButtonMenuToggled\" swapped=\"no\"/>\n                    <child>\n                      <placeholder/>\n                    </child>\n                  </object>\n                  <packing>\n                    <property name=\"expand\">False</property>\n                    <property name=\"fill\">True</property>\n                    <property name=\"pack-type\">end</property>\n                    <property name=\"position\">3</property>\n                  </packing>\n                </child>\n                <child>\n                  <placeholder/>\n                </child>\n                <child>\n                  <placeholder/>\n                </child>\n              </object>\n              <packing>\n                <property name=\"expand\">False</property>\n                <property name=\"fill\">True</property>\n                <property name=\"position\">0</property>\n              </packing>\n            </child>\n            <child>\n              <object class=\"GtkViewport\">\n                <property name=\"height-request\">780</property>\n                <property name=\"visible\">True</property>\n                <property name=\"can-focus\">False</property>\n                <child>\n                  <object class=\"GtkScrolledWindow\">\n                    <property name=\"visible\">True</property>\n                    <property name=\"can-focus\">True</property>\n                    <property name=\"shadow-type\">in</property>\n                    <child>\n                      <object class=\"GtkViewport\">\n                        <property name=\"visible\">True</property>\n                        <property name=\"can-focus\">False</property>\n                        <child>\n                          <object class=\"GtkNotebook\" id=\"notebook\">\n                            <property name=\"name\">notebook</property>\n                            <property name=\"width-request\">200</property>\n                            <property name=\"height-request\">200</property>\n                            <property name=\"visible\">True</property>\n                            <property name=\"can-focus\">True</property>\n                            <child>\n                              <object class=\"GtkTextView\">\n                                <property name=\"visible\">True</property>\n                                <property name=\"can-focus\">True</property>\n                              </object>\n                            </child>\n                            <child type=\"tab\">\n                              <object class=\"GtkLabel\">\n                                <property name=\"visible\">True</property>\n                                <property name=\"can-focus\">False</property>\n                                <property name=\"label\" translatable=\"yes\">page 1</property>\n                              </object>\n                              <packing>\n                                <property name=\"tab-fill\">False</property>\n                              </packing>\n                            </child>\n                            <child>\n                              <placeholder/>\n                            </child>\n                            <child type=\"tab\">\n                              <placeholder/>\n                            </child>\n                          </object>\n                        </child>\n                      </object>\n                    </child>\n                  </object>\n                </child>\n              </object>\n              <packing>\n                <property name=\"expand\">False</property>\n                <property name=\"fill\">True</property>\n                <property name=\"position\">1</property>\n              </packing>\n            </child>\n            <child>\n              <placeholder/>\n            </child>\n          </object>\n        </child>\n      </object>\n    </child>\n  </object>\n  <object class=\"GtkFileChooserDialog\" id=\"openFileDialog\">\n    <property name=\"name\">openFileDialog</property>\n    <property name=\"width-request\">800</property>\n    <property name=\"height-request\">600</property>\n    <property name=\"can-focus\">False</property>\n    <property name=\"type-hint\">dialog</property>\n    <child internal-child=\"vbox\">\n      <object class=\"GtkBox\">\n        <property name=\"width-request\">800</property>\n        <property name=\"height-request\">600</property>\n        <property name=\"can-focus\">False</property>\n        <property name=\"orientation\">vertical</property>\n        <property name=\"spacing\">2</property>\n        <child internal-child=\"action_area\">\n          <object class=\"GtkButtonBox\">\n            <property name=\"can-focus\">False</property>\n            <property name=\"layout-style\">end</property>\n            <child>\n              <object class=\"GtkButton\" id=\"dialogButtonOpen\">\n                <property name=\"label\" translatable=\"yes\">Open</property>\n                <property name=\"name\">dialogButtonOpen</property>\n                <property name=\"visible\">True</property>\n                <property name=\"can-focus\">True</property>\n                <property name=\"receives-default\">True</property>\n              </object>\n              <packing>\n                <property name=\"expand\">True</property>\n                <property name=\"fill\">True</property>\n                <property name=\"position\">0</property>\n              </packing>\n            </child>\n          </object>\n          <packing>\n            <property name=\"expand\">False</property>\n            <property name=\"fill\">False</property>\n            <property name=\"position\">0</property>\n          </packing>\n        </child>\n      </object>\n    </child>\n  </object>\n</interface>\n\nWhatever I try to append to the notebook, be it a Gtk::Box or Gtk:TextView, the new tab doesn't show.\nNote: This is a work in progress, so the save button's clicked signal is responsible for adding a new tab(blank document)to the notebook.\n",
"AnswerId": "76391800",
"AnswerBody": "The problem is that:\n\nThe Gtk::Notebook does not take ownership of the widget you are adding.\nThe widget you are adding is local to your callback (and hence destroyed when leaving it).\n\nI was able to make your example work by adding a widget (here a Gtk::Label) attribute to your window (so it outlives the callback):\nclass MainWindow : public Gtk::Window\n{\nprotected:\n    \n    Gtk::Button* buttonOpenFile;\n    Gtk::Button* buttonSave;\n    Gtk::Button* buttonSaveAs;\n    Gtk::Label   label;        // <-- See here\n    \n    Gtk::Button *dialogButonOpen;\n\n    ...\n\nand then show()ing it explicitly in the callback:\nvoid MainWindow::AddTabToNotebook()\n{\n    notebook->append_page(label);\n\n    label.set_text(\"test\");\n    label.show();\n}\n\non Ubuntu and Gtkmm 3.24.20. You can achieve the same thing by using the Glade file, I leave this part to you.\n"
},
{
"QuestionId": "76385362",
"QuestionTitle": "Dragging fields in CrafterCMS Studio",
"QuestionBody": "I'm currently teaching myself how to use a headless CMS (CrafterCMS) with Next.js.\nI have the following simple content type in CrafterCMS studio (just a title and a text):\n\nAnd the respective code:\nexport default async function TestPage() {\n    const model = await getModel('/site/website/test/index.xml');\n    return (\n        <TestComponent model={model} />\n    );\n}\n\nexport default function TestComponent(props) {\n    const { isAuthoring } = useCrafterAppContext();\n    const { model } = props;\n\n    return (\n        <ExperienceBuilder path={model.craftercms.path} isAuthoring={isAuthoring}>\n            <Model model={model} >\n                <div className=\"space-y-4\">\n                    <RenderField\n                        model={model}\n                        fieldId=\"title_s\"\n                        className=\"text-xl text-gray-800\"\n                    />\n\n                    <RenderField\n                        model={model}\n                        fieldId=\"text_t\"\n                        className=\"text-xl text-gray-800\"\n                    />\n                </div>\n            </Model>\n        </ExperienceBuilder>\n    );\n}\n\nIs it possible to use Studio functionality to drag and change the positions of my two fields? For example I want to drag the text to be the first element. It seems that i only have the option to change the content, dragging is not available:\n\n",
"AnswerId": "76391913",
"AnswerBody": "On CrafterCMS, you can drag & drop mainly 3 things:\n\nRepeating group items\nComponent item references from an Item Selector control with a \"Components\" datasource\nMedia items into a media control (image or video)\n\nThe simplest way of achieving what you describe, would be to change your model to wrap with a repeat group the fields you want to reorder via drag & drop (i.e. create a repeat group and add the \"title\" input control inside of it; only 1, discard the other). Once you've done that, you'll need to update your TestComponent code to use <RenderRepeat ... /> and you should be able to reorder via drag & drop, via the contextual menu up/down buttons, or via the content form.\nThe rendering of the repeat with your title field, would roughly look something like this:\n<RenderRepeat\n  model={model}\n  fieldId=\"yourRepeatGroupId_o\"\n  componentProps={{ className: \"space-y-4\" }}\n  renderItem={(item, index) => (\n    <RenderField\n      model={model}\n      fieldId=\"yourRepeatGroupId_o.title_s\"\n      index={index}\n      className=\"text-xl text-gray-800\"\n    />\n  )}\n/>\n\nAs I mentioned, you could achieve it via components (Item selector control, Components datasource), but the repeat group is simplest for this case; specially to get started and learn.\n"
},
{
"QuestionId": "76394140",
"QuestionTitle": "Python: Comparing two lists using a for-loop, how do I print the results correctly?",
"QuestionBody": "import random\n\nlst1 = []\nlst2 = []\nn = int(input('Step a: How many numbers in each list?  '))\n\nfor i in range(0, n):\n    number1 = random.randint(1, 15)\n    number2 = random.randint(1, 15)\n    lst1.append(number1)\n    lst2.append(number2)\n    count = 0\n    if lst1[i] > lst2[i]:\n        count += 1\n        print(f'{number1} : First List')\n    else:\n        print(f'{number2} : Second List')\n\n\nprint(f'Step b: First List{lst1}')\nprint(f'Step c: Second List{lst2}')\nprint('Step d:')\nprint('Larger number in each comparison:')\n\nProgram is supposed to make two lists and compare each element.\nCurrent program prints like this:\nStep a: How many numbers in each list?  5\n12 : First List\n14 : First List\n14 : First List\n15 : First List\n5 : Second List\nStep b: First List\\[12, 14, 14, 15, 4\\]\nStep c: Second List\\[5, 2, 8, 13, 5\\]\nStep d:\nLarger number in each comparison:\n\nI'm trying to get it to print like this:\nStep a: How many numbers in each list?  5\nStep b: First List\\[12, 14, 14, 15, 4\\]\nStep c: Second List\\[5, 2, 8, 13, 5\\]\nStep d:\nLarger number in each comparison:\n12 : First List\n14 : First List\n14 : First List\n15 : First List\n5 : Second List\n\nAny suggestions?\nI've tried to make functions out of them and kept getting errors. Very new to this and not sure what I should do.\n",
"AnswerId": "76394152",
"AnswerBody": "Try creating a third list to store the comparison results and then printing the contents only at the end with another loop:\nimport random\n\nlst1 = []\nlst2 = []\ncomparison_results = []\n\nn = int(input('Step a: How many numbers in each list? '))\n\nfor i in range(n):\n    number1 = random.randint(1, 15)\n    number2 = random.randint(1, 15)\n    lst1.append(number1)\n    lst2.append(number2)\n\n    if lst1[i] > lst2[i]:\n        comparison_results.append(f'{number1} : First List')\n    elif lst1[i] < lst2[i]:\n        comparison_results.append(f'{number2} : Second List')\n    else:\n        comparison_results.append(f'{number2} : In Both Lists')\n\nprint(f'Step b: First List {lst1}')\nprint(f'Step c: Second List {lst2}')\nprint('Step d: Larger number in each comparison:')\nfor result in comparison_results:\n    print(result)\n\n\nExample Output:\nStep a: How many numbers in each list? 5\nStep b: First List [5, 11, 9, 3, 4]\nStep c: Second List [15, 11, 9, 13, 15]\nStep d: Larger number in each comparison:\n15 : Second List\n11 : In Both Lists\n9 : In Both Lists\n13 : Second List\n15 : Second List\n\n"
},
{
"QuestionId": "76391153",
"QuestionTitle": "Python Polars: Lazy Frame Row Count not equal wc -l",
"QuestionBody": "Been experimenting with polars and of the key features that peak my interest is the larger than RAM operations.\nI downloaded some files to play with from HERE. On the website: First line in each file is header; 1 line corresponds to 1 record.. WARNING total download is quite large (~1.3GB)! This experiment was done on AWS server (t2.medium, 2cpu, 4GB)\nwget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Shoes_v1_00.tsv.gz \\\nhttps://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz \\\nhttps://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Software_v1_00.tsv.gz \\\nhttps://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv  .gz \\\nhttps://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Watches_v1_00.tsv.gz \n\ngunzip *\n\nHere are the results from wc -l\ndrwxrwxr-x 3 ubuntu ubuntu       4096 Jun  2 12:44 ../\n-rw-rw-r-- 1 ubuntu ubuntu 1243069057 Nov 25  2017 amazon_reviews_us_Office_Products_v1_00.tsv\n-rw-rw-r-- 1 ubuntu ubuntu   44891575 Nov 25  2017 amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv\n-rw-rw-r-- 1 ubuntu ubuntu 1570176560 Nov 25  2017 amazon_reviews_us_Shoes_v1_00.tsv\n-rw-rw-r-- 1 ubuntu ubuntu  249565371 Nov 25  2017 amazon_reviews_us_Software_v1_00.tsv\n-rw-rw-r-- 1 ubuntu ubuntu  412542975 Nov 25  2017 amazon_reviews_us_Watches_v1_00.tsv\n\n$ find . -type f -exec cat {} + | wc -l\n8398139\n\n$ find . -name '*.tsv' | xargs wc -l\n   2642435 ./amazon_reviews_us_Office_Products_v1_00.tsv\n    341932 ./amazon_reviews_us_Software_v1_00.tsv\n     85982 ./amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv\n   4366917 ./amazon_reviews_us_Shoes_v1_00.tsv\n    960873 ./amazon_reviews_us_Watches_v1_00.tsv\n   8398139 total\n\nNow, if I count the rows using polars using our new fancy lazy function:\nimport polars as pl\n\ncsvfile = \"~/data/amazon/*.tsv\"\n(\n    pl.scan_csv(csvfile, separator = '\\t')\n    .select( \n        pl.count()\n        )\n    .collect()\n)\nshape: (1, 1)\n┌─────────┐\n│ count   │\n│ ---     │\n│ u32     │\n╞═════════╡\n│ 4186305 │\n└─────────┘\n\nWow, thats a BIG difference between wc -l and polars. Thats weird... maybe its a data issue. Lets only focus on the column of interest:\ncsvfile = \"~/data/amazon/*.tsv\"\n(\n...     pl.scan_csv(csvfile, separator = '\\t')\n...     .select( \n...         pl.col(\"product_category\").count()\n...         )\n...     .collect()\n... )\nshape: (1, 1)\n┌──────────────────┐\n│ product_category │\n│ ---              │\n│ u32              │\n╞══════════════════╡\n│ 7126095          │\n└──────────────────┘\n\nAnd with .collect(streaming = True):\nshape: (1, 1)\n┌──────────────────┐\n│ product_category │\n│ ---              │\n│ u32              │\n╞══════════════════╡\n│ 7125569          │\n└──────────────────┘\n\nOk, still a difference of about 1 million? Lets do it bottom up:\ncsvfile = \"~/data/amazon/*.tsv\"\n(\n    pl.scan_csv(csvfile, separator = '\\t') \n    .groupby([\"product_category\"])\n    .agg(pl.col(\"product_category\").count().alias(\"counts\"))\n    .collect(streaming = True)\n    .filter(pl.col('counts') > 100)\n    .sort(pl.col(\"counts\"), descending = True)\n    .select(\n        pl.col('counts').sum()\n    )\n)\nshape: (1, 1)\n┌─────────┐\n│ counts  │\n│ ---     │\n│ u32     │\n╞═════════╡\n│ 7125553 │\n└─────────┘\n\nClose, albeit that its once again a different count...\nSome more checks using R:\nlibrary(vroom)\nlibrary(purrr)\nlibrary(glue)\nlibrary(logger)\namazon <- list.files(\"~/data/amazon/\", full.names = TRUE)\nf <- function(file){\n     df <- vroom(file, col_select = 'product_category', show_col_types=FALSE )\n     log_info(glue(\"File [{basename(file)}] has [{nrow(df)}] rows\"))\n}\n\nwalk(amazon, f)\nINFO [2023-06-02 14:23:40] File [amazon_reviews_us_Office_Products_v1_00.tsv] has [2633651] rows\nINFO [2023-06-02 14:23:41] File [amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv] has [85898] rows\nINFO [2023-06-02 14:24:06] File [amazon_reviews_us_Shoes_v1_00.tsv] has [4353998] rows\nINFO [2023-06-02 14:24:30] File [amazon_reviews_us_Software_v1_00.tsv] has [331152] rows\nINFO [2023-06-02 14:24:37] File [amazon_reviews_us_Watches_v1_00.tsv] has [943763] rows\n\nTotal: 8348462\n\nOk. Screw it. Basically a random number generating exercise and nothing is real.\nSurely if its a data hygiene issue the error should be constant? Any idea why there might be such a large discrepancy?\n",
"AnswerId": "76392845",
"AnswerBody": "It's usually helpful to declare the size of downloads in cases like this.\n\nFor any readers, the total size is 1.3 GB\n\nThe smallest file is https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv.gz at 17.6 MB\n\n\nI tried pandas to debug this, it cannot read any of these files:\npd.read_csv('amazon-reviews/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv', sep='\\t')\n\nParserError: Error tokenizing data. C error: \n Expected 15 fields in line 1598, saw 22\n\nLine 1598:\nUS  3878437 R3BH4UXFRP6F8L  B00J7G8EL0  381088677   GUM Expanding Floss - 30 m - 2 pk   Personal_Care_Appliances    \n4   0   0   N   Y   \" like the REACH woven that's no longer available--THAT was the wish it was a bit &#34;fluffier,&#34; like the REACH woven that's no longer available--THAT was the best    2015-08-06\n\nThe issue is the single \" character, you need to disable the default quoting behaviour.\nWith that change I get a total count of 8398134 each time.\n\npolars\n(pl.scan_csv('amazon-reviews/*.tsv', separator='\\t', quote_char=None)\n   .select(pl.count())\n   .collect()\n)\n\nCPU times: user 3.65 s, sys: 2.02 s, total: 5.67 s\nWall time: 2.48 s\nshape: (1, 1)\n┌─────────┐\n│ count   │\n│ ---     │\n│ u32     │\n╞═════════╡\n│ 8398134 │\n└─────────┘\n\n\npandas\nsum(\n   len(pd.read_csv(file, sep='\\t', quoting=3).index)\n   for file in files\n)\n\nCPU times: user 57.6 s, sys: 9.78 s, total: 1min 7s\nWall time: 1min 7s\n8398134\n\n\nduckdb\nduckdb.sql(\"\"\"\nfrom read_csv_auto('amazon-reviews/*.tsv', sep='\\t', quote='')\nselect count(*)\n\"\"\").pl()\n\nCPU times: user 12.4 s, sys: 2.32 s, total: 14.7 s\nWall time: 5.05 s\nshape: (1, 1)\n┌──────────────┐\n│ count_star() │\n│ ---          │\n│ i64          │\n╞══════════════╡\n│ 8398134      │\n└──────────────┘\n\n\npyarrow\nparse_options = pyarrow.csv.ParseOptions(delimiter='\\t', quote_char=False)\n\nsum(\n   pyarrow.csv.read_csv(file, parse_options=parse_options).num_rows\n   for file in files\n)\n\nCPU times: user 12.9 s, sys: 6.46 s, total: 19.4 s\nWall time: 6.65 s\n8398134\n\n"
},
{
"QuestionId": "76389541",
"QuestionTitle": "How to upload only updated files in Google Apps Script using clasp?",
"QuestionBody": "I'm developing Google Apps Script locally. I used the clasp push --watch command for pushing updated code to the original Apps Script as per the documentation.\nhttps://www.npmjs.com/package/@google/clasp#push\nThe problem is that when I update the code of any one file, it uploads the whole file. I have attached the screenshot of the file structure and vs code terminal.\nYou can see there I had updated the code of home.html but still, it's uploaded the whole project. Because of this, we are getting time-consuming issues. It's taking a long time to upload the project. I had also attached the screen shot of clasp.json file.\nIs there any way to upload the only updated file ?\n\n\n\n",
"AnswerId": "76391919",
"AnswerBody": "It seems this behavior is expected based on the documentation:\n\nWarning: Google scripts APIs do not currently support atomic nor per file operations. Thus the push command always replaces the whole content of the online project with the files being pushed.\n\n\nclasp push replaces code that is on script.google.com and clasp pull\nreplaces all files locally. For this reason, follow these guidelines:\nDo not concurrently edit code locally and on script.google.com. Use a\nversion control system, like git.\n\nA new feature would be required from the Google Apps Script API to accomplish what you're looking for, it seems there is already a Feature Request here, you can vote for it, add your comments and look for any future updates.\nReferences\n\nPulling & Pushing Files\nFeature request: clasp push -w - add option to push only changed files\nProblems when using CLASP to push client-side files from a local editor\n\n"
},
{
"QuestionId": "76389283",
"QuestionTitle": "How to retrieve an image from database and show it in asp image box with a click of a button?",
"QuestionBody": "private void ProcessedImage()\n    {\n        try\n        {\n            if (FileUpload1.HasFile)\n            {\n\n                int length = 192;\n                int width = 192;\n\n                using (Bitmap sourceImage = new Bitmap(FileUpload1.PostedFile.InputStream))\n                {\n                    using (Bitmap resizedImage = new Bitmap(length, width))\n                    {\n                        using (Graphics graphics = Graphics.FromImage(resizedImage))\n                        {\n                            graphics.InterpolationMode = InterpolationMode.HighQualityBicubic;\n                            graphics.SmoothingMode = SmoothingMode.HighQuality;\n                            graphics.PixelOffsetMode = PixelOffsetMode.HighQuality;\n\n                            graphics.DrawImage(sourceImage, 0, 0, length, width);\n                        }\n\n                        string resizedImagePath = Server.MapPath(\"~/Images/Image.png\");\n                        resizedImage.Save(resizedImagePath, ImageFormat.Png);\n\n                        ImgPhoto.ImageUrl = \"~/Images/Image.png\";\n                    }\n                }\n            }\n        }\n        catch (Exception ex)\n        {\n            string errorMessage = (\"An error occurred \" + ex.Message);\n        }\n    }\n\n    public void Save()\n        {\n            try\n            {\n                byte[] imageData;\n                using (MemoryStream ms = new MemoryStream())\n                {\n                    using (Bitmap bitmap = new Bitmap(Server.MapPath(\"~/Images/finalImage.png\")))\n                    {\n                        bitmap.Save(ms, ImageFormat.Png);\n                        imageData = ms.ToArray();\n                    }\n                }\n        \n                using (SqlConnection con = new SqlConnection(\"Data Source=127.0.0.1;Initial Catalog=Karthik;User ID=admin;Password=admin\"))\n                {\n                    con.Open();\n                    SqlCommand cmd = new SqlCommand(\"INSERT INTO image_tbl (ImageID,image_data) VALUES (@ImageID,@image_data)\", con);\n                    cmd.Parameters.AddWithValue(\"@ImageID\", ImageID.Text.Trim());\n                    cmd.Parameters.AddWithValue(\"@image_data\", imageData);\n                    cmd.ExecuteNonQuery();\n\n                    Response.Write(\"<script>alert('Saved Succefully')</script>\");\n                }\n            }\n            catch (Exception ex)\n            {\n                string errorMessage = \"An error occurred: \" + ex.Message;\n            }\n        }\n\nThis is my code. I resized the image and saved it in the database. Now I want to take an input from the user for Image ID and retrieve the image corresponding to the image ID and show it in the asp text box. Is it possible to do so? Note that I am working in Visual Studio 2010. And I don't think it supports JavaScript codes.\n",
"AnswerId": "76391945",
"AnswerBody": "Ok, first up, even vs2010 used lots of JavaScript, and in fact came with a bootstrap main menu, had the JavaScript \"helper\" library jQuery installed.\nAnd in fact, YOUR above code even uses JavaScript here:\n Response.Write(\"<script>alert('Saved Succefully')</script>\");\n\nSo, to be clear?\nYou have full use of JavaScript, and there is ZERO issues in regards to enjoying the use of JavaScript, and nothing stops you from using JavaScript.\nNow, having stated the above, there is no need to use JavaScript, and you don't have to write any JavaScript to solve your question. But, to be crystal clear, you have full use of JavaScript in your markup, and even projects created in vs2010 have FULL support for using JavaScript.\nOk, so, lets assume we have that saved image, as you note nice and small, and you want to show the preview.\nAbout the ONLY real issue? How many images do you need to display on a page.\nWhy do I ask \"how many\" images?\nAnswer:\nBecause I going to post a VERY easy bit of code to display that image from the database, but this approach NEEDS MUCH caution, since we going to stream the image to the page as raw image bytes, and this approach means the \"image\" will travel back to the server when you click on a button, or ANY thing on that page that triggers a post-back (standard round trip) of the browser will \"increase\" the size and payload of this web page.\nSo, for a smaller image or thumbnail type of image display, and only a few on the page, then this approach is acceptable, and VERY easy to code.\nHowever, if there are to be many images, or the image is large, then I do NOT recommend this \"easy\" and \"simple\" code approach.\nAs noted, since we only are to display one image, and since it is small, then we don't care. However, if your goal was to display MANY images on a page, then I do not recommend this approach for more then a few images displayed at the same time on a single page.\nOk, I don' have your data, but this code shows how you can do this:\nI have a sql server table, and one of the columns is raw byte data of the saved image.\nThe OTHER issue is you NEED to know what file extension your picture was in the first place. For this example, it looks like .png, but if you are to allow different kinds of images, then you MUST save the file extension, or even better yet save the so called \"mine\" type of the image. This information allows us to tell the browser what kind of image we want to display.\nSo, lets say we fill a dropdown list with the rows of the database (without the column that holds the data).\nSo, we have this markup:\n        <h3>Select Fighter</h3>\n        <asp:DropDownList ID=\"cboFighters\" runat=\"server\"\n            DataValueField=\"ID\"\n            DataTextField=\"Fighter\"\n            AutoPostBack=\"true\"\n            OnSelectedIndexChanged=\"cboFighters_SelectedIndexChanged\"\n            Width=\"250px\">\n        </asp:DropDownList>\n\n        <br />\n\n\n        <div class=\"mybox\" style=\"float: left\">\n            <div style=\"text-align: center; padding: 2px 10px 12px 10px\">\n\n                <h3 id=\"Fighter\" runat=\"server\"></h3>\n                <asp:Image ID=\"Image2\" runat=\"server\"\n                    Width=\"180\" Height=\"120\" />\n\n                <h4>Engine</h4>\n                <asp:Label ID=\"EngineLabel\" runat=\"server\" Text=\"\" />\n\n                <h4>Description</h4>\n                <asp:Label ID=\"DescLabel\" runat=\"server\" Width=\"400px\"\n                    Text=\"\" Style=\"text-align: left\" Font-Size=\"Large\" />\n            </div>\n        </div>\n\nNote close in above, there is a image control.\nSo, now our code behind is this:\n    protected void Page_Load(object sender, EventArgs e)\n    {\n        if (!IsPostBack)\n        {\n            cboFighters.DataSource =\n                General.MyRst(\"SELECT ID, Fighter FROM Fighters\");\n            cboFighters.DataBind();\n            cboFighters.Items.Insert(0, new ListItem(\"Select Fighter\", \"0\"));\n        }\n    }\n\n    protected void cboFighters_SelectedIndexChanged(object sender, EventArgs e)\n    {\n\n        SqlCommand cmdSQL = \n            new SqlCommand(\"SELECT * FROM Fighters WHERE ID = @ID\");\n        cmdSQL.Parameters.Add(\"@ID\", SqlDbType.Int).Value = cboFighters.SelectedItem.Value;\n\n        DataRow OneFighter = General.MyRstP(cmdSQL).Rows[0];\n        Fighter.InnerText = OneFighter[\"Fighter\"].ToString();\n        EngineLabel.Text = OneFighter[\"Engine\"].ToString();\n        DescLabel.Text = OneFighter[\"Description\"].ToString();\n\n        string sMineType = OneFighter[\"MineType\"].ToString();\n        // stringSmineType = \"image/png\"  // hard coded value if all are .png\n\n        byte[] MyBytePic = (byte[])OneFighter[\"MyImage\"];\n\n        Image2.ImageUrl = \n            $@\"data:{sMineType};base64,{Convert.ToBase64String(MyBytePic)}\";\n\n    }\n\nAnd the result is this:\n\nNote the use of \"mine mapping\". Quite sure that needs .net 4.5 or later.\nHowever, if all of your raw byte saved images in the database are .png, then you can hard code as the above commented out line shows.\nNote that the above same trick works if we fill out a gridview.\nHowever, as I stated, use \"some\" caution with this approach, since the image does not have any \"real\" URL path name to resolve, the browser will wind up sending the picture back to the server with each button click (and post back). Since there is no \"real\" URL, then the browser cannot cache such pictures. As noted, you can also consider creating a http handler, and they play much nicer then sending the picture as a base64 string.\nSo, if your concerned about keeping the page size small, or to leverage browser caching, then consider a custom picture handler.\nHowever, since in your case we have a small picture of 192x192, then the above approach is fine and easy to code.\n"
},
{
"QuestionId": "76394222",
"QuestionTitle": "How to compile Packages in java",
"QuestionBody": "I am new to java , how do I compile packages in Intelij\nThis is my directory\n\nIt is running perfectly in Main.java\nTo compile , I first ran\njavac people/People.java\nThen I compile javac Main.java, it returns Main.java:8: error: package com.amigoscode.people does not exist\nMain.java\npackage com.amigoscode;\n\n// Press Shift twice to open the Search Everywhere dialog and type `show whitespaces`,\n// then press Enter. You can now see whitespace characters in your code.\n\n\nimport java.util.Scanner;\nimport com.amigoscode.people.People;\n\n\npublic class Main {\n\n    public static void main(String[] args) {\n        People p = new People();\n        System.out.println(p.fullName());\n    }\n\n}\n\nPeople.java\npackage com.amigoscode.people;\n\npublic class People {\n\n    public String fname = \"John\";\n    public String lname = \"Doe\";\n    public int age = 24;\n\n\n    public String fullName() {\n        String fullName = fname + \" \" + lname;\n        return fullName;\n    }\n\n}\n\nThank you very much.\n",
"AnswerId": "76394267",
"AnswerBody": "First, navigate to the src directory using terminal. Then execute the command below to compile the People.java.\njavac com/amigoscode/people/People.java\n\nNow, to compile the Main.java execute the command below.\njavac com/amigoscode/Main.java\n\nThis should work fine.\n"
},
{
"QuestionId": "76389911",
"QuestionTitle": "CMake CMAKE_SOURCE_DIR and CMAKE_CURRENT_SOURCE_DIR to set same path, but only latter 'works'",
"QuestionBody": "I'm using CMake in, so far as I can tell, the same way as I always use it.  The problem is that now include_directories($(CMAKE_SOURCE_DIR)/server/include) results in my header files not being found.  When instead I use include_directories($(CMAKE_CURRENT_SOURCE_DIR)/server/include) they are found.\ni.e. $(CMAKE_CURRENT_SOURCE_DIR) works, and $(CMAKE_SOURCE_DIR) doesn't.\nThe bizarre thing is that both of:\nmessage(${CMAKE_SOURCE_DIR}/server/include)\nmessage(${CMAKE_CURRENT_SOURCE_DIR}/server/include)\n\ngive:\n/home/username/projects/repo/server/include\n\nSo why does one work while the other doesn't?\n",
"AnswerId": "76391974",
"AnswerBody": "$(FOO) is not the correct syntax to refer to the cmake variable FOO. You need to use ${FOO} instead. Neither of the uses of include_directories should work, unless the build system interprets the path $(CMAKE_CURRENT_SOURCE_DIR)/server/include.\nNote that you're using the proper syntax for the message commands.\nThe message command\nmessage($(CMAKE_CURRENT_SOURCE_DIR)/server/include)\n\nprints\n$(CMAKE_CURRENT_SOURCE_DIR)/server/include\n\ndemonstrating the issue.\nI recommend using the CMAKE_CURRENT_SOURCE_DIR instead of CMAKE_SOURCE_DIR btw in all cases except for rare exceptions where you know that the toplevel CMakeLists.txt is located in a directory with specific contents. The former version is easier to recombine when used as part of a larger project via add_subdirectory.\ninclude_directories(${CMAKE_CURRENT_SOURCE_DIR}/server/include)\n#                    ^                        ^\n\nNote that the use of target_include_directories usually is preferrable to the use of include_directories, since the former allows restricts the targets the include directories are applied to to the one specifically mentioned. It also would allow you to make the include directories to targets linking a cmake library target, if desired.\n"
},
{
"QuestionId": "76392241",
"QuestionTitle": "How to fix '535-5.7.8 Username and Password not accepted. Learn more at' error in Devise mail confirmation?",
"QuestionBody": "I'm a beginner programmer Rails. I'll start with a problem: I'm using Devise to work with users, and I tried to enable mail confirmation. It doesn't work, unfortunately. If possible, please help!\nMy error:\nNet::SMTPAuthenticationError in Devise::ConfirmationsController#create\n535-5.7.8 Username and Password not accepted. Learn more at\nMy config/environments/develorment.rb:\nconfig.action_mailer.perform_deliveries = true\nconfig.action_mailer.raise_delivery_errors = true\nconfig.action_mailer.perform_caching = false\nconfig.action_mailer.default_url_options = { host: 'localhost', port: 3000 }\nconfig.action_mailer.delivery_method = :smtp\nconfig.action_mailer.smtp_settings = {\n  address: \"smtp.gmail.com\",\n  port: 587,\n  authentication: \"plain\",\n  enable_starttls_auto: true,\n  user_name: \"xyz@gmail.com\",\n  password: \"xyz\", \n  domain: \"gmail.com\",\n  openssl_verify_mode: \"none\",\n}\n\nMy config/initializers/devise.rb\nconfig.mailer_sender = \"xxx@gmail.com\"\n\nconfig.mailer = 'Devise::Mailer'\n\nMy server starts with configurations:\n=> Booting Puma\n=> Rails 7.0.5 application starting in development\n=> Run `bin/rails server --help` for more startup options\nPuma starting in single mode...\n* Puma version: 5.6.5 (ruby 3.2.0-p0) (\"Birdie's Version\")\n*  Min threads: 5\n*  Max threads: 5\n*  Environment: development\n*          PID: 6074\n* Listening on http://127.0.0.1:3000\n* Listening on http://[::1]:3000\nUse Ctrl-C to stop\n\nAnd Errors in files (or what is it called):\nnet-smtp (0.3.3) lib/net/smtp.rb:1088:in `check_auth_response'\nnet-smtp (0.3.3) lib/net/smtp.rb:845:in `auth_plain'\nnet-smtp (0.3.3) lib/net/smtp.rb:837:in `public_send'\nnet-smtp (0.3.3) lib/net/smtp.rb:837:in `authenticate'\nnet-smtp (0.3.3) lib/net/smtp.rb:670:in `do_start'\nnet-smtp (0.3.3) lib/net/smtp.rb:611:in `start'\nmail (2.8.1) lib/mail/network/delivery_methods/smtp.rb:109:in `start_smtp_session'\nmail (2.8.1) lib/mail/network/delivery_methods/smtp.rb:100:in `deliver!'\nmail (2.8.1) lib/mail/message.rb:2145:in `do_delivery'\nmail (2.8.1) lib/mail/message.rb:253:in `block in deliver'\nactionmailer (7.0.5) lib/action_mailer/base.rb:588:in `block in deliver_mail'\nactivesupport (7.0.5) lib/active_support/notifications.rb:206:in `block in instrument'\nactivesupport (7.0.5) lib/active_support/notifications/instrumenter.rb:24:in `instrument'\nactivesupport (7.0.5) lib/active_support/notifications.rb:206:in `instrument'\nactionmailer (7.0.5) lib/action_mailer/base.rb:586:in `deliver_mail'\nmail (2.8.1) lib/mail/message.rb:253:in `deliver'\nactionmailer (7.0.5) lib/action_mailer/message_delivery.rb:119:in `block in deliver_now'\nactionmailer (7.0.5) lib/action_mailer/rescuable.rb:17:in `handle_exceptions'\nactionmailer (7.0.5) lib/action_mailer/message_delivery.rb:118:in `deliver_now'\ndevise (4.9.2) lib/devise/models/authenticatable.rb:204:in `send_devise_notification'\ndevise (4.9.2) lib/devise/models/confirmable.rb:121:in `send_confirmation_instructions'\ndevise (4.9.2) lib/devise/models/confirmable.rb:136:in `block in resend_confirmation_instructions'\ndevise (4.9.2) lib/devise/models/confirmable.rb:239:in `pending_any_confirmation'\ndevise (4.9.2) lib/devise/models/confirmable.rb:135:in `resend_confirmation_instructions'\ndevise (4.9.2) lib/devise/models/confirmable.rb:321:in `send_confirmation_instructions'\ndevise (4.9.2) app/controllers/devise/confirmations_controller.rb:11:in `create'\nactionpack (7.0.5) lib/action_controller/metal/basic_implicit_render.rb:6:in `send_action'\nactionpack (7.0.5) lib/abstract_controller/base.rb:215:in `process_action'\nactionpack (7.0.5) lib/action_controller/metal/rendering.rb:165:in `process_action'\nactionpack (7.0.5) lib/abstract_controller/callbacks.rb:234:in `block in process_action'\nactivesupport (7.0.5) lib/active_support/callbacks.rb:118:in `block in run_callbacks'\nactiontext (7.0.5) lib/action_text/rendering.rb:20:in `with_renderer'\nactiontext (7.0.5) lib/action_text/engine.rb:69:in `block (4 levels) in <class:Engine>'\nactivesupport (7.0.5) lib/active_support/callbacks.rb:127:in `instance_exec'\nactivesupport (7.0.5) lib/active_support/callbacks.rb:127:in `block in run_callbacks'\nactivesupport (7.0.5) lib/active_support/callbacks.rb:138:in `run_callbacks'\nactionpack (7.0.5) lib/abstract_controller/callbacks.rb:233:in `process_action'\nactionpack (7.0.5) lib/action_controller/metal/rescue.rb:22:in `process_action'\nactionpack (7.0.5) lib/action_controller/metal/instrumentation.rb:67:in `block in process_action'\nactivesupport (7.0.5) lib/active_support/notifications.rb:206:in `block in instrument'\nactivesupport (7.0.5) lib/active_support/notifications/instrumenter.rb:24:in `instrument'\nactivesupport (7.0.5) lib/active_support/notifications.rb:206:in `instrument'\nactionpack (7.0.5) lib/action_controller/metal/instrumentation.rb:66:in `process_action'\nactionpack (7.0.5) lib/action_controller/metal/params_wrapper.rb:259:in `process_action'\nactiverecord (7.0.5) lib/active_record/railties/controller_runtime.rb:27:in `process_action'\nactionpack (7.0.5) lib/abstract_controller/base.rb:151:in `process'\nactionview (7.0.5) lib/action_view/rendering.rb:39:in `process'\nactionpack (7.0.5) lib/action_controller/metal.rb:188:in `dispatch'\nactionpack (7.0.5) lib/action_controller/metal.rb:251:in `dispatch'\nactionpack (7.0.5) lib/action_dispatch/routing/route_set.rb:49:in `dispatch'\nactionpack (7.0.5) lib/action_dispatch/routing/route_set.rb:32:in `serve'\nactionpack (7.0.5) lib/action_dispatch/routing/mapper.rb:18:in `block in <class:Constraints>'\nactionpack (7.0.5) lib/action_dispatch/routing/mapper.rb:48:in `serve'\nactionpack (7.0.5) lib/action_dispatch/journey/router.rb:50:in `block in serve'\nactionpack (7.0.5) lib/action_dispatch/journey/router.rb:32:in `each'\nactionpack (7.0.5) lib/action_dispatch/journey/router.rb:32:in `serve'\nactionpack (7.0.5) lib/action_dispatch/routing/route_set.rb:852:in `call'\nwarden (1.2.9) lib/warden/manager.rb:36:in `block in call'\nwarden (1.2.9) lib/warden/manager.rb:34:in `catch'\nwarden (1.2.9) lib/warden/manager.rb:34:in `call'\nrack (2.2.7) lib/rack/tempfile_reaper.rb:15:in `call'\nrack (2.2.7) lib/rack/etag.rb:27:in `call'\nrack (2.2.7) lib/rack/conditional_get.rb:40:in `call'\nrack (2.2.7) lib/rack/head.rb:12:in `call'\nactionpack (7.0.5) lib/action_dispatch/http/permissions_policy.rb:38:in `call'\nactionpack (7.0.5) lib/action_dispatch/http/content_security_policy.rb:36:in `call'\nrack (2.2.7) lib/rack/session/abstract/id.rb:266:in `context'\nrack (2.2.7) lib/rack/session/abstract/id.rb:260:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/cookies.rb:704:in `call'\nactiverecord (7.0.5) lib/active_record/migration.rb:603:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/callbacks.rb:27:in `block in call'\nactivesupport (7.0.5) lib/active_support/callbacks.rb:99:in `run_callbacks'\nactionpack (7.0.5) lib/action_dispatch/middleware/callbacks.rb:26:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/executor.rb:14:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/actionable_exceptions.rb:17:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/debug_exceptions.rb:28:in `call'\nweb-console (4.2.0) lib/web_console/middleware.rb:132:in `call_app'\nweb-console (4.2.0) lib/web_console/middleware.rb:28:in `block in call'\nweb-console (4.2.0) lib/web_console/middleware.rb:17:in `catch'\nweb-console (4.2.0) lib/web_console/middleware.rb:17:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/show_exceptions.rb:26:in `call'\nrailties (7.0.5) lib/rails/rack/logger.rb:40:in `call_app'\nrailties (7.0.5) lib/rails/rack/logger.rb:25:in `block in call'\nactivesupport (7.0.5) lib/active_support/tagged_logging.rb:99:in `block in tagged'\nactivesupport (7.0.5) lib/active_support/tagged_logging.rb:37:in `tagged'\nactivesupport (7.0.5) lib/active_support/tagged_logging.rb:99:in `tagged'\nrailties (7.0.5) lib/rails/rack/logger.rb:25:in `call'\nsprockets-rails (3.4.2) lib/sprockets/rails/quiet_assets.rb:13:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/remote_ip.rb:93:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/request_id.rb:26:in `call'\nrack (2.2.7) lib/rack/method_override.rb:24:in `call'\nrack (2.2.7) lib/rack/runtime.rb:22:in `call'\nactivesupport (7.0.5) lib/active_support/cache/strategy/local_cache_middleware.rb:29:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/server_timing.rb:61:in `block in call'\nactionpack (7.0.5) lib/action_dispatch/middleware/server_timing.rb:26:in `collect_events'\nactionpack (7.0.5) lib/action_dispatch/middleware/server_timing.rb:60:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/executor.rb:14:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/static.rb:23:in `call'\nrack (2.2.7) lib/rack/sendfile.rb:110:in `call'\nactionpack (7.0.5) lib/action_dispatch/middleware/host_authorization.rb:137:in `call'\nrailties (7.0.5) lib/rails/engine.rb:530:in `call'\npuma (5.6.5) lib/puma/configuration.rb:252:in `call'\npuma (5.6.5) lib/puma/request.rb:77:in `block in handle_request'\npuma (5.6.5) lib/puma/thread_pool.rb:340:in `with_force_shutdown'\npuma (5.6.5) lib/puma/request.rb:76:in `handle_request'\npuma (5.6.5) lib/puma/server.rb:443:in `process_client'\npuma (5.6.5) lib/puma/thread_pool.rb:147:in `block in spawn_thread'\n\nThe message is shown in the terminal.\nAnd yes, I know it's important, e-mail exists, and the data is taken from it.\nI tried many options, including the part of the code that I ended up with. Nothing helps.\n",
"AnswerId": "76392975",
"AnswerBody": "This is related to ActionMailer configuration rather than Devise.\nFrom the documentation authentication should be set to one of the following\n:plain, :login or :cram_md5\nThe following is an excerpt taken from the relevant section in the documentation linked to above and is the explanation of the available options and what they do, so it all depends on your mail server as to which you wish to use however you can see that SSL is not amongst the available options\n\n:authentication - If your mail server requires authentication, you\nneed to specify the authentication type here. This is a symbol and one\nof :plain (will send the password in the clear), :login (will send\npassword Base64 encoded) or :cram_md5 (combines a Challenge/Response\nmechanism to exchange information and a cryptographic Message Digest 5\nalgorithm to hash important information)\n\nAs requested, a typical gmail configuration would be to use SMTP like so\nconfig.action_mailer.delivery_method = :smtp\nconfig.action_mailer.smtp_settings = {\n  address:              'smtp.gmail.com',\n  port:                 587,\n  domain:               'example.com',\n  user_name:            '<username>',\n  password:             '<password>',\n  authentication:       'plain',\n  enable_starttls_auto: true,\n  open_timeout:         5,\n  read_timeout:         5 }\n\nTaken from the rails action mailer documentation section 5.2\nMake sure to replace username x's and password x's with your credentials and NEVER post your credentials anywhere public, I suggest you amend your password on your google account immediately, I have edited your question to hide your password but it is still available to view by those with the correct privileges\n"
},
{
"QuestionId": "76389742",
"QuestionTitle": "why .gitconfig [includIf] override the default config",
"QuestionBody": "I have two keys to different github account and there is the config ~/.gitconfig:\n[user]\n        name = example\n        email = example@example.com\n[pull]\n        rebase = true\n[rebase]\n        autoStash = true\n[filter \"lfs\"]\n        clean = git-lfs clean -- %f\n        smudge = git-lfs smudge -- %f\n        process = git-lfs filter-process\n        required = true\n[includeIf \"gitdir/i:/Users/example/Documents/github_2/\"]\n    [core]\n        sshCommand = \"ssh -i ~/.ssh/github2_key\"\n\nthen, I go to a folder that did not at /Users/example/Documents/github_2/, and run git clone github1_private_project, git told me Please make sure you have the correct access rights\nIt works to git clone the project from account 'github2' in /Users/example/Documents/github_2/\n\ngit version:\n% git -v\ngit version 2.39.2 (Apple Git-143)\n\n",
"AnswerId": "76392034",
"AnswerBody": "The syntax for includeIf should be (see the docs):\n[includeIf \"gitdir/i:/Users/example/Documents/github_2/\"]\npath = </path/to/includeFile>\n\nThe syntax\n[includeIf \"gitdir/i:/Users/example/Documents/github_2/\"]\n    [core]\n        sshCommand = \"ssh -i ~/.ssh/github2_key\"\n\nactually means\n[includeIf \"gitdir/i:/Users/example/Documents/github_2/\"]\n# No `path` hence no include\n\n[core]\n    sshCommand = \"ssh -i ~/.ssh/github2_key\"\n\nwhere the key core.sshCommand is always (unconditionally) defined.\n"
},
{
"QuestionId": "76385174",
"QuestionTitle": "How can I define a type in TypeScript that's a string that only should contain words from a predefined list",
"QuestionBody": "I have a tricky TypeScript question.\nLet say I have this Icon component with the prop size. Size can be \"2\", \"4\", \"6\". I map these values to predefined tailwind classes.\nSo I type it like\ntype SizeValues = '2' | '4' | '6';\n\nfunction Icon({size = '4'}: {size: SizeValues}) {\n   const sizeMap = {\n     '2': 'w-2 h-2',\n     '4': 'w-4 h-4',\n     '6': 'w-6 h-6',\n   };\n \n   return <span className={sizeMap[size]}>My icon goes here</span>\n}\n\n<Icon size=\"sm\" />\n\nEverything is fine. But what if I wanna have different sizes depending on what screen size I have. So I wanna try to have like tailwinds nice syntax.\nSo I rewrite my Icon component to following:\ntype SizeValues = ???\n\nfunction Icon({size = '4'}: {size: SizeValues}) {\n   const sizeMap = {\n     '2': 'w-2 h-2',\n     '4': 'w-4 h-4',\n     '6': 'w-6 h-6',\n     'md:2': 'md:w-2 md:h-2',\n     'md:4': 'md:w-4 md:h-4',\n     'md:6': 'md:w-6 md:h-6',\n     'lg:2': 'lg:w-2 lg:h-2',\n     'lg:4': 'lg:w-4 lg:h-4',\n     'lg:6': 'lg:w-6 lg:h-6',\n   };\n \n   return <span className={size.split(' ').map(s => sizeMap[s]).join(' ').trim()}>My icon goes here</span>\n}\n\n<Icon size=\"2 md:4 lg:6\" />\n\nThat works fine, but how do I type it? I read TypeScript will support regex in the future. That will make it easier, but is it possible to type this now?\nThis is not a real component so please don't give me awesome suggestions how I can improve it. I just wanna know how I can type my size prop so it works the way I've coded it.\n",
"AnswerId": "76392131",
"AnswerBody": "First, we need to extract sizeMap into the global scope, and const assert it to let the compiler know that this is immutable constant and restrict  it from widening types:\nconst sizeMap = {\n  '2': 'w-2 h-2',\n  '4': 'w-4 h-4',\n  '6': 'w-6 h-6',\n  'md:2': 'md:w-2 md:h-2',\n  'md:4': 'md:w-4 md:h-4',\n  'md:6': 'md:w-6 md:h-6',\n  'lg:2': 'lg:w-2 lg:h-2',\n  'lg:4': 'lg:w-4 lg:h-4',\n  'lg:6': 'lg:w-6 lg:h-6',\n} as const;\n\nNext, we need to get a type for the keys of the sizeMap:\ntype SizeMap = typeof sizeMap;\ntype SizeMapKeys = keyof SizeMap;\n\nImplementation:\nWe will create a type that accepts a string and returns it if it is valid; otherwise, return never.\nPseudo-code:\nLet type accept T - string to validate, Original - original string, AlreadyUsed - union of already used keys.\nIf T is an empty string\n\nreturn Original\nElse if T starts with keys of the size map (ClassName), excluding AlreadyUsed, followed by a space and the remaining string(Rest).\n\nRecursively call this type, passing Rest as a string to validate Original, and the AlreadyUsed with ClassName added to it.\n\n\nElse if T is the key of the size map excluding AlreadyUsed\n\nreturn Original\nelse\nreturn never\n\nRealization:\ntype _SizeValue<\n  T extends string,\n  Original extends string = T,\n  AlreadyUsed extends string = never\n> = T extends \"\"\n  ? Original\n  : T extends `${infer ClassName extends Exclude<\n      SizeMapKeys,\n      AlreadyUsed\n    >} ${infer Rest extends string}`\n  ? _SizeValue<Rest, Original, AlreadyUsed | ClassName>\n  : T extends Exclude<SizeMapKeys, AlreadyUsed>\n  ? Original\n  : never;\n\nWe have to add a generic parameter to Item that will represent the size.\nfunction Icon<T extends string | undefined>({\n  size,\n}: {\n  size: _SizeValue<T>;\n}) {\n  return null;\n}\n\nSince, size is optional in the component, we will add a wrapper around the SizeValue which will turn string | undefined to string and pass it to _SizeValue, additionally we will add a default value for size:\ntype SizeValue<T extends string | undefined> = _SizeValue<NonNullable<T>>;\n\nfunction Icon<T extends string | undefined>({\n  size = \"2\",\n}: {\n  size?: SizeValue<T> | \"2\";\n}) {\n  return null;\n}\n\nUsage:\n<Icon size=\"2\" />;\n<Icon size=\"md:2\" />;\n<Icon size=\"md:2 md:6\" />;\n<Icon size=\"md:2 md:6 lg:6\" />;\n\n// expected error\n<Icon size=\"md:2 md:6 lg:5\" />;\n\n// no duplicates allowed\n<Icon size=\"2 2\" />;\n\nplayground\n"
},
{
"QuestionId": "76394256",
"QuestionTitle": "Why does __m128 cause alignment issues in a union with float x/y/z?",
"QuestionBody": "I've never actually ran into this problem before, at least not that I'm aware of... But I'm working on some SIMD vector optimizations in some of my code and I'm having some alignment issues.\nHere's some minimal code that I've been able to reproduce the problem with, on MSVC (Visual Studio 2022):\n#include <stdio.h>\n#include <stdint.h>\n#include <stdbool.h>\n#include <stdlib.h>\n#include <string.h>\n#include <xmmintrin.h>\n\n_declspec(align(16)) typedef union\n{\n    struct { float x, y, z; };\n\n#if 0\n    // This works:\n    float v[4];\n#else\n    // This does not:\n    __m128 v;\n#endif\n} vec;\n\ntypedef struct\n{\n    vec pos;\n    vec vel;\n    float radius;\n} particle;\n\nint main(int argc, char **argv)\n{\n    particle *particles=malloc(sizeof(particle)*10);\n\n    if(particles==NULL)\n        return -1;\n\n    // intentionally misalign the pointer\n    ((uint8_t *)particles)+=3;\n\n    printf(\"misalignment: %lld\\n\", (uintptr_t)particles%16);\n\n    particles[0].pos=(vec){ 1.0f, 2.0f, 3.0f };\n    particles[0].vel=(vec){ 4.0f, 5.0f, 6.0f };\n\n    printf(\"pos: %f %f %f\\nvel: %f %f %f\\n\",\n           particles[0].pos.x, particles[0].pos.y, particles[0].pos.z,\n           particles[0].vel.x, particles[0].vel.y, particles[0].vel.z);\n\n    return 0;\n}\n\nI don't understand why a union with float x/y/z and float[4] works with misaligned memory addresses, but a union with the float x/y/z and an __m128 generates an access violation.\nI get that the __m128 type has some extra alignment specs on it, but the overall union size doesn't change and it's also 16 byte aligned anyway, so why does it matter?\nI do understand the importance of memory alignment, but the extra weird part is that I added in an aligned_malloc to my code that's allocating the offending misaligned memory (I use a slab/zone memory allocator in my code) and it still continued to crash out with an access violation, which further adds to my hair loss.\n",
"AnswerId": "76394286",
"AnswerBody": "alignof(your_union) is 16 when it includes a __m128 member, so compilers will use movaps or movdqa because you've promised them that the data is aligned. Otherwise alignof(your_union) is only 4 (inherited from float, so they'll use movups or movdqu which has no alignment requirement.\nIt's still alignment undefined behaviour, as gcc -fsanitize=undefined will tell you, since you're using an address that's not even aligned by 4.\nhttps://godbolt.org/z/6GxebxT7r shows MSVC is using movdqa stores for your code, like movdqa [rbx+19], xmm2 where RBX holds a malloc return value.  This is guaranteed to fault because malloc return values are aligned by alignof(max_align_t), which is definitely an even number and usually 16 in x86-64.\nOften MSVC will only use unaligned movdqu / movups loads/stores even when you use _mm_store_ps.  (But alignment-required intrinsics will let it fold the load into a memory source operand for non-AVX instructions like addps xmm0, [rcx]).\nBut apparently MSVC treats aggregates differently from deref of a __m128*.\nSo your type has alignof(T) == 16, and thus your code has alignment UB, so it can and does compile to asm that faults.\n\nBTW, I wouldn't recommend using this union; especially not for function args / return values since being part of an aggregate can make the calling conventions treat it less efficiently.  (On MSVC you have to use vectorcall to get it passed in a register if it doesn't inline, but x86-64 System V passes vector args in vector regs normally, if they aren't part of a union.)\nUse __m128 vectors and write helper functions to get your data in/out as scalar.\nIdeally don't use 1 SIMD vector to hold 1 geometry vector, that's kind of an anti-pattern since it leads to a lot of shuffling.  Better to have arrays of x, arrays of y, and arrays of z, so you can load 3 vectors of data and process 4 vectors in parallel with no shuffling.  (Struct-of-Arrays rather than Array-of-Structs).  See https://stackoverflow.com/tags/sse/info especially https://deplinenoise.wordpress.com/2015/03/06/slides-simd-at-insomniac-games-gdc-2015/\nOr if you really want to do it this way, you could still improve this.  Your struct particle is 36 bytes as you've defined it, with two wasted 32-bit float slots.  It could have been 32 bytes: xyz, radius, xyz, zeroed padding, so you could have alignof(particle) == 16 without increasing the size to 48 bytes, to be able to load it efficiently (never spanning cache-line boundaries).  The radius would get loaded as high garbage along _mm_load_ps(&particle->pos_x) which gets the x,y,z positions and whatever comes next.  You might sometimes have to use an extra instruction to zero out the high element, but probably most of the time you could be shuffling in ways that don't care about it.\nActually your struct particle is 48 bytes when you have a __m128 member, since it inherits the alignof(T) from its vec pos and vec vel members, and sizeof(T) has to be a multiple of alignof(T) (so arrays work).\n"
},
{
"QuestionId": "76390159",
"QuestionTitle": "Am I using NSIS nsexec::ExecToStack Output correctly?",
"QuestionBody": "I am calling nsExec::ExecToStack to get the output of a powershell command.  Based on the result, I will either do nothing, or install a windows feature.  I seem to get the result I expect from the powershell command, but the if/then logic is not doing what I expect.\nHere's the code:\nDetailPrint \"======================\"\nDetailPrint \"Checking MSMQ Services\"\nDetailPrint \"======================\"\n\nnsExec::ExecToStack 'powershell.exe -command \"(get-windowsfeature -name MSMQ-Services).InstallState\"'\nPop $0\nPop $InstallState\n\nDetailPrint \"MSMQ is: $InstallState\"\n\n${If} $Installstate == \"Installed\"\n    DetailPrint \"MSMQ is Installed\"\n${Else}\n    DetailPrint \"========================\"\n    DetailPrint \"Installing MSMQ Services\"\n    DetailPrint \"========================\"\n\n    nsexec::exectolog 'powershell -command \"install-windowsfeature -name msmq-services\"'\n    \n${EndIf}\n\nI set ${DisableX64FSRedirection} in the same section, above this code, to ensure powershell is the 64-bit version and can run the command properly.\nHere is what I am seeing in the Log:\n======================\nChecking MSMQ Services\n======================\nMSMQ is: Installed\n\n========================\nInstalling MSMQ Services\n========================\n\nSuccess Restart Needed Exit Code      Feature Result                               \n------- -------------- ---------      --------------                               \nTrue    Yes            NoChangeNeeded {}                                           \n\n\nI have been staring at this code, tweaking, trying different logic...\nHere is what the powershell command returns:\nPS C:\\Windows\\system32> $tom=(get-windowsfeature -name MSMQ-Services).InstallState\nPS C:\\Windows\\system32> echo $tom\nInstalled\n\nFirst thought was that there were leading or trailing spaces, so I did the comparison with \"X$InstallStateX\".\nI tried adding the /OEM flag to ExectoStack.\nI tried variations of if/then logic:\n${If} $Installstate != \"Installed\"\n    <install command>\n${EndIf}\n\nHonestly, I'm not sure if this is a stupid logic flaw (on my part) or some funky output from exectostack that I'm not expecting.\n",
"AnswerId": "76392137",
"AnswerBody": "It was just a CR/LF at the end of the PowerShell output.\nBy changing my statement to:\n${If} $InstallState == \"Installed$\\r$\\n\"\n\nWorked like it should.\nIt's always something simple in the end.\n"
},
{
"QuestionId": "76389426",
"QuestionTitle": "Is there a way to warn C++ developers when they accidentally include internal implementation headers of std library?",
"QuestionBody": "How to let know developers automatically that this \"bits/shared_ptr.h\" is internal to standard library (gcc and clang).\n#include <bits/shared_ptr.h>\n\n// some code using std::shared_ptr\n\n\nThe best would be to also inform <memory> should be used instead.\nThis <bits/shared_ptr.h> is just an example - I mean - how to warn about any implementation header being included.\nBy \"automatically\" I mean - compiler warning or static analysis like clang-tidy.\nI have tried \"-Wall -Wextra -pedantic\" and all clang-tidy checks, without llvm* checks - these llvm* warns for almost every header and it is just for llvm developers, not for us, regular developers.\nAny advice?\nI prefer existing solution, I know I can write script for that.\n\nOk, I found one check in clang-tidy that I can use.\nIt is portability-restrict-system-includes\nJust need to specify in config that \"bits\" things are not allowed:\n-config=\"CheckOptions: {portability-restrict-system-includes.Includes: '*,-bits/*,bitset'}\"\nSee demo.\nBut, well, it is not perfect solution - one would need to maintain list of \"not allowed\" headers.\n",
"AnswerId": "76392179",
"AnswerBody": "It seems like include-what-you-use does what you want.\nIt has a mapping of what names are supposed to come from what header, and it seems to know which headers are internal.\nFor example, when including <bits/shared_ptr.h> https://godbolt.org/z/cvq7354K6:\n#include <bits/shared_ptr.h>\n\nstd::shared_ptr<int> x;\n\nIt says to remove <bits/shared_ptr.h> and add <memory>.\n"
},
{
"QuestionId": "76392017",
"QuestionTitle": "How can I fix incorrect flat lines on my PowerBI line chart with a date hierarchy?",
"QuestionBody": "I have a PowerBI report with a line chart that shows average costs over a time period. The time period is based on a date that is set to use a date hierarchy for the year and the month.\n\nWhen I open the report the line chart does not display correctly. The lines are incorrectly flat.\n\nIf I change the date from a date hierarchy to just the date and then back to the hierarchy, then it displays correctly.\n\nThis also happened when I published the report to the PBI service. What can be done to negate the need to do this?\nI have tried resetting the field for the X-axis and restarting the application.\n",
"AnswerId": "76393019",
"AnswerBody": "Clicking on the double arrow icon to expand the next level by default resolved my issue.\n"
},
{
"QuestionId": "76384859",
"QuestionTitle": "Create Global HTTPS load-balancer with gcloud",
"QuestionBody": "I haven't kept up with changes to GCP's load-balancing, and they've introduced a new kind of global L7 load-balancer, and the ones which I am used to are now termed \"classic\".\nI am not able to find ways to create these new style of load-balancers using gcloud CLI. Is there a way to do this?\n",
"AnswerId": "76392236",
"AnswerBody": "Just to mark the question answered, I will post @John_Hanley's reply here:\nSet the flag like this:\ngcloud gcloud compute backend-services create --load-balancing-scheme=EXTERNAL_MANAGED\n"
},
{
"QuestionId": "76394247",
"QuestionTitle": "Create unique pair of elements in a list based on some attribute of the class/object",
"QuestionBody": "I have a JSON file in the below format\n[\n  { \"name\": \"John\", \"team\": \"NW\", \"available\": true },\n  { \"name\": \"Dani\", \"team\": \"NW\", \"available\": true },\n  { \"name\": \"Lyle\", \"team\": \"NW\", \"available\": false },\n  { \"name\": \"Dean\", \"team\": \"W\", \"available\": true },\n  { \"name\": \"Lyle\", \"team\": \"W\", \"available\": true },\n  { \"name\": \"David\", \"team\": \"W\", \"available\": true },\n  { \"name\": \"George\", \"team\": \"SW\", \"available\": false },\n  { \"name\": \"Luke\", \"team\": \"SW\", \"available\": false }\n]\n\nand the corresponding Java class like below:\npublic class Agent {\n  private String name;\n  private String team;\n  private Boolean available;\n  ...\n  ...\n}\n\nI need to pair members from the list with other people on the list. The rules are that the pair has to be with a member who is available and is from a different team.\nNeed to list the pairs of the members along with any members which could not be paired (odd number of 'pairable' members/not enough members in other teams).\nI have written the code to read the JSON in a list of 'Agent' objects using Jackson and have tried the following approaches till now\n\nIterating over the list and getting the first 'available' member and fetching another one from different team (used stream API/filtering to do this)\nCreate a map of agents (key: team, value: agent list) and iterate the EntrySet to pair the agents with agents from another team.\nNaive approach of creating anew list and adding elements from the original list as and when they are mapped)\n\nHowever, I am getting a lot of agents unmapped. I wanted to write the logic in such a way that it matches/pairs maximum numbers of agents and print the remaining agents in the output alongwith the agents that were paired.\nNot looking for a full blown solution - any pointers will be greatly appreciated!\n",
"AnswerId": "76394291",
"AnswerBody": "To confirm, when running you first,\n\nCheck if the agent is available.\nFind a matching agent from a different team (From the map of agents)\nAnd if a match is found, add the pair of agents to the list of pairs and mark both agents in the EntrySet, otherwise mark the agent as unmatched.\n\nCorrect?\nIf so, it sounds like you already have a good solution to the problem, and I would double check your code to ensure you are following these steps properly. A limitation within the data (Such as very unbalanced team sizes), could also cause you to get unbalanced results.\nIf you wanted another approach though, I would suggest using a 'Maximal Matching' Algorithm, like the Hopcroft-Karp algorithm or the Edmonds' Blossom algorithm to find the maximum matching.\nIn your case, the agents would be represented as nodes in the bipartite graph, Node set 1 representing available agents and Node set 2 representing unavailable agents. Then generate the edges between the two sets, where each node would represent a potential pairing.\nAn overview of the algorithm can be found here; https://www.geeksforgeeks.org/hopcroft-karp-algorithm-for-maximum-matching-set-1-introduction/\nAll you would need to do is generate these nodes and edges, as many implementations of the algorithm can be found online :)\n"
},
{
"QuestionId": "76390788",
"QuestionTitle": "How can I temporarily set a folder as the workspace in VS Code to run specific configurations?",
"QuestionBody": "I have a tree structure with multiple different projects in Visual Studio Code (VS Code). Each project is in a separate folder within the tree structure.\nIs there a way to make one of these folders the current workspace folder ad hoc, so that I can easily run the configuration specific to that folder?\nIs there a way to designate a folder as the active workspace folder temporarily, so that I can execute the configurations specific to that folder without modifying the overall workspace settings?\nI've come across the concept of multi-root workspaces in VS Code, but I'm not sure if it allows me to achieve what I need.\n",
"AnswerId": "76393048",
"AnswerBody": "\nIs there a way to make one of these folders the current workspace folder ad hoc, so that I can easily run the configuration specific to that folder?\n\nAs far as I'm aware, the easiest you'll get is using File: Open File... (if you've never opened the folder / workspace) before, or using File: Open Recent... (these are command palette commands and both of which have keybindings, which you can find in the command palette. They're also both available under the \"File\" menu item)\n\n\nI've come across the concept of multi-root workspaces in VS Code, but I'm not sure if it allows me to achieve what I need.\n\nMulti-root workspaces allow you to create a flat list of workspace roots that are all open at once. You can set configuration for all workspaces by putting it in the .code-workspace file, or per-workspace-root by putting it in their .vscode/settings.json files.\n"
},
{
"QuestionId": "76391976",
"QuestionTitle": "Generate a set of non repeating pairs of users in multiple groups",
"QuestionBody": "I have a dataset that looks like this.\nTo give some context, there can multiple user groups (odd number of people in it). Each of the groups can contain multiple users in it. So, within each and every group, I needed to select pairs of users in such a fashion that,\nA person must not be repeated in any of the pairs, until the entire user list is exhausted. The partial solution below starts pairing users that do not belong to the same group as well. Not sure how to tackle this grouping constraint.\n\n\n\n\ngroup_id\nuser_id\n\n\n\n\n1\na1\n\n\n1\nb1\n\n\n1\nc1\n\n\n1\nd1\n\n\n2\nx1\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndf = [[1, 'a1'], \n      [1, 'b1'], \n      [1, 'c1'], \n      [1, 'd1'], \n      [2, 'x1'], \n      [2, 'y1'], \n      [2, 'z1']]\ndf = pd.DataFrame(df, columns=['group_id', 'user_id'])\ndf.head()\n\nI have a partial solution after going through numerous questions and answers.\nThis solution starts pairing users that do not belong to the same group as well.\nWhich is not what I want:\nfrom itertools import combinations\n\n# Even Number of users Required\nusers = df['user_id'].to_list()\nn = int(len(users) / 2)\n\nstages = []\nfor i in range(len(users) - 1):\n    t = users[:1] + users[-i:] + users[1:-i] if i else users\n    stages.append(list(zip(t[:n], reversed(t[n:]))))\n    \nprint(stages)\n\nNot sure how to store the pairs back into a pandas data frame.\n\nExpected Output (which was updated later on):\nFor group 1 and group 2, note that there can n number of groups:\n\n\n\n\ngroup_id\ncombinations\n\n\n\n\n1\na1-d1\n\n\n1\nb1-c1\n\n\n1\na1-c1\n\n\n1\nd1-b1\n\n\n1\na1-b1\n\n\n2\nx1-x2\n\n\n2\nx2-x3\n\n\n2\nx1-x3\n\n\n\n\nError while running @mozway's code:\nThis error happens for all inputs:\nAssertionError                            Traceback (most recent call last)\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py in _finalize_columns_and_data(content, columns, dtype)\n    981     try:\n--> 982         columns = _validate_or_indexify_columns(contents, columns)\n    983     except AssertionError as err:\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py in _validate_or_indexify_columns(content, columns)\n   1029             # caller's responsibility to check for this...\n-> 1030             raise AssertionError(\n   1031                 f\"{len(columns)} columns passed, passed data had \"\n\nAssertionError: 1 columns passed, passed data had 6 columns\n\nThe above exception was the direct cause of the following exception:\n\nValueError                                Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel_14172\\369883545.py in <module>\n     24     return stages\n     25 \n---> 26 out = (df.groupby(['group_id'], as_index=False)['user_id'].apply(combine).explode('user_id'))\n     27 print(out.head())\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py in apply(self, func, *args, **kwargs)\n   1421         with option_context(\"mode.chained_assignment\", None):\n   1422             try:\n-> 1423                 result = self._python_apply_general(f, self._selected_obj)\n   1424             except TypeError:\n   1425                 # gh-20949\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py in _python_apply_general(self, f, data, not_indexed_same)\n   1467             not_indexed_same = mutated or self.mutated\n   1468 \n-> 1469         return self._wrap_applied_output(\n   1470             data, values, not_indexed_same=not_indexed_same\n   1471         )\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py in _wrap_applied_output(self, data, values, not_indexed_same)\n   1025                 return self.obj._constructor_sliced(values, index=key_index)\n   1026             else:\n-> 1027                 result = self.obj._constructor(values, columns=[self._selection])\n   1028                 self._insert_inaxis_grouper_inplace(result)\n   1029                 return result\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py in __init__(self, data, index, columns, dtype, copy)\n    719                         # ndarray], Index, Series], Sequence[Any]]\"\n    720                         columns = ensure_index(columns)  # type: ignore[arg-type]\n--> 721                     arrays, columns, index = nested_data_to_arrays(\n    722                         # error: Argument 3 to \"nested_data_to_arrays\" has incompatible\n    723                         # type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py in nested_data_to_arrays(data, columns, index, dtype)\n    517         columns = ensure_index(data[0]._fields)\n    518 \n--> 519     arrays, columns = to_arrays(data, columns, dtype=dtype)\n    520     columns = ensure_index(columns)\n    521 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py in to_arrays(data, columns, dtype)\n    881         arr = _list_to_arrays(data)\n    882 \n--> 883     content, columns = _finalize_columns_and_data(arr, columns, dtype)\n    884     return content, columns\n    885 \n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py in _finalize_columns_and_data(content, columns, dtype)\n    983     except AssertionError as err:\n    984         # GH#26429 do not raise user-facing AssertionError\n--> 985         raise ValueError(err) from err\n    986 \n    987     if len(contents) and contents[0].dtype == np.object_:\n\nValueError: 1 columns passed, passed data had 6 columns```\n\n",
"AnswerId": "76393123",
"AnswerBody": "updated answer\nUsing your code here, but applying it per group:\ndef combine(s):\n    users = s.tolist()\n    n = int(len(users) / 2)\n    \n    stages = []\n    for i in range(len(users) - 1):\n        t = users[:1] + users[-i:] + users[1:-i] if i else users\n        stages.extend([f'{a}-{b}' for a,b in zip(t[:n], reversed(t[n:]))])\n    return stages\n\nout = (df.groupby('group_id', as_index=False)['user_id']\n          .apply(combine).explode('user_id')\n      )\n\nOutput:\n   group_id user_id\n0         1   a1-d1\n0         1   b1-c1\n0         1   a1-c1\n0         1   d1-b1\n0         1   a1-b1\n0         1   c1-d1\n1         2   x1-z1\n1         2   x1-y1\n\noriginal answer before question clarirication (incorrect)\nYou can use:\nfrom itertools import combinations\n\nout = [c for k, g in df.groupby('group_id')['user_id']\n       for c in combinations(g, 2)]\n\nOutput:\n[('a1', 'b1'),\n ('a1', 'c1'),\n ('a1', 'd1'),\n ('b1', 'c1'),\n ('b1', 'd1'),\n ('c1', 'd1'),\n ('x1', 'y1'),\n ('x1', 'z1'),\n ('y1', 'z1')]\n\n"
},
{
"QuestionId": "76390308",
"QuestionTitle": "Is there an equivalent of the /hierarchy API endpoint for DSpace 7.x?",
"QuestionBody": "The DSpace OAI-PMH repository exposes an endpoint /hierarchy for API v6, which provides the logical structure of how communities, sub-communities and collections are related. This is documented at https://wiki.lyrasis.org/pages/viewpage.action?pageId=104566810#RESTAPIv6(deprecated)-Hierarchy\nAs v6 will be deprecated, is there a direct replacement for this endpoint in v7?\nThere's no reference to it in the documentation https://wiki.lyrasis.org/display/DSDOC7x/REST+API nor can I see anything equivalent in the live demo: https://api7.dspace.org/server/#/server/api\n",
"AnswerId": "76392296",
"AnswerBody": "There is no exact replacement in DSpace 7 REST API.  But you can retrieve the same information as follows:\n\nStart from the \"Top level Communities\" search endpoint here: https://github.com/DSpace/RestContract/blob/main/communities.md#search-methods\n\nThis will retrieve all the communities at the top of that hierarchy\n\n\nThen, for each of those top Communities, it's possible to retrieve their sub-communities and sub-collections via the \"linked entities\"\n\nSub-Communities: https://github.com/DSpace/RestContract/blob/main/communities.md#subcommunities\nSub-Collections: https://github.com/DSpace/RestContract/blob/main/communities.md#collections\n\n\n\nThis is how the hierarchy is achieved in the DSpace 7 User Interface when you visit the \"/community-list\" page, e.g. https://demo7.dspace.org/community-list\n"
},
{
"QuestionId": "76392027",
"QuestionTitle": "TypeScript array intersection type: property does not exist when accessed in Array.forEach, Array.some, etc, but accessible within for loop",
"QuestionBody": "So, I might not have the right terminology to describe this problem, which made searching for it tricky, but I hope my example helps clear it up.\nContext: I'm using query data selectors in react-query to preprocess query results and attach some properties that I need globally in the application. I'm running into an issue with the produced types, which I managed to narrow down and reproduce outside of react-query itself.\nHere's the reproduction code (also on TS Playground)\n// Data structure coming from third-party code (I have no control over it)\n// Simplified for a more concise reproduction:\ntype DataStructure =\n  & Array<{ a: number; b: number }>\n  & Array<{ b: number; c: number }>\n\nconst structure: DataStructure = [\n  {\n    a: 1,\n    b: 2,\n    c: 3,\n  },\n]\n\nstructure[0].a // ok\nstructure[0].b // ok\nstructure[0].c // ok\n\nfor (const s of structure) {\n  s.a // ok\n  s.b // ok\n  s.c // ok\n}\n\nstructure.forEach(s => {\n  s.a // ok\n  s.b // ok\n  s.c // Property 'c' does not exist on type '{ a: number; b: number; }'.(2339)\n})\n\n// If we had control over DataStructure, we'd write it like this instead:\n// Array<{ a: number; b: number } & { b: number; c: number }>\n\n\nThe DataStructure is an intersection type of two Arrays with partially overlapping item types.\nAs demonstrated by the code and the comments, all 3 properties are available when the array items are accessed either by their index or inside a for loop, but inside a forEach loop (or any array method like some, every, etc,) only properties of the first array type (from the intersection) are available.\nTrying to access c inside the forEach loop, TypeScript complains:\nProperty 'c' does not exist on type '{ a: number; b: number; }'.(2339)\n\nNow, if I had control over the data structure definition, I'd describe it like this:\ntype DataStrcture = Array<{ a: number; b: number } & { b: number; c: number }>\n\nThat would indeed solve the issue. But I don't have control over that part of the code.\nWhat I'm more interested in is understanding WHY TypeScript behaves the way it does here. That's what's baffling me the most, but if someone can offer a clean solution, too, that'd be extra amazing!\n",
"AnswerId": "76393168",
"AnswerBody": "This is considered a design limitation of TypeScript. Intersections of array types behave strangely and are not recommended.  See microsoft/TypeScript#41874 for an authoritative answer. It says:\n\nArray intersection is weird since there are many invariants of arrays and many invariants of intersections that can't be simultaneously met. For example, if it's valid to call a.push(x) when a is A, then it should be valid to write ab.push(x) when ab is A & B, but that creates an unsound read on (A & B)[number].\nIn higher-order the current behavior is really the best we can do; in zero-order it's really preferable to just write Array<A & B>, Array<A> | Array<B>, or Array<A | B> depending on which you mean to happen.\n\nSome of the weirdness is due to the fact that intersections of functions and methods behave like overloads, and arrays are unsafely considered covariant in their element type (see Why are TypeScript arrays covariant? ), which means you suddenly have the situation with push() as described above.\nOther weirdness happens when you try to iterate through them, as you've shown, and as described in microsoft/TypeScript#39693.\n\nSo the recommended approach is to avoid intersections of arrays, and instead use arrays of intersections if that's what you want.  If you can write that out directly, you should.  If you have a type with nested intersected arrays you can look at Why does the merge of 2 types with a shared property name not work when making a type with that property from the merged type? for a possible approach to writing a utility type to deal with those.\nAs I mentioned in the comment, if you can't control the data type, you should show this to whoever does so they can fix it.  Otherwise, you'll need to work around it by translating between the external type definition and your fixed version of it.\n"
},
{
"QuestionId": "76390991",
"QuestionTitle": "From a list, how to get only the items with dates within a certain time period?",
"QuestionBody": "I have a list of items, each item has a date value:\n[\n  {\n    \"Date Merged\": \"6/1/2023 3:46:53 PM\",\n    \"PR ID\": \"470\"\n  },\n  {\n    \"Date Merged\": \"5/30/2023 2:44:25 PM\",\n    \"PR ID\": \"447\"\n  }\n]\n\nI want to get only the PRs of the items with dates that happened in May. I think I can grab the 'PR ID' values with: map(attribute='PR ID'), but I don't know how to filter within a certain date range.\n",
"AnswerId": "76393253",
"AnswerBody": "Given the data\n  prs:\n    - Date Merged: 6/1/2023 3:46:53 PM\n      PR ID: '470'\n    - Date Merged: 5/30/2023 2:44:25 PM\n      PR ID: '447'\n\nQ: \"Get the PRs with dates that happened in May.\"\nA: There are more options:\n\nQuick & dirty. The test match \"succeeds if it finds the pattern at the beginning of the string\"\n\n  result: \"{{ prs|selectattr('Date Merged', 'match', '5')|\n                  map(attribute='PR ID') }}\"\n\ngives\n  result:\n  - '447'\n\n\nUse the filter to_datetime to get the date objects and create the list of the hashes\n\n  format: '%m/%d/%Y %I:%M:%S %p'\n  months: \"{{ prs|map(attribute='Date Merged')|\n                  map('to_datetime', format)|\n                  map(attribute='month')|\n                  map('community.general.dict_kv', 'month') }}\"\n\ngives\n  months:\n  - month: 6\n  - month: 5\n\nUpdate the dictionaries\n  prs_months: \"{{ prs|zip(months)|map('combine') }}\"\n\ngives\n  prs_months:\n  - Date Merged: 6/1/2023 3:46:53 PM\n    PR ID: '470'\n    month: 6\n  - Date Merged: 5/30/2023 2:44:25 PM\n    PR ID: '447'\n    month: 5\n\nSelect the items and get the ids\n  result: \"{{ prs_months|selectattr('month', 'eq', 5)|\n                         map(attribute='PR ID') }}\"\n\ngives the same result\n  result:\n  - '447'\n\n\n\nExample of a complete playbook for testing\n- hosts: localhost\n\n  vars:\n\n    prs:\n      - Date Merged: 6/1/2023 3:46:53 PM\n        PR ID: '470'\n      - Date Merged: 5/30/2023 2:44:25 PM\n        PR ID: '447'\n\n    result1: \"{{ prs|selectattr('Date Merged', 'match', '5')|\n                     map(attribute='PR ID') }}\"\n\n    format: '%m/%d/%Y %I:%M:%S %p'\n    months: \"{{ prs|map(attribute='Date Merged')|\n                    map('to_datetime', format)|\n                    map(attribute='month')|\n                    map('community.general.dict_kv', 'month') }}\"\n    prs_months: \"{{ prs|zip(months)|map('combine') }}\"\n    result2: \"{{ prs_months|selectattr('month', 'eq', 5)|\n                            map(attribute='PR ID') }}\"\n\n  tasks:\n\n    - debug:\n        var: result1\n\n    - debug:\n        var: months\n    - debug:\n        var: prs_months\n    - debug:\n        var: result2\n\n\n"
},
{
"QuestionId": "76389963",
"QuestionTitle": "WinDbg | Application memory full dump - Show file path of file handle",
"QuestionBody": "I created a memory dump of an application with procdump -ma abc.exe.\nThe application access various files.\nI run !handle 0 f FILE and get over 100 file handles.\nWhen I get a specific handle address, I run the following command !handle 000000000000161c f which results in:\n0:000> !handle 000000000000161c f\nHandle 000000000000161c\n  Type          File\n  Attributes    0\n  GrantedAccess 0x12019f:\n         ReadControl,Synch\n         Read/List,Write/Add,Append/SubDir/CreatePipe,ReadEA,WriteEA,ReadAttr,WriteAttr\n  HandleCount   2\n  PointerCount  65479\n  No object specific information available\n\nIs there a chance to retrieve the actual file path? Something like that: How get file path by handle in windbg? seems to work only in kernel mode debugging.\n",
"AnswerId": "76392419",
"AnswerBody": "For post-mortem debugging (crash dump analysis), there's no way, except if you have a kernel dump (I can't tell you how to do that then). Windows will close handles of a process that terminated.\n!handle combined with !handleex\nThere is handleex on Github.\nCombine !handle and !handleex to get nice information.\n.foreach /pS 1 /ps 1 (file {!handle 0 4 FILE}) { .echo Handle file; !handleex file; .echo }\n\nExample output\n0:007> .foreach /pS 1 /ps 1 (file {!handle 0 4 FILE}) { .echo Handle file; !handleex file; .echo }\nHandle 4c\nObject Type: File\nHandle Name: \\Device\\HarddiskVolume3\\Users\\T\n\nHandle 8c\nObject Type: File\nHandle Name: \\Device\\HarddiskVolume3\\Windows\\WinSxS\\amd64_microsoft.windows.common-controls_6595b64144ccf1df_6.0.19041.1110_none_60b5254171f9507e\n\nHandle b4\nObject Type: File\nHandle Name: \\Device\\HarddiskVolume3\\Windows\\System32\\en-US\\notepad.exe.mui\n\n...\n\n!handle combined with SysInternals Handle\nYou can combine the !handle WinDbg command and the SysInternals Handle tool.\nExample notepad debugging session:\n:018> !handle 0 1 FILE\nHandle 4c\n  Type          File\nHandle 8c\n  Type          File\nHandle b8\n  Type          File\nHandle 134\n  Type          File\n...\n\nCombined with the information from the console:\nC:\\...>handle -p notepad.exe | findstr 8C:\n   8C: File          C:\\Windows\\WinSxS\\amd64_microsoft.windows.common-controls_6595b64144ccf1df_6.0.19041.1110_none_60b5254171f9507e\n\nC:\\...>handle -p notepad.exe | findstr B8:\n   B8: File          C:\\Windows\\System32\\en-US\\notepad.exe.mui\n\nAutomating it doesn't really work well:\n0:007> .printf \"%d\\n\",$tpid\n2168\n0:007> .foreach /pS 1 /ps 1 (file {!handle 0 4 FILE}) { .shell C:\\handle.exe -p 2168 | findstr file: }\n\nThe process seems to be too slow and require too much user input.\n"
},
{
"QuestionId": "76389602",
"QuestionTitle": "How to get SKTypeface.FromFamilyName to return a font for Japanese, Korean, Chinese (Android + iOS, Xamarin.Forms)",
"QuestionBody": "I'm using a library that uses SKTypeface.FromFamilyName internally to render font on the screen. However, as I found out if the text to display is japanese, korean or chinese, it just prints squares. I tried to add a custom font to my project but I was not able to make SKTypeface.FromFamilyName return anything but NULL with custom fonts. As I have no access to change SKTypeface.FromFamilyName to something else ( at least as far as I know because it's in a private method of a static class - https://github.com/Mapsui/Mapsui/blob/5008d3ab8b0453c27cb487fe6ad3fac87435abbe/Mapsui.Rendering.Skia/LabelRenderer.cs#L277 ), is there any way I can make it return any font for each language (or one per language) that works with these?\n",
"AnswerId": "76392485",
"AnswerBody": "Alright, I found a solution for this. This seems to work for me:\nstring fontFamily;\nswitch (Thread.CurrentThread.CurrentUICulture.TwoLetterISOLanguageName.ToLower())\n{\n    case \"ja\":\n        fontFamily = SKFontManager.Default.MatchCharacter('あ').FamilyName;\n        break;\n\n    case \"ko\":\n        fontFamily = SKFontManager.Default.MatchCharacter('매').FamilyName;\n        break;\n\n    case \"zh\":\n        fontFamily = Thread.CurrentThread.CurrentUICulture.IetfLanguageTag.ToLower() switch\n            {\n                \"zh-cn\" => SKFontManager.Default.MatchCharacter('实').FamilyName,\n                \"zh-tw\" => SKFontManager.Default.MatchCharacter('實').FamilyName,\n                _ => null\n            };\n        break;\n\n    default:\n        fontFamily = null;\n        break;\n}\n\n"
},
{
"QuestionId": "76391957",
"QuestionTitle": "Function return type depending on argument type",
"QuestionBody": "I have the following code where the useSearchResults function (it's a React hook, but it doesn't matter) initializes the state based on the argument.\nconfig.state can be anything defined in SearchResultsState or a function that returns anything defined in SearchResultsState.\nThe state returned by useSearchResults is defined as Partial<SearchResultsState> because, initially could be anything in that state type. I need state to be a partial SearchResultsState but also whatever type config.state has (an object or the object returned by a function or undefined).\nI've trying and trying around this but couldn't find a solution.\n\ntype State = Record<string, any>;\ninterface IWidget {\n  State: State;\n}\ninterface SearchResultsState extends State {\n  a: number; \n  b: string;\n}\n\ninterface SearchResultsWidget extends IWidget {\n  State: SearchResultsState;\n}\nexport type StateInitializerFunction<W extends IWidget> = () => Partial<W['State']>;\nexport type StateInitializer<W extends IWidget> = StateInitializerFunction<W> | Partial<W['State']>;\n\nexport type WidgetInitializer<W extends IWidget> = {\n  state?: StateInitializer<W>;\n};\n\nexport type WidgetWrapperResult<\n  W extends IWidget,\n> = {\n  state: Partial<W['State']>;\n};\n\n\nconst useSearchResults = (\n  config: WidgetInitializer<SearchResultsWidget> = {},\n): WidgetWrapperResult<SearchResultsWidget> => {\n  const state = typeof config.state === 'function' ? config.state() : config.state || {};\n  \n  return { state };\n};\n\nconst { state: { a, b } } = useSearchResults({ state: { a: 1 } });\n// or const { state: { a, b } } = useSearchResults({ state: () => ({ a: 1 }) });\n\nconst test = (a: number) => console.log(a);\n\n// error\ntest(a); // a is number | undefined and I'm looking to be just number because a is number in state\n\n\nYou can play with it here\n",
"AnswerId": "76393265",
"AnswerBody": "If you want a function's return type to depend on its argument type then you either need to overload it with multiple call signatures, or generic in some number of type parameters.  Overloads only work if you have a relatively small number of ways you want to call the function, while generics are more appropriate to represent an arbitrary relationship between input and output.\n\nOverloads might work for this use case, if you only want to support the four possible cases for a and b being present or possibly absent, but it's tedious:\nfunction useSearchResults(\n  config: { state?: { a: number, b: string } | (() => { a: number, b: string }) }\n): { state: { a: number, b: string } };\nfunction useSearchResults(\n  config: { state?: { a: number, b?: string } | (() => { a: number, b?: string }) }\n): { state: { a: number, b?: string } };\nfunction useSearchResults(\n  config: { state?: { a?: number, b: string } | (() => { a?: number, b: string }) }\n): { state: { a?: number, b: string } };\nfunction useSearchResults(\n  config: { state?: { a?: number, b?: string } | (() => { a?: number, b?: string }) }\n): { state: { a?: number, b?: string } };\n\nfunction useSearchResults(\n  config: WidgetInitializer<SearchResultsWidget> = {},\n): WidgetWrapperResult<SearchResultsWidget> {\n  const state = typeof config.state === 'function' ? config.state() : config.state || {};\n\n  return { state };\n};\n\nconst { state: { a, b } } = useSearchResults({ state: { a: 1 } });\n/* (property) state: {\n  a: number;\n  b?: string | undefined;\n} */\n\nuseSearchResults({ state: () => ({ a: 1 }) }).state.a\n\n\nThat can quickly get out of hand, though, so you might need to use generics instead.  Once you use generics you need to make the generic type arguments inferrable from the inputs, but you can't do that with indexed access types like W[\"state\"] (there was a pull request at ms/TS#20126 which would have made this possible, but it's not part of the language now.  A new PR at ms/TS#53017 might be merged eventually, but for now it's not.)\nSo you'll need to refactor significantly to use that type directly.  Possibly as shown here:\ntype StateInitializerFunction<S extends State> = () => S;\ntype StateInitializer<S extends State> = StateInitializerFunction<S> | S;\ntype WidgetInitializer<S extends State> = { state?: StateInitializer<S>; };\ntype WidgetWrapperResult<S extends State> = { state: S; };\n\nconst useSearchResults = <S extends Partial<SearchResultsState>>(\n  config: WidgetInitializer<S> = {},\n): WidgetWrapperResult<S & Partial<SearchResultsState>> => {\n  const state = typeof config.state === 'function' ? config.state() : config.state || {};\n  return { state } as any;\n};\n\nHere what I've done is replace mentions of W with just its state property type S. I've also replaced the Partial stuff in the definitions and moved it to the function. Now the function useSearchResults accepts a WidgetInitializer<S> for some S that extends Partial<SearchResultsState>, and it returns a WidgetWrapperResults<S & Partial<SearchResultsState>>.  That intersection just helps make sure the compiler is still aware of b's existence when you don't pass it.  Let's test it:\nconst { state: { a, b } } = useSearchResults({ state: { a: 1 } });\n/* (property) state: {\n    a: number;\n} & Partial<SearchResultsState> */\n\nconst test = (a: number) => console.log(a);\n\nuseSearchResults({ state: () => ({ a: 1 }) }).state.a\n\ntest(a);\n\nLooks good!\nPlayground link to code\n"
},
{
"QuestionId": "76389562",
"QuestionTitle": "Excel 2016 - compare two columns for match",
"QuestionBody": "I have two columns where I want to highlight differences \nI want to see if the letter in Column A exists in Column B - it should be case-sensitive, because there are C and c in column A\nIf there is a match I want the row preferably turn green - otherwise a OK / NOT OK in column C\nThank you in advance\n",
"AnswerId": "76392514",
"AnswerBody": "Copy this Sub to the Worksheet code pane. For this open the Developer tab and click Visual Basic. In the left pane select the worksheet where your datas are, and doubleclick it. Insert the code.\nPrivate Sub Worksheet_Change(ByVal Target As Excel.Range)\nIf Target.Column = 1 And InStr(1, Target.Offset(0, 1).Value, Target.Value) > 0 Then\nTarget.EntireRow.Interior.Color = vbGreen\nElse\nTarget.EntireRow.Interior.ColorIndex = xlColorIndexNone\nEnd If\nIf Target.Column = 2 Then\nIf InStr(1, Target.Value, Target.Offset(0, -1)) > 0 Then\nTarget.EntireRow.Interior.Color = vbGreen\nElse\nTarget.EntireRow.Interior.ColorIndex = xlColorIndexNone\nEnd If\nEnd If\nEnd Sub\n\n\nIf the content change in column A or B the respective row color will change.\n"
},
{
"QuestionId": "76382415",
"QuestionTitle": "Why does my Python code using scipy.curve_fit() for Planck's Radiation Law produce 'popt=1' and 'pcov=inf' errors?",
"QuestionBody": "Covariance not estimated in SciPy's Curvefit\nHere's my dataset:\nfrequency (Hz)  brightness (ergs/s/cm^2/sr/Hz)  brightness (J/s/m^2/sr/Hz)\nfloat64 float64 float64\n34473577711.372055  7.029471536390586e-16   7.029471536390586e-19\n42896956937.69582   1.0253178228238486e-15  1.0253178228238486e-18\n51322332225.44733   1.3544045476166584e-15  1.3544045476166584e-18\n60344529880.18272   1.6902073280174815e-15  1.6902073280174815e-18\n68767909106.5062    2.0125779972022745e-15  2.0125779972022743e-18\n77780126454.10146   2.3148004995630144e-15  2.3148004995630145e-18\n... ... ...\n489996752265.52826  3.201319839821188e-16   3.201319839821188e-19\n506039097962.6759   2.5968748350997043e-16  2.596874835099704e-19\n523273092332.3638   2.0595903864583913e-16  2.0595903864583912e-19\n539918248580.7806   1.7237876060575648e-16  1.7237876060575649e-19\n557158231134.7507   1.3879848256567381e-16  1.3879848256567383e-19\n573803387383.1646   1.0521820452559118e-16  1.0521820452559118e-19\n591049358121.42 9.178609330955852e-17   9.178609330955852e-20\n\nI tried to use CurveFit to fit this to Planck's Radiation Law:\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\nh=6.626*10e-34\nc=3*10e8\nk=1.38*10e-23\nconst1=2*h/(c**2)\nconst2=h/k\n\ndef planck(x,v):\n    return const1*(v**3)*(1/((np.exp(const2*v/x))-1))\n\npopt,pcov= curve_fit(planck, cmb['frequency (Hz)'],cmb['brightness (J/s/m^2/sr/Hz)'])\nprint(popt, pcov)\n\nWarning:\n/tmp/ipykernel_2500/4072287013.py:11: RuntimeWarning: divide by zero encountered in divide\n  return const1*(v**3)*(1/((np.exp((const2)*v/x))-1))\n\nI get popt=1 and pcov=nan. Now the exponential term in the function differs by several orders of magnitude. And some of the values don't permit to approximate the law mathematically. I tried using the logarithmic form of the law but that doesn't work either. How can I overcome this problem?\n",
"AnswerId": "76393313",
"AnswerBody": "A lot of problems here, including that your variables were swapped, you're needlessly redefining physical constants, and your expression was highly numerically unstable. You need to use exp1m instead:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.constants import h, c, k\nfrom scipy.optimize import curve_fit\n\nfreq, brightness_erg, brightness_j = np.array((\n    (34473577711.372055, 7.0294715363905860e-16, 7.0294715363905860e-19),\n    (42896956937.695820, 1.0253178228238486e-15, 1.0253178228238486e-18),\n    (51322332225.447330, 1.3544045476166584e-15, 1.3544045476166584e-18),\n    (60344529880.182720, 1.6902073280174815e-15, 1.6902073280174815e-18),\n    (68767909106.506200, 2.0125779972022745e-15, 2.0125779972022743e-18),\n    (77780126454.101460, 2.3148004995630144e-15, 2.3148004995630145e-18),\n    (489996752265.52826, 3.2013198398211880e-16, 3.2013198398211880e-19),\n    (506039097962.67590, 2.5968748350997043e-16, 2.5968748350997040e-19),\n    (523273092332.36380, 2.0595903864583913e-16, 2.0595903864583912e-19),\n    (539918248580.78060, 1.7237876060575648e-16, 1.7237876060575649e-19),\n    (557158231134.75070, 1.3879848256567381e-16, 1.3879848256567383e-19),\n    (573803387383.16460, 1.0521820452559118e-16, 1.0521820452559118e-19),\n    (591049358121.42000, 9.1786093309558520e-17, 9.1786093309558520e-20),\n)).T\n\n\ndef planck(v: np.ndarray, T: float) -> np.ndarray:\n    return 2*h/c/c * v**3 / np.expm1(h*v/k/T)\n\nguess = 2.5,\n\n(T,), _ = curve_fit(\n    f=planck, xdata=freq, ydata=brightness_j, p0=guess, method='lm',\n    # bounds=(0.1, np.inf),\n)\nprint('T =', T)\n\nfig, ax = plt.subplots()\nv = np.linspace(freq.min(), freq.max(), 500)\nax.scatter(freq, brightness_j, label='data')\nax.plot(v, planck(v, *guess), label='guess')\nax.plot(v, planck(v, T), label='fit')\nax.legend()\nplt.show()\n\n\n"
},
{
"QuestionId": "76387822",
"QuestionTitle": "Snowflake Flatten and parsing values",
"QuestionBody": "I have a snowflake table that has VARCHAR column containing input from api. I have 300+ columns to be flattened and one of them has input like below for a particular row. I need to parse the values from the below (please refer output) and store it as a single row for a particular input row. The number of elements inside the input list might be 1 or more than 1 but the order of the keys present remain same.\nInput:\n[\n{\"active\":false,\"urls\":{\"6x6\":\"https://url.url.com/secure/?size=xsmall&ownerId=B12345&id=123\",\"4x4\":\"https://url.url.com/secure/?size=small&ownerId=B12345&id=123\",\"22x22\":\"https://url.url.com/secure/?size=medium&ownerId=B12345&id=123\",\"44x44\":\"https://url.url.com/secure/?ownerId=B12345&id=123\"},\"displayName\":\"Name1,Lname1\",\"emailAddress\":\"\",\"key\":\"B12345\",\"name\":\"B12345\",\"self\":\"https://url.url.com/rest/api/2/user?username=B12345\",\"timeZone\":\"India/Mumbai\"},\n\n\n{\"active\":true,\"urls\":{\"6x6\":\"https://url.url.com/secure/?size=xsmall&ownerId=A12345&id=456\",\"4x4\":\"https://url.url.com/secure/?size=small&ownerId=A12345&id=456\",\"22x22\":\"https://url.url.com/secure/?size=medium&ownerId=A12345&id=456\",\"44x44\":\"https://url.url.com/secure/?ownerId=A12345&id=456\"},\"displayName\":\"Name1,Lname2.\",\"emailAddress\":\"name.lname@abcdef.com\",\"key\":\"A12345\",\"name\":\"A12345\",\"self\":\"https://url.url.com/rest/api/2/user?username=A12345\",\"timeZone\":\"India/Mumbai\"}\n\n \n{\"active\":true,\"urls\":{\"6x6\":\"https://url.url.com/secure/?size=xsmall&ownerId=C12345&id=456\",\"4x4\":\"https://url.url.com/secure/?size=small&ownerId=C12345&id=456\",\"22x22\":\"https://url.url.com/secure/?size=medium&ownerId=C12345&id=456\",\"44x44\":\"https://url.url.com/secure/?ownerId=C12345&id=456\"},\"displayName\":\"Name1,Lname3.\",\"emailAddress\":\"name.lname@abcdef.com\",\"key\":\"C12345\",\"name\":\"C12345\",\"self\":\"https://url.url.com/rest/api/2/user?username=C12345\",\"timeZone\":\"India/Mumbai\"}\n ]\n\nOutput I am looking for is: list of values of the keys (nested)\n[ \n[false,\n[https://url.url.com/secure/?size=xsmall&ownerId=B12345&id=123,\nhttps://url.url.com/secure/?size=small&ownerId=B12345&id=123,\nhttps://url.url.com/secure/?size=medium&ownerId=B12345&id=123,\nhttps://url.url.com/secure/?ownerId=B12345&id=123], Name1, Lname1, ,\nB12345, B12345, https://url.url.com/rest/api/2/user?username=B12345,\nIndia/Mumbai],  \n\n[true,\n[https://url.url.com/secure/?size=xsmall&ownerId=A12345&id=456,\nhttps://url.url.com/secure/?size=small&ownerId=A12345&id=456,\nhttps://url.url.com/secure/?size=medium&ownerId=A12345&id=456,\nhttps://url.url.com/secure/?ownerId=A12345&id=456], Name1, Lname2.,\nname.lname@abcdef.com, A12345,\nA12345,https://url.url.com/rest/api/2/user?username=B12345,\nIndia/Mumbai] ,\n\n[true,\n[https://url.url.com/secure/?size=xsmall&ownerId=C12345&id=456,\nhttps://url.url.com/secure/?size=small&ownerId=C12345&id=456,\nhttps://url.url.com/secure/?size=medium&ownerId=C12345&id=456,\nhttps://url.url.com/secure/?ownerId=C12345&id=456], Name1, Lname3.,\nname.lname@abcdef.com, C12345,\nC12345,https://url.url.com/rest/api/2/user?username=B12345,\nIndia/Mumbai] \n]\n\nQuery that I tried:\nSELECT  \nCONCAT('[[',\nREPLACE(GET(flattened.value,  'active'), '\"', '') , ', ',\n'[',\nlistagg(CASE WHEN flattened_nested.value LIKE '%https%' THEN 'https:' || REPLACE(SPLIT_PART(flattened_nested.value, ':', 2), '\"', '') ELSE NULL END,',')within group (order by null)\n\n,']', ', ',  --<== this causes issue while trying to parse urls values for each elements and to store them.\nREPLACE(GET(flattened.value,  'displayName'), '\"', '') , ', ',\nREPLACE(GET(flattened.value,  'emailAddress'), '\"', '') , ', ',\nREPLACE(GET(flattened.value,  'key'), '\"', '') , ', ',\nREPLACE(GET(flattened.value,  'name'), '\"', '')  , ', ',\nREPLACE(GET(flattened.value,  'self'), '\"', '') , ', ',\nREPLACE(GET(flattened.value,  'timeZone'), '\"', ''),   \n\n']]')  as output_column\nFROM snowflake_table  SRC\n\n,LATERAL FLATTEN(input=>SRC.json_values:\"fields\":\"field_12345\") AS flattened --<== the field that contains the above input.\n,LATERAL FLATTEN(input=>flattened.value:urls) AS flattened_nested\ngroup by  flattened.value\n;\n\n\nThe below output that I get is aggregating all the 3 urls value for a particular input and stores it as comma separated. but, it doesn't take the other values like displayname, key,name, self etc for all 3 elements. It gives me only the first occurrence.\n\nThe other issue with this approach is if I need to include other 300+ columns, I have place everything in group by clause.\n\n\n\n[ [false,\n[https://url.url.com/secure/?size=xsmall&ownerId=B12345&id=123,\nhttps://url.url.com/secure/?size=small&ownerId=B12345&id=123,\nhttps://url.url.com/secure/?size=medium&ownerId=B12345&id=123,\nhttps://url.url.com/secure/?ownerId=B12345&id=123,https://url.url.com/secure/?size=xsmall&ownerId=A12345&id=456,\nhttps://url.url.com/secure/?size=small&ownerId=A12345&id=456,\nhttps://url.url.com/secure/?size=medium&ownerId=A12345&id=456,\nhttps://url.url.com/secure/?ownerId=A12345&id=456,https://url.url.com/secure/?size=xsmall&ownerId=C12345&id=456,\nhttps://url.url.com/secure/?size=small&ownerId=C12345&id=456,\nhttps://url.url.com/secure/?size=medium&ownerId=C12345&id=456,\nhttps://url.url.com/secure/?ownerId=C12345&id=456], Name1, Lname1, ,\nB12345, B12345, https://url.url.com/rest/api/2/user?username=B12345,\nIndia/Mumbai] ]\n\nCan anyone please let me know how to get the desired output with any different approach irrespective of the number of input elements inside the list?\n",
"AnswerId": "76394313",
"AnswerBody": "This won't produce the nested JSON, but it should I believe pick-out the values you want, and from there you should be able to form the JSON from it:\nSELECT \n      t.value:active::BOOLEAN AS active\n    , ARRAY_AGG(t.value:urls) WITHIN GROUP (ORDER BY seq) AS urls\n    , SPLIT_PART(t.value:displayName::STRING, ',', 1) AS firstName\n    , SPLIT_PART(t.value:displayName::STRING, ',', 2) AS lastName\n    , t.value:emailAddress::STRING AS emailAddress\n    , t.value:key::STRING AS key\n    , t.value:name::STRING AS name\n    , t.value:self::STRING AS self\n    , t.value:timeZone::STRING AS timeZone\nFROM snowflake_table\n    , LATERAL FLATTEN(input => json_values) t\nGROUP BY active, firstName, lastName, emailAddress, key, name, self, timeZone;\n\nAn alternative syntax via JSON_PARSE is also possible I feel:\nSELECT \n      json_values:active::BOOLEAN AS active\n    , ARRAY_AGG(json_values:urls) AS urls\n    , json_values:displayName::STRING AS displayName\n    , json_values:emailAddress::STRING AS emailAddress\n    , json_values:key::STRING AS key\n    , json_values:name::STRING AS name\n    , json_values:self::STRING AS self\n    , json_values:timeZone::STRING AS timeZone\nFROM snowflake_table\n    , LATERAL JSON_PARSE(json_values) AS json_values\nGROUP BY active, displayName, emailAddress, key, name, self, timeZone;\n\nYou may want to consider both for ease of application of the final step and relative performance. It does feel like using JSON_VALUES is easier to understand but the difference in that is very a=marginal.\n"
},
{
"QuestionId": "76394361",
"QuestionTitle": "A more organic way to resolve and return a resolved promise from a JavaScript/Node function than using Promise.resolve?",
"QuestionBody": "For instance, I'm writing a Mongoose utility method, and I'm wanting to return a value after the async methods resolve. This is a highly simplified example.\nconst testConnect = () => {\n    let msg;\n    mongoose.connect(mongoServer.getUri())\n        .then(() => {\n            msg =\"Connection success!\";\n        })\n        .catch((err) => {\n            msg = \"Connection failure! Error: \" + err;\n        });\n    return Promise.resolve(msg);\n};\n\nMy test buildup utilizes this method in a matter like this.\nbeforeAll(() => {\n    iMDT.testConnect()\n        .then((result) => {\n            console.log(result);\n        })\n        .catch((err) => {\n            console.log(err);\n        });\n});\n\nIs there a simpler, more organic way to return that value as a resolved promise - without using the prototype Promise? It feels kludgy to me.\n",
"AnswerId": "76394377",
"AnswerBody": "What you're attempting to do won't work because your asynchronous operation is non-blocking so you will do return Promise.resolve(msg); before there's even a value in msg.  It's almost always a warning sign when you're assigning higher scoped variables inside of a .then() or .catch() handler and then trying to use those variables at the top scope.  That won't work because of timing issues (attempting to use the variable before its value is set).\nInstead, you can just return the promise directly.  The general advice is to use the promises you already have and not create new ones unnecessarily.  Return the one you already have like this:\nconst testConnect = () => {\n    return mongoose.connect(mongoServer.getUri()).then(() => {\n        // set the final resolved value\n        return \"Connection success!\";\n    }).catch((err) => {\n        // set the final rejected reason object\n        throw new Error(\"Connection failure! Error:\"  + err.message, { cause: err });\n    });\n};\n\nNote, how the failure code path returns a rejected promise that contains a human readable message and also contains the original error object as the cause.  This is the usual way to use promises, not to hide the rejection by returning a different resolved value.  This allows the caller to more easily know if the operation succeeded or failed without having to compare to specific resolved values.\nAnd, this is also what your beforeAll() code block is expecting.  It is expecting a rejected promise if the operation fails which is not what your first code block was doing.\n"
},
{
"QuestionId": "76384965",
"QuestionTitle": "Behavior of `git push --force` when no upstream branch exists",
"QuestionBody": "What's the behavior of git push --force when no upstream branch exists?\nWill I get something like fatal: The current branch branch_name has no upstream branch, as would happen with a normal push, or would the upstream branch be \"forcefully\" created?\n",
"AnswerId": "76392645",
"AnswerBody": "--force does not change the behaviour of git push without an upstream set (when no push.default and push.autoSetupRemote config is set) empirically with git 2.40.0.\n$ git checkout -b dev/test\nSwitched to a new branch 'dev/test'\n$ git push\nfatal: The current branch dev/test has no upstream branch.\nTo push the current branch and set the remote as upstream, use\n\n    git push --set-upstream origin dev/test\n\nTo have this happen automatically for branches without a tracking\nupstream, see 'push.autoSetupRemote' in 'git help config'.\n\n$ git push --force\nfatal: The current branch dev/test has no upstream branch.\nTo push the current branch and set the remote as upstream, use\n\n    git push --set-upstream origin dev/test\n\nTo have this happen automatically for branches without a tracking\nupstream, see 'push.autoSetupRemote' in 'git help config'.\n\n"
},
{
"QuestionId": "76390292",
"QuestionTitle": "Oracle Date ranges that are present in parent rows but not in child rows",
"QuestionBody": "Dates ranges that are found in rule1 but 'not in' rule2 E.g.,\n\n\n\n\nitem_no\nitem_type\nactive_from\nactive_to\nruleid\n\n\n\n\n10001\nSAR\n2022-01-01\n2023-05-31\nrule1\n\n\n10001\nSAR\n2023-07-01\n2099-12-31\nrule1\n\n\n10001\nSAR\n2023-01-01\n9999-12-31\nrule2\n\n\n10001\nSAR\n2020-12-01\n2021-12-31\nrule2\n\n\n\n\nIn this case output will be the date ranges which are in rule1 but not in rule2 is.\n10001 SAR 2022-01-01 2022-12-31 \n\nI have used connect by level which is taking more time to generate dates and compare them.. as date end is 9999-12-31.\n",
"AnswerId": "76392654",
"AnswerBody": "Adapting my answer to your previous question, from Oracle 12, you can UNPIVOT the dates and then use analytic functions and MATCH_RECOGNIZE to process the result set row-by-row to find the consecutive rows where rule1 is active and rule2 is inactive:\nSELECT item_no,\n       item_type,\n       active_from\n       + CASE\n         WHEN prev_rule2 > 0\n         THEN INTERVAL '1' SECOND\n         ELSE INTERVAL '0' SECOND\n         END AS active_from,\n       active_to\n       - CASE\n         WHEN next_rule2 > 0\n         THEN INTERVAL '1' SECOND\n         ELSE INTERVAL '0' SECOND\n         END AS active_to\nFROM   (\n  SELECT item_no,\n         item_type,\n         rule_id,\n         dt,\n         COALESCE(\n           SUM(CASE rule_id WHEN 'rule1' THEN active END) OVER (\n             PARTITION BY item_no, item_type ORDER BY dt, ACTIVE DESC\n           ),\n           0\n         ) AS rule1,\n         COALESCE(\n           SUM(CASE rule_id WHEN 'rule2' THEN active END) OVER (\n             PARTITION BY item_no, item_type ORDER BY dt, ACTIVE DESC\n           ),\n           0\n         ) AS rule2\n  FROM   table_name\n         UNPIVOT (\n           dt FOR active IN ( active_from AS 1, active_to AS -1 )\n         )\n)\nMATCH_RECOGNIZE(\n  PARTITION BY item_no, item_type\n  ORDER BY dt, rule1 DESC, rule2 DESC\n  MEASURES\n    FIRST(dt) AS active_from,\n    PREV(rule1) AS prev_rule1,\n    PREV(rule2) AS prev_rule2,\n    NEXT(dt) AS active_to,\n    NEXT(rule1) AS next_rule1,\n    NEXT(rule2) AS next_rule2\n  PATTERN ( active_rules+ )\n  DEFINE active_rules AS rule1 > 0 AND rule2 = 0\n)\n\nWhich, for the sample data from your previous question:\nCREATE TABLE table_name (Item_no, item_type, active_from, active_to, rule_id) AS\nSELECT 10001, 'SAR', DATE '2020-01-01', DATE '2023-01-01', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2024-01-01', DATE '9999-12-31', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2020-05-01', DATE '2021-06-01', 'rule2' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2021-01-01', DATE '2021-02-01', 'rule2' FROM DUAL;\n\nOutputs:\n\n\n\n\nITEM_NO\nITEM_TYPE\nACTIVE_FROM\nACTIVE_TO\n\n\n\n\n10001\nSAR\n2020-01-01 00:00:00\n2020-04-30 23:59:59\n\n\n10001\nSAR\n2021-06-01 00:00:01\n2023-01-01 00:00:00\n\n\n10001\nSAR\n2024-01-01 00:00:00\n9999-12-31 00:00:00\n\n\n\n\nAnd, for the sample data in this question:\nCREATE TABLE table_name (Item_no, item_type, active_from, active_to, rule_id) AS\nSELECT 10001, 'SAR', DATE '2022-01-01', DATE '2023-05-31', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2023-07-01', DATE '2099-12-31', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2023-01-01', DATE '9999-12-31', 'rule2' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2020-12-01', DATE '2021-12-31', 'rule2' FROM DUAL;\n\nOutputs:\n\n\n\n\nITEM_NO\nITEM_TYPE\nACTIVE_FROM\nACTIVE_TO\n\n\n\n\n10001\nSAR\n2022-01-01 00:00:00\n2022-12-31 23:59:59\n\n\n\n\nAnd, for the sample data:\nCREATE TABLE table_name (Item_no, item_type, active_from, active_to, rule_id) AS\nSELECT 10001, 'SAR', DATE '2022-01-01', DATE '9999-12-31', 'rule1' FROM DUAL UNION ALL\nSELECT 10001, 'SAR', DATE '2022-01-01', DATE '2023-05-31', 'rule2' FROM DUAL;\n\nOutputs:\n\n\n\n\nITEM_NO\nITEM_TYPE\nACTIVE_FROM\nACTIVE_TO\n\n\n\n\n10001\nSAR\n2023-05-31 00:00:01\n9999-12-31 00:00:00\n\n\n\n\nfiddle\n"
},
{
"QuestionId": "76394383",
"QuestionTitle": "Python List formatting with small bracket",
"QuestionBody": "I need to add small bracket at the start and end of a Python list (Python 3)\nMy list is\nlist1 = ['1','2','3']\nList needed is [('1','2','3')]\nI know the solution may be simple, but I am not getting it.\nThanks in advance\nTried fstring and join\n",
"AnswerId": "76394393",
"AnswerBody": "Here's one way to print a list in that formatting with a combination of an f-string and str.join:\n>>> list1 = ['1','2','3']\n>>> print(f\"[({','.join(repr(i) for i in list1)})]\")\n[('1','2','3')]\n\nNote that repr(i) adds quotes around the strings so that they print as '1' instead of 1.\nNote also that this is converting the list into a particular string, not adding anything to the list.  If you wanted to add the literal strings ( and ) to list1 you could do:\n>>> list1.insert(0, '(')\n>>> list1.append(')')\n>>> list1\n['(', '1', '2', '3', ')']\n\nBut parentheses themselves aren't objects that you can add to a list.  If you want to construct an object that will render with parens, that's a tuple:\n>>> list1 = ['1','2','3']\n>>> [tuple(list1)]\n[('1', '2', '3')]\n\n"
},
{
"QuestionId": "76391866",
"QuestionTitle": "How to show a list of all my todos across all the files of my project?",
"QuestionBody": "I am an Emacs newbie transitioning from Neovim.\nI want something that will show me a list of all of my todos across all the files of the project.\nI've tried the following packages:\n\nhl-todo\nfixmee\n\nBoth of them can highlight todos, and show a list of all the todos in the current buffer.\nBut, what I need is a list of todos across all the files of the project and not just the current buffer. They do provide such functionality, but it is very clunky and impossible to bind to just a single key (they require choosing a path where to search and pressing enter).\nThe question: how can I show a list of all my todos across all the files in my project?\n",
"AnswerId": "76393314",
"AnswerBody": "I'm not sure about todo modes, but using the rg (ripgrep) package, it is easy to add custom commands.  For example, to define a command that searches for 'TODO' or 'FIXME' in the current project,\n(rg-define-search my-rg-todo\n  :query \"(TODO|FIXME)\"\n  :format regexp\n  :dir project\n  :files current)\n\nThere are a lot of other similar solutions, like builtin rgrep, ag or another ripgrep/ag library.\n"
},
{
"QuestionId": "76389311",
"QuestionTitle": "How can I open a Markdown file in preview mode by default in VS Code?",
"QuestionBody": "I'm trying to configure a GitPod or GitHub Codespace so that the README.md gets automatically opened in preview mode at boot time.\nI managed to open the file as:\ncode README.md\n\nbut that opens the editor, I'd like to open it in preview only mode.\n",
"AnswerId": "76392934",
"AnswerBody": "If you google \"github vscode issues markdown open preview by default\", you will probably find this issue ticket pretty high up in the search results: Option to automatically open markdown in preview\n#54776. Quoting Matt Bernier from their comment there:\n\nTo change this, you can configure the default editor for .md files (or whatever other markdown file extension you wish). Here's an example setting:\n\"workbench.editorAssociations\": {\n    \"*.md\": \"vscode.markdown.preview.editor\"\n}\n\nUse the [View: Reopen Editor With...] command to switch back to the standard text editor.\n\n\nThere's also another related issue ticket about opening the Markdown preview to the side by default: Automatically Activate Markdown Preview #2766. If you're interested in that one too, give it a thumbs up to show support, and subscribe to it to get notified of discussion and progress, but please avoid noisy comments like \"+1\" or \"bump\".\n"
},
{
"QuestionId": "76391982",
"QuestionTitle": "Is there a way to represent a range of indexes in a lua table for a dissector?",
"QuestionBody": "Trying to build a dissector in lua where in the ProtoField for one of the values, I map it to a table so that when passed some uint it can get said string from the list of outputs. The current issue is that I have some indexes of 1, 2, and 3, but I also need a range of numbers that correspond to one output string, and its too many to hardcode it all in. I thought about just adding some check that will add said index whenever it doesn't exist, but that would result in alot of wasted time and wanted to ensure there wasn't a better way.\nTried mapping it to a function and setting a default value with a metatable.\n",
"AnswerId": "76393363",
"AnswerBody": "Generically, a table can contain tables as indices. These tables could each be used to represent a range of indices.\nA cursory example (note that overlapping ranges are not stable):\nlocal range_mt = {}\nrange_mt.__index = range_mt\n\nfunction range_mt:contains(value)\n    return self.lower <= value and value <= self.upper\nend\n\nlocal function range(lower, upper)\n    return setmetatable({\n        lower = lower,\n        upper = upper\n    }, range_mt)\nend\n\nlocal map = setmetatable({\n    [1] = 'hello',\n    [2] = 'world',\n    [3] = 'goodbye',\n    ranges = {\n        [range(10, 20)] = 'foo',\n        [range(51, 99)] = 'bar'\n    }\n}, {\n    __index = function (self, value)\n        for r, str in pairs(self.ranges) do\n            if r:contains(value) then\n                return str\n            end\n        end\n\n        return \"DEFAULT\"\n    end\n})\n\nfor _, value in ipairs { 9, 6, 1, 2, 16, 4, 15, 66, 51, 3, 94 } do\n    print(value, '->', map[value])\nend\n\n9   ->  DEFAULT\n6   ->  DEFAULT\n1   ->  hello\n2   ->  world\n16  ->  foo\n4   ->  DEFAULT\n15  ->  foo\n66  ->  bar\n51  ->  bar\n3   ->  goodbye\n94  ->  bar\n\n"
},
{
"QuestionId": "76391998",
"QuestionTitle": "Sequelize - Is it possible to search all columns of a table with Op.or operator?",
"QuestionBody": "In a project with NodeJS and ExpressJS, using Sequelize, I'm attempting to implement server-side pagination and searching\nconst products = await Product.findAll({\n      where: {\n        [Op.and]: [\n          {\n            status: {\n              [Op.ne]: -1\n            },\n          },{\n            [Op.or]:[\n              {\n                name:{\n                  [Op.substring]:searchString\n                }\n              },{\n                category:{\n                  [Op.substring]:searchString\n                },\n              }\n            ]\n          }\n        ]\n      },\n      limit: rows,\n      offset: offset\n    });\n\nNow this allows me to search in the name and category columns, but Product's table has like 10 columns, Client's table has like 15 columns, is there a way to get something like\nWHERE any-column LIKE \"%searchString%\"\nwhere:{\n    [Op.or]:[\n        {any-column}:{\n            [Op.substring]:searchString\n        }\n    ]\n}\n\nOr is my only option to add each column manually?\n",
"AnswerId": "76393387",
"AnswerBody": "If all columns are string type, you can use CONCAT_WS function to search in a whole combined string.\nconst searchCols = ['name', 'description', 'category'].map(sequelize.col);\n\nawait Product.findAll({\n    where: {\n        status: {\n            [Op.ne]: -1\n        },\n        [Op.where]: Sequelize.where(Sequelize.fn('CONCAT_WS', ' ', ...searchCols), \n                                    Op.like,\n                                    `%${searchString}%`)\n    }\n})\n\n"
},
{
"QuestionId": "76394368",
"QuestionTitle": "Does RailwayCLI ignore files defined in .gitignore?",
"QuestionBody": "The command railway up takes your current local project and uploads it directly to railway without having to link a Github repo to your railway project.\nDoes RailwayCLI take into account .gitignore file like Git does? if not what is the proper way to ignore files (not upload them) when using the command.\nI couldn't find anything relevant mentioned in their docs.\n",
"AnswerId": "76394404",
"AnswerBody": "No, RailwayCLI does not take into account the .gitignore file. If you want to ignore certain files when using the railway up command, you can use the --ignore-files flag. For example, to ignore all files with the .txt extension, you would use the following command:\nrailway up --ignore-files .txt\n\nUpdate:\nThe -ignore-files flag uses the same globbing patterns as .gitignore. So you can use the * character to match any number of characters, and the ? character to match any single character.\nFor example, the following command will ignore all files that start with the word \"app\" and have any extension:\nrailway up --ignore-files app*\n\nThis command will ignore all files that have the .txt or .json extensions:\nrailway up --ignore-files .txt,.json\n\nThis command will ignore all files in the ./test directory and its subdirectories:\nrailway up --ignore-files ./test/*\n\nYou can also use the -ignore-files option to ignore specific files, even if they have extensions that are not listed in the .gitignore file. For example, the following command will ignore the file app.txt, even though the .txt extension is not listed in the .gitignore file:\nrailway up --ignore-files app.txt\n\n"
},
{
"QuestionId": "76394390",
"QuestionTitle": "How to replace a string defined by starting and ending index by another string in R?",
"QuestionBody": "string <- \"this is a funny cat\"\n\nI want to replace the first 15 characters of string with 'orange`. The desired output is\n'orange cat'\n\nHowever, using substr gives me\nsubstr(string, 1, 15) <- \"orange\"\n> string\n[1] \"oranges a funny cat\"\n\nwhich is not the desired output.\n",
"AnswerId": "76394420",
"AnswerBody": "The output of substr should be the pattern of sub.\nstring <- \"this is a funny cat\"\n\nsub(substr(string, 1, 15), \"orange\", string)\n[1] \"orange cat\"\n\nOr directly replace the first 15 characters in sub.\nsub(\"^.{15}\", \"orange\", string)\n[1] \"orange cat\"\n\n"
},
{
"QuestionId": "76392186",
"QuestionTitle": "How can I stop codelenses from breaking up indent guides in VS Code?",
"QuestionBody": "I have this visual annoyance when I am using VS Code. Whenever a method or class is declared, the \"reference\" counting is causing the vertical lines that connects the curly braces to break.\nIt is very annoying, I tried finding the settings in user preference but could not find anything. Could someone help me?\nI find the \"reference\" count is alright, but how can I keep the vertical curly braces pair lines from breaking. I don't have this problem in Visual Studio.\n\n",
"AnswerId": "76393456",
"AnswerBody": "This is a known issue and as far as I know, there's not much you can do about it for now except wait for it to get handled. If you google \"github vscode issues codelens indent guide\", you should easily find Indent Guides Have Breaks Where CodeLens UI is Rendered #9604. There, you'll see that one of the maintainers, @alexdima commented:\n\nCode lenses are implemented as view zones (same mechanism as embedded editors when you find all references or as the diff editor). In some of the view zones (such as code lens) it makes sense to render the indent guides inside view zones, while in others (such as the embedded editors or the diff editor) it does not, therefore marking this as both a feature request and a bug.\n\nYou can give that issue ticket a thumbs up reaction to show support for it getting prioritized (there's a big backlog), and subscribe to it to get notified about discussions and updates. But please don't make noisy comments like \"me too\" / \"+1\" / \"bump\".\n"
},
{
"QuestionId": "76389877",
"QuestionTitle": "Micrometer Tracing, Spring Boot 3.0, OTLP exporter class not found error",
"QuestionBody": "I have Spring Boot 3.0 based project, Kotlin and Micrometer Tracing (which superseded Spring Cloud Sleuth)\nTrying to connect Micrometer tracing to OTLP collector, which is part of Jaeger.\nThe configuration class:\n@Configuration\nclass OpenTelemetryConfiguration(\n    @Value(\"\\${otel.exporter.otlp.traces.endpoint:http://localhost:4317}\")\n    private val tracesEndpoint: String\n) {\n    @Bean\n    fun spanExporter(): SpanExporter =\n        OtlpGrpcSpanExporter.builder().setEndpoint(tracesEndpoint).build()\n\n    @Bean\n    fun jaegerPropagator(): TextMapPropagator =\n        JaegerPropagator.getInstance()\n\n}\n\nDependencies in gradle:\nimplementation(\"io.micrometer:micrometer-core:1.11.0\")\nimplementation(\"io.micrometer:micrometer-tracing:1.1.1\")\nimplementation(\"io.micrometer:micrometer-registry-prometheus:1.10.5\")\nimplementation(\"io.micrometer:micrometer-tracing-bridge-otel:1.1.1\")\nimplementation(\"io.opentelemetry:opentelemetry-sdk:1.26.0\")\nimplementation(\"io.opentelemetry:opentelemetry-sdk-extension-autoconfigure-spi:1.26.0\")\nimplementation(\"io.opentelemetry:opentelemetry-exporter-common:1.26.0\")\nimplementation(\"io.opentelemetry:opentelemetry-exporter-otlp:1.26.0\")\n\nThe error when application starts:\nFailed to instantiate [io.opentelemetry.sdk.trace.export.SpanExporter]: Factory method 'spanExporter' threw exception with message: io/opentelemetry/exporter/internal/otlp/OtlpUserAgent\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:171)\n    at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)\n    ... 170 common frames omitted\nCaused by: java.lang.NoClassDefFoundError: io/opentelemetry/exporter/internal/otlp/OtlpUserAgent\n    at io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporterBuilder.<init>(OtlpGrpcSpanExporterBuilder.java:48)\n    at io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporter.builder(OtlpGrpcSpanExporter.java:40)\n    at com.logindex.geoservice.configuration.OtelConfiguration.spanExporter(OtelConfiguration.kt:19)\n    ... 171 common frames omitted\nCaused by: java.lang.ClassNotFoundException: io.opentelemetry.exporter.internal.otlp.OtlpUserAgent\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)\n\nWhat dependency is missing there?\nthere's no such class io.opentelemetry.exporter.internal.otlp.OtlpUserAgent in the library io.opentelemetry:opentelemetry-exporter-otlp:1.26.0\n",
"AnswerId": "76392983",
"AnswerBody": "OTel is not stable yet so not every version of the OTel SDK is compatible with every version of Micrometer Tracing due to breaking changes in the OTel SDK.\nYou should delete all of your version definitions and let the Spring Boot BOM define versions for you, this is what you need:\nimplementation 'org.springframework.boot:spring-boot-starter-actuator'\nimplementation 'io.micrometer:micrometer-registry-prometheus'\nimplementation 'io.micrometer:micrometer-tracing-bridge-otel'\nimplementation 'io.opentelemetry:opentelemetry-exporter-otlp'\n\nBtw Jaeger also supports Zipkin so you can use Brave too with the Zipkin exporter.\n"
},
{
"QuestionId": "76392156",
"QuestionTitle": "How to find different between two times with sql",
"QuestionBody": "I have a table contain reference time and a user check-in time. Both data is different in type.\nSample data\n\ndtime = 2023-06-02 08:23:21\nwork_time = 08:00-18:00\n\nAnd my code is...\nSELECT substring(dtime,-8,5) AS chkin, \nSUBSTRING(work_time, 1, 5) AS wt1, \nTIMESTAMPDIFF(MINUTE, substring(dtime,-8,5), SUBSTRING(work_time, 1, 5)) AS min_diff \nFROM ta_db \nWHERE id = 13181;\n\nAs a result...\n\nchkin = 08:23\nwt1 = 08:00\n\nNow, I want to know how many minutes different from chkin and wt with TIMESTAMPDIFF.\nSo I did this...\nTIMESTAMPDIFF(MINUTE, substring(dtime,-8,5), SUBSTRING(work_time, 1, 5)) AS min_diff \n\nBut it returns NULL. Please be advised.\n",
"AnswerId": "76393483",
"AnswerBody": "Try this:\nSET @dtime = '2023-06-02 08:28:21';\nSET @work_time = '08:00-18:00';\n\nSELECT substring(@dtime,-8,5) AS chkin, \nSUBSTRING(@work_time, 1, 5) AS wt1, \nTIMESTAMPDIFF(MINUTE, @dtime, CONCAT(SUBSTRING(@dtime, 1,10), ' ', SUBSTRING(@work_time, 1, 5))) AS min_diff\n\n"
},
{
"QuestionId": "76392180",
"QuestionTitle": "Hide views in a stack view when auto layout attempts to reduce the stack view size?",
"QuestionBody": "I have a UIStackView that contains multiple arranged subviews. I want to dynamically hide certain views within the stack view when auto layout attempts to reduce the stack view's size. I'm looking for a way to achieve this behavior using auto layout and without manually manipulating the frame.\nI've tried setting the isHidden property of the subviews, but it doesn't seem to update the layout of the stack view correctly. The views still take up space within the stack view.\nWhat would be the recommended approach to hide views in a stack view when auto layout attempts to reduce its size? Are there any specific methods or techniques that should be used to achieve this behavior?\nAny guidance or code examples would be greatly appreciated. Thank you!\nI've try to override layoutSubviews method.\n    override func layoutSubviews() {\n        super.layoutSubviews()\n\n        for view in stackView.arrangedSubviews {\n            if visibilityManager.shouldBeVisible(view: view) {\n                if let view = view as? MyButton {\n                    if view.intrinsicContentSize.height > view.bounds.height {\n                        view.isHidden = true\n                    } else {\n                        view.isHidden = false\n                    }\n                }\n            }\n        }\n    }\n\nExpect:\nThe views in the stack view will be hidden\nActual:\nViews are just compressed\n",
"AnswerId": "76393491",
"AnswerBody": "When we set .isHidden = true on a stack view's arranged subview, that subview remains in the .arrangedSubviews collection but it is removed from the hierarchy and no longer has a valid frame.\nAnother approach would be to set the .alpha to either 1.0 or 0.0 to \"show / hide\" the view.\nWe create a custom view subclass - let's call it AutoHideSubviewsView. It will have a stack view with Top / Leading / Trailing constraints, but no Bottom constraint.\nWhen the view frame changes - gets shorter or taller - we loop through the arranged subviews and:\n\nget the frame\nconvert it to the view coordinate space (it's relative to the stack view itself)\nif the view's bounds contains the frame, set its .alpha = 1.0 (show it)\nelse, set its .alpha = 0.0 (hide it)\n\nHere's some quick example code...\nCustom View\nclass AutoHideSubviewsView: UIView {\n    \n    let stackView: UIStackView = {\n        let v = UIStackView()\n        v.axis = .vertical\n        v.spacing = 12.0\n        v.translatesAutoresizingMaskIntoConstraints = false\n        return v\n    }()\n    \n    override init(frame: CGRect) {\n        super.init(frame: frame)\n        commonInit()\n    }\n    required init?(coder: NSCoder) {\n        super.init(coder: coder)\n        commonInit()\n    }\n    private func commonInit() {\n        addSubview(stackView)\n        NSLayoutConstraint.activate([\n            stackView.topAnchor.constraint(equalTo: topAnchor, constant: 8.0),\n            stackView.leadingAnchor.constraint(equalTo: leadingAnchor, constant: 8.0),\n            stackView.trailingAnchor.constraint(equalTo: trailingAnchor, constant: -8.0),\n            // NO Bottom constraint\n        ])\n        // not strictly necessary, but let's do this anyway\n        self.clipsToBounds = true\n    }\n    \n    override func layoutSubviews() {\n        super.layoutSubviews()\n        \n        // on first layout, the stackView's subview's frames are not set\n        //  so force another layout pass\n        if stackView.arrangedSubviews.first!.frame.height == 0.0 {\n            stackView.setNeedsLayout()\n            stackView.layoutIfNeeded()\n            self.setNeedsLayout()\n            self.layoutIfNeeded()\n            return\n        }\n        for v in stackView.arrangedSubviews {\n            // the frames of the arranged subviews are\n            //  relative to the stack view frame, so\n            //  we want to convert the frames in case\n            //  the stack view TOP is not Zero\n            let r = stackView.convert(v.frame, to: self)\n            // animate the alpha change so we can see it\n            UIView.animate(withDuration: 0.3, animations: {\n                v.alpha = self.bounds.contains(r) ? 1.0 : 0.0\n            })\n        }\n    }\n    \n}\n\nExample Controller\nclass ViewController: UIViewController {\n    \n    let ahView = AutoHideSubviewsView()\n    \n    var hConstraint: NSLayoutConstraint!\n    \n    override func viewDidLoad() {\n        super.viewDidLoad()\n        view.backgroundColor = .systemBackground\n        \n        // grow and shrink buttons\n        var cfg = UIButton.Configuration.gray()\n        cfg.title = \"Shrink\"\n        let btn1 = UIButton(configuration: cfg, primaryAction: UIAction() { _ in\n            if self.hConstraint.constant > 15.0 {\n                self.hConstraint.constant -= 10.0\n            }\n        })\n        cfg.title = \"Grow\"\n        let btn2 = UIButton(configuration: cfg, primaryAction: UIAction() { _ in\n            self.hConstraint.constant += 10.0\n        })\n\n        [ahView, btn1, btn2].forEach { v in\n            v.translatesAutoresizingMaskIntoConstraints = false\n            view.addSubview(v)\n        }\n\n        let g = view.safeAreaLayoutGuide\n        NSLayoutConstraint.activate([\n            \n            ahView.topAnchor.constraint(equalTo: g.topAnchor, constant: 20.0),\n            ahView.leadingAnchor.constraint(equalTo: g.leadingAnchor, constant: 20.0),\n            ahView.widthAnchor.constraint(equalToConstant: 200.0),\n            \n            btn1.topAnchor.constraint(equalTo: g.topAnchor, constant: 40.0),\n            btn1.leadingAnchor.constraint(equalTo: ahView.trailingAnchor, constant: 20.0),\n            btn1.trailingAnchor.constraint(equalTo: g.trailingAnchor, constant: -20.0),\n            \n            btn2.topAnchor.constraint(equalTo: btn1.bottomAnchor, constant: 20.0),\n            btn2.leadingAnchor.constraint(equalTo: ahView.trailingAnchor, constant: 20.0),\n            btn2.trailingAnchor.constraint(equalTo: g.trailingAnchor, constant: -20.0),\n            \n        ])\n        \n        // start with the view height at 320\n        hConstraint = ahView.heightAnchor.constraint(equalToConstant: 320.0)\n        hConstraint.isActive = true\n        \n        // let's add 3 labels and 3 buttons to the custom view's stackView\n        let strings: [String] = [\"First\", \"Second\", \"Third\"]\n        let colors: [UIColor] = [.cyan, .green, .yellow]\n        for (str, c) in zip(strings, colors) {\n            let label = UILabel()\n            label.font = .systemFont(ofSize: 24, weight: .light)\n            label.text = str\n            label.textAlignment = .center\n            label.backgroundColor = c\n            label.heightAnchor.constraint(equalToConstant: 40.0).isActive = true\n            var cfg = UIButton.Configuration.filled()\n            cfg.title = str\n            let btn = UIButton(configuration: cfg, primaryAction: UIAction() { _ in\n                print(\"\\(str) Button Tapped\")\n            })\n            ahView.stackView.addArrangedSubview(label)\n            ahView.stackView.addArrangedSubview(btn)\n        }\n\n        // so we can see the framing\n        ahView.backgroundColor = .red\n    }\n    \n}\n\nLooks like this (custom view's background is red):\n\nTapping the \"Shrink\" button will decrease the height of the view, tapping the \"Grow\" button will increase it.\n\n\n\nTo make it really easy to see what's happening, I animate the .alpha change so the subviews \"fade\" in and out.\nHere's an animation (too big to post here): https://imgur.com/a/glRRh2O\n"
},
{
"QuestionId": "76390199",
"QuestionTitle": "How to validate and submit a modal dialog, and, when succesful, execute some Javascript",
"QuestionBody": "The following order of events should happen in my Oracle APEX app:\n\nUser clicks Submit button in a modal dialog.\nThe configured validations are executed (mostly package functions).\nIf validation is OK, the page is submitted (a package function is called).\nIf no validation error or exception during submit happened, Javascript is executed. This Javascript needs access to the item values entered by the user, so it must not be executed after a page reload.\nModal dialog is closed.\n\nI tried many ways to accomplish this, but all failed. The obvious solution would be two dynamic actions on the button click, but I learned that the order of the actions is not guaranteed, and the Javascript is executed even after an error in the validation or submit.\nNow I think I have to do it with Javascript in a single dynamic action (button click on the modal dialog) like this:\n// Validate and submit.\napex.page.submit( {\n    validate: true,\n} );\n\n// Other JS code on successful submit, which is accessing page items.\n... $v(\"myItem\") ...\n\n// Close modal dialog.\napex.navigation.dialog.close(true);\n\nHow can I check if apex.page.submit was successful?\nAnd will the javascript be able to access item values entered by the user?\nBy the way, I don't want to put this Javascript on the parent page, because there will be multiple such modal dialogs, and I prefer to keep their respective logic separate, and not turn the parent page into a \"God object\".\nThank you in advance.\n",
"AnswerId": "76392996",
"AnswerBody": "This isn't an answer to your question, because I believe what you want is simply not possible. To understand why, you need to check how APEX processes work.\n\nA number of processes run in a pre-rendering phase. These are server-side processes (computations, pl/sql processes, form initialization, etc).\nThe dom is rendered based on the components. These components (optionally) take data from the pre-rendering process. In this phase client-side actions can be executed (dynamic actions, custom javascript)\nOnce a page is submitted, the \"processing\" starts. The form data entered in the previous phase it sent to the server. From this point onward everything is server-side: validations, page processing, branches, etc).\n\nNow... javascript is client side only. and only in phase 2 can client-side code be executed. Once a page is submitted, the client can no longer be accessed. So \"execute javascript\" after \"server side validations\" is simply not possible in APEX. javascript can be executed onload OR when the page is rendered via an event OR before page submit. That's it in the current version of apex (23.1).\n"
},
{
"QuestionId": "76394381",
"QuestionTitle": "React Hook Form Error on custom Input component",
"QuestionBody": "I am having a problem when I use react hook form + zod in my application, in short the inputs never change value and I get the following error in the console:\nWarning: Function components cannot be given refs. Attempts to access this ref will fail. Did you mean to use React.forwardRef()?\n\nmy components:\n// Login.tsx\n\nimport { useForm } from \"react-hook-form\";\nimport { zodResolver } from \"@hookform/resolvers/zod\";\nimport { z } from \"zod\";\n\nimport { Button } from \"../components/Form/Button\";\nimport { Input } from \"../components/Form/Input\";\n\nconst loginFormValidationSchema = z.object({\n  username: z.string().min(3),\n  password: z.string().min(3)\n});\n\ntype LoginFormFields = z.infer<typeof loginFormValidationSchema>;\n\nexport function Login() {\n  const {\n    register,\n    handleSubmit,\n    formState: { errors, isSubmitting }\n  } = useForm<LoginFormFields>({\n    resolver: zodResolver(loginFormValidationSchema)\n  });\n\n  function handleSignIn(data: LoginFormFields) {\n    console.log(data);\n  }\n\n  return (\n    <section>\n      <h1>Login</h1>\n\n      <form onSubmit={handleSubmit(handleSignIn)}>\n        <Input\n          type=\"text\"\n          error={errors.username?.message}\n          autoComplete=\"off\"\n          {...register(\"username\")}\n        />\n\n        <Input\n          type=\"password\"\n          label=\"Senha\"\n          error={errors.password?.message}\n          {...register(\"password\")}\n        />\n\n        <Button type=\"submit\" disabled={isSubmitting}>\n          Entrar\n        </Button>\n      </form>\n    </section>\n  );\n}\n\n// Input.tsx\n\nimport { InputHTMLAttributes } from \"react\";\n\nimport styles from \"./Input.module.css\";\n\ninterface InputProps extends InputHTMLAttributes<HTMLInputElement> {\n  name: string;\n  label?: string;\n  error?: string;\n}\n\nexport function Input({ name, label, error, ...props }: InputProps) {\n  return (\n    <div className={styles.wrapper}>\n      {!!label && (\n        <label htmlFor={name} className={styles.label}>\n          {label}\n        </label>\n      )}\n\n      <input id={name} name={name} className={styles.input} {...props} />\n\n      {!!error && <p className={styles.error}>{error}</p>}\n    </div>\n  );\n}\n\nI have tried some alternatives that I found in some threads, but so far I have not been successful, has anyone experienced at least or has any notion of how it is possible to get around this error?\n",
"AnswerId": "76394421",
"AnswerBody": "I think what's happening is the {...register(\"username\")}, which gets picked up as ...props in the Input component's props, is using a ref under the hood (this is how the react-hook-form library identifies inputs). You should be able to fix this by converting the Input component to use a forwardRef like this:\nexport const Input = React.forwardRef<HTMLInputElement, Omit<InputProps, \"ref\">>(({ name, label, error, ...props }, ref) => (\n    <div className={styles.wrapper}>\n      {!!label && (\n        <label htmlFor={name} className={styles.label}>\n          {label}\n        </label>\n      )}\n\n      <input id={name} name={name} className={styles.input} ref={ref} {...props} />\n\n      {!!error && <p className={styles.error}>{error}</p>}\n    </div>\n));\n\nInput.displayName = \"Input\";\n\nBasically what this does is it allows you to put a ref attribute on the Input component, which gets 'forwarded' to the input component. This allows the library to monitor changes.\n"
},
{
"QuestionId": "76391609",
"QuestionTitle": "Multiple AJAX calls ; get all the failed calls",
"QuestionBody": "I am making multiple ajax calls as shown below. Below code works fine If all the calls succeed. But, let's say urlId 3 and 4 failed for some reason. Is it possible to get all the failed urlId's in the fail function?\nvar urlId = [1, 3, 4, 7]\nlet requests = [];\nfor (let i = 0; i < urlId.length; i++) {\n    requests.push($.ajax(...));\n}\n$.when.apply($, requests).done(function () {\n    $.each(arguments, function (idx, args) {\n        //process args : urlId[idx]\n    });\n}).fail(function (jqXHR) {\n    //how to get urlId's failed\n});\n\n",
"AnswerId": "76393867",
"AnswerBody": "You would not be able to reliably get all of the failed IDs in the .fail handler because it will fire as soon as any of the deferreds becomes rejected, regardless of the state of the other deferreds.\nIf you want to keep track of which requests succeeded and which failed, I think your best option would be to attach a catch handler to each $.ajax call that will catch a failure and map it to an object that has a reference to the id and to the success/failure status. Catching errors this way will mean that all of the deferreds will succeed, so the handling of success and failed states will then need to be performed in the done handler attached to the $.when. For example:\nvar urlId = [1, 3, 4, 7]\nlet requests = [];\n\nurlId.forEach(id => {\n  requests.push(\n    $.ajax(/*...*/)\n      .then(response => {\n        return {\n          id,\n          success: true,\n          response\n        };\n      })\n      .catch(error => {\n        return {\n          id,\n          success: false,\n          error\n        }\n      })\n  );\n});\n\n$.when.apply($, requests)\n  .done(function (values) {\n    $.each(arguments, function (idx, obj) {\n      console.log(`${obj.id}: success = ${obj.success}`);\n    });\n });\n\nHere is a fiddle for reference.\n"
},
{
"QuestionId": "76392242",
"QuestionTitle": "Get the instance type of a singleton class in TypeScript",
"QuestionBody": "I have a singleton class:\nclass Singleton {\n  private static instance: Singleton;\n\n  private constructor() {\n    // Private constructor to prevent instantiation outside the class\n  }\n\n  public static getInstance(): Singleton {\n    if (!Singleton.instance) {\n      Singleton.instance = new Singleton();\n    }\n    return Singleton.instance;\n  }\n\n  someMethod(): void {\n    console.log(\"Singleton method called\");\n  }\n}\n\nI know there is a type InstanceType, but it doesn't work with private constructors.\n// Cannot assign a 'private' constructor type to a 'public' constructor type\ntype SingletonType = InstanceType<typeof Singleton>;\n\nIs it possible to create a custom type that returns instance type of classes with private constructors?\n\nEDIT\nWell, I'll try to shed some light on the whole situation. I hope this clears up misunderstandings. As I wrote earlier I have a singleton class with a private constructor. I have to pass this singleton to constructor of another generic class as a parameter:\nclass BaseEntity<T extends typeof Singleton = typeof Singleton> {\n    private singletonInstance: InstanceType<T>;\n    \n    constructor(instance: InstanceType<T>) {        \n        this.singletonInstance = instance;        \n    }\n}\n\nAs far as Singleton class has a private constructor, I get an error Cannot assign a 'private' constructor type to a 'public' constructor type when trying to get its instance InstanceType<T>. So my question is, is it possible to create a custom generic type that accepts classes with \"private\" constructors and returns an instance type similar to \"InstanceType\"?\n",
"AnswerId": "76393891",
"AnswerBody": "TypeScript assumes that class constructors have a prototype property whose type is the same as the class instance type.  This isn't actually true in practice, since generally speaking class fields won't actually be present on the prototype.  But TypeScript makes that assumption as an approximation intentionally, and has declined suggestions to change this (see microsoft/TypeScript#11558 and microsoft/TypeScript#20922 for examples).\nAnd so, if the InstanceType<T> utility type is unavailable to you because of a private constructor, you can get the same information by indexing into the constructor's type with \"prototype\":\ntype AlsoInstanceType<T extends { prototype: any }> =\n  T[\"prototype\"];\n\ntype SingletonType = AlsoInstanceType<typeof Singleton>\n// type SingletonType = Singleton\n\nclass Foo { a = 1 }\ntype Example = AlsoInstanceType<typeof Foo>\n// type Example = Foo;\n\nAnd thus your BaseEntity can be written that way:\nclass BaseEntity<T extends typeof Singleton = typeof Singleton> {\n  private singletonInstance: AlsoInstanceType<T>;\n\n  constructor(instance: AlsoInstanceType<T>) {\n    this.singletonInstance = instance;\n  }\n}\n\n\nFor Singleton in particular you could write ReturnType<typeof Singleton.getInstance> using the ReturnType<T> utility type:\ntype AlsoSingletonType = ReturnType<typeof Singleton.getInstance>;\n// type AlsoSingletonType = Singleton\n\ntype SingletonInstance<T extends typeof Singleton> = ReturnType<T[\"getInstance\"]>;\ntype AlsoAlsoSingletonType = SingletonInstance<typeof Singleton>;\n// type AlsoAlsoSingletonType = Singleton\n\nBut T[\"prototype\"] is more flexible.\nPlayground link to code\n"
},
{
"QuestionId": "76394041",
"QuestionTitle": "Why is this one paragraph link showing up funky?",
"QuestionBody": "I am attaching some code in here, I have recently added in a link to my portfolio website and the paragraph link is doing something weird, it seems to be aligning funky and I'm not sure what the issue is. I'm wondering if it might be stemming from some other a stylings in the CSS (like nav_links) but I'm unsure how to correct this without messing up the other a stylings.\nI added a class to the a href and tried to add in some CSS styling for it, it fixed some issues (like the size and color)but that gap\n",
"AnswerId": "76394431",
"AnswerBody": "You're making a mistake in your CSS, doing things like this:\n.nav_link li, a\n\nYou need to remove those commas. I assume here you're trying to style an a within an li within an element with a class of .nav_link. But that's NOT what you're doing. Instead, this selector is applying a bunch of styles to .nav_link li and separately to all a elements. The selector should actually read like so:\n.nav_link li a\n\nYou have this issue at several points in your CSS.\n"
},
{
"QuestionId": "76391772",
"QuestionTitle": "Extracting a nested type from the generic parameter of a generic class in TypeScript",
"QuestionBody": "I'm working on a TypeScript project and I have a generic class AbstractDAL with a generic type parameter T_DEFAULT_RETURN. Inside the AbstractDAL class, I'm trying to extract a nested type that is specified within the T_DEFAULT_RETURN generic type parameter, but I'm facing some challenges.\nHere's the simplified code structure I have:\nclass A {\n    alpha() { }\n};\n\nclass B extends A {\n    beta() { }\n};\n\nabstract class AbstractDAL<\n    T_DEFAULT_RETURN extends BaseEntity = BaseEntity,       \n    T_DATA = T_DEFAULT_RETURN extends BaseEntity<infer D> ? D : never\n> {\n    get result() {\n        return {} as T_DATA\n    }\n}\n\nclass BaseEntity<       \n    T_DATA extends A = A\n> { }\n\n\n\nclass TestDAL extends AbstractDAL<TestEntity> {\n    delta() {\n        this.result.alpha // should also be beta, not just alpha\n    }\n}\n\nclass TestEntity extends BaseEntity<B> { }\n\nIn the above code, the AbstractDAL class is defined with a generic type parameter T_DEFAULT_RETURN, and I'm trying to extract a nested type from this parameter. I have used a conditional type with infer and a helper type T_DATA to accomplish this. However, the inferred type for T_DATA is A instead of the expected type B.\nIs there a way to correctly extract the nested type B from the T_DEFAULT_RETURN generic type parameter within the AbstractDAL class? If so, what modifications are needed in the code to achieve this?\n",
"AnswerId": "76393963",
"AnswerBody": "The problem is that BaseEntity<T> does not depend on T structurally, and thus inference from BaseEntity<T> to T is, at best, unreliable.\n\nTypeScript's type system is largely structural and not nominal.  That means types are compared by their structure or shape, and not by what they are named or where they are declared.  If type X and type Y are both object types with the same members, then they are the same type:\ninterface X { w: string; z: number; }\nlet x: X = { w: \"abc\", z: 123 };\n\ninterface Y { w: string; z: number; }\nlet y: Y = { w: \"def\", z: 456 };\n\nx = y; // okay\ny = x; // okay\n\nIn the above it doesn't matter whether you use the name X or the name Y to refer to the type.  They are interchangeable.\nThis extends to generics as well.  If you have a generic type that doesn't use its type parameter inside the type definition, like\ninterface F<T> { w: string; z: number }\n\nthen all types you create by specifying T with a type argument will be identical to each other, and thus interchangeable:\nlet fs: F<string> = x; // okay\nlet fn: F<number> = y; // okay\nfs = fn; // okay\nfn = fs; // okay\n\nThere is no difference between F<string> and F<number>, or between either of them and X or Y.  We don't care about the name F<string>, just the shape { w: string; z: number }.\nAnd that's indicative of a problem in the code.  Type inference, such as what you get when you use infer in a conditional type, can only work consistently if it is inferring from structure.\nAsking TypeScript \"given G<T>, what type is T\", the compiler cannot necessarily answer correctly.  It depends strongly on the definition of G.  For example, given our F<T> definition above, where F<T> is identical to X for all T, then the information you want is essentially gone.  If I asked you to tell me which T makes F<T> equal to { w: string; z: number }, there's no principled away to answer.  Indeed any answer is equally correct.  There's no principled way to say that a particular { w: string; z: number } came from F<string> vs F<number>.  Sometimes you'll find that the compiler does infer from names, but you can't rely on it.\nSo, in general, you should never have unused type parameters.  See the TypeScript FAQ entry Why doesn't type inference work on this interface: interface Foo<T> { }?.\n\nThe solution is therefore to add some structure to your type that depends on the generic type parameter.  A BaseEntity<T> should have something to do with T!  For example, if you add a property of type T, everything starts working:\nclass BaseEntity<D extends A = A> {\n    declare d: D // <-- make it structurally dependent\n}\n\nclass TestDAL extends AbstractDAL<TestEntity> {\n    delta() {\n        this.result.alpha\n        //^? (property) AbstractDAL<TestEntity, B>.result: B            \n    }\n}\nclass TestEntity extends BaseEntity<B> { }\n\nThat declare field is just me telling the compiler that a BaseEntity<D> has a field of type D at key d without having to actually initialize it.  In practice you should always initialize your class fields. The compiler will allow you to write new BaseEntity<string>().d.toUpperCase() but it will explode at runtime if d wasn't initialized.  I'm more worried about typings than initialization.\nThat's just an example.  You should try to give BaseEntity<T> some structural dependence on T that makes sense for the actual use case, and only resort to a \"phantom\" property like declare d if you really don't have anything better.\nPlayground link to code\n"
},
{
"QuestionId": "76390366",
"QuestionTitle": "How can I include price filter logic in a React filter?",
"QuestionBody": "I am working on multi filter checkbox in react and redux. How to add extra price filter logic when:\n\nThe price range is less than 250\n\nThe price range is between 251 and 450\n\nThe price range is greater than 450\n\n\nBelow is the code for the filter reducer. Tried this if else condition but the problem is if multiple checkboxes are clicked this doesn't work\ncase actionTypes.FILTER_PRODUCT:\n      const searchParameters = data && Object.keys(Object.assign({}, ...data));\n      let filterData;\n      console.log('test',action.payload);\n      const searchQuery = action.payload.map((val) => val.toLowerCase());\n      const getItemParam = (item, parameter) =>\n        (item[parameter] ?? \"\").toString().toLowerCase();\n\n      if (action.payload.length === 0) {\n        filterData = state.products;\n      } \n      else if(action.payload.includes('0-Rs250')){\n        filterData = state.products.filter((item) => {\n          return item.price <= 250\n        })\n      }\n      else if(action.payload.includes('Rs251-450')){\n        data = state.products.filter((item) => {\n          return item.price > 250 && item.price <= 450\n        })\n\n      }else if(action.payload.includes('Rs 450')){\n        filterData = state.products.filter((item) => {\n          return item.price > 450\n        })\n      }\n      else {\n        filterData = state.products.filter((item) => {\n          return searchParameters.some((parameter) => {\n            const itemParam = getItemParam(item, parameter);\n\n            return searchQuery.some(\n              (color) => itemParam === color)\n          });\n        });\n      }\n      console.log('test1',filterData);\n      return {\n        ...state,\n        filteredData: filterData,\n      };\n\n",
"AnswerId": "76393192",
"AnswerBody": "Change the conditions from exclusive OR to inclusive OR by changing from if - else if - else to if - if - if.\nExample:\nStart with initially empty filtered result set, and for each filtering criteria filter and append the original state.products array.\ncase actionTypes.FILTER_PRODUCT:\n  ...\n\n  let filteredData = [];\n\n  ...\n\n  if (action.payload.length) {\n    if (action.payload.includes(\"0-Rs250\")) {\n      filteredData.push(...state.products.filter((item) => {\n        return item.price <= 250;\n      }));\n    }\n    if (action.payload.includes(\"Rs251-450\")) {\n      filteredData.push(...state.products.filter((item) => {\n        return item.price > 250 && item.price <= 450;\n      }));\n    }\n    if (action.payload.includes(\"Rs 450\")) {\n      filteredData.push(...state.products.filter((item) => {\n        return item.price > 450;\n      }));\n    }\n  } else {\n    filteredData = state.products.filter(/* filter by searchParams */);\n  }\n\n  return {\n    ...state,\n    filteredData,\n  };\n\nAn alternative using a more inline solution:\ncase actionTypes.FILTER_PRODUCT:\n  ...\n\n  const filteredData = state.products.filter((item) => {\n    if (action.payload.length) {\n      return (\n        (action.payload.includes(\"0-Rs250\") && item.price <= 250) ||\n        (action.payload.includes(\"Rs251-450\") &&\n          item.price > 250 &&\n          item.price <= 450) ||\n        (action.payload.includes(\"Rs 450\") && item.price > 450)\n      );\n    }\n    return /* filter by searchParams */;\n  });\n\n  return {\n    ...state,\n    filteredData,\n  };\n\nThis second method retains the original order of products from the source array.\n"
},
{
"QuestionId": "76390529",
"QuestionTitle": "TinyMCE insertHTML modifies some HTML tags",
"QuestionBody": "I have some content in tinymce 6 editor. I moved the cursor and placed it inside the content and executed\ntinymce.activeEditor.insertContent(`<span class='dummy'>\n                        <div><span style=\"font-style:italic;font-weight:bold;text-decoration:underline;\">This Text is BOLD</span></div>\n                        <div><span style=\"font-style:italic;\">This text is Italic</span></div>\n                        <div><span style=\"text-decoration:underline;\">This Text is&#160; Underlined</span></div>\n                      </span>`, {format: 'html'});\n\nWhen I execute this the div elements are getting removed.\nI can see the content inside the BeforeSetContent event. But on the SetContent event the content is getting modified and the div are removed. Is there any way to prevent this behaviour ?\nI tried adding\nvalid_children: '+div[span], +span[div]' \n\nin the editor config.\nI am expecting the html content to be added into the tinymce 6 editor without modifying the tags\n",
"AnswerId": "76393668",
"AnswerBody": "The default behavior is to remove certain elements, such as <div>, when they are inserted using the insertContent method.\nBut you can override this behavior by customizing the editor's schema and adding a rule to allow the <div> element:\ntinymce.init({\n  selector: '#your-selector',\n  // other configurations...\n  setup: function (editor) {\n    editor.on('BeforeSetContent', function (e) {\n      // Allow the <div> element in the content\n      e.content = e.content.replace(/<div>/g, '<div data-mce-bogus=\"1\">');\n    });\n  },\n  valid_elements: 'div[*]' // Allow all attributes on <div> elements\n});\n\n"
},
{
"QuestionId": "76394423",
"QuestionTitle": "Do I need any environment variables set to execute some code, call openai's api, and return a response?",
"QuestionBody": "I was going through a course in OpenAI's API using an in-browser jupyter notebook page but wanted to copy some example code from there into a local IDE. I installed Python and the jupyter extention in VS Code and the OpenAI library. My code is below:\nimport openai\nimport os\n\n# from dotenv import load_dotenv, find_dotenv\n# _ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = \"my api key is here\"\n\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]\n\nprompt = f\"\"\"\nDetermine whether each item in the following list of \\\ntopics is a topic in the text below, which\nis delimited with triple backticks.\n\nGive your answer as list with 0 or 1 for each topic.\\\n\nList of topics: {\", \".join(topic_list)}\n\nText sample: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nI installed Python and imported the openai library. When I run I am getting the error:\nAPIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\nI'm assuming that's because I commented out lines 3 and 4 in the code because I am unsure what they do and do not know how to use the dotenv library. Is it simple to set this up just to make a basic call to the openai API? That's all I'm trying to do with this code right now.\n",
"AnswerId": "76394444",
"AnswerBody": "Usually, you load your API KEY from your .env file but, as you are hardcoding it, you don't need anything else.\nThe error you are getting might be related to the absence of the topic_list and story definitions.\n"
},
{
"QuestionId": "76385353",
"QuestionTitle": "SQLAlchemy 2.0 mock is inserting data",
"QuestionBody": "I am trying to test a SQLAlchemy 2.0 repository and I am getting the error:\nsqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"professions_name_key\"\nSo, although I am mocking the test, it inserts data into the database. What should I do to the test not insert data into the database?\nI am using pytest-mock.\nHere is the SQLAlchemy model\n# File src.infra.db_models.profession_db_model.py\nimport uuid\nfrom sqlalchemy import Column, String\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom src.infra.db_models.db_base import Base\n\n\nclass ProfessionsDBModel(Base):\n    \"\"\" Defines the professions database model.\n    \"\"\"\n\n    __tablename__ = \"professions\"\n\n    profession_id: Mapped[uuid.UUID] = mapped_column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    name: Mapped[str] = mapped_column(String(80), nullable=False, unique=True)\n    description: Mapped[str] = mapped_column(String(200), nullable=False)\n\nHere is the repository:\n# File src.infra.repositories.profession_postgresql_repository.py\n\nfrom typing import Dict, Optional\nimport copy\nimport uuid\nfrom src.domain.entities.profession import Profession\nfrom src.interactor.interfaces.repositories.profession_repository \\\n    import ProfessionRepositoryInterface\nfrom src.domain.value_objects import ProfessionId\nfrom src.infra.db_models.db_base import Session\nfrom src.infra.db_models.profession_db_model import ProfessionsDBModel\n\n\nclass ProfessionPostgresqlRepository(ProfessionRepositoryInterface):\n    \"\"\" Postgresql Repository for Profession\n    \"\"\"\n    def __init__(self) -> None:\n        self._data: Dict[ProfessionId, Profession] = {}\n\n    def __db_to_entity(self, db_row: ProfessionsDBModel) -> Optional[Profession]:\n        return Profession(\n            profession_id=db_row.profession_id,\n            name=db_row.name,\n            description=db_row.description\n        )\n\n    def create(self, name: str, description: str) -> Optional[Profession]:\n        session = Session()\n        profession_id=uuid.uuid4()\n        profession = ProfessionsDBModel(\n            profession_id=profession_id,\n            name=name,\n            description=description\n        )\n        session.add(profession)\n        session.commit()\n        session.refresh(profession)\n        if profession is not None:\n            return self.__db_to_entity(profession)\n        return None\n\nHere is the test:\nimport uuid\nimport pytest\nfrom src.infra.db_models.db_base import Session\nfrom src.domain.entities.profession import Profession\nfrom src.infra.db_models.profession_db_model import ProfessionsDBModel\nfrom .profession_postgresql_repository import ProfessionPostgresqlRepository\nfrom unittest.mock import patch\n\n\ndef test_profession_postgresql_repository(mocker, fixture_profession_developer):\n    \n    \n    mocker.patch(\n        'uuid.uuid4',\n        return_value=fixture_profession_developer[\"profession_id\"]\n    )\n    professions_db_model_mock = mocker.patch(\n        'src.infra.db_models.profession_db_model.ProfessionsDBModel')\n    session_add_mock = mocker.patch.object(\n        Session,\n        \"add\"\n    )\n    session_commit_mock = mocker.patch.object(\n        Session,\n        \"commit\"\n    )\n    session_refresh_mock = mocker.patch.object(\n        Session,\n        \"refresh\"\n    )\n\n    repository = ProfessionPostgresqlRepository()\n    repository.create(\n        fixture_profession_developer[\"name\"],\n        fixture_profession_developer[\"description\"]\n    )\n\n    assert session_add_mock.add.call_once_with(professions_db_model_mock)\n    assert session_commit_mock.commit.call_once_with()\n    assert session_refresh_mock.refresh.call_once_with(professions_db_model_mock)\n\n",
"AnswerId": "76393734",
"AnswerBody": "This solution don't need to pass the session as parameter.\nThe solution was to mock the Session and not its methods separately.\nAs an advantage, the test is more concise now!\nimport uuid\nimport pytest\nfrom src.domain.entities.profession import Profession\nfrom src.infra.db_models.profession_db_model import ProfessionsDBModel\nfrom .profession_postgresql_repository import ProfessionPostgresqlRepository\n\n\ndef test_profession_postgresql_repository(\n        mocker,\n        fixture_profession_developer\n):\n\n    mocker.patch(\n        'uuid.uuid4',\n        return_value=fixture_profession_developer[\"profession_id\"]\n    )\n    professions_db_model_mock = mocker.patch(\n        'src.infra.repositories.profession_postgresql_repository.\\\nProfessionsDBModel')\n    session_mock = mocker.patch(\n        'src.infra.repositories.profession_postgresql_repository.Session')\n    professions_db_model = ProfessionsDBModel(\n        profession_id = fixture_profession_developer[\"profession_id\"],\n        name = fixture_profession_developer[\"name\"],\n        description = fixture_profession_developer[\"description\"]\n    )\n    professions_db_model_mock.return_value = professions_db_model\n    repository = ProfessionPostgresqlRepository()\n    result = repository.create(\n        fixture_profession_developer[\"name\"],\n        fixture_profession_developer[\"description\"]\n    )\n    profession = Profession(\n        professions_db_model_mock.return_value.profession_id,\n        professions_db_model_mock.return_value.name,\n        professions_db_model_mock.return_value.description\n    )\n    session_mock.add.assert_called_once_with(professions_db_model_mock())\n    session_mock.commit.assert_called_once_with()\n    session_mock.refresh.assert_called_once_with(professions_db_model_mock())\n    assert result == profession\n\n\n"
},
{
"QuestionId": "76383075",
"QuestionTitle": "How to access the Fisher Weight matrix W from glmer() fit?",
"QuestionBody": "As stated in my question, I would like to access the Fisher weights used in PIRLS model fitting for GLMMs from my glmer() fit in the R package lme4. For such a simple task, I was surprised that I couldn't find any information in the documentation or on the internet at all. By looking at the structure of the glmer fit, I found two possible quantities that might correspond to what I want (but I have no way to know):\nglmmfit@resp$sqrtWrkWt() and glmmfit@pp$Xwts. They seem to be the same thing (up to very small numerical error). Are these the Fisher weights, or the square root of them? Or is this something else entirely?\nP.S.: Could someone also confirm that glmmfit@resp$wrkResp() gives the working responses z=G(y-mu)+eta (sometimes called pseudodata), where G is a matrix containing the derivaties of the link function? Unexpectedly, it turns out that when I do GLMM_model@resp$eta+GLMM_model@resp$wrkResids()-GLMM_model@resp$wrkResp(), having added an offset of 4 to the model, I get a vector of fours, not zeros as I would expect..\n",
"AnswerId": "76393989",
"AnswerBody": "This is a harder question to answer than it should be, but let's try.\nThere is a draft paper describing the implementation of glmer (an unpublished sequel to the Bates et al. JSS paper available via vignette(\"lmer\", package = \"lme4\") in this directory (PDF here), but — although it is useful as background reading — it doesn't make a direct connection with the code.\n\nThe weights are updated here via\n\ndouble glmResp::updateWts() {\n        d_sqrtrwt = (d_weights.array() / variance()).sqrt();\n        d_sqrtXwt = muEta() * d_sqrtrwt.array();\n        return updateWrss();\n    }\n\ni.e., d_sqrtrtwt is the square root of the working weights [on the linear predictor or link scale] (to be honest I'm not sure what the r signifies); d_sqrtXwt is those weights transformed back on to the response/data scale (by multiplying by dmu/deta, the derivative of the inverse-link function).\nFrom here, sqrtWrkWt is the same as the d_sqrtXwt value computed in updateWts.\nHere we can see that the weights(., type = \"working\") returns object@pp$Xwts^2, and we can even see the comment that\n\nthe working weights available through pp$Xwts should be\nequivalent to: object@resp$weights*(object@resp$muEta()^2)/object@resp$variance() \nHowever, the unit tests in tests/glmmWeights.R suggest that this equivalence is approximate.  This may be fine, however, if the discrepancy is due to another instance of the general problem of reference class fields not being updated at the optimum, then this could cause real problems.  see for example: https://github.com/lme4/lme4/issues/166\n\nHere we see that wrkResp is defined as (d_eta - d_offset).array() + wrkResids(); and here that wrkResids() is (d_y - d_mu).array() / muEta();\nHopefully you should be able to access all the pieces you need without poking around in the guts this way ... e.g. weights(., \"working\") should give you the weights; family(.)$mu.eta should give you the derivative of the inverse-link function; residuals(., \"working\") should give you the working residuals.\nThe clue to why your \"PS\" is not working is that, as you can see from the code listed above, the $eta component of the @resp slot does not include the offset ... another reason it's best to try to work with accessor methods whenever possible instead of digging around ...\n"
},
{
"QuestionId": "76394283",
"QuestionTitle": "Why does my logo not appear in the Bootstrap navbar when using Ruby on Rails?",
"QuestionBody": "I'm working on Ruby on Rails and I'm trying to put a logo.png image in a bootstrap navbar.\nso i used this code in app/views/home/_header.html.erb\n<nav class=\"navbar navbar-expand-lg bg-primary \" data-bs-theme=\"dark\"> \n  <div class=\"container-fluid\">\n   <!-- <a class=\"navbar-brand\" href=\"#\">Estrutecnia</a> -->\n <a class=\"navbar-brand\" href=\"#\">\n      <img src=\"logo.png\" alt=\"Estrutecnia\" width=\"30\" height=\"24\">\n    </a>\n\n\n    <button class=\"navbar-toggler\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#navbarSupportedContent\" aria-controls=\"navbarSupportedContent\" aria-expanded=\"false\" aria-label=\"Toggle navigation\">\n      <span class=\"navbar-toggler-icon\"></span>\n    </button>\n    <div class=\"collapse navbar-collapse\" id=\"navbarSupportedContent\">\n      <ul class=\"navbar-nav me-auto mb-2 mb-lg-0\">\n        <li class=\"nav-item\">\n          <a class=\"nav-link active\" aria-current=\"page\" href=\"#\">Home</a>\n        </li>\n        <li class=\"nav-item\">\n          <a class=\"nav-link\" href=\"#\">Link</a>\n        </li>\n        <li class=\"nav-item dropdown\">\n          <a class=\"nav-link dropdown-toggle\" href=\"#\" role=\"button\" data-bs-toggle=\"dropdown\" aria-expanded=\"false\">\n            Dropdown\n          </a>\n          <ul class=\"dropdown-menu\">\n            <li><a class=\"dropdown-item\" href=\"#\">Action</a></li>\n            <li><a class=\"dropdown-item\" href=\"#\">Another action</a></li>\n            <li><hr class=\"dropdown-divider\"></li>\n            <li><a class=\"dropdown-item\" href=\"#\">Something else here</a></li>\n          </ul>\n        </li>\n        <li class=\"nav-item\">\n          <a class=\"nav-link disabled\">Disabled</a>\n        </li>\n      </ul>\n      <form class=\"d-flex\" role=\"search\">\n        <input class=\"form-control me-2\" type=\"search\" placeholder=\"Search\" aria-label=\"Search\">\n        <button class=\"btn btn-outline-success\" type=\"submit\">Search</button>\n      </form>\n    </div>\n  </div>\n\n</nav>\n\nThe problem is that the logo doesn't appear, look at the navbar\n\nAnd the next errors display\nStarted GET \"/logo.png\" for 127.0.0.1 at 2023-06-02 20:05:47 -0500\n\nActionController::RoutingError (No route matches [GET] \"/logo.png\"):\n\nI tried to put the logo.png file in the root directory that I guess is the folder where the Gemfile and the README.md files are.\nI expect that the logo.png appears at the navbar, but a brocken file icon appears at the left side of the navbar, like described in the image above.\n",
"AnswerId": "76394445",
"AnswerBody": "Images are normally placed in the app/assets/images directory.\nWhen you render a view using the ActionView image_tag helper, Rails automatically populates the image source for you:\nimage_tag('logo.png')\n# => <img src='/assets/icon.png>\n\nThis would be the idiomatic way to handle images in Rails, but of course there's nothing that prevents you from including <image src='/assets/icon.png'> in your markup\n"
},
{
"QuestionId": "76394394",
"QuestionTitle": "React/NextJS Timer-based fade in/fade out of text not working",
"QuestionBody": "I'm relatively new to React and NextJS. I've spent a good 8 hours and a fair amount of research trying to figure this out with no luck!\nI'm trying to set up a component that picks a word at random from an array, fades this in, then after a delay fades it out and fades in a new word.\nAfter hacking together several of my own failed solutions, I found a tutorial and tried their code (with some changes to shift it from TS to JS) but it still doesn't work.\nI can get the text to change on a timer easily enough, but not the fading.\nAny ideas?\nUsing NextJS 13, built on StackBlitz's basic NextJS setup\nindex.js\nimport { useEffect, useState } from 'react';\nimport styles from './index.module.css';\n\nconst FADE_INTERVAL_MS = 2000;\nconst WORD_CHANGE_INTERVAL_MS = FADE_INTERVAL_MS * 2;\nconst WORDS_TO_ANIMATE = [\n  'Hello',\n  'Ciao',\n  'Jambo',\n  'Bonjour',\n  'Salut',\n  'Hola',\n  'Nǐ hǎo',\n  'Hallo',\n  'Hej',\n  '👋🏻',\n];\n\nexport default function AnimatedText() {\n  const [fadeProp, setFadeProp] = useState('fadeout');\n  const [wordOrder, setWordOrder] = useState(0);\n\n  useEffect(() => {\n    const fadeTimeout = setInterval(() => {\n      fadeProp === 'fadein' ? setFadeProp('fadeout') : setFadeProp('fadein');\n    }, FADE_INTERVAL_MS);\n\n    return () => clearInterval(fadeTimeout);\n  }, [fadeProp]);\n\n  useEffect(() => {\n    const wordTimeout = setInterval(() => {\n      setWordOrder(\n        (prevWordOrder) => (prevWordOrder + 1) % WORDS_TO_ANIMATE.length\n      );\n    }, WORD_CHANGE_INTERVAL_MS);\n\n    return () => clearInterval(wordTimeout);\n  }, []);\n\n  return (\n    <h2 className={styles.white}>\n      <span className={`styles.${fadeProp}`}>\n        {WORDS_TO_ANIMATE[wordOrder]}\n      </span>\n      , I'm bleh.\n    </h2>\n  );\n}\n\n\nindex.module.css\n.fadein {\n  animation: fadein 0.3s;\n  -moz-animation: fadein 0.3s;\n  -webkit-animation: fadein 0.3s;\n  -o-animation: fadein 0.3s;\n}\n\n.fadein {\n  animation: fadeout 0.3s;\n  -moz-animation: fadeout 0.3s;\n  -webkit-animation: fadeout 0.3s;\n  -o-animation: fadeout 0.3s;\n}\n\n.white {\n  color: silver;\n}\n\n@keyframes fadein {\n  0% {\n    opacity: 0;\n  }\n  100% {\n    opacity: 1;\n  }\n}\n\n@keyframes fadeout {\n  0% {\n    opacity: 1;\n    color: blue;\n  }\n  100% {\n    opacity: 0;\n    color: red;\n  }\n}\n\n\n",
"AnswerId": "76394468",
"AnswerBody": "You are in the right path. But you need to fix a few things. Instead of doing:\n <span className={`styles.${fadeProp}`}>\n      {WORDS_TO_ANIMATE[wordOrder]}\n </span>\n\nTry it with\n <span className={fadeProp}>\n      {WORDS_TO_ANIMATE[wordOrder]}\n </span>\n\nThe reason being is that you were not setting your css class name selector correclty. I think after that you can tweak it for you convenience.\n------ EDIT -----\nAlso, you will need to create a .css file, not .module.css. I think the reason  is because the .module.css are compiled and cannot be dynamic.\nCreate a global.css file inside styles dir. Import it in you _app.js entrypoint inside pages dir.\nIf you do not have it, it looks something like this:\n_app.js\nimport '../styles/globals.css';\n \n// This default export is required in a new `pages/_app.js` file.\nexport default function MyApp({ Component, pageProps }) {\n  return <Component {...pageProps} />;\n}\n\n\nUsing globals.css is not the best option but you can imrove that later on. Please find more info about styling Nextjs apps here.\n"
},
{
"QuestionId": "76394396",
"QuestionTitle": "store data in memory with nestjs",
"QuestionBody": "I am trying to persist some data in my nestjs server so I can then use that data in my client app through http requests.\nI have created a products.service.ts file with the function getAllData() that fetch some data and creates a new array that is assigned to the variable products (which is the data I'm trying to persist). This function is called when the app is initialized (I know this works because when I run the app the console.log(this.products) inside the function shows data.\nThis is my products.service.ts code:\nimport { Injectable } from '@nestjs/common';\n\n@Injectable()\nexport class ProductsService {\n  private products: any[] = [];\n\n  getProducts(): any[] {\n    //empty\n    console.log(this.products); \n    return this.products;\n  }\n\n  async getAllProducts(): Promise<any[]> {\n    const categories = await this.getProductsCategories();\n    const productsPromises = categories.categories.map(async (category) => {\n        const products = await this.getProductsByCategory(category.strCategory);\n        const modifiedProducts = products.meals.map((product) => {\n            ....\n        });\n        return modifiedProducts;\n      });\n      \n      const products = await Promise.all(productsPromises);\n      const flattenedProducts = products.flat();\n\n      this.products = flattenedProducts;\n      //shows data\n      console.log(this.products) \n      \n      return flattenedProducts;\n    }\n\n  async getProductsCategories(): Promise<any>{\n    try{\n      const apiURL = 'https://www.themealdb.com/api/json/v1/1/categories.php';\n      const apiResponse = await fetch(apiURL);\n      const categories = await apiResponse.json(); \n\n      return categories;\n    }\n    catch(e){\n      throw new Error('Error while fetching products');\n    }\n  }\n  async getProductsByCategory(category: string): Promise<any> {\n    try {\n      const apiURL = `https://www.themealdb.com/api/json/v1/1/filter.php?c=${category}`;\n      const apiResponse = await fetch(apiURL);\n      const products = await apiResponse.json();\n\n      return products;\n    } catch (e) {\n      throw new Error('Error while fetching products by category');\n    }\n  }\n}\n\nThe function getProducts() is called in my products.controller.ts file when an http request is done in the route '/products' but the products array is empty:\nimport { Controller, Get, Param } from '@nestjs/common';\nimport { ProductsService } from './products.service';\n\n@Controller('products')\nexport class ProductsController {\n    constructor(private readonly ProductsService: ProductsService) {}\n\n @Get('/')\n    async getAllProducts(): Promise<any[]> {\n        const products = await this.ProductsService.getProducts();\n\n        return products;\n     }\n }\n\nAny idea why the products variable is empty when I make the request ? It should have the data created with getAllProducts() as this function is called onModuleInit\nUPDATE 1:\nI'll add the products.module.ts where I call getAllProducts() onModuleInit:\nimport { Module, OnModuleInit } from '@nestjs/common';\nimport { ProductsController } from './products.controller';\nimport { ProductsService } from './products.service';\n\n@Module({\n    controllers: [ProductsController],\n    providers: [ProductsService],\n})\n\nexport class ProductsModule implements OnModuleInit {\n    constructor(private readonly productsService: ProductsService) {}\n  \n    async onModuleInit() {\n      await this.productsService.getAllProducts();\n    }\n}\n\nThen I import and use this module at app.module.ts file:\nimport { ProductsModule } from './products/products.module';\n...\n\n@Module({\n  imports: [ProductsModule],\n  controllers: [AppController, ProductsController],\n  providers: [AppService, ProductsService],\n})\n\nexport class AppModule {}\n\n",
"AnswerId": "76394477",
"AnswerBody": "Don't add the ProductsController and ProductsService to the AppModule. You essentially have two \"versions\" of the ProductsController and ProductsService being instantiated, and Nest is calling the one that didn't run the onModuleInit from the ProductsModule. Remove them from the AppModule it and should all work.\n"
},
{
"QuestionId": "76390606",
"QuestionTitle": "How can I add a chatter for many2many fields (tags) in Odoo 16?",
"QuestionBody": "I want to add chatter for Tags. But odoo does not support tracking of many2many fields.\nWhat should i do?\nAny Suggestions.\nI tried to put tracking=true on tag_ids field but it does not work.\nI am stuck here. Please give your suggestions.\n",
"AnswerId": "76393898",
"AnswerBody": "You can override the _track_mail function to track x2many fields.\nCheck the code just after # Many2many tracking comment in the project module\nExample:\nif len(changes) > len(tracking_value_ids):\n    for changed_field in changes:\n        if tracked_fields[changed_field]['type'] in ['one2many', 'many2many']:\n            field = self.env['ir.model.fields']._get(self._name, changed_field)\n            vals = {\n                'field': field.id,\n                'field_desc': field.field_description,\n                'field_type': field.ttype,\n                'tracking_sequence': field.tracking,\n                'old_value_char': ', '.join(initial_values[changed_field].mapped('name')),\n                'new_value_char': ', '.join(self[changed_field].mapped('name')),\n            }\n            tracking_value_ids.append(Command.create(vals))\n\n"
},
{
"QuestionId": "76392212",
"QuestionTitle": "Typescript return type of intersected functions is mismatched with the inferred type",
"QuestionBody": "As I was trying to extract the return type of a request that is intersected, I came across the this mismatch of the return type and the inferred type. Here is the shortened url https://tsplay.dev/mAxZZN\nexport {}\ntype Foo =  (() => Promise<string>) & (() => Promise<any>) ;\n\n\ntype FooResult = Foo extends () => Promise<infer T> ? T : null\n//   ^?\n\nconst a:Foo = async () => {\n        return \"\";\n    }\n\nconst b = await a();\n//    ^?\n\n\ntype Foo2 =  (() => Promise<any>) & (() => Promise<string>);\n\ntype FooResult2 = Foo2 extends () => Promise<infer T> ? T : null\n//   ^?\n\nconst c:Foo2 = async () => {\n    return \"\";\n}\n\nconst d = await c();\n//    ^?\n\nIn these 2 above examples the results are mismatched to FooResult:any b:string and FooResult2:string d:any\nTo make my example more clear instead of having a Foo type I just have a intersected type like HTTPRequest & {json: () => Promise<Type>} to have a correct return type of the request json object.\nIs there anyway I can make these 2 be matched correctly to same type? If so how? Thanks for the help in advance! <3\n",
"AnswerId": "76394011",
"AnswerBody": "An intersection of function types is equivalent to an overloaded function type with multiple call signatures.  And there are known limitations when dealing with such types at the type level. Unless you're trying to use overloads and have a strong need for them, you should consider refactoring to use a single call signature instead.\n\nWhen you call an overloaded function, the call is resolved with \"the most appropriate\" call signature; often the first one in the ordered list that applies:\n// call signatures\nfunction foo(x: string): number;\nfunction foo(x: number): string;\n\n// implementation\nfunction foo(x: string | number) {\n    return typeof x === \"string\" ? x.length : x.toFixed(1)\n}\n\nconst n = foo(\"abc\"); // resolves to first call signature\n// const n: number\n\nconst s = foo(123); // resolves to second call signature\n// const s: string\n\nSo the return type will depend on the input type.\n\nOn the other hand, when you try to infer from an overloaded function type, the compiler pretty much only infers from the last call signature:\ntype FooRet = ReturnType<typeof foo>\n// type FooRet = string\n// ^^^^^^^^^^^^^^^^^^^^ not (string & number) or [string, number]\n\nThis is mentioned in the Handbook documentation for using infer in conditional types and is considered a design limitation of TypeScript, as mentioned in microsoft/TypeScript#43301.\nThere are some possible workarounds to try to tease apart multiple call signature information using conditional types, but they are fragile, and before you even think of using them, you should re-examine your use case.\n\nIf you've got two call signatures with the same parameter types, then they really will not behave well at all:\nfunction bar(): { a: string };\nfunction bar(): { b: number }; // why?\nfunction bar() {\n    return { a: \"\", b: 1 }\n}\n\nWhen you call the function you'll get the first return type:\nconst a = bar();\n// const a: { a: string; }\n\nBut when you infer you'll get the last return type:\ntype BarRet = ReturnType<typeof bar>;\n// type BarRet = { b: number; }\n\nAnd there doesn't seem to be a reason to have multiple call signatures in such cases.  If you want to get an intersection of return types, you should just have one call signature that does that:\nfunction baz(): { a: string } & { b: number } {\n    return { a: \"\", b: 1 }\n}\nconst ab = baz();\n// const ab: { a: string; } & { b: number; }\ntype BazRet = ReturnType<typeof baz>;\n// type BazRet: { a: string; } & { b: number; }\n\n\nSo in your case, (() => Promise<string>) & (() => Promise<any>) is equivalent to an overloaded function whose first no-arg call signature returns Promise<string> and whose second no-arg call signature returns Promise<any>.  So you'll get the first when you call and the last when you infer.  Instead you should just have a single call signature like () => Promise<string> or () => Promise<any> or whatever your desired type is (the any type is problematic itself, but I won't digress further here to talk about it).\nPlayground link to code\n"
},
{
"QuestionId": "76394330",
"QuestionTitle": "MobSF unable to install on windows 11",
"QuestionBody": "I have a question regarding installation of MobSF on my windows 11. its been countless times i tried without any luck.\ni appreciate the expert here to point out what is my problems.I have downloaded latest MobSF from git\nC:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF>setup\n[INSTALL] Checking for Python version 3.8+\n[INSTALL] Found Python 3.9.5\n[INSTALL] Found pip\nRequirement already satisfied: pip in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (21.1.1)\nCollecting pip\n  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n     |████████████████████████████████| 2.1 MB 261 kB/s\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.1.1\n    Uninstalling pip-21.1.1:\n      Successfully uninstalled pip-21.1.1\nSuccessfully installed pip-23.1.2\n[INSTALL] Found OpenSSL executable\n[INSTALL] Found Visual Studio Build Tools\n[INSTALL] Creating venv\nRequirement already satisfied: pip in c:\\users\\user\\documents\\mobile-security-framework-mobsf\\venv\\lib\\site-packages (21.1.1)\nCollecting pip\n  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n     |████████████████████████████████| 2.1 MB 384 kB/s\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.1.1\n    Uninstalling pip-21.1.1:\n      Successfully uninstalled pip-21.1.1\nSuccessfully installed pip-23.1.2\n[INSTALL] Installing Requirements\nCollecting wheel\n  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n     ---------------------------------------- 64.5/64.5 kB 53.4 kB/s eta 0:00:00\nInstalling collected packages: wheel\nSuccessfully installed wheel-0.40.0\nIgnoring gunicorn: markers 'platform_system != \"Windows\"' don't match your environment\nCollecting Django>=3.1.5 (from -r requirements.txt (line 1))\n  Downloading Django-4.2.1-py3-none-any.whl (8.0 MB)\n     ---------------------------------------- 8.0/8.0 MB 2.2 MB/s eta 0:00:00\nCollecting lxml>=4.6.2 (from -r requirements.txt (line 2))\n  Downloading lxml-4.9.2-cp39-cp39-win_amd64.whl (3.9 MB)\n     ---------------------------------------- 3.9/3.9 MB 524.7 kB/s eta 0:00:00\nCollecting rsa>=4.7 (from -r requirements.txt (line 3))\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting biplist>=1.0.3 (from -r requirements.txt (line 4))\n  Downloading biplist-1.0.3.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... done\nCollecting requests>=2.25.1 (from -r requirements.txt (line 5))\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n     ---------------------------------------- 62.6/62.6 kB 418.7 kB/s eta 0:00:00\nCollecting bs4>=0.0.1 (from -r requirements.txt (line 6))\n  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n  Preparing metadata (setup.py) ... done\nCollecting colorlog>=4.7.2 (from -r requirements.txt (line 7))\n  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\nCollecting macholib>=1.14 (from -r requirements.txt (line 8))\n  Downloading macholib-1.16.2-py2.py3-none-any.whl (38 kB)\nCollecting whitenoise>=5.2.0 (from -r requirements.txt (line 9))\n  Downloading whitenoise-6.4.0-py3-none-any.whl (19 kB)\nCollecting waitress>=1.4.4 (from -r requirements.txt (line 10))\n  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n     ---------------------------------------- 57.7/57.7 kB 1.0 MB/s eta 0:00:00\nCollecting psutil>=5.8.0 (from -r requirements.txt (line 12))\n  Downloading psutil-5.9.5-cp36-abi3-win_amd64.whl (255 kB)\n     ---------------------------------------- 255.1/255.1 kB 1.4 MB/s eta 0:00:00\nCollecting shelljob>=0.6.2 (from -r requirements.txt (line 13))\n  Downloading shelljob-0.6.3-py3-none-any.whl (9.9 kB)\nCollecting asn1crypto>=1.4.0 (from -r requirements.txt (line 14))\n  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n     ---------------------------------------- 105.0/105.0 kB 1.5 MB/s eta 0:00:00\nCollecting oscrypto>=1.2.1 (from -r requirements.txt (line 15))\n  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n     ---------------------------------------- 194.6/194.6 kB 2.0 MB/s eta 0:00:00\nCollecting distro>=1.5.0 (from -r requirements.txt (line 16))\n  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\nCollecting IP2Location==8.9.0 (from -r requirements.txt (line 17))\n  Downloading IP2Location-8.9.0-py3-none-any.whl (16 kB)\nCollecting lief>=0.12.3 (from -r requirements.txt (line 18))\n  Downloading lief-0.13.1-cp39-cp39-win_amd64.whl (3.1 MB)\n     ---------------------------------------- 3.1/3.1 MB 2.7 MB/s eta 0:00:00\nCollecting http-tools>=2.1.1 (from -r requirements.txt (line 19))\n  Downloading http-tools-2.1.1.tar.gz (550 kB)\n     ---------------------------------------- 550.3/550.3 kB 3.8 MB/s eta 0:00:00\n  Preparing metadata (setup.py) ... done\nCollecting libsast>=1.5.1 (from -r requirements.txt (line 20))\n  Downloading libsast-1.5.2.tar.gz (36 kB)\n  Preparing metadata (setup.py) ... done\nCollecting pdfkit>=0.6.1 (from -r requirements.txt (line 21))\n  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\nCollecting google-play-scraper>=0.1.2 (from -r requirements.txt (line 22))\n  Downloading google_play_scraper-1.2.4-py3-none-any.whl (28 kB)\nCollecting androguard==3.4.0a1 (from -r requirements.txt (line 23))\n  Downloading androguard-3.4.0a1-py3-none-any.whl (918 kB)\n     ---------------------------------------- 918.1/918.1 kB 668.1 kB/s eta 0:00:00\nCollecting apkid==2.1.4 (from -r requirements.txt (line 24))\n  Downloading apkid-2.1.4-py2.py3-none-any.whl (116 kB)\n     ---------------------------------------- 116.6/116.6 kB 3.4 MB/s eta 0:00:00\nCollecting quark-engine==22.10.1 (from -r requirements.txt (line 25))\n  Downloading quark_engine-22.10.1-py3-none-any.whl (97 kB)\n     ---------------------------------------- 97.6/97.6 kB 1.4 MB/s eta 0:00:00\nCollecting frida==15.2.2 (from -r requirements.txt (line 26))\n  Downloading frida-15.2.2.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... done\nCollecting tldextract==3.4.0 (from -r requirements.txt (line 27))\n  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n     ---------------------------------------- 93.9/93.9 kB 1.8 MB/s eta 0:00:00\nCollecting openstep-parser==1.5.4 (from -r requirements.txt (line 28))\n  Downloading openstep_parser-1.5.4-py3-none-any.whl (4.5 kB)\nCollecting svgutils==0.3.4 (from -r requirements.txt (line 29))\n  Downloading svgutils-0.3.4-py3-none-any.whl (10 kB)\nCollecting ruamel.yaml==0.16.13 (from -r requirements.txt (line 31))\n  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)\n     ---------------------------------------- 111.9/111.9 kB 1.6 MB/s eta 0:00:00\nCollecting click==8.0.1 (from -r requirements.txt (line 32))\n  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n     ---------------------------------------- 97.4/97.4 kB 1.4 MB/s eta 0:00:00\nCollecting decorator==4.4.2 (from -r requirements.txt (line 33))\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nCollecting asgiref<4,>=3.6.0 (from Django>=3.1.5->-r requirements.txt (line 1))\n  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\nCollecting sqlparse>=0.3.1 (from Django>=3.1.5->-r requirements.txt (line 1))\n  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n     ---------------------------------------- 41.2/41.2 kB 998.2 kB/s eta 0:00:00\nCollecting tzdata; sys_platform == \"win32\" (from Django>=3.1.5->-r requirements.txt (line 1))\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n     ---------------------------------------- 341.8/341.8 kB 1.5 MB/s eta 0:00:00\nCollecting pyasn1>=0.1.3 (from rsa>=4.7->-r requirements.txt (line 3))\n  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n     ---------------------------------------- 83.9/83.9 kB 1.6 MB/s eta 0:00:00\nCollecting charset-normalizer<4,>=2 (from requests>=2.25.1->-r requirements.txt (line 5))\n  Downloading charset_normalizer-3.1.0-cp39-cp39-win_amd64.whl (97 kB)\n     ---------------------------------------- 97.1/97.1 kB 2.8 MB/s eta 0:00:00\nCollecting idna<4,>=2.5 (from requests>=2.25.1->-r requirements.txt (line 5))\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n     ---------------------------------------- 61.5/61.5 kB 1.7 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1 (from requests>=2.25.1->-r requirements.txt (line 5))\n  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n     ---------------------------------------- 123.2/123.2 kB 904.1 kB/s eta 0:00:00\nCollecting certifi>=2017.4.17 (from requests>=2.25.1->-r requirements.txt (line 5))\n  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n     ---------------------------------------- 157.0/157.0 kB 1.6 MB/s eta 0:00:00\nCollecting beautifulsoup4 (from bs4>=0.0.1->-r requirements.txt (line 6))\n  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n     ---------------------------------------- 143.0/143.0 kB 1.4 MB/s eta 0:00:00\nCollecting colorama; sys_platform == \"win32\" (from colorlog>=4.7.2->-r requirements.txt (line 7))\n  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nCollecting altgraph>=0.17 (from macholib>=1.14->-r requirements.txt (line 8))\n  Downloading altgraph-0.17.3-py2.py3-none-any.whl (21 kB)\nCollecting mitmproxy==6.0.2 (from http-tools>=2.1.1->-r requirements.txt (line 19))\n  Downloading mitmproxy-6.0.2-py3-none-any.whl (1.1 MB)\n     ---------------------------------------- 1.1/1.1 MB 2.6 MB/s eta 0:00:00\nCollecting markupsafe==2.0.1 (from http-tools>=2.1.1->-r requirements.txt (line 19))\n  Downloading MarkupSafe-2.0.1-cp39-cp39-win_amd64.whl (14 kB)\nCollecting pyyaml>=6.0 (from libsast>=1.5.1->-r requirements.txt (line 20))\n  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n     ---------------------------------------- 151.6/151.6 kB 3.0 MB/s eta 0:00:00\nCollecting networkx>=2.2 (from androguard==3.4.0a1->-r requirements.txt (line 23))\n  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n     ---------------------------------------- 2.1/2.1 MB 3.9 MB/s eta 0:00:00\nCollecting pygments>=2.3.1 (from androguard==3.4.0a1->-r requirements.txt (line 23))\n  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n     ---------------------------------------- 1.1/1.1 MB 5.2 MB/s eta 0:00:00\nCollecting matplotlib>=3.0.2 (from androguard==3.4.0a1->-r requirements.txt (line 23))\n  Downloading matplotlib-3.7.1-cp39-cp39-win_amd64.whl (7.6 MB)\n     ---------------------------------------- 7.6/7.6 MB 5.2 MB/s eta 0:00:00\nCollecting pydot>=1.4.1 (from androguard==3.4.0a1->-r requirements.txt (line 23))\n  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\nCollecting ipython>=5.0.0 (from androguard==3.4.0a1->-r requirements.txt (line 23))\n  Downloading ipython-8.14.0-py3-none-any.whl (798 kB)\n     ---------------------------------------- 798.7/798.7 kB 5.1 MB/s eta 0:00:00\nCollecting yara-python-dex>=1.0.1 (from apkid==2.1.4->-r requirements.txt (line 24))\n  Downloading yara_python_dex-1.0.4-cp39-cp39-win_amd64.whl (130 kB)\n     ---------------------------------------- 130.2/130.2 kB 8.0 MB/s eta 0:00:00\nCollecting prettytable>=1.0.0 (from quark-engine==22.10.1->-r requirements.txt (line 25))\n  Downloading prettytable-3.7.0-py3-none-any.whl (27 kB)\nCollecting tqdm (from quark-engine==22.10.1->-r requirements.txt (line 25))\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n     ---------------------------------------- 77.1/77.1 kB 4.5 MB/s eta 0:00:00\nCollecting graphviz (from quark-engine==22.10.1->-r requirements.txt (line 25))\n  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n     ---------------------------------------- 47.0/47.0 kB 2.3 MB/s eta 0:00:00\nCollecting pandas (from quark-engine==22.10.1->-r requirements.txt (line 25))\n  Downloading pandas-2.0.2-cp39-cp39-win_amd64.whl (10.7 MB)\n     ---------------------------------------- 10.7/10.7 MB 4.9 MB/s eta 0:00:00\nCollecting prompt-toolkit==3.0.19 (from quark-engine==22.10.1->-r requirements.txt (line 25))\n  Downloading prompt_toolkit-3.0.19-py3-none-any.whl (368 kB)\n     ---------------------------------------- 368.4/368.4 kB 5.8 MB/s eta 0:00:00\nCollecting plotly (from quark-engine==22.10.1->-r requirements.txt (line 25))\n  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n     ----------------------------- ---------- 11.3/15.3 MB 32.1 kB/s eta 0:02:06\nERROR: Exception:\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n    yield\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n    data = self._fp_read(amt) if not fp_closed else b\"\"\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 455, in read\n    n = self.readinto(b)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 499, in readinto\n    n = self.fp.readinto(b)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py\", line 704, in readinto\n    return self._sock.recv_into(b)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\", line 1241, in recv_into\n    return self.read(nbytes, buffer)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\", line 1099, in read\n    return self._sslobj.read(len, buffer)\nsocket.timeout: The read operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 169, in exc_logging_wrapper\n    status = run_func(*args)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 248, in wrapper\n    return func(self, options, args)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n    requirement_set = resolver.resolve(\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 185, in resolve\n    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 509, in _resolve_one\n    dist = self._get_dist_for(req_to_install)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 462, in _get_dist_for\n    dist = self.preparer.prepare_linked_requirement(req)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 516, in prepare_linked_requirement\n    return self._prepare_linked_requirement(req, parallel_builds)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 587, in _prepare_linked_requirement\n    local_file = unpack_url(\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n    file = get_http_url(\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n    from_path, content_type = download(link, temp_dir.path)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n    for chunk in chunks:\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n    for chunk in iterable:\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n    for chunk in response.raw.stream(\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py\", line 135, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\venv\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\npip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n[INSTALL] Clean Up\n=======================MobSF Clean Script for Windows=======================\nRunning this script will delete the Scan database, all files uploaded and generated.\nC:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\scripts\nDeleting all uploads\nDeleting all downloads\nDeleting Static Analyzer migrations\nDeleting Dynamic Analyzer migrations\nDeleting MobSF migrations\nDeleting temp and log files\nDeleting Scan database\nDeleting Secret file\nDeleting Previous setup files\nDeleting MobSF data directory: \"C:\\Users\\User\\.MobSF\"\nDone\n[INSTALL] Migrating Database\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\manage.py\", line 12, in <module>\n    from django.core.management import execute_from_command_line\nModuleNotFoundError: No module named 'django'\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\manage.py\", line 12, in <module>\n    from django.core.management import execute_from_command_line\nModuleNotFoundError: No module named 'django'\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\Documents\\Mobile-Security-Framework-MobSF\\manage.py\", line 12, in <module>\n    from django.core.management import execute_from_command_line\nModuleNotFoundError: No module named 'django'\nDownload and Install wkhtmltopdf for PDF Report Generation - https://wkhtmltopdf.org/downloads.html\n[INSTALL] Installation Complete\n[ERROR] Installation Failed!\nPlease ensure that all the requirements mentioned in documentation are installed before you run setup script.\nScroll up to see any installation errors.\n\nThe 'decorator==4.4.2' distribution was not found and is required by the application\n\nIve tried git clone\nreinstall python to 3.9.5\nput the environment variables for python\n",
"AnswerId": "76394486",
"AnswerBody": "The error message says:\nThe 'decorator==4.4.2' distribution was not found\nSo have you tried simply running pip install decorator==4.4.2? According to this github issue, installing the missing package fixed a similar problem.\n"
},
{
"QuestionId": "76390794",
"QuestionTitle": "How to detect variables defined outside the function (or undefined) without running the function in python",
"QuestionBody": "I would like a function (let's call it detect_undefined) which detects variables used in a function, which are not defined inside the function without running it.\nExamples:\nimport numpy as np\n\ndef add(a):\n    return np.sum(a)\n\nprint(detect_undefined(add))\n\nOutput: [\"np\"]\ndef add(a):\n    import numpy as np\n    return np.sum(a)\n\nprint(detect_undefined(add))\n\nOutput: []\nb = 3\n\n\ndef add(a):\n    return a + b\n\nprint(detect_undefined(add))\n\nOutput: [\"b\"]\ndef add(a, b=3):\n    return a + b\n\nprint(detect_undefined(add))\n\nOutput: []\nIt is crucial that the algorithm works without running the function to be examined, i.e. I cannot do something like try ... except. ChatGPT suggested to use inspect and ast, but its suggestion didn't quite work.\n",
"AnswerId": "76394082",
"AnswerBody": "I'll provide two solutions, the first one doesn't work exactly, but I'll leave the information in case someone sees this post a few years later.\nSolution1\ninspect.getclosurevars or func.__code__.co_names is exactly what it is for. And it should be preferred over the 2nd solution.\nb = 3\n\n\ndef add(a):\n    return a + b\n\n\nprint(inspect.getclosurevars(add))\n# ClosureVars(nonlocals={}, globals={'b': 3}, builtins={}, unbound=set())\nprint(add.__code__.co_names)\n# ('b',)\n\nUnfortunately, there is a bug in it, so it won't work.\nimport numpy as np\n\n\ndef add(a):\n    return np.sum(a)\n\n\nprint(inspect.getclosurevars(add))\n# ClosureVars(nonlocals={}, globals={'np': <module 'numpy' from ...>}, builtins={'sum': <built-in function sum>}, unbound=set())\nprint(add.__code__.co_names)\n# ('np', 'sum')\n# Note: sum is incorrectly detected as a built-in function.\n\nSolution2\nUse the dis module to analyze the function in bytecode. Below is an example of the information that dis provides.\nb = 3\n\n\ndef add(a):\n    return np.sum([a, b])\n\n\nprint(dis.dis(add))\n\nResult:\n 10           0 LOAD_GLOBAL              0 (np)\n              2 LOAD_METHOD              1 (sum)\n              4 LOAD_FAST                0 (a)\n              6 LOAD_GLOBAL              2 (b)\n              8 BUILD_LIST               2\n             10 CALL_METHOD              1\n             12 RETURN_VALUE\n\nAs you can see, LOAD_GLOBAL lines are what you are looking for. Now we can parse the lines and extract the names.\nTo parse the above result, dis.get_instructions is more useful.\ndef detect_undefined(func):\n    for ins in dis.get_instructions(func):\n        if inspect.iscode(ins.argval):  # inner function\n            yield from detect_undefined(ins.argval)\n        elif ins.opname == \"LOAD_GLOBAL\":  # global variable\n            yield ins.argval\n\nHere is the complete code with some tests.\nimport dis\nimport inspect\nimport numpy as np\n\n\ndef detect_undefined(func):\n    for ins in dis.get_instructions(func):\n        if inspect.iscode(ins.argval):  # inner function\n            yield from detect_undefined(ins.argval)\n        elif ins.opname == \"LOAD_GLOBAL\":  # global variable\n            yield ins.argval\n\n\ndef add1(a):\n    return np.sum(a)\n\nprint(list(detect_undefined(add1)))\n# ['np']\n\n\ndef add2(a):\n    import numpy as np\n    return np.sum(a)\n\nprint(list(detect_undefined(add2)))\n# []\n\n\nb = 3\n\ndef add3(a):\n    return a + b\n\nprint(list(detect_undefined(add3)))\n# ['b']\n\n\ndef add4(a, b=3):\n    return a + b\n\nprint(list(detect_undefined(add4)))\n# []\n\n\nx = 0\ny = 1\nz = 2\n\ndef complex_func(*args, **kwargs):\n    p = 0\n    print(f\"{x}\")\n    def inner1(t):\n        q = y\n        return lambda s: x + add3(z)\n    return inner1(2)\n\nprint(list(detect_undefined(complex_func)))\n# ['print', 'x', 'y', 'x', 'add3', 'z']\n# Note that x is used twice, so it is detected twice.\n\nOne last thing to mention is that it also detects global functions. This may not be the OP's desired result, but excluding functions would be quite a challenge. Keep in mind that in Python we can assign functions to variables (b = add) or redefine functions as variables (add = 0). Or even worse, what are we supposed to do with a tuple that contains both variables and functions.\n"
},
{
"QuestionId": "76385145",
"QuestionTitle": "Weird behavior in linking table creation in EF Core, adding it in the DbContext but shows two versions in the migration file",
"QuestionBody": "I have a weird behavior happening in my code.\nI've created a Place entity and a SubCategory entity.\nBecause it is a many to many relationship, I created a PlaceSubCategory entity with a composite key.\nNow, here's what its creation looks like in the DbContext:\npublic DbSet<PlaceSubCategory> PlaceSubCategories { get; set; }\n\nAnd here's what it creates in the migration file:\nmigrationBuilder.CreateTable(\n    name: \"PlaceSubCategories\",\n    columns: table => new\n    {\n        PlaceId = table.Column<Guid>(type: \"uniqueidentifier\", nullable: false),\n        SubCategoryId = table.Column<Guid>(type: \"uniqueidentifier\", nullable: false),\n        CreatedDateTime = table.Column<DateTime>(type: \"datetime2\", nullable: false, defaultValueSql: \"getutcdate()\")\n    },\n    constraints: table =>\n    {\n        table.PrimaryKey(\"PK_PlaceSubCategories\", x => new { x.PlaceId, x.SubCategoryId });\n        table.ForeignKey(\n            name: \"FK_PlaceSubCategories_Places_PlaceId\",\n            column: x => x.PlaceId,\n            principalTable: \"Places\",\n            principalColumn: \"PlaceId\");\n        table.ForeignKey(\n            name: \"FK_PlaceSubCategories_SubCategories_SubCategoryId\",\n            column: x => x.SubCategoryId,\n            principalTable: \"SubCategories\",\n            principalColumn: \"SubCategoryId\");\n    });\n\nmigrationBuilder.CreateTable(\n    name: \"PlaceSubCategory\",\n    columns: table => new\n    {\n        PlacesPlaceId = table.Column<Guid>(type: \"uniqueidentifier\", nullable: false),\n        SubCategoriesSubCategoryId = table.Column<Guid>(type: \"uniqueidentifier\", nullable: false)\n    },\n    constraints: table =>\n    {\n        table.PrimaryKey(\"PK_PlaceSubCategory\", x => new { x.PlacesPlaceId, x.SubCategoriesSubCategoryId });\n        table.ForeignKey(\n            name: \"FK_PlaceSubCategory_Places_PlacesPlaceId\",\n            column: x => x.PlacesPlaceId,\n            principalTable: \"Places\",\n            principalColumn: \"PlaceId\",\n            onDelete: ReferentialAction.Cascade);\n        table.ForeignKey(\n            name: \"FK_PlaceSubCategory_SubCategories_SubCategoriesSubCategoryId\",\n            column: x => x.SubCategoriesSubCategoryId,\n            principalTable: \"SubCategories\",\n            principalColumn: \"SubCategoryId\",\n            onDelete: ReferentialAction.Cascade);\n    });\n\nIt creates the table twice, which I thought was the default behaviour in EF Core to create a background linking table and so it shows in the migration file, but I'm not sure if that's the case.\nAlso, here's the configuration file for PlaceSubCategory (and not PlaceSubCategories):\npublic class PlaceSubCategoryConfiguration : IEntityTypeConfiguration<PlaceSubCategory>\n{\n    public void Configure(EntityTypeBuilder<PlaceSubCategory> builder)\n    {\n        // define the composite key for PlaceSubCategory table\n        builder.HasKey(x => new { x.PlaceId, x.SubCategoryId });\n\n        builder.HasOne<Place>(d => d.Place)\n            .WithMany(d => d.SubCategoriesLink)\n            .HasForeignKey(d => d.PlaceId)\n            .OnDelete(DeleteBehavior.NoAction)\n            .IsRequired();\n\n        builder.HasOne<SubCategory>(d => d.SubCategory)\n            .WithMany(d => d.PlacesLink)\n            .HasForeignKey(d => d.SubCategoryId)\n            .OnDelete(DeleteBehavior.NoAction)\n            .IsRequired();\n\n        builder.Property(p => p.CreatedDateTime)\n            .HasConversion(AppDbContext.utcConverter)\n            .HasDefaultValueSql(\"getutcdate()\");\n    }\n}\n\nBut it isn't taking it into account, as you can see by the delete behavior being non-existent in the PlaceSubCategories creation, but there's an automatically set delete behavior for\nPlaceSubCategory that's not what I set in the configuration file.\nAnd of course the configuration has been set:\nmodelBuilder.ApplyConfiguration(new PlaceSubCategoryConfiguration());\n\n",
"AnswerId": "76393995",
"AnswerBody": "The reason was that by creating this linking entity I was doing what EF Core would do anyway which is to create a linking entity in the background that would be showing in the migration file. So my entity got created and EF Core's as well without warning.\nI deleted my entity and the EF Core's automatically created linking entity got added to the migration file, which seems fine and the same thing as if I created it.\n"
},
{
"QuestionId": "76391247",
"QuestionTitle": "Accessibility Rules Check for Progress Bars",
"QuestionBody": "I am working on a React eCommerce website. The designs given to me show a flow for checking someone's credit for approval. When the user hits the \"Submit Application\" button, it takes them to a page that says \"Reviewing Application\" with a progress bar that takes about 12 seconds to load. When the bar is complete, the text says, \"You're Approved\" or \"Sorry, you are not approved\".\nThe designs then show that the Approved screen stays for a few seconds and then they are redirected to the checkout page. My question is, does this break any accessibility rules? It feels wrong to have a user click a button and then all these actions happen and if they are not paying attention, they could miss it telling them that they are approved.\nThe client is very keen on having a good accessibility score and wants to make sure that they don't break any rules. If this isn't allowed, can you please add a link to where it is stated more specifically? All I keep getting when Googleing this are examples of how to build a progress bar. TIA!\n",
"AnswerId": "76394272",
"AnswerBody": "There two WCAG checkpoints at play here.\nThe first is dynamic content added to the page. \"Reviewing application...\" and then \"you're approved (or not)\".  That falls under WCAG 4.1.3 Status Messages. Just make sure the \"reviewing application\" indicates that the process is running. I'm guessing you have some kind of animation during the 12 seconds or so that it takes to approve or disapprove?  You could potentially use aria-busy=\"true\" during the 12 seconds then set it to false when done.\nAlternatively, you can use an aria-live region and then update the contents of that region to say \"reviewing application...\" and then maybe update it every 5 seconds or so to say \"still reviewing...\".  You'll probably need aria-atomic=\"true\" if you update the region with the same text (\"still reviewing...\") multiple times, otherwise the live region won't think anything changed.\nThe second checkpoint is WCAG 2.2.1 Timing Adjustable because you are redirecting the user on your own timing, and like you said, they might miss the approval status.  Or they might not have had time to read the approval page.\nThere are 6 ways to fix 2.2.1 as noted in the guideline itself.  \"Extend\" is the most common and you typically see this in \"log off\" situations where you're about to be logged off due to inactivity but are given a chance to extend your session. The same would be applied to your redirect. You can show the user the approval or denial message and then have a \"you will be redirected to the checkout page in XX seconds\" message with an option to extend the time limit.\nPersonally, I think the redirection should be avoided altogether. Just tell the user they've been approved or denied and then have a call to action button (CTA) and let the user navigate to the checkout screen on their own time. Then you avoid the 2.2.1 issue.\n"
},
{
"QuestionId": "76394452",
"QuestionTitle": "about the remove() function,how can i del the last element only?",
"QuestionBody": "I have the problem is that,When i press remove button,whole list is deleted,\nfor example,i add ABC and DEF,this 2 parts,\nI press one time and ABC also gone!\nhow can i fix it?\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>To-Do List</title>\n  </head>\n  <body>\n    <h1>To-Do List</h1>`\n    <input type=\"text\" class=\"task\" placeholder=\"Enter a task\">\n    <button class=\"Add\">Add Task</button>\n    <button class=\"removeTask\">Remove</button>\n    <ul class=\"taskList\"></ul>\n  </body>\n  <script>\n\n\n\nconst taskList = document.querySelector(\".taskList\");\nconst RemoveEl = document.querySelector(\".removeTask\");\nconst addTask = document.querySelector(\".Add\");\n\n\naddTask.addEventListener(\"click\", (e)=>{ \n  const taskInput = document.querySelector(\".task\");\nconst newTask = document.createElement(\"li\");\nlet task = taskInput.value;\n\n  if (task.trim() != \"\") {\n    \n    newTask.innerText = task;\n    taskList.appendChild(newTask);\n    taskInput.value = \"\";};\n  \n    if(newTask){\n  RemoveEl.addEventListener(\"click\",()=>{\n\n    taskList.remove();\n\n  })\n}});\n  </script>\n</html>\n\nthank you so much!\n",
"AnswerId": "76394488",
"AnswerBody": "The issue you're facing is because in the event handler for the Remove button, you are calling remove() on the taskList, which is the ul containing all your tasks. This will remove the entire ul element from the DOM, thereby deleting all tasks.\nInstead, you should remove only the last task added to the list. Here's how you can do it:\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>To-Do List</title>\n  </head>\n  <body>\n    <h1>To-Do List</h1>`\n    <input type=\"text\" class=\"task\" placeholder=\"Enter a task\">\n    <button class=\"Add\">Add Task</button>\n    <button class=\"removeTask\">Remove</button>\n    <ul class=\"taskList\"></ul>\n  </body>\n  <script>\n    const taskList = document.querySelector(\".taskList\");\n    const RemoveEl = document.querySelector(\".removeTask\");\n    const addTask = document.querySelector(\".Add\");\n\n    addTask.addEventListener(\"click\", () => {\n      const taskInput = document.querySelector(\".task\");\n      const newTask = document.createElement(\"li\");\n      let task = taskInput.value;\n\n      if (task.trim() != \"\") {\n        newTask.innerText = task;\n        taskList.appendChild(newTask);\n        taskInput.value = \"\";\n      }\n    });\n\n    RemoveEl.addEventListener(\"click\", () => {\n      if (taskList.lastChild) {\n        taskList.lastChild.remove();\n      }\n    });\n  </script>\n</html>\n\nThis updated script adds an event listener to the Remove button outside of the Add button's event listener. When the Remove button is clicked, it checks if there is a last child element in the task list (the last task added). If there is, it removes that element, leaving the rest of the task list intact.\n"
},
{
"QuestionId": "76389619",
"QuestionTitle": "How to solve Fatal error: Maximum execution time of 300 seconds exceeded in Drupal installation on line 171?",
"QuestionBody": "Fatal error: Maximum execution time of 300 seconds exceeded on line 171\nI am new in the world of drupal My port no.80 is assigned to my ASP server so I changed my Apache server from 80 to 8080 in httpd.conf , BTW I am using XAMPP server I got Error \"Fatal error: Maximum execution time of 300 seconds exceeded in C:\\xampp\\htdocs\\MyDemoWebsite\\core\\modules\\mysql\\src\\Driver\\Database\\mysql\\Connection.php on line 171\" while install site after Set up database in core instal Set up database Image\nMaximum execution time of 300 seconds exceeded in\nMay be I am doing somthing wrong in Set Up Database enter image description here   I have tried by changing the port no. to 8080port no. to 8080\n",
"AnswerId": "76394033",
"AnswerBody": "Maybe you're doing it first time. So, you have confused Apache port with mysql port.\n\nYou can see, I have started Xampp, here I am running Apache, with http and https, in ports (80, and 443) now according to the availability of ports in your pc, you can change them\nNow, comes the database i.e. MySQL, whose port is normally 3306, or you can change to something else, according to your availability.\nDuring Drupal installation. The database port which you have put as 8080, will be 3306, if you have not changed it either, which you can check from your xampp control panel, as I have added screenshot.\nNow, as apache is running on port 8080, then your site will run on localhost:8080/<folder-name>, by default apache port is 80 which is omitted by browser, if that changed to anything else, which requires to be mentioned on http address\n"
},
{
"QuestionId": "76383192",
"QuestionTitle": "How can I create a D3 transition animation to update a React component without re-rendering the whole plot?",
"QuestionBody": "I have a D3js Plot wrapped inside a React component (v7). For example a Bar Plot with a data table and a parameter for which column to plot. On change of the plotting variable, I do not want to re-render the whole plot but instead execute a D3 transition animation to the new variable.\nRight now I have tried it following the stump-code here, but first I have problems getting the initial plot to render and second I really would like to understand what the correct React hook way is to achieve this…\nimport * as React from \"react\";\nimport * as d3 from \"d3\";\n\nexport function BarPlot({\n  data,\n  x,\n  width,\n  height,\n}: {\n  data: DataTable;\n  x: string;\n  width: number;\n  height: number;\n}) {\n  const svgRef = React.useRef<SVGSVGElement>(null);\n  const svg = d3.select(svgRef.current);\n\n  const prevX = React.useRef<string>(x);\n  \n  \n  if (svgRef.current === null) {\n    svg.selectAll(\"*\").remove();\n    svg\n      .append(\"g\")\n      .selectAll()\n      .data(data)\n    // …\n    // Normal d3 plotting code here\n    // …\n  }\n\n\n  if (prevX.current !== x) {\n    // Update the plot, animate the transition from plotting the old bars to the new bars\n\n    prevX.current = x;\n  }\n\n  return <svg ref={svgRef} width={width} height={height} />;\n}\n\nWhen looking around for the correct React-way to do this, it seems useEffect is not the right choice here. I also tried to use useMemo to save the inital plot, but even then I need to manually check whether the transitionable parameters have changed…\nAbstract, I think the question is how to have a React component, where part of the render code is executed intially and another part only if the already rendered component has a change in one of the props.\n",
"AnswerId": "76394700",
"AnswerBody": "Here is an example of animated bar chart using React with D3.\nJust add a useEffect on the SVG element ref and build the chart when ref is valid (when the component is mounted)\n\n\nconst MAX_VALUE = 200;\n\nconst BarChart = ({ data, height, width }) => {\n  const svgRef = React.useRef(null);\n\n  React.useEffect(() => {\n    const svg = d3.select(svgRef.current);\n\n    const xScale = d3.scaleBand()\n      .domain(data.map((value, index) => index.toString()))\n      .range([0, width])\n      .padding(0.1);\n\n    const yScale = d3.scaleLinear()\n      .domain([0, MAX_VALUE])\n      .range([height, 0]);\n\n    const xAxis = d3.axisBottom(xScale)\n      .ticks(data.length)\n      .tickFormat((_, index) => data[index].label);\n\n    svg\n      .select(\"#x-axis\")\n      .style(\"transform\", `translateY(${height}px)`)\n      .style(\"font-size\", '16px')\n      .call(xAxis);\n\n    const yAxis = d3.axisLeft(yScale);\n    svg\n      .select(\"#y-axis\")\n      .style(\"font-size\", '16px')\n      .call(yAxis)\n\n    svg.selectAll('g.tick');\n\n    const bars = svg\n      .selectAll(\".bar\")\n      .data(data)\n      .join(\"g\")\n      .classed(\"bar\", true);\n      \n    bars.append(\"rect\")\n      .style(\"transform\", \"scale(1, -1)\")\n      .attr(\"x\", (_, index) => xScale(index.toString()))\n      .attr(\"y\", -height)\n      .attr(\"width\", xScale.bandwidth())\n      .transition()\n      .delay((_, index) => index * 500)\n      .duration(1000)\n      .attr(\"fill\", d => d.color)\n      .attr(\"height\", (d) => height - yScale(d.value));\n      \n  }, [data]);\n\n  return (\n      <svg ref={svgRef} height={height} width={width} />\n  );\n};\n\nconst data = [\n  {value: 50, color: '#008'}, \n  {value: 100, color: '#00C'}, \n  {value: 150, color: '#00f'}\n];\n\nReactDOM.render(\n  <BarChart data={data} width={300} height={170} />, \n  document.getElementById(\"chart\")\n);\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.4/d3.min.js\"></script>\n\n<script crossorigin src=\"https://unpkg.com/react@16/umd/react.development.js\"></script>\n\n<script crossorigin src=\"https://unpkg.com/react-dom@16/umd/react-dom.development.js\"></script>\n\n<div id='chart'></div>\n\n\n\n"
},
{
"QuestionId": "76390441",
"QuestionTitle": "Procedure pointer vs procedure name as argument of Fortran procedures",
"QuestionBody": "My understanding is that we can pass the information about which procedure should be used inside a Fortran procedure, either using an argument and declaring it to be a procedure name through a specific interface, or using an argument declared to be a procedure pointer.\nI do not think I have grasped all pros and cons of the two alternatives. Maybe one has some limitations not present with the other? Are there efficiency issues?\n\nJust to make clear what this question is about (if necessary), I'll briefly recall through two examples the different ways of passing information about which procedure should be used inside a procedure, through the procedure arguments.\n\nusing an argument and declaring it to be a procedure name through a specific interface\n\nmodule pro\n implicit none\ncontains\n\n function myfunction(x) result(res) ! this is an actual function with the right signature to be used as argument of the subroutine prosub\n    real, intent(in) :: x\n    real :: res\n    res = 2*x\n end function myfunction\n\n subroutine prosub(f,x)\n   real, intent(in) :: x\n   procedure(myfunction) :: f  ! the actual argument used in place of the dummy argument f must be the name of a function with the same signature as myfunction\n   print*,f(x)\n end subroutine prosub\nend module pro\n\nprogram ppp\n use pro\n implicit none\n real :: x\n print*,' x= ?'\n read*,x\n call prosub(myfunction,x)\nend program ppp\n\n\n\nusing an argument declared to be a procedure pointer\n\nmodule pro\n implicit none\n abstract interface ! defines the signature of the functions the procedure pointers argument of the subroutine prosub must have\n   function f(x) result(res)\n     real, intent(in) :: x\n     real :: res\n   end function f\n end interface\n\ncontains\n\n function myfunction(x) result(res) ! one of the possible actual functions the procedure pointer can point to\n    real, intent(in) :: x\n    real :: res\n    res = 2*x\n end function myfunction\n\n subroutine prosub(fp,x)\n   real, intent(in) :: x\n   procedure(f), pointer :: fp\n   print*,fp(x)\n end subroutine prosub\nend module pro\n\nprogram ppp\n use pro\n implicit none\n real :: x\n procedure(f), pointer :: f1\n\n f1 => myfunction\n\n print*,' x= ?'\n read*,x\n call prosub(f1,x)\nend program ppp \n\n\n",
"AnswerId": "76394100",
"AnswerBody": "A dummy procedure pointer, when contrasted with a non-pointer dummy procedure, may (depending on argument intent and the like):\n\nbe passed in as disasssociated or undefined,\nhave its association status tested,\nhave its association status changed,\npass out information to the calling context.\n\nIf these capabilities are useful to have when writing a subprogram, then there might be a need for a dummy procedure pointer.\nSpecifying that something is a procedure pointer or non-pointer is orthogonal to how you specify the interface.  There is no semantic difference between a declaration of the form\nprocedure(some_interface) :: proc\n\nand writing out an interface body for proc that has the same characteristics as some_interface. In your first \"non-pointer\" program, you could have equally written:\nsubroutine prosub(f,x)\n  real, intent(in) :: x\n  procedure(myfunction) :: f  ! or use the abstract interface\n  print*,f(x)\nend subroutine prosub\n\nand in your second \"pointer\" program, you could have written:\nsubroutine prosub(fp,x)\n  real, intent(in) :: x\n \n  interface \n    function fp(x) result(res)\n      real, intent(in) :: x\n      real :: res\n    end function fp\n  end interface\n  pointer :: fp\n \n  print*,fp(x)\nend subroutine prosub\n\nThis choice comes down to whether you want to specify the (perhaps abstract) interface in one location, or how much you like typing.\n"
},
{
"QuestionId": "76394304",
"QuestionTitle": "Confusion regarding converting recursion to iteration using stack",
"QuestionBody": "I have a big confusion on what is meant by the general method of converting recursive functions (tail and non tail) to iterative ones using stack. I made this simple example to illustrate the point:\nint sigma1(int n) {\n  if(n == 0) \n    return 0;\n  else \n    return n + sigma1(n-1);\n}\n\nwhich of the following versions reflects the method correctly:\nVersion 1\nint sigma1_iter(int n) {\n  stack* s = create_stack(n);\n  push(s, n);\n  int res = 0;\n  while(!is_empty(s)) {\n    int elm = pop(s);\n    if(elm == 0)\n      return res;\n    else {\n      res += n;\n      push(s, n-1);\n    }\n  }\n}\n\n\nVersion 2\nint sigma1_iter(int n) {\n  stack* s = create_stack(n);\n  push(s, n);\n  int res = 0;\n  while(!is_empty(s)) {\n    if (n > 0) {\n      n--;\n      push(s, n);\n    }\n    else {\n      int elm = pop(s);\n      if(elm == 0)\n        return res;\n      else {\n        res += n;\n    }\n  }\n}\n\nAlso, in case of the tail recursive version of sigma with an accumulator:\nint sigma2(int n, int res) {\n  if (n == 0) \n    return res;\n  else\n    return sigma2(n-1, n+res);\n}\n\nHow would one convert it? I am thinking of creating a second stack for res, but how that might work?\n",
"AnswerId": "76394489",
"AnswerBody": "Be sure to post a minimal, reproducible example when you ask a question. That helps everyone understand the question and generate and test potential answers.\nIf you had created such an example, it would be evident that version 1 of your iterative solution never returns and version 2 always returns 0 making neither a good candidate for correctness.\nRecursion can be challenging, but I think we can walk through a general method for converting a recursive function to an iterative function for this example.\nLet's look at the recursive implementation for sigma1,\nint sigma1(int n) {\n    if (n == 0)\n        return 0;\n    else\n        return n + sigma1(n - 1);\n}\n\nUnder the hood, calling this function generates a new stack frame for each recursive invocation (assuming the compiler doesn't optimize it away). Each of these call frames will have the value of the argument n for that frame which will decrease by one at each level of recursion. We can think about the iterative version, in the same way, storing the value of n on our explicit std::stack<int> instead of it being handled automagically by the call stack.\nWhen the recursion terminates and the call frames unwind, the local value of n is added to the result of the previous call creating a new result to be returned. In the same way, we can pop values from the explicit std::stack<int> and add them to the running total in the iterative version.\nThe function would look something like this,\nint sigma1_stack(int n) {\n    std::stack<int> stack;\n    for (int i = n; i > 0; --i)\n        stack.push(i);\n\n    int res{};\n    while (not stack.empty()) {\n        res += stack.top();\n        stack.pop();\n    }\n\n    return res;\n}\n\nNow, in this particular scenario, you can simplify the two loops into a single iterative loop without a stack. This, of course, will not always be the case.\nint sigma1_iter(int n) {\n    int res{};\n    for (int i = n; i > 0; --i)\n        res += i;\n    return res;\n}\n\nI took the code you posted and changed it to compile using a std::stack<int> since you did not post a complete example. I also added a correct version of iteration for both sigma1 and sigma2 and the corresponding output. Hope this is helpful.\nSample Code\n#include <iostream>\n#include <stack>\n\nusing std::cout, std::endl;\n\nint sigma1(int n) {\n    if (n == 0)\n        return 0;\n    else\n        return n + sigma1(n - 1);\n}\n\nint sigma1_iter_v1(int n) {\n    std::stack<int> stack;\n    stack.push(n);\n\n    int res = 0;\n    while (not stack.empty()) {\n        int elm = stack.top();\n        stack.pop();\n        if (elm == 0)\n            return res;\n        else {\n            res += n;\n            stack.push(n - 1);\n        }\n    }\n\n    return res;\n}\n\nint sigma1_iter_v2(int n) {\n    std::stack<int> stack;\n    stack.push(n);\n\n    int res = 0;\n    while (not stack.empty()) {\n        if (n > 0) {\n            n--;\n            stack.push(n);\n        } else {\n            int elm = stack.top();\n            stack.pop();\n            if(elm == 0)\n                return res;\n            else {\n                res += n;\n            }\n        }\n    }\n\n    return res;\n}\n\nint sigma1_iter(int n) {\n    int res{};\n    for (int i = n; i > 0; --i)\n        res += i;\n    return res;\n}\n\nint sigma1_stack(int n) {\n    std::stack<int> stack;\n    for (int i = n; i > 0; --i)\n        stack.push(i);\n\n    int res{};\n    while (not stack.empty()) {\n        res += stack.top();\n        stack.pop();\n    }\n\n    return res;\n}\n\nint sigma2(int n, int res = 0) {\n    if (n == 0)\n        return res;\n    else\n        return sigma2(n - 1, n + res);\n}\n\nint sigma2_iter(int n) {\n    int res{};\n    for (int i = n; i > 0; --i)\n        res += i;\n    return res;\n}\n\nint main(int argc, const char *argv[]) {\n    cout << \"sigma1         : \" << sigma1(20) << endl;\n    cout << \"sigma1_iter   : \" << sigma1_iter(20) << endl;\n    cout << \"sigma1_stack  : \" << sigma1_stack(20) << endl;\n    // This never returns\n    // cout << \"sigma1_iter_v1 : \" << sigma1_iter_v1(20) << endl;\n    cout << \"sigma1_iter_v1 : \" << \"never returns\" << endl;\n    cout << \"sigma1_iter_v2 : \" << sigma1_iter_v2(20) << endl;\n\n    cout << endl;\n    cout << \"sigma2         : \" << sigma2(20) << endl;\n    cout << \"sigma2_iter    : \" << sigma2_iter(20) << endl;\n    return 0;\n}\n\nOutput\nsigma1         : 210\nsigma1_iter    : 210\nsigma1_stack   : 210\nsigma1_iter_v1 : never returns\nsigma1_iter_v2 : 0\n\nsigma2         : 210\nsigma2_iter    : 210\n\n"
},
{
"QuestionId": "76392206",
"QuestionTitle": "Where to host Django project files on deployment server",
"QuestionBody": "New to Django here. I have developed a minimum working django website with Postgres as database back-end and nginx/gunicorn as web server on Ubuntu linux. Currently all the files are on my laptop in ~/workspace/djangoapp/src$ in my home directory. I want to now deploy the project to GCP. Which directory, on the production server, the files would go in? It can't be my home directory on the production server. Shouldn't they go in one of the system directories like /opt?\n",
"AnswerId": "76395043",
"AnswerBody": "If you want to deploy your project on Google Cloud Platform, you should follow GCP guidelines. There are step by step guide on how to deploy and run Django app on GCP as for example running \"Django on App Engine standard environment\".\nIt would be easier to follow the GCP guides for your production server.\n"
},
{
"QuestionId": "76384215",
"QuestionTitle": "How to increase Kubeflow Jupyter notebook image name to see the complete path",
"QuestionBody": "I have a deployment of Kubeflow. During creation of Jupyter Notebook, we have image name tags that are longer than that can be displayed in the  Docker image name list.  See the image list in the attached image. Here the names are short, but for our customer the repository URL is a long fqdn of the harbor registry URL.   Is there any configuration that can increase the visible text ?\n\nLooking for a configuration to increase the visible text. Tried adding tags to the docker image, but this is only a suffix for the name.\n",
"AnswerId": "76394322",
"AnswerBody": "As I understand it, you'd like to display the repository prefix for your Jupyter images. For this, you can set to false the hideRegistry key in the Jupyter Web App ConfigMap. By default, the value of this key is true, which hides the image repository in the user interface.\nSearch this ConfigMap in kubeflow namespace. In Kubeflow Manifests GitHub repository you can found in spawner_ui_config.yaml file.\n"
},
{
"QuestionId": "76394292",
"QuestionTitle": "Filling NAN values in Pandas by using previous values",
"QuestionBody": "I have a Pandas DataFrame in the following format.\n\nI am trying to fill the NaN value by using the most recent non-NaN value and adding one second to the time value. For example, in this case, the program should take the most recent non-NaN value of 8:30:20 and add one second to replace the NaN value. So, the replacement value should be 8:30:21. Is there a way in Pandas to simulate this process for the entire column?\n",
"AnswerId": "76394541",
"AnswerBody": "You can convert your data to_timedelta, ffill and add 1 second:\ndf['col1'] = pd.to_timedelta(df['col1'])\n\ndf['col1'] = df['col1'].ffill().add(df['col1'].isna()*pd.Timedelta('1s'))\n\nOutput:\n             col1\n0 0 days 08:30:18\n1 0 days 08:30:19\n2 0 days 08:30:20\n3 0 days 08:30:21\n4 0 days 08:30:22\n\nUsed input:\ndf = pd.DataFrame({'col1': ['8:30:18', '8:30:19', '8:30:20', np.nan, '8:30:22']})\n\nconverting back to strings\nUse a custom function:\ndef to_str(s):\n    h,m = s.dt.total_seconds().divmod(3600)\n    m,s = m.divmod(60)\n    return (h.astype(int).astype(str).str.zfill(2)\n            +':'+\n            m.astype(int).astype(str).str.zfill(2)\n            +':'+\n            s.astype(int).astype(str).str.zfill(2)\n            )\n    \ndf['col1'] = to_str(df['col1'])\n\nOutput:\n       col1\n0  08:30:18\n1  08:30:19\n2  08:30:20\n3  08:30:21\n4  08:30:22\n\n"
},
{
"QuestionId": "76383655",
"QuestionTitle": "docker compose 3.3 cannot reach other containers",
"QuestionBody": "I have a docker-compose file version 3.3 describing a Postgres (PostGIS) database instance and a GeoServer (HTTP backend).\nI run them with no dependencies, but in the same docker network.\nLater once PostGIS has done its thing and GeoServer has done its thing as well, I configure a GeoServer datastore with the Postgres connection details via the GeoServer API using the Postgres Docker service name as host, but then when I test these connection details the test fails i.e. GeoServer cannot reach Postgres in the same Docker network.\nInteresting fact: the Postgres container is on reach from localhost.\n# this works\nPGCONNECT_TIMEOUT=2 psql \"postgresql://adm_pg_user:1234abcd@localhost:6666/fgag_db\" --command \"SELECT NOW();\"\n\nIt's a pure TCP/IP issue as I logged into the GeoServer running container and used the command psql to see that Postgres is not on reach, see below and notice pg-db instead of localhost:\n# from within the GeoServer container this doesn't work\nPGCONNECT_TIMEOUT=2 psql \"postgresql://adm_pg_user:1234abcd@pg-db:6666/fgag_db\" --command \"SELECT NOW();\"\n\n\nThe error message is:\npsql: error: connection to server at \"pg-db\" (172.19.0.3), port 6666 failed: Connection refused\n    Is the server running on that host and accepting TCP/IP connections?\n\n\nWhat's wrong with the Docker Compose YAML below?\nHow can I implement networking checks?\n\nFor completeness: I use this env var COMPOSE_PROJECT_NAME=fgag to be able to add my preferred prefix to docker services / docker network names. Maybe this is relevant to the networking issues.\nversion: \"3.3\"\nservices:\n  pg-db:\n    image: postgis/postgis:15-3.3-alpine\n    restart: always\n    ports:\n      - \"${MYPG_PORT:-5432}:5432\"\n    environment:\n      # https://github.com/docker-library/docs/tree/master/postgres#environment-variables\n      POSTGRES_USER: \"${MYPG_USER:-adm_pg_user}\"\n      POSTGRES_PASSWORD: \"${MYPG_PASSWORD:-1234abcd}\"\n      POSTGRES_DB: \"${MYPG_DB:-fgag_db}\"\n      PGPASSWORD: \"${MYPG_PASSWORD:-1234abcd}\"\n      MYDB_SCHEMA: \"${MYDB_SCHEMA:-fgag_schema}\"\n    volumes:\n      - ./docker-volume/pg:/var/lib/postgresql/data\n      - ./db-sql-init.sh:/docker-entrypoint-initdb.d/db-sql-init.sh\n    networks:\n      - fgagnet\n  # https://github.com/geoserver/docker/blob/master/docker-compose-demo.yml\n  # geoserver default admin:geoserver credentials\n  #\n  # to connect to the running container: `docker exec -it fgag_geoserver_1 /bin/bash`\n  #\n  # to be able to use `psql`:\n  # apt-get update && apt-get install postgresql-client\n  #\n  # docker network inspect fgag_fgagnet\n  geoserver:\n    image:  docker.osgeo.org/geoserver:2.23.0\n    ports:\n      - \"${MYGS_PORT:-7777}:8080\"\n    environment:\n      INSTALL_EXTENSIONS: \"true\"\n      STABLE_EXTENSIONS: wps,csw\n      EXTRA_JAVA_OPTS: -Xms1G -Xmx2G\n    volumes:\n      - ./docker-volume/gs/geoserver_data:/opt/geoserver_data/:Z\n      - ./docker-volume/gs/additional_libs:/opt/additional_libs:Z # by mounting this we can install libs from host on startup\n    networks:\n      - fgagnet\nnetworks:\n  fgagnet:\n    driver: bridge\n\n",
"AnswerId": "76395132",
"AnswerBody": "Are you sure that this command connects to the same docker container ?\n# this works\nPGCONNECT_TIMEOUT=2 psql \"postgresql://adm_pg_user:1234abcd@localhost:6666/fgag_db\" --command \"SELECT NOW();\"\n\nAre you sure that you have correctly configured the container to expose port 6666 ?\nexport MYPG_PORT=6666\n\n"
},
{
"QuestionId": "76390662",
"QuestionTitle": "Can't use PHPickerViewController delegate with KMM",
"QuestionBody": "I'm trying to use the UiKit API PHPickerViewController using KMM and Compose for iOS.\nimport androidx.compose.runtime.Composable\nimport androidx.compose.ui.interop.LocalUIViewController\nimport platform.PhotosUI.PHPickerConfiguration\nimport platform.PhotosUI.PHPickerViewController\nimport platform.PhotosUI.PHPickerViewControllerDelegateProtocol\nimport platform.darwin.NSObject\n\n@Composable\nactual fun pickerController() {\n    val uiViewController = LocalUIViewController.current\n    val configuration = PHPickerConfiguration()\n    val pickerController = PHPickerViewController(configuration)\n    val pickerDelegate = object : NSObject(), PHPickerViewControllerDelegateProtocol {\n        override fun picker(picker: PHPickerViewController, didFinishPicking: List<*>) {\n            println(\"didFinishPicking: $didFinishPicking\")\n            picker.dismissViewControllerAnimated(flag = false, completion = {})\n            uiViewController.dismissModalViewControllerAnimated(false)\n        }\n    }\n\n    pickerController.setDelegate(pickerDelegate)\n    uiViewController.presentViewController(pickerController, animated = false, completion = null)\n}\n\nThis displays the image picker:\n\nUnfortunately, when clicking on Cancel, the delegate callback is not called, and I get the following message on the console:\n[Picker] PHPickerViewControllerDelegate doesn't respond to picker:didFinishPicking:\n\nIs it possible to implement the callback in Kotlin?\nWhat am I missing?\n",
"AnswerId": "76395154",
"AnswerBody": "Since pickerDelegate is NSObject, it's lifecycle follows ObjC rules, not KMM memory model.\nSo as soon as the execution leaves composable block, this objects gets released - as setDelegate takes it as weak reference.\nYou can fix it by storing it using remember.\nAlso using your function is dangerous because you're gonna call presentViewController on each recomposition - e.g. if some of your reactive data changes on the calling side.\nYou can update it to return an action that will present it, but store delegate and the action itself using remember:\n@Composable\nactual fun rememberOpenPickerAction(): () -> Unit {\n    val uiViewController = LocalUIViewController.current\n    val pickerDelegate = remember {\n        object : NSObject(), PHPickerViewControllerDelegateProtocol {\n            override fun picker(picker: PHPickerViewController, didFinishPicking: List<*>) {\n                println(\"didFinishPicking: $didFinishPicking\")\n                picker.dismissViewControllerAnimated(flag = false, completion = {})\n            }\n        }\n    }\n\n    return remember {\n        {\n            val configuration = PHPickerConfiguration()\n            val pickerController = PHPickerViewController(configuration)\n            pickerController.setDelegate(pickerDelegate)\n            uiViewController.presentViewController(pickerController, animated = true, completion = null)\n        }\n    }\n}\n\nUsage:\nButton(onClick = rememberOpenPickerAction()) {\n\n}\n\n"
},
{
"QuestionId": "76388968",
"QuestionTitle": "print all unmet dependencies in conda",
"QuestionBody": "I'm trying to install a package via conda on an M1 mac. This package has a lot of dependencies, some of which seem to be un-satisfiable due to lack of pre-built packages in conda-forge.\nI know I can trigger building of packages in conda-forge by issuing a PR like shown here, but I'd prefer sending one big PR with all the packages I need built, rather than trigger building of package A, trying to install, running into dependency B, trigger building of package B, ...\nCan I somehow list all unmet dependencies of a conda package?\n",
"AnswerId": "76394534",
"AnswerBody": "Trival case: directly missing package\nFirst, let's note that this question only has a non-trivial answer when the package in question is noarch. A noarch designation means the package itself is already compatible with osx-arm64. But if it cannot be installed with a plain mamba install, then some non-noarch (compiled) dependency(s) must be missing.\nOtherwise, if the package were not noarch and does not itself have osx-arm64 builds, then requesting migration for that package would trigger both the package and all its (recursive) dependencies to be made available for osx-arm64. (Conda Forge bot is smart like that!)\nI'm not assuming OP has any confusion about this, but I want to get ahead of this situation for the future visitors. Now that that's out of the way let's address OP's question proper...\nAvailable package, but missing dependencies\nWe can absolutely do this with Mamba's amazing subcommand repoquery. Let's find ourselves a concrete example!\nFinding an example\nTo illustrate, I know that Conda Forge doesn't have r-terra building for osx-arm64 right now1. We can use the mamba repoquery whoneeds command to list every noarch package that needs r-terra:\n## search `conda-forge` and only consider `noarch`\n$ mamba repoquery whoneeds -c conda-forge -p noarch r-terra\n\n## abridged output, only showing r-base=4.2 packages\n\n Name         Version Build         Depends          Channel\n────────────────────────────────────────────────────────────────────────\n r-rasterdiv  0.2_5.2 r42hc72bb7e_1 r-terra          conda-forge/noarch\n r-rastervis  0.51.2  r42hc72bb7e_1 r-terra          conda-forge/noarch\n r-biomod2    4.2_2   r42hc72bb7e_0 r-terra >=1.6_33 conda-forge/noarch\n r-biomod2    4.2_3   r42hc72bb7e_0 r-terra >=1.6_33 conda-forge/noarch\n r-rasterdiv  0.3.1   r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-rastervis  0.51.4  r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-rastervis  0.51.5  r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-spatialeco 2.0_0   r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-rasterdiv  0.2_5.2 r42hc72bb7e_1 r-terra          conda-forge/noarch\n r-rastervis  0.51.2  r42hc72bb7e_1 r-terra          conda-forge/noarch\n r-biomod2    4.2_2   r42hc72bb7e_0 r-terra >=1.6_33 conda-forge/noarch\n r-biomod2    4.2_3   r42hc72bb7e_0 r-terra >=1.6_33 conda-forge/noarch\n r-rasterdiv  0.3.1   r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-rastervis  0.51.4  r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-rastervis  0.51.5  r42hc72bb7e_0 r-terra          conda-forge/noarch\n r-spatialeco 2.0_0   r42hc72bb7e_0 r-terra          conda-forge/noarch\n\nSo, all of these are theoretically compatible with osx-arm64, but they depend on the package r-terra that isn't available yet.\nLet's use for our example, r-spatialeco.\nMissing dependencies of r-spatialeco\nAbove we used the whoneeds subcommand for a reverse dependency search; now we'll use the depends command for (forward) dependency search:\n$ mamba repoquery depends -c conda-forge -p osx-arm64 r-spatialeco\n\nExecuting the query r-spatialeco\n\nconda-forge/osx-arm64                                       Using cache\nconda-forge/noarch                                          Using cache\n\n\n Name                            Version Build         Channel\n─────────────────────────────────────────────────────────────────────────────\n r-spatialeco                    2.0_0   r41hc72bb7e_0 conda-forge/noarch\n r-mass                          7.3_53  r40h4d528fc_0 conda-forge/osx-arm64\n r-cluster                       2.1.0   r40h09a9d6b_4 conda-forge/osx-arm64\n r-rcurl >>> NOT FOUND <<<\n r-readr                         2.0.2   r40h8ea1354_0 conda-forge/osx-arm64\n r-sf >>> NOT FOUND <<<\n r-mgcv                          1.8_33  r40hdd02fd4_0 conda-forge/osx-arm64\n r-rann                          2.6.1   r40h39468a4_2 conda-forge/osx-arm64\n r-envstats                      2.3.1   r351_1000     conda-forge/noarch\n r-yaimpute >>> NOT FOUND <<<\n r-spdep >>> NOT FOUND <<<\n r-rms >>> NOT FOUND <<<\n r-terra >>> NOT FOUND <<<\n r-ks                            1.14.0  r41h5d63f41_0 conda-forge/osx-arm64\n r-spatstat.explore              3.0_5   r41h5d63f41_0 conda-forge/osx-arm64\n r-base                          4.1.3   hc39b4fc_7    conda-forge/osx-arm64\n r-spatialpack >>> NOT FOUND <<<\n r-spatstat.geom                 3.2_1   r42h21dc0da_0 conda-forge/osx-arm64\n\nAnd there you have it: the r-spatialeco package is missing seven packages that need to be migrated to osx-arm64, as indicated by the >>> NOT FOUND <<< string.\n\n[1]: I know this because I've taken a stab at getting it migrated multiple times and have yet to succeed. :/\n"
},
{
"QuestionId": "76394525",
"QuestionTitle": "Count exact occurrences of number in array and return True or False",
"QuestionBody": "I have two arrays\nArr1 = [1,1,1,2,2,2,3,3]  and Arr2 =[1,1,2,1]\nComparing both arrays should return True as there are same occurrences of no. 1.\nHowever If Arr2 = [1,1,2] it should return false as the no. Of occurrences of 1 or 2 don't match with the no. Of occurrences of 1 and 2 in Arr1\nEven Arr2 = [1,1,2,3,1] should return True.\nThanks in advance! Cheers\nI tried this but doesn't work for other instances.\nfunction allElementsPresent(first, second) {\n  return second.every((element) => first.includes(element));\n}\n\n",
"AnswerId": "76394579",
"AnswerBody": "I believe I understand what you want to accomplish. You want to see if the number of occurrences in the second array matches the first. If that's the case, I've used this answer as a basis\n\n\nfunction allElementsPresent(first, second, matchAll = false) {\n  if (first.length > 0 && second.length === 0) return false;\n  var counts1st = {};\n  var counts2nd = {};\n\n  for (var num of first) {\n    counts1st[num] = counts1st[num] ? counts1st[num] + 1 : 1;\n  }\n  for (var num of second) {\n    counts2nd[num] = counts2nd[num] ? counts2nd[num] + 1 : 1;\n  }\n\n  for (var count in counts2nd) {\n    if (matchAll && (!counts1st[count] || counts1st[count] !== counts2nd[count])) return false;\n    if (!matchAll && (counts1st[count] && counts1st[count] === counts2nd[count])) return true;\n  }\n  return matchAll ? true : false;\n}\n\n\n\n"
},
{
"QuestionId": "76391948",
"QuestionTitle": "IdentityServer - how to get grant_type from within a Protected API?",
"QuestionBody": "I have an API protected by IdentityServer with an associated allowed scope.\nI have two Identity Server clients with permission to access that allowed scope - one accepts client_credentials (for machine-machine operations), and the other accepts authorization_code (for user-machine operations).\nWithin the API itself, how can I determine whether a given client has been authorised by client_credentials or by authorization_code?\nI can find a few references to the \"gty\" claim but this is not included in tokens generated by identity server. Is there a way to force IdentityServer to include this claim, or is there some other convention for how to identify whether a request originated from a machine client, or from a user?\n",
"AnswerId": "76395205",
"AnswerBody": "you can have different clientID and client definitions for the different use cases (Authorization code flow cs. client credentials flow).\nThen in the client definition for each one, you can add Client Claims, that will be included in the access token and will be included for any user.\nSee https://docs.duendesoftware.com/identityserver/v6/reference/models/client/#token\nThere settings there are related to this:\n\nClaims\n\nAllows settings claims for the client (will be included in the access token).\n\nAlwaysSendClientClaims\n\nIf set, the client claims will be sent for every flow. If not, only for client credentials flow (default is false)\n\nAlwaysIncludeUserClaimsInIdToken\n\nWhen requesting both an id token and access token, should the user claims always be added to the id token instead of requiring the client to use the userinfo endpoint. Default is false.\n\nClientClaimsPrefix\n\nIf set, the prefix client claim types will be prefixed with. Defaults to client_. The intent is to make sure they don’t accidentally collide with user claims.\n"
},
{
"QuestionId": "76390032",
"QuestionTitle": "React Native Component + Navigation with Paramameters not working error undefined is not a method",
"QuestionBody": "I have Reactive Component which passes data from one screen to another..., trying to call second component via Navigate(name,params) method. but it gives an error saying \"undefined method is not a method\". Copying component code below. Guid me to clear the error.\nimport React from 'react';\nimport {\n  StyleSheet,\n  Text,\n  View,\n  Pressable,\n} from 'react-native';\n\nimport { NavigationContainer } from '@react-navigation/native';\n\nexport default function ScreenA(navigation:any) {\n    const onPressHandler = () => {\n        navigation.navigate(\"Screen_B\",{ ItemName: 'Item from ScreenA', ItemId: 12 });\n        // navigation.navigate(\"Screen_B\");\n    }\n\n",
"AnswerId": "76394730",
"AnswerBody": "Destructure navigation from function parameter:\nimport React from 'react';\nimport {\n  StyleSheet,\n  Text,\n  View,\n  Pressable,\n} from 'react-native';\n\nimport { NavigationContainer } from '@react-navigation/native';\n\nexport default function ScreenA({navigation}) { // wrap navigation with curly brackets\n    const onPressHandler = () => {\n        navigation.navigate(\"Screen_B\",{ ItemName: 'Item from ScreenA', ItemId: 12 });\n    }\n\n"
},
{
"QuestionId": "76388515",
"QuestionTitle": "Why mocking HuggingFace datasets library does not work?",
"QuestionBody": "I have a Python function that uses the HuggingFace datasets library to load a private dataset from HuggingFace Hub.\nI want to write a unit test for that function, but it seems pytest-mock does not work for some reason. The real function keeps getting called, even if the mock structure should be correct.\nThis is the main function:\ndef load_data(token: str):\n    dataset = load_dataset(\"MYORG/MYDATASET\", use_auth_token=token, split=\"train\")\n    return dataset\n\nAnd this is the test function I wrote:\ndef test_data(mocker):\n    # Mocked data\n    token_test = \"test_token\"\n    mocked_dataset = [\n        {'image': [[0.5, 0.3], [0.7, 0.9]], 'timestamp': datetime.date(2023, 1, 1)},\n    ]\n    mocker.patch('datasets.load_dataset', return_value=mocked_dataset)\n\n    result = load_data(token_test)\n\n    assert len(result) == 1\n\nCould it be that there are some \"unmockable\" libraries which do stuff under the hood and make their functions impossible to stub?\n",
"AnswerId": "76394624",
"AnswerBody": "The official Python documentation has this part: where-to-patch.\nIf your module is called my_module, and it does from datasets import load_dataset then you should patch mocker.patch('my_module.load_dataset' so that your module is using the mock.\nPatching datasets.load_dataset might be too late, since if the import in your module happened before that instruction, it has no effect.\n"
},
{
"QuestionId": "76390333",
"QuestionTitle": "Is there an escape code to pause the terminal screen refresh?",
"QuestionBody": "I have an application that displays images using 8-bit ANSI-art. This is handy for viewing images on a remote machine via SSH. When the viewer starts, it replaces all the 8-bit palette values from 16-255 with my standard values. This runs fine on the Mac terminal, but the xterm display flickers because it is trying to refresh while it is still executing these 240 commands.\nI get the same thing when the program exits, and I have to reset the colours.  Here is the code for resetting the palette when the program exits.\nfor (int N=16; N<256; ++N) printf(\"\\e]104;%d\\a\", N);\nI can see the colours changing in the terminal as it runs.\nI have not found an escape code that resets the whole palette. Sending Ctrl-C resets some things but not the palette. All the examples I have found use a loop like this. It would be nice to find a reset escape sequence if there is one, but I will also need a way to pause the screen refresh until the commands have finished.\nI tried running all the escape sequences into one big string and submitting all of them at once with puts(). That did not do the trick.\nI hoped to find an escape sequence that pauses the screen refresh, and another that un-pauses it. It seems like something that ought to be there, and I am not seeing it. Or, if we know for sure that no such escape sequences exist, then I can stop looking. There may be other ways of fixing this other than escape codes. However, the application is handiest when working remotely, so I want it to work on whatever terminal is running at the time, not just xterm. I can ignore the flickering if I have to.\nPS:\nI have a workaround. Xterm supports 24-bit Truecolor. I can use that and not change the 8-bit palette.\n",
"AnswerId": "76394804",
"AnswerBody": "Not what the title asks for, but enabling the alternative screen buffer is a fix.\nPrint \"\\e[?1049h to enable when the program starts and and \"\\e[?1049l to disable.\nThe Wikipedia entry says little more than that, so it is easy to ignore. Enabling the alternative screen buffer means the application works with a terminal-sized window of characters. This is probably what an interactive terminal program needs rather than add all the screen refreshes to the current scrolling terminal buffer. Disabling restores the terminal to its previous state.\n"
},
{
"QuestionId": "76391329",
"QuestionTitle": "How do you sort lists of tuples based on the count of a specific value?",
"QuestionBody": "I am working on a NER problem—hence the BIO tagging—with a very small dataset, and I am manually splitting it into train, validation, and test data. Thus, to make the first of two splits, I need to sort lists of tuples into two lists based on the count of 'B' in data.\nI am shuffling data, so the output varies, but it typically yeilds what I provide below. data can be split such that a total count of 10 instances of 'B' is possible in bin_1. So it's not that data won't split this way given the way B is distributed through the lists of tuples.\nHow do I get the split that I am after? For this example, and the desired split, I want the total count of 'B' in bin_1 to be 10, but it's always over.\nAssistance would be much appreciated.\nData:\ndata = [[('a', 'B'), ('b', 'I'), ('c', 'O'), ('d', 'B'), ('e', 'I'), ('f', 'O')],\n        [('g', 'O'), ('h', 'O')],\n        [('i', 'B'), ('j', 'I'), ('k', 'O')],\n        [('l', 'B'), ('m', ''), ('n', 'B'), ('o', 'O')],\n        [('p', 'O'), ('q', 'O'), ('r', 'O')],\n        [('s', 'B'), ('t', 'O')],\n        [('u', 'O'), ('v', 'B'), ('w', 'I'), ('x', 'O'), ('y', 'O')],\n        [('z', 'B')],\n        [('a', 'B'), ('b', 'I'), ('c', 'O')],\n        [('d', 'O')],\n        [('e', 'O'), ('f', 'O')],\n        [('g', 'O'), ('h', 'B')],\n        [('i', 'B'), ('j', 'I')],\n        [('k', 'O')],\n        [('l', 'O'), ('m', 'O'), ('n', 'O'), ('o', 'O')],\n        [('p', 'O'), ('q', 'O'), ('r', 'O'), ('s', 'B'), ('t', 'O')],\n        [('u', 'O'), ('v', 'B'), ('w', 'I'), ('x', 'O'), ('y', 'O'), ('z', 'B')]]\n\nCurrent code:\nsplit = 0.7\nd = []\ntotal_B = 0\nbin_1 = []\nbin_2 = []\ncounter = 0\n\nrandom.shuffle(data)\n\nfor f in data:\n    cnt = {}\n    for _, label in f:\n        if label in cnt:\n            cnt[label] += 1\n        else:\n            cnt[label] = 1\n    d.append(cnt)\n\nfor f in d:\n    total_B += f.get('B', 0)\n\nfor f,g in zip(d, data):\n    if f.get('B') is not None:\n        if counter <= round(total_B * split):\n            counter += f.get('B')\n            bin_1.append(g)\n        else:\n            bin_2.append(g)\n\nprint(round(total_B * split))\nprint(sum(1 for sublist in bin_1 for tuple_item in sublist if tuple_item[1] == 'B'))\nprint(sum(1 for sublist in bin_2 for tuple_item in sublist if tuple_item[1] == 'B'))\n\nCurrent output:\nTotal count of 'B' in 'bin_1' should be: 10\nTotal count of 'B' in 'bin_1' is': 11\nTotal count of 'B' in 'bin_2' is': 3\n\nbin_1, bin_2\n>>>\n[[('a', 'B'), ('b', 'I'), ('c', 'O')],\n  [('g', 'O'), ('h', 'B')],\n  [('i', 'B'), ('j', 'I'), ('k', 'O')],\n  [('u', 'O'), ('v', 'B'), ('w', 'I'), ('x', 'O'), ('y', 'O'), ('z', 'B')],\n  [('s', 'B'), ('t', 'O')],\n  [('l', 'B'), ('m', ''), ('n', 'B'), ('o', 'O')],\n  [('a', 'B'), ('b', 'I'), ('c', 'O'), ('d', 'B'), ('e', 'I'), ('f', 'O')],\n  [('i', 'B'), ('j', 'I')]],\n [[('u', 'O'), ('v', 'B'), ('w', 'I'), ('x', 'O'), ('y', 'O')],\n  [('z', 'B')],\n  [('p', 'O'), ('q', 'O'), ('r', 'O'), ('s', 'B'), ('t', 'O')]]\n\nDesired output:\nTotal count of 'B' in 'bin_1' should be: 10\nTotal count of 'B' in 'bin_1' is': 10\nTotal count of 'B' in 'bin_2' is': 4\n\n",
"AnswerId": "76395290",
"AnswerBody": "One possible solution is to get the distribution of the 'B' among indexes of your data.\nLet's say data was shuffled already, make use of:\n\ndict com prehension: https://peps.python.org/pep-0274/\nenumarate: https://python-reference.readthedocs.io/en/latest/docs/functions/enumerate.html\n\ndef get_distribution(data):\n    return {i: len([x for x in t if (x[1] == 'B')]) for i, t in enumerate(data) }\n\nFor data you get:\ndistribution = get_distribution(data)\nprint(distribution)\n#=> {0: 2, 1: 0, 2: 1, 3: 2, 4: 0, 5: 1, 6: 1, 7: 1, 8: 1, 9: 0, 10: 0, 11: 1, 12: 1, 13: 0, 14: 0, 15: 1, 16: 2}\n\nNow, iterate over distribution and fill your bins. You can develop a more complex algorithm, this is the simplest:\nbin_1 = []\nbin_2 = []\nratio = 0.7\ncount = 0\ntotal = sum(distribution.values())\n\nfor k, v in distribution.items():\n    if count/total < ratio:\n        bin_1.append(data[k])\n        count += v\n    else:\n        bin_2.append(data[k])\n\nSo, check:\nprint(bin_1)\nprint(bin_2)\ndistr_bin_1 = get_distribution(bin_1)\ndistr_bin_2 = get_distribution(bin_2)\nprint(distr_bin_1)\nprint(distr_bin_2)\ncount_bin_1 = sum(distr_bin_1.values())\ncount_bin_2 = sum(distr_bin_2.values())\nprint(count_bin_1/(count_bin_1 + count_bin_2)) # actual ratio\n\n"
},
{
"QuestionId": "76391771",
"QuestionTitle": "How to add the data of this table in markers (pop-up) on map?",
"QuestionBody": "I imported this table from Excel into Jupyter. I was using pandas for this. But now I want to mark markers with cities from table below on my map with  popups with the data from colognes A1,A2,A3 and I don't know how to do this.\nExample: I press on a definite marker and after this the popup appears with this data from colognes A1,A2,A3.\nImage 1:\n\nImage 2:\n\nCan you tell me the corresponding code for this operation?\n",
"AnswerId": "76395312",
"AnswerBody": "To display the pop-up in tabular form at each location, a loop process is performed on each row of the data frame, converting one row from a series to a data frame, and then transposing it. I also adjust the width of the data frame.\nimport pandas as pd\nimport io\nimport folium\n\ndata = '''\nName A1 A2 A3 LAT LON\n\"Malibu Beach\" 0.63 0.55 0.95 34.03194 -118.698387\nCommerce 0.17 0.45 0.25 34.00031 -118.159770\n\"Long Beach\" 0.19 0.21 0.09 33.77171 -118.181310\n'''\ndf = pd.read_csv(io.StringIO(data), delim_whitespace=True)\n\nimport folium\n\nm = folium.Map([df.LAT.mean(), df.LON.mean()], zoom_start=8)\n\nfor i in range(len(df)):\n    html = df.loc[i,['Name','A1','A2','A3']].to_frame().T.to_html(\n        classes=\"table table-striped table-hover table-condensed table-responsive\"\n    )\n    popup = folium.Popup(html, max_width=500)\n    folium.Marker([df.iloc[i]['LAT'], df.iloc[i]['LON']], popup=popup).add_to(m)\n\nm\n\n\n"
},
{
"QuestionId": "76391309",
"QuestionTitle": "ffmpeg - stretched pixel issue",
"QuestionBody": "Context\nI'm converting a PNG sequence into a video using FFMPEG. The images are semi-transparent portraits where the background has been removed digitally.\nIssue\nThe edge pixels of the subject are stretched all the way to the frame border, creating a fully opaque video.\nCause Analysis\nThe process worked fine in the previous workflow using rembg from command line however, since I started using rembg via python script using alpha_matting to obtain higher quality results, the resulting video has these issues.\nThe issue is present in both webm format (target) and mp4 (used for testing).\nCommand Used\nCommand used for webm is:\nffmpeg -thread_queue_size 64 -framerate 30 -i <png sequence location> -c:v libvpx -b:v 0 -crf 18 -pix_fmt yuva420p -auto-alt-ref 0 -c:a libvorbis <png output>\n\nThroubleshooting Steps Taken\n\nPNG Visual inspection The PNG images have a fully transparent background as desired.\nPNG Alpha Measurement I have created a couple of python scripts to look at alpha level in pixels and confirmed that there is no subtle alpha level in the background pixels\nExported MP4 with AE Using the native AE renderer the resulting MP4/H.265 has a black background, so not showing the stretched pixel issue\n\nImage of the Issue\n\nSample PNG Image from sequence\n\nCode Context\nrembg call via API using alpha_matting seems to generate a premultiplied alpha which uses non black pixels for 0 alpha pixels.\nremove(input_data, alpha_matting=True, alpha_matting_foreground_threshold=250,\n                    alpha_matting_background_threshold=250, alpha_matting_erode_size=12)\n\nA test using a rough RGB reset of 0-alpha pixels confirms that the images are being played with their RGB value ignoring Alpha.\ndef reset_alpha_pixels(img):\n    # Open the image file\n    # Process each pixel\n    data = list(img.getdata())\n    new_data = []\n    for item in data:\n        if item[3] == 0:\n            new_data.append((0, 0, 0, 0))\n        else:\n            new_data.append((item[0], item[1], item[2], item[3]))\n        # Replace the alpha value but keep the RGB\n        \n\n    # Update the image data\n    img.putdata(new_data)\n\n    return img\n\nUpdates\n\nAdded python context to make the question more relevant within SO scope.\n\n",
"AnswerId": "76395320",
"AnswerBody": "The issue is related to the video player.\nMost video players doesn't support transparency, and ignores the alpha (transparency) channel.\nThe video player displays the rgb content of the background even if the background is supposed to be hidden (background pixels are fully according to their alpha value).\nApparently, rembg output background is not filled with solid black or white, but having the stretched effect.\nWhen opening the PNG image, and when video in Chrome browser for example, the background is transparent (RGB values are hidden), and we can't see the \"stretched effect\".\n\nSolving the issue using FFMPEG is challenging.\nWe better fix the issue in the Python code after applying rembg.\nFor fixing the issue, me may select a solid background color like (200, 200, 200) gray background, and apply alpha compositing between RGB channels and the background.\n\nExtract RGB channels:\n\n    foreground_rgb = image_after_rembg[:, :, 0:3]  # Extract RGB channels.\n\n\nExtract alpha (transparency) channel and convert from range [0, 255] to [0, 1]:\n\n    alpha = image_after_rembg[:, :, 3].astype(np.float32) / 255  # Extract alpha (transparency) channel and convert from range [0, 255] to [0, 1].\n    alpha = alpha[..., np.newaxis]  # Add axis - new alpha shape is (1024, 1024, 1). We need it for scaling 3D rgb by 2D alpha channel.\n\n\nSet background RGB color to light gray color (for example):\n\n    background_rgb = np.full_like(foreground_rgb, (200, 200, 200))  # Set background RGB color to light gray color (for example).\n\n\nApply \"alpha compositing\" of rgb and background_rgb:\n\n    composed_rgb = foreground_rgb.astype(np.float32) * alpha + background_rgb.astype(np.float32) * (1 -alpha)\n    composed_rgb = composed_rgb.round().astype(np.uint8)  # Convert to uint8 with rounding.\n\n\nAdd the original alpha channel to composed_rgb:\n\n    composed_rgba = np.dstack((composed_rgb, alpha_ch))\n\n\nComplete Python code sample:\nfrom PIL import Image\nimport numpy as np\n#from rembg import remove\n\n#image_file_before_rembg = 'input.png'\nimage_file_after_rembg = 'frame-00001.png'\n\n# Assume code for removing background looks as follows:\n#image_before_rembg = Image.open(image_file_before_rembg)\n#image_after_rembg = remove(image_before_rembg)\n#image_after_rembg.save(image_file_after_rembg)\n\nimage_after_rembg = Image.open(image_file_after_rembg)  # Skip background removing, and read the result from a file.\nimage_after_rembg = np.array(image_after_rembg)  # Convert PIL to NumPy array.\n\nforeground_rgb = image_after_rembg[:, :, 0:3]  # Extract RGB channels.\nalpha_ch = image_after_rembg[:, :, 3]  # Extract alpha (transparency) channel\nalpha = alpha_ch.astype(np.float32) / 255  # Convert alpha from range [0, 255] to [0, 1].\nalpha = alpha[..., np.newaxis]  # Add axis - new alpha shape is (1024, 1024, 1). We need it for scaling 3D rgb by 2D alpha channel.\n\nbackground_rgb = np.full_like(foreground_rgb, (200, 200, 200))  # Set background RGB color to light gray color (for example).\n\n# Apply \"alpha compositing\" of rgb and background_rgb\ncomposed_rgb = foreground_rgb.astype(np.float32) * alpha + background_rgb.astype(np.float32) * (1 -alpha)\n\ncomposed_rgb = composed_rgb.round().astype(np.uint8)  # Convert to uint8 with rounding.\n\ncomposed_rgba = np.dstack((composed_rgb, alpha_ch))  # Add the original alpha channel to composed_rgb\n\n\nImage.fromarray(composed_rgba).save('new_frame-00001.png')  # Save the RGBA output image to PNG file\n\n\nExecuting FFmpeg:\nffmpeg -y -framerate 30 -loop 1 -t 5 -i new_frame-00001.png -vf \"format=rgba\" -c:v libvpx -crf 18 -pix_fmt yuva420p -auto-alt-ref 0 out.webm\n\n\nWhen playing with Chrome browser, the background is transparent.\nWhen playing with VLC Player, the background is light gray:\n\n\nUsing FFmpeg CLI, we have to use alphaextract, overlay and alphamerge filters.\nExample (5 seconds at 3fps for testing):\nffmpeg -y -framerate 3 -loop 1 -i frame-00001.png -filter_complex \"color=white:r=3[bg];[0:v]format=rgba,split=2[va][vb];[vb]alphaextract[alpha];[bg][va]scale2ref[bg0][v0];[bg0][v0]overlay=shortest=1,format=rgb24[rgb];[rgb][alpha]alphamerge\" -c:v libvpx -crf 18 -pix_fmt yuva420p -auto-alt-ref 0 -t 5 out.webm\n"
},
{
"QuestionId": "76389179",
"QuestionTitle": "find values on a user form from text box and results shown on a List box",
"QuestionBody": "i have an excel sheet the has column A which the search value will be in , and it should retrieve results from column B,the code should whenever I enter a value in textbox (txtreg) get results in Listbox (txtledglist) which might be 1 result or more up to 6 .\nthe code that I have is this: whenever I type the search value that has just 1 result brings it fine, but when it has multiple results it gets it but takes over 5 min and somtimes excel crashes which is really unsuall. or when I delete the search value to try and enter a new one it also craches , when I check the VBA I see that the code keeps running which is causing the excel to crash.\nany ideas to make the code simpler or what am I doing wrong?\nthanks.\nPrivate Sub txtreg_Change()\n\n\n    Dim wb As Workbook\n    Dim ws As Worksheet\n    Dim lookupValue As String\n    Dim results() As Variant\n    Dim rng As Range\n    Dim cell As Range\n    Dim index As Long\n    Dim count As Long\n    \n\n    Set wb = ThisWorkbook\n    Set ws = wb.Sheets(\"L 403\")\n    \n\n    lookupValue = txtreg.Value\n    \n    txtledglist.Clear\n    \n    Set rng = ws.Range(\"A:B\")\n    On Error Resume Next\n    Set cell = rng.Columns(1).Find(What:=lookupValue, LookIn:=xlValues, LookAt:=xlWhole)\n    On Error GoTo 0\n    \n    If Not cell Is Nothing Then\n        count = 0\n        Do\n            count = count + 1\n            ' Find the next match\n            Set cell = rng.Columns(1).FindNext(cell)\n        Loop While Not cell Is Nothing And cell.Address <> rng.Columns(1).Find(What:=lookupValue, After:=cell, LookIn:=xlValues, LookAt:=xlWhole).Address\n        \n        ReDim results(1 To count)\n        \n        Set cell = rng.Columns(1).Find(What:=lookupValue, LookIn:=xlValues, LookAt:=xlWhole)\n        \n        index = 1\n        Do\n            results(index) = rng.Columns(2).Cells(cell.Row - rng.Cells(1).Row + 1).Value ' Adjusting for header row\n            index = index + 1\n            Set cell = rng.Columns(1).FindNext(cell)\n        Loop While Not cell Is Nothing And cell.Address <> rng.Columns(1).Find(What:=lookupValue, After:=cell, LookIn:=xlValues, LookAt:=xlWhole).Address\n        \n        txtledglist.List = results\n       \n    End If\n\nEnd Sub\n\n",
"AnswerId": "76395808",
"AnswerBody": "First of all, you should save the first cell you found, so that you don't have to call .Find again, which would restart the search. Also, you don't need to compare against Nothing in the loop condition.\nSecond, I don't clearly understand the line with the comment \"Adjusting for header row\". Anyway, there is no adjustment necessary: the two cells are in the same row.\nThe corrected code:\nPrivate Sub txtreg_Change()\n    Dim lookupValue As String: lookupValue = txtreg.Value\n    Dim wb As Workbook: Set wb = ThisWorkbook\n    Dim ws As Worksheet: Set ws = wb.Sheets(\"L 403\")\n    \n    txtledglist.Clear\n    \n    Dim rng As Range: Set rng = ws.Range(\"A:B\")\n    On Error Resume Next\n    Dim firstCell As Range: Set firstCell = rng.Columns(1).Find(What:=lookupValue, LookIn:=xlValues, LookAt:=xlWhole)\n    On Error GoTo 0\n    \n    If Not firstCell Is Nothing Then\n        Dim cell As Range: Set cell = firstCell\n        Dim count As Long: count = 0\n        Do\n            count = count + 1\n            Set cell = rng.Columns(1).FindNext(cell)\n        Loop While cell.Address <> firstCell.Address\n        \n        Dim results() As Variant: ReDim results(1 To count)\n        \n        Set cell = rng.Columns(1).Find(What:=lookupValue, LookIn:=xlValues, LookAt:=xlWhole)\n        \n        Dim index As Long: index = 1\n        Do\n            results(index) = rng.Cells(cell.Row, 2).Value\n            index = index + 1\n            Set cell = rng.Columns(1).FindNext(cell)\n        Loop While cell.Address <> firstCell.Address\n        \n        txtledglist.List = results\n    End If\nEnd Sub\n\nI don't exactly know your whole application but may be it is worth avoiding .Find and .FindNext.\n"
},
{
"QuestionId": "76391148",
"QuestionTitle": "How to avoid links shifting on hover while increasing font size in a navigation bar?",
"QuestionBody": "i want to create a navigation bar for my website that includes some links and a company logo upon it. The links should have customize spacing in them and means some at first and some at last of right edge . i also want to include an transformation that when the links are hovered the font size of the links increases without affecting or shifting the nearby links or content. i am having a problem as the font increases the neighbours links shifts themselves to maintain margin gap . What should i change or add in my code to do so ?\ni basically tried to use hover subclass of link 'a'. it worked but not perfectly it shift the neighbour links . i am using margin left and right for each link and assigning unique margin for each. when i hover on a link each of the other links shifts themselves to maintain margin respectivley . i think is it good to use margin property in such cases or i should use float if yes then how to align them at particular distances. i am providing an online editor link of my code at end .\nOr here is some part of my css code\n\n\nbody {\n    font-family: Arial, sans-serif;\n    line-height: 1.5;\n    background-color: #f7f7f7;\n    margin: 0;\n}\n\nheader {\n    background-color: black;\n}\n\n.navigation-bar {\n    width: 100%;\n    height: 76px;\n    display: flex;\n    padding: 10px;\n    align-items: center;\n}\n\n.logo img {\n    position: relative;\n    left: 20%;\n    height: 80px;\n    width: auto;\n}\n\n.navigation-links {\n    display: flex;\n    list-style: none;\n    margin: 0;\n    padding: 0;\n}\n\n.navigation-links li {\n    display: inline-block;\n    margin-left: 90px;\n    margin-right: 0px;\n}\n\n.navigation-links li a {\n    font-size: 25px;\n    color: white;\n    text-decoration: none;\n    text-align: center;\n}\n\n.navigation-links li a:hover {\n    font-size: 30px;\n}\n\n/* join now class    */\n.navigation-links li a.special1 {\n    font-size: 25px;\n    font-weight: bold;\n    color: white;\n    margin-left: 60px;\n    margin-right: 0px;\n    text-decoration: none;\n    border: 2px solid rgb(226, 19, 54);\n    border-radius: 50px;\n    padding: 15px 10px;\n    background-color: rgb(226, 19, 54);\n}\n\n/* login class */\n.navigation-links li a.special2 {\n    font-size: 25px;\n    font-weight: bold;\n    color: white;\n    margin-left: 2px;\n    margin-right: 0px;\n    text-decoration: none;\n    border: 2px solid white;\n    border-radius: 50px;\n    padding: 15px 40px;\n    background-color: black;\n}\n\n/*resposive nature*/\n@media screen and (max-width: 768px) {\n    .navigation-links {\n        display: none;\n    }\n}\n<!DOCTYPE html>\n<html lang=\"en\">\n    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Lato\">\n\n    <head>\n      <title>Navigation Bar Example</title>\n      <link rel=\"stylesheet\" type=\"text/css\" href=\"styles2.css\">\n    </head>\n    <body>\n        <header>\n            <div>\n                <nav class=\"navigation-bar\">\n                    <div class=\"logo\">\n                        <img src=\"rocket-g9cbacc798_1280.png\" alt=\"Company Logo\" > \n                    </div>\n                    <ul class=\"navigation-links\">\n                        <li><a href=\"#\">Home</a></li>\n                        <li><a href=\"#\">Projects</a></li>\n                        <li><a href=\"#\">Services</a></li>\n                        <li><a href=\"#\">About</a></li>\n                        <li ><a class=\"special1\"href=\"#\">JOIN NOW</a></li>\n                        <li ><a class=\"special2\" href=\"#\">LOG IN</a></li>\n                    </ul>\n\n                </nav>\n            </div>\n        </header>\n        <!-- Rest of the content -->\n    </body>\n</html>\n\n\n\ncode link - https://codepen.io/Divyansh-Sharma-the-flexboxer/pen/JjmgJVy\n",
"AnswerId": "76395439",
"AnswerBody": "In the example below, there many ascetic changes which are optional. The following CSS is required:\nli {\n  /* Start vertically and horizontally center of `<li>` when transforming */\n  transform-origin: center center;\n  /* Original state is at normal size */\n  transform: scale(1.0); \n  /* When state changes, stretch the duration by 0.7 seconds in a easing pattern */ \n  transition: 0.7s ease /* ✥ */;\n}\n\n/* When the user hovers over a <li>... */\nli:hover {\n  /* ...take it out of the normal \"flow\" of the document... */\n  position: relative;\n  /* ...give it a higher position on the z-axis... */\n  z-index: 1;\n  /* ...increase it's size by 20% */\n  transform: scale(1.2) /* ✥ */;\n}\n/* ✥ Values can vary according to preference */ \n\nInitially each <li> is inert but has instructions when it is hovered over. When a <li> is hovered over it is out of the normal \"flow\" of the document and it's size will not interfere with any \"static\" elements (any element that doesn't have position: relative/absolute/fixed/sticky).\nNote: Please review the example in Full Page mode, viewing in the iframe doesn't render perfectly (links are too small).\n\n\n:root {\n  margin: 0;\n  font: 5vmin/1.15 Lato;\n}\n\nbody {\n  min-height: 100vh;\n  margin: 0;\n  background-color: #f7f7f7;\n}\n\nheader {\n  background-color: black;\n}\n\nnav {\n  display: flex;\n  align-items: center;\n  width: 100%;\n  height: clamp(3ex 80px 10vh);\n}\n\nnav img {\n  display: inline-block;\n  width: 20vw;\n  height: auto;\n  margin-right: 1rem;\n}\n\nmenu {\n  display: flex;\n  flex-flow: row nowrap;\n  align-items: center;\n  list-style: none;\n  margin: 0;\n  padding: 0;\n}\n\nmenu li {\n  margin-right: 1.5rem;\n  text-align: center;\n  transform-origin: center center;\n  transform: scale(1.0);\n  transition: 0.7s ease;\n}\n\nmenu li a {\n  font-size: clamp(5rem 8vw 10rem);\n  color: white;\n  text-decoration: none;\n}\n\nmenu li:hover {\n  position: relative;\n  z-index: 1;\n  transform: scale(1.2);\n}\n\n.btn {\n  min-width: 3rem;\n  margin-right: 0.75rem;\n  padding: 0.25rem 0.5rem;\n  border: 2px solid rgb(226, 19, 54);\n  border-radius: 50px;\n  font-weight: bold;\n  font-variant: small-caps;\n}\n\n.join {\n  background-color: rgb(226, 19, 54);\n}\n\n.login {\n  background-color: black;\n}\n\n@media screen and (max-width: 300px) {\n  menu {\n    display: none;\n  }\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n  <title>Navigation Bar Example</title>\n  <link href=\"https://fonts.googleapis.com/css?family=Lato\" rel=\"stylesheet\">\n</head>\n\n<body>\n  <header>\n    <nav>\n      <img src=\"https://www.clipartmax.com/png/middle/31-316935_universe-rocket-icon-svg.png\n\" alt=\"Company Logo\">\n      <menu>\n        <li><a href=\"#\">Home</a></li>\n        <li><a href=\"#\">Projects</a></li>\n        <li><a href=\"#\">Services</a></li>\n        <li><a href=\"#\">About</a></li>\n        <li class=\"btn join\"><a href=\"#\">Join Now</a></li>\n        <li class=\"btn login\"><a href=\"#\">Log In</a></li>\n      </menu>\n    </nav>\n  </header>\n  <!-- Rest of the content -->\n</body>\n\n</html>\n\n\n\n"
},
{
"QuestionId": "76394497",
"QuestionTitle": "RelativeLayout problem: how to set RecyclerView not to overlap a Button on bottom",
"QuestionBody": "This is my activity: SearchView on top, RecyclerView on middle, and a Button at bottom\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    android:background=\"@drawable/app_background\"\n    tools:context=\".ui.home.customer.CustomerListActivity\">\n\n    <androidx.appcompat.widget.SearchView\n        android:background=\"@color/white\"\n        android:layout_marginLeft=\"20dp\"\n        android:layout_marginRight=\"20dp\"\n        android:layout_marginTop=\"20dp\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"wrap_content\"\n        android:id=\"@+id/searchCustomer\" />\n\n    <androidx.recyclerview.widget.RecyclerView\n        android:layout_marginLeft=\"20dp\"\n        android:clipToPadding=\"false\"\n        android:layout_marginRight=\"20dp\"\n        android:layout_marginTop=\"20dp\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"wrap_content\"\n        android:layout_below=\"@id/searchCustomer\"\n        tools:listitem=\"@layout/row_item_customer\"\n        android:id=\"@+id/rvCustomers\" />\n\n    <com.google.android.material.button.MaterialButton\n        android:id=\"@+id/btnAddCustomer\"\n        android:layout_marginLeft=\"20dp\"\n        android:layout_marginRight=\"20dp\"\n        android:layout_alignParentBottom=\"true\"\n        android:layout_marginBottom=\"20dp\"\n        android:textColor=\"@color/text_blue_1\"\n        app:backgroundTint=\"@color/white\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"53dp\"\n        android:text=\"Add Customer\" />\n\n</RelativeLayout>\n\n\nTurns out it doesn't work as I expected, because the RecyclerView overlaps/crosses the Button. I want the RecyclerView to \"stay\" on top of the Botton. How to fix this?\n",
"AnswerId": "76394646",
"AnswerBody": "Just add following line in recyclerView\nandroid:layout_above=\"@id/btnAddCustomer\"\n\n"
},
{
"QuestionId": "76395850",
"QuestionTitle": "Writing a large collection of lists to a txt file in Python",
"QuestionBody": "I am trying to save links to photos in a topic on an internet forum in a txt file. I tried many ways, but the links of one page are saved in a txt file, and when the loop goes to the next page of the topic, the previous links are deleted and new links are replaced! I want to have all the links together.\nThis is my code:\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef list_image_links(url):\n    response = requests.get(url)\n\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    \n    # Separation of download links\n    image_links = []\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href is not None and 'attach' in href and href.endswith('image')==False:\n            image_links.append(href)\n    \n    # Writing links in a txt file\n    with open('my_file.txt', 'w') as my_file:\n        my_file.write('image links:' + '\\n')    \n        for branch in image_links:\n            my_file.write(branch + '\\n')\n            print('File created')\n    \n# Browse through different pages of the topic\ni = 0\nwhile i <= 5175:\n    list_image_links(f'https://forum.ubuntu.ir/index.php?topic=211.{i}')\n    i = i+15\n\nIt is clear from the comments what each section does.\nThank you in advance for your help.\n",
"AnswerId": "76395863",
"AnswerBody": "You need to append to the file. This can be achieved by using 'a' instead of 'w' as an argument to open().\nWhen using 'w' a file will be created if it does not exist and it will always truncate the file first, meaning it will overwrite its contents. With 'a' on the other hand the file will also be created if it does not yet exists, but it won't truncate but instead append to the end of the file if it already exists, meaning the content will not be overridden.\nSee Python docs.\nSo for your example the line\nwith open('my_file.txt', 'w') as my_file:\n\nwould need to be changed to:\nwith open('my_file.txt', 'a') as my_file:\n\n"
},
{
"QuestionId": "76394508",
"QuestionTitle": "How to transition text along with a circle in CSS animation?",
"QuestionBody": "The code I am developing is for mobile site and the animation I expect is as following: Firstly a bigger circle appears such that it covers the whole screen looking like a splash screen and afterwards the bigger circle will transition into smaller circle towards bottom left. Along with that image inside the bigger circle will transit towards bottom left.\nThe Problem is circle is transitioning properly but the text is not going to bottom left properly it kind of goes to left and then goes down. Below is the code that I tried.\n\n\nsetTimeout(function() {\n  let i = document.getElementById(\"test\");\n  let d = document.getElementById(\"icon-img\");\n\n  i.classList.add(\"active\");\n  d.classList.add(\"active\");\n}, 2000);\n.test {\n  position: fixed;\n  left: 0;\n  bottom: 0;\n  width: 40px;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  height: 40px;\n  transition: all 3s ease;\n  background: gray;\n  transform: scale(100);\n  border-radius: 30px;\n  left: 20px;\n  bottom: 20px;\n}\n\n.test.active {\n  transform: scale(1);\n  transition: all 2s ease;\n  left: 20px;\n  bottom: 20px;\n}\n\n.wrapper {\n  position: relative;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  height: 100vh;\n}\n\n.myclass {\n  width: 100%;\n  height: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n.before {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  transition: all 2s ease-in-out;\n  width: 50%;\n  height: 50%;\n  position: fixed;\n  font-size: 50px;\n}\n\n.before.active {\n  left: 20px;\n  bottom: 20px;\n  width: 40px;\n  height: 40px;\n  font-size: 15px;\n  position: fixed;\n  transform: translate(0, 0);\n}\n<div class=\"wrapper\">\n  <div id=\"test\" class=\"test\"></div>\n  <div class=\"myclass\">\n    <img src=\"./logo.svg\" id=\"icon-img\" class=\"before\"></img>\n  </div>\n</div>\n\n\n\n",
"AnswerId": "76394648",
"AnswerBody": "A problem is that some properties do not have an initial value set so there is nothing for them to transition from. So you get a sort of jump effect.\nThis snippet removes the flex used for centering the image and instead uses left and bottom in conjunction with translation to center it initially.\n\n\n<!DOCTYPE html>\n<html>\n\n<head>\n  <meta charset=\"utf-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n  <title></title>\n  <style type=\"text/css\">\n    .test {\n      position: fixed;\n      left: 0;\n      bottom: 0;\n      width: 40px;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      height: 40px;\n      transition: all 3s ease;\n      background: gray;\n      transform: scale(100);\n      border-radius: 30px;\n      left: 20px;\n      bottom: 20px;\n    }\n    \n    .test.active {\n      transform: scale(1);\n      transition: all 2s ease;\n      left: 20px;\n      bottom: 20px;\n    }\n    \n    .wrapper {\n      position: relative;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      height: 100vh;\n    }\n    \n    .myclass {\n      width: 100%;\n      height: 100%;\n    }\n    \n    .before {\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      transition: all 2s ease-in-out;\n      width: 50%;\n      height: 50%;\n      position: fixed;\n      font-size: 50px;\n      left: 50%;\n      bottom: 50%;\n      transform: translate(-50%, 50%);\n      background: pink;\n    }\n    \n    .before.active {\n      left: 20px;\n      bottom: 20px;\n      width: 40px;\n      height: 40px;\n      font-size: 15px;\n      position: fixed;\n      transform: translate(0, 0);\n    }\n  </style>\n</head>\n\n<body>\n  <div class=\"wrapper\">\n    <div id=\"test\" class=\"test\"></div>\n    <div class=\"myclass\">\n      <img src=\"./logo.svg\" id=\"icon-img\" class=\"before\"></img>\n    </div>\n  </div>\n  <script>\n    setTimeout(function() {\n      let i = document.getElementById(\"test\");\n      let d = document.getElementById(\"icon-img\");\n\n      i.classList.add(\"active\");\n      d.classList.add(\"active\");\n    }, 2000);\n  </script>\n</body>\n\n</html>\n\n\n\nNote: the image is given a background of pink as no actual image was supplied, just so we can see its position and size.\nTwo transition times are used in the question - 2s and 3s. This means the image and text arrive at different times. I've kept that in the snippet but maybe the same time was intended?\n"
},
{
"QuestionId": "76383756",
"QuestionTitle": "change database based on request origin using expressjs & prisma",
"QuestionBody": "I want to change database dynamically based on request origin.\nI create a globalMiddleware which is called on every routes.\n\n\n// middlwares/global.middleware.js\n\nimport DBController from \"../controllers/db.controller.js\";\nimport { db1, db2 } from \"../prisma/prismaClient.js\";\nexport default (req, res, next) => {\n  const dbcontroller = DBController();\n  const domain = req.get(\"origin\");\n  switch (domain) {\n    case \"http://localhost:3000\":\n      dbcontroller.setDB(db1);\n      break;\n    case \"http://localhost:3001\":\n      dbcontroller.setDB(db2);\n      break;\n  }\n  next();\n};\n\n\n\nbut when i set the db inside DBController by calling dbcontroller.setDB() method and  finally calling this.DB it is undefined.\n\n\n// controller/db.controller.js\n\nimport autoBind from \"auto-bind\";\nclass DBController {\n  constructor() {\n    this.DB;\n    autoBind(this);\n  }\n  setDB(prismaClient) {\n    this.DB = prismaClient;\n  }\n}\nexport default DBController;\n\n\n\n\n\n// conrtoller/controller.js\n\nimport { generateResponse } from \"./../util/public.util.js\";\nimport DBController from \"./db.controller.js\";\nimport autoBind from \"auto-bind\";\nimport createError from \"http-errors\";\nclass Controller extends DBController {\n  constructor() {\n    super();\n    this.generateResponse = generateResponse;\n    this.createError = createError;\n    autoBind(this);\n  }\n}\nexport default Controller;\n\n\n\n\n\n// controller/article.controller.js\n\nimport Controller from \"./controller.js\";\nclass ArticleController extends Controller {\n  async get(req, res, next) {\n    try {\n      const articles = await this.DB.article.findMany(); //this.DB is undefined\n      const response = this.generateResponse(\"success\", articles);\n      res.send(response);\n    } catch (error) {\n      next(error);\n    }\n  }\n}\nexport default new ArticleController();\n\n\n\nI don't know how should i set a global DB inside a top-level controller which can be used every where.\nI also try js global.db vars and express app.set(\"db\",db1) but i think these are not a good solution for this work.\n",
"AnswerId": "76395526",
"AnswerBody": "finally I modify global.middleware.js file and modify request instead of setting database in a high-level controller :\n\n\nimport {\n  prisma_aramgostar,\n  prisma_karen\n} from \"../prisma/prismaClient.js\";\nexport default async(req, res, next) => {\n  const domain = await req.get(\"x-forwarded-host\");\n  switch (domain) {\n    case \"localhost:3000\":\n      req.DB = prisma_aramgostar;\n      console.log(\"db: aramgostar\");\n      break;\n    case \"127.0.0.1:3001\":\n      req.DB = prisma_karen;\n      console.log(\"db: karen\");\n      break;\n  }\n  next();\n};\n\n\n\n"
},
{
"QuestionId": "76388569",
"QuestionTitle": "Codeigniter 4 unique name validation",
"QuestionBody": "My problem is that I have a modal and the input contains the value from the database. When I press the update button, the unique name validation check if the name already exists in the database. However, if I don't change it, it also checks the unique name validation, which I don't want to happen.\nHere is the form.\n<form action=\"<?= base_url('users/createRole'); ?> \" method=\"post\">\n<div class=\"modal-body\">\n    <input type=\"hidden\" name=\"roleID\" id=\"roleID\">\n    <div class=\"mb-3\">\n        <label for=\"inputRoleName\" class=\"form-label\">Rolle hinzufügen</label>\n        <input type=\"text\" class=\"form-control\" id=\"inputRoleName\" name=\"inputRoleName\" placeholder=\"Role Name\">\n    </div>\n</div>\n<div class=\"modal-footer\">\n    <button type=\"submit\" class=\"btn btn-primary\">Rolle speichern</button>\n    <button type=\"button\" class=\"btn btn-light\" data-bs-dismiss=\"modal\">Schließen</button>\n</div>\n</form>\n\n        $(\".btnEditRole\").click(function() {\n            const roleID = $(this).data('id');\n            const inputRoleName = $(this).data('role');\n            $('#modalTitle').html('Update Data Role');\n            $('.modal-footer button[type=submit]').html('Update rolle');\n            $('.modal-content form').attr('action', '<?= base_url('users/updateRole') ?>');\n            $('#roleID').val(roleID);\n            $('#inputRoleName').val(inputRoleName);\n            $('.modal').on('hidden.bs.modal', function() {\n                location.reload(); // Refresh the page when modal is closed\n            });\n        });\n\nHere is the Function.\npublic function updateRole()\n{\nif (!$this->validate(['inputRoleName' => ['rules' => 'is_unique[user_role.role_name]']])) {\n    session()->setFlashdata('notif_error', '<b>Das Hinzufügen eines neuen Benutzers ist fehlgeschlagen</b> Der Benutzer existiert bereits! ');\n    return redirect()->to(base_url('users'));\n}\n$updateRole = $this->userModel->updateRole($this->request->getPost(null, FILTER_UNSAFE_RAW));\nif ($updateRole) {\n    session()->setFlashdata('notif_success', '<b>Benutzerdaten erfolgreich aktualisieren</b> ');\n    return redirect()->to(base_url('users'));\n} else {\n    session()->setFlashdata('notif_error', '<b>Benutzerdaten konnten nicht aktualisiert werden</b> ');\n    return redirect()->to(base_url('users'));\n}\n}\n\n",
"AnswerId": "76394654",
"AnswerBody": "When using unique values, you check them in this way:\n(this assumes your AutoIncrement/Primary is roleID\nFor updating values\nchange this:\n['rules' => 'is_unique[user_role.role_name]']])) {\n\nto this:\n['rules' => 'is_unique[user_role.role_name,roleID,{roleID}]])) {\n\nMore information on placeholders can be found here:\nhttps://codeigniter.com/user_guide/libraries/validation.html?highlight=is_unique#validation-placeholders\n"
},
{
"QuestionId": "76395784",
"QuestionTitle": "Reversing array in C with pointers",
"QuestionBody": "Trying to reverse the array. And then print it\nI am trying to reverse the array by indenting from last to first element of array and copy it to another array. arra will be the reversed array :\nHere's my code :\n#include <stdio.h>\n#include <stdlib.h>\n\nint main()\n{\n    int num, *arr, i;\n    scanf(\"%d\", &num);\n    arr = (int *)malloc(num * sizeof(int));\n    for (i = 0; i < num; i++) {\n        scanf(\"%d\", arr + i);\n    }\n    \n    int arra[] = {};\n    /* Write the logic to reverse the array. */\n    arra[0] = *(arr + num);\n    for (int k = 1; k == num; k++) {\n        int j = 1;\n        arra[j] = *(arr + num -k);\n        j++;\n    }\n\n    for (i = 0; i < num; i++)\n        printf(\"%d \", *(arra + i));\n    return 0;\n}\n\n",
"AnswerId": "76395864",
"AnswerBody": "For starters this declaration\nint arra[] = {};\n\nis invalid in C and C++.\nYou should define the array also allocating dynamically memory for it as for the first array or in the worst case you could define a variable length array (provided that the compiler supports VLAs) like\nint arra[num];\n\nThis for loop\nfor(int k = 1; k == num; k++){\n\nwill iterate only one time when num initially is set to 1.\nAlso within the body of the loop the variable j is created in each iteration of the loop (provided that the condition of the loop will be updated correctly) with the value 1\n    int j = 1;\n    arra[j] = *(arr + num -k);\n    j++;\n\nThus this statement\n    arra[j] = *(arr + num -k);\n\nin each iteration of the loop is equivalent to\n    arra[1] = *(arr + num -k);\n\nthat does not make sense.\nTo copy one array into another array using pointers the for loop can look for example the following way\nfor ( int *src = arr, *dsn = arra + n; src != arr + n; ++src )\n{\n    *--dsn = *src;\n}\n\n"
},
{
"QuestionId": "76391514",
"QuestionTitle": "Generate all possible combinations basing on binary string and under some conditions",
"QuestionBody": "I have to write algorithm that will generate all possible combinations of different binary strings but under some conditions. The combinations are created by:\nReplacing binary \"1\" with \"00\"\nOther conditions:\n\nInput binary string, if contains 0, they are in pairs always, so \"00\"\nThe output also can contain 0 only in pairs\n\nExample:\nInput:\n11\n\nOutput:\n001\n100\n0000\n11\n\nIn above example, there is no 010, because as mentioned earlier, the \"0\" must have a pair (another \"0\")\nNote that if given binary string contains \"00\", we don't change them to 1.\nIn other words, the algorithm should determine how many different binary strings can be created by replacing \"1\" with \"00\" (but under the conditions present above), for given binary string and returns all the possible combinations.\nI tried O(n^2) algorithm, recursion but can't achieve my goal :/\nThat's my code:\nvoid get_combinations(const std::string& bin, std::set<std::string>& result) {\n    result.insert(bin);\n    for (int i = 0; i < bin.length(); i++) {\n        std::string local_combination = bin;\n        for (int j = i; j < bin.length(); j++) {\n            if (local_combination[j] == '1') {\n                local_combination[j] = '0';\n                local_combination.insert(j, \"0\");\n\n                result.insert(local_combination);\n            }\n        }\n    }\n}\n\nIt works e.g. for simple input 10, 01. But for input 11, the output doesn't contain 0000. For \"longer\" inputs, like 1111 it gives completely bad output.\n",
"AnswerId": "76395561",
"AnswerBody": "Fundamentally your combinations are built up like a tree. The units are either\n    (0)               (1)\n    / \\       or      / \\\n   0                 1   00\n\nwhere (.) signifies what was in the original binary string and the strings at the bottom are what you would add as a result.\nSo, like any binary search tree you can either do the equivalent of BFS (breadth-first-search): deal with all the possibilities at one level before moving to the next, or DFS (depth-first-search): recursively work down each branch to the bottom to insert a new combination string.\nThe two approaches are illustrated for your problem in the code below.\n#include <iostream>\n#include <string>\n#include <set>\nusing namespace std;\n\n//======================================================================\n\nset<string> BFS( const string &str )\n{\n   set<string> result;\n   if ( str.length() == 0 ) return result;\n\n   result.insert( str.substr( 0, 1 ) );   if ( str[0] == '1' ) result.insert( \"00\" );\n   for ( int i = 1; i < str.length(); i++ )\n   {\n      auto last = result;   result.clear();\n      for ( const string &s : last )\n      {\n         result.insert( s + str[i] );\n         if ( str[i] == '1' ) result.insert( s + \"00\" );\n      }\n   }\n   return result;\n}\n\n//======================================================================\n\nvoid DFS( const string &left, const string &right, set<string> &result )\n{\n   if ( right.length() == 0 )\n   {\n      result.insert( left );\n   }\n   else\n   {\n      DFS( left + right[0], right.substr( 1 ), result );\n      if ( right[0] == '1' ) DFS( left + \"00\", right.substr( 1 ), result );\n   }\n}\n\n//======================================================================\n\nint main()\n{\n   string str;\n   cout << \"Enter a binary string: \";   cin >> str;\n\n   cout << \"BFS:\\n\";\n   for ( const string &s : BFS( str ) ) cout << s << '\\n';\n\n   cout << \"\\nDFS:\\n\";\n   set<string> result;\n   DFS( \"\", str, result );\n   for ( string s : result ) cout << s << '\\n';\n}\n\nOutput for 1111\nBFS:\n00000000\n0000001\n0000100\n000011\n0010000\n001001\n001100\n00111\n1000000\n100001\n100100\n10011\n110000\n11001\n11100\n1111\n\nDFS:\n00000000\n0000001\n0000100\n000011\n0010000\n001001\n001100\n00111\n1000000\n100001\n100100\n10011\n110000\n11001\n11100\n1111\n\n"
},
{
"QuestionId": "76394580",
"QuestionTitle": "Duplicate Buttons in xml file using android studio java",
"QuestionBody": "Duplicate buttons are in my xml file which is fragment_employee2\nI'm only creating one xml file to list out all the list in one xml\nHere is the code in my https://gist.github.com/Umen14/8d1a205f016fa970369d37f37d4bf15d\nAnd here are the images:-\nenter image description here\nI tried by removing here and there but the code seems to be the same but there is a problem in the onclick listener in my EmployeeFragment.java\nenter image description here\n",
"AnswerId": "76394668",
"AnswerBody": "This is showing duplicate because you are using same xml in recyclerView item   as well as activity layout. which R.layout.fragment_employee2 in your case. You need to define different layout in EmployeeAdapter without button. This will resolve you issue.\n"
},
{
"QuestionId": "76389676",
"QuestionTitle": "Cannot connect to WebSocket controller in .Net Core Blazor WASM application",
"QuestionBody": "I am trying to get a WebSocket connection going in my WASM application.\nI have followed the MSDN tutorial and enabled WebSockets in my Program.cs:\napp.UseWebSockets();\n\nAfter that, I added a new controller like this:\n[AllowAnonymous]\n[ApiController]\n[Route(\"[controller]\")]\ninternal class ShellyPlusDataController : ControllerBase\n{\n    [HttpGet]\n    [Route(\"[controller]/OnDataReceived\")]\n    public async Task OnDataReceived()\n    {\n        if (HttpContext.WebSockets.IsWebSocketRequest)\n        {\n            using var webSocket = await HttpContext.WebSockets.AcceptWebSocketAsync();\n\n            var buffer = new byte[1024 * 4];\n            WebSocketReceiveResult result = await webSocket.ReceiveAsync(new ArraySegment<byte>(buffer), CancellationToken.None);\n\n            while (!result.CloseStatus.HasValue)\n            {\n                string raw = Encoding.UTF8.GetString(buffer, 0, result.Count);\n                result = await webSocket.ReceiveAsync(new ArraySegment<byte>(buffer), CancellationToken.None);\n            }\n\n            await webSocket.CloseAsync(result.CloseStatus.Value, result.CloseStatusDescription, CancellationToken.None);\n        }\n        else\n        {\n            HttpContext.Response.StatusCode = StatusCodes.Status400BadRequest;\n        }\n    }\n}\n\nOpening a connection to 'wss://localhost:7220/ShellyPlusData/OnDataReceived' with PostMan doesn't work. The error displayed is: Error: Unexpected server response: 200\nI have placed a breakpoint at the start of OnDataReceived(); it is never hit.\nI have also tried changing the URL to ws:// or omitting the method name, but no success.\nThe Microsoft tutorial also suggests this in Program.cs:\napp.Use(async (context, next) =>\n{\n    if (context.Request.Path == \"/ws\")\n    {\n        if (context.WebSockets.IsWebSocketRequest)\n        {\n            using var webSocket = await context.WebSockets.AcceptWebSocketAsync();\n            await Echo(webSocket);\n        }\n        else\n        {\n            context.Response.StatusCode = StatusCodes.Status400BadRequest;\n        }\n    }\n    else\n    {\n        await next(context);\n    }\n});\n\nDoesn't work either.\nAny suggestions?\n",
"AnswerId": "76395916",
"AnswerBody": "So I had to figure it out on my own. There were 2 things that needed to be fixed:\n\nLocal WebSocket connection doesn't work. I don't know what needs to be configured to enable WebSockets in local debug mode, but when I deploy the application to a remote IIS server, I can establish a connection.\nMy controller class was internal and routing seems to work differently when working with WS connections. Here's the working class:\n\npublic class ShellyPlusDataConnectionController : ControllerBase\n{\n    [HttpGet(\"/ShellyPlusDataConnection/OnDataReceived\")]\n    public async Task OnDataReceived()\n    {\n        if (HttpContext.WebSockets.IsWebSocketRequest)\n        {\n            using var webSocket = await HttpContext.WebSockets.AcceptWebSocketAsync();\n\n            var buffer = new byte[1024 * 4];\n            WebSocketReceiveResult result = await webSocket.ReceiveAsync(new ArraySegment<byte>(buffer), CancellationToken.None);\n\n            while (!result.CloseStatus.HasValue)\n            {\n                string raw = Encoding.UTF8.GetString(buffer, 0, result.Count);\n\n\n                result = await webSocket.ReceiveAsync(new ArraySegment<byte>(buffer), CancellationToken.None);\n            }\n\n            await webSocket.CloseAsync(result.CloseStatus.Value, result.CloseStatusDescription, CancellationToken.None);\n        }\n        else\n        {\n            HttpContext.Response.StatusCode = StatusCodes.Status400BadRequest;\n        }\n    }\n}\n\n"
},
{
"QuestionId": "76395827",
"QuestionTitle": "PySimpleGUI button event not working in Python code - why?",
"QuestionBody": "Why the button event is not avalible with pysimplegui?\nThis is my Code.\nimport os\nimport threading\nimport PySimpleGUI as gui\nfrom rsa_controller import decryptwithPrivatekey, loadPublicKey, loadPrivateKey\n\nid = 0\ntarget_id = 0\nprikey = None\n\n\ndef popout(title):\n    gui.popup(title)\n\n\ndef read_keys():\n    print(\"Opening key files: \" + os.getcwd() + \"\\\\keys\\\\\")\n    pubkey = loadPublicKey(os.getcwd() + \"\\\\keys\\\\public.pem\")\n    prikey = loadPrivateKey(os.getcwd() + \"\\\\keys\\\\private.pem\")\n\n\ndef recv_msg():\n    global target_id\n    from main import s\n    while True:\n        data = s.recv(1024)\n        if not data:\n            break\n        decoded_data = data.decode('utf-8')\n        if decoded_data == 'target_connected_Success':\n            print(\"Received message:\", decoded_data)\n        elif decoded_data.startswith(\"!+@\"):\n            target_id = decoded_data[3:]\n            window2()\n        elif decoded_data == 'target_connect_denied':\n            gui.popup('Connection request denied')\n        else:\n            msg_to_recv = decryptwithPrivatekey(decoded_data, prikey)\n            print(\"Received message:\", msg_to_recv)\n\n\ndef window2():\n    from main import s\n    global target_id\n    layout2 = [\n        [gui.Text('Connecting with'), gui.Text(str(target_id), key='target_id'), gui.Text(\"Establishing contact\")],\n        [gui.Button('Accept and share my public key', key='accept', enable_events=True),\n         gui.Button('Deny connection invitation', key='denied', enable_events=True)]\n    ]\n    window = gui.Window(\"Connection Request\", layout2, finalize=True)\n    while True:\n        event2, values2 = window.read()\n        if event2 == gui.WINDOW_CLOSED:\n            break\n        if event2 == 'Deny connection invitation':\n            print(\"Connection denied\")\n            s.send('!x!{}'.format(target_id).encode('utf-8'))\n            window.close()\n        if event2 == 'Accept and share my public key':\n            print(\"Accepting and sharing public key\")\n            # Handle the logic for accepting the connection\n    window.close()\n\n\ndef start_GUI_progress(id):\n    from main import s\n    read_keys()\n    layout = [\n        [gui.Text('Your identification code'), gui.Text(id)],\n        [gui.Text('Hint: Please enter the identification code of the person you want to connect to in the input box below and click the Connect button')],\n        [gui.Input(key='target_id'), gui.Button('Connect', key='connect')]\n    ]\n    window = gui.Window(\"RSA Encrypted Chat Software\", layout)\n    host = \"localhost\"\n    port = 23333\n    s.connect((host, port))\n    print(s.recv(1024))\n    t_recv = threading.Thread(target=recv_msg)\n    t_recv.start()\n    s.send(b\"__!\" + str(id).encode('utf-8'))\n    while True:\n        event, values = window.read()\n        if event is None:\n            break\n        if event == 'connect':\n            print(\"Client is attempting to connect to: {}\".format(values['target_id']))\n            message = \"_!?{}\".format(values['target_id'])\n            s.send(message.encode('utf-8'))\n    window.close()\n\n\n\nI found that the first window is intractivable,but after the window2 successfully displayed,i press buttons on it and nothing happend,what's more,when the window2 displaying, there is an error:\n\nException in thread Thread-1 (recv_msg):\nTraceback (most recent call last):\nFile \"C:\\Users\\bao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1009, in _bootstrap_inner\nself.run()\nFile \"C:\\Users\\bao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 946, in run\nself._target(*self._args, **self._kwargs)\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\GUIDisplay.py\", line 32, in recv_msg\nwindow2()\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\GUIDisplay.py\", line 46, in window2\nwindow = gui.Window(\"Connecting with\", layout2, finalize=True)\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\venv\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 9614, in init\nself.Finalize()\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\venv\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 10300, in finalize\nself.Read(timeout=1)\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\venv\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 10075, in read\nresults = self._read(timeout=timeout, timeout_key=timeout_key)\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\venv\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 10146, in _read\nself._Show()\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\venv\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 9886, in Show\nStartupTK(self)\nFile \"C:\\Users\\bao\\PycharmProjects\\RSAEncryptedChatSoftware\\venv\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 16935, in StartupTK\nwindow.TKroot.mainloop()\nFile \"C:\\Users\\bao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter_init.py\", line 1458, in mainloop\nself.tk.mainloop(n)\nRuntimeError: Calling Tcl from different apartment\n\nProcess finished with exit code 0\n",
"AnswerId": "76395933",
"AnswerBody": "    layout2 = [\n        [gui.Text('Connecting with'), gui.Text(str(target_id), key='target_id'), gui.Text(\"Establishing contact\")],\n        [gui.Button('Accept and share my public key', key='accept', enable_events=True),\n         gui.Button('Deny connection invitation', key='denied', enable_events=True)]\n    ]\n\n        if event2 == 'Deny connection invitation':\n            print(\"Connection denied\")\n            s.send('!x!{}'.format(target_id).encode('utf-8'))\n            window.close()\n        if event2 == 'Accept and share my public key':\n            print(\"Accepting and sharing public key\")\n            # Handle the logic for accepting the connection\n\nThe keys defined for buttons are different from the events used in the event loop.\n\nkeys defined for buttons:'accept' and 'denied'.\nThe events: 'Accept and share my public key' and 'Deny connection invitation'.\n\n\nt_recv = threading.Thread(target=recv_msg)\n\ndef recv_msg():\n    # ... wrong, try to call `window.write_event_value` to generate an event to call `window2` in main thread.\n            window2()\n    # ... wrong, try to call `window.write_event_value` to generate an event to call `gui.popup` in main thread.\n            gui.popup('Connection request denied')\n    # ...\n\nGUI should be run under main thread !\n"
},
{
"QuestionId": "76391959",
"QuestionTitle": "Flutter: How to update locale in GetxController",
"QuestionBody": "my splash code this\nclass App extends StatelessWidget {\n  const App();\n\n  @override\n  Widget build(BuildContext context) {\n    Get.put(SplashController());\n    Get.put(ThemeController());\n    Get.put(HomeController());\n    Get.put(LocaleController());\n    var localeController = Get.find<LocaleController>();\n    print('amirrrrrrrrrrr${localeController.locale}');\n    return GetMaterialApp(\n      debugShowCheckedModeBanner: false,\n      translations: LocaleString(),\n      locale: localeController.locale,\n      initialBinding: MyBindings(),\n      home: Splash(),\n    );\n  }\n}\n\nafter update locale in controller\nclass LocaleController extends GetxController {\n  Locale locale = const Locale('fa', 'FA');\n\n  Future<void> saveLocale(Locale newLocale) async {\n    SharedPreferences prefs = await SharedPreferences.getInstance();\n    await prefs.setString('languageCode', newLocale.languageCode);\n    await prefs.setString('countryCode', newLocale.countryCode.toString());\n    locale = newLocale;\n    update();\n    print('amirrrrrrr$locale');\n  }\n\n  Future<Locale> loadLocale() async {\n    SharedPreferences prefs = await SharedPreferences.getInstance();\n    String? languageCode = prefs.getString('languageCode');\n    String? countryCode = prefs.getString('countryCode');\n    Locale? locale;\n    if (languageCode != null && countryCode != null) {\n      locale = Locale(languageCode, countryCode);\n      this.locale = locale;\n    }\n    update();\n    print('amirrrrrrr$locale');\n    return locale!;\n  }\n}\n\nthis code not updated\nvar localeController = Get.find<LocaleController>();\nprint('amirrrrrrrrrrr${localeController.locale}');\n\nhow to fix ?\nIt is updated in the LocaleController controller, but in the app class, it always returns fa_FA and does not show the updated locale.\n",
"AnswerId": "76395790",
"AnswerBody": "As documentation mentioned you need to call;\ngetx\nGet.changeLocale(Locale(\"pt\"));\n\nYou need to call this method with expected Locale.\nAdditionally, current locale can be checked with;\n  Get.locale;\n\n"
},
{
"QuestionId": "76395847",
"QuestionTitle": "What is the algorithm applied to create a circular array in javascript?",
"QuestionBody": "I have a code like below.\nvar t = [1, 2];\nt[2] = t;\n\n\nThis creates a circular array. What is the algorithm applied to create this circular array in javascript.\n",
"AnswerId": "76395972",
"AnswerBody": "There's no algorithm involved. It's just that your array refers to itself. When a variable or property refers to an object (arrays are objects), what's held in the variable is an object reference, which is a value that tells the JavaScript engine where that object is elsewhere in memory. You can think of it as a number that uniquely identifies a memory location where the object is. (That isn't what it is, but it's a handy way to think of it.)\nLet's look at the code. You start with:\nvar t = [1, 2];\n\nThat creates an array and stores an object reference for it in t. That creates something somewhat like this in memory (various details omitted for clarity):\n\n                  +−−−−−−−−−−−−−−−+\nt:{Ref18465}−−−−−>|    (array)    |\n                  +−−−−−−−−−−−−−−−+\n                  | length: 2     |\n                  | 0: 1          |\n                  | 1: 2          |\n                  +−−−−−−−−−−−−−−−+\n\nThe Ref18465 I've shown is a stand-in for the object reference, which we never directly see in code. We have an array, and a variable containing an object reference saying where the array is.\nThen your code does this:\nt[2] = t;\n\nThat adds a new element to the array containing the object reference of the array, making it refer to itself:\n\n              +−−−−−−−−−−−−−−−−−−−−−−+\n              |                      |\n              \\   +−−−−−−−−−−−−−−−+  |\nt:{Ref18465}−−−+−>|    (array)    |  |\n                  +−−−−−−−−−−−−−−−+  |\n                  | length: 3     |  |\n                  | 0: 1          |  |\n                  | 1: 2          |  |\n                  | 2: {Ref18465} |>−/\n                  +−−−−−−−−−−−−−−−+\n\nNow, both t and t[2] contain the object reference to the array. As you say, the array refers to itself. There's no particular algorithm involved, it's just a circular data structure.\n"
},
{
"QuestionId": "76394621",
"QuestionTitle": "curl_formfree not working properly return error: SegFault",
"QuestionBody": "I am writing code to upload file on file server along with two other string variables as part of HTTP post request.\nIdea to use multi interface here is to upload multiple file in future.\nLibcurl version being used here is: 7.44\nHere is my program:\n#include <iostream>\n#include <string>\n#include <curl/curl.h>\n\nconst auto TimeoutInMS = 1000;\nconst auto FileDescriptorZero = 0;\n\nbool HTTPPostSuccessful(long httpResponseCode)\n{\n    bool httpRequestSuccessful = false;\n    if (httpResponseCode == 200)\n    {\n        httpRequestSuccessful = true;\n    }\n    return httpRequestSuccessful;\n}\n\nsize_t WriteCallback(void * buffer, size_t size, size_t count, void * userp)\n{\n    size_t numBytes = size * count;\n    static_cast<std::string*>(userp)->append(static_cast<char*>(buffer), numBytes);\n    return numBytes;\n}\n\nvoid HTTPPost(const std::string& value1, const std::string& value2, const std::string& filePath)\n{\n    struct curl_slist *pHTTPRequestHeaders = nullptr;\n    struct curl_httppost* pFormpost = nullptr;\n    struct curl_httppost* pLastptr = nullptr;\n    uint16_t httpResponseCode = 0;\n    int stillSendingFile = 0;\n    CURL* pCurlEasyHandle = curl_easy_init();\n    CURLM *pCurlMultiHandle = curl_multi_init();\n    std::string responseData{};\n\n    \n    if (pCurlEasyHandle && pCurlMultiHandle)\n    {\n        pHTTPRequestHeaders = curl_slist_append(pHTTPRequestHeaders, \"Content-Type: multipart/form-data\");\n        curl_easy_setopt(pCurlEasyHandle, CURLOPT_HTTPHEADER, pHTTPRequestHeaders);\n        curl_easy_setopt(pCurlEasyHandle, CURLOPT_URL, \"https://http_.org/logs/readers\");\n        curl_easy_setopt(pCurlEasyHandle, CURLOPT_VERBOSE, 1L);\n        \n        curl_formadd(&pFormpost, &pLastptr,\n                     CURLFORM_COPYNAME, \"fileName\",\n                     CURLFORM_FILE, filePath.c_str(),\n                     CURLFORM_CONTENTTYPE, \"text/csv\",\n                     CURLFORM_END);\n        \n        curl_formadd(&pFormpost, &pLastptr,\n                     CURLFORM_COPYNAME, \"Value1\",\n                     CURLFORM_COPYCONTENTS, value1.c_str(),\n                     CURLFORM_END);\n        \n        curl_formadd(&pFormpost, &pLastptr,\n                     CURLFORM_COPYNAME, \"Value2\",\n                     CURLFORM_COPYCONTENTS, value2.c_str(),\n                     CURLFORM_END);\n        \n        curl_easy_setopt(pCurlEasyHandle, CURLOPT_HTTPPOST, pFormpost);\n        curl_easy_setopt(pCurlEasyHandle, CURLOPT_WRITEFUNCTION, WriteCallback);\n        curl_easy_setopt(pCurlEasyHandle, CURLOPT_WRITEDATA, &responseData);\n        \n        curl_multi_add_handle(pCurlMultiHandle, pCurlEasyHandle);\n        \n        do\n        {\n            curl_multi_perform(pCurlMultiHandle, &stillSendingFile);\n            if (stillSendingFile)\n            {\n                curl_multi_wait(pCurlMultiHandle, nullptr, FileDescriptorZero, TimeoutInMS, nullptr);\n            }\n        }\n        while(stillSendingFile);\n        \n        CURLcode res = curl_easy_getinfo(pCurlEasyHandle, CURLINFO_RESPONSE_CODE, &httpResponseCode);\n        \n        if (HTTPPostSuccessful(httpResponseCode) && res == CURLE_OK)\n        {\n            \n            std::cout << \"File sent Successfully, HTTP response code: \" << httpResponseCode << \", ResponseData: \"<< responseData<< std::endl;\n        }\n        else\n        {\n            std::cerr << \"Error during request: \" << curl_easy_strerror(res) << \", Failure HTTP response code: \" << httpResponseCode << std::endl;\n        }\n        \n        if (pCurlMultiHandle && pCurlEasyHandle)\n        {\n            std::cout << \"Clean up for curl_multi_remove_handle \" << std::endl;\n            curl_multi_remove_handle(pCurlMultiHandle, pCurlEasyHandle);\n        }\n        \n        if (pCurlEasyHandle)\n        {\n            std::cout << \"Clean up for pCurlEasyHandle \" << std::endl;\n            curl_easy_cleanup(pCurlEasyHandle);\n            pCurlEasyHandle = nullptr;\n        }\n        \n        if (pCurlMultiHandle)\n        {\n            std::cout << \"Clean up for pCurlMultiHandle \" << std::endl;\n            curl_multi_cleanup(pCurlMultiHandle);\n            pCurlMultiHandle = nullptr;\n        }\n        \n        if (pHTTPRequestHeaders)\n        {\n            std::cout << \"Clean up pHTTPRequestHeaders \" << std::endl;\n            curl_slist_free_all(pHTTPRequestHeaders);\n            pHTTPRequestHeaders = nullptr;\n        }\n        \n        if (pFormpost)\n        {\n            std::cout << \"Clean up pFormpost \" << std::endl;\n            curl_formfree(pFormpost);\n            pFormpost = nullptr;\n            pLastptr = nullptr;\n        }\n    }\n\n\n}\n\n\nbool UploadFile(const std::string& value1, const std::string& value2, const std::string& filePath)\n{\n    curl_global_init(CURL_GLOBAL_ALL);\n    HTTPPost(value1, value2, filePath);\n    curl_global_cleanup();\n\n    return true;\n}\n\nint main ()\n{\n    UploadFile(\"1\", \"1\", \"/tmp/UploadFIle/testDoc.txt\");\n}\n\nabove code works fine in my machine, when I commit it on Jenkins build server, I get following error:\n7: HTTPClient Initialization is successful.\n7: * Could not resolve host: http_.org\n7: * Closing connection 0\n7: Error during request: No error, Failure HTTP response code: 0\n7: Clean up for curl_multi_remove_handle \n7: Clean up for pCurlEasyHandle \n7: Clean up for pCurlMultiHandle \n7: Clean up pHTTPRequestHeaders \n7: Clean up pFormpost \n 7/30 Test  #7: **** ....................................***Exception: SegFault  0.29 sec\n\nIn Few cases also seeing following error:\n8: HTTPClient Initialization is successful.\n8: * Could not resolve host: http_.org\n8: * Closing connection 0\n8: Error during request: No error, Failure HTTP response code: 0\n8: Clean up for curl_multi_remove_handle \n8: Clean up for pCurlEasyHandle \n8: Clean up for pCurlMultiHandle \n8: Clean up pHTTPRequestHeaders \n8: Clean up pFormpost \n8: ==11267== Invalid read of size 8\n8: ==11267==    at 0x4E48018: curl_formfree (in /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0)\n\nCan somebody please inform me what is wrong here, new to Curl.\n",
"AnswerId": "76394679",
"AnswerBody": "The first issue resulting in UB is in WriteCallback:\nstatic_cast<std::string*>(userp)->append(static_cast<char*>(buffer), 0, numBytes);\n\nYou have chosen the overloaded member function\nbasic_string& append( const basic_string& str,\n                      size_type pos, size_type count )\n\nthat creates std::string from a not null-terminated data in the buffer.\nYou should use the other overloaded member function\nbasic_string& append( const CharT* s, size_type count )\n\ntherefore the correct call is\nstatic_cast<std::string*>(userp)->append(static_cast<char*>(buffer), numBytes);\n\nThe second issue is uint16_t httpResponseCode, whereas CURLINFO_RESPONSE_CODE requires a pointer to a long value, you pass &httpResponseCode, a pointer to a short value, this is yet another UB. Particularly it corrupts data in the local variables, writes zeros in 2 or 6 bytes outside the httpResponseCode storage, probably in pFormpost bytes. It should be\nlong httpResponseCode = 0;\n\n"
},
{
"QuestionId": "76391583",
"QuestionTitle": "Spring Rest Controller not able to validate path variable when request body is also passed in addition to path variable",
"QuestionBody": "I've a rest controller and one of the endpoint looks like this:\n@PostMapping(value = \"/myapi/{id}\", produces = APPLICATION_JSON_VALUE, consumes = APPLICATION_JSON_VALUE)\npublic ResponseEntity<MyEntity> myApi(\n          @Valid @PathVariable(\"id\") @NotBlank String id,\n          @Valid @RequestBody MyRequestPayload myRequestPayload) throws Exception)\n{\n  LOGGER.info(\"Id is {}\",id);\n  ...............\n  .........................\n  .............................\n}\n\nFor some reason, when I call the API with an empty or null path variable and a request payload, the path variable is not failing the validation and the control comes inside the method block.\nWhat am I doing wrong? Kindly advise.\n",
"AnswerId": "76395798",
"AnswerBody": "@Valid validates complex objects, containing fields annotated with constraint annotations.\nFor this case, you need to use @Validated:\n\nThe @Validated annotation is a class-level annotation that we can use to tell Spring to validate parameters that are passed into a method of the annotated class.\n\nSo mark your controller class as @Validated, which would trigger the validation of the id path variable.\n@RestController\n@RequestMapping(\"/my\")\n@Validated\npublic class MyController {\n\n  @PostMapping(value = \"/myapi/{id}\", produces = APPLICATION_JSON_VALUE, consumes = APPLICATION_JSON_VALUE)\n  public ResponseEntity<MyEntity> myApi(\n      @PathVariable(\"id\") @NotBlank String id,\n      @Valid @RequestBody MyRequestPayload myRequestPayload) throws\n      Exception {\n    LOGGER.info(\"Id is {}\", id);\n  }\n}\n\nReference: Validation with Spring Boot\n"
},
{
"QuestionId": "76394660",
"QuestionTitle": "Fixing a function checking whether the input binary tree is ordered",
"QuestionBody": "I have the following algebraic data type:\ndata Tree a = Empty | Node a (Tree a) (Tree a)\n  deriving (Show, Eq)\n\nAlso, I have this code snippet:\nfromJust :: Maybe a -> a\nfromJust (Just val) = val\nfromJust Nothing = error \"Cannot unpack Nothing.\"\n\ngetTreeMinimum :: Ord a => Tree a -> Maybe a\ngetTreeMaximum :: Ord a => Tree a -> Maybe a\n\ngetTreeMaximum Empty = Nothing\ngetTreeMaximum (Node value l r) =\n  if l == Empty && r == Empty then Just value else\n  if l == Empty && r /= Empty then if value < fromJust (getTreeMinimum r) then (getTreeMaximum r) else\n  if l /= Empty && r == Empty then if fromJust (getTreeMaximum l) < value then Just (value) else\n  if l /= Empty && r /= Empty then if fromJust (getTreeMaximum l) < value && value < fromJust (getTreeMinimum r) then (getTreeMaximum r) else Nothing\n\ngetTreeMinimum Empty = Nothing\ngetTreeMinimum (Node value l r) = \n  if l == Empty && r == Empty then Just value else\n  if l == Empty && r /= Empty then if value < fromJust (getTreeMinimum r) then Just (value) else\n  if l /= Empty && r == Empty then if fromJust (getTreeMaximum l) < value then (getTreeMinimum l)\n  if l /= Empty && r /= Empty then if fromJust (getTreeMaximum l) < value && value < fromJust (getTreeMinimum r) then (getTreeMinimum l) else Nothing\n\nisOrderedHelper :: Ord a => Tree a -> Bool\nisOrderedHelper Empty = True\n\nisOrderedHelper (Node nodeValue leftChild Empty) = if isOrderedHelper leftChild == False then False else (fromJust (getTreeMaximum leftChild)) < nodeValue\n\nisOrderedHelper (Node nodeValue Empty rightChild) = if isOrderedHelper rightChild == False then False else nodeValue < fromJust ((getTreeMinimum rightChild))\n\nisOrderedHelper (Node nodeValue leftChild rightChild) =\n  if isOrderedHelper leftChild == False || isOrderedHelper rightChild == False\n  then False \n  else fromJust (getTreeMaximum leftChild) < nodeValue && nodeValue < fromJust (getTreeMinimum rightChild)\n\nisOrdered :: Ord a => Tree a -> Bool\nisOrdered Empty = True\nisOrdered tree = isOrderedHelper tree\n\nThe above gives me:\nerror: parse error on input 'getTreeMinimum'\n    getTreeMinimum Empty = Nothing\n    ^^^^^^^^^^^^^^\nFailed, no modules loaded.\n\nI have two questions (the second one is optional):\n\nHow to fix the compile time error?\nIs it possible to improve the efficiency of the function in question?\n\n",
"AnswerId": "76394688",
"AnswerBody": "Since if is an expression in Haskell each if has to have exatly one then and one else but this\ngetTreeMaximum (Node value l r) =\n  if l == Empty && r == Empty then Just value else\n  if l == Empty && r /= Empty then if value < fromJust (getTreeMinimum r) then (getTreeMaximum r) else\n  if l /= Empty && r == Empty then if fromJust (getTreeMaximum l) < value then Just (value) else\n  if l /= Empty && r /= Empty then if fromJust (getTreeMaximum l) < value && value < fromJust (getTreeMinimum r) then (getTreeMaximum r) else Nothing\n\nhas 7 if and 7 then\nbut only 4 else\nI would probably write that using pattern matching to avoid such a deeply nested if tree:\ngetTreeMaximum (Node value Empty Empty) = Just value\ngetTreeMaximum (Node value Empty r) = if value < fromJust (getTreeMinimum r) then (getTreeMaximum r) else Nothing\ngetTreeMaximum (Node value l Empty) = if fromJust (getTreeMaximum l) < value then Just (value) else Nothing\ngetTreeMaximum (Node value l r) = if fromJust (getTreeMaximum l) < value && value < fromJust (getTreeMinimum r) then (getTreeMaximum r) else Nothing\n\nBut I don't think the clauses other than the getTreeMaximum Empty have any reason to return Nothing at all since there's always a value, so you'll have to adjust these.\n"
},
{
"QuestionId": "76395953",
"QuestionTitle": "Regex to catch email addresses in email header",
"QuestionBody": "I'm trying to parse a To email header with a regex. If there are no <> characters then I want the whole string otherwise I want what is inside the <> pair.\nimport re\nre_destinatario = re.compile(r'^.*?<?(?P<to>.*)>?')\naddresses = [\n    'XKYDF/ABC (Caixa Corporativa)',\n    'Fulano de Tal | Atlantica Beans <fulano.tal@atlanticabeans.com>'\n]\nfor address in addresses:\n    m = re_destinatario.search(address)\n    print(m.groups())\n    print(m.group('to'))\n\nBut the regex is wrong:\n('XKYDF/ABC (Caixa Corporativa)',)\nXKYDF/ABC (Caixa Corporativa)\n('Fulano de Tal | Atlantica Beans <fulano.tal@atlanticabeans.com>',)\nFulano de Tal | Atlantica Beans <fulano.tal@atlanticabeans.com>\n\nWhat am I missing?\n",
"AnswerId": "76395988",
"AnswerBody": "You may use this regex:\n<?(?P<to>[^<>]+)>?$\n\nRegEx Demo\nRegEx Demo:\n\n<?: Match an optional <\n(?P<to>[^<>]+): Named capture group to to match 1+ of any characters that are not < and >\n>?: Match an optional >\n$: End\n\nCode Demo\nCode:\nimport re\nre_destinatario = re.compile(r'<?(?P<to>[^<>]+)>?$')\naddresses = [\n    'XKYDF/ABC (Caixa Corporativa)',\n    'Fulano de Tal | Atlantica Beans <fulano.tal@atlanticabeans.com>'\n]\nfor address in addresses:\n    m = re_destinatario.search(address)\n    print(m.group('to'))\n\nOutput:\nXKYDF/ABC (Caixa Corporativa)\nfulano.tal@atlanticabeans.com\n\n"
},
{
"QuestionId": "76396013",
"QuestionTitle": "MySql count with GROUP BY returns 1 even when count is 0",
"QuestionBody": "I have two tables in MySql i.e., subjects and photos and I wished to count the number of photos on each subjects\nSELECT a.id, a.name, count(a.id) as `refcount`, \nFROM `subjects` a \nLEFT JOIN `photos` b ON (a.id = b.subject_id)\nGROUP by a.id\nORDER BY a.name\";\n\nreturns 1 even when the rowcount()=0.  How to fix it\nI tried various MySql syntax including count(field), but in vain\n",
"AnswerId": "76396051",
"AnswerBody": "You will need to count photos.id (b.id), if no photos are found for the given subject, the query will return null, count(null) = 0.\nSELECT a.id, a.name, count(b.id) as `refcount`\nFROM `subjects` a \nLEFT JOIN `photos` b ON a.id = b.subject_id\nGROUP by a.id, a.name\nORDER BY a.name;\n\n"
},
{
"QuestionId": "76383009",
"QuestionTitle": "Building a Type from an object with properties of type Boolean?",
"QuestionBody": "I would like to construct a type from this object:\nconst isSynchronized: Record<SynchronizableField, boolean> = {\n    /* synchronized */\n    surveyMacroEnvironments: true,\n    coordinateReferenceSystemCrs: true,\n    transactionType: true,\n    epsgTransformation: true,\n    startingAgreementDate: true,\n    expirationAgreementDate: true,\n    transactionTypeNotes: true,\n    surveyDataType: true,\n    /* not synchronized */\n    surveyName: false,\n    validationStateCd: false,\n    legacy: false,\n    notifyOnCreate: false,\n    notifyOnValidate: false,\n    finalReportLink: false,\n    // timestamp fields\n    creationDate: false,\n    lastUpdate: false,\n    // continent and country are handled differently\n    continent: false,\n    country: false,\n};\n\nwhere the type needs to have only the keys with values equal to true, could you please help me or give me any suggestions?\nThanks\n",
"AnswerId": "76396573",
"AnswerBody": "As a first step we have to remove that type annotation on isSynchronized; we need the compiler to infer its type and then use that inferred type to compute the key set you're looking for.  You could use the satisfies operator instead to make sure the property types are checked against and constrained to boolean:\nconst isSynchronized = {\n    surveyMacroEnvironments: true,\n    coordinateReferenceSystemCrs: true,\n    transactionType: true,\n    epsgTransformation: true,\n    startingAgreementDate: true,\n    // ✂ ⋯ ✂\n    lastUpdate: false,\n    continent: false,\n    country: false,\n} satisfies Record<string, boolean>;\n\ntype IsSynchronized = typeof isSynchronized;\n\nNow you can inspect IsSynchronized to get the desired type.\n\nYou're looking for an application of a type function I call KeysMatching<T, V>, as requested in microsoft/TypeScript#48992 and as discussed in\nIn TypeScript, how to get the keys of an object type whose values are of a given type?.  The idea is that KeysMatching<T, V> would evaluate to the union of property keys of T where the property values at those keys are assignable to V.  Specifically it looks like you want KeysMatching<IsSynchronized, true>.\nThere's no native KeysMatching provided by the language, but there are a number of ways to implement it yourself, with various issues and edge cases.  One approach is a distributive object type where we map over all the properties of T and then index into the result with all the keys to end up with the union of the computed property types.  Like this:\ntype KeysMatching<T, V> =\n    { [K in keyof T]: T[K] extends V ? K : never }[keyof T]\n\nAnd let's use it:\ntype SynchronizedKeys = KeysMatching<IsSynchronized, true>;\n// type SynchronizedKeys = \"surveyMacroEnvironments\" | \"coordinateReferenceSystemCrs\" |\n//   \"transactionType\" | \"epsgTransformation\" | \"startingAgreementDate\" | \n//   \"expirationAgreementDate\" | \"transactionTypeNotes\" | \"surveyDataType\"\n\nLooks good. If you don't want to keep KeysMatching around, you can inline the definition to compute SynchronizedKeys directly:\ntype SynchronizedKeys = {\n    [K in keyof IsSynchronized]: IsSynchronized[K] extends true ? K : never\n}[keyof IsSynchronized];\n\nPlayground link to code\n"
},
{
"QuestionId": "76394387",
"QuestionTitle": "Need help in string replacement in PHP",
"QuestionBody": "I have a string like this:\n$str = '[{\"action\": \"verify_with_source\",\"created_at\": \"2023-05-30T01:39:54+05:30\",\"status\": \"in_progress\",\"type\": \"license\"}] {\"address\":null,\"badge_details\":null,\"card_serial_no\":null,\"city\":null,\"cov_details\":[{\"category\":\"NT\",\"cov\":\"MCWG\",\"issue_date\":\"2021-03-30\"},{\"category\":\"NT\",\"cov\":\"LMV\",\"issue_date\":\"2021-03-30\"}],\"date_of_issue\":\"2021-03-30\",\"date_of_last_transaction\":\"2021-03-30\",\"dl_status\":\"Active\",\"dob\":\"1996-10-09\",\"face_image\":null,\"gender\":null,\"hazardous_valid_till\":null,\"hill_valid_till\":null,\"id_number\":\"DL1234567890\",\"issuing_rto_name\":\"MY CITY\",\"last_transacted_at\":\"MY CITY\",\"name\":\"MY NAME\",\"nt_validity_from\":\"2021-03-30\",\"nt_validity_to\":\"2036-10-08\",\"relatives_name\":null,\"source\":\"SOURCE\",\"status\":\"id_found\",\"t_validity_from\":null,\"t_validity_to\":null}'\n\nWhat I want to split the string in 2 parts - [{\"action\": \"verify_with_source\",...\"type\": \"license\"}] and {\"category\":\"NT\",\"cov\":\"LMV\",\"issue_date\":\"2021-03-30\"}],...,\"t_validity_to\":null\"}.\nI removed [ and ] with -\n$raw = str_replace(['[', ']'], '', $raw);\n\nThen, I have tried-\n$str = preg_replace('^/} {/', '}{', $raw);\n\nand\n$str = preg_replace('^/}\\s{/', '}{', $raw);\n\nand\n$str = str_replace('} {', '{}', $raw);\n\nThen I intend to split string $str into array of 2 strings with statement -\n$arr = explode('}{', $str);\n\nThe string is not being splitted and above statement returns whole string in first element of array.\nWhat is wrong with my script?\n",
"AnswerId": "76394754",
"AnswerBody": "I would suggest to make it a bit easier instead of replacing all the braces.\nexplode can handle that for you and split the string at a place you want. So just split it at the position ] { where the license ends and the objects starts and add the missing braces afterwards to that strings.\n<?php\n\n$str = \"<your long string>\"\n\n$jsonStrings = explode('] {', $str, 1);\n\n$jsonStrings[0] .= ']';\n$jsonStrings[1] = '{' . $jsonStrings[1];\n\n\nbe aware of there is no error handling. if there is no ] { chars in your string, explode will not create an array with two strings and the rest of the code is failing.\n"
},
{
"QuestionId": "76395778",
"QuestionTitle": "MongoDB insertMany skip the same _id field to avoid 'code: 11000,'",
"QuestionBody": "await testCollection.insertMany(testArray, { ordered: false });\n\nI have this code. I found that putting { ordered: false } will prevent getting E11000 error code. But, it looks like, it does not. Is there any way that I can avoid this error? I want to skip and do not insert a doc that has the same _id code.\n",
"AnswerId": "76396057",
"AnswerBody": "You can't avoid error, but you can proceed with inserting. See here. For example:\n    MongoDB Enterprise replset:PRIMARY> db.products.insert(\n    ...    [\n    ...      { _id: 20, item: \"lamp\", qty: 50, type: \"desk\" },\n    ...      { _id: 21, item: \"lamp\", qty: 20, type: \"floor\" },\n    ...      { _id: 21, item: \"lamp\", qty: 20, type: \"floor\" },\n    ...      { _id: 22, item: \"bulk\", qty: 100 }\n    ...    ],\n    ...    { ordered: false }\n    ... )\n    BulkWriteResult({\n            \"writeErrors\" : [\n                    {\n                            \"index\" : 2,\n                            \"code\" : 11000,\n                            \"errmsg\" : \"E11000 duplicate key error collection: newdb1.products index: _id_ dup key: { _id: 21.0 }\",\n                            \"op\" : {\n                                    \"_id\" : 21,\n                                    \"item\" : \"lamp\",\n                                    \"qty\" : 20,\n                                    \"type\" : \"floor\"\n                            }\n                    }\n            ],\n            \"writeConcernErrors\" : [ ],\n            \"nInserted\" : 3,\n            \"nUpserted\" : 0,\n            \"nMatched\" : 0,\n            \"nModified\" : 0,\n            \"nRemoved\" : 0,\n            \"upserted\" : [ ]\n    })\n    MongoDB Enterprise replset:PRIMARY> db.products.find()\n    { \"_id\" : 20, \"item\" : \"lamp\", \"qty\" : 50, \"type\" : \"desk\" }\n    { \"_id\" : 21, \"item\" : \"lamp\", \"qty\" : 20, \"type\" : \"floor\" }\n    { \"_id\" : 22, \"item\" : \"bulk\", \"qty\" : 100 }\n\nyou may see, that if you remove { ordered: false }, the only inserted records will be records before first error accured:\nMongoDB Enterprise replset:PRIMARY> db.products.find()\n{ \"_id\" : 20, \"item\" : \"lamp\", \"qty\" : 50, \"type\" : \"desk\" }\n{ \"_id\" : 21, \"item\" : \"lamp\", \"qty\" : 20, \"type\" : \"floor\" }\n\n"
},
{
"QuestionId": "76391858",
"QuestionTitle": "how to generate relationship between two enumerate with double cycle",
"QuestionBody": "Thanks a lot in advance .  trouble in how to generate relationship between two enumerate .\n%-------------------------------\nenum weeks = {w1,w2,w3,w4};\narray[weeks] of 1..10 : weekShiftQty = [4,5,7,4]; % total shift = 20\nenum shift = _(1..20);\narray[shift] of weeks : shiftWeek\n= [\n% how to generate shiftWeek relationship %\n  % just like following : calculate shift belog to which week base on weekShiftQty\n  % shiftWeek[1] = w1 , ... , shiftWeek[4] = w1 , \n  % shiftWeek[5] = w2 ,...  , shiftWeek[9] = w2 ,\n  % shiftWeek[10] = w3 ,...  , shiftWeek[16] = w3 ,\n  % shiftWeek[17] = w4 ,...  , shiftWeek[20] = w4 ,\n  | s in shift\n];\n\n%-------------------------------\n",
"AnswerId": "76397188",
"AnswerBody": "Here's a solution, i.e. using [ w | w in weeks, _ in 1..weekShiftQty[w]] to generate the shiftWeek array:\nenum weeks = {w1,w2,w3,w4};\narray[weeks] of 1..10 : weekShiftQty = [4,5,7,4]; % total shift = 20\nenum shift = _(1..20);\n\narray[shift] of weeks: shiftWeek = [\n                                     w\n                                     | w in weeks,\n                                       _ in 1..weekShiftQty[w]\n                                     ];\noutput [\n        \"shiftWeek: \\(shiftWeek)\\n\"\n        ];\n\n\nThe output is\nshiftWeek: [w1, w1, w1, w1, w2, w2, w2, w2, w2, w3, w3, w3, w3, w3, w3, w3, w4, w4, w4, w4]\n\n"
},
{
"QuestionId": "76394627",
"QuestionTitle": "Why are the curves of the data samples connected by a line?",
"QuestionBody": "I am attaching my txt file, graph, and code. Can you please tell me what to change in this code, or why this third straight line is coming in my graph, because I only need two curve lines. In other software like xmgrace it's showing two curves only.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndeformation, potential = np.loadtxt(\"poten-Rf259.txt\", unpack=True)\nplt.subplot(1,3,1)\nplt.plot(deformation, potential, linewidth=1, color='b')\nplt.xlabel(\"$deformation$\")\nplt.ylabel(\"potential\")\nplt.yscale(\"log\")\nplt.show()\n\n\n0.60     1996.95397779\n0.61     1995.35525840\n0.62     1993.86701437\n0.63     1992.48491231\n0.64     1991.19969171\n0.65     1990.00485364\n0.66     1988.89605689\n0.67     1987.86875188\n0.68     1986.91599808\n0.69     1986.03420343\n0.70     1985.21922699\n0.71     1984.46631470\n0.72     1983.77171151\n0.73     1983.13117131\n0.74     1982.53983312\n0.75     1981.99532235\n0.76     1981.49445904\n0.77     1981.03536392\n0.78     1980.61563713\n0.79     1980.23282155\n0.80     1979.88357050\n0.81     1979.56605195\n0.82     1979.27790062\n0.83     1979.01687947\n0.84     1978.78288516\n0.85     1978.57209950\n0.86     1978.38399957\n0.87     1978.21704688\n0.88     1978.06886192\n0.89     1977.93793974\n0.90     1977.82377479\n0.91     1977.72453886\n0.92     1977.64028757\n0.93     1977.56966186\n0.94     1977.51247702\n0.95     1977.46734438\n0.96     1977.43305218\n0.97     1977.40866283\n0.98     1977.39347411\n0.99     1977.38486567\n1.00     1977.38198044\n1.01     1977.38578333\n1.02     1977.39435293\n1.03     1977.40721066\n1.04     1977.42425865\n1.05     1977.44721979\n1.06     1977.47357918\n1.07     1977.50320577\n1.08     1977.53535737\n1.09     1977.56925776\n1.10     1977.60496583\n1.11     1977.64155671\n1.12     1977.67899730\n1.13     1977.71674843\n1.14     1977.75457845\n1.15     1977.79221495\n1.16     1977.82838072\n1.17     1977.86261243\n1.18     1977.89473051\n1.19     1977.92436517\n1.20     1977.95062327\n1.21     1977.97352605\n1.22     1977.99387754\n1.23     1978.01047267\n1.24     1978.02233261\n1.25     1978.03018886\n1.26     1978.03434229\n1.27     1978.03431686\n1.28     1978.02782602\n1.29     1978.01489388\n1.30     1977.99620759\n1.31     1977.97164846\n1.32     1977.94011930\n1.33     1977.90108165\n1.34     1977.85474975\n1.35     1977.80116069\n1.36     1977.73920528\n1.37     1977.66702371\n1.38     1977.58440415\n1.39     1977.49291347\n1.40     1977.39203011\n1.41     1977.28170103\n1.42     1977.16108588\n1.43     1977.02866014\n1.44     1976.88410316\n1.45     1976.72847328\n1.46     1976.56259216\n1.47     1976.38386074\n1.48     1976.20047863\n1.49     1976.00349668\n1.50     1975.79062208\n1.51     1975.56427272\n1.52     1975.32369916\n1.53     1975.06525907\n1.54     1974.78917861\n1.55     1974.49730653\n1.56     1974.19357061\n1.57     1973.87528322\n1.58     1973.54134915\n1.59     1973.19101633\n1.60     1972.82834582\n1.61     1972.45110208\n1.62     1972.05553210\n1.63     1971.64144442\n1.64     1971.20783885\n1.65     1970.75735680\n1.66     1970.29140464\n1.67     1969.81219620\n1.68     1969.31582059\n1.69     1968.80021418\n1.70     1968.26283644\n1.71     1967.70510563\n1.72     1967.13020137\n1.73     1966.53988789\n1.74     1965.93070810\n1.75     1965.30035432\n1.76     1964.64993511\n1.77     1963.98214335\n1.78     1963.29607120\n1.79     1962.58677705\n1.80     1961.85278252\n1.81     1961.10290054\n1.82     1960.33687553\n1.83     1959.54927874\n1.84     1958.74001445\n1.85     1957.90788391\n1.86     1957.05397043\n1.87     1956.17614396\n1.88     1955.26999324\n1.89     1954.33375080\n1.90     1953.37236582\n1.91     1952.38212458\n1.92     1951.35983354\n1.93     1950.30220457\n1.94     1949.20603907\n1.95     1948.05714844\n1.96     1946.84779027\n1.97     1945.58008527\n1.98     1944.23420931\n1.99     1942.79805826\n2.00     1941.26241606\n2.01     1939.59635092\n2.02     1937.76411055\n2.03     1935.72007499\n2.04     1933.39927526\n2.05     1930.72795563\n2.06     1927.60977402\n2.07     1923.90784077\n2.08     1919.45804354\n2.09     1914.31285484\n\n0.60     1998.69655342\n0.61     1997.10205960\n0.62     1995.61774169\n0.63     1994.23972037\n0.64     1992.95788603\n0.65     1991.76641764\n0.66     1990.66090368\n0.67     1989.63677721\n0.68     1988.68674207\n0.69     1987.80810777\n0.70     1986.99582463\n0.71     1986.24553783\n0.72     1985.55344269\n0.73     1984.91507367\n0.74     1984.32536754\n0.75     1983.78293400\n0.76     1983.28383613\n0.77     1982.82671380\n0.78     1982.40862045\n0.79     1982.02768397\n0.80     1981.67975264\n0.81     1981.36364770\n0.82     1981.07656995\n0.83     1980.81699835\n0.84     1980.58410256\n0.85     1980.37438858\n0.86     1980.18712107\n0.87     1980.02126097\n0.88     1979.87363292\n0.89     1979.74345272\n0.90     1979.62995824\n0.91     1979.53135472\n0.92     1979.44772023\n0.93     1979.37757311\n0.94     1979.32104058\n0.95     1979.27599816\n0.96     1979.24203421\n0.97     1979.21798198\n0.98     1979.20293129\n0.99     1979.19417215\n1.00     1979.19165696\n1.01     1979.19541560\n1.02     1979.20395824\n1.03     1979.21615707\n1.04     1979.23320721\n1.05     1979.25599428\n1.06     1979.28171220\n1.07     1979.31101088\n1.08     1979.34264374\n1.09     1979.37618654\n1.10     1979.41145970\n1.11     1979.44782160\n1.12     1979.48476237\n1.13     1979.52196027\n1.14     1979.55904133\n1.15     1979.59588083\n1.16     1979.63104564\n1.17     1979.66430513\n1.18     1979.69566099\n1.19     1979.72388637\n1.20     1979.74966849\n1.21     1979.77150493\n1.22     1979.79086274\n1.23     1979.80610500\n1.24     1979.81670006\n1.25     1979.82369958\n1.26     1979.82686535\n1.27     1979.82547672\n1.28     1979.81769448\n1.29     1979.80330511\n1.30     1979.78339939\n1.31     1979.75736288\n1.32     1979.72409901\n1.33     1979.68352105\n1.34     1979.63566920\n1.35     1979.58069993\n1.36     1979.51670517\n1.37     1979.44233796\n1.38     1979.35779846\n1.39     1979.26468767\n1.40     1979.16177621\n1.41     1979.04976449\n1.42     1978.92676326\n1.43     1978.79213218\n1.44     1978.64555037\n1.45     1978.48837015\n1.46     1978.32011092\n1.47     1978.14017085\n1.48     1977.95500440\n1.49     1977.75460116\n1.50     1977.53929775\n1.51     1977.31056663\n1.52     1977.06737359\n1.53     1976.80606527\n1.54     1976.52721955\n1.55     1976.23286883\n1.56     1975.92682410\n1.57     1975.60574409\n1.58     1975.26801315\n1.59     1974.91469758\n1.60     1974.54947451\n1.61     1974.16923372\n1.62     1973.77070376\n1.63     1973.35355306\n1.64     1972.91665268\n1.65     1972.46280943\n1.66     1971.99372187\n1.67     1971.51115360\n1.68     1971.01142423\n1.69     1970.49285180\n1.70     1969.95210065\n1.71     1969.39103370\n1.72     1968.81236301\n1.73     1968.21808006\n1.74     1967.60511707\n1.75     1966.97077175\n1.76     1966.31642577\n1.77     1965.64473808\n1.78     1964.95488565\n1.79     1964.24169727\n1.80     1963.50348643\n1.81     1962.74968760\n1.82     1961.97913235\n1.83     1961.18709132\n1.84     1960.37331514\n1.85     1959.53686374\n1.86     1958.67882118\n1.87     1957.79696651\n1.88     1956.88661558\n1.89     1955.94582437\n1.90     1954.97949954\n1.91     1953.98399101\n1.92     1952.95610229\n1.93     1951.89377598\n1.94     1950.79298520\n1.95     1949.63969262\n1.96     1948.42603486\n1.97     1947.15347382\n1.98     1945.80171537\n1.99     1944.35916231\n2.00     1942.81707081\n2.01     1941.14446913\n2.02     1939.30723411\n2.03     1937.25876976\n2.04     1934.93414618\n2.05     1932.25762526\n2.06     1929.13222293\n2.07     1925.42169053\n2.08     1920.96503220\n2.09     1915.81720928\n\n",
"AnswerId": "76394768",
"AnswerBody": "It's simply because you are plotting one line for one set of x,y data, not two lines; hence the one line has to join all points. Try\n p.scatter(deformation, potential, s = 2,  color='b')\n\nand see your data as it should be shown. As these are data points this is more appropriate anyway.\n"
},
{
"QuestionId": "76396037",
"QuestionTitle": "Check in range of multiple float variables",
"QuestionBody": "User input scores of subjects and I need to check if these scores are valid (0->10, step is 0.1 because for exp: 5.25 or 5.1 is acceptable). Below is my code:\ndef Task_22():\n    mathematics = float(input(\"Input mathematics score: \"))\n    literature  = float(input(\"Input literature score: \"))\n    english     = float(input(\"Input english score: \"))\n    # check valid score\n    if all(i in range(0,11) for i in [mathematics, literature, english]):\n        print(\"OK\")\n    else: print(\"NOK\")\n\nbut when input as below, the result is not as my expected:\nInput mathematics score: 2\nInput literature score: 5\nInput english score: 7.25\nNOK\n\n",
"AnswerId": "76396113",
"AnswerBody": "The range() function lets you create an iterator so you can loop over some integers. When you use i in range(0, 11), you're essentially asking \"will range(0, 11) eventually iterate over i\", not \"is i within the upper and lower bounds of range(0, 11)\". Because range() only works with integers, a float will be iterator over by range, and thus a float will never be in a range.\nWhat you really want to do is check if the number is greater or equal to a lower bound and less than or equal to an upper bound, using operators like >= and <=.\ndef Task_22():\n    mathematics = float(input(\"Input mathematics score: \"))\n    literature  = float(input(\"Input literature score: \"))\n    english     = float(input(\"Input english score: \"))\n    # check valid score\n    if all(0 <= i <= 10 for i in [mathematics, literature, english]):\n        print(\"OK\")\n    else: print(\"NOK\")\n\n"
},
{
"QuestionId": "76396082",
"QuestionTitle": "I'm trying to do a search by title and by content, but it gives an error syntax error at or near \\\"OR\\",
"QuestionBody": "I'm trying to do a search by title and by content, but it gives an error\nTypeorm\nselect\np.*,\nfrom post p\nleft join vote v on p.id = v.post_id and v.user_id = $1\nwhere p.is_published = true AND p.title ilike OR p.context::text ilike $2\nlimit 5 offset $3\n\nconst posts = await AppDataSource.query(`\n  select\n  p.*,\n  from post p\n  left join vote v on p.id = v.post_id and v.user_id = $1\n  where p.is_published = true AND p.title ilike OR p.context::text ilike $2\n  limit 5 offset $3\n `, [req.user.id, `%${req.query.q}%`, req.query.skip]\n)\n\n",
"AnswerId": "76396144",
"AnswerBody": "There's a matching pattern missing:\np.title ilike OR p.context::text ilike $2\n             ^ HERE\n\n"
},
{
"QuestionId": "76390635",
"QuestionTitle": "resampling/\"upscaling\" using scipy.interpolate.RectBivariateSpline no diffrence",
"QuestionBody": "I am testing out scipy.interpolate.RectBivariateSpline for a project where I want to upscale some data to achieve better resolution. My attempt at using both scipy.interpolate.RectBivariateSpline and scipy.interpolate.interp2d results in no interpolation actually happening to the data; I just end up with a bigger matrix filled with more zeros. I have looked at some examples as well, but I am unable to see what I have done differently from them. And i would also expect my orgianal data to be centerd. Any help is appreciated\ncode\nn = 10\nsmile = np.zeros((n,n))\na = 0.5\nsmile[2,2] = a\nsmile[3,2] = a\nsmile[2,7] = a\nsmile[3,7] = a\nsmile[6,2] = a\nsmile[6,7] = a\nsmile[7,3:7] = a\n\n\nplt.imshow(smile)\nplt.show()\n\n#RECTBIVARIATESPLINE\n#making interpolation function\nx = np.arange(n)\ny = x \nz = smile\n\ninterpolation_funk = scipy.interpolate.RectBivariateSpline(x,y,z)\n\n#using interpolation\nx_new = np.arange(2*n)\ny_new = x_new\nZ_new = interpolation_funk(x_new,y_new)\n\n\n#plotting new funtion\nplt.imshow(Z_new)\n\n\n",
"AnswerId": "76397231",
"AnswerBody": "Note x_new = np.arange(2*n) : you are evaluating the interpolant outside of the original data range ([0, 9] x [0, 9]) and you get all zeros for the extrapolation.\nUse x_new = np.arange(2*n) / 2 or some such to actually interpolate between the data points.\n"
},
{
"QuestionId": "76396174",
"QuestionTitle": "Why is my SQL query not updating user properties other than 'user' in Node.js and MySQL?",
"QuestionBody": "I have a Service method to update a user from the database:\nconst updateUser = async (user) => {\n    const {firstName, lastName, email, password, phone, dob, countryid, gender, address, role, id} = user;\n    const sql = `UPDATE user set user_firstName = ?, user_lastName = ?, user_email = ?, user_password = ?, user_phoneNumber = ?, user_dob= ?, user_countryId = ?, user_gender = ?, user_address = ?, user_role= ? WHERE client_id = ?`;\n    try {\n        await db.query(sql, [firstName, lastName, email, password, phone, dob, countryid, gender, address, role, id]);\n        return { message: \"records updated successfully.\" }\n    } catch (error) {\n        return { message: \"Failed to updated\" }\n    }\n}\n\nwhenever I log user alone it can read it, but it's not reading any other properties ( firstName etc...) and getting this error: Bind parameters must not contain undefined. To pass SQL NULL specify JS null.\npreview of console.log(user):\n\nmy route is working perfectly, the same function has been used before without any issues\n",
"AnswerId": "76396198",
"AnswerBody": "The user argument you're printing out isn't an object representing a user, it's an array with a single such element. In addition, the object itself doesn't have the firstName and lastName properties you're trying to use, it has firstname and lastname (notice the lowercase ns). Since they aren't there, they get undefined values\nAssuming you intended to pass an array to the function, you should probably iterate over all the users an update each of them. Regarding the properties, if you replace firstName and lastName with firstname and lastname, respectively, you should be OK:\nconst updateUser = async (users) => {\n    users.forEach(user => {\n        const {firstname, lastname, email, password, phone, dob, countryid, gender, address, role, id} = user; // Here\n        const sql = `UPDATE user set user_firstName = ?, user_lastName = ?, user_email = ?, user_password = ?, user_phoneNumber = ?, user_dob= ?, user_countryId = ?, user_gender = ?, user_address = ?, user_role= ? WHERE client_id = ?`;\n        try {\n            await db.query(sql, [firstname, lastname, email, password, phone, dob, countryid, gender, address, role, id]); // And here!\n            return { message: \"records updated successfully.\" }\n        } catch (error) {\n            return { message: \"Failed to updated\" }\n        }\n    }\n});\n\n"
},
{
"QuestionId": "76394699",
"QuestionTitle": "Conditionally project a field value in mongodb",
"QuestionBody": "**I have a mongo document as below.\n**\n{\n  \"metadata\": {\n    \"docId\": \"7b96a\"\n  },\n  \"items\": {\n    \"content\": \"abcd\",\n    \"contentWithInfo\": \"content with additional info\"\n  }\n}\n\nI want to project content field based on the condition whether contentWithInfo field is present or not. If contentWithInfo is present, it's value should be projected as content field value and contentWithInfo should be empty. Otherwise content should be projected as is. Is it possible?\nI tried the following shell query:\ndb.collection1.aggregate([\n  {\n    \"$match\": {\n      \"metadata.docId\": {\n        \"$in\": [\n          \"7b96a\"\n        ]\n      }\n    }\n  },\n  {\n    \"$unwind\": \"$items\"\n  },\n  {\n    \"$project\": {\n      \"metadata\": 1,\n      \"items.content\": {\n        \"$cond\": {\n          \"if\": {\n            \"$eq\": [\n              \"$items.contentWithInfo\",\n              null\n            ]\n          },\n          \"then\": \"$items.content\",\n          \"else\": \"$items.contentWithInfo\"\n        }\n      }\n    }\n  }\n])\n\n\nIf contentWithInfo is present, it is returning the following:\n{\n  \"metadata\": {\n    \"docId\": \"7b96a\"\n  },\n  \"items\": {\n    \"content\": \"content with additional info\"\n  }\n}\n\nIf contentWithInfo is not present, it is returning the following:\n{\n  \"metadata\": {\n    \"docId\": \"7b96a\"\n  },\n  \"items\": {}\n}\n\n\nwhereas I expect it to return\n{\n  \"metadata\": {\n    \"docId\": \"7b96a\"\n  },\n  \"items\": {\n    \"content\": \"abcd\"\n  }\n}\n\n",
"AnswerId": "76394770",
"AnswerBody": "Approach 1\nInstead of checking items.contentWithInfo is null, check whether the items.contentWithInfo is missing with $type operator.\ndb.collection.aggregate([\n  {\n    \"$match\": {\n      \"metadata.docId\": {\n        \"$in\": [\n          \"7b96a\"\n        ]\n      }\n    }\n  },\n  {\n    \"$unwind\": \"$items\"\n  },\n  {\n    \"$project\": {\n      \"metadata\": 1,\n      \"items.content\": {\n        \"$cond\": {\n          \"if\": {\n            \"$eq\": [\n              {\n                $type: \"$items.contentWithInfo\"\n              },\n              \"missing\"\n            ]\n          },\n          \"then\": \"$items.content\",\n          \"else\": \"$items.contentWithInfo\"\n        }        \n      }\n    }\n  }\n])\n\nDemo Approach 1 @ Mongo Playground\nAnother approach, if you want items.content as default value if items.contentWithInfo is missing or null, you can use $ifNull operator.\ndb.collection.aggregate([\n  {\n    \"$match\": {\n      \"metadata.docId\": {\n        \"$in\": [\n          \"7b96a\"\n        ]\n      }\n    }\n  },\n  {\n    \"$unwind\": \"$items\"\n  },\n  {\n    \"$project\": {\n      \"metadata\": 1,\n      \"items.content\": {\n        $ifNull: [\n          \"$items.contentWithInfo\",\n          \"$items.content\"\n        ]\n      }\n    }\n  }\n])\n\nDemo Approach 2 @ Mongo Playground\n"
},
{
"QuestionId": "76396065",
"QuestionTitle": "\"You have requested more vCPU capacity\", when launching G instance",
"QuestionBody": "I have this error when launching g4dn.xlarge instance\nYou have requested more vCPU capacity than your current vCPU limit of 0 allows for the instance bucket that the specified instance type belongs to. Please visit http://aws.amazon.com/contact-us/ec2-request to request an adjustment to this limit.\n\nHowever my Service Quota is like this below\n\nAll G and VT Spot Instance Requestss is 8\nAnd I don't launch another G instance at the same time.\nWhere should I check?\nOr is it relevant?(EC2 -> Limit, It shows  Limits page deactivated)\n(I can jump to the service quota page from the link in this page though)\n\n",
"AnswerId": "76396319",
"AnswerBody": "Ensure you are requesting a spot instance when you configure the launch of your vm. There is a check box under the Advanced section of the launch wizard.\n"
},
{
"QuestionId": "76390618",
"QuestionTitle": "How to perform XML Element substitution in config.wxi using Replace Tokens?",
"QuestionBody": "I am building an Azure Devops Release pipeline and I have a WIX config file in my source code with the following structure\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Include>\n  <?define Key =\"MyValue\"?>\n</Include>\n\nI would like to replace \"MyValue\" with \"MyNewValue\" using the Replace Tokens package\n(link here)\nFollowing the answer given here.\nI have <Include> as my token prefix and </Include> as my token suffix. I've added the following pipeline variable:\nenter image description here\nWhen I build my pipeline it finds the file correctly, but doesn't find any variables to replace, am I missing something to link the variables step to the pipeline variables?\nalternatively I was thinking the '<?' tags could be throwing it off or perhaps it's just not compatible with the WIX xml files?\n",
"AnswerId": "76397387",
"AnswerBody": "Why not just pass the preprocessor variable via the .wixproj or command-line (whichever way you are building). That way you avoid the include file completely and have a much simpler solution.\nI cover this technique in Episode 12 of the Deployment Dojo - All the Ways to Change. Variables and Variables. Directories and Properties:\n<Project Sdk=\"WixToolset.Sdk/4.0.0\">\n  <PropertyGroup>\n   <DefineConstants>Key=MyValue</DefineConstants>\n  </PropertyGroup>\n</Project>\n\nThen you can easily override the value with msbuild -p:Key=MyNewValue.\n"
},
{
"QuestionId": "76394516",
"QuestionTitle": "creating a function looping through multiple subsets and then grouping and summing those combinations of subsets",
"QuestionBody": "I am attempting to build a function that processes data and subsets across two combinations of dimensions, grouping on a status label and sums on price creating a single row dataframe with the different combinations of subsets of the summed prices as output.\nedit\nto clarify, what I'm looking for is to subset on two different combinations of dimensions; a time delta and an association label.\nI'm then looking to group on a different status label (which is different from the association label) and sum those on price.\nCombinations of subsets:\n\nthe association labels are in the \"Association Label\" column and the three of interest are [\"SDAR\", \"NSDCAR\", \"PSAR\"] there are others in the column/data but they can be ignored\nthe time interval are [7, 30, 60, 90, 120, None] and are in the \"Status Date\" column\n\nWhat's being grouped and summed as per those combination of subsets:\n\nThe Status Labelled are transaction statuses which are to be grouped on as per the different combinations of the above subsets from time deltas and association labels. They include [\"Active\",\"Pending\",\"Sold\",Withdrawn\",\"Contingent\",\"Unknown\"] (this is not an exhaustive list but just an example)\nAnd finally ['List Price (H)'] which is to be summed per each of those status labelled and as per each combination of the fist two subsets.\n\nSo example columns of desired output would be something like PSAR_7_Contingent_price or SDAR_60_Withdrawn_price\nThis builds off of this question and answer which worked fantastic for value counts, but I'm having difficulty modifying it for summing on a price variable.\nThe code I used to build off of is\ndef crossubsets(df):\n    labels = [\"SDAR\", \"NSDCAR\", \"PSAR\"]\n    time_intervals = [7, 30, 60, 90, 120, None]\n    group_dfs = df.loc[\n        df[\"Association Label\"].isin(labels)\n    ].groupby(\"Association Label\")\n\n    data = []\n    for l, g in group_dfs:\n        for ti in time_intervals:\n            s = (\n                g[g[\"Status Date\"] > (pd.Timestamp.now() - pd.Timedelta(ti, \"d\"))]\n                if ti is not None else g\n            )\n            data.append(s[\"Status Labelled\"].value_counts().rename(f\"counts_{l}_{ti}\"))\n\n    return pd.concat(data, axis=1) #with optional .T to have 18 rows instead of cols\n\n# additional code to flatten the output to a (1, 180) dataframe\n\ncounts_processeed = counts_processeed.unstack().to_frame().sort_index(level=1).T\ncounts_processeed .columns = counts_processeed.columns.map('_'.join)\n\nThis worked great for the value_counts per Status Labelled, but now I'm looking to sum the associated price per those that Status Labelled, and across those dimensions of subsets. I naively attempted to modify the above function with:\ndef crossubsetsprice(df):\n    labels = [\"SDAR\", \"NSDCAR\", \"PSAR\"]\n    time_intervals = [7, 30, 60, 90, 120, None]\n    group_dfs = df.loc[\n        df[\"Association Label\"].isin(labels)\n    ].groupby(\"Association Label\")\n\n    data = []\n    for l, g in group_dfs:\n        for ti in time_intervals:\n            s = (\n                g[g[\"Status Date\"] > (pd.Timestamp.now() - pd.Timedelta(ti, \"d\"))]\n                if ti is not None else g\n            )\n            data.append(s['List Price (H)'].sum().rename(f\"price_{l}_{ti}\"))\n\n    return pd.concat(data, axis=1) #with optional .T to have 18 rows instead of cols\n\nBut that throws and error AttributeError: 'numpy.float64' object has no attribute 'rename' and I don't think makes much sense or would get the desired output anyway.\nThe alternative I want to avoid, but I know would work, is creating 18 distinct functions for each of combination of subsets then concatinating the output. An example would be:\ndef price_PSAR_90(df):\n    subset_90 = df[df['Status Date'] > (datetime.now() - pd.to_timedelta(\"90day\"))]\n    subset_90_PSAR= subset_90[subset_90['Association Label']==\"PSAR\"]  \n\n    grouped_90_PSAR = subset_90_PSAR.groupby(['Status Labelled'])\n\n    price_summed_90_PSAR = (pd.DataFrame(grouped_90_PSAR['List Price (H)'].sum()))\n    price_summed_90_PSAR.columns = ['Price']\n    price_summed_90_PSAR = price_summed_90_PSAR.reset_index()\n    price_summed_90_PSAR = price_summed_90_PSAR.T\n    price_summed_90_PSAR = price_summed_90_PSAR.reset_index()\n    price_summed_90_PSAR.drop(price_summed_90_PSAR.columns[[0]], axis=1, inplace=True)\n    price_summed_90_PSAR_header = price_summed_90_PSAR.iloc[0] #grab the first row for the header\n    price_summed_90_PSAR = price_summed_90_PSAR[1:] #take the data less the header row\n    price_summed_90_PSAR.columns = price_summed_90_PSAR_header\n\n\n    return price_summed_90_PSAR\n\nThe last code snippet works, but without looping would need to be repeated with the time delta and association label being changed for each combination, and then relabelling the output columns and concatenated them together, which I want to avoid if possible.\n",
"AnswerId": "76394776",
"AnswerBody": "Maybe you can try to use a dict for data instead of a list. Something like:\ndef crossubsetsprice(df):\n    labels = [\"SDAR\", \"NSDCAR\", \"PSAR\"]\n    time_intervals = [7, 30, 60, 90, 120, None]\n    group_dfs = df.loc[\n        df[\"Association Label\"].isin(labels)\n    ].groupby([\"Association Label\", 'Status Labelled'])\n\n    data = {}  # HERE\n    for (l1, l2), g in group_dfs:\n        for ti in time_intervals:\n            s = (\n                g[g[\"Status Date\"] > (pd.Timestamp.now() - pd.Timedelta(ti, \"d\"))]\n                if ti is not None else g\n            )\n            data[(l1, l2, ti)] = s['List Price (H)'].sum()  # HERE\n\n    names = ['Association Label', 'Status Labelled', 'Time Interval']\n    return pd.Series(data, name='Price').rename_axis(names)  # HERE\n\nOutput:\n>>> crossubsetsprice(df)\nAssociation Label  Status Labelled  Time Interval\nNSDCAR             Active           7.0               1393\n                                    30.0              6090\n                                    60.0             11397\n                                    90.0             16540\n                                    120.0            21660\n                                                     ...  \nSDAR               Withdrawn        30.0              3167\n                                    60.0              8897\n                                    90.0             15768\n                                    120.0            21806\n                                    NaN              28379\nName: Price, Length: 108, dtype: int64\n\nMinimal Reproducible Example:\nimport pandas as pd\nimport numpy as np\n\nN = 1000\nrng = np.random.default_rng(42)\nlabels = rng.choice([\"SDAR\", \"NSDCAR\", \"PSAR\"], N)\nstatus = rng.choice([\"Active\", \"Pending\", \"Sold\", \"Withdrawn\", \"Contingent\", \"Unknown\"], N)\ntoday = pd.Timestamp.today()\nstart = pd.Timestamp('2023-01-01 00:00:00')\noffsets = rng.integers(0, (today - start).total_seconds(), N)\ndates = start + pd.to_timedelta(offsets, unit='S')\nprices = rng.integers(1, 1001, N)\ndf = pd.DataFrame({'Association Label': labels,\n                   'Status Date': dates,\n                   'Status Labelled': status,\n                   'List Price (H)': prices})\n\n"
},
{
"QuestionId": "76397512",
"QuestionTitle": "ggplot - ordering legends with guides changes continuous legend to discrete",
"QuestionBody": "I'm running ggplot2 v3.4.1. I created this 2 legend plot that by default it is placing the year2 size legend below the cty color legend. However, I would like the size legend to be on top.\nlibrary(tidyverse)\n\nmpg$year2 = factor(mpg$year)\nvalues = c(2,4); names(values) = c(\"1999\", \"2008\")\np = mpg %>%\n  ggplot(aes(x = cty, y = hwy, color = cty, size = year2)) + \n  geom_point() +\n  scale_size_manual(name = \"year2\", values = values)\np\n\n\nTherefore, I used guides() to specify the legend ordering but it changes the continuous color legend cty to discrete\np + guides(size = guide_legend(order = 1), \n           color = guide_legend(order = 2))\n\n\nI saw this post ggplot guide_legend argument changes continuous legend to discrete but am unable to figure out how to use guide_colorbar() when you have 2 or more legends.\nHow do I change my code to keep the cty legend as continuous? Thx\n",
"AnswerId": "76397558",
"AnswerBody": "It's simply\np + guides(size = guide_legend(order = 1), \n           color = guide_colorbar(order = 2))\n\n\n"
},
{
"QuestionId": "76396169",
"QuestionTitle": "python3, converting integer to bytes: which are the alternatives to using to_bytes() for small integers?",
"QuestionBody": "Is there a more efficient method to convert an integer, in the range 0..255 (in C uint8), to one byte?\nx = 100\nx.to_bytes(1, \"big\")\n\n",
"AnswerId": "76396390",
"AnswerBody": "More efficient method for a single integer? Probably not.\nHere's a comparison of the common ones:\npython -m timeit -s \"import struct\" \"struct.pack('<B', 100)\"\n2000000 loops, best of 5: 101 nsec per loop\npython -m timeit \"(100).to_bytes(1)\"                     \n5000000 loops, best of 5: 81.1 nsec per loop\npython -m timeit \"bytes([100])\"     \n2000000 loops, best of 5: 199 nsec per loop\n\nIf you're talking about multiple, bytes([integers]) will probably be the most efficient.\nFor some premature optimization you can cache the function, which will net you a few nanoseconds:\npython -m timeit -s \"tb = int.to_bytes\" \"tb(100,1)\" \n5000000 loops, best of 5: 78.6 nsec per loop\n\nAnd if you want the most efficient possible, it would probably be using a tuple:\npython -m timeit -s \"b=tuple(map(int.to_bytes, range(256)))\" \"b[100]\"\n10000000 loops, best of 5: 20.9 nsec per loop\n\nBut personally I find it disgusting.\n"
},
{
"QuestionId": "76394463",
"QuestionTitle": "Simulate decaying function",
"QuestionBody": "Lets t be the time tick i.e. 1,2,3,4,5....\nI want to calculate and plot a cumulative decaying function f(inits[],peaks[],peak-ticks,zero-ticks).\nPreferably in python\nWhere :\n- inits[] is a list of points at time/tick t where a new 'signal' is introduced\n- peaks[] is a list of values which must be reached after peak-ticks. (corresponding to inits)\n- peak-ticks is how many ticks it takes to reach the next peak value\n- zero-ticks is how many ticks it takes to reach zero from the peak\n\nFor example :\n f(inits=[10,15,18], peaks=[1,1,1], peak-ticks=1, zero-ticks=10)\n\nin this case decay takes 10 ticks i.e. 0.1 per tick.\nat tick:\n 10! result is 0\n 11. = 1\n 12. = 0.9\n .....\n 15! = 0.6 + 0 = 0.6\n 16. = 0.5 + 1 = 1.5\n 17. = 0.4 + 0.9 = 1.3\n 18! = 0.3 + 0.8 + 0 = 1.1\n 19. = 0.2 + 0.7 + 1 = 1.9\n 20. = 0.1 + 0.6 + 0.9 = 1.6\n .....\n\nPS> As a complication, what if the decay is exponential like 1/x ?\n",
"AnswerId": "76394795",
"AnswerBody": "For the base case you mentioned, it is actually pretty simple, you just need to define a triangular function that returns the contribution of a specific singal at the current tick t.\nThen, just sum the contribution of all signals at tick t, that is your answer.\nIn the code below, I implemented the decaying function as an infinite generator, so I have to use islice to define how many ticks to compute (or maybe the start and end ticks). You could also implement it as a normal function, you'd just have to pass in the start and end ticks.\nfrom itertools import count, islice\n\ndef fdecay(inits, peaks, ptks, ztks):\n  for t in count():\n    yield sum(triang(p, i, i+ptks, i+ptks+ztks, t) for i, p in zip(inits, peaks))\n\ndef triang(ymax, xa, xb, xc, x):\n  if x < xa: return 0\n  if x < xb: return ymax * (x-xa) / (xb-xa)\n  if x < xc: return ymax * (xc-x) / (xc-xb)\n  return 0\n\nx = list(islice(fdecay([10,15,18], [1,1,1], 1, 10), 30))\nprint(x)\n# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0.9, 0.8, 0.7, 0.6, 1.5, 1.3, 1.1, 1.9, 1.6, 1.3, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.1, 0]\n\n\nIf you want exponential decay, just switch the triangular function to the exponential function at time t (with the appropriate params).\n"
},
{
"QuestionId": "76396125",
"QuestionTitle": "Rails 7 - Accessing joined model generate new query",
"QuestionBody": "I have Rails 7 project where I've got tables\nPipelines\nclass Pipeline < ApplicationRecord\n  has_many :states, inverse_of: :pipeline, dependent: :destroy  \nend\n\nStates\nclass State < ApplicationRecord\n  belongs_to :pipeline, inverse_of: :states \n  has_many :items, inverse_of: :state\nend\n\nItems\nclass Item < ApplicationRecord\n  belongs_to :state, inverse_of: :items\nend\n\nI wrote a query to limit only specific items on state\n@pipeline = Pipeline.joins(states: :items)\n                    .where(states: { items: { name: \"Lorem\" } })\n                    .find_by(id: '123')\n\nquery:\nPipeline Load (0.7ms)  SELECT \"pipelines\".* FROM \"pipelines\" INNER JOIN \"states\" ON \"states\".\"pipeline_id\" = \"pipelines\".\"id\" INNER JOIN \"items\" ON \"items\".\"state_id\" = \"states\".\"id\" WHERE \"items\".\"name\" = $1 AND \"pipelines\".\"id\" = $2 LIMIT $3  [[\"name\", \"Lotem\"], [\"id\", \"123\"], [\"LIMIT\", 1]]\n\nbut once I call states from pipeline it generates new query without limitation:\nputs @pipeline.states.inspect\n\nState Load (0.4ms)  SELECT \"states\".* FROM \"states\" WHERE \"states\".\"pipeline_id\" = $1 /* loading for inspect */ LIMIT $2  [[\"pipeline_id\", \"123\"], [\"LIMIT\", 11]]\n\nI'm expecting that it should grab states from collection it already has loaded,\nam I missing something ?\n",
"AnswerId": "76396459",
"AnswerBody": "\nbut once I call states from pipeline it generates new query without\nlimitation\n\nyeah, that's how joins work, it doesn't do more than that so the docs even don't bother adding more information. If you want to access the states within a single query (really it'll end up being 2 queries) you could use includes instead;\nActiveRecord::QueryMethods#includes;\n\nSpecify relationships to be included in the result set. It allows you\nto access the address attribute of the User model without firing an\nadditional query.\n\nand your query would slightly change to;\nPipeline\n  .includes(states: :items)\n  .where(items: { name: \"Lorem\" })\n  .find('123')\n\nThe fact that invoking states on a Pipeline instance makes a new query is because you're invoking an instance method on that object which by definition makes a new query. Active Record won't know that you're referring to something that was already created in the query unless is specified otherwise (by using a custom select clause or similar).\n\nNotice\nPipeline.joins(states: :items).where(items: { name: \"Lorem\" }) is the same as Pipeline.joins(states: :items).where(states: { items: { name: \"Lorem\" } }), you don't need to nest items under states.\n"
},
{
"QuestionId": "76397544",
"QuestionTitle": "When injecting the DbContext using DI and using its private field in a query, should you still use the \"using\" scope?",
"QuestionBody": "I wanted to know if when you inject your DbContext with DI in a class, within the methods calling that context, should you use the using scope as well ? Or does DI knows about disposal after the method has been executed and/or does transient by default and it's safe ?\n",
"AnswerId": "76397591",
"AnswerBody": "\nWhen you inject a DbContext using dependency injection (DI), you generally don't need to use the using scope explicitly within the methods calling that context.\nIn the case of a transient registration for your DbContext, a new instance of the context will be created for each method call, and the DI container will automatically dispose of it once the method execution is complete. Therefore, you don't need to manually dispose of the context using the using statement.\n\n Microsoft Docs\n"
},
{
"QuestionId": "76395882",
"QuestionTitle": "How can I generate signed URLs for accessing Firebase Storage images?",
"QuestionBody": "I am making a web service with sveltekit and firebase.\nBy the way, when users save images on firebase storage and other users try to use these images, I want to create a signed url and show it on the page to prevent Hotlink.\nI searched and found that there is a function called getSignedUrl that generates a signed url, but there is no official document page that describes it in the firebase document.\nWhere can I get some example functions or information related to this?\n",
"AnswerId": "76396461",
"AnswerBody": "The Firebase SDK for Cloud Storage uses a different type of URL, called a download URL. You can generate a download URL by calling getDownloadURL with/on a reference to the file, as shown in the documentation on downloading data through a URL.\n"
},
{
"QuestionId": "76396176",
"QuestionTitle": "ngx-image-cropper , roundCropper = \"true\" not working , its showing this error - Type 'string' is not assignable to type 'boolean'",
"QuestionBody": "<image-cropper [imageChangedEvent]=\"imageChangedEvent\" [maintainAspectRatio]=\"true\" [aspectRatio]=\"4 / 4\"\n    format=\"jpg\" (imageCropped)=\"imageCropped($event)\" roundCropper = \"true\">\n</image-cropper>\n\n[screenshot attached for your reference]\nI used roundCropper = \"True\". But its not working and throwing the error:\n\nType 'string' is not assignable to type 'boolean'.\n\nIf a try to run the same code on stackblitz then its working. I have also tried it with roundCropper = true , but its giving same error.\nI want to use round cropper in my ngx-image-cropper.\n",
"AnswerId": "76396467",
"AnswerBody": "Try to surround roundCropper with []\n[roundCropper] = \"true\"\n"
},
{
"QuestionId": "76387496",
"QuestionTitle": "ASP.Net Core can't connect to MySql database in docker",
"QuestionBody": "I have error in the fifth line when asp.net try to connect db.\n2023-06-02 09:36:59 warn: Microsoft.AspNetCore.DataProtection.Repositories.FileSystemXmlRepository[60]\n2023-06-02 09:36:59       Storing keys in a directory '/root/.aspnet/DataProtection-Keys' that may not be persisted outside of the container. Protected data will be unavailable when container is destroyed.\n2023-06-02 09:37:00 info: Microsoft.EntityFrameworkCore.Infrastructure[10403]\n2023-06-02 09:37:00       Entity Framework Core 6.0.8 initialized 'AppIdentityDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.2' with options: ServerVersion 0.0-mysql \n2023-06-02 09:37:00 fail: Microsoft.EntityFrameworkCore.Database.Connection[20004]\n2023-06-02 09:37:00       An error occurred using the connection to database '' on server 'db2'.\n2023-06-02 09:37:00 Unhandled exception. System.InvalidOperationException: An exception has been raised that is likely due to a transient failure. Consider enabling transient error resiliency by adding 'EnableRetryOnFailure()' to the 'UseMySql' call.\n2023-06-02 09:37:00  ---> MySqlConnector.MySqlException (0x80004005): Unable to connect to any of the specified MySQL hosts.\n2023-06-02 09:37:00    at MySqlConnector.Core.ServerSession.ConnectAsync(ConnectionSettings cs, MySqlConnection connection, Int32 startTickCount, ILoadBalancer loadBalancer, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/Core/ServerSession.cs:line 433\n2023-06-02 09:37:00    at MySqlConnector.MySqlConnection.CreateSessionAsync(ConnectionPool pool, Int32 startTickCount, Nullable`1 ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlConnection.cs:line 926\n2023-06-02 09:37:00    at MySqlConnector.MySqlConnection.OpenAsync(Nullable`1 ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlConnection.cs:line 406\n2023-06-02 09:37:00    at MySqlConnector.MySqlConnection.Open() in /_/src/MySqlConnector/MySqlConnection.cs:line 369\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.Storage.RelationalConnection.OpenDbConnection(Boolean errorsExpected)\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.Storage.RelationalConnection.OpenInternal(Boolean errorsExpected)\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.Storage.RelationalConnection.Open(Boolean errorsExpected)\n2023-06-02 09:37:00    at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlRelationalConnection.Open(Boolean errorsExpected)\n2023-06-02 09:37:00    at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlDatabaseCreator.<>c__DisplayClass18_0.<Exists>b__0(DateTime giveUp)\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.ExecutionStrategyExtensions.<>c__DisplayClass12_0`2.<Execute>b__0(DbContext c, TState s)\n2023-06-02 09:37:00    at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlExecutionStrategy.Execute[TState,TResult](TState state, Func`3 operation, Func`3 verifySucceeded)\n2023-06-02 09:37:00    --- End of inner exception stack trace ---\n2023-06-02 09:37:00    at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlExecutionStrategy.Execute[TState,TResult](TState state, Func`3 operation, Func`3 verifySucceeded)\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.ExecutionStrategyExtensions.Execute[TState,TResult](IExecutionStrategy strategy, TState state, Func`2 operation, Func`2 verifySucceeded)\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.ExecutionStrategyExtensions.Execute[TState,TResult](IExecutionStrategy strategy, TState state, Func`2 operation)\n2023-06-02 09:37:00    at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlDatabaseCreator.Exists(Boolean retryOnNotExists)\n2023-06-02 09:37:00    at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlDatabaseCreator.Exists()\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.Migrations.HistoryRepository.Exists()\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.Migrations.HistoryRepository.GetAppliedMigrations()\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.RelationalDatabaseFacadeExtensions.GetAppliedMigrations(DatabaseFacade databaseFacade)\n2023-06-02 09:37:00    at Microsoft.EntityFrameworkCore.RelationalDatabaseFacadeExtensions.GetPendingMigrations(DatabaseFacade databaseFacade)\n2023-06-02 09:37:00    at ClothingShop.Models.IdentitySeedData.EnsurePopulated(IApplicationBuilder app) in /src/Models/IdentitySeedData.cs:line 16\n2023-06-02 09:37:00    at System.Threading.Tasks.Task.<>c.<ThrowAsync>b__128_1(Object state)\n2023-06-02 09:37:00    at System.Threading.QueueUserWorkItemCallbackDefaultContext.Execute()\n2023-06-02 09:37:00    at System.Threading.ThreadPoolWorkQueue.Dispatch()\n2023-06-02 09:37:00    at System.Threading.PortableThreadPool.WorkerThread.WorkerThreadStart()\n2023-06-02 09:37:00    at System.Threading.Thread.StartCallback()\n\nI have an asp.net core project and two databases. I am creating a docker compose file.\nversion: '3.8'\n\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:80\"\n    depends_on:\n      - db1\n      - db2\n\n  db1:\n    image: mysql:8.0.30\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: clothingshop1\n    volumes:\n      - ./db1:/docker-entrypoint-initdb.d\n    ports:\n      - \"3307:3306\"\n\n  db2:\n    image: mysql:8.0.30\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: identity\n    volumes:\n      - ./db2:/docker-entrypoint-initdb.d\n    ports:\n      - \"3308:3306\"\n\nI am using generated file docker\n#See https://aka.ms/customizecontainer to learn how to customize your debug container and how Visual Studio uses this Dockerfile to build your images for faster debugging.\n\nFROM mcr.microsoft.com/dotnet/aspnet:6.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build\nWORKDIR /src\nCOPY [\"ClothingShop.csproj\", \".\"]\nRUN dotnet restore \"./ClothingShop.csproj\"\nCOPY . .\nWORKDIR \"/src/.\"\nRUN dotnet build \"ClothingShop.csproj\" -c Release -o /app/build\n\nFROM build AS publish\nRUN dotnet publish \"ClothingShop.csproj\" -c Release -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"ClothingShop.dll\"]\n\nIn programm.cs i have:\nbuilder.Services.AddDbContext<StoreDbContext>(opts =>\n{\n    opts.UseMySql(builder.Configuration.GetConnectionString(\"ClothingShopConnection\"), new MySqlServerVersion(new Version()), b => b.EnableRetryOnFailure());\n});\n\nand\nbuilder.Services.AddDbContext<AppIdentityDbContext>(options =>\n options.UseMySql(builder.Configuration.GetConnectionString(\"IdentityConnection\"), new MySqlServerVersion(new Version())));\n\nIn appsettings.json i have:\n  \"AllowedHosts\": \"*\",\n  \"ConnectionStrings\": {\n    \"ClothingShopConnection\": \"server=db1;port=3307;user=root;password=root;Pooling=true;Max Pool Size=200;database=clothingshop1\",\n    \"IdentityConnection\": \"server=db2;port=3308;user=root;password=root;database=identity\"\n  },\n\nI run\ndocker-compose up -d in cmd. And i have this result Created container but asp won't start.\nI try edit appsettings.json to:\n    \"ClothingShopConnection\": \"server=localhost;port=3306;user=root;password=root;Pooling=true;Max Pool Size=200;database=clothingshop1\",\n    \"IdentityConnection\": \"server=localhost;port=3306;user=root;password=root;database=identity\"\n\n    \"ClothingShopConnection\": \"server=localhost;port=3307;user=root;password=root;Pooling=true;Max Pool Size=200;database=clothingshop1\",\n    \"IdentityConnection\": \"server=localhost;port=3308;user=root;password=root;database=identity\"\n\n    \"ClothingShopConnection\": \"server=db-1;port=3307;user=root;password=root;Pooling=true;Max Pool Size=200;database=clothingshop1\",\n    \"IdentityConnection\": \"server=db-2;port=3308;user=root;password=root;database=identity\"\n\nbut to no avail.\nAn interesting fact is that it mysql worckbanch connector sees these databases and makes it possible to connect to them through localhost: 3307 and 08, respectively.Successful connection. Db created correct.\nI've looked at similar threads but haven't found an answer.\n",
"AnswerId": "76394801",
"AnswerBody": "I solved my problem by configuring the connection string like this:\n\"ConnectionStrings\": {\n\"ClothingShopConnection\": \"server=dbClothingShop;port=3306;user=root;password=root;Pooling=true;Max Pool Size=200;database=clothingshop1\",\n\"IdentityConnection\": \"server=dbIdentity;port=3306;user=root;password=root;database=identity\"\n}\n\nAnd apparently part of the problem was due to incorrect reading of tables from the database. Tables with capital letters were expected, but in the table they are with small letters (apparently something broke when importing and exporting the database).\nI solved it with attributes DataAnnotation:\n[Table(\"size\")]\npublic class Size\n{\n   //SizeID...\n}\n\nThanks a lot for the great questions @QiangFu\n"
},
{
"QuestionId": "76396262",
"QuestionTitle": "Plotly: auto resize height",
"QuestionBody": "I am creating a bar graph using plotly express inside dash application. The graph is getting displayed but I am having an issue with height.Currently I am using default height and width.\nNow for eg:\n\ndataframe having field column contain 3 entires, the graph looks ok.\n\ndataframe having field column contain 10 entires, the bar width is reduced auto and height remains the same and graph looks congested and hard to read.\n\n\nfigure = (\n    px.bar(\n        data_frame=dataframe,\n        x=\"size\",\n        y=\"field\",\n        title=\"Memory Usage\",\n        text=\"size\",\n        # width=400,\n        # height=400,\n        orientation=\"h\",\n        labels={\"size\": \"size in byte(s)\"},\n        template=template,\n    ).update_traces(width=0.4)\n    .update_layout(autosize=True)\n)\n        \ndcc.Graph(id=\"memory_bar\", figure=figure, className=\"dbc\")\n\nIs it possible depending on number of entires, the height can be auto-resized? Also I am using orient as horrizontal. I tried autosize=true but got no effect on height it remains same.\n",
"AnswerId": "76396484",
"AnswerBody": "It is possible to define a dynamic width and height based on the dataframe:\n\nThe number of categories can be found with dataframe['field'].nunique() (assuming you are using pandas). It will impact the height of the figure (since the bar chart is horizontal)\nThe number of entries can be found with dataframe.shape[0] and will impact the width of the figure. You could be more precise if you use dataframe.groupby(\"field\").count()[\"size\"].max() instead. It returns the maximum entry per category.\n\nThen, we can define two methods for computing height and width of the figure:\ndef num_fields_based_height(num_fields: int) -> int:\n    padding = 150 # arbitrary value depending on legends\n    row_size = 100 # arbitrary value\n    return padding + row_size * num_fields\n\ndef num_entries_based_width(num_entries: int) -> int:\n    padding = 150 # arbitrary value depending on legends\n    entry_size = 100 # arbitrary value\n    return padding + entry_size * num_entries\n\nThen call this methods when declaring the figure:\nfigure = (\n    px.bar(\n        data_frame=dataframe,\n        x=\"size\",\n        y=\"field\",\n        title=\"Memory Usage\",\n        text=\"size\",\n        width=num_entries_based_width(dataframe.shape[0]),\n        height=num_fields_based_height(dataframe['field'].nunique()),\n        orientation=\"h\",\n        labels={\"size\": \"size in byte(s)\"},\n    )\n)\n\nNow you need to find the right parameters (padding, entry_size, row_size) for your scenario.\n"
},
{
"QuestionId": "76397539",
"QuestionTitle": "Rendering a Polygon in Pyglet using GL_TRIANGLES - KeyError 'v' Error",
"QuestionBody": "I am trying to render a polygon using the GL_TRIANGLES mode for pyglet.graphics.draw but have been running into issues.\nI have been attempting to render it like I've seen people do in many other places\ndef draw(self):\n    pyglet.graphics.draw(\n       size=int(len(self.coords) / 2), \n       mode=pyglet.gl.GL_TRIANGLES,\n       position=('v2f', self.coords),\n    )\n\nbut have been running into the following error:\n  File \"C:\\Python311\\Lib\\site-packages\\pyglet\\graphics\\__init__.py\", line 52, in draw\n    gl_type = vertexdomain._gl_types[fmt[0]]\n              ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'v'\n\nDid the usage change? Not sure exactly what I'm doing wrong here.\n",
"AnswerId": "76397621",
"AnswerBody": "v2f is the old format specification. In Pyglet Version 2.0, this has changed. See the documentation of draw(size, mode, **data). The first parameter is the number of vertices and each vertex has to have 3 components. The format is just f for float. e.g.:\nself.coords = [x0, y0, z0, x1, y1, z1, ...]\n\npyglet.graphics.draw(\n    size = len(self.coords) // 3,\n    mode = pyglet.gl.GL_TRIANGLES,\n    position = ('f', self.coords)\n)\n\nNote that this will draw only black triangles. Set the colors  attribute to draw a colorful shape.\nMinimal example:\n\nimport pyglet\n\nwindow = pyglet.window.Window(800, 600)\n\nvertices = [100, 100, 0, 300, 100, 0, 200, 300, 0]\ncolors = [255, 0, 0, 255, 0, 255, 0, 255, 0, 0, 255, 255]\n\n@window.event\ndef on_draw():\n    window.clear()\n    pyglet.graphics.draw(\n        size = 3, \n        mode = pyglet.gl.GL_TRIANGLES, \n        position = ('f', vertices),\n        colors = ('Bn', colors))\n    \npyglet.app.run()\n\n"
},
{
"QuestionId": "76394514",
"QuestionTitle": "Switching between Tkinter screens with withdraw() method on button click",
"QuestionBody": "Everything here works just fine but I haven't found a way to make it so that when I press the start button   it withdraws the Main Menu screen and displays the next one. It already creates the second screen when I run the code and it withdraws the MainMenu Screen before I even click the start button.\nhttps://replit.com/@AbdullahKaran/ConfusedSophisticatedFolders#main.py\n",
"AnswerId": "76394813",
"AnswerBody": "work on how you ask questions, as this can lead to your account being blocked. I've seen this happen before, so it's good advice.\nNow, you can do this by using the tkraise() method of the Frame widget. To learn more, please visit this website: https://www.pythontutorial.net/tkinter/tkraise/\n"
},
{
"QuestionId": "76396417",
"QuestionTitle": "Dependent names vs non-dependent names",
"QuestionBody": "In the following example:\ntemplate<typename T>\nstruct MyList {\n    typedef std::list<T> type1;\n};\n\ntemplate<typename T>\nclass MyList2 {\n    typename MyList<T>::type1 type2;\n};\n\nI thought that both type1 and type2 are dependent name since both of their types depend on the template parameter. However, why is the first one considered non-dependent since I can use typedef with it?\n",
"AnswerId": "76396495",
"AnswerBody": "A dependent name is, in C++ terms, a name whose grammatical properties are dependent on a template parameter.\nNames can mean a lot of different things in C++, and the grammatical location where a name can be used depends on certain properties of that name. In order to understand what X x; is trying to do, the compiler needs to know what X is at this point in the program. If X names a type, then this is declaring a variable named x. The compiler doesn't need to know everything about X, but grammatically, in order to even begin to make sense of this text, the compiler does need to know that X here names a type.\nstd::list is the name of a class template; the compiler can easily see that because that's how it is declared. It doesn't need to have the body of the declaration; template<typename T> class list; is sufficient. std::list<T> is an instantiation of a class template, so just from the declaration, the compiler knows that this is the name of a type.\nHowever, MyList<T>::type1 now requires more than just the declaration of the MyList template. It requires actually instantiating that template. And if T is itself a template parameter of the current code (as is the case for MyList2), then instantiation at the point of initially compiling the code is impossible. That instantiation must be delayed until MyList2 is itself given a concrete T to work with.\nBut the compiler still has to make sense of this code: typename MyList<T>::type1 type2;. And to do that, it needs some idea of what MyList<T>::type1 actually is. Without instantiating MyList<T>.\nWhich is why you have to tell it that it is a typename.\n"
},
{
"QuestionId": "76397594",
"QuestionTitle": "Get parameters from JavaThread* before a call takes place",
"QuestionBody": "I am currently working on a c++ project that interacts with the JVM, more specifically I have a block of code that will run before some Java function ( lets call it funcABC ) runs, within this block of code I am able to read/write the registers and stack of the JVM.\nI am able to get a JavaThread* ptr out of a register, and so far I have successfully been able to get important data from that JavaThread instance such as the JNIEnv and the thread state.\nThis is done by reconstructing the JavaThread structure in ReClass.NET, allowing me to access the variables stored within the structure.\nI would like to also get the parameters that are being passed to funcABC, I am told that they are stored somewhere within the JavaThread structure, so far I have not been able to find them, I dont see anything within the jdk sources that would suggest where they might be.\nDoes anyone know how and where they are stored in the JavaThread?\nAs an alternative I tried getting the parameters directly from the stack, only to find that there is no consistent layout, the parameters will be in a random order, sometimes on the stack and sometimes within registers like rdi, r9, and r8, or both, their positions/order also change during runtime.\nBy printing all the registers and a large chunk of the stack I was able to find them, they are all there, but using them in this current state is beyond impractical unless there is some sort of field somewhere that specifics where everything is located in that particular call, but I cant find anything like that.\n",
"AnswerId": "76397628",
"AnswerBody": "In the JVM, the method parameters are typically passed on the stack or stored in registers, depending on the platform's calling convention. However, the exact layout and location of these parameters can be complex and implementation-dependent. As you have observed, the layout may change during runtime, making it challenging to reliably extract the parameters directly from the stack or registers.\nTo access the parameters passed to funcABC, you may need to dig deeper into the JVM implementation and examine the bytecode interpretation and method invocation process. The JVM uses a bytecode instruction set, and the parameters are usually pushed onto the stack before the method is invoked. The JVM then retrieves the parameters from the stack and places them in appropriate locations, such as registers or stack frames, for the method to access.\nSince you are already working with the JavaThread structure and have access to the JNIEnv and thread state, you might consider examining the thread's stack frames. The stack frames store local variables, including method parameters, and their layout can be platform-specific. You may need to navigate through the stack frames to locate the specific frame corresponding to funcABC and extract the parameters from there. However, keep in mind that accessing stack frames directly can be challenging and error-prone.\nAnother option is to leverage JVM debugging interfaces, such as the Java Debug Interface (JDI), which provides a higher-level abstraction for inspecting and manipulating JVM internals. The JDI allows you to programmatically interact with the JVM, inspect variables, and retrieve method arguments using a more convenient API.\nI would recommend consulting JVM-specific documentation, such as the OpenJDK source code or documentation for the particular JVM implementation you are working with. Additionally, exploring JVM debugging and profiling tools might provide insights into how to access method parameters at runtime.\nKeep in mind that manipulating JVM internals at such a low level can be fragile and might lead to unpredictable behavior. Exercise caution and thoroughly test your code to ensure it works reliably across different JVM versions and configurations.\n"
},
{
"QuestionId": "76394498",
"QuestionTitle": "handling 401 in angular, how does pipe work really?",
"QuestionBody": "I am using Angular 14 and making a post request to my json server using the pattern like this:\nmyApiCall(data:any): Observable<any> {\n  return this.http.post<any>(url, data).pipe(catchError(this.handleError));\n}\n\n( as specified in https://angular.io/guide/http)\nAnd then wanted to add 401 (unauthorized) handling to handleError\nso I added this block\n  if (error.status===401){//UnAthorized\n    this.router.navigate(['login']);\n  }\n\nto my handleError like so:\nprivate handleError(error: HttpErrorResponse) {\n  if (error.status===401){//UnAthorized\n    this.router.navigate(['login']);\n  }\n...\n  return throwError(\n    () => new Error('Something bad happened; please try again later.')\n  );\n\n}\nI can see in debugger that this.router.navigate(['login']); is hit, but it does not navigate to the login screen.  same code does work in another place.\nThe error in chrome console is :\nERROR TypeError: Cannot read properties of (has file and line see below for details) undefined (reading 'router')\n    at handleError (line where this.router.navigate(['login']); is)\n    at catchError.js:10:39\n    at OperatorSubscriber._error (OperatorSubscriber.js:23:21)\n    ...\n\nThe top in call stack in the error is the .subscribe after myApiCall...\nSo what happens to handleError when I call\nthis.router.navigate(['login']);\n\nDoes it cause a return? And if so what gets returned ?\nUPDATE\nAfter Igor's suggestion of adding\nreturn of([]) \n\nAND declaring handleError with ()=>{} syntax instead of normal, it worked.\nI wonder why the second part is needed. I still suspect it has something to do with how pipe works.\nThis works:\nprivate handleError = (error: HttpErrorResponse) => { \n  if (error.status===401)//UnAthorized\n  {\n    this.router.navigate(['login']);\n    return of([]);\n  } \n  ...\n  return throwError(\n    () => new Error('Something bad happened; please try again later.')\n  );  \n}\n\nThis does not\nprivate handleError(error: HttpErrorResponse){ \n  if (error.status===401)//UnAthorized\n  {\n    this.router.navigate(['login']);\n    return of([]);\n  } \n  ...\n  return throwError(\n    () => new Error('Something bad happened; please try again later.')\n  );  \n}\n\nAfter this.router.navigate instead of hitting return, control is transferred to the caller that results in an error that mentions router.\nWhy?\nSECOND UPDATE:\nActually the first part (return of...) is not necessary to make it work, only the second (making it a lambda expression) is enough.\n",
"AnswerId": "76394825",
"AnswerBody": "Try this:\nmyApiCall(data:any): Observable<any> {\n  return this.http.post<any>(url, data).pipe(\n    catchError((err) =>\n        if (err.status===401){\n          // Redirect if unhautorized\n          this.router.navigate(['login']);\n        }\n        ...\n    );\n}\n\nNote the lambda syntax of the error handler declaration. It is required in order to pass in the context (this). Without it the 'router' is not known hence the error. More details here\n"
},
{
"QuestionId": "76396165",
"QuestionTitle": "How to create a spatial gridlines using Latitude and Longitude in R",
"QuestionBody": "How to create a gridline of 7*7 sqkm using Latitude and Longitude values. These values should be the centroid value of a single square in the grid. I am not sure if I am doing it in the right way. I tried st_make_grid from sf (Simple Features) library but that shows me an empty plot.\nMyGrid <- st_make_grid(DF, cellsize = c(0.07, 0.07), square = TRUE, crs = 4326) \n\nBelow is my example DF\nDF <- structure(list(lat = c(43.25724, 43.25724, 43.25724, 43.25616, \n43.25616, 43.25616), lon = c(-96.01955, -95.98172, -95.92336, \n-96.40973, -96.25733, -96.17735)), class = \"data.frame\", row.names = c(NA, \n6L))\n\n## > DF\n##        lat       lon\n## 1 43.25724 -96.01955\n## 2 43.25724 -95.98172\n## 3 43.25724 -95.92336\n## 4 43.25616 -96.40973\n## 5 43.25616 -96.25733\n## 6 43.25616 -96.17735\n\nThanks\n",
"AnswerId": "76396510",
"AnswerBody": "from the documentation of st_make_grid:\n\nCreate a square or hexagonal grid covering the\nbounding box of the geometry of an sf or sfc object\n\n\nso you need to convert your dataframe of point coordinates to an sf-object \"the_points\" (and reproject to a projection accepting metric length units):\n\nlibrary(sf)\n\nthe_points <- \n    st_sf(geometry = DF[c('lon', 'lat')] |>\n              as.matrix() |>\n              st_multipoint() |>\n              st_sfc() |>\n              st_cast('POINT'),\n          crs = 4326 ## geographic data (in degrees)\n          ) |>\n    ## convert to projected coordinates (to specify dimensions in m\n    ## take Google Mercator as first guess (EPSG-code 3857)\n    st_transform(3857)\n\n\ncreate grid (note that your points have only about 100 m latitudinal range):\n\nthe_grid <- \n    st_make_grid(n = c(10, 1), cellsize = 7e3 ## 7000 km)\n\n\ninspect result:\n\nplot(the_grid)\nplot(the_points, add = TRUE)\n\n\n"
},
{
"QuestionId": "76397550",
"QuestionTitle": "incorrect array index being rendered using react tsx upon deletion of an index",
"QuestionBody": "basically I'm creating a flashcards kind of application, where you can either go through the flashcards (which is an array) or you can edit them. in the editing phase, 2 input boxes get rendered with a button next to them where you can edit the text or you can delete that entire index. the problem lies with deletion, once the delete button is clicked, in the the correct index is deleted in the array which I verified using console logs, but in the UI the bottom index gets removed. so like lets say I have an array with 4 indexes, and i delete the 2nd, the UI will display 1 2 3, but the array it self will have 1 3 4. not really sure how to fix it but here is my code:\nconst [flashcardsState, setFlashcardsState] = useState(flashcards);\n\nconst handleDeleteClick = (index: number) => {\n        const updatedFlashcards = [...flashcardsState];\n        updatedFlashcards.splice(index, 1);\n        setFlashcardsState(updatedFlashcards);\n}\nconst handleCardChange = (cardIndex: number, fieldIndex: number, newValue: string) => {\n        const updatedFlashcards = [...flashcardsState];\n        updatedFlashcards[cardIndex][fieldIndex] = newValue;\n        setFlashcardsState(updatedFlashcards);\n};\n\nconst renderEdit = () =>{\n        return (\n            <div className=\"card-container\">\n                <div className=\"inputcardstext\">\n                    <h4>Front</h4>\n                    <h4>Back</h4>\n                </div>\n                {flashcardsState.map((flashcardsState, index) => (\n                    <div key={index}>\n                        <div className=\"inputcards\">\n                            <input\n                                type=\"text\"\n                                className='front-back'\n                                defaultValue={flashcardsState[0]}\n                                onChange={(e) => handleCardChange(index, 0, e.target.value)}\n\n                            />\n                            <input\n                                type=\"text\"\n                                className='front-back'\n                                defaultValue={flashcardsState[1]}\n                                onChange={(e) => handleCardChange(index, 1, e.target.value)}\n                            />\n                            <button onClick={() => handleDeleteClick(index)}></button>\n                        </div>\n                    </div>\n                ))}\n            </div>\n        );\n}\n\n",
"AnswerId": "76397649",
"AnswerBody": "It's deleting the right element, your issue is that you're using the array index as they key in React (<div key={index}>), which is a no-no. You're seeing this issue because of a combination of the array key as an index and defaultValue.\nTL;DR chose a different key, like\n  const flashcards = [\n    [\"key\", \"a\", \"1\"],\n    [\"key\", \"b\", \"2\"],\n    [\"key\", \"c\", \"3\"]\n  ];\n  const [flashcardsState, setFlashcardsState] = useState<string[][]>(\n    flashcards\n  );\n\n  //...\n\n        {flashcardsState.map((flashcardsState, index) => (\n          <div key={flashcardsState[2]}>\n            ...\n          </div>\n        ))}\n\nSee this example on Codepen.\nOr, you can see your removal is working correctly if you change defaultValue to value (I explain why below).\nYou should also install ESLint which will warn you against using an array key as an index.\nWhat's happening is you've told React each element's unique identifier is the array index. The first element in your array has index 0. React says \"ok, I'll render element with id 0, and I'll remember what I rendered, to compare it later.\"\nThen you remove element at index 0, but your array still has an element at index 0. So you give your new array back to React. React then says:\n\n\"Ok I have the same element here with id 0, so I only need to change it if the new render of id 0 is different from what I already have\nReact re-renders element with \"id\" 0, and even though it's a different element in the array, the render output is identical. This is because defaultValue is only set on first render, not on subsequent ones.\nReact says \"ok, nothing in id 0 has changed, I'll move on and not update the DOM\nReact gets to \"id\" of 2, the last element in the array, and sees \"ah, there is no longer an id of 2, I shall remove the last component in the list for you.\n\n"
},
{
"QuestionId": "76395825",
"QuestionTitle": "Efficient way to change the class of several matrices in R",
"QuestionBody": "I have several matrices and I would like to apply something like\nclass(matrix) <- \"numeric\" to all of them at once, i.e. the class of all matrices should be changed to numeric.\nDo you know how to do this?\ndput(matrix[1:3,]) results in structure(c(285.789361223578, 282.564165145159, 273.633228540421,  256.789452806115, 260.808130130172, 241.718192100525, 266.765343174338,  267.881099879742, 250.710165724158, 284.365977942944, 281.670583188534,  268.735618144274, 264.118778035045, 262.856532484293, 254.31867428124,  286.250801086426, 284.585711210966, 268.984649181366, 286.17267370224,  284.429456442595, 267.478255555034, 275.10055847466, 274.141056537628,  259.477523118258, 246.454664766788, 252.470473349094, 232.699362188578,  284.998321458697, 283.73363442719, 269.555955678225, 0, 0, 0), dim = c(3L,  11L), dimnames = list(NULL, c(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",  \"\", \"\", \"vec\")))\n",
"AnswerId": "76396539",
"AnswerBody": "In this examples all matrix variables of the current environment are converted to numeric.\nSee the warning in the case where matrix cannot be converted to numeric.\nvar1 <- matrix(1:10, 5, 2)\nvar2 <- matrix(as.character(5:13), 3,3)\nvar3 <- letters[1:5]\nvar4 <- matrix(letters[1])\n\nprint(sapply(mget(ls()), typeof))\n#>        var1        var2        var3        var4 \n#>   \"integer\" \"character\" \"character\" \"character\"\n\nfor (i in ls()[sapply(mget(ls()), is.matrix)])\n  assign(i, as.numeric(get(i)))\n#> Warning in assign(i, as.numeric(get(i))): NAs introduced by coercion\n\nprint(sapply(mget(ls()), typeof))\n#>           i        var1        var2        var3        var4 \n#> \"character\"    \"double\"    \"double\" \"character\"    \"double\"\n\nCreated on 2023-06-03 with reprex v2.0.2\n"
},
{
"QuestionId": "76396002",
"QuestionTitle": "Authentication between Azure Web PubSub and server",
"QuestionBody": "There is a simple ASP.NET app as an event handler Server:\nWebApplicationBuilder builder = WebApplication.CreateBuilder(args);\nbuilder.Services\n    .AddWebPubSub(options => options.ServiceEndpoint = new ServiceEndpoint(WebPubSubConnectionString))\n    .AddWebPubSubServiceClient<WebPubSubHub>();\n\nWebApplication app = builder.Build();\n\napp.MapWebPubSubHub<WebPubSubHub>(\"/eventhandler\");\napp.Run();\n\nThe Azure Web PubSub has the following configuration of Webhook URL:\n\nI need to protect this endpoint somehow /eventhandler because it's public and anyone can call it. One of the options that Azure suggests is using a simple authentication code.\n\nHelp me to understand where I should verify that code in my ASP.NET app?\nLet's say I configured the URL template in WPS like\nhttps://a9e5-92-253-212-316.ngrok-free.app/eventhandler?code=RRRRR\n\nthen in the server code\napp.MapWebPubSubHub<WebPubSubHub>(\"/eventhandler?code=RRRRR\")\n\nresult is exception\n\nMicrosoft.AspNetCore.Routing.Patterns.RoutePatternException: 'The\nliteral section 'eventhandler?code=RRRRR' is invalid. Literal sections\ncannot contain the '?' character.'\n\n",
"AnswerId": "76396544",
"AnswerBody": "One possible way is to use AddEndpointFilter\napp.MapWebPubSubHub<WebPubSubHub>(\"/eventhandler\").AddEndpointFilter(new ApiKeyFilter(builder.Configuration));\n\nthe implementation could look like this:\npublic class ApiKeyFilter : IEndpointFilter\n{\n    private readonly string _apiKey;\n\n    public ApiKeyFilter(IConfiguration configuration)\n    {\n        _apiKey = configuration.GetValue<string>(\"ApiKey\");\n    }\n\n    public async ValueTask<object> InvokeAsync(EndpointFilterInvocationContext context, EndpointFilterDelegate next)\n    {\n        if (!context.HttpContext.Request.Query.TryGetValue(\"code\", out var extractedApiKey))\n        {\n            return Results.Unauthorized();\n        }\n\n        if (!_apiKey.Equals(extractedApiKey))\n        {\n            return Results.Unauthorized();\n        }\n\n        return await next(context);\n    }\n}\n\nanother option is to use\napp.MapWebPubSubHub<WebPubSubHub>`(\"/eventhandler\").RequireAuthorization(builder => builder.AddRequirements(new ApiKeyRequirement))\n\nwhere ApiKeyRequirement is your implementation of IAuthorizationRequirement\n"
},
{
"QuestionId": "76394476",
"QuestionTitle": "How to convert milliseconds to seconds units and display them in textView?",
"QuestionBody": "How to convert milliseconds to seconds units?\nFor example the seekBar values are from 100 to 1000 and I want to display the units if they are under 1000(second) as 0.1 0.2 0.3....0.9 then 1\nprivate var counter: Long = 0\n\n    @RequiresApi(Build.VERSION_CODES.O)\n    override fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        setContentView(R.layout.activity_main)\n\n        val textView = findViewById<TextView>(R.id.textView)\n        val seek = findViewById<SeekBar>(R.id.seekBar)\n        seek.min = 100\n        seek.max = 1000\n        seek.progress = 500\n        counter = seek.progress.toLong()\n\n        seek.setOnSeekBarChangeListener(\n            object : SeekBar.OnSeekBarChangeListener {\n                override fun onProgressChanged(\n                    seekBar: SeekBar?,\n                    progress: Int,\n                    fromUser: Boolean\n                ) {\n                    counter = progress.toLong()\n                    textView.text = (counter/1000).toString()\n\nThe line:\ntextView.text = (counter/1000).toString()\nmake it that if the bar is on the right side it will display 1 but then to the left it will display only 0.\nand I want that on the right end it will display 1 but then when moving it to the left it will display 0.9 then 0.8 then 0.7.....0.1\nI tried:\ntextView.text = (counter/1000).toString()\n",
"AnswerId": "76394841",
"AnswerBody": "Change the data type of counter from Long to Float or Double. Long only allows integer values.\nprivate var counter: Float = 0.0F\n...\ncounter = seek.progress.toFloat()\n\n"
},
{
"QuestionId": "76396150",
"QuestionTitle": "Unbound module Sqlite3",
"QuestionBody": "I am trying to learn some OCaml, I created a very simple example to open and then close a sqlite file.\nlet () =\n  let db = Sqlite3.db_open \"test.db\" in\n  Sqlite3.db_close db\n\nI did an opam install sqlite3 and I see the .opam/default/lib/sqlite3 files in place. I would expect this means that the package is installed.\nWhen I run ocaml sqltest.ml I would expect this to execute. Instead I get a Error: Unbound module Sqlite3\nEven when I make it ocaml -I +sqlite3 sqltest.ml I get the same result. It's kind of hard to search for info on ocaml and most of the stuff I find is using dune or ocamlbuild or ocamlfind or something... I think that's fine, but in the interest of starting with the basics and building from there I would like to understand how all of the pieces are working. I'd imagine the basic ocaml or ocamlc should work in this simple case.\nHow do I make it understand where these libs are and use them? Why does it not understand it's own \"default libs\"?\n",
"AnswerId": "76396550",
"AnswerBody": "Using ocamlfind to compile a trivial demonstration program that opens the Sqlite3 module.\n$ cat test.ml\nopen Sqlite3\n\nlet () = print_endline \"hello\"\n$ ocamlc test.ml\nFile \"test.ml\", line 1, characters 5-12:\n1 | open Sqlite3\n         ^^^^^^^\nError: Unbound module Sqlite3\n$ ocamlfind ocamlc test.ml -package sqlite3 -linkpkg\n$ ./a.out\nhello\n\nAlternative use of ocamlfind:\n$ ocamlc -I `ocamlfind query sqlite3` sqlite3.cma test.ml\n$ ./a.out\nhello\n\nAs a side note, your code will not compile even with proper use of the compiler and ocamlfind because Sqlite3.db_close returns a boolean, you're trying to bind that expression to (). This is a type mismatch.\nAnd you've opened Sqlite3 so you don't need to use the fully qualified names. You might want to use let& to avoid the db_close.\nopen Sqlite3\n\nlet () =\n  let& db = db_open \"test.db\" in\n  print_endline \"hello\"\n\n"
},
{
"QuestionId": "76397627",
"QuestionTitle": "ggplot - reorder_within - Order month",
"QuestionBody": "I am plotting a bar graph. However, the axes x show in different month order. Using the command reoder_within, doesn't work for the purpose.\nFollow below the ME.\nggplot(de, aes(fill=Cidade, y = Leitura  , x = Mes ))+geom_bar(position='dodge', stat='identity')\n\nGenerate the follow plot:\nPlot\nMy purpose is modify the axes x to: Jan, Fev, March .....\nThe set of data is:\n  Cidade    Mes       Leitura\n  <chr>     <chr>       <dbl>\n1 Petrolina Janeiro     74.2 \n2 Petrolina Fevereiro   73.2 \n3 Petrolina Março       68.7 \n4 Petrolina Abril       42.9 \n5 Petrolina Maio         9.84\n6 Petrolina Junho        8.02\n\n",
"AnswerId": "76397651",
"AnswerBody": "We can use fct_inorder here:\nggplot will order x axis alphapetically. To get the order in your table use fct_inorder:\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(dplyr)\n\nde %>% \n  mutate(Mes = fct_inorder(Mes)) %>% \n  ggplot(aes(fill = Cidade, y = Leitura, x = Mes)) +\n  geom_bar(position = 'dodge', stat = 'identity')\n\n\n"
},
{
"QuestionId": "76396027",
"QuestionTitle": "How to define a command alias in PowerShell for filtering output?",
"QuestionBody": "I need to define an alias for this:\nSelect-String -NotMatch -Pattern \"^[\\t ]+\\d\"\nso that I can use the alias instead of writing that long string each time.\nAfter googling for 5 minutes and doing some experiments I came up with this:\nfilter foo {\n    $_ | Select-String -NotMatch -Pattern \"^[\\t ]+\\d\"\n}\n\nSo now my script looks like this:\ncommand1 | foo\ncommand2 | foo\ncommand3 | foo\ncommand4 | foo\n\nThis is apparently working as expected, but I'm concerned about the efficiency implications of doing this.\nIs the foo filter acting as a transparent alias of the longer command line, or is it creating an entire new pipe or buffer or something?\n",
"AnswerId": "76396561",
"AnswerBody": "\nIs the foo filter acting as a transparent alias of the longer command line, or is it creating an entire new pipe or buffer or something?\n\nThe latter, your current implementation is invoking Select-String per pipeline input object instead of invoking it once and processing all input. If you care about performance you should change your implementation for a steppable pipeline:\nfunction steppablefoo {\n    param([Parameter(ValueFromPipeline)] $InputObject)\n\n    begin {\n        $pipe = { Select-String -NotMatch -Pattern '^[\\t ]+\\d' }.GetSteppablePipeline()\n        $pipe.Begin($PSCmdlet)\n    }\n    process {\n        $pipe.Process($InputObject)\n    }\n    end {\n        $pipe.End()\n    }\n}\n\nYou can test it for yourself with this performance comparison:\n$tests = @{\n    Filter = {\n        0..300kb | foo\n    }\n    SteppablePipeline = {\n        0..300kb | steppablefoo\n    }\n}\n\n$tests.GetEnumerator() | ForEach-Object {\n    [pscustomobject]@{\n        Test              = $_.Key\n        TotalMilliseconds = (Measure-Command { & $_.Value }).TotalMilliseconds\n    }\n}\n\n"
},
{
"QuestionId": "76396418",
"QuestionTitle": "Why do I receive an access violation error in my SFML C++ project when passing object and function pointers?",
"QuestionBody": "I'm currently learning c++ and I'm working on my first game using SFML/TGUI. I have tried making a function that creates a button, which in turn calls on a function when pressed. In an effort to make the button creator smarter and more versitile, I have made it so that it takes an object pointer and a function pointer as parameters. When the button then gets pressed, I want it to be able to call a member function from the object that was passed to it. It should also be noted that I got it working for a while, but then I changed something and now it doesn't work.\nIn my main.cpp, I create a gui and a pointer to this gui. I then pass the pointer into my Utility class, which consists of static variables and functions:\n//Create gui object\ntgui::GuiSFML gui{ window };\n\n//Create pointer to gui object\ntgui::GuiSFML* guiPointer = &gui;\n\n//Pass guiPointer into Utility class\nUtility::setup_getGuiPointer(guiPointer);\n\nThis is what is in my Utility class:\n//Static gui pointer in Utility\nstatic tgui::GuiSFML* guiPointer;\n\n//Passes gui pointer from main into Utility\nstatic void Utility::setup_getGuiPointer(tgui::GuiSFML* passedGuiPointer)\n{\n    guiPointer = passedGuiPointer;\n}\n\nThe create button function in my utility class looks like this,\n//Takes arguments: ObjectPtr, FunctionPtr, Size, Pos and Text to create button\ntemplate<typename Class>\ninline tgui::Button::Ptr& Utility::u_createButton(Class* object, void(Class::* functionPointer)(tgui::GuiSFML* guiPointer, tgui::Button::Ptr& button), tgui::Layout2d size, tgui::Layout2d position, std::string buttonText)\n{\n        //Creates the button\n    tgui::Button::Ptr button = tgui::Button::create(buttonText);\n\n        //Sets size and position\n    button->setSize(size);\n    button->setPosition(position);\n\n        //Adds button to gui\n    guiPointer->add(button);\n\n        //Sets onPress on the button to call the passed function from the passed objects,\n        //passing the gui pointer and button pointer into this function.\n    button->onPress([&]() { (object->*functionPointer)(guiPointer, button); });\n\n        //Returns button pointer if it's needed before onPress.\n    return button;\n}\n\nNow, I can then create a custom button from inside any class using the following line:\nUtility::u_createButton(this, &ClassName::FunctionName, size, position, text;\n\nAnd I create a button inside one of my classes, and the function that I pass a pointer to is just:\nvoid ClassName::FunctionName(tgui::GuiSFML* guiPointer, tgui::Button::Ptr& button)\n{\n    std::cout << \"Button Pressed\" << std::endl;\n\n        //The reson behind the passed arguments is so that the function itself can delete\n        //the button after use if needed using the following line:\n    //guiPointer->remove(button);\n}\n\nWhen I run this, it creates a button but gives the following error when I press it:\nUnhandled exception at 0x85EEB600 in GUI_SFML_Template.exe: 0xC0000005: Access violation executing location 0x00000000.\n\nThe current stack frame was not found in a loaded module. Source cannot be shown for this location.\n\nI don't understand why I get this error, though I believe it has something to do with my objects and functions trying to write onto the gui without the proper access to it. I would be very grateful if anybody could help me.\n",
"AnswerId": "76396580",
"AnswerBody": "Your lambda is capturing by reference, all the local variables it captures references to will cause undefined behaviour when the button is pressed as the local variables will have gone out of scope. You should capture by value instead:\nbutton->onPress([object, functionPointer, guiPointer, button]() { (object->*functionPointer)(guiPointer, button); });\n\nGenerally lambdas capturing all by reference are only safe to use within the function they're declared in and shouldn't be stored for long term use.\n"
},
{
"QuestionId": "76394772",
"QuestionTitle": "Remove whitespace from an array of string",
"QuestionBody": "Remove whitespace from an array of string.\nWhile creating an array of string from a sentence, I'm encountering multiple spaces and need to remove them in order to create a new reverse sentence from the given sentence. How do I remove extra spaces in the middle of two words?\nExample: a good   example\nHow do I remove two spaces in between good and example ?\nHere is the code I'm using:\npublic class reverseString {\n    public static void main(String[] args) {\n        String s = \"a good   example\";\n        String ans = revString(s);\n        System.out.println(ans);\n    }\n    static String revString(String s) {\n        String[] arr = s.split(\" \");\n        List<String> list = new ArrayList<String>();\n        StringBuilder ans = new StringBuilder();\n        for (int i = arr.length - 1; i >= 0; i--) {\n            if (arr[i] == null) {\n                continue;\n            } else {\n                ans.append(arr[i].trim());\n                // ans.append(\" \");\n            }\n        }\n        String is = ans.toString();\n        return is.trim();\n    }\n}\n\nThe expected output was: example good a\nThe output I'm getting is: example   good a\nComparing the string at the I-th index with \" \" should result in continuation of the loop. Instead it jumps to the else condition.\n",
"AnswerId": "76394849",
"AnswerBody": "The parameter to method split (of class java.lang.String) is a regular expression. Just add a + (i.e. \"plus\" symbol – which means one or more) to the value of the parameter.\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class ReverseString {\n\n    public static void main(String[] args) {\n        String s = \"a good   example\";\n        String ans = revString(s);\n        System.out.println(ans);\n\n    }\n\n    static String revString(String s) {\n        String[] arr = s.split(\" +\"); // CHANGE HERE - added '+'\n        List<String> list = new ArrayList<String>();\n        StringBuilder ans = new StringBuilder();\n        for (int i = arr.length - 1; i >= 0; i--) {\n            if (arr[i] == null) {\n                continue;\n            }\n            else {\n                ans.append(arr[i].trim());\n                ans.append(\" \");\n            }\n        }\n        String is = ans.toString();\n        return is.trim();\n    }\n}\n\nRunning the above code produces the following output:\nexample good a\n\n"
},
{
"QuestionId": "76381579",
"QuestionTitle": "Is there a way to listen for changes in p-columnFilter match options and call a function in Angular and PrimeNG?",
"QuestionBody": "Is it possible to bind a function that gets called every time user chooses between matchOption of p-columnFilter.\n<p-columnFilter type=\"date\">\n...\n</p-columnFilter>\n\n\nexample: https://stackblitz.com/edit/owuvzd?file=src%2Fapp%2Fdemo%2Ftable-filter-menu-demo.html\n",
"AnswerId": "76394860",
"AnswerBody": "I was able to find a workaround to this, by creating my own matchModeOptions and their filter functions.\nTo do this I made use of FilterService\npublic dateIsFilter: string = \"is-date\";\n\npublic matchModeOptions: any[] = [\n  { label: \"Date is\", value: this.dateIsFilter }\n]\n\nconstructor(private filterService: FilterService){\n}\n\nngOnInit(): void {\n  this.filterService.register(this.dateIsFilter, (value: any, filter: any) => {\n  // code here\n  return this.filterService.filters.dateIs(value, filter)\n});\n}\n\nThen I changed p-columnFilter to use custom matchModeOptions.\n<p-columnFilter type=\"date\" [matchModeOptions]=\"this.matchModeOptions\">\n...\n</p-columnFilter>\n\n\n"
},
{
"QuestionId": "76397575",
"QuestionTitle": "Laravel issue creating new user",
"QuestionBody": "I want to fix an error regarding an unassigned variable, but I don't know where to define it:\n\nUse of unassigned variable '$userInfo'PHP(PHP1412)\n\nThe error is occuring in this line $accessToken = $userInfo->createToken(uniqid())->plainTextToken;.\nThis is my code:\npublic function createUser(Request $request)\n{\n    try {\n        // Validate\n\n        $validateUser = Validator::make($request->all(), [\n            'avatar' => 'required',\n            'type' => 'required',\n            'open_id' => 'required',\n            'name' => 'required',\n            'email' => 'required|email|unique:users,email',\n        ]);\n\n        if ($validateUser->fails()) {\n            return response()->json([\n                'status' => false,\n                'message' => 'validation error',\n                'errors' => $validateUser->errors()\n            ], 401);\n        }\n\n        // validated, will have all user field values\n        // we can save in the database\n        $validated = $validateUser->validated();\n\n        $map = [];\n        // email, phone, facebook, apple\n        $map['type'] = $validated['type'];\n        $map['open_id'] = $validated['open_id']; // if there is user in our database\n        $user = User::where($map)->first();\n\n        $user = User::where($map)->first();\n\n        // whether user have already logged in or not\n        // empty means does not exist\n        // this token is user id\n        if (empty($user->id)) {\n            // this certain user has never been in our website\n            // our job is to assign the user to database\n            // this token is user id\n            $validated[\"token\"] = md5(uniqid().rand(10000,99999));\n            // user first time created\n            $validated['created_at'] = Carbon::now();\n            // returns the id of row after saving\n            $userID = User::insertGetId($validated); // we return the userid\n            // users all info will be here\n            $userInfo = User::where(\"id\", \"=\", $userID)->first();\n\n            $accessToken = $userInfo->createToken(uniqid())->plainTextToken;\n\n            $userInfo->access_token = $accessToken;\n\n            return response()->json([\n                'status' => true,\n                'message' => 'User Created Successfully',\n                'data' => $userInfo\n            ], 200);\n        }\n\n        $accessToken = $userInfo->createToken(uniqid())->plainTextToken;\n        $userInfo->access_token = $accessToken;\n        return response()->json([\n            'status' => true,\n            'message' => 'User Logged In Successfully',\n            'token' => $userInfo\n        ], 200);\n    } catch (\\Throwable $th) {\n        return response()->json([\n            'status' => false,\n            'message' => $th->getMessage()\n        ], 500);\n    }\n}\n\n",
"AnswerId": "76397661",
"AnswerBody": "The variable $userInfo is not defined before the line where the error is occurring. To fix this issue, you need to define $userInfo before using it. Replace the variable $userInfo with $user in the last part of the code.\npublic function createUser(Request $request)\n{\n    try {\n        // Validated\n        $validateUser = Validator::make($request->all(), [\n            'avatar' => 'required',\n            'type' => 'required',\n            'open_id' => 'required',\n            'name' => 'required',\n            'email' => 'required|email|unique:users,email',\n        ]);\n\n        if ($validateUser->fails()) {\n            return response()->json([\n                'status' => false,\n                'message' => 'validation error',\n                'errors' => $validateUser->errors()\n            ], 401);\n        }\n\n        // Validated, will have all user field values\n        // We can save in the database\n        $validated = $validateUser->validated();\n\n        $map = [];\n        $map['type'] = $validated['type'];\n        $map['open_id'] = $validated['open_id'];\n        $user = User::where($map)->first();\n\n        // Whether user has already logged in or not\n        // Empty means does not exist\n        // This token is user id\n        if (empty($user->id)) {\n            // This certain user has never been on our website\n            // Our job is to assign the user to the database\n            // This token is user id\n            $validated[\"token\"] = md5(uniqid() . rand(10000, 99999));\n            // User first time created\n            $validated['created_at'] = Carbon::now();\n            // Returns the id of row after saving\n            $userID = User::insertGetId($validated);\n            // Users all info will be here\n            $userInfo = User::where(\"id\", \"=\", $userID)->first();\n\n            $accessToken = $userInfo->createToken(uniqid())->plainTextToken;\n            $userInfo->access_token = $accessToken;\n\n            return response()->json([\n                'status' => true,\n                'message' => 'User Created Successfully',\n                'data' => $userInfo\n            ], 200);\n        }\n\n        $accessToken = $user->createToken(uniqid())->plainTextToken;\n        $user->access_token = $accessToken;\n\n        return response()->json([\n            'status' => true,\n            'message' => 'User Logged In Successfully',\n            'token' => $user\n        ], 200);\n\n    } catch (\\Throwable $th) {\n        return response()->json([\n            'status' => false,\n            'message' => $th->getMessage()\n        ], 500);\n    }\n}\n\n"
},
{
"QuestionId": "76394425",
"QuestionTitle": "How can I convert an array with key-value pairs to an array with separate sub-arrays for the keys and values in PHP?",
"QuestionBody": "Converting an array [fields => values] to one [fields, values]\nIf I have an array like this:\n[\nfield1 => value1,\nfield2 => value2,\nfield3 => value3\n];\n\nand I want to convert it to an array like this:\n[\n[field1, field2, field3],\n[value1, value2, value3]\n];\n\nnow I just took the keys and values and put them in another array:\n[\narray_keys($array),\narray_values($array)\n];\n\nIs there a more elegant way to do this?\n",
"AnswerId": "76394893",
"AnswerBody": "Before considering \"elegant\", first consider output consistency.  If you always want to create an array with two first level elements, your approach is suitable.\nHowever, if you want an empty output array when your input array is empty, you'll need a different approach where the result array is only deepened when necessary such as...\nCode: (Demo)\n$result = [];\nforeach ($array as $k => $v) {\n    $result[0][] = $k;\n    $result[1][] = $v;\n}\nvar_export($result);\n\n\nIf you always want a two-element result, a body-less loop can avoid making any function calls in a concise way. (Demo)\n$result = [[], []];\nforeach ($array as $result[0][] => $result[1][]);\nvar_export($result);\n\n\nFunctional programming with array_reduce() can become ugly/verbose for this task. (Demo)\nvar_export(\n    array_reduce(\n        array_keys($array),\n        function ($result, $k) use ($array) {\n            $result[0][] = $k;\n            $result[1][] = $array[$k];\n            return $result;\n        },\n        []\n    )\n);\n\nAnd if you are considering array_walk(), that is just going to work like a foreach() anyhow because it doesn't deliver its result payload as a returned value.\n\nIf you consider functional programming to be elegant, bear in mind that double-transposing with array-map() calls will not work when there is one element or less in your input array. Proof\n"
},
{
"QuestionId": "76396496",
"QuestionTitle": "How to have child div not trigger hover effect of parent div?",
"QuestionBody": "I am trying to find out how to have a child element that has position: absolute that is positioned outside of its parent element that does not trigger the parent's :hover effect.\nSince the parent has a hover effect, the child elements will  trigger the parent element, even though that child is outside of the parent element's boundary.\nIs there an attribute I am missing, or is this just the way inheritance in HTML works?\nPicture Example:\n\nIn this image, my mouse cursor is inside the child div, but outside of the parent div.\n\n\nbody {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n.container {\n  background-color: black;\n  width: 800px;\n  aspect-ratio: 1 / 1;\n}\n\n.container:hover {\n  background-color: darkorange;\n}\n\n.child {\n  position: absolute;\n  background-color: red;\n  width: 100px;\n  height: 100px;\n  transform: translate(-50px, 0px);\n}\n<div class=\"container\">\n  <div class=\"child\"></div>\n</div>\n\n\n\n",
"AnswerId": "76396581",
"AnswerBody": "You can use following solutions for this.\n\nYou can use pointer-events: none on the child element. But remember that this will block all types of pointer events on that, and not just hover event. So any sort of click events will also not work on that child element.\n\nAnother option is to use :has() method in the css. :has() allows you to target an element that meets the conditions passed to it. You can do it like this -\n\n\n  .container:not(:has(.child:hover)):hover {\n    background-color: darkorange;\n  }\n        \n\nThis will prevent the hover effect on container when hovered over its child element, which is specified in the :has() method.\nHere is the JSFiddle example demonstrating this method.\nRead more about :has() in here\n"
},
{
"QuestionId": "76392269",
"QuestionTitle": "Executing RXJS Functions in Sequence Defined By Array",
"QuestionBody": "I am attempting to execute multiple functions consecutively by defining them in an array (specifically for an Angular APP_INITIALIZER function).\nI have this array:\nconst obsArray = [\n    myService1.init(),\n    myService2.init(),\n    ...\n    myServiceN.init()\n]\n\nEach of these init() methods returns Observable<void>. Here's an example:\n    init() : Observable<void> {\n         return this.http.get(this.apiUrl)\n             .pipe(\n                 // do something with the response\n                 switchMap(() => EMPTY)\n             );\n    }\n\nThe ``switchMapstatement ensures that the return type isObservable```.\nI've tried this:\n    const init$ : Observable<void> = forkJoin(obsArray);\n\nBut at best it executes the function but not the HTTP call inside. There is no subscribe() call since this is inside an Angular factory function assigned to the APP_INITIALIZER token.\nI've also tried concatMap() with no luck.\nIs there an rxjs function that will execute each of these consecutively, while waiting for the previous to complete?\nI have followed this up with this question.\n",
"AnswerId": "76397689",
"AnswerBody": "You can also put all the observables from the array into an observable, essentially converting Array<Observable<T>> to Observable<Observable<T>> and then use the higher order function concatAll:\nfrom(obsArray).pipe(concatAll())\n\nHere's a live demo.\n"
},
{
"QuestionId": "76396395",
"QuestionTitle": "How can I extract text from single quotes, even if the text itself contains single quotes, using regex in Python?",
"QuestionBody": "I'm trying to extract data from a .txt file and while my regex did work for the most part, it fails when it comes across single quotes within the text I'm trying to extract.\n{'pro_id':'1692423', 'pro_model':'SKUF42051', 'pro_category':'accessories', 'pro_name':'Gants tactiques Escalade en plein air Gants antidérapants résistants à l'usure Formation Gants de moto d'équitation', 'pro_current_price':'27.99', 'pro_raw_price':'27.99', 'pro_discount':'36', 'pro_likes_count':'11'}\n\nThis is what my text in the .txt file looks like.\nI'm looping through and creating dicts from them. I do that by extracting the content from within the single quotes and appending the \"key\" and \"value\" pairs to a dict.\nI've first extracted the content from within the curly brackets, then split that at \", \" to get the \"items\" in a list, after which I looped through the list and used the regex in the command key, value = re.findall(r\"\\'([^']+)\\'\", element) to extract the \"key\" and \"value\".\nI'm a regex as well as a programming novice, so I could use some expert help.\nI did ask ChatGPT for a regex '([^']+(?:\\\\'[^']+)*?)':'([^']+(?:\\\\'[^']+)*?)' but that fails too.\nI want to get a list that holds\n['pro_name', 'Gants tactiques Escalade en plein air Gants antidérapants résistants à l'usure Formation Gants de moto d'équitation'] from re.findall\nbut instead I get\n['Gants tactiques Escalade en plein air Gants antidérapants résistants à l', 'équitation'].\n",
"AnswerId": "76396624",
"AnswerBody": "Your string is malformed. Strings containing literal single quotes should be enclosed in double quotes, else it can't be parsed correctly.\nIt is extremely difficult to use regex to sort this out, and also by using a for loop.\nBut I have discovered a way, I have found simple patterns. Since all strings are enclosed in single quotes, and the key value pairs are separated by commas followed by a space, and the keys are separated from values by single colons, it is easy to identify key value pairs by first split the string by \"', '\", then split each substring by \"':'\".\nYou can then convert it to dict, with cleanup if necessary.\nExample:\nimport re\n\ntext = \"{'pro_id':'1692423', 'pro_model':'SKUF42051', 'pro_category':'accessories', 'pro_name':'Gants tactiques Escalade en plein air Gants antidérapants résistants à l'usure Formation Gants de moto d'équitation', 'pro_current_price':'27.99', 'pro_raw_price':'27.99', 'pro_discount':'36', 'pro_likes_count':'11'}\"\narr = [i.split(\"':'\") for i in text.split(\"', '\")]\ndef clean(s):\n    return re.sub(\"^[{']+|[}']+$\", '', s)\n\n{clean(a): clean(b) for a, b in arr}\n\nThe result is:\n{'pro_id': '1692423',\n 'pro_model': 'SKUF42051',\n 'pro_category': 'accessories',\n 'pro_name': \"Gants tactiques Escalade en plein air Gants antidérapants résistants à l'usure Formation Gants de moto d'équitation\",\n 'pro_current_price': '27.99',\n 'pro_raw_price': '27.99',\n 'pro_discount': '36',\n 'pro_likes_count': '11'}\n\nWrap it in a function:\ndef dictify(text):\n    arr = [i.split(\"':'\") for i in text.split(\"', '\")]\n    return {clean(a): clean(b) for a, b in arr}\n\nI assume you have many more strings like the above in your text file, since I don't know the exact format, I can only demonstrate how to convert the file to a list of dicts as if it is newline separated.\nwith open('/path/to/file', 'r') as f:\n   text = f.read()\n[dictify(row) for row in text.split('\\n')]\n\nYou need to change the file path placeholder to the actual path. The above won't work if your file isn't newline separated.\nAnd my method won't work if your string deviates from the format, for example if there are spaces after the key-value delimiting colons, or there aren't spaces after the commas that separate key-value pairs.\nIf that is the case I cannot help you, you need to figure out a different method, but my example does work on the example you have given.\n"
},
{
"QuestionId": "76394871",
"QuestionTitle": "Cubic-bezier fixes exiting animation but breaks entering animation",
"QuestionBody": "I'm trying to animate a collapsing list with React/Joy-UI\nHere is my Transition element\n     <Transition nodeRef={nodeRef} in={browseOpen} timeout={1000}>\n      {(state: string) => (<List\n        aria-labelledby=\"nav-list-browse\"\n        sx={{\n          '& .JoyListItemButton-root': { p: '8px' },\n          transition: '1000ms',\n          transitionProperty: 'max-height',\n          overflow: 'hidden',\n          ...{\n            exiting: { maxHeight: '0px'},\n            exited: { maxHeight: '0px'},\n            entering: { maxHeight: '500px'},\n            entered: { maxHeight: '500px'},\n          }[state],\n        }}\n      >\n\nWith this the list expands fine, but there appears to be a delay on collapsing.\nI then added \"cubic-bezier(0, 1, 0, 1)\" to the \"transition\" property, which fixes the collapsing animation, but the expand animation then seems to break entirely.\nHow can I get both the entering and exiting working?\nBefore adding cubic bezier (sorry for the loss-y gifs):\n\nAfter adding cubic bezier:\n\n",
"AnswerId": "76394902",
"AnswerBody": "Found the answer:\nThe transition needed to be set like this:\ntransition: `1000ms ${state === \"exiting\" ? \"cubic-bezier(0, 1, 0, 1)\" : \"ease-out\"}`\n\nFor any other novices out there, note the backticks `` around the string rather than ''\n"
},
{
"QuestionId": "76394248",
"QuestionTitle": "Can I publish client ID?",
"QuestionBody": "I've coded beyond my ability and managed to get MSAL authentication working for my Browser Extension. I'm ready to push code to GitHub.\nIs it ok to push code with the Client ID in it? Can someone else use my Client ID? If I can't safely push this to a public GitHub, how do I handle it?\n// Microsoft Authentication Library (MSAL) instance\n// Client ID is the Application (client) ID GUID from the Azure portal\nconst msalInstance = new msal.PublicClientApplication({\n    auth: {\n        authority: \"https://login.microsoftonline.com/common/\",\n        clientId: \"ffffffff-ffff-ffff-ffff-ffffffffffff\",\n        redirectUri: redirectUri,\n        postLogoutRedirectUri: redirectUri\n    },\n    cache: {\n        cacheLocation: \"localStorage\"\n    }\n});\n\n",
"AnswerId": "76394918",
"AnswerBody": "Technically, it should be okay.\n\nIs it ok to push code with the Client ID in it?\n\nThe question you should ask yourself is, what information does the client ID give away? According to the Microsoft identity platform and the OAuth 2.0 client credentials flow a client_id is,\n\nThe Application (client) ID that the Azure portal – App registrations experience assigned to your app.\n\nIt is essentially like your name. It won't be end of the world if you give it away but you probably should not where there is no reason to.\nQuoting, Should the OAuth client_id be kept confidential?\n\nYour client_id is like your username or e-mail address you use to authenticate your application/service to OAuth. It's not exactly top-secret, but putting it out in the public domain might also be undesirable.\n\nFurther,\n\nCan someone else use my Client ID?\n\nYes, but even in the confidential client apps, \"The client ID is exposed through the web browser.\"\nNote that we can actually see the Thunderbird's client id exposed in their source code. It isn't really meant to be private information.\n\nIf I can't safely push this to a public GitHub, how do I handle it?\n\nYou can use a password manager if you are the only user of your extension.\n"
},
{
"QuestionId": "76397713",
"QuestionTitle": "Mixing grid auto layout with a fixed row-column position",
"QuestionBody": "I have the following HTML with a CSS grid\n<div id=\"grid\">\n    <div class=\"main-item\">Main</div>\n</div>\n\n#grid {\n    display: grid;\n    grid-template-columns: repeat(5, auto);\n    text-align: center;\n}\n\n#grid > * {\n    border: 1px solid blue;\n    padding: 20px;\n}\n\n#grid > .main-item {\n    grid-row: 3;\n    grid-column: 3 / 5;\n    background: rgba(0, 0, 0, 0.2);\n}\n\nThe important part is .main-item has a fixed position in the grid.\nI now add 25 cells to the grid.\nconst grid = document.querySelector(\"#grid\");\n\nfor (let i = 0; i < 25; i++) {\n    const item = document.createElement(\"div\");\n    item.innerText = i.toString();\n    grid.append(item);\n}\n\nThe problem is that I want these elements to ignore the position of the .main-item (treat it as if it wasn't there). However the CSS currently corrects for this and flows the elements around .main-item. I want the secondary behaviour below:\n\nI can correct by setting style.gridRow and style.gridColumn in the JavaScript\nitem.style.gridRow = (Math.floor(i / 5) + 1).toString();\nitem.style.gridColumn = ((i % 5) + 1).toString();\n\nIs there a way to do this without setting every other element in JS? Is there a CSS to prevent fixed element affecting the flow correction?\nCodepen Link\n",
"AnswerId": "76397738",
"AnswerBody": "You can give the grid a relative position and position that specific grid item absolutely.\n\n\nconst grid = document.querySelector(\"#grid\");\nfor (let i = 0; i < 25; i++) {\n    const item = document.createElement(\"div\");\n    item.innerText = i;\n    grid.append(item);\n}\n#grid {\n    display: grid;\n    grid-template-columns: repeat(5, auto);\n    text-align: center;\n    position: relative;\n}\n\n#grid > * {\n    border: 1px solid blue;\n    padding: 20px;\n}\n\n#grid > .main-item {\n    position: absolute;\n    left: 0;\n    right: 0;\n    grid-row: 3;\n    grid-column: 3 / 5;\n    background: rgba(0, 0, 0, 0.2);\n}\n<div id=\"grid\">\n    <div class=\"main-item\">Main</div>\n</div>\n\n\n\n"
},
{
"QuestionId": "76394958",
"QuestionTitle": "How to pass curly bracket ({) as a string in f-string python?",
"QuestionBody": "due to these bracket { and } in Hourly Status','{',''),'}','') causing the syntax error in query .How to pass these bracket as string in a f-string format?\nquery = f\"\"\"Select fd.serial_number,txidkey,cast(replace(replace(data->>'Hourly Status','{',''),'}','') as text) as description,TO_TIMESTAMP(TIME/1000+19800) as date_time,time,total_min from filter_data fd , total_sum ts\nwhere fd.serial_number = ts.serial_number\nand time between {yesterday10PM*1000} and {today6AM*1000}'''\n\n",
"AnswerId": "76394976",
"AnswerBody": "just use double curly braces {{:\nquery = f\"\"\"\\\nSelect fd.serial_number, txidkey, cast(\\\nreplace(replace(data->>'Hourly Status','{{',''),'}}','') as text) \\\nas description,TO_TIMESTAMP(TIME/1000+19800) as date_time,time,total_min \\\nfrom filter_data fd , total_sum ts \\\nwhere fd.serial_number = ts.serial_number \\\nand time between {yesterday10PM*1000} and {today6AM*1000}\n'''\n\nYou can also read about formatted strings here:\nhttps://docs.python.org/3/reference/lexical_analysis.html#formatted-string-literals\n"
},
{
"QuestionId": "76396569",
"QuestionTitle": "Calculating Collective Count of departments on individual dates from a given date range",
"QuestionBody": "I have the following table\n\n\n\n\nFunction\nDepartment\nStart Date\nEnd Date\n\n\n\n\nConst\nConst 1\n2023-03-01\n2023-03-05\n\n\nConst\nConst 2\n2023-03-02\n2023-03-03\n\n\nMining\nMining 1\n2023-03-02\n2023-03-05\n\n\nMining\nMining 2\n2023-03-01\n2023-03-06\n\n\nConst\nConst 1\n2023-03-03\n2023-03-07\n\n\nConst\nConst 2\n2023-03-02\n2023-03-05\n\n\nMining\nMining 1\n2023-03-06\n2023-03-09\n\n\nMining\nMining 2\n2023-03-05\n2023-03-08\n\n\n\n\nI want to get per date the total count in each department. Both start date and end date and included in counting.\nIt would be nice to have an intermediate output as follows\n\n\n\n\nFunction\nDepartment\nDate\nCount\n\n\n\n\nConst\nConst1\n2023-03-01\n1\n\n\nConst\nConst1\n2023-03-02\n1\n\n\nConst\nConst1\n2023-03-03\n2\n\n\nConst\nConst1\n2023-03-04\n2\n\n\nConst\nConst1\n2023-03-05\n2\n\n\nConst\nConst1\n2023-03-06\n1\n\n\nConst\nConst1\n2023-03-07\n1\n\n\nConst\nConst1\n2023-03-08\n0\n\n\nConst\nConst1\n2023-03-09\n0\n\n\nConst\nConst1\n2023-03-10\n0\n\n\nConst\nConst2\n2023-03-01\n0\n\n\nConst\nConst2\n2023-03-02\n2\n\n\nConst\nConst2\n2023-03-03\n2\n\n\nConst\nConst2\n2023-03-04\n1\n\n\nConst\nConst2\n2023-03-05\n1\n\n\nConst\nConst2\n2023-03-06\n0\n\n\nConst\nConst2\n2023-03-07\n0\n\n\nConst\nConst2\n2023-03-08\n0\n\n\nConst\nConst2\n2023-03-09\n0\n\n\nConst\nConst2\n2023-03-10\n0\n\n\nMining\nMining 1\n2023-03-01\n0\n\n\nMining\nMining 1\n2023-03-02\n1\n\n\nMining\nMining 1\n2023-03-03\n1\n\n\nMining\nMining 1\n2023-03-04\n1\n\n\nMining\nMining 1\n2023-03-05\n1\n\n\nMining\nMining 1\n2023-03-06\n1\n\n\nMining\nMining 1\n2023-03-07\n1\n\n\nMining\nMining 1\n2023-03-08\n1\n\n\nMining\nMining 1\n2023-03-09\n1\n\n\nMining\nMining 1\n2023-03-10\n0\n\n\nMining\nMining 2\n2023-03-01\n1\n\n\nMining\nMining 2\n2023-03-02\n1\n\n\nMining\nMining 2\n2023-03-03\n1\n\n\nMining\nMining 2\n2023-03-04\n1\n\n\nMining\nMining 2\n2023-03-05\n2\n\n\nMining\nMining 2\n2023-03-06\n2\n\n\nMining\nMining 2\n2023-03-07\n1\n\n\nMining\nMining 2\n2023-03-08\n1\n\n\nMining\nMining 2\n2023-03-09\n0\n\n\nMining\nMining 2\n2023-03-10\n0\n\n\n\n\nThe desired final output is a pandas df as follows\n\n\n\n\nDate\nConst 1\nConst 2\nMining 1\nMining 2\n\n\n\n\n2023-03-01\n1\n0\n0\n1\n\n\n2023-03-02\n1\n2\n1\n1\n\n\n2023-03-03\n2\n2\n1\n1\n\n\n2023-03-04\n2\n1\n1\n1\n\n\n2023-03-05\n2\n1\n1\n2\n\n\n\n",
"AnswerId": "76396655",
"AnswerBody": "df['Start Date'] = pd.to_datetime(df['Start Date'])\ndf['End Date'] = pd.to_datetime(df['End Date'])\n\ndates = pd.date_range(df['Start Date'].min(), df['End Date'].max()) #get the complete dates in data set\nfinal_df = pd.DataFrame({'Date': dates})\nfinal_df = final_df.set_index('Date')\n\ndepartments = df['Department'].unique()\n\nfor department in departments:\n    mask = (df['Department'] == department)\n    department_counts = (df.loc[mask, 'Start Date'].value_counts() + df.loc[mask, 'End Date'].value_counts()).sort_index()\n    final_df[department] = department_counts\n\nfinal_df = final_df.fillna(0)\n\n"
},
{
"QuestionId": "76397698",
"QuestionTitle": "Displaying colored text in windows console by linux codes (C++)",
"QuestionBody": "I'm writing game for project in VS Community 2017 in c++. I can see that coloring text works well in windows terminal, but I'm not sure if it'll be working on every windows compiler?  Is there any safer way to print colored text?\nExample code:\n#include <iostream>\n#include <Windows.h>\n\nusing namespace std;\n\nint main()\n{\n    cout<<\"\\033[34m\"<<\"Hello World in blue\\n\";\n    cout<<\"\\033[31m\"<<\"Hello World in red\\n\";\n    cout<<\"\\033[35m\"<<\"Hello World in purple\\n\";\n    return 0;\n}\n\n",
"AnswerId": "76397757",
"AnswerBody": "The compiler has little (if anything) to do with this. Your code just sends data. It's up to the terminal program to do something with that data.\nThere are some terminal programs that do, and others that don't interpret them well. Prior to Windows 10, the default Windows console didn't, so if you care about supporting older versions of Windows, it's not a great choice.\nSo, it depends on what you about. If you want portability to (current) Windows and Linux, what you're doing is fine. If you want portability to older versions of Windows...not so much.\nIf you need something that works for older Windows and don't care about Linux, you can Windows' console functions (e.g., WriteConsoleOutputAttribute or FillConsoleOutputAttribute).\nMy own advice would be to use some manipulators, so you'd do something like:\nconsole << blue << \"Hello world in blue\\n\";\nconsole << red << \"Hello world in red\\n\";\n\n...and when/if you need to move code to a different platform, you can rewrite just those manipulators. For Linux can current Windows you can send the ANSI escape sequences you already know about.\nSupporting manipulators like this on older versions of Windows isn't trivial, at least using actual cout. You need a Windows handle to the console. But it's pretty easy to do that, with an ostream, so writing to it works about like you'd normally expect.\nFor example:\n// winbuf.hpp\n#pragma once\n#include <ios>\n#include <ostream>\n#include <windows.h>\n\nclass WinBuf : public std::streambuf\n{\n    HANDLE h;\n\npublic:\n    WinBuf(HANDLE h) : h(h) {}\n    WinBuf(WinBuf const &) = delete;\n    WinBuf &operator=(WinBuf const &) = delete;\n\n    HANDLE handle() const { return h; }\n\nprotected:\n    virtual int_type overflow(int_type c) override\n    {\n        if (c != EOF)\n        {\n            DWORD written;\n            WriteConsole(h, &c, 1, &written, nullptr);\n        }\n        return c;\n    }\n\n    virtual std::streamsize xsputn(char_type const *s, std::streamsize count) override\n    {\n        DWORD written;\n        WriteConsole(h, s, DWORD(count), &written, nullptr);\n        return written;\n    }\n};\n\nclass WinStream : public virtual std::ostream\n{\n    WinBuf buf;\n\npublic:\n    WinStream(HANDLE dest = GetStdHandle(STD_OUTPUT_HANDLE))\n        : buf(dest), std::ostream(&buf)\n    {\n    }\n\n    WinBuf *rdbuf() { return &buf; }\n};\n\nclass SetAttr\n{\n    WORD attr;\n\npublic:\n    SetAttr(WORD attr) : attr(attr) {}\n\n    friend WinStream &operator<<(WinStream &w, SetAttr const &c)\n    {\n        WinBuf *buf = w.rdbuf();\n        auto h = buf->handle();\n        SetConsoleTextAttribute(h, c.attr);\n        return w;\n    }\n\n    SetAttr operator|(SetAttr const &r)\n    {\n        return SetAttr(attr | r.attr);\n    }\n};\n\nclass gotoxy\n{\n    COORD coord;\n\npublic:\n    gotoxy(SHORT x, SHORT y) : coord{.X = x, .Y = y} {}\n\n    friend WinStream &operator<<(WinStream &w, gotoxy const &pos)\n    {\n        WinBuf *buf = w.rdbuf();\n        auto h = buf->handle();\n        SetConsoleCursorPosition(h, pos.coord);\n        return w;\n    }\n};\n\nclass cls\n{\n    char ch;\n\npublic:\n    cls(char ch = ' ') : ch(ch) {}\n\n    friend WinStream &operator<<(WinStream &os, cls const &c)\n    {\n        COORD tl = {0, 0};\n        CONSOLE_SCREEN_BUFFER_INFO s;\n        WinBuf *w = os.rdbuf();\n        HANDLE console = w->handle();\n\n        GetConsoleScreenBufferInfo(console, &s);\n        DWORD written, cells = s.dwSize.X * s.dwSize.Y;\n        FillConsoleOutputCharacter(console, c.ch, cells, tl, &written);\n        FillConsoleOutputAttribute(console, s.wAttributes, cells, tl, &written);\n        SetConsoleCursorPosition(console, tl);\n        return os;\n    }\n};\n\nextern SetAttr red;\nextern SetAttr green;\nextern SetAttr blue;\nextern SetAttr intense;\n\nextern SetAttr red_back;\nextern SetAttr blue_back;\nextern SetAttr green_back;\nextern SetAttr intense_back;\n\nAlong with:\n// winbuf.cpp\n#include \"winbuf.hpp\"\n\n#define WIN32_LEAN_AND_MEAN\n#include <Windows.h>\n\nSetAttr red { FOREGROUND_RED };\nSetAttr green { FOREGROUND_GREEN };\nSetAttr blue { FOREGROUND_BLUE };\nSetAttr intense { FOREGROUND_INTENSITY };\n\nSetAttr red_back { BACKGROUND_RED };\nSetAttr blue_back { BACKGROUND_BLUE };\nSetAttr green_back { BACKGROUND_GREEN };\nSetAttr intense_back { BACKGROUND_INTENSITY };\n\n...and a quick demo:\n#include \"winbuf.hpp\"\n\nint main() {\n    WinStream w;\n\n    auto attrib = intense | blue_back;\n\n    w << attrib << cls() << \"Some stuff\";\n    w << gotoxy(0, 4) << (green | blue_back) << \"This should be green\";\n    w << gotoxy(0, 5) << attrib << \"And this should be grey\";\n}\n\n"
},
{
"QuestionId": "76394719",
"QuestionTitle": "Extract predefined URL text (starts with the same prefix) into an Array",
"QuestionBody": "I have files URLs text like these examples:\nhttp://xxxxx.pdf http://xxxxxxxxxxx.doc http://xxxxxxxxxxxxx.xls\nThe delimiter between each URL is not a space, it may be separated by vbTab , vbLf or what ever.\nBut in all cases the URLs start with the same prefix \"http:\" and end with a dot+three characters.\nI need to extract these predefined URLs into an Array to manipulate it later.\nI made the below code as a workaround, by using two arrays and also I had to start looping from the second element from the first array because I found there is extra \"http\" on the second array.\nMy question, Is there another neater code?\nSub Split_URLs_to_Array()\n\n  Dim wDoc As Word.Document, rngSel As String\n  Dim arrS, arrD, i As Long\n  \n  Set wDoc = Application.ActiveInspector.WordEditor\n  \n  rngSel = Trim(wDoc.Windows(1).Selection.Text)\n\n  arrS = Split(rngSel, \"http\")\n  \n  ReDim arrD(0 To UBound(arrS))\n  \n   For i = 1 To UBound(arrS)\n       arrD(i) = \"http\" & arrS(i)\n     Debug.Print arrD(i)\n   Next\n\nEnd Sub \n \n\n",
"AnswerId": "76394978",
"AnswerBody": "\nYou asked (yesterday) about a way to extract URLs from a string, separated by no any separator... The next function will do it:\n\nFunction SplitByStartOfString(strTxt As String, strDelim As String) As Variant\n  Dim arr: arr = Split(strTxt, strDelim)\n  \n  arr(0) = \"@#$%^\": arr = filter(arr, \"@#$%^\", False) 'eliminate the first empty element\n  SplitByStartOfString = Split(strDelim & Join(arr, \"|\" & strDelim), \"|\")\nEnd Function\n\nIt can be tested in the next way:\nSub testSplitByStartOfString()\n   Dim x As String: x = \"https://myurl1/x.pdfhttps://myurl2/y.xlsxhttps://myurl3/z.docx\"\n   Dim arr\n   arr = SplitByStartOfString(x, \"https:\")\n   Debug.Print Join(arr, \"||\") 'just to visually see the array result.\nEnd Sub\n\nOf course, you can use what strings you know, the delimiter will be the common prefix of each of them...\nAnd end of line separators or VbTab exists, the above code will also work, but these separators will be included of the end of the string. Which, for URL in Outlook will not count. They will only be arranged using the respective separator.\n1.1 Another function, using FilterXML may be the next one:\nFunction splitXMLByStartOfString(strText As String, strDelim As String) As Variant\n    Dim XML As String: XML = \"<t><s>\" & VBA.Replace(strText, strDelim, \"</s><s>\" & strDelim) & \"</s></t>\"\n    splitXMLByStartOfString = Application.FilterXML(XML, \"//s[position()>1]\")  'nodes starting from the second one...\n    'splitXMLByStartOfString = Application.FilterXML(XML, \"//s[count(node())>0]\")   'another working way (all not empty nodes)\n    'splitXMLByStartOfString = Application.FilterXML(XML, \"//s[starts-with(., '\" & strDelim & \"')]\") 'working way, too (nodes starting with strDelim)\nEnd Function\n\nIt can be tested using the next sub:\nSub TestFilterXMLHttp()\n   Dim x As String: x = \"https://myurl1/x.pdfhttps://myurl2/y.xlsxhttps://myurl3/z.docx\"\n   Dim arr: arr = splitXMLByStartOfString(x, \"https:\") 'It returns a 2D, 1 column array...\n  \n   Debug.Print Join(Application.Transpose(arr), \"||\")\nEnd Sub\n\nThe above function works well and fast, but in Excel. The question does not mention that it should be used in Outlook VBA (but I knew about that...). So, the next solution uses an automation from Outlook, and use Excel.Application it this way. This version needs an Excel session open, but it can be easily adapted to open a new one if nothing open:\nFunction splitXMLByStartOfString(strText As String, strDelim As String, objEx As Object) As Variant\n   \n    Dim XML As String: XML = \"<t><s>\" & VBA.Replace(strText, strDelim, \"</s><s>\" & strDelim) & \"</s></t>\"\n    splitXMLByStartOfString = objEx.FilterXML(XML, \"//s[position()>1]\")  'nodes starting from the second one...\n    'splitXMLByStartOfString = Application.FilterXML(XML, \"//s[count(node())>0]\")   'another working way (all not empty nodes)\n    'splitXMLByStartOfString = Application.FilterXML(XML, \"//s[starts-with(., '\" & strDelim & \"')]\") 'working way, too (nodes starting with strDelim)\nEnd Function\n\nAnd the sub to test it, using the above mentioned automation:\nSub TestFilterXMLHttp()\n   Dim objEx As Object: Set objEx = GetObject(, \"Excel.application\")\n   Dim x As String: x = \"https://myurl1/x.pdfhttps://myurl2/y.xlsxhttps://myurl3/z.docx\"\n   Dim arr: arr = splitXMLByStartOfString(x, \"https:\", objEx) 'It returns a 2D, 1 column array...\n  \n   Debug.Print Join(objEx.Transpose(arr), \"||\")\nEnd Sub\n\n\nExtracting an array from string elements separated by one from more supposed separators can be extracted using the next function:\n\nFunction extractFromStringSep(strText As String) As Variant\n   Dim arrC: arrC = Array(vbTab, vbLf) 'you can extend the supposed separators...\n   Dim El\n   \n   For Each El In arrC\n        If InStr(strText, El) > 0 Then\n            extractFromStringSep = Split(strText, El): Exit Function\n        End If\n   Next El\nEnd Function\n\nOf course, the string to be extracted must NOT contain the supposed separators...\nIt can be tested like in the next sub:\nSub TestextractFromStringSep()\n   Dim x As String: x = \"https://myurl1/x.pdf\" & vbTab & \"https://myurl2/y.xlsx\" & vbTab & \"https://myurl3/z.docx\"\n          'x = \"https://myurl1/x.pdf\" & vbLf & \"https://myurl2/y.xlsx\" & vbLf & \"https://myurl3/z.docx\"\n   Dim arr\n   arr = extractFromStringSep(x)\n   Debug.Print Join(arr, \"||\") 'just to visually see the array result.\nEnd Sub\n\n\nAnd a last version, also allowing part of the url string as separator (only for didactic purpose):\n\nFunction extractFromStrAndSep(strText As String, strDelim As String) As Variant\n     Dim arrC: arrC = Array(vbTab, vbLf, \"myur\") 'you can extend the supposed separators...\n     Dim El\n     \n     For Each El In arrC\n        If InStr(strText, El & strDelim) > 0 Then\n            extractFromStrAndSep = Split(strText, El & strDelim): Exit Function\n        End If\n   Next El\nEnd Function\n\nTested with the next (adapted) sub:\nSub TestextractFromStrAndSep()\n   Dim x As String: 'x = \"https://myurl1/x.pdf\" & vbTab & \"https://myurl2/y.xlsx\" & vbTab & \"https://myurl3/z.docx\"\n          'x = \"https://myurl1/x.pd\" & vbLf & \"https://myurl2/y.xlsx\" & vbLf & \"https://myurl3/z.docx\"\n          x = \"https://myurl1/x.pd\" & \"myur\" & \"https://myurl2/y.xlsx\" & \"myur\" & \"https://myurl3/z.docx\"\n   Dim arr\n   arr = extractFromStrAndSep(x, \"https:\")\n   Debug.Print Join(arr, \"||\") 'just to visually see the array result.\nEnd Sub\n\n"
},
{
"QuestionId": "76387096",
"QuestionTitle": "Why are the fitting results of the Arima() and glm() function different?",
"QuestionBody": "I am confused about the difference in the fitting results of the Arima() function and glm() function.\nI want to fit an AR(1) model with an exogeneous variable. Here is the equation:\n$$\nx_{t} = \\alpha_{0} + \\alpha_{1}x_{t-1} + \\beta_{1}z_{t} + \\epsilon_{t}\n$$\n\nNow I estimate this model using the Arima() function and glm() function and compare the results, but the results turned out to be quite different!\nHere is the sample data. x denotes the time-series variable, and z denotes the exogeneous variable, as shown in the equation above.\nlibrary(forecast)\nlibrary(tidyverse)\ndata(\"Nile\")\ndf <- \n  Nile %>% \n  as_tibble() %>% \n  mutate(x = as.numeric(x)) %>% \n  mutate(z = rnorm(100))\n\nThen fit the model using the Arima() and glm() and compare the results.\nfit_arima <- Arima(df$x, order = c(1, 0, 0), include.mean = TRUE, xreg = df$z)\ntibble(Parameters = c(\"x lag\", \"intercept\", \"z\"),\n       Coefficients = coef(fit_arima),\n       Standard_Errors = sqrt(diag(vcov(fit_arima))))  \nfit_glm <- glm(df$x ~ lag(df$x) + df$z) \ntibble(Parameters = c(\"intercept\", \"x lag\", \"z\"),\n       Coefficients = coef(fit_glm),\n       Standard_Errors = summary(fit_glm)$coefficients[, \"Std. Error\"])\n\nThe results are displayed as follows.\nArima() function:\n# A tibble: 3 × 3\n  Parameters Coefficients Standard_Errors\n  <chr>             <dbl>           <dbl>\n1 x lag             0.510          0.0868\n2 intercept       920.            29.4   \n3 z                 5.02          12.1    \n\nglm() function:\n# A tibble: 3 × 3\n  Parameters Coefficients Standard_Errors\n  <chr>             <dbl>           <dbl>\n1 intercept       444.            83.4   \n2 x lag             0.516          0.0896\n3 z                 8.95          13.9 \n\nThe estimated coefficient and standard error of x lag are quite close, but the values of other two variables are very different. I find this puzzling because both the Arima() and glm() function use the maximum likelihood estimator. Could you please explain why this difference happens and how can I fix this?\n",
"AnswerId": "76394984",
"AnswerBody": "First, Arima() does not fit the model given in your equation. It fits a regression with ARIMA errors like this:\nx_{t} = \\alpha_{0} + \\beta_{1}z_{t} + \\eta_{t}\n\nwhere\n\\eta_t = \\phi_{1}\\eta_{t-1}+\\varepsilon_{t}.\n\nWe can rearrange this to give\nx_{t} = (1-\\phi_{1})\\alpha_{0} + \\phi_{1}x_{t-1} + \\beta_{1}z_{t} - \\beta_{1}\\phi_{1}z_{t-1} + \\varepsilon_{t}\n\nThis explains the major differences in the two results.\nBut even if you specified exactly the same model, they would give slightly different results because Arima() uses the true likelihood whereas glm() will use a conditional likelihood because of the initial missing value due to the lag() function.\nSee https://robjhyndman.com/hyndsight/arimax/ for a discussion of the different model specifications.\n"
},
{
"QuestionId": "76397650",
"QuestionTitle": "Is there a better/faster way to fill one vector with contents of another (smaller) vector than using a for loop?",
"QuestionBody": "I'm trying to figure out a better solution to fill a vector with another vector whill avoiding loops. Is it even possible? Maybe using address range or something else?\nThis is my working code which does exactly what I need but slowly:\n#include <iostream>\n#include <vector>\n#include <string>\n\ntypedef std::vector<std::vector<int>> Vec2i;\n\nvoid Vec2DPrinter(Vec2i vec)\n{\n    size_t vec_h = vec.size();\n\n    for (size_t y = 0; y < vec_h; y++)\n    {\n        size_t vec_w = vec.at(y).size();\n\n        for (size_t x = 0; x < vec_w; x++)\n        {\n            std::cout << vec.at(y).at(x);\n        }\n\n        std::cout << std::endl;\n    }\n}\n\nvoid Vec2DFiller(Vec2i &dest, Vec2i src, int dest_x, int dest_y)\n{\n    int src_h = (int)src.size();\n\n    // Loop to fill dest vector with elements of src vector at specific coords\n    for (int y = 0; y < src_h; y++)\n    {\n        int src_w = (int)src.at(y).size();\n        int dest_h = (int)dest.size();\n\n        if ((y + dest_y) >= dest_h)\n        {\n            break;\n        }\n\n        if ((y + dest_y) < 0)\n        {\n            continue;\n        }\n\n        int dest_w = (int)dest.at(y + dest_y).size();\n\n        for (int x = 0; x < src_w; x++)\n        {\n            if (x + dest_x >= dest_w)\n            {\n                break;\n            }\n\n            if (x + dest_x < 0)\n            {\n                continue;\n            }\n\n            dest.at(y + dest_y).at(x + dest_x) = src.at(y).at(x);\n        }\n    }\n}\n\nint main(void)\n{\n    // This is just visual example (i know how to fill vectors)\n    Vec2i dest =\n    {\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }\n    };\n\n    Vec2i src =\n    {\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 }\n    };\n\n    std::cout << \"Destination contents (before change):\" << std::endl;\n    Vec2DPrinter(dest);\n    std::cout << \"\\nSurce contents:\" << std::endl;\n    Vec2DPrinter(src);\n\n    // Destination coords\n    int dest_x = 3;\n    int dest_y = 4;\n\n    // Key function to fill one vector with another\n    Vec2DFiller(dest, src, dest_x, dest_y);\n\n    std::cout << \"\\nDestination contents (after change):\" << std::endl;\n    Vec2DPrinter(dest);\n\n    std::string exit = \"\";\n    std::getline(std::cin, exit);\n\n    return 0;\n}\n\nKey part:\n// Destination coords\nint dest_x = 3;\nint dest_y = 4;\n\nint src_h = (int)src.size();\n\n// Loop to fill dest vector with elements of src vector at specific coords\nfor (int y = 0; y < src_h; y++)\n{\n    int src_w = (int)src.at(y).size();\n    int dest_h = (int)dest.size();\n\n    if ((y + dest_y) >= dest_h)\n    {\n        break;\n    }\n\n    if ((y + dest_y) < 0)\n    {\n        continue;\n    }\n\n    int dest_w = (int)dest.at(y + dest_y).size();\n\n    for (int x = 0; x < src_w; x++)\n    {\n        if (x + dest_x >= dest_w)\n        {\n            break;\n        }\n\n        if (x + dest_x < 0)\n        {\n            continue;\n        }\n\n        dest.at(y + dest_y).at(x + dest_x) = src.at(y).at(x);\n    }\n}\n\nThis is the best solution I could come with. (Not the same but similar. The original one has single but wide if statement so it wouldn't fit on a single line here so that is why I changed it a bit.)\nThe reason why I want to do this is pretty simple.\nI'm doing this thousand times a second and on a bigger scale, that is why.\nI was searching on the web and found things like std::fill and std::copy but none of them meets my requirements. (std::fill is not what I need and std::copy is an algorithm that consists of loop.)\n",
"AnswerId": "76397766",
"AnswerBody": "As with all performance questions, the solution is going to depend heavily on the hardware and software being used and the particulars of the test conditions. In this case, for example, the dataset size is relevant.\nWith that caveat, I was able to improve the performance by over 4x on my platform (M1, MacOSX, clang). Your mileage will vary. I moved the conditional checks out of the inner loop and used std::copy for the actual work. For larger dataset sizes, I suspect the speedup will be greater.\nI used the timer library for measuring performance.\nPerformance could be improved further by using a native 2D storage structure like a matrix or std::mdspan instead of a std::vector of std::vector.\nSample Code\n#include <iostream>\n#include <vector>\n#include <string>\n#include \"core/timer/timer.h\"\n\nusing std::cout, std::endl;\n\ntypedef std::vector<std::vector<int>> Vec2i;\n\nvoid Vec2DPrinter(Vec2i vec) {\n    size_t vec_h = vec.size();\n    for (size_t y = 0; y < vec_h; y++) {\n        size_t vec_w = vec.at(y).size();\n        for (size_t x = 0; x < vec_w; x++)\n            std::cout << vec.at(y).at(x);\n        std::cout << std::endl;\n    }\n}\n\nvoid Vec2DFiller(Vec2i &dest, Vec2i src, int dest_x, int dest_y) {\n    int src_h = (int)src.size();\n\n    // Loop to fill dest vector with elements of src vector at specific coords\n    for (int y = 0; y < src_h; y++) {\n        int src_w = (int)src.at(y).size();\n        int dest_h = (int)dest.size();\n\n        if ((y + dest_y) >= dest_h)\n            break;\n\n        if ((y + dest_y) < 0)\n            continue;\n\n        int dest_w = (int)dest.at(y + dest_y).size();\n\n        for (int x = 0; x < src_w; x++) {\n            if (x + dest_x >= dest_w)\n                break;\n\n            if (x + dest_x < 0)\n                continue;\n\n            dest.at(y + dest_y).at(x + dest_x) = src.at(y).at(x);\n        }\n    }\n}\n\nvoid Vec2DFiller2(Vec2i &dest, const Vec2i& src, int dest_x, int dest_y) {\n    int ylen = std::min(src.size(), dest.size() > dest_y ? dest.size() - dest_y : 0);\n    if (ylen == 0)\n        return;\n\n    int xlen = std::min(src.at(0).size(), dest.at(0).size() - dest_x);\n    if (xlen == 0)\n        return;\n\n    for (auto ydx = 0; ydx < ylen; ++ydx) {\n        auto& ydest = dest.at(ydx + dest_y);\n        const auto& ysrc = src.at(ydx);\n        std::copy(ysrc.data(), ysrc.data() + xlen, ydest.data() + dest_x);\n    }\n}\n\nint main(void)\n{\n    // This is just visual example (i know how to fill vectors)\n    Vec2i dest =\n    {\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }\n    };\n\n    Vec2i src =\n    {\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 },\n        { 1, 1, 1, 1, 1 }\n    };\n\n    std::cout << \"Destination contents (before change):\" << std::endl;\n    Vec2DPrinter(dest);\n    std::cout << \"\\nSurce contents:\" << std::endl;\n    Vec2DPrinter(src);\n\n    // Destination coords\n    int dest_x = 3;\n    int dest_y = 4;\n\n    // Key function to fill one vector with another\n    auto ns = core::timer::Timer().run(1'000'000, [&]() {\n        Vec2DFiller(dest, src, dest_x, dest_y);\n    }).elapsed_per_iteration();\n    cout << ns << \" ns / op\" << endl;\n\n    ns = core::timer::Timer().run(1'000'000, [&]() {\n        Vec2DFiller2(dest, src, dest_x, dest_y);\n    }).elapsed_per_iteration();\n    cout << ns << \" ns / op\" << endl;\n\n    std::cout << \"\\nDestination contents (after change):\" << std::endl;\n    Vec2DPrinter(dest);\n\n    return 0;\n}\n\nRelevant Output\n142.167 ns / op\n30.4702 ns / op\n\n"
},
{
"QuestionId": "76394895",
"QuestionTitle": "Problems with Alamofire and Swift closures",
"QuestionBody": "I have the following class with a function that returns a boolean value using alamofire.\nclass Productos: Codable{\n    \n    // MARK: Propiedades de los productos\n    var id_producto : String = \"\"\n    var producto_es : String = \"\"\n    var id_seccion : String = \"\"\n   \n    init(id_producto : String = \"\", producto_es : String = \"\", id_seccion : String = \"\"){\n        self.id_producto = id_producto\n        self.producto_es = producto_es\n        self.id_seccion = id_seccion\n    }\n\n    func hayProductosNuevos(ultimoProductoEnBd: Int, completion: @escaping (Bool) -> Void) {\n        let urlWS = Globales().urlWS//Url para la webservice\n      \n        AF.request(urlWS+\"actualiza_productos.php?ultimo_producto=\\(ultimoProductoEnBd)\",method: .get).responseDecodable(of: [Productos].self) { responseConsulta in\n            switch responseConsulta.result{\n                case .success(let actualizacionDeProductos):\n                    if (actualizacionDeProductos.isEmpty){\n                        completion(false)\n                    } else {\n                        completion(true)\n                    }\n                case .failure(let error):\n                    print(\"hay un error \\(String(describing: error.errorDescription))\")\n            }\n         }\n    }\n}\n\nMy problem is how to call it and control what is returned to me from my view:\n\nI know that within a view I cannot call it that. The idea is if I return true, perform a product update and display a ProgressView.\nI have tried everything I have been reading, using its init() in the view. But I get another error.\n\nI think my problem is that from Alamofire I need to know if I have to update my application's data or not, that's why it returns true or false, but I'm not clear about the use of closures, so I don't know how I have to call Alamofire from my view so I can control the data.\n",
"AnswerId": "76395000",
"AnswerBody": "This approach is wrong, you cannot put the model which is used in an array   containing multiple instances and the controller to load the data in the same object. Well actually you can do it but then you have to create static APIs which is bad practice though.\nFirst of all declare the object representing a product as struct named in singular form and without the logic to load the data.\nstruct Producto: Decodable {\n    \n    // MARK: Propiedades de los productos\n    var id_producto : String \n    var producto_es : String\n    var id_seccion : String\n}\n\nAnd it's highly recommended to use camelCase struct member names, but this is beyond the question. And if the values will never change declare the struct members as constants (let).\n\nThen create a class conforming to ObservableObject for the logic to load the data with a @Published property for the products and a method to load the data. A completion handler is not needed, assign (or append) the result to the array. Actually AF is not needed either for a simple GET request, built-in URLSession and JSONDecoder can do the same.\n@MainActor\nclass ViewModel : ObservableObject {\n    @Published var productos = [Producto]()\n\n    func hayProductosNuevos(ultimoProductoEnBd: Int) {\n        let urlWS = Globales().urlWS //Url para la webservice\n      \n        AF.request(urlWS+\"actualiza_productos.php?ultimo_producto=\\(ultimoProductoEnBd)\",method: .get).responseDecodable(of: [Producto].self) { responseConsulta in\n            switch responseConsulta.result {\n                case .success(let actualizacionDeProductos):\n                    self.productos = actualizacionDeProductos\n                    // or self.productos.append(contentsOf: actualizacionDeProductos)\n                case .failure(let error):\n                    print(\"hay un error\", error)\n            }\n         }\n    }\n}\n\n\nIn the view create an instance of ViewModel as @StateObject and load the data in onAppear\nstruct ActualizarProductos : View {\n    @StateObject private var viewModel = ViewModel()\n    @State private var ultimoProductoEnBd = 0\n\n    var body: some View {\n        NavigationView {\n          // UI stuff\n        }\n        .onAppear {\n            viewModel.hayProductosNuevos(ultimoProductoEnBd: ultimoProductoEnBd)\n        }\n    }\n}\n\nThe ultimoProductoEnBd is not handled in the question, it's just an example adding a @State property.\n"
},
{
"QuestionId": "76396627",
"QuestionTitle": "Why am I getting a syntax error when using modulo on floats in my fragment shader?",
"QuestionBody": "I'm new to using the fragment shader. Why does my code raise a syntax error? I can't understand why it doesn't work. This is the piece of code that raises the error:\nif ((int) pos.y % 9 == 1) shade = 1;\n\nBoth pos.y and shade are floats. I've put (int) before pos.y so that I could use modulo on it. The error message says this:\nERROR: 0:17: ')' : syntax error syntax error\n\nI'm taking the error to mean I have too many or to few brackets, but I checked that and my code seems fine. Why is there an error, and what can I do to solve it?\n",
"AnswerId": "76396665",
"AnswerBody": "GLSL is not C. As stated in the GLSL specification:\n\nThere is no typecast operator; constructors are used instead.\n\nAs such, (int) is not a thing in GLSL. If you want to convert some float to an int, you use constructor syntax: int(pos.y).\n"
},
{
"QuestionId": "76397759",
"QuestionTitle": "How to find a specific class that contains another class?",
"QuestionBody": "I have the following code:\n<div class=\"accordion mobile ui-accordion ui-widget ui-helper-reset\" role=\"tablist\">\n    <h3 class=\"accord-**19** **ui-state-active**\"><span class=\"ui-accordion-header-icon ui-icon ui-icon-triangle-1-s\">Title 1</h3>\n        <div style=\"\" class=\"ui-accordion-content ui-corner-bottom ui-helper-reset ui-widget-content ui-accordion-content-active\" id=\"ui-id-2\" aria-labelledby=\"ui-id-1\" role=\"tabpanel\" aria-hidden=\"false\">\n            Content for title 1\n        </div>\n        <h3 class=\"accord-41\">Title 2</h3>\n        <div style=\"display: none;\" class=\"ui-accordion-content ui-corner-bottom ui-helper-reset ui-widget-content\" id=\"ui-id-4\" aria-labelledby=\"ui-id-3\" role=\"tabpanel\" aria-hidden=\"true\">\n            Content for title 2\n        </div>\n        <h3 class=\"accord-47\">Title 3</h3>\n        <div style=\"display: none;\" class=\"ui-accordion-content ui-corner-bottom ui-helper-reset ui-widget-content\" id=\"ui-id-6\" aria-labelledby=\"ui-id-5\" role=\"tabpanel\" aria-hidden=\"true\">\n            Content for title 3\n        </div>        \n</div>\n\nWhat I am trying to do is:\n\nGet the h3 tag that contains the class ui-state-active\nand then\nGet the unique id  (in this example, 19) that comes after the class name that starts with \"accord-\".\n\nNote, the above is churned out by a plugin I am using, which means I cannot set and \"id\" tag for h3 to be unique.\nI have tried:\nvar classname = $(\"div.accordion h3.ui-state-active\").find('class^=\"accord-\"');\nTo get the name of the class, before I substring it.\nHowever, this doesn't work.\n",
"AnswerId": "76397790",
"AnswerBody": "When you tried to retrieve the class name .find  was not the correct way to do it. To find the attributes of an element you should use .attr, and then specify .attr(\"class\") to find classes. Then from there use regex to find the correct accord-id.\nvar classname = $(\"div.accordion h3.ui-state-active\").attr(\"class\");\nvar id = classname.match(/accord-(\\d+)/)[0];\n\n"
},
{
"QuestionId": "76396594",
"QuestionTitle": "Nested for loop - model.id in parent for loop does not match model.id in nested for loop (django)",
"QuestionBody": "I am trying to access data from a parent to a child via a foreign key.\nWHAT WORKS - the views\nThe data in the child is not \"ready to be used\" and need to be processed, to be represented in a progress bar in %.\nThe data processing is handled in the views. When I print it on the console, it seems to work and stored into a variable reward_positions.\nReward positions = [(<Venue: Venue_name>, reward_points, reward_position_on_bar)]\n\nSo this part works.\nThe plan is therefore to access reward_position_on_bar by calling {{reward_positions.2}}\nWHAT DOESNT WORK - the template\nBut something is not working to plan in the template.\nThe template renders the last child_model (thats rewardprogram) objects of the last parent_id (thats venue) irrespective of the actual parent_id processed in the for loop.\nTEST RESULT & WHERE I THINK THE PROBLEM IS\nI think my problem lies in my nested forloop. The parent_id in the parent forloop does not match the '{{reward_position.0}}' in the nested forloop.\nDoing a verification test, {{key}} should be equal to {{reward_position.0}} as they both go through the same parent forloop.\nHowever, if {{key}} does change based on venue.id (parent forloop id), {{reward_position.0}} is stuck to the same id irrespective of the parent forloop id.\nCan anyone seem what I am doing wrong?\nTHE CODE\nmodels\nclass Venue(models.Model):\n    name = models.CharField(verbose_name=\"Name\",max_length=100, blank=True)\n\nclass RewardProgram(models.Model):\n    venue = models.ForeignKey(Venue, null = True, blank=True, on_delete=models.CASCADE, related_name=\"venuerewardprogram\")\n    title = models.CharField(verbose_name=\"reward_title\",max_length=100, null=True, blank=True)\n    points = models.IntegerField(verbose_name = 'points', null = True, blank=True, default=0)\n\nviews\ndef list_venues(request):\n    venue_markers = Venue.objects.filter(venue_active=True)\n    \n    #Progress bar per venue\n    \n    bar_total_lenght = 100\n    rewards_available_per_venue = 0\n    reward_position_on_bar = 0\n    venue_data = {}\n    reward_positions = {}\n    \n    for venue in venue_markers:\n        print(f'venue name ={venue}')\n                \n        #list all reward programs\n        venue.reward_programs = venue.venuerewardprogram.all()\n        reward_program_per_venue = venue.reward_programs\n        \n        #creates a list of reward points needed for each venue for each object\n        reward_points_per_venue_test = []\n        \n        #appends the points to empty list from reward program from each venue\n        for rewardprogram in reward_program_per_venue:\n            reward_points_per_venue_test.append(rewardprogram.points)\n        \n        #sorts list in descending order\n        reward_points_per_venue_test.sort(reverse=True)\n        \n        #set position of highest reward to 100 (100% of bar length)\n        if reward_points_per_venue_test:\n            highest_reward = reward_points_per_venue_test[0]\n\n        if not reward_program_per_venue:\n            pass\n        else:    \n            #counts reward program per venue\n            rewards_available_per_venue = venue.reward_programs.count()\n                    \n            if rewards_available_per_venue == 0:\n                pass\n            else:   \n                #position of reward on bar  \n                reward_positions = []\n                for rewardprogram in reward_program_per_venue:\n                    #list all points needed per reward program objects\n                    reward_points = rewardprogram.points\n  \n                    #position each reward on bar\n                \n                    reward_position_on_bar = reward_points/highest_reward\n                    reward_positions.append((venue, reward_points, reward_position_on_bar))\n                    #reward_positions[venue.id] = reward_position_on_bar\n                reward_positions = reward_positions\n                print(f'Reward positions = {reward_positions}')\n\n    context = {'reward_positions':reward_positions,'venue_data':venue_data,'venue_markers':venue_markers}\n    \n    return render(request,'template.html',context)\n\ntemplate\n            {%for venue in venue_markers%}\n    \n            {%for key, value in venue_data.items%}\n            {%if key == venue.id%} #venue.id = 3\n                                  {% for reward_position in reward_positions %}#test result\n                                  {{reward_position.0.id}} # = id = 7 (thats not the good result)\n{{key}} #id = 3 (thats the good result)\n                                  {% endfor %}\n                                  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: {{value}}%\" aria-valuenow=\"{{value}}\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n    \n            {%endif%}\n            {%endfor%}\n       \n            {%endfor%}\n\n",
"AnswerId": "76396668",
"AnswerBody": "You are overcomplicating things, which makes the template very complex (which often will only introduce extra bugs), and makes it even quite slow because of an N+1 problem in the view.\ndef list_venues(request):\n    venues = (\n        Venue.objects.filter(venue_active=True)\n        .annotate(\n            total_points=Sum('venuerewardprogram__points'),\n            rewards_available=Count('venuerewardprogram'),\n        )\n        .prefetch_related('venuerewardprogram')\n    )\n    for venue in venues:\n        for rewardprogram in venue.venuerewardprogram.all():\n            rewardprogram.position_on_bar = round(\n                100 * rewardprogram.reward_points / venue.total_points\n            )\n    return render(request, 'template.html', {'venues': venues})\nthen in the template, we can render this as:\n{%for venue in venues %}\n  <h1>{{ venue.name }}</h1>\n  {% for rewardprogram in venue.venuerewardprogram.all %}\n    <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: {{ rewardprogram.position_on_bar }}%\" aria-valuenow=\"{{ rewardprogram.position_on_bar }}\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n  {% endfor %}\n{% endfor %}\nthis will thus take the .position_on_bar attributes we added to the rewardPrograms that we prefetched for the Venues.\n"
},
{
"QuestionId": "76394285",
"QuestionTitle": "Show Tool Tip When a certain Button is Held down & Removetool Tip when button is Released / Up",
"QuestionBody": "need help creating an example script of tool tip\nScenario : when i held down / press down CTRL a tooltip will appear , the tooltip will only dissappear if\n\nthe CTRL modifier is released\nwhen CTRL key is held down then ANY KEYS is triggered / combine ( ex. Ctrl + A B C so forth ) or any modifier keys like ( Ctrl + SHIFT  ) ( ctrl + alt ) ( ctrl + alt + shift ) so forth\n\nthank you\n",
"AnswerId": "76395019",
"AnswerBody": "~LControl::\n    ToolTip, LControl,,, 1\n    SetTimer RemoveTooltip1, 50\nreturn\n\n~LControl Up:: \n    SetTimer RemoveTooltip1, off\n    ToolTip,,,, 1\nreturn\n\nRemoveTooltip1:\n    If (A_PriorKey != \"LControl\")\n        ToolTip,,,, 1\nreturn\n\nFor all modifier keys:\n; List of keys to bind\nkeys := \"LControl,RControl,LShift,RShift,LAlt,RAlt,LWin,RWin\"\n\n; bind the keys to keypress_handler\nLoop, parse, keys, `,\n{\n    hotkey, ~%A_Loopfield%, keypress_handler1\n    hotkey, ~%A_Loopfield% Up, keypress_handler2\n}\n\nkeypress_handler1:\n    ThisKeyLabel := StrReplace(A_ThisHotkey, \"~\")\n    ToolTip, %ThisKeyLabel%,,, 1\n    SetTimer RemoveTooltip1, 50\nreturn\n\nkeypress_handler2:\n    SetTimer RemoveTooltip1, off\n    ToolTip,,,, 1\nreturn\n\nRemoveTooltip1:\n    ThisKeyLabel := StrReplace(A_ThisHotkey, \"~\")\n    If (A_PriorKey != ThisKeyLabel)\n        ToolTip,,,, 1\nreturn\n\n"
},
{
"QuestionId": "76397770",
"QuestionTitle": "Is it possible to replace a word used within an argument to a preprocessor macro?",
"QuestionBody": "Say I have a macro:\n#define SUBST(MAGIC, ...) __VA_ARGS__  /* this won't work*/\n\nAnd I want to call it like:\nSUBST(int, MAGIC a = 1);\n\n// expected output:\nint a = 1;\n\nIs there some set of wild indirections and expansions that I can use to force the expansion of MAGIC within the second argument with a value which depends on the call to the macro?\nThis comes up when the other arguments come from another layer and the SUBST macro is repeated many times with different values of MAGIC.\nFor example:\n#define WRAP(function, MAGIC, stuff, ...) \\\n  void function(__VA_ARGS__) { stuff };\n#define SUPERWRAP(function, stuff, ...) \\\n    WRAP(function, uint8_t, stuff##_u8, __VA_ARGS__) \\\n    WRAP(function, uint16_t, stuff##_u16, __VA_ARGS__)\n\nSUPERWRAP(example, EXAMPLE_IMPL, template_t<MAGIC>, int)\n\nWhich cannot be solved in templates because:\n#define WRAP(function, stuff, ...) \\\n  template<class MAGIC>\n  int function(__VA_ARGS__) { stuff }\nWRAP(example, /*...*/, template_t<MAGIC>, int)\n\ndoesn't allow for specialised implementaion, and and taking the type as a templatea argument in the specialisation is a partial specialisation which is also illegal.\n",
"AnswerId": "76397841",
"AnswerBody": "\nIs it possible to replace a word used within an argument to a preprocessor macro?\n\nNo, it is not possible to replace a word used within an argument to a preprocessor macro.\n\nSUBST(int, MAGIC a = 1);\n// expected output:\nint a = 1;\n\n\nThat is not possible.\n\nIs there some set of wild indirections and expansions that I can use to force the expansion of MAGIC within the second argument with a value which depends on the call to the macro?\n\nNo.\n\nFor example: #define WRAP(function, MAGIC, stuff, ...) \\\n\nUsing C macros to generate function definition results in hard to read, maintain and debug code that no one is ever able to fix or do anything with later. Consider writing the stuff that you want line by line.\nYou could consider using a better preprocessor, like jinja2, m4 or php.\n"
},
{
"QuestionId": "76396589",
"QuestionTitle": "Add namespace Microsoft.Exchange.Data.Mime to project?",
"QuestionBody": "Sorry as I know I must sound stupid here but how do I add/import a namespace to my project? Microsoft.Exchange.Data.Mime is what i need but I cannot find the way to add in visual studio?\nThanks\n",
"AnswerId": "76396678",
"AnswerBody": "You have to install the 'Microsoft.Exchange.Data.Common' nuget package first. Then try to import it into your file. I would suggest using MimeKit, which is a more sophisticated Mime tool for .NET.\n"
},
{
"QuestionId": "76396616",
"QuestionTitle": "Wrapping text around a box in the corner but keep scroll possibility",
"QuestionBody": "I have some text which should wrap around a toolbox in the top right corner.\nThe total height should be limited, therefore the text should be scroll-able.\nThe corner box should stay in the corner, not scrolling with the text.\nHow can I achieve this?\nI have a box and some text, but when adding overflow-y: scroll it will break like this:\n\n\n.box {\n  width: 100px;\n  height: 40px;\n  float: right;\n  clear: both;\n}\n\n#blue {\n  background-color: blue;\n}\n\n#text {\n  height: 120px;\n  overflow-y: scroll;\n}\n<div id='blue' class='box'></div>\n<div id='text'>\n  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor\n  in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit,\n  sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore\n  eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n</div>\n\n\n\n",
"AnswerId": "76396679",
"AnswerBody": "You can add a div as a parent for the box and text and set the blue box position to sticky position: sticky;\nI hope This is what you want\n\n\n.box {\n    width:100px;\n    height:40px;\n    float:right;\n    clear: both;\n}\n\n#blue {\n    background-color:blue;\n    position: sticky;\n    top: 0;\n}\n\n#text {\n}\n.container{\n height: 120px;\n    overflow-y: auto;\n}\n<div class=\"container\">\n <div id='blue' class='box'></div>\n  <div id='text'>\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n  </div>\n</div>\n\n\n\n"
},
{
"QuestionId": "76394915",
"QuestionTitle": "Convert to ISO time format in Angular using moment.js",
"QuestionBody": "I'm trying to format date in this below format\n\n20230201T103000Z\n\ni tried this method in angular\nmoment(utctime).format('YYYYMMDDTHHmmsssZ')\n\nthis is returning following date format\n20230523T1900000+05:30\n\n",
"AnswerId": "76395044",
"AnswerBody": "'Z' is a token witch will show time zone. You can add your 'Z' as part of string\nhttps://momentjs.com/docs/#/displaying/format/\nconsole.log(moment().format('YYYYMMDDTHHmmss') + 'Z');\n\nThe second option is Escaping characters using []\nconsole.log(moment().format('YYYYMMDDTHHmmss[Z]'));\n\n"
},
{
"QuestionId": "76397802",
"QuestionTitle": "SQL MAX mixes up lines",
"QuestionBody": "I have a little table where i like to get the latest content for each groupId.\nThis is the Table with my data:\n\nThis is my try to get it.\nSELECT *, MAX(highest_datetime.creattionDate)\nFROM highest_datetime\nGROUP BY highest_datetime.groupId;\n\n\nThe MAX(highest_datetime.creattionDate) includes the latest content witch is a success. \nBut the complete rest of the line does not match the MAX(highest_datetime.creattionDate). \nThe rest of the row got mixed up.\nHow do i prevent this?\nDo i use it wrong?\nhere is the data for the Database so you can create it yourself:\nCREATE TABLE `test`.`highest_datetime` (\n  `id` INT NOT NULL AUTO_INCREMENT,\n  `groupId` INT NOT NULL,\n  `creationDate` DATETIME NOT NULL,\n  `Content` VARCHAR(100) NOT NULL,\n  PRIMARY KEY (`id`),\n  INDEX (`groupId`)\n) ENGINE = InnoDB;\n\n\n\n\nINSERT INTO `test`.`highest_datetime` (`groupId`, `creationDate`, `Content`)\nVALUES\n(1, '2023-05-02 00:00:00', 'Newest content'),\n(1, '2023-01-01 00:00:00', 'Middle Content'),\n(2, '2023-03-01 00:00:00', 'Middle Content'),\n(2, '2022-11-01 00:00:00', 'Old Content'),\n(2, '2023-06-01 00:00:00', 'New Content'),\n(1, '2022-11-20 00:00:00', 'Old Content'),\n(2, '2024-11-01 00:00:00', 'Future Content');\n\n",
"AnswerId": "76397843",
"AnswerBody": "You are probably running MySQL in its notorious cheat mode, i.e. you haven't SET sql_mode = 'ONLY_FULL_GROUP_BY', and the DBMS allows invalid aggregation queries.\nYou have:\nSELECT *, MAX(highest_datetime.creationDate)\nFROM highest_datetime\nGROUP BY highest_datetime.groupId;\n\nSo you want one result row per groupid, with the maximum creation date. You also want all columns, but you don't tell the DBMS from which row. For example you select the content, but which? The first in alhabet or the last? You don't state this, and so this query is invalid.\nThis would raise an error in about every DBMS. In MySQL's old cheat mode however, the DBMS silently applies ANY_VALUE on all non-aggregated columns. In other words it picks the content and other columns from arbitrary rows.\nWhat you want instead is to get the rows with the maximum creation dates for their group. One way to do this:\nSELECT id, groupid, creationdate, content\nFROM highest_datetime\nWHERE (groupid, creationdate) IN\n(\n  SELECT groupid, MAX(creationdate)\n  FROM highest_datetime\n  GROUP BY groupid\n);\n\nAnother approach:\nSELECT id, groupid, creationdate, content\nFROM\n(\n  SELECT *, MAX(creationdate) OVER (PARTITION BY groupid) as max_grp_date\n  FROM highest_datetime\n) with_max_date\nWHERE creationdate = max_grp_date;\n\nAdd an ORDER BY clause to the queries, if you want your result rows in a particular order.\nDemo: https://dbfiddle.uk/FzP5oloZ\n"
},
{
"QuestionId": "76397864",
"QuestionTitle": "How do I add multiple lines of text to tabs in Swift Playgrounds?",
"QuestionBody": "My app in Swift Playgrounds has tabs. I want to add multiple lines of text to one tab, but I don’t know how. I can’t find an answer anywhere.\n Text(\"Developer\").tabItem { Text(\"Settings\").tag(5)\n                                        VStack {\n                                            Image(systemName: \"gear\")\n                                                .font(.title)\n                                            Text(\"Settings\")\n                                        }\n                                    }\n\nI tried it the normal way, but it just spaced out the specific tab more than all of the other tabs.\n",
"AnswerId": "76397894",
"AnswerBody": "I think you need to specify the text you would like to add, and where you would like to add it. This can work to add more text within the main content area of the tab:\nTabView {\n    VStack {\n        Text(\"Line 1\")\n        Text(\"Line 2\")\n        Text(\"Line 3\")\n    }\n    .tabItem {\n        VStack {\n            Image(systemName: \"gear\")\n                .font(.title)\n            Text(\"Settings\")\n        }\n    }\n    .tag(5)\n\n    // ... other tabs ...\n}\n\n"
},
{
"QuestionId": "76396628",
"QuestionTitle": "Cast lambda expression to class object whose constructor accept that lambda (Brief lambda)",
"QuestionBody": "I am figuring out a way to program a kinda of FunctionalInterface - Java's similar ones - in C++ (although it already provides these features).\nI am practicing with Predicate for the moment. Actually I have already done it:\nnamespace _utils{\n\n    namespace _functional{\n\n        template <typename T>\n        class Predicate: public FunctionalI{\n            protected:\n                std::function<bool(T)> predicate;\n\n            public:\n                Predicate(std::function<bool(T)> predicate){\n                    this->predicate = predicate;\n                }\n\n                inline bool test(T t){\n                    return this->predicate(t);\n                }\n        };\n    }\n}\n\nAnd this is main.cpp:\nbool foo(_functional::Predicate<int> predicate){\n    return predicate.test(2);\n}\n\nint main(){\n    _functional::Predicate<int> tmp = _functional::Predicate<int>([] (int x) ->  bool{ return x == 2; });\n\n    std::cout << foo(tmp);\n\n    return 0;\n}\n\nNow, of course it works!\nMy question is about how could I make a brief of that lambda expression? I mean, is there any way to pass \"directly\" the lambda expression (without give it to the Predicate constructor) and then let it construct the Predicate object with right that lambda expression.\nI have taken a look at using aliasing and even at functor with operator(), but they did not helped me (maybe I have not been able to do it)\nAn example of main.cpp which I wish to reach:\nbool foo(_functional::Predicate<int> predicate){\n    return predicate.test(2);\n}\n\nint main(){\n    // To much stuff to write\n    //std::cout<<foo(_functional::Predicate<int>( [] (int x) -> bool{ return x == 2; } ));\n\n    //What I whish to reach\n    foo([] (int x) -> bool{return x == 2;} );\n\n    return 0;\n}\n\nAnother question to make a brief of lambda expr is: is there a way to make implicit the return type of lambda and even the keyword return?\n",
"AnswerId": "76396680",
"AnswerBody": "The problem with foo( [] (int x) -> bool{return x == 2;} ); is that it tries to perform two implicit conversions (lambda to std::function and std::function to Predicate). C++ doesn't allow you to do that. Instead, you can state explicitly that you are initialising Predicate by adding braces:\nfoo( { [] (int x) -> bool{return x == 2;} } );\n//   ^ initialise Predicate object        ^\n\nOr create a template constructor as suggested in comments:\nclass Predicate : public FunctionalI {\nprotected:\n    std::function<bool(T)> predicate;\n\npublic:\n    template <typename PredType>\n    Predicate(PredType predicate) : predicate{ std::move(predicate) }\n    {\n        // use member init list instead of reassigning object in constructor\n    }\n    // ...\n};\n\n"
},
{
"QuestionId": "76394826",
"QuestionTitle": "Matching records between EventA and the first EventB before the next EventA, in a specific order",
"QuestionBody": "I have the following data (fiddle),\n\n\n\n\nid\ndatec\nevent\n\n\n\n\n1\n2022-09-19 12:16:38\nEVENTA\n\n\n2\n2022-09-19 12:16:38\nA\n\n\n3\n2022-09-19 12:21:08\nB\n\n\n4\n2022-09-19 12:21:12\nEVENTD\n\n\n5\n2022-09-19 12:25:18\nC\n\n\n6\n2022-09-19 12:25:18\nD\n\n\n7\n2022-09-19 12:25:28\nE\n\n\n8\n2022-09-19 12:25:29\nF\n\n\n9\n2022-09-19 12:25:38\nEVENTA\n\n\n10\n2022-09-19 12:25:39\nG\n\n\n11\n2022-09-19 12:25:40\nH\n\n\n12\n2022-09-19 12:25:48\nI\n\n\n13\n2022-09-19 12:27:18\nEVENTD\n\n\n14\n2022-09-19 12:29:08\nJ\n\n\n\n\nI can't figure out how to select values between two others, but in a specific order. Only events between EVENTA and EVENTD should be returned, in that order.\nSo that results should be the rows with id 1 to 4 and 9 to 13\nTried to do something like the following, but it is giving me id 1,4,9 and 13 omitting what is between them.\nSELECT id, datec, event \nFROM table1 \nWHERE event BETWEEN 'EVENTA' AND 'EVENTD';\n\nI then tried to use this,\nSELECT id, datec, event \nFROM table1 \nWHERE (id BETWEEN (SELECT id \n                   FROM table1 \n                   WHERE event BETWEEN 'EVENTA' AND 'EVENTD' \n                   LIMIT 1) \n              AND (SELECT id \n                   FROM table1 \n                   WHERE event BETWEEN 'EVENTA' AND 'EVENTD' \n                   LIMIT 1,1)) \n   OR (id BETWEEN (SELECT id \n                   FROM table1 \n                   WHERE event BETWEEN 'EVENTA' AND 'EVENTD' \n                   LIMIT 2,1) \n              AND (SELECT id \n                   FROM table1 \n                   WHERE event BETWEEN 'EVENTA' AND 'EVENTD' LIMIT 3,1));\n\nAnd it gives me the results but I have many rows in my table.\nCan please someone guide me on how to repeat this till the end as i'm sure there is a way to do this but i can't figure out how?\nRegards,\npierre\n",
"AnswerId": "76395095",
"AnswerBody": "Here's one approach:\n\ncompute running counts of armed events and disarmed events, ordering by date\ncompute a ranking order of records for each armed event count, by ordering on the amount of disarmed events\n\nAt this point you should note that this ranking value we generated, assumes value 0 when there's not yet an EventD in our armed_event partition. And it gets value 1 when the first EventD is found, till the successive EventD.\nSo you can just filter accordingly inside a WHERE clause, when this ranking value is either 0 or is 1 and event is exactly \"EventD\".\nWITH cte AS (\n    SELECT *, SUM(`event`='EVENTA') OVER(ORDER BY datec, id) AS armed_events,\n              SUM(`event`='EVENTD') OVER(ORDER BY datec, id) AS disarmed_events\n    FROM Table1\n), cte2 AS (\n    SELECT *, DENSE_RANK() OVER(PARTITION BY armed_events ORDER BY disarmed_events) -1 AS rn\n    FROM cte\n)\nSELECT `id`, `datec`, `event` \nFROM cte2\nWHERE rn = 0 OR (rn = 1 AND `event` = 'EVENTD')\nORDER BY id\n\nOutput:\n\n\n\n\nid\ndatec\nevent\n\n\n\n\n1\n2022-09-19 12:16:38\nEVENTA\n\n\n2\n2022-09-19 12:16:38\nA\n\n\n3\n2022-09-19 12:21:08\nB\n\n\n4\n2022-09-19 12:21:12\nEVENTD\n\n\n9\n2022-09-19 12:25:38\nEVENTA\n\n\n10\n2022-09-19 12:25:39\nG\n\n\n11\n2022-09-19 12:25:40\nH\n\n\n12\n2022-09-19 12:25:48\nI\n\n\n13\n2022-09-19 12:27:18\nEVENTD\n\n\n\n\nCheck the demo here.\nNote: The last ORDER BY clause is not necessary. It's there just for visualization purposes.\n"
},
{
"QuestionId": "76394665",
"QuestionTitle": "How to pass SQLX connection - a `&mut Trait` as a fn parameter in Rust",
"QuestionBody": "I need to generalize functions to pass an Executor trait for SQLX code. In the code below with a concrete &mut SqliteConnection parameter, main can call process, or it can call process_twice which calls process 2x times.  All sqlx functions require arg type E: Executor.\nI need to make my code generic so that conn: &mut SqliteConnection arg is also written with some generic, but so i can use it more than once.\nInside Sqlx, multiple structs implement Executor trait on a mutable reference, e.g.\nimpl<'c> Executor<'c> for &'c mut SqliteConnection {...}\n\nI was able to convert a SINGLE call (the fn process), but not the  fn process_twice - because executor is not copyable.\nasync fn process<'a, E>(conn: E) -> anyhow::Result<()>\nwhere E: sqlx::Executor<'a, Database = sqlx::Sqlite> {...}\n\nFull example\n// [dependencies]\n// anyhow = \"1.0\"\n// futures = \"0.3\"\n// sqlx = { version = \"0.6\", features = [ \"sqlite\", \"runtime-tokio-native-tls\"] }\n// tokio = { version = \"1.28.2\", features = [\"macros\"] }\n//\n//  //// TO RUN, must set env var:\n// DATABASE_URL='sqlite::memory:' cargo run\n\nuse futures::TryStreamExt;\nuse sqlx::SqliteConnection;\nuse sqlx::{query, Connection};\n\n#[tokio::main]\nasync fn main() -> anyhow::Result<()> {\n    let mut conn = SqliteConnection::connect(\"sqlite::memory:\").await?;\n    process(&mut conn).await?;\n    process_twice(&mut conn).await?;\n    Ok(())\n}\n\nasync fn process(conn: &mut SqliteConnection) -> anyhow::Result<()> {\n    let sql = query!(\"SELECT name FROM sqlite_master\");\n    let mut rows = sql.fetch(conn);\n    while let Some(row) = rows.try_next().await? {\n        println!(\"{row:?}\")\n    }\n    Ok(())\n}\n\nasync fn process_twice(conn: &mut SqliteConnection) -> anyhow::Result<()> {\n    process(conn).await?;\n    process(conn).await?;\n    Ok(())\n}\n\nSimilar questions: this\n",
"AnswerId": "76395111",
"AnswerBody": "The trick is to not parametrize the whole E but just the type behind the reference:\nasync fn process_twice<T>(conn: &mut T) -> anyhow::Result<()>\nwhere\n    for<'e> &'e mut T: Executor<'e, Database = Sqlite>,\n{\n    process(&mut *conn).await?;\n    process(conn).await\n}\n\nThat way you can still reborrow the reference. That does mean that you can't take Pool<DB> any more because it only implements Executor for &Pool but should work for your usecase.\n"
},
{
"QuestionId": "76397789",
"QuestionTitle": "Issue with loading jquery after bootstrap",
"QuestionBody": "I tried to research before asking here, but I coun't find any answers. Just for context, I'm using old version of bootstrap v2.0.2. I doubled checked if my paths are correct, and they are.\n\nThis is the order of imported scripts that produce the errors above. If I load bootstrap.min.js first, I will get a different error.\n<head>\n   <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        \n   <script src=\"lib/jquery/jquery-3.7.0.min.js\"></script>\n   <script src=\"lib/bootstrap/js/bootstrap.min.js\"></script>\n        \n   <link rel=\"stylesheet\" href=\"lib/bootstrap/css/bootstrap.min.css\">\n   <link rel=\"stylesheet\" href=\"lib/bootstrap/css/bootstrap-responsive.min.css\">\n   <link rel=\"stylesheet\" href=\"css/app.css\">\n\n   <script src=\"lib/angular/angular.min.js\"></script> \n   <script src=\"js/app.js\"></script>\n</head>\n\nI've tried to import bootstrap.min.js first, but this the error message I get, and I'm not sure why.\n<head>\n   <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        \n   <script src=\"lib/bootstrap/js/bootstrap.min.js\"></script>\n   <script src=\"lib/jquery/jquery-3.7.0.min.js\"></script>\n        \n   <link rel=\"stylesheet\" href=\"lib/bootstrap/css/bootstrap.min.css\">\n   <link rel=\"stylesheet\" href=\"lib/bootstrap/css/bootstrap-responsive.min.css\">\n   <link rel=\"stylesheet\" href=\"css/app.css\">\n\n   <script src=\"lib/angular/angular.min.js\"></script> \n   <script src=\"js/app.js\"></script>\n</head>\n\nI expected it that this small change would resolve the issue, but it didn't.\n\n",
"AnswerId": "76397903",
"AnswerBody": "You cannot use jQuery versions starting with 1.9 with Bootstrap 2.0.2.\njQuery 1.8.3 does work as shown below (note that jQuery must still be loaded before Bootstrap's JavaScript):\n\n\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/1.8.3/jquery.min.js\" integrity=\"sha512-J9QfbPuFlqGD2CYVCa6zn8/7PEgZnGpM5qtFOBZgwujjDnG5w5Fjx46YzqvIh/ORstcj7luStvvIHkisQi5SKw==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.0.2/bootstrap.min.js\" integrity=\"sha512-jv0RCzX/cFYIF5KkvheT4Xk06YMyEmYAJ8mxZ0pgzwHMgIdT/KGedWD2dK2modKDyaK6DSDwh6ptzTHtfJ0Nng==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.3.0/css/bootstrap-responsive.min.css\" integrity=\"sha512-c4E36NNKxeFBnGTk/nFCssF4B7gXdZ9hqBnR0fec+DiZ7EnCB2RA42O8HPdgKHFnseb4s6ieQtmT8iksW+QfWw==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n\n\n\n"
},
{
"QuestionId": "76396498",
"QuestionTitle": "Finding first empty cell in a row problem",
"QuestionBody": "I would like to clear everything in each sheet starting from the first empty cell in the 10th row (Microsoft Excel) but .End property skip the empty cell between filled ones.\nI tried such code:\nSub clearRange()\n    \n    Dim ws As Worksheet\n    Dim lastColumn As Long, i As Long\n    \n    For i = 2 To Worksheets.Count - 1\n        Set ws = Worksheets(i)\n        lastColumn = ws.Cells(10, ws.Columns.Count).End(xlToLeft).Column\n        ws.Range(ws.Cells(10, lastColumn + 1), ws.Range(\"CZ200000\")).ClearContents\n    Next i\n    \nEnd Sub\n\nCell D10 is skipped:\nSheet screenshot\nThank you for help in advance.\n",
"AnswerId": "76396696",
"AnswerBody": "The statement\nlastColumn = ws.Cells(10, ws.Columns.Count).End(xlToLeft).Column\n\nwill take you to column J as the last column in your picture (lastColumn = 10), NOT to column D.\nTo find the first empty cell, start in column A and use end-right, if A10:B10 are both non-empty. If either can be empty, you'll have to address them individually.\nSub clearRange()\n    Dim ws As Worksheet\n    Dim lastColumn As Long, i As Long\n    \n    For i = 2 To Worksheets.Count - 1\n        Set ws = Worksheets(i)\n        lastColumn = ws.Cells(10, 1).End(xlToRight).Column + 1  ' Do this\n        ws.Range(ws.Cells(10, lastColumn + 1), ws.Range(\"CZ200000\")).ClearContents\n    Next i\n    \nEnd Sub\n\nIf this does or doesn't work for you, let us know the result.\nAnd in future requests, please include a table we can copy. We can't copy a screenshot to a worksheet.\n"
},
{
"QuestionId": "76396524",
"QuestionTitle": "Execution failed while running a Kotlin module in Android Studio",
"QuestionBody": "I am getting following error in Build Output when running a Kotlin module :-\nExecution failed for task ':Test:compileKotlin'.\n> 'compileJava' task (current target is 1.7) and 'compileKotlin' task (current target is 17) jvm target compatibility should be set to the same Java version.\nConsider using JVM toolchain: https://kotl.in/gradle/jvm/toolchain\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --scan to get full insights.\n\nThe build.gradle file for this module has the following code:-\nplugins {\n    id 'java-library'\n    id 'org.jetbrains.kotlin.jvm'\n}\n\njava {\n    sourceCompatibility = JavaVersion.VERSION_1_7\n    targetCompatibility = JavaVersion.VERSION_1_7\n}\n\nKindly help me find the error and its resolution.\n",
"AnswerId": "76396697",
"AnswerBody": "try to make java version 17 not 1.7 like this:\nplugins {\nid 'java-library'\nid 'org.jetbrains.kotlin.jvm'\n}\n\njava {\nsourceCompatibility = JavaVersion.VERSION_17\ntargetCompatibility = JavaVersion.VERSION_17\n}\n\n"
},
{
"QuestionId": "76391066",
"QuestionTitle": "Altair: only show related field on hover, not all of them",
"QuestionBody": "This is a follow-up question to a previous (solved) question about Altair with the same toy dataset.\nIn the code below, we have a dataset that can be read as: \"two cooks cook1, cook2 are doing a competition. They have to make four dishes, each time with two given ingredients ingredient1, ingredient2. A jury has scored the dishes and the grades are stored in _score.\nMy code is working well already:\n\non the y-axis the score is given, both for cook1 and cook2\nin the legend, cook1 and cook2 are separate\na vertical line is drawn over the nearest x-axis item when hovering\n\nI would like to make changes to the legend.\nNow it shows the following properties:\n\ndish (x-axis number)\ningredient 1, ingredient 2\ncook1's dish, cook2's dish\nscore of the cook that we're hovering closest to\ncookX_score (cook1_score, cook2_score) of the cook that we're hovering closest to\n\nInstead, I would like to change it so that the dishes (cook1 and cook2) are not both shown but that, just like with score, only the respective dish is included. So if I hover closer to a point of cook1_score I only want to show cook1 and not also cook2.\nMy attempts to restrict this have failed, but the reason is simply because Altair does not know that cook1 and cook1_score, and cook2 and cook2_score are linked. But I am not sure how I can tell Altair that so that it only shows the relevant fields when hovering close to a point.\nimport altair as alt\nimport pandas as pd\n\nalt.renderers.enable(\"altair_viewer\")\ndf = pd.DataFrame({\n    \"ingredient1\": [\"potato\", \"onion\", \"carrot\", \"beet\"],\n    \"ingredient2\": [\"tomato\", \"pepper\", \"zucchini\", \"lettuce\"],\n    \"dish\": [1, 2, 3, 4],\n    \"cook1\": [\"cook1 dish1\", \"cook1 dish2\", \"cook1 dish3\", \"cook1 dish4\"],\n    \"cook1_score\": [0.4, 0.3, 0.7, 0.9],\n    \"cook2\": [\"cook2 dish1\", \"cook2 dish2\", \"cook2 dish3\", \"cook2 dish4\"],\n    \"cook2_score\": [0.6, 0.2, 0.5, 0.6],\n})\n\n\nvalue_vars = [c for c in df.columns if c.endswith(\"_score\")]\ncook_names = [c.replace(\"_score\", \"\") for c in value_vars]\nid_vars = [\"dish\", \"ingredient1\", \"ingredient2\"] + cook_names\ndf_melt = df.melt(id_vars=id_vars, value_vars=value_vars, var_name=\"cook\", value_name=\"score\")\n\nnearest_dish = alt.selection(type=\"single\", nearest=True, on=\"mouseover\", fields=[\"dish\"], empty=\"none\")\n\n# Main chart with marked circles\nchart = alt.Chart(df_melt).mark_circle().encode(\n    x=\"dish:O\",\n    y=\"score:Q\",\n    color=\"cook:N\",\n    tooltip=id_vars + [\"score\", \"cook\"]\n).add_selection(\n    nearest_dish\n)\n\n# Draw a vertical rule at the location of the selection\nvertical_line = alt.Chart(df_melt).mark_rule(color=\"gray\").encode(\n    x=\"dish:O\",\n).transform_filter(\n    nearest_dish\n)\n\n# Combine the chart and vertical_line\nlayer = alt.layer(\n    chart, vertical_line\n).properties(\n    width=600, height=300\n).interactive()\n\nlayer.show()\n\nNote: I'm stuck on Altair<5.\n",
"AnswerId": "76397917",
"AnswerBody": "I ended up modifying my DataFrame so that every row contains the dish name and the scores separately as well. That way I could target those items within the tooltip.\nimport altair as alt\nimport pandas as pd\n\nalt.renderers.enable(\"altair_viewer\")\ndf = pd.DataFrame({\n    \"ingredient1\": [\"potato\", \"onion\", \"carrot\", \"beet\"],\n    \"ingredient2\": [\"tomato\", \"pepper\", \"zucchini\", \"lettuce\"],\n    \"dish_id\": [1, 2, 3, 4],\n    \"cook1\": [\"cook1 dish1\", \"cook1 dish2\", \"cook1 dish3\", \"cook1 dish4\"],\n    \"cook1_score\": [0.4, 0.3, 0.7, 0.9],\n    \"cook2\": [\"cook2 dish1\", \"cook2 dish2\", \"cook2 dish3\", \"cook2 dish4\"],\n    \"cook2_score\": [0.6, 0.2, 0.5, 0.6],\n})\n\n\nvalue_vars = [c for c in df.columns if c.endswith(\"_score\")]\ncook_names = [c.replace(\"_score\", \"\") for c in value_vars]\nid_vars = [\"dish_id\", \"ingredient1\", \"ingredient2\"] + cook_names\ndf_melt_score = df.melt(id_vars=[\"dish_id\", \"ingredient1\", \"ingredient2\"], value_vars=value_vars, var_name=\"cook_score\", value_name=\"score\")\ndf_melt_score[\"cook\"] = df_melt_score[\"cook_score\"].str.replace(\"_score\", \"\")\ndf_melt_score = df_melt_score.drop(columns=[\"cook_score\"])\ndf_melt_dish = df.melt(id_vars=[\"dish_id\", \"ingredient1\", \"ingredient2\"], value_vars=[\"cook1\", \"cook2\"], var_name=\"cook\", value_name=\"dish_name\")\n\ndf_concat = pd.merge(df_melt_score, df_melt_dish, on=[\"dish_id\", \"cook\", \"ingredient1\", \"ingredient2\"], how=\"left\").reset_index()\n\nnearest_dish = alt.selection(type=\"single\", nearest=True, on=\"mouseover\", fields=[\"dish_id\"], empty=\"none\")\n\n# Main chart with marked circles\nchart = alt.Chart(df_concat).mark_circle().encode(\n    x=\"dish_id:O\",\n    y=\"score:Q\",\n    color=\"cook:N\",\n    tooltip=[\"dish_id\", \"ingredient1\", \"ingredient2\", \"cook\", \"dish_name\"]\n).add_selection(\n    nearest_dish\n)\n\n# Draw a vertical rule at the location of the selection\nvertical_line = alt.Chart(df_melt_score).mark_rule(color=\"gray\").encode(\n    x=\"dish_id:O\",\n).transform_filter(\n    nearest_dish\n)\n\n# Combine the chart and vertical_line\nlayer = alt.layer(\n    chart, vertical_line\n).properties(\n    width=600, height=300\n).interactive()\n\nlayer.show()\n\n\n"
},
{
"QuestionId": "76396585",
"QuestionTitle": "How to pass a div ID to a PHP function using jQuery AJAX?",
"QuestionBody": "PHP Post doesn't receive jQuery ajax post value\nI have created an ajax POST with jQuery to obtain the ID of a div and pass it to a PHP function. The function of php is in a folder phpFunction taht contains the file phpFunc.php in the same root of index.php. The post request is:\n$(document).ready(function() {\n            $('.openModal').click(function() {\n                var divId = $(this).attr('id');\n                // Invia l'ID al server tramite richiesta AJAX\n                $.ajax({\n                    type: 'POST',\n                    url: 'http://localhost/icollegati/phpFunction/phpFunc.php',\n                    data: {divId: divId},\n                    success: function(response) {\n                        // Gestisci la risposta del server\n                        console.log(\"Risposta\",response);\n                    }\n                });\n            });\n        });\n\nthe PHP function is:\nfunction FetchIdNumber(){\n    if ($_SERVER['REQUEST_METHOD'] === 'POST') {\n    // Verifica se il parametro \"divId\" è stato inviato tramite POST\n    if (isset($_POST['divId'])) {\n        $id = $_POST['divId'];\n        echo \"ID: \" . $id;\n        return $id;\n    }\n  }\n};\n\nThanks in adavance for the help.\n",
"AnswerId": "76396706",
"AnswerBody": "you need to call the FetchIdNumber function in your PHP code.\nfunction FetchIdNumber(){\n    if ($_SERVER['REQUEST_METHOD'] === 'POST') {\n        // Verifica se il parametro \"divId\" è stato inviato tramite POST\n        if (isset($_POST['divId'])) {\n            $id = $_POST['divId'];\n            echo \"ID: \" . $id;\n            return $id;\n        }\n    }\n}\n\n// Call the function\nFetchIdNumber();\n\nMake sure to place the function call FetchIdNumber(); after the function definition.\nAdditionally, please ensure that the path to your PHP file is correct. In your AJAX code, you have specified the URL as http://localhost/icollegati/phpFunction/phpFunc.php. Make sure that this path is accurate and matches the actual location of the PHP file on your server.\n"
},
{
"QuestionId": "76396634",
"QuestionTitle": "Numpy interval of indices around max value on the last dimension",
"QuestionBody": "I have an array arr in which I would like to zero the interval (over the last dim) around every max value.\nHere's what I'm generally trying to do (this code doesn't work):\nassume that interval_size is some positive odd integer.\nargmax = np.argmax(arr, axis=-1)\n\nhalf_interval = (interval_size - 1) // 2  # assume the interval is of odd size\nleft_index = argmax - half_interval\nright_index = argmax + half_interval\n# fix overflow\nleft_index[left_index < 0] = 0\nright_index[right_index >= arr.shape[-1]] = arr.shape[-1] - 1\n\n# this is just illustrative and doesn't work:\narr[left_index:right_index] = 0  # zero the interval in-place\n\n",
"AnswerId": "76396739",
"AnswerBody": "Given that the intervals could be different sizes, I'd go for boolean indexing:\nimport numpy as np\n\narr = np.random.randint(10, size=(8, 8))\nhalf_interval = 2\n\n# Use keepdims=True for easy broadcasting\nargmax = arr.argmax(axis=-1, keepdims=True)\n\n# \"Normal\" indices for the last axis\nidx = np.arange(arr.shape[-1])\n\n# True when \"normal\" index is between\n# [argmax - half_interval, argmax + half_interval]\nmask = (argmax - half_interval <= idx) & (idx <= argmax + half_interval)\n\narr[mask] = 0\n# or out = np.where(mask, 0, arr) if you don't want to modify arr\n\nResults:\n>>> arr\narray([[6, 8, 5, 4, 6, 9, 3, 6],\n       [9, 4, 9, 3, 9, 0, 3, 6],\n       [7, 9, 7, 1, 0, 3, 0, 0],\n       [9, 9, 4, 8, 3, 8, 3, 2],\n       [9, 7, 6, 9, 2, 0, 9, 6],\n       [1, 7, 9, 7, 6, 2, 9, 4],\n       [8, 0, 8, 9, 6, 5, 0, 9],\n       [2, 0, 9, 5, 9, 0, 2, 4]])\n>>> argmax\narray([[5],\n       [0],\n       [1],\n       [0],\n       [0],\n       [2],\n       [3],\n       [2]], dtype=int64)\n>>> mask\narray([[False, False, False,  True,  True,  True,  True,  True],\n       [ True,  True,  True, False, False, False, False, False],\n       [ True,  True,  True,  True, False, False, False, False],\n       [ True,  True,  True, False, False, False, False, False],\n       [ True,  True,  True, False, False, False, False, False],\n       [ True,  True,  True,  True,  True, False, False, False],\n       [False,  True,  True,  True,  True,  True, False, False],\n       [ True,  True,  True,  True,  True, False, False, False]])\n>>> out\narray([[6, 8, 5, 0, 0, 0, 0, 0],\n       [0, 0, 0, 3, 9, 0, 3, 6],\n       [0, 0, 0, 0, 0, 3, 0, 0],\n       [0, 0, 0, 8, 3, 8, 3, 2],\n       [0, 0, 0, 9, 2, 0, 9, 6],\n       [0, 0, 0, 0, 0, 2, 9, 4],\n       [8, 0, 0, 0, 0, 0, 0, 9],\n       [0, 0, 0, 0, 0, 0, 2, 4]])\n\nThe above should work for arrays with more than 2 axes as well due to broadcasting. But only because you argmax over the final axis.\n"
},
{
"QuestionId": "76395036",
"QuestionTitle": "Converting np.int16 to torch.ShortTensor",
"QuestionBody": "I have many NumPy arrays of dtype np.int16 that I need to convert to torch.Tensor within a torch.utils.data.Dataset.  This np.int16 ideally gets converted to a torch.ShortTensor of size torch.int16 (docs).\ntorch.from_numpy(array) will convert the data to torch.float64, which takes up 4X more memory than torch.int16 (64 bits vs 16 bits).  I have a LOT of data, so I care about this.\nHow can I convert a numpy array to a torch.Tensor minimizing memory?\n",
"AnswerId": "76395145",
"AnswerBody": "Converting a numpy array to torch tensor:\narray = np.ones((1000, 1000), dtype=np.int16)\nprint(\"NP Array size: {}\".format(array.nbytes))\nt = torch.as_tensor(array) # as_tensor avoids copying of array \nprint(\"Torch tensor type: {}\".format(t.dtype))\nprint(\"Torch tensor size: {}\".format(t.storage().nbytes()))\n\nNP Array size: 2000000\nTorch tensor type: torch.int16\nTorch tensor size: 2000000\n\n"
},
{
"QuestionId": "76397906",
"QuestionTitle": "In sveltekit, what's the convention for splitting client side code between route files?",
"QuestionBody": "Both +page.js/ts and the <script><script/> tags within +page.svelte files are for processing client side code.\nWhat's the typical convention for choosing between these 2 files?\n",
"AnswerId": "76397930",
"AnswerBody": "The question has been clearly answered in the Documentation. The separate file is for loading and constructing data that is required by your route, the script tag is for DOM manipulation and client side logic.\nThat is the convention as per the docs but you are free to use both methods as per your preference but +page.server.js/ts is strictly  for server side logic like authentication and database calls.\n"
},
{
"QuestionId": "76396256",
"QuestionTitle": "How to send a widget object created later to callback in Tk?",
"QuestionBody": "I am new to Perl Tk.\nI have option menu.  In its callback, I want to pass a table object which is created later. As per the selection of the option, I want to render specific data into the table.\nSince my optionmenu is created before, how can I send the table object to it?\nIn the code, I have commented it as 'HOW TO PASS ?\nuse Tk;\nuse Tk::Table;\nuse Tk::NoteBook;\nuse Tk::Optionmenu;\n\nmy $data = { 'Jan' =>  { 'id' => 1, 'product' => 'new'} , 'Feb' => {'id'=>2, \n'product'=> 'latest'} }; \n\n&tk_gui(); \n\nsub tk_gui {\n\nmy $mw = MainWindow->new;\n$mw->geometry(\"500x500\");\nmy $f = $mw->Frame()->pack(-side=>'top');\nmy ($var, $tvar);\nmy $opt = $f->Optionmenu(\n-options => [[jan =>1], [feb =>2]],\n-command => sub { \n        my @nums = @_;\n        #HOW TO PASS ?\n        &show_table_data($nums[0], $table)\n\n        \n    },\n-variable => \\$var,\n-textvariable => \\$tvar,\n)->pack(-side => 'left', -anchor => 'n',);  \n\nmy $f2 = $mw->Frame()->pack(-side=>'bottom');\nmy $table = $f2->Table( -columns => 2);\nmy @col = qw(id product);\n\nforeach my $c (0 .. 1) {\nif ($c) {\n    my $t = $table->Label(-text => 'product'); \n    $table->put(0, $c, $t); \n} else {\n    my $t = $table->Label(-text => 'id'); \n    $table->put(0, $c, $t); \n\n }\n\n}\n\n$table->pack();\n\nMainLoop;\n\n}\n\nsub show_table_data {\n    my $num = shift;\n    my $table = shift;\n}\n\n",
"AnswerId": "76396740",
"AnswerBody": "\nSince my optionmenu is created before, how can I send the table object to it?\n\nJust declare the $table variable before it is used in the callback. Even if the variable has not been defined when the callback is compiled, it will be defined when the callback is called at runtime. Example:\nuse feature qw(say);\nuse strict;\nuse warnings;\nuse Tk;\nuse Tk::Table;\nuse Tk::NoteBook;\nuse Tk::Optionmenu;\n\n{    \n    tk_gui(); \n}\n\nsub tk_gui {\n    my $mw = MainWindow->new;\n    $mw->geometry(\"500x500\");\n    my $f = $mw->Frame()->pack(-side=>'top');\n    my ($var, $tvar);\n    my $table;  # <-- declare the variable here..\n    my $opt = $f->Optionmenu(\n        -options => [[jan =>1], [feb =>2]],\n        -command => sub { \n            my @nums = @_;\n            show_table_data($nums[0], $table);                \n        },\n        -variable => \\$var,\n        -textvariable => \\$tvar,\n    )->pack(-side => 'left', -anchor => 'n',);  \n\n    my $f2 = $mw->Frame()->pack(-side=>'bottom');\n    $table = $f2->Table( -columns => 2);\n\n    foreach my $c (0 .. 1) {\n        if ($c) {\n            my $t = $table->Label(-text => 'product'); \n            $table->put(0, $c, $t); \n        } else {\n            my $t = $table->Label(-text => 'id'); \n            $table->put(0, $c, $t); \n\n        }\n    }\n    $table->pack();\n    MainLoop;\n}\n\nsub show_table_data {\n    my $num = shift;\n    my $table = shift;\n    return if !defined $table;\n    say \"Num = $num\";\n    say \"table = $table\";\n}\n\n"
},
{
"QuestionId": "76394556",
"QuestionTitle": "Android need fullwidth drawerlayout. it should appear and disappear when hamburger icon is clicked",
"QuestionBody": "xml code\n    <?xml version=\"1.0\" encoding=\"utf-8\"?>\n<androidx.constraintlayout.widget.ConstraintLayout\n    xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    android:background=\"@drawable/app_background_01\"\n    tools:context=\".FullscreenActivity\">\n    <androidx.constraintlayout.widget.ConstraintLayout\n        android:id=\"@+id/topbar\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"50dp\"\n         app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintTop_toTopOf=\"parent\">\n        <ImageView\n            android:id=\"@+id/actionDrawer\"\n            android:layout_width=\"28dp\"\n            android:layout_height=\"28dp\"\n            android:layout_marginStart=\"16dp\"\n            app:layout_constraintBottom_toBottomOf=\"parent\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\"\n            app:srcCompat=\"@drawable/ic_hamburger\" />\n\n        <ImageView\n            android:id=\"@+id/actionHome\"\n            android:layout_width=\"28dp\"\n            android:layout_height=\"28dp\"\n            android:layout_marginRight=\"16dp\"\n            app:layout_constraintBottom_toBottomOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\"\n            app:srcCompat=\"@drawable/ic_home\" />\n    </androidx.constraintlayout.widget.ConstraintLayout>\n\n    <androidx.constraintlayout.widget.ConstraintLayout\n        android:id=\"@+id/containerFragments\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"0dp\"\n        app:layout_constraintBottom_toBottomOf=\"parent\"\n        app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintTop_toBottomOf=\"@id/topbar\">\n\n        <TextView\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"match_parent\"\n            android:fontFamily=\"sans-serif-condensed\"\n            android:text=\"This is Home page\"\n            android:textAlignment=\"center\"\n            android:textColor=\"#FFFFFF\"\n            android:textSize=\"40sp\"\n            app:layout_constraintBottom_toBottomOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\">\n\n        </TextView>\n    </androidx.constraintlayout.widget.ConstraintLayout>\n\n    <androidx.drawerlayout.widget.DrawerLayout\n        android:id=\"@+id/drawer\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"match_parent\"\n        android:layout_marginTop=\"50dp\"\n        app:layout_constraintBottom_toBottomOf=\"parent\"\n        app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintTop_toBottomOf=\"@+id/topbar\">\n            <LinearLayout\n                android:layout_width=\"match_parent\"\n                android:layout_height=\"match_parent\"\n                app:layout_constraintEnd_toEndOf=\"parent\"\n                app:layout_constraintStart_toStartOf=\"parent\"\n                android:background=\"@drawable/app_background_01\"\n                android:orientation=\"vertical\"\n                android:layout_gravity=\"left\">\n                <androidx.constraintlayout.widget.ConstraintLayout\n                    android:layout_width=\"match_parent\"\n                    android:layout_height=\"wrap_content\"\n                    app:layout_constraintEnd_toEndOf=\"parent\"\n                    app:layout_constraintStart_toStartOf=\"parent\">\n                    <ImageView\n                        android:id=\"@+id/imageView2\"\n                        android:layout_width=\"50dp\"\n                        android:layout_height=\"50dp\"\n                        app:layout_constraintBottom_toBottomOf=\"parent\"\n                        app:layout_constraintStart_toStartOf=\"parent\"\n                        app:layout_constraintTop_toTopOf=\"parent\"\n                        app:srcCompat=\"?android:attr/textSelectHandle\" />\n                </androidx.constraintlayout.widget.ConstraintLayout>\n            </LinearLayout>\n    </androidx.drawerlayout.widget.DrawerLayout>\n</androidx.constraintlayout.widget.ConstraintLayout>\n\nkotlin code\npackage com.example.testdrawer\n\nimport androidx.appcompat.app.AppCompatActivity\nimport android.os.Bundle\nimport android.view.Gravity\nimport androidx.constraintlayout.widget.ConstraintLayout\nimport androidx.core.view.GravityCompat\nimport com.example.testdrawer.databinding.ActivityFullscreenBinding\n\nclass FullscreenActivity : AppCompatActivity() {\n    private lateinit var binding: ActivityFullscreenBinding\n\n    override fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        binding = ActivityFullscreenBinding.inflate(layoutInflater)\n        setContentView(binding.root)\n        setListeners()\n    }\n    private fun setListeners() {\n        binding.actionDrawer.setOnClickListener {\n            if (binding.drawer.isDrawerOpen(GravityCompat.START)) {\n                binding.drawer.closeDrawer(Gravity.LEFT)\n            } else {\n                binding.drawer.openDrawer(GravityCompat.START)\n            }\n        }\n    }\n}\n\nBehaviour Required\n1- Home screen comes in start\n2- When click on hamburger icon the drawerlayout should come with full height and width also containing hamrbuger and home icons.\n3- When click on hamburger icon the drawerlayout should close and the home screen should come.\nIssues\n1- drawerlayout is not full width and required functionality is not achievable.\nThe below is the homescreen\n\nWant the drawerlayout to fully occupy the screen as in the design its having full background and icons on top.\n\nWhen I tried Drawerlayout constraint in xml toptotopof parents I was not able to click on hamburger icon\n",
"AnswerId": "76395167",
"AnswerBody": "you can add negative margin for the sides of your drawer layout to fill the whole screen.\nandroid:layout_marginRight=\"-64dp\"\n\n"
},
{
"QuestionId": "76397897",
"QuestionTitle": "How do I disable bpython colored output?",
"QuestionBody": "bpython by default has a really nice blue theme, but it doesn't go well with light backgrounds. How can I disable its colour output and have it give just plain black (on Arch Linux)?\n",
"AnswerId": "76397934",
"AnswerBody": "You could create a theme that only uses black as an output color. That might look like:\n[syntax]\nkeyword = k\nname = k\ncomment = k\nstring = k\nerror = k\nnumber = K\noperator = K\npunctuation = k\ntoken = K\nparen = K\n\n[interface]\nbackground = d\noutput = k\nmain = k\nprompt = k\nprompt_more = k\nright_arrow_suggestion = K\n\nThis is based on the default theme, replacing all the colors with k (for normal black) or K (for bold black).\nSave this in ~/.config/bpython/light.theme and then set color_scheme = light in ~/.config/bpython/config.\n"
},
{
"QuestionId": "76396610",
"QuestionTitle": "Remove everything in brackets at the end",
"QuestionBody": "I'd like to removing everything that is is brackets () if (and only if) they are at the end and not do match the following pattern \\(\\d{4}\\p{Pd}\\d{4}\\) *. This pattern is nothing more than date range in brackets, eg. (1920-2988).\nFor instance, I'd like to match/capture (for removing, ie. string.replaceAll(my_regex_here, \"\")):\n\nfoo bar (blah)\n\nfoo bar (blah) blah (blah)\n\n\nI don't like to match:\n\nsome (blah) data\nsome date following (1920-1921).\n\nI have the following regex: \\s*(.+?)\\s*$. It tends to match too much:\n\nsome data (..) match (match)\nsome data (1920-1977)\n\n",
"AnswerId": "76396741",
"AnswerBody": "Use negative look ahead to avoid date ranges, then actually match it using [^()]+?:\n\\s*\\(                  # Match 0+ spaces, a '(',\n(?!\\d{4}\\p{Pd}\\d{4}\\)) # which is not followed by a date range and a ')',\n[^()]+                 # 1+ non-parenthesis characters and\n\\)\\s*$                 # ')' then 0+ spaces right before the end of line.\n\nTry it on regex101.com.\nThe above regex will not match:\nparentheses with no content ()\nyears with more than 4 digits (1234-56789)\nor less than 4 (123-4567)\nnested ((brackets))\nmismatched (brackets\n\n"
},
{
"QuestionId": "76397679",
"QuestionTitle": "TrackBar: no Scroll events in the list",
"QuestionBody": "I replaced my TrackBar with another TrackBar but when I look for the Scroll event of the new TrackBar I can't find it.\nHere is the cole of the old TrackBar:\nprivate void TrackBar_Scroll(object sender, ScrollEventArgs e)\n\nHow can I create the Scroll event for the new TrackBar, as it doesn't exist in the event list?\n",
"AnswerId": "76397939",
"AnswerBody": "Looking at the code of the HZH_Controls in their Github, it would appear you need to handle the ValueChanged event.\n/// <summary>\n/// Occurs when [value changed].\n/// </summary>\n[Description(\"值改变事件\"), Category(\"自定义\")]\npublic event EventHandler ValueChanged;\n\nOther parts of the code suggest that this event is raised Scrollbar is moved\n"
},
{
"QuestionId": "76394788",
"QuestionTitle": "Reorder data from multiplexed column values to rows",
"QuestionBody": "I have a table organization as below where temperature measurements are all stored in one column and there are 14 different temperature samples at different depths per timestamp.\nselect * from water_temp order by unixtimestamp desc limit 28;\n\n\n\n\n\nid\nunixtimestamp\ndepthname\ndepth\ntemperature\n\n\n\n\n481042727209\n1685770037\n600ft\n600\n38.5910000\n\n\n481042727208\n1685770037\n500ft\n500\n38.6960000\n\n\n481042727207\n1685770037\n400ft\n400\n38.6570000\n\n\n481042727206\n1685770037\n300ft\n300\n38.9040000\n\n\n481042727205\n1685770037\n200ft\n200\n39.3400000\n\n\n481042727204\n1685770037\n150ft\n150\n39.5030000\n\n\n481042727203\n1685770037\n100ft\n100\n40.2140000\n\n\n481042727202\n1685770037\n80ft\n80\n41.3850000\n\n\n481042727201\n1685770037\n60ft\n60\n44.1530000\n\n\n481042727200\n1685770037\n50ft\n50\n46.2590000\n\n\n481042727199\n1685770037\n40ft\n40\n47.2420000\n\n\n481042727198\n1685770037\n30ft\n30\n49.7390000\n\n\n481042727197\n1685770037\n20ft\n20\n55.3010000\n\n\n481042727196\n1685770037\n10ft\n10\n61.8840000\n\n\n481041534602\n1685769380\n600ft\n600\n38.5910000\n\n\n481041534601\n1685769380\n500ft\n500\n38.6400000\n\n\n481041534600\n1685769380\n400ft\n400\n38.7130000\n\n\n481041534599\n1685769380\n300ft\n300\n38.9040000\n\n\n481041534598\n1685769380\n200ft\n200\n39.2840000\n\n\n481041534597\n1685769380\n150ft\n150\n39.5600000\n\n\n481041534596\n1685769380\n100ft\n100\n40.2700000\n\n\n481041534595\n1685769380\n80ft\n80\n41.4410000\n\n\n481041534594\n1685769380\n60ft\n60\n44.3220000\n\n\n481041534593\n1685769380\n50ft\n50\n46.3150000\n\n\n481041534592\n1685769380\n40ft\n40\n47.3540000\n\n\n481041534591\n1685769380\n30ft\n30\n49.9070000\n\n\n481041534590\n1685769380\n20ft\n20\n56.1450000\n\n\n481041534589\n1685769380\n10ft\n10\n62.5030000\n\n\n\n\nHoping to get output in this format:\n\n\n\n\nunixtimestamp\ndepth10\ndepth20\ndepth30\n...\n\n\n\n\n1685769380\n62.5\n56.14\n49.91\n...\n\n\n1685770037\n61.8\n55.3\n49.74\n...\n\n\n...\n...\n...\n...\n...\n\n\n\n\nI have inherited this table format. I have tried using distinct but can't find a way to have a distinct timestamp and depth. Thinking I may have to dump the data and use python to read and reorganize in a one row per timestamp.\nIs there a straightforward SQL query to get the data to list in one row per timestamp with each depth temperature as columns? I want to output the data in csv format where each row is one timestamp.\nAlso is there some reason to organize data in a DB in the manner? I am tying to understand. Seems to me the more intuitive/useful way would be to have one column per temperature depth and one row per timestamp.\nThanks in advance.\n",
"AnswerId": "76395179",
"AnswerBody": "\nIs there some reason to organize data in a DB in the manner? I am tying to understand. Seems to me the more intuitive/useful way would be to have one column per temperature depth and one row per timestamp.\n\nYou organize data in a way so that your queries are faster or to make data more consumable for your purposes. If having pivoted data make them more consumable for your needs, you should go for it.\nJust to give you an example, if you had to get depth values when the temperature went higher than 40, attempting to do it with the output you're requiring, would likely force you to go through unpivoting, while it would be straight simple if you used your original table.\nConversely, if you need to do some kind of reporting, and observe only temperatures for specific depths (say depth 10 and depth 100), using the input table would require you a filtering, while using the output table can give you that instantly.\n\nWhat you're looking for is called \"pivot\", and allows you to change rows into columns. Since in the output there are 14 columns dedicated to depth (from the data I assume they're always 14 for each timestamp), you should expect to put 14 computed fields inside the SELECT statement, like:\nSELECT unixtimestamp,\n       ... AS depth10,\n       ... AS depth20,\n       ... AS depth30,\n       ... AS depth40,\n       ...\n       ... AS depth600\nFROM water_temp \n\nThen you realize that you actually need to select your temperatures, but only when the depth corresponds to your selected depth. Something you can do with a CASE expression (or an IF, if we want):\nSELECT unixtimestamp,\n       CASE WHEN depth =  10 THEN temperature END AS depth10,\n       CASE WHEN depth =  20 THEN temperature END AS depth20,\n       CASE WHEN depth =  30 THEN temperature END AS depth30,\n       CASE WHEN depth =  40 THEN temperature END AS depth40,\n       ...\n       CASE WHEN depth = 600 THEN temperature END AS depth600\nFROM water_temp \n\nAnd when you attempt to do that, you realize you will have a kind of squared matrix, for which unique timestamp has now 14 records, each of which with one non-null value (on the corresponding depth column).\nSince you wanted one record only, for each of your timestamps, one of the best options for reducing the size of tables is aggregation (as long as it \"aggregates\" data). You need to aggregate by grouping on your timestamps (because you want one record for each timestamp), and using an aggregate function that can compress one non-null value with other null values, and that's either MIN or MAX. Your code then becomes:\nSELECT unixtimestamp,\n       MAX(CASE WHEN depth =  10 THEN temperature END) AS depth10,\n       MAX(CASE WHEN depth =  20 THEN temperature END) AS depth20,\n       MAX(CASE WHEN depth =  30 THEN temperature END) AS depth30,\n       MAX(CASE WHEN depth =  40 THEN temperature END) AS depth40,\n       ...\n       MAX(CASE WHEN depth = 600 THEN temperature END) AS depth600\nFROM water_temp \nGROUP BY unixtimestamp\n\nwhich gives you exactly what you were looking for.\n"
},
{
"QuestionId": "76396158",
"QuestionTitle": "\"instagram api\" business discovery api on python return 'Invalid OAuth access token - Cannot parse access token' error",
"QuestionBody": "I'm writing python code to use instagram graph api/business discovery to get data.\nBut I get \"Invalid OAuth access token\" error but I could not figure out how to solve this problam, please enlighten me.\nFollowing code works fine on Graph Api Explorer\nIgUserId?fields=business_discovery.username(bluebottle){followers_count,media_count,name}\n\nBut when I operate following code on Python file in Jupyter lab\nimport requests\nimport pandas as pd\npd.set_option('display.max_rows', None)\n\n# information\nbusiness_account_id = \"same as IgUserId\"\ntoken = \"one that generated on Graph Api Explorer\"\nfields = \"followers_count,media_count,name\"\nversion = \"v17.0\"\nusername = \"bluebottle\"\n\ndef user_info(version, igUserId,token,username,fields):\n    request_url = \"https://graph.facebook.com/{version}/{igUserId}?fields={fields}&access_token={access-token}\"\n    response = requests.get(request_url)\n    return response.json()\n\nprint(user_info(business_account_id,token,username,fields,version))\n\nI get following error\n\n{'error': {'message': 'Invalid OAuth access token - Cannot parse access token', 'type': 'OAuthException', 'code': 190, 'fbtrace_id': 'Just for case I'm deleteing this bit'}}\n\nTo avoid my misunderstanding to confuse anybody, following is picture of Graph Api Explorer where I got Access Token which I just copy and pasted from top black shadowed bit.\n\n",
"AnswerId": "76396782",
"AnswerBody": "I am not a Python guy, but just to help you I modified your Python script and while doing that, I saw many issues with your script. Use the below script which I tested with my IG User ID and access_token and is working perfectly fine.\nimport requests\nimport pandas as pd\npd.set_option('display.max_rows', None)\n\n# information\nbusiness_account_id = \"YOUR_IG_USER_ID\"\naccess_token = \"YOUR_ACCESS_TOKEN\"\nfields = \"followers_count,media_count,name\"\nversion = \"v17.0\"\nusername = \"bluebottle\"\n\ndef user_info(version, igUserId,access_token,username,fields):\n    request_url = f\"https://graph.facebook.com/{version}/{igUserId}?fields=business_discovery.username({username}){{{fields}}}&access_token={access_token}\"\n    print(request_url);\n    response = requests.get(request_url)\n    return response.json()\n\nprint(user_info(version,business_account_id,access_token,username,fields))\n\nOutput:-\n{'business_discovery': {'followers_count': 442462, 'media_count': 2076, 'name': 'Blue Bottle Coffee', 'id': '17841401441775531'}, 'id': '17841448XXXXX'}\n\nI used Python 3.10.6 to test this script.\nHope this helps.\n"
},
{
"QuestionId": "76397787",
"QuestionTitle": "Renaming dataframe columns via User Defined Function via Pandas",
"QuestionBody": "i'm trying to rename dataframe columns through User Defined Function without success.\nIn particular it seems that doesn't exist \"rename\" method when called inside a UDF.\nFollowing an example to better explain my problem:\nimport pandas as pd`\n\ndata = {'Age': [21, 19, 20, 18,80,90],'Stream': [88, 65,99, 765,65,55],'Percentage': [88, 92, 95, 70,55,47]}\n\ndf = pd.DataFrame(data, columns=['Age', 'Stream', 'Percentage'])\n\nprint(\"Given Dataframe :n\", df)\n\ndef modname(frame):\n\n\n    frame=frame.rename(columns={'Age':'aa','Stream':'bb','Percentage':'cc'})\n    \n    return frame\n\ndf=df.apply(modname)\n\nprint(df)\n\n`\nI greatly appreciate your help\ni tried the same code without UDF and it works\n",
"AnswerId": "76397970",
"AnswerBody": "Instead of doing:\ndf=df.apply(modname)\n\nYou should do:\ndf = modname(df)\n\n"
},
{
"QuestionId": "76395115",
"QuestionTitle": "How to create comment block in visual studio fast?",
"QuestionBody": "In Eclipse I can just type /* and enter, and it would form a perfect comment block for complex comments above the code:\n/*\n *\n */\n\nHow to do the same or similar in Visual Studio?\n",
"AnswerId": "76395187",
"AnswerBody": "What language? I'm going to assume C++.\nTools > Options > Text Editor > C/C++ > Advanced > Brace Completion > Complete Multiline Comments > True\nThis setting will do exactly what you describe. Typing /* will auto-complete the */ and any new line entered after /* will auto-insert a new * at the beginning of the line.\nAlternatively:\n\nDownload and install Visual Assist: https://www.wholetomato.com/\nHighlight code to be commented.\nShift + 8 or * on the keypad.\nProfit.\n\n"
},
{
"QuestionId": "76396291",
"QuestionTitle": "Error encountered when trying to plot individual trees from cforest() forest using the partykit package in R",
"QuestionBody": "I am doing conditional inference tree analysis using the partykit package in R. I want to plot any tree that is extracted from the forest grown by cforest(). But I got an error message when I am trying with the plot function. The following is a chunk of codes that may produce the like error message with the iris data.\nCode:\nlibrary(partykit)\n\ncf <- cforest(Species ~., data=iris)\ntr <- gettree(cf, tree=1)\nplot(tr)\n\nErrors in console:\n\nError in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, :\n‘min’ not meaningful for factors\n\nI am expecting plots for individual trees in the cforest() result.\n",
"AnswerId": "76396797",
"AnswerBody": "I have got an answer after researching into it.\nSince plot works well with ctree() objects, I compared the extracted tree from cforest and the tree generated by ctree() and found the following difference in their data structure.\nFor ctree object, which can be plotted:\n$ fitted:'data.frame':  150 obs. of  3 variables:\n  ..$ (fitted)  : int [1:150] 2 2 2 2 2 2 2 2 2 2 ...\n  ..$ (weights) : num [1:150] 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ (response): Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nbut for a tree from cforest() result, which cannot be plotted:\n$ fitted:'data.frame':  150 obs. of  4 variables:\n  ..$ idx       : int [1:150] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ (response): Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ (weights) : int [1:150] 0 1 1 1 1 1 1 1 0 0 ...\n  ..$ (fitted)  : int [1:150] 2 2 2 2 2 2 2 2 2 2 ...\n\nPlease note that the variables (response), (weights) and (fitted) are in different columns in the data structure of \"fitted\" dataframe in these two trees.\nTherefore, I use the following manipulation to adjust the \"fitted\" dataframe structure in the cforest tree object, and plotting is successful:\nlibrary(partykit)\ncf <- cforest(Species ~., data=iris)\ntr <- gettree(cf, tree=1)\nnfitted <- data.frame(tr$fitted$`(fitted)`,tr$fitted$`(weights)`,tr$fitted$`(response)`)\ncolnames(nfitted) <- c('(fitted)', '(weights)', '(response)')\ntr$fitted <- nfitted\nplot(tr)\n\nHope this will help those who encounter the same problem with the plotting of trees from cforest() in the partykit package.\n"
},
{
"QuestionId": "76397687",
"QuestionTitle": "SQL ORDER BY next",
"QuestionBody": "Please tell me how to sort in PostgreSQL (15+) such a table:\nid |  name  | next_id\n1  | Test01 |  2\n2  | Test02 |  3\n3  | Test03 |  6\n4  | Test04 |  5\n5  | Test05 |  null\n6  | Test06 |  4\n7  | Test07 |  null\n\nIt takes an SQL query to order by the next_id column - it's a pointer to the next row. The result I expect is:\nid |  name  | next_id\n1  | Test01 |  2\n2  | Test02 |  3\n3  | Test03 |  6\n6  | Test06 |  4\n4  | Test04 |  5\n5  | Test05 |  null\n7  | Test07 |  null\n\nIt is necessary to read the next_id field for each record, find this record and display it after the existing one. After all, this field can change, so sorting in ascending order will not work and other tricks.\nSo far, there are no ideas how to do it gracefully. Except for loops and temporary tables.\n",
"AnswerId": "76397971",
"AnswerBody": "The following demonstrates an approach to sorting as requested:\nWITH RECURSIVE t(id, name, next_id) AS (\n  VALUES (1  , 'Test01',   2),\n         (2  , 'Test02',   3),\n         (3  , 'Test03',   6),\n         (4  , 'Test04',   5),\n         (5  , 'Test05',   NULL),\n         (6  , 'Test06',   4),\n         (7  , 'Test07',   NULL)),\ncte AS (\n  SELECT t.id, t.name, t.next_id, t.id AS root_id, 1 AS depth\n    FROM t\n   WHERE NOT EXISTS (SELECT * FROM t t2 WHERE t.id = t2.next_id)\n  UNION ALL\n  SELECT t.id, t.name, t.next_id, cte.root_id, cte.depth + 1 AS depth\n    FROM t\n    JOIN cte ON (t.id = cte.next_id))\nSELECT cte.id, cte.name, cte.next_id\n  FROM cte\n ORDER BY cte.root_id, cte.depth, cte.id;\n\nThis query assumes that there are no cycles in the path defined by next_id.\nThe query first initializes the recursive CTE by identifying the rows that are not referenced by any next_id, memoizing the root id, and initializing depth. The recursive portion of the CTE finds the rows referenced by these root rows and incrementing depth. The recursive part repeats using the rows discovered by the prior iteration until no rows are found.\nThe final step sorts by root_id, depth, and id. Including id in the sort is done to create a deterministic order for the case of ids with multiple next_ids (a tree structure instead of linear paths): it can be left out if only linear paths are allowed.\n"
},
{
"QuestionId": "76394209",
"QuestionTitle": "Creating AWS Security Group for a range of ports in Terraform",
"QuestionBody": "I want to create the following AWS security group in Terraform, using Hashi Corp Language. In this configuration the second ingress rule contains the range of ports, but such a syntax is not supported by Terraform.\nIn current implementation Terraform treats port's range as the math expression and computes the difference which gives the negative value. If I close the port range in parenthesis it fails because it requires number format.\nWhat is the appropriate way to create ingress rule for a large range of ports?\n  resource \"aws_security_group\" \"sg_nx\" {\n  name   = \"sg_nx\"\n  vpc_id = aws_vpc.vpc.id\n  ingress {\n    from_port   = 4000\n    to_port     = 4000\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  ingress {\n    from_port   = 4011-4999\n    to_port     = 4011-4999\n    protocol    = \"udp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nUsing list does not work either. I know Terraform allows dynamicly generated resources, how to implement it in this case?\n",
"AnswerId": "76395234",
"AnswerBody": "If you look at AWS docs https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules.html they support port range. The way to do it with terraform is:\nfrom_port = 4011 and to_port = 4999\nSee also the terraform docs:\nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group#from_port\n"
},
{
"QuestionId": "76396441",
"QuestionTitle": "Best practice for allowing multiple Vulkan instances as part of 'renderer' objects",
"QuestionBody": "I'm writing a library in C to abstract multiple graphics APIs including Vulkan behind the same interface.\nCurrently, the library allows for the creation of multiple 'renderer' objects, which contain a whole 'state' of a graphics API - as it stands, this translates to having one Vulkan instance per renderer, for example.\nHowever, I am using volk to load Vulkan symbols. This library loads global functions based on the extensions enabled for a Vulkan instance, and problems arise when attempting to create multiple instances, potentially with different layers/extensions enabled.\nFor example, if I create an instance with debug utils enabled, the associated functions like vkCreateDebugUtilsMessengerEXT are loaded as expected. If I then create another instance without debug utils enabled, these functions seem to be unloaded, which sets their function pointers to NULL, causing a segfault when the instance that enabled them attempts to call them.\nAt the end of the day, supporting multiple Vulkan instances seems to be introducing a lot of issues - is there perhaps a better way of abstracting this design, or should I just limit the user to creating one Vulkan renderer (and therefore one instance) per program?\n",
"AnswerId": "76396804",
"AnswerBody": "Function pointers obtained through a particular VkInstance object (through vkGetInstanceProcAddr) cannot be used with different instance objects. This is just as true of the Vulkan SDK as it is of Volk. That is, a function pointer obtained as the result of calling volkLoadInstance(some_instance) can only be used on other some_instance objects or those derived from them (like VkDevices).\nNote that Volk doesn't hand you function pointers; it initializes global function pointers. Therefore, if you call volkLoadInstance, all of the global functions it hands you are bound to that instance. You can call it again for a different instance, but you're just changing which global pointers you're talking about.\nThat is, Volk is specifically designed to be used with a single instance. It has functionality for easily using it with multiple devices without dynamic dispatch logic (volkLoadDeviceTable returns a table of function pointers specific to a device), but it has no similar construct for instances.\nAs such, trying to allow each \"renderer\" to have its own VkInstance object is going to run into problems. volkLoadInstance is not a fast function.\nThe reason Volk is written this way is because creating multiple instances like this is generally... not useful. Vulkan instance extensions tend to be about the interaction between your code and the operating system.\nConsider VK_KHR_surface. This is an instance extension that acts as glue between your program and an OS window. If you want to render into a window, you need this instance extension. But the glue between the OS window (represented by a VkSurfaceKHR) and a Vulkan device is governed by VK_KHR_swapchain, which is a device extension. A device created from an instance doesn't have to use that extension. If it doesn't, then it won't be able to render into a surface.\nBut it doesn't harm the device in any way to have been created from an instance that uses VK_KHR_surface. So you should get your \"renderers\" together and set down a list of instance extensions that they could rely on, and then require them for the one VkInstance that they all share.\n\nBroadly speaking, separate VkInstance objects exist primarily for DLLs, where there is a hard barrier between the global state of two pieces of code that happen to exist in the same program. One DLL can use a Vulkan instance, while the main program uses a separate one. The separate instances, and attendant global instance function pointers, make it easy for these two pieces of code to co-exist without stomping on each other.\n"
},
{
"QuestionId": "76397780",
"QuestionTitle": "Compose WebView - avoid closing application when I press button back, but save ability go back in web view",
"QuestionBody": "I am experiencing an issue with the BackButton in a Compose WebView. The current code works well with the WebView backstack. However, when the backstack is empty and the back button is pressed, it causes the application to close, which is not the desired behavior.\n@Composable\nfun StatScreen(zeusPrefManager: ZeusPrefManager){\n\n    var fPCallback: ValueCallback<Array<Uri>>? by remember {\n        mutableStateOf(null)\n    }\n\n    val launcher = rememberLauncherForActivityResult(\n        contract = ActivityResultContracts.GetMultipleContents()\n    ) {\n        fPCallback!!.onReceiveValue(it.toTypedArray())\n    }\n\n    var backEnabled by remember { mutableStateOf(false) }\n    var webView: WebView? = null\n\n\n    var gameStat by remember {\n        mutableStateOf(\"\")\n    }\n\n    LaunchedEffect(key1 = \"goStat\"){\n        val destination = zeusPrefManager.zeusStatDataFlow.first()\n        gameStat = destination\n    }\n\n    if (gameStat != \"\"){\n        AndroidView(factory = { context ->\n            WebView(context).apply {\n                layoutParams = ViewGroup.LayoutParams(\n                    ViewGroup.LayoutParams.MATCH_PARENT,\n                    ViewGroup.LayoutParams.MATCH_PARENT\n                )\n                settings.javaScriptEnabled = true\n                settings.domStorageEnabled = true\n                settings.loadWithOverviewMode = true\n                settings.userAgentString = ZeusConstan.converter007(settings.userAgentString)\n\n                webViewClient = object: WebViewClient(){\n\n                    override fun onPageStarted(view: WebView, url: String?, favicon: Bitmap?) {\n                        backEnabled = view.canGoBack()\n                    }\n\n                    override fun onPageFinished(view: WebView?, url: String?) {\n                        super.onPageFinished(view, url)\n\n                    }\n                }\n\n                webChromeClient = object : WebChromeClient(){\n                    override fun onShowFileChooser(\n                        webView: WebView?,\n                        filePathCallback: ValueCallback<Array<Uri>>?,\n                        fileChooserParams: FileChooserParams?\n                    ): Boolean {\n\n                        if (fPCallback != null){\n                            fPCallback!!.onReceiveValue(null)\n                        }\n                        fPCallback = filePathCallback\n                        launcher.launch(\"image/*\")\n                        return true\n                    }\n                }\n                loadUrl(gameStat)\n            }\n        }, update = {\n            webView = it\n        })\n\n        BackHandler(enabled = backEnabled) {\n            if (webView!!.canGoBack()){\n                webView?.goBack()\n            } else {\n                //Do nothing but webView!!.canGoBack() is always true, and close the app\n            }\n\n        }\n    }\n}\n\nI didn't override onBackPressed() in Activity.\nI need to avoid closing application when I press button back\n",
"AnswerId": "76397994",
"AnswerBody": "you can make use of the onBackPressedDispatcher in your activity. Change your code as below-\n    @Composable\nfun StatScreen(zeusPrefManager: ZeusPrefManager, onBackPressed: () -> Unit) {\n    \n    BackHandler(enabled = backEnabled) {\n        if (webView!!.canGoBack()) {\n            webView?.goBack()\n        } else {\n            onBackPressed()\n        }\n    }\n}\n\nIn your activity, override the onBackPressed() method and pass it to the StatScreen composable function:\noverride fun onBackPressed() {\n    // Handle the back button press here\n}\n\n"
},
{
"QuestionId": "76395225",
"QuestionTitle": "Happend multiple .csv file from Drive Folder to Unique Sheet in Google",
"QuestionBody": "Hello to everyone guys!\nI've got a problem with the code below; my purpose is to retrieve all the .csv file in a google drive folder and put them all in sequence in a specific sheet in Google.\nThe error code that it get is: \"Exception: Cannot convert 'function () { [native code] }1' to int.\"\nCould you please help me solving that issue?\nMany thanks in advance\nfunction happendCSV() {\n  const folder = DriveApp.getFolderById(\"ID_Folder\");\n  const sheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(\"Sheet_Name\");\n  const files = folder.getFiles();\n  while (files.hasNext()) {\n    let file = files.next();\n    //let fn = file.getName();\n    let fileID = file.getId();\n    let fileType = file.getMimeType();\n    if (fileType === \"text/csv\") {\n      let csvData = Utilities.parseCsv(file.getBlob().getDataAsString(), \",\");\n      sheet.getRange(sheet.getLastRow +1, 1, csvData.length, csvData[0].length).setValues(csvData);\n    }\n  }\n}\n\n",
"AnswerId": "76395250",
"AnswerBody": "Modification points:\n\nIn your script, sheet.getLastRow  of sheet.getRange(sheet.getLastRow +1, 1, csvData.length, csvData[0].length).setValues(csvData); should be sheet.getLastRow(). I thought that this might be the reason for your current issue of Exception: Cannot convert 'function () { [native code] }1' to int..\nIn your situation, I thought that getFilesByType might be useful.\nWhen setValues is used outside of the loop, the process cost becomes low a little.\n\nWhen these points are reflected in your script, it becomes as follows.\nModified script:\nfunction happendCSV() {\n  const folder = DriveApp.getFolderById(\"ID_Folder\");\n  const sheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(\"Sheet_Name\");\n  const files = folder.getFilesByType(MimeType.CSV);\n  let values = [];\n  while (files.hasNext()) {\n    let file = files.next();\n    let csvData = Utilities.parseCsv(file.getBlob().getDataAsString(), \",\");\n    values = [...values, ...csvData];\n    console.log(`Now: ${file.getName()}`); // For confirming the current processing file.\n  }\n  sheet.getRange(sheet.getLastRow() + 1, 1, values.length, values[0].length).setValues(values);\n}\n\nNote:\n\nIf your CSV data is large, Sheets API might be suitable instead of Spreadsheet service (SpreadsheetApp).\n\nReferences:\n\ngetFilesByType(mimeType)\ngetLastRow()\n\n"
},
{
"QuestionId": "76397874",
"QuestionTitle": "Get all appointments for the month (including recurring appointments that are scheduled in previous months)",
"QuestionBody": "I am having some issues getting all the appointments from specific month. Problem is with appointments that has been scheduled with recurring setting. Is there some way to get all appointments present in outlook calendar recurring and not recurring?\nThe best so far I was able to achieve is to check for is appointment.IsRecurring and if true I can get some parameters from recurrencePattern. However it seems to work only for appointments that has been set in this specific month with recurring parameter. If appointment with recurrence has been set earlier, then current code does not seem to work.\nIs there some way to get just all the appointments from specific month?\nprivate void GetAllItems(DateTime startDate, DateTime endDate)\n{\n  Outlook.Application outlookApp = new Outlook.Application();\n  Outlook.NameSpace outlookNamespace = outlookApp.GetNamespace(\"MAPI\");\n  Outlook.MAPIFolder calendarFolder = outlookNamespace.GetDefaultFolder(Outlook.OlDefaultFolders.olFolderCalendar);\n  Outlook.Items calendarItems = calendarFolder.Items;\n\n  string restriction = $\"[Start] >= '{startDate.ToShortDateString()}' AND [Start] <= '{endDate.ToShortDateString()}'\";\n  Outlook.Items filteredItems = calendarItems.Restrict(restriction);\n\n  foreach (Outlook.AppointmentItem appointment in filteredItems)\n  {\n    DataModel dataModel = new DataModel\n    {\n      Subject = appointment.Subject,\n    };\n    this.Data.Add(dataModel);\n\n    if (appointment.IsRecurring)\n    {\n      Outlook.RecurrencePattern recurrencePattern = appointment.GetRecurrencePattern();\n\n      DataModel recurringDataModel = new DataModel\n      {\n        Subject = appointment.Subject,\n      };\n      this.Data.Add(recurringDataModel);\n    }\n  }\n}\n\n",
"AnswerId": "76398005",
"AnswerBody": "You are almost there - you need to set the Items.IncludeRecurrences property to true and call Items.Sort on the Start property to tell Items.Restrict to expand the recurrences. See https://learn.microsoft.com/en-us/office/vba/api/outlook.items.includerecurrences for more details and an example\n  Outlook.Items calendarItems = calendarFolder.Items;\n  calendarItems.Sort(\"[Start]\");\n  calendarItems.IncludeRecurrences = true;\n  string restriction = $\"[Start] >= '{startDate.ToShortDateString()}' AND [Start] <= '{endDate.ToShortDateString()}'\";\n  Outlook.Items filteredItems = calendarItems.Restrict(restriction);\n\n"
},
{
"QuestionId": "76396574",
"QuestionTitle": "Qt QObject::connect receiver and slot of different classes",
"QuestionBody": "I have two classes: first one is the main QMainWindow class, and the second one is my custom class. For example, I want to make a connection in the constructor of my custom class where when I press a TestButton (which is a part of the ui of main class), it calls a function from my custom class.\nHere are code:\nProgram.h:\nclass Custom;\n\nclass Program : public QMainWindow\n{\n    Q_OBJECT\n\n    friend class Custom;\n\npublic:\n    Program(QWidget *parent = nullptr);\n    ~Program();\n\nprivate:\n    Ui::ProgramClass ui;\n}\n\nProgram.cpp:\n#include \"Program.h\"\n#include \"Custom.h\"\n\nProgram::Program(QWidget *parent)\n    : QMainWindow(parent)\n{\n    ui.setupUi\n\n    Custom custom = Custom(this);\n}\n\nCustom.h:\n#include \"Program.h\"\n\nclass Custom : public QObject {\n    Q_OBJECT\npublic:\n    Custom(Program* program);\n    ~Custom();\n\npublic slots:\n    void foo();\n\nprivate:\n    Program* m_program;\n}\n\nand finally Custom.cpp:\n#include \"Custom.h\"\n#include \"Program.h\"\n\nCustom::Custom(Program* program) {\n    m_program = program;\n\n    /* Here's the main problem */\n    QObject::connect(m_program->ui.TestButton, &QPushButton::clicked, m_program, &Custom::foo);\n}\n\n/* Here just changing text of the button and set flat true or false every time button is clicked */\nvoid Custom::foo() {\n    QPushButton* button = m_program->ui.TestButton;\n\n    button->setFlat(!button->isFlat());\n    button->setText(button->isFlat() ?\n        \"If you see the text changing when clicking the button, it means test is working correctly\" :\n        \"Text changed\");\n}\n\nThe main part is in the Custom constructor, where I typed connect function.\nError: cannot convert argument 3 from 'Program *' to 'const Custom *.\nSo, a pointer to receiver and to function foo must be the same classes.\nSo I tried this:\nQObject::connect(m_program->ui.TestButton, &QPushButton::clicked, this, &Custom::foo);\nNo error, but there is actually no connection to the main program and when I click the button - nothing changing.\nThe only working variants are:\n\nmake foo function as a method of Program class, BUT I don't want to make Program class have a lot of functions which are actually should be methods of separated classes. And if I want to modify some other fields of these separated classes, this variant won't work;\ntype lambda-function inside QObject::connection, BUT I have some big functions, and I need to call some of them as a slot in QObject::connect oftently.\n\nSo, how can I make a proper connection to the whole program but leave foo function as the method of Custom class?\n",
"AnswerId": "76396831",
"AnswerBody": "The line  Custom custom = Custom(this); creates a local object which \"dies immediately\" after exit from Program constructor, that's not what you want to do. This is what you have to do for an instance of Custom to persist:\n Custom *custom = new Custom(this);\n\nYou can even make pointer named custom a member variable if you want access it later. The constructor of Custom must be:\n Custom::Custom(Program* program) : QObject(program) \n {\n     QObject::connect( m_program->ui.TestButton, &QPushButton::clicked,\n                       this, &Custom::foo );\n }\n\nThis constructor passes pointer to constructor of QObject, which registers Custom as a \"child\" of provided object, a Program in our case. In Qt terms Program will be responsible for Custom instance's destruction.\nIs what you meant to do? To connect a button to an instance of Custom? Frankly, using m_program->ui.TestButton here invades Programs personal space and relies on implementation, but it's an offtopic here.\nBut let's make a step aside and take a look why actually what you did, even if that was utterly wrong, didn't work?\nLet's put aside functions and slots. What you'd do if had to do  this with \"normal\" classes and to call a method foo() of class B using a pointer of distinct class A?\nRight, class B should be derived from A and foo() should be a virtual method first declared in A. THis allows a kind of type erasure where  a pointer  or reference to B can be passed as pointer to A. Functions can be passed by pointer too, but not if they are members of a class. For that a special kind of pointer exist.\n#include <iostream>\n\nclass A {\npublic:\n   virtual void foo() = 0;\n};\n\nclass B : public A {\npublic:\n   virtual void foo() { std::cout << \"Hello from foo()!\\n\"; }\n};\n\n// A registering\\calling class\nclass C {\npublic:\n\n   void connect(A* p) {  \n         cptr = p;\n         f_ptr = &A::foo;\n   }\n\n   void call() {  (cptr->*f_ptr)(); }\nprivate:\n   A    *cptr;\n   void (A::*f_ptr)();\n};\n\nint main() {\n    B  b;\n    C  c;\n    c.connect(&b);\n    c.call();\n}\n\nNow, you must understand what C::connect does there: it saves value of pointer to the object A* p and a pointer to the member. The expression &A::foo, a pointer to a member of A, is legal and correct for overridden &B::foo if we will use it with a pointer to B.\nThe pointer-to-member could be made a parameter of C::connect like  in Qt, but to make it work with any member function we need to create a template and another level of type erasure to save those values. I left it out for brevity.\nIt's almost same what happens with Qt signal\\slot system, at least if you use direct connection and new connect syntax. You need a class instance in order to call its member, that's why connect got such syntax. Even if you had succeed in performing connection, you would have invoked an Undefined Behavior by clicking connected button. Thankfully, Qt handles it gracefully by disconnecting destroyed objects, therefore nothing actually happens.\nThat's why all classes that use signal\\slot have to be descendants of QObject. Signals and slots are just functions. The difference between them is that meta object compiler generates an implementation for signals.\nFor type erasure to work, you can do either of those:\n\nhave to pass a pointer of type QObject* to an instance of Custom and cast it to class Custom in order for QObject::connect to work. The cast is unnecessary if signal or virtual slot is declared in QObject.\nOr you have to pass a pointer to some base class which already got the slot void foo() declared.\n\nYou can declare a slot as virtual and you don't need to do so for signals.\npublic slots:\n    virtual void foo();  // can be pure in abstract class\n\nIt appears to me that to have a QMainWindow as a base class is a bad idea, you'd needs some third class. In simplest cases it creates too verbose code and that's why another overload was introduced, which allows a lambda or functor object.\n"
},
{
"QuestionId": "76397857",
"QuestionTitle": "React Router DOM: Custom Route component not working",
"QuestionBody": "My application in total has 5 routes, out of these 5 for four of them I need a condition to be true first to let user access those routes. So I wanted to create checks for said routes.\nI made PublicRoute and PrivateRoute Components\nimport { Route } from 'react-router-dom';\n\n\nconst PublicRoute = ({ component: Component, ...rest }) => (\n    <Route {...rest} render={(props) => <Component {...props} />} />\n);  \n\nexport default PublicRoute\n\nimport { Route, Redirect } from 'react-router-dom';\n\nconst PrivateRoute = ({ component: Component, isAuthenticated, ...rest }) => (\n  <Route\n    {...rest}\n    render={(props) =>\n      isAuthenticated ? (\n        <Component {...props} />\n      ) : (\n        <Redirect to=\"/\" />\n      )\n    }\n  />\n);\n\nexport default PrivateRoute\n\nAnd my app.js\nimport { Routes } from \"react-router-dom\"\nimport PublicRoute from \"./components/PublicRoute\"\n\nconst App = () => {\n  return (\n    <>\n      <Routes>\n\n        <PublicRoute\n          exact\n          path=\"/\"\n          component={Com}\n        />\n\n      </Routes>\n    </>\n  )\n}\n\nexport default App\n\nconst Com=()=>(\n  <>\n  <h1>Hi</h1>\n  </>\n)\n\nAnd currently I am getting this error\n not a <Route> component. All component children of <Routes> must be a <Route> or <React.Fragment>\n    at invariant (history.ts:48\n\nGiven I am returning a Route Component I can't quite understand why this error pops up. Eventually I want a way to perform checks and keep code clean, If there's another efficient way please let me know!\n",
"AnswerId": "76398007",
"AnswerBody": "The Routes component needs a literal Route component as the child.\nThis worked for me -\nPublicRoute\nimport { Route } from \"react-router-dom\";\n\nconst PublicRoute = ({ component: Component, ...rest }) => (\n  <Component {...rest} />\n);\n\nexport default PublicRoute;\n\n\nApp.js\nimport { BrowserRouter, Routes, Route } from \"react-router-dom\";\nimport PublicRoute from \"./PublicRoute\";\n\nconst App = () => {\n  return (\n    <BrowserRouter>\n      <Routes>\n        <Route\n          exact\n          path=\"/\"\n          element={\n            <PublicRoute component={Com} msg={\"there\"} person={\"sandy\"} />\n          }\n        />\n      </Routes>\n    </BrowserRouter>\n  );\n};\n\nexport default App;\n\nconst Com = ({ msg, person }) => (\n  <>\n    <h1>\n      Hi {msg} {person}\n    </h1>\n  </>\n);\n\n"
},
{
"QuestionId": "76395133",
"QuestionTitle": "To increase the font size of label that appears on hover in chart.js",
"QuestionBody": "I want increase font size of label that appears on hover in chart.js,I am trying to give custom text to label but am not able to increase it's font.\n var myPieChart = new Chart(ctxP, {\n                            type: 'pie',\n                            data: {\n                                labels: datas.labels,\n                                datasets: [{\n                                    label: 'Dataset 1',\n                                    data: datas.value,\n                                    backgroundColor: datas.colour\n                                }],\n                                others: datas.others\n                            },\n                            options: {\n                                hover: {\n                                    mode:'index'\n                                },\n                                legend: {\n                                    display: true,\n                                    position: \"right\",\n                                    \"labels\": {\n                                        \"fontSize\": 20,\n                                    }\n                                },\n                                tooltips: {\n                                    \"fontSize\": 20, bodyFont:20,\n                                    callbacks: {                                       \n                                        label: function (tooltipItem, data) {\n                                            let label = data.labels[tooltipItem.index];\n                                            let value = data.datasets[tooltipItem.datasetIndex].data[tooltipItem.index];\n                                            let otherdata = data.others[tooltipItem.index];\n                                            return ' ' + label + ': ' + value + '%  ' + otherdata;\n                                        }\n                                    }\n                                }, hover: {\n                                    mode: 'index',\n                                    \"label\": {\n                                        \"fontSize\": 20,\n                                    }\n                                }\n                            }\n                        })\n\ni tried hover: {                  mode: 'index', \"label\": { \"fontSize\": 20, } } but it didn't work\nthis is how it looks right now\n",
"AnswerId": "76395272",
"AnswerBody": "To change the font size of tooltips in Chart.js 3.x, just use options.plugins.tooltip.titleFont.size or options.plugins.tooltip.bodyFont.size.\n\n\nlet ctxP=document.getElementById('mychart').getContext('2d');\nlet datas={\n    value: [10, 15, 20, 25],\n    labels: ['A', 'B', 'C', 'D']\n};\nvar myPieChart=new Chart(ctxP, {\n    type: 'pie',\n    data: {\n        labels: datas.labels,\n        datasets: [{\n            label: 'Dataset 1',\n            data: datas.value,\n            backgroundColor: datas.colour\n        }],\n        others: datas.others\n    },\n    options: {\n        hover: {\n            mode: 'index'\n        },\n        legend: {\n            display: true,\n            position: \"right\",\n            \"labels\": {\n                \"fontSize\": 20,\n            }\n        },\n        tooltips: {\n            // \"fontSize\": 20, bodyFont: 20,\n            callbacks: {\n                label: function (tooltipItem, data) {\n                    let label=data.labels[tooltipItem.index];\n                    let value=data.datasets[tooltipItem.datasetIndex].data[tooltipItem.index];\n                    let otherdata=data.others[tooltipItem.index];\n                    return ' '+label+': '+value+'%  '+otherdata;\n                }\n            }\n        },\n        hover: {\n            mode: 'index',\n            \"label\": {\n                \"fontSize\": 20,\n            }\n        },\n        plugins: {\n            tooltip: {\n                titleFont: {\n                    size: 20\n                },\n                bodyFont: {\n                    size: 20\n                }\n            }\n        }\n    }\n})\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.9.1/chart.min.js\"></script>\n<canvas id=\"mychart\"></canvas>\n\n\n\n"
},
{
"QuestionId": "76396771",
"QuestionTitle": "Cypress - How to check if a checkbox is checked or not?",
"QuestionBody": "I have some code below to check if a checkbox is checked or not. Even if the checkbox is checked, it says that its not. Why does the code fail and how to fix it?\nfunction isChecked(locator : string) : boolean {\n let checked : boolean = false;\n cy.get(locator).then(el){\n  if(el.val() === \"on\"){\n   checked = true;//Is actually true when element is checked.\n  }\n }\n return checked;//Is actually false when element is checked.\n}\n\n",
"AnswerId": "76396836",
"AnswerBody": "function isChecked(locator) : Promise<boolean>{\n  return new Cypress.Promise((resolve) => {\n    cy.get(locator).then((el) => {\n      resolve(el.prop('checked'));\n    });\n  });\n}\n\nisChecked('#myCheckbox').then((checked) => {\n  if (checked) {\n    // Checkbox is checked\n  } else {\n    // Checkbox is not checked\n  }\n});\n\n"
},
{
"QuestionId": "76397886",
"QuestionTitle": "Query to find difference between today and yesterday's data along with a pseudo column",
"QuestionBody": "There is a table that stores account data for everyday. I want to find out the difference in data between today and yesterday. The query for table creation and insert statements are below :\nCREATE TABLE daily_account_data (id varchar(6), Name varchar (20), DS_DW_Id varchar(4), flag_1 varchar(5), flag_2 varchar(5), Insert_date date );\n\nINSERT INTO daily_account_data VALUES('A01R11', 'Gene Graham',      'PT12', 'TRUE', 'FALSE', '2023-06-01');\nINSERT INTO daily_account_data VALUES('A01R16', 'Molly Ringwald',   'PT15', 'TRUE', 'TRUE',  '2023-06-01');\nINSERT INTO daily_account_data VALUES('A01R19', 'John Doe',         'PT24', 'FALSE','TRUE',  '2023-06-01');\nINSERT INTO daily_account_data VALUES('A01R34', 'Jane Doe',         'PT26', 'TRUE', 'FALSE', '2023-06-01');\nINSERT INTO daily_account_data VALUES('A01R11', 'Gene Wilder',      'PT12', 'TRUE', 'FALSE', '2023-06-02');\nINSERT INTO daily_account_data VALUES('A01R16', 'Molly Ringwald',   'PT15', 'TRUE', 'TRUE',  '2023-06-02');\nINSERT INTO daily_account_data VALUES('A01R19', 'John Doe',         'PT24', 'TRUE', 'TRUE',  '2023-06-02');\nINSERT INTO daily_account_data VALUES('A01R34', 'Jane Doe',         'PT26', 'TRUE', 'FALSE', '2023-06-02');\n\nI have the query to find the difference in the data of the 2 days.\nSELECT id, name, DS_DW_Id, flag_1, flag_2 FROM daily_account_data WHERE Insert_date = '2023-06-02'\nEXCEPT\nSELECT id, name, DS_DW_Id, flag_1, flag_2 FROM daily_account_data WHERE Insert_date = '2023-06-01';\n\nBut I can't figure out to get the data in the pseudo column. The last column is changed data. On 1st June data the name of the id A01R11 is Gene Graham and on 2nd it is Gene Wilder. The pseudo column should display \"Name change\".\nSimilarly for id A01R19 (John Doe) the value for flag_1 has changed to TRUE. The pseudo column should display \"flag_1 change\".\nThe output should look like :\n\n\n\n\nid\nName\nDS_DW_Id\nflag_1\nflag_2\nData Change\n\n\n\n\nA01R11\nGene Wilder\nPT12\nTRUE\nFALSE\nName Change\n\n\nA01R19\nJohn Doe\nPT24\nTRUE\nTRUE\nflag_1 Change\n\n\n\n",
"AnswerId": "76398014",
"AnswerBody": "You can join the table and subtract the date.\nIf the order of the record is correct (the previous day must be the previous record, you can use the window function(LEAD ))\nselect \n         a.id\n        ,a.Name\n        ,a.DS_DW_Id\n        ,a.flag_1\n        ,a.flag_2\n\n        ,iif(a.Name=b.Name ,'',' Name Change') \n        +iif(a.DS_DW_Id=b.DS_DW_Id ,'',' DS_DW_Id Change')\n        +iif(a.flag_1=b.flag_1 ,'',' flag_1 Change')\n        +iif(a.flag_2=b.flag_2 ,'',' flag_2 Change') AS [Data Change]\n\nfrom daily_account_data a\ninner join(\n            select *\n            from daily_account_data b\n)b on   a.id=b.id \nand DATEADD(day,-1, b.Insert_date)=a.Insert_date\nwhere a.Name<>b.Name \n        or  a.DS_DW_Id<>b.DS_DW_Id   \n        or    a.flag_1<>b.flag_1\n        or    a.flag_2<>b.flag_2\n\n\n"
},
{
"QuestionId": "76394491",
"QuestionTitle": "Why is my .LockAspectRatio=msoTrue showing as an error",
"QuestionBody": "I want to load data including an image from a Userform onto an excel worksheet.  I want to specify the image width and to maintain the aspect ratio.\nThe line .LockASpectRatio = MsoTrue shows as an error.  Can anyone help with the syntax?\n'Save image to Cell\n\n    Dim FileNAme As Variant\n    Dim Img As Picture\n\nIf FileNAme <> \"\" Then\n    \n     FileNAme = Me.TextBox_5\n    \nWith ws\n     Set Img = .Pictures.Insert(FileNAme)\n\nWith Img\n    .Placement = xlMove\n    .Width = 150\n    .LockAspectRatio = msoTrue\n    .Left = ws.Cells(lr, \"D\").Left\n    .Top = ws.Cells(lr, \"D\").Top\n           \nEnd With\n\nEnd With\n\nEnd If\n\n",
"AnswerId": "76395303",
"AnswerBody": "I'm sure it should be\n.ShapeRange.LockAspectRatio = msoTrue\nAnother observation,\nIf FileNAme <> \"\" Then    \n FileNAme = Me.TextBox_5\n\nYou are checking if Textbox is not empty before you set the text box variable. Therefore FileNAme  would always empty.\n"
},
{
"QuestionId": "76396783",
"QuestionTitle": "How to use 'if' and 'else' function to distinguish answer 'yes' from 'no' in python3",
"QuestionBody": "I`ve just started to learn my first coding language, python.\nAnd I want to give to print() informations in my program, depending from user choice.\nI am very fresh so pls be forgiving.\nthe code:\nanswer = input(\"Do You like it?\" + \" Yes/No\")\n    if answer = (yes)\n    print(\"That`s great!\\nThank You\" + name + \".\")\n    else answer == (no)\nprint(\"Sorry to hear that\\nPerhaps we could use other names?\")\n\nI want to give to print() informations in my program, depending from user choice.\nI am very fresh so pls be forgiving.\n",
"AnswerId": "76396846",
"AnswerBody": "you can try and modify this code. hope this helps\ndef ifelse():\n    entername = input() #first user input\n    print('Do you like it?') #first prompt \n    answer = input()\n    \n    if answer == 'yes': \n        print(\"That`s great!\") \n        print(\"Thank You name\" )\n    else:  # you can also use 'elif answer == 'no'\n        #but since you only have two choices consider this a shortcut\n        print(\"Sorry to hear that\")  \n        print(\"Perhaps we could use other names?\")\n        \nifelse()\n\nps. you can format the print statement so that the user input 'entername' can be printed along side it [ you can also do this w/o using def fcns]\n"
},
{
"QuestionId": "76395256",
"QuestionTitle": "I have a trouble in counting amount of \"items\" in binary file. C",
"QuestionBody": "I want to count the amount of \"items\" in binary file using feof and fseek functions.\nI have a binary file with names of people in chars and their salaries in floats.\nbefore each name there is an int that represents the amount of chars in the name.\nfor example my file could look like this (but without spaces and without \\0's):\n5danny5000.00 4lena2500.50\none item is \"4lena2500.50\" for example.\nin my code, the while loop does not stops.\nwhat can I do to repair the problem?\nthanks!\nint count_items(FILE* file)\n{\n    int count=0;\n    int curr_name_len;\n    while (!feof(file))\n    {\n        fread(&curr_name_len, sizeof(int), 1, file);\n        fseek(file, (curr_name_len * sizeof(char)) + sizeof(float), SEEK_CUR);\n        count++;\n    }\n    rewind(file);\n    return count;\n}\n\n",
"AnswerId": "76395340",
"AnswerBody": "feof doesn't check whether the file is at the EOF, it checks whether the eof-indicator of the file was set on a previous operation. fseek allows to seek to an arbitrary position (if the operating system and the file system supports this) to allow for example to write with holes inside of the file, which is useful if you intend to write things inbetween.\nThus the eof-indicator is set after the fread-call, but is cleared after your fseek-call.\nSo this should work:\nint count_items(FILE* file)\n{\n    int count=0;\n    int curr_name_len;\n    for (fread(&curr_name_len, sizeof(int), 1, file);\n         !feof(file);\n         fread(&curr_name_len, sizeof(int), 1, file))\n    {\n        fseek(file, (curr_name_len*sizeof(char))+sizeof(float), SEEK_CUR);\n        count++;\n    }\n    rewind(file);\n    return count;\n}\n\nor if you don't like that style:\nint count_items(FILE* file)\n{\n    int count=0;\n    int curr_name_len;\n\n    fread(&curr_name_len, sizeof(int), 1, file);\n    while (!feof(file))\n    {\n        fseek(file, (curr_name_len*sizeof(char))+sizeof(float), SEEK_CUR);\n        count++;\n        fread(&curr_name_len, sizeof(int), 1, file);\n    }\n    rewind(file);\n    return count;\n}\n\nor less structured, but more clearly:\nint count_items(FILE* file)\n{\n    int count=0;\n    int curr_name_len;\n\n    while (true);\n    {\n        if (sizeof(int) != fread(&curr_name_len, sizeof(int), 1, file)))\n        {\n            break;\n        }\n\n        fseek(file, (curr_name_len*sizeof(char))+sizeof(float), SEEK_CUR);\n        count++;\n    }\n\n    if (feof(file))\n    {\n        rewind(file);\n        return count;\n    }\n\n    if (ferror(file))\n    {\n        /* error handling */\n    }\n    else\n    {\n        /* fatal error handling */\n    }\n}\n\n"
},
{
"QuestionId": "76396806",
"QuestionTitle": "draggable position:absolute div shrinking after hitting edge of position:relative div?",
"QuestionBody": "I have two draggable divs with position:absolute positioned inside of a position:relative div. My problem is that when I drag my divs to the edge of the position:relative parent they start to shrink. I need my draggable divs to stay the same size when they leave the parent's container, but I have no idea how to fix this issue.\nHere's my codepen with the problem\n    <div id=\"all\">\n        <div class=\"move txtbox\">\n            <div class=\"topper\">test test</div>\n            <span id=\"test\">test test etst test test test</span>\n        </div>\n        <div class=\"move txtbox\">\n            <div class=\"topper\">test test</div>\n            <span id=\"test\">test test etst test test test</span>\n        </div>\n    </div>\n    <script src=\"move.js\"></script>\n\n* {\n    box-sizing: border-box;\n    font-family: Arial, Helvetica, sans-serif;\n    line-height: 1.1;\n    margin: 0;\n}\n\n#all {\n    position: relative;\n    margin: 0 auto;\n    width: 50%;\n    height: 100vh;\n}\n\n.move {\n    cursor: move;\n    position: absolute;\n}\n\n.txtbox, .topper {\n    background-color: lightgrey;\n}\n\n.txtbox {\n    min-height: 70px;\n    max-width: 250px;\n}\n\n.topper {\n    font-size: .625em;\n    border-bottom: 1px solid black;\n    padding: 2px;\n}\n\nconst els = document.querySelectorAll(\".move\");\nels.forEach((name) => {\n  dragElement(name);\n});\n\nfunction dragElement(elmnt) {\n  var pos1 = 0,\n    pos2 = 0,\n    pos3 = 0,\n    pos4 = 0;\n  elmnt.onmousedown = dragMouseDown;\n\n  function dragMouseDown(e) {\n    e = e || window.event;\n    e.preventDefault();\n    // get the mouse cursor position at startup:\n    pos3 = e.clientX;\n    pos4 = e.clientY;\n    document.onmouseup = closeDragElement;\n    // call a function whenever the cursor moves:\n    document.onmousemove = elementDrag;\n  }\n  function elementDrag(e) {\n    e = e || window.event;\n    e.preventDefault();\n    // calculate the new cursor position:\n    pos1 = pos3 - e.clientX;\n    pos2 = pos4 - e.clientY;\n    pos3 = e.clientX;\n    pos4 = e.clientY;\n    // set the element's new position:\n    elmnt.style.top = elmnt.offsetTop - pos2 + \"px\";\n    elmnt.style.left = elmnt.offsetLeft - pos1 + \"px\";\n  }\n  function closeDragElement() {\n    /* stop moving when mouse button is released:*/\n    document.onmouseup = null;\n    document.onmousemove = null;\n  }\n}\n\n",
"AnswerId": "76396874",
"AnswerBody": "That's totally fine since an absolute positioned element wraps its content according its relative/absolute parent. Just set the width manually:\nelmnt.style.width = elmnt.offsetWidth + 'px';\n\nCODEPEN\n"
},
{
"QuestionId": "76383000",
"QuestionTitle": "Creating a WHILE Loop in Visio ShapeSheet",
"QuestionBody": "I'm aware that this can be easily done using VBA, but I'd like a macroless solution if possible.\nI have 2 User rows in a Shape's ShapeSheet: User.Count and User.Loop. User.Count will simply store a number, and the While loop will be performed by User.Loop using the following basic conditional:\nUser.Loop = IF(User.Count < 1000, SETF(GETREF(User.Count), User.Count + 1), \"Loop complete!\")  + DEPENDSON(User.Count)\n\nThis executes to User.Count = 41 (these pulses of 41 are consistent). Is performing this type of loop possible?\n",
"AnswerId": "76398016",
"AnswerBody": "\nbecause if the answer ever becomes 42 then that is the end of Life, The Universe and Everything!\n\nPaul you are right ! :)\n\nchanging the loop limit to 40 and\n\nSad, but this trick dont works…\n\nMy experiment results.\n\nMy example file\nMy loop can't make it to the 1000 mark. It has to stop at 80. You can continue the loop through the context menu Go to 1000 limit.\n"
},
{
"QuestionId": "76394237",
"QuestionTitle": "incorrect number of arguments to numeric-type constructor",
"QuestionBody": "So I've been following this tutorial to make a portal shader and I understand by looking elsewhere that I'm apparently missing the expected number of arguments. Error locations indicated\"\n        fixed4 frag (v2f i) : SV_Target\n        {\n            fixed2 uvs = fixed2(i.uv.x, i.uv.y + (_Time.y * _Speed)); <ERROR 1>\n            fixed4 col = tex2D(_MainTex, i.uv);\n\n            UNITY_APPLY_FOG(i.fogCoord, col);\n            return fixed4(col.rgb * _Color.rgb, col.a * i.uv.y * _Intensity); <ERROR 2>\n        }\n\nAt line 58 (first error) there are only two arguments requested by the fixed2 call. It's only calling for two things, which I would expect would be fulfilled by i.uv.x and i.uv.y, and that the addition shouldn't affect the number of arguments..\nAt line 62 (second error), from what I can tell it's returning the arguments R,G,B (multiplied by user input in the _Color variable), and A (multiplied by the Intensity variable), so that should be working, too, right?\nI should note that the second error is only thrown in the absence of line 58, and that these errors are thrown even if I change them to fixed1, fixed2, fixed3, or fixed4, just as experiments.\nSeeing as I've reproduced his code exactly, I can't begin to know where to look that would be causing this error.\nThe whole code is as follows (I've commented out the problem lines, and it works fine without them, just without the desired functionality):\n\n\nShader \"Unlit/Shader_PortalVortex\"\n{\n    Properties\n    {\n        _MainTex (\"Texture\", 2D) = \"white\" {}\n        _Color (\"Color\", Color) = (1, 1, 1, 1)\n        _Intensity (\"Intensity\", Range(0, 1)) = 1\n        _Speed (\"Speed\", Range(0, 1)) = 0.5\n    }\n    SubShader\n    {\n        Tags { \"RenderType\"=\"Opaque\" \"Queue\"=\"Transparent+2\"}\n        ZTest Greater\n        Blend SrcAlpha OneMinusSrcAlpha\n        Cull Front\n        LOD 100\n\n        Pass\n        {\n            CGPROGRAM\n            #pragma vertex vert\n            #pragma fragment frag\n            // make fog work\n            #pragma multi_compile_fog\n\n            #include \"UnityCG.cginc\"\n\n            struct appdata\n            {\n                float4 vertex : POSITION;\n                float2 uv : TEXCOORD0;\n            };\n\n            struct v2f\n            {\n                float2 uv : TEXCOORD0;\n                UNITY_FOG_COORDS(1)\n                float4 vertex : SV_POSITION;\n            };\n\n            sampler2D _MainTex;\n            float4 _MainTex_ST;\n            float4 _Color;\n            float4 _Intensity;\n            float4 _Speed;\n\n            v2f vert (appdata v)\n            {\n                v2f o;\n                o.vertex = UnityObjectToClipPos(v.vertex);\n                o.uv = TRANSFORM_TEX(v.uv, _MainTex);\n                UNITY_TRANSFER_FOG(o,o.vertex);\n                return o;\n            }\n\n            fixed4 frag (v2f i) : SV_Target\n            {\n                //fixed2 uvs = fixed2(i.uv.x, i.uv.y + (_Time.y * _Speed));\n                fixed4 col = tex2D(_MainTex, i.uv);\n\n                UNITY_APPLY_FOG(i.fogCoord, col);\n                //return fixed4(col.rgb * _Color.rgb, col.a * i.uv.y * _Intensity);\n            }\n            ENDCG\n        }\n    }\n}\n  \n\n\n\nThanks in advance.\n",
"AnswerId": "76395389",
"AnswerBody": "Could be happening because of trying to do calculations of mismatching types.\nMost likely it’s because you’re multiplying ‘_Time.y’ by ‘float4 _Speed’.\nfloat4 _Intensity; \nfloat4 _Speed; \n\n// vs\n\n// Incorrect arguments because \n// you’re implicitly calling: ‘fixed2(x, y + (a * (p, q, r, s));’ // error\nfixed2 uvs = fixed2(i.uv.x, i.uv.y + (_Time.y * _Speed));\n\nSame thing for line 62 and Intensity\n\nCast: Try casting to native HLSL types such as ‘float2’. They are more precise than ‘fixed’, which only usually takes 11 bits or make Speed and Intensity float\n\nDebugging: Try removing ’Time’ and ‘Speed’ variables one by one and running each time to see if one of them makes the error or both.\n\n\nHLSL in Unity reference\n"
},
{
"QuestionId": "76397881",
"QuestionTitle": "Returning a Task vs using await",
"QuestionBody": "I am trying to follow the guidance in this blog about not using await when not needed. And first off, if using { ... } is involved, then yes - use await.\nOk, so for the following code, why does DoItTask() not work? Is returning a Task and not using await only work if there are no uses of await in the method?\n    private static async Task<string> ReadOne()\n    {\n        return await readerOne.ReadAsync();\n    }\n\n    private static async Task<string> ReadTwo()\n    {\n        return await readerTwo.ReadAsync();\n    }\n\n    private static async Task<string> ReadThree()\n    {\n        return await readerOne.ReadAsync();\n    }\n\n    private static async Task<string> ReadCombinedAsync(string one, string two, string three)\n    {\n        return await reader.CombineAsync(one, two, three);\n    }\n\n    private static Task<string> ReadCombinedTask(string one, string two, string three)\n    {\n        return reader.CombineAsync(one, two, three);\n    }\n\n    private static async Task<string> DoItAwait()\n    {\n        string one = await ReadOne();\n        string two = await ReadOne();\n        string three = await ReadOne();\n\n        return await ReadCombinedAsync(one, two, three);\n    }\n\n    private static Task<string> DoItTask()\n    {\n        string one = await ReadOne();\n        string two = await ReadOne();\n        string three = await ReadOne();\n\n        return ReadCombinedAsync(one, two, three);\n    }\n\nps - I initially asked this question with a very sloppy example. Apologies for that.\n",
"AnswerId": "76398036",
"AnswerBody": "The following doesn't work, because you cannot use await without async. These keywords always go together when using the Task Parallel Library (TPL):\nprivate static Task<string> DoItTask()\n{\n    //problem: method is not async - compiler error\n    string one = await ReadOne(); \n    string two = await ReadOne();\n    string three = await ReadOne();\n\n    // OK, because method is not async\n    return ReadCombinedAsync(one, two, three);\n}\n\nAsynchronous methods with the async Task signature create a state machine under the hood, which then executes the asynchronous operation without blocking the calling thread. The calling method gets suspended while any Task that is being executed hasn't finished yet. Inside of an asynchronous method, you can only await other asynchronous Tasks or start Tasks without returning them.\nThis is different when you have a synchronous method. There, the Task can actually be returned directly:\npublic Task GetSomeTaskAsync()\n{\n    return SomethingElseAsync();\n}\n\npublic async Task AwaitTaskAsync()\n{\n    await GetSomeTaskAsync();\n}\n\nThis only is useful when you really can just pass along a Task without doing anything else related to that operation, so that you can save some resources, because the state machines of async Task create some overhead. The downside is that you'll lose some stack trace information when exceptions occur.\nYou can find more useful information here: Why use async and return await, when you can return Task directly?\nComing back to your scenario, your only two options here are:\nprivate static async Task<string> DoItTask()\n{\n    string one = await ReadOne();\n    string two = await ReadOne();\n    string three = await ReadOne();\n\n    return await ReadCombinedAsync(one, two, three);\n}\n\nor\nprivate static async Task<Task<string>> DoItTask()\n{\n    string one = await ReadOne();\n    string two = await ReadOne();\n    string three = await ReadOne();\n\n    return ReadCombinedAsync(one, two, three);\n}\n\nThe latter actually returns a Task<string> as the result of the async Task.\nNote: I don't recommend doing this, it will be very confusing for other developers as this is unexpected. Tasks should be awaited whenever possible. If you return a Task, you'll lose parts of the call stack in the stack trace when an exception occurs and it makes debugging quite nasty if you do this in many places, especially when wrapping Tasks in Tasks like this.\n"
},
{
"QuestionId": "76395346",
"QuestionTitle": "Manage edge's weight and attributes with Netoworkx",
"QuestionBody": "I'm facing on a trouble related to how I'm managing the edges and their weight and attributes in a MultiDiGraph.\nI've a list of edges like below:\n[\n(0, 1, {'weight': {'weight': 0.8407885973127324, 'attributes': {'orig_id': 1, 'direction': 1, 'flip': 0, 'lane-length': 3181.294317920477, 'lane-width': 3.6, 'lane-shoulder': 0.0, 'lane-max-speed': 50.0, 'lane-typology': 'real', 'lane-access-points': 6, 'lane-travel-time': 292.159682258003, 'lane-capacity': 7200.0, 'lane-cost': 0.8407885973127324, 'other-attributes': None, 'linestring-wkt': 'LINESTRING (434757.15286960197 4524762.33387408, 434267.30180536775 4525511.90463009, 436180.7891782945 4526762.385413274)'}}}), \n(1, 4, {'weight': {'weight': 0.6659876355281887, 'attributes': {'orig_id': 131, 'direction': 1, 'flip': 0, 'lane-length': 2496.129360921626, 'lane-width': 3.6, 'lane-shoulder': 0.0, 'lane-max-speed': 50.0, 'lane-typology': 'real', 'lan...\n\nThat list is used to add weight and attributes to a MultiDiGraph previous mentioned:\n graph = ntx.MultiDiGraph(weight=None)\n graph.add_weighted_edges_from(edge_list)\n\nTrying to read the properties of a single edge(graph.edges.data()) I see this:\n(0, 1, {'weight': {'weight': 0.8407885973127324, 'attributes': {'orig_id': 1, 'direction': 1, 'flip': 0, 'lane-length': 3181.294317920477, 'lane-width': 3.6, 'lane-shoulder': 0.0, 'lane-max-speed': 50.0, 'lane-typology': 'real', 'lane-access-points': 6, 'lane-travel-time': 292.159682258003, 'lane-capacity': 7200.0, 'lane-cost': 0.8407885973127324, 'other-attributes': None, 'linestring-wkt': 'LINESTRING (434757.15286960197 4524762.33387408, 434267.30180536775 4525511.90463009, 436180.7891782945 4526762.385413274)'}}})\n\nEvery edge is builded in that way: [node[0], node[1], {'weight': weight, 'attributes': attributes}].\nIf I use this way: [node[0], node[1], weight], I see the right use of the weight but I need to use also the attributes.\n[(0, 1, {'weight': 0.8407885973127324}), (1, 4, {'weight': 0.6659876355281887}), (1, 46, {'weight': None}), (4, 5, {'weight': 1.2046936800705539}), (4, 6, {'weight': 0.4469496439663275})....\n\nWhat is the correct way to manage in the same time both weight and attributes?\n",
"AnswerId": "76395409",
"AnswerBody": "Using add_weighted_edges_from does not have an option to add independent edge attributes. It takes a list of triples (u,v,w) and consider w as the weight. That's why, you find a nested dictionary in the weight attribute of the node.\nYou can add shared attribute for the bunch by specifying keyword argument:\ngraph.add_weighted_edgees_from([...], attr1=..., attr2=...)\n\nbut you will find the same attribute values for all edges in the bunch.\nInstead, you can directly use the add_edge method in a for loop:\nfor u, v, attr in [...]:\n   graph.add_edge(u, v, **attr)\n\nwhich will add your edges with individual attributes.\n"
},
{
"QuestionId": "76396049",
"QuestionTitle": "PySpark: Create a new column in dataframe based on another dataframe's cell values",
"QuestionBody": "I have PySpark dataframe dhl_price of the following form:\n+------+-----+-----+-----+------+\n|Weight|    A|    B|    C|     D|\n+------+-----+-----+-----+------+\n|     1|16.78|17.05|20.23|  40.1|\n|     2|16.78|17.05|20.23| 58.07|\n|     3|18.43|18.86| 25.0| 66.03|\n|     4|20.08|20.67|29.77| 73.99|\n\nSo you can get the delivery price based on the category (i.e. the columns A, B, C, D) and the weight of your parcel (i.e. the first column Weight) and for weights larger than 30, we have prices specified only for 30, 40, 50 etc.\nI also have PySpark dataframe requests, one row for each request by a customer. It includes columns product_weight, Type (the category that is in dhl_price). I want to create a new column in requests delivery_fee based on dhl_price dataframe. In particular, for each row in dhl_price column, I want to get a cell value in dhl_price where column is the one specified in column Type and row is the one specified in column product_weight of requests dataframe.\nSo far I could code it in pandas:\ndef get_dhl_fee(weight, type):\n    if weight <= 30:\n        price = dhl_price.loc[dhl_price[\"Weight\"] == weight][type].values[0]\n    else:\n        price = dhl_price.loc[dhl_price[\"Weight\"] >= weight].reset_index(drop = True).iloc[0][type].values[0]\n    return price\n    \nnew_requests[\"dhl_fee\"] = new_requests.apply(lambda x: get_dhl_fee(x[\"product_weight_g\"], x[\"Type\"]), axis = 1)\n\nHow can I do the same with PySpark? I tried to use PySpark's UDF:\n# Define the UDF (User-Defined Function) for calculating DHL fee\n@fn.udf(returnType=DoubleType())\ndef get_dhl_fee(product_weight_g, calculate_way):\n    broadcast_dhl_price = fn.broadcast(dhl_price)\n\n    if weight <= 30:\n        price = broadcast_dhl_price.filter(dhl_price[\"Weight\"] == weight).select(calculate_way).first()[0]\n    else:\n        price = broadcast_dhl_price.filter(dhl_price[\"Weight\"] >= weight).select(calculate_way).first()[0]\n\n    return price\n\n# Register the UDF\nsc.udf.register(\"get_dhl_fee\", get_dhl_fee)\n\n# Apply the UDF to calculate dhl_fee column\nrequests = requests.withColumn(\"dhl_fee\", get_dhl_fee(fn.col(\"product_weight\"), fn.col(\"Type\")))\n\nbut it returns error SPARK-5063:\n\n\"It appears that you are attempting to reference SparkContext from a\nbroadcast variable, action, or transformation. SparkContext can only\nbe used on the driver, not in code that it run on workers.\"\n\n",
"AnswerId": "76396875",
"AnswerBody": "Setup\ndhl_price.show()\n+------+-----+-----+-----+-----+\n|Weight|    A|    B|    C|    D|\n+------+-----+-----+-----+-----+\n|     1|16.78|17.05|20.23| 40.1|\n|     2|16.78|17.05|20.23|58.07|\n|     3|18.43|18.86| 25.0|66.03|\n|     4|20.08|20.67|29.77|73.99|\n|    30|20.08|20.67|29.77|73.99|\n|    40|21.08|21.67|30.77|74.99|\n+------+-----+-----+-----+-----+\n\nrequests.show()\n+--------------+----+\n|product_weight|type|\n+--------------+----+\n|             1|   B|\n|             2|   D|\n|             4|   A|\n|            30|   A|\n|           100|   C|\n+--------------+----+\n\nCode\nCreate a column of map type which maps type to corresponding price for a given weight\nc = dhl_price.columns[1:]\ndhl_price_map = dhl_price.select('Weight', F.map_from_arrays(F.array(*map(F.lit, c)), F.array(*c)).alias('price'))\ndhl_price_map.show()\n\n\n+------+--------------------+\n|Weight|               price|\n+------+--------------------+\n|     1|{A -> 16.78, B ->...|\n|     2|{A -> 16.78, B ->...|\n|     3|{A -> 18.43, B ->...|\n|     4|{A -> 20.08, B ->...|\n|    30|{A -> 20.08, B ->...|\n|    40|{A -> 21.08, B ->...|\n+------+--------------------+\n\nAssign a unique identifier for each row in the requests dataframe\ndf = requests.withColumn('id_', F.monotonically_increasing_id())\ndf.show()\n+--------------+----+-----------+\n|product_weight|type|        id_|\n+--------------+----+-----------+\n|             1|   B| 8589934592|\n|             2|   D|25769803776|\n|             4|   A|34359738368|\n|            30|   A|51539607552|\n|           100|   C|60129542144|\n+--------------+----+-----------+\n\nJoin the two dataframes on weight condition then use the indexing to yank the value of price corresponding to type for each row\ndf = df.join(dhl_price_map, on=df['product_weight'] >= dhl_price_map['Weight'], how='left')\ndf = df.withColumn('dhl_fee', F.expr(\"price[type]\"))\ndf.show()\n\n\n+--------------+----+-----------+------+--------------------+-------+\n|product_weight|type|        id_|Weight|               price|dhl_fee|\n+--------------+----+-----------+------+--------------------+-------+\n|             1|   B| 8589934592|     1|{A -> 16.78, B ->...|  17.05|\n|             2|   D|25769803776|     1|{A -> 16.78, B ->...|   40.1|\n|             2|   D|25769803776|     2|{A -> 16.78, B ->...|  58.07|\n|             4|   A|34359738368|     1|{A -> 16.78, B ->...|  16.78|\n|             4|   A|34359738368|     2|{A -> 16.78, B ->...|  16.78|\n|             4|   A|34359738368|     3|{A -> 18.43, B ->...|  18.43|\n|             4|   A|34359738368|     4|{A -> 20.08, B ->...|  20.08|\n|            30|   A|51539607552|     1|{A -> 16.78, B ->...|  16.78|\n|            30|   A|51539607552|     2|{A -> 16.78, B ->...|  16.78|\n|            30|   A|51539607552|     3|{A -> 18.43, B ->...|  18.43|\n|            30|   A|51539607552|     4|{A -> 20.08, B ->...|  20.08|\n|            30|   A|51539607552|    30|{A -> 20.08, B ->...|  20.08|\n|           100|   C|60129542144|     1|{A -> 16.78, B ->...|  20.23|\n|           100|   C|60129542144|     2|{A -> 16.78, B ->...|  20.23|\n|           100|   C|60129542144|     3|{A -> 18.43, B ->...|   25.0|\n|           100|   C|60129542144|     4|{A -> 20.08, B ->...|  29.77|\n|           100|   C|60129542144|    30|{A -> 20.08, B ->...|  29.77|\n|           100|   C|60129542144|    40|{A -> 21.08, B ->...|  30.77|\n+--------------+----+-----------+------+--------------------+-------+\n\nCreate a window specification to rank the Weight per unique row in the requests, and then filter the rows to retain only those corresponding to the maximum weight in dhl_price.\nW = Window.partitionBy('id_').orderBy(F.desc('Weight'))\ndf = df.withColumn('rank', F.dense_rank().over(W)).filter('rank == 1')\n\n+--------------+----+-----------+------+--------------------+-------+----+\n|product_weight|type|        id_|Weight|               price|dhl_fee|rank|\n+--------------+----+-----------+------+--------------------+-------+----+\n|             1|   B| 8589934592|     1|{A -> 16.78, B ->...|  17.05|   1|\n|             2|   D|25769803776|     2|{A -> 16.78, B ->...|  58.07|   1|\n|             4|   A|34359738368|     4|{A -> 20.08, B ->...|  20.08|   1|\n|            30|   A|51539607552|    30|{A -> 20.08, B ->...|  20.08|   1|\n|           100|   C|60129542144|    40|{A -> 21.08, B ->...|  30.77|   1|\n+--------------+----+-----------+------+--------------------+-------+----+\n\nDrop the extra columns\ndf = df.select(*requests.columns, 'dhl_fee')\ndf.show()\n\n+--------------+----+-------+\n|product_weight|type|dhl_fee|\n+--------------+----+-------+\n|             1|   B|  17.05|\n|             2|   D|  58.07|\n|             4|   A|  20.08|\n|            30|   A|  20.08|\n|           100|   C|  30.77|\n+--------------+----+-------+\n\n"
},
{
"QuestionId": "76397895",
"QuestionTitle": "Error while compiling Spring boot maven poject",
"QuestionBody": "Hi im learning Sping Boot and when I compile the maven project im getting the next error:\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-resources-plugin:3.3.0:resources (default-resources) on project backweb-api: filtering D:\\***\\***\\backweb\\backweb-api\\src\\main\\resources\\application-test.properties to D:\\***\\***\\backweb\\backweb-api\\target\\classes\\application-test.properties failed with MalformedInputException: Input length = 1 -> [Help 1]\nCompile output\napplication-test.properties\nFull trace mvn compile -3\n-I reviewed the application-test.properties file and I think that it's ok.\n-I cleanned the target folders and re compiled maven project.\n\n\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-resources-plugin:3.3.0:resources (default-resources) on project backweb-api: filtering D:\\***\\***\\backweb\\backweb-api\\src\\main\\resources\\application-test.propert\nies to D:\\***\\***\\backweb\\backweb-api\\target\\classes\\application-test.properties failed with MalformedInputException: Input length = 1 -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-resources-plugin:3.3.0:resources (default-resources) on project backweb-api: filtering D:\\***\\***\\backweb\\backweb\n-api\\src\\main\\resources\\application-test.properties to D:\\***\\***\\backweb\\backweb-api\\target\\classes\\application-test.properties failed with MalformedInputException: Input length = 1\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:347)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:260)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:172)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:100)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:821)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:270)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:192)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:568)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\nCaused by: org.apache.maven.plugin.MojoExecutionException: filtering D:\\***\\***\\backweb\\backweb-api\\src\\main\\resources\\application-test.properties to D:\\***\\***\\backweb\\backweb-api\\target\\classes\\application-test.p\nroperties failed with MalformedInputException: Input length = 1\n    at org.apache.maven.plugins.resources.ResourcesMojo.execute (ResourcesMojo.java:362)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:126)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:342)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:260)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:172)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:100)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:821)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:270)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:192)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:568)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\nCaused by: org.apache.maven.shared.filtering.MavenFilteringException: filtering D:\\***\\***\\backweb\\backweb-api\\src\\main\\resources\\application-test.properties to D:\\***\\***\\backweb\\backweb-api\\target\\classes\\applica\ntion-test.properties failed with MalformedInputException: Input length = 1\n    at org.apache.maven.shared.filtering.DefaultMavenFileFilter.copyFile (DefaultMavenFileFilter.java:118)\n    at org.apache.maven.shared.filtering.DefaultMavenResourcesFiltering.filterResources (DefaultMavenResourcesFiltering.java:277)\n    at org.apache.maven.plugins.resources.ResourcesMojo.execute (ResourcesMojo.java:356)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:126)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:342)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:260)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:172)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:100)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:821)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:270)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:192)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:568)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\nCaused by: java.nio.charset.MalformedInputException: Input length = 1\n    at java.nio.charset.CoderResult.throwException (CoderResult.java:274)\n    at sun.nio.cs.StreamDecoder.implRead (StreamDecoder.java:326)\n    at sun.nio.cs.StreamDecoder.read (StreamDecoder.java:188)\n    at java.io.InputStreamReader.read (InputStreamReader.java:177)\n    at java.io.BufferedReader.read1 (BufferedReader.java:211)\n    at java.io.BufferedReader.read (BufferedReader.java:287)\n    at java.io.BufferedReader.fill (BufferedReader.java:162)\n    at java.io.BufferedReader.read (BufferedReader.java:183)\n    at org.apache.maven.shared.filtering.BoundedReader.read (BoundedReader.java:85)\n    at org.apache.maven.shared.filtering.MultiDelimiterInterpolatorFilterReaderLineEnding.read (MultiDelimiterInterpolatorFilterReaderLineEnding.java:235)\n    at org.apache.maven.shared.filtering.MultiDelimiterInterpolatorFilterReaderLineEnding.read (MultiDelimiterInterpolatorFilterReaderLineEnding.java:197)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:126)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2 (MojoExecutor.java:342)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:330)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:175)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:76)\n    at org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:163)\n    at org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:160)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:260)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:172)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:100)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:821)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:270)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:192)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:568)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n[ERROR]\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n[ERROR]\n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <args> -rf :backweb-api\n\n\n\n",
"AnswerId": "76398039",
"AnswerBody": "Your application-test.properties contains non-UTF8 characters (e.g. the accent on the configuration o). This causes this error\n"
},
{
"QuestionId": "76396209",
"QuestionTitle": "Table only appears for a split second on button click",
"QuestionBody": "I have a button and a table on my webpage. I want to view the table when I click that button. I have tried it using javascript but the table only appears for a split second and then disappears. following is the code for my table:\n\n\nvar button = document.getElementById('BtnNextInsured'); // Assumes element with id='button'\n\nbutton.onclick = function() {\n  var div = document.getElementById('tblContact');\n  if (div.style.display !== 'none') {\n    div.style.display = 'none';\n  } else {\n    div.style.display = 'block';\n  }\n};\n<button id=\"BtnNextInsured\" class=\"btn btn-md btn-primary\">Next</button> Table to show:\n\n<table id=\"tblContact\" class=\"table table-light table-borderless\" style=\"display:none;\">\n  <tr>\n    <td class=\"cellContent\">\n      <input id=\"txtEmail\" class=\"txt\" placeholder=\"Email\" />\n    </td>\n    <td class=\"cellContent\">\n      <input id=\"txtCell\" class=\"txt\" placeholder=\"Cell Phone\" />\n    </td>\n    <td class=\"cellContent\">\n      <input id=\"txtLandline\" class=\"txt\" placeholder=\"Landline\" />\n    </td>\n  </tr>\n\n  <tr>\n    <td colspan=\"3\" style=\"text-align: right\">\n      <button id=\"BtnNextContact\" class=\"btn btn-md btn-primary\">Next</button>\n    </td>\n  </tr>\n</table>\n\n\n\nI don't understand what's wrong with my code. I am a beginner to javascript.\n",
"AnswerId": "76396902",
"AnswerBody": "as comments saying better using eventlistener.\nwith the eventlistene, you can use the event and like here stop it to avoid double click.\nto appear disappear use a class 'hide' so you can toggle it, easier than than checking display none.\n\n\nconst tableAppear = () => {\n  document.querySelector('#BtnNextInsured').addEventListener('click', evt => {\n    evt.stopImmediatePropagation();\n    document.querySelector('#tblContact').classList.toggle('hide');\n  });\n}\nwindow.addEventListener('load', tableAppear);\n.hide {\n  display: none;\n}\n<button id=\"BtnNextInsured\" class=\"btn btn-md btn-primary\">Next</button> Table to show:\n\n<table id=\"tblContact\" class=\"table table-light table-borderless hide\">\n  <tr>\n    <td class=\"cellContent\">\n      <input id=\"txtEmail\" class=\"txt\" placeholder=\"Email\" />\n    </td>\n    <td class=\"cellContent\">\n      <input id=\"txtCell\" class=\"txt\" placeholder=\"Cell Phone\" />\n    </td>\n    <td class=\"cellContent\">\n      <input id=\"txtLandline\" class=\"txt\" placeholder=\"Landline\" />\n    </td>\n  </tr>\n\n  <tr>\n    <td colspan=\"3\" style=\"text-align: right\">\n      <button id=\"BtnNextContact\" class=\"btn btn-md btn-primary\">Next</button>\n    </td>\n  </tr>\n</table>\n\n\n\n"
},
{
"QuestionId": "76395403",
"QuestionTitle": "Why am I able to use C# lists without writing \"using System.Collections.Generic;\" at the beginning of my file?",
"QuestionBody": "Take a look at this simple C# program:\nusing System;\n\nnamespace testProgram\n{\n    internal class Program\n    {\n        static void Main(string[] args)\n        {\n            List<string> list = new List<string>();\n            list.Add(\"List element.\");\n            Console.WriteLine(list[0]);\n        }\n    }\n}\n\nOutput:\nList element.\n\nYou can see that it uses a list. I always saw on the Internet that in order to use a list, I need to add \"using System.Collections.Generic;\" at the beginning of my file. However, the program can run without this line, why?\n",
"AnswerId": "76395424",
"AnswerBody": "Look at your project file. I strongly suspect it will include this:\n<ImplicitUsings>enable</ImplicitUsings>\n\nThe ImplicitUsings feature is described here:\n\nThe ImplicitUsings property can be used to enable and disable implicit global using directives in C# projects that target .NET 6 or a later version and C# 10 or a later version. When the feature is enabled, the .NET SDK adds global using directives for a set of default namespaces based on the type of project SDK. Set this property to true or enable to enable implicit global using directives. To disable implicit global using directives, remove the property or set it to false or disable.\n\nNote that that means you don't need using System; either.\nCombined with top-level statements, your whole file could actually be:\nList<string> list = new List<string>();\nlist.Add(\"List element.\");\nConsole.WriteLine(list[0]);\n\nOr if the namespace is important to you:\nnamespace testProgram;\n\nList<string> list = new List<string>();\nlist.Add(\"List element.\");\nConsole.WriteLine(list[0]);\n\n"
},
{
"QuestionId": "76396701",
"QuestionTitle": "import python libraries (eg: rapidjson) in airflow",
"QuestionBody": "I want to use the Python library rapidjson in my Airflow DAG. My code repo is hosted on Git. Whenever I merge something into the master or test branch, the changes are automatically configured to reflect on the Airflow UI.\nMy Airflow is hosted as a VM on AWS EC2. Under the EC2 instances, I see three different instances for: scheduler, webserver, workers.\nI connected to these 3 individually via Session Manager. Once the terminal opened, I installed the library using\npip install python-rapidjson\n\nI also verified the installation using pip list. Now, I import the library in my dag's code simply like this:\nimport rapidjson\n\nHowever, when I open the Airflow UI, my DAG has an error that:\nNo module named 'rapidjson'\n\nAre there additional steps that I am missing out on? Do I need to import it into my Airflow code base in any other way as well?\nWithin my Airflow git repository, I also have a \"requirements.txt\" file. I tried to include\npython-rapidjson==1.5.5\nthis there as well but I do not know how to actually install this.\nI tried this:\npip install requirements.txt\nwithin the session manager's terminal as well. However, the terminal is not able to locate this file. In fact, when I do \"ls\", I don't see anything.\npwd\n/var/snap/amazon-ssm-agent/6522\n\n",
"AnswerId": "76396926",
"AnswerBody": "Have you tried using the PythonVirtualEnvOperator ?\nIt will allow you to install the library at runtime so you don't need to make changes on the server just for one job.\nTo run a function called my_callable, simply use the following:\nfrom airflow.operators.python import PythonVirtualenvOperator\n\n\nmy_task = PythonVirtualenvOperator(\n        task_id=\"my_task \",\n        requirements=\"python-rapidjson==1.5.5\",\n        python_callable=my_callable,\n    )\n\nI still recommend updating your server environment for core libs, but this is a best practice when using special libs for a small minority of jobs.\n"
},
{
"QuestionId": "76397951",
"QuestionTitle": "Is there a way to set a ConsoleColor value equal to a variable?",
"QuestionBody": "I am working on creating a class to support a console app I am developing, and I would like to create a method within to change both the background and foreground color.  Is there a way to set a ConsoleColor value (which I believe is an enum) to another variable so this can easily be changed by the user at runtime?  For instance, I am hoping for something like the following.\nPublic class ConsoleOutput\n{\n  private var consoleBackground = ConsoleColor.White;\n  private var consoleForeground = ConsoleColor.Black;\n  \n  Public ConsoleOutput\n  {\n    Console.BackgroundColor = consoleBackground\n    Console.ForegroundColor = consoleForeground\n  }\n}\n\nThis, however, did not work.\n",
"AnswerId": "76398063",
"AnswerBody": "You don't seem to ever write to the console in your program, which you obviously need to do. Other then that you also need a way to change the colors during runtime using e.g. setters or a function like ChangeColors().\nHere a working sample program for reference:\nnamespace MyProgram;\n\nclass Program\n{\n    static void Main(string[] args)\n    {\n        var coloredPrinter = new ColoredPrinter(ConsoleColor.White, ConsoleColor.Blue);\n        coloredPrinter.WriteLine(\"This is white text on blue background\");\n        coloredPrinter.ChangeColors(ConsoleColor.Yellow, ConsoleColor.Red);\n        coloredPrinter.WriteLine(\"This is yellow text on red background\");\n        Console.WriteLine(\"This is the default\");\n    }\n}\n\nclass ColoredPrinter\n{\n    public ConsoleColor ForegroundColor { get; set; }\n    public ConsoleColor BackgroundColor { get; set; }\n\n    public ColoredPrinter(ConsoleColor foregroundColor, ConsoleColor backgroundColor)\n    {\n        ChangeColors(foregroundColor, backgroundColor);\n    }\n\n    public void ChangeColors(ConsoleColor foregroundColor, ConsoleColor backgroundColor)\n    {\n        ForegroundColor = foregroundColor;\n        BackgroundColor = backgroundColor;\n    }\n\n    public void WriteLine(string text)\n    {\n        Console.ResetColor();\n        Console.BackgroundColor = BackgroundColor;\n        Console.ForegroundColor = ForegroundColor;\n        Console.WriteLine(text);\n        Console.ResetColor();\n    }\n}\n\n\nThis prints out the following:\n\n"
},
{
"QuestionId": "76396427",
"QuestionTitle": "How to destroy an initiated GameObject on collision?",
"QuestionBody": "I have created a script that spawns bullets/projectiles that moves forward with a certain force. However, the bullet itself does not disappear on collision. Since it is a instantiated object, how do I make it disappear? I've tried OnCollisionEnter() but to no avail. The code below is how i created the bullet.\n// Instantiate bullet/projectile\nGameObject currentBullet = Instantiate(bullet, attackPoint.position, Quaternion.identity);\n        \n// Rotate bullet to shoot direction\ncurrentBullet.transform.forward = directionWithSpread.normalized;\n\n// Add forces to bullet\ncurrentBullet.GetComponent<Rigidbody>().AddForce(directionWithSpread.normalized * shootForce, ForceMode.Impulse);\ncurrentBullet.GetComponent<Rigidbody>().AddForce(fpsCam.transform.up * upwardForce, ForceMode.Impulse);\n\nEDIT\nPerhaps, is there anyway to assign a script to a prefab that will be instantiated?\n",
"AnswerId": "76396935",
"AnswerBody": "You can choose two paths to achieve this\n1) Adding the script to the prefab (done in the editor)\nYou can edit the prefab (opening it from the editor) and add the script to it.\n2) Adding the script to the instance (done programmatically)\nIn this case your first instantiate the prefab and then programmatically add the script to it with something like this:\nGameObject currentBullet = Instantiate(bullet, attackPoint.position, Quaternion.identity);\n\ncurrentBullet.AddComponent<YourScript>();\n\n3? Using RayCasting (this option in my opinion fits your needs)\nUsually the best way to handle bullets is using RayCast\nIn this case the bullet does not need the code to handle its collision but it is just the visual representation of the bullet, the real collision detection and other actions linked to it are controlled by the raycasting, in this way you save some memory\nHope this helps\n"
},
{
"QuestionId": "76395282",
"QuestionTitle": "reading input from .txt file in C",
"QuestionBody": "john smith 21 VETERAN 1   \nI have  a .txt file writing this . I want to read this .txt file and take john smith as a variable . but I can't read with whitespaces.\nedit: I want to take john smith and print it in the console with\n printf(\"%s\",name);\nI tried code below but didnt work. only takes smith.\nwhile (fscanf(file, \"%s, %d %s %d\", name, &age, priorityGroup, &priorityLevel) == 4)\n\nedit2:\n",
"AnswerId": "76395427",
"AnswerBody": "The task is not easy for beginners learning C.\nThere can be different approaches.\nI can suggest the following approach.\nAt first a full record is read from the file using standard C function fgets as for example\nchar record[100];\n\nfgets( record, sizeof( record ), fp );\n\nNow let's assume that the record is already read. Then to output the first two words in record you can use standard C function sscanf as shown in the demonstration program below.\n#include <stdio.h>\n\nint main( void )\n{\n    char record[] = \"john smith 21 VETERAN 1\\n\";\n\n    int n = 0;\n\n    for (size_t i = 0; i < 2; i++)\n    {\n        const char *p = record + n;\n        int m;\n\n        sscanf( p, \"%*s%n\", &m );\n\n        n += m;\n    }\n\n    printf( \"\\\"%.*s\\\"\\n\", n, record );\n}\n\nThe program output is\n\"john smith\"\n\nOr you could make a string of the two words just writing\nrecord[n] = '\\0';\nprintf( \"\\\"%s\\\"\\n\", record );\n\nOr if your compiler supports variable length arrays you could write\n#include <string.h>\n\n//...\n\nchar name[n + 1];\n\nmemcpy( name, record, n );\nname[n] = '\\0';\n\nprintf( \"\\\"%s\\\"\\n\", name );\n\nIf the compiler does not support variable length arrays then you will need to allocate an array dynamically like for example\n#include <string.h>\n#include <stdlib.h>\n\n//...\n\nchar *name = malloc( n + 1 );\n\nmemcpy( name, record, n );\nname[n] = '\\0';\n\nprintf( \"\\\"%s\\\"\\n\", name );\n\nIn this case do not forget to free the allocated memory when it will not be required any more\nfree( name );\n\nIn the demonstration program the string literal used as an initializer of the array record is appended with the new line character '\\n' because the function fgets itself can store this character in the destination array.\n"
},
{
"QuestionId": "76398040",
"QuestionTitle": "ForEach method skips Console.WriteLine() on each iteration, then dumps all the logs when loop is done. Why?",
"QuestionBody": "I have this piece of code:\n[Test]\npublic void LinqConsoleOutputTest() {\n    Enumerable.Range(0, 10).ToList().ForEach(_ => {\n        Thread.Sleep(500);\n        Console.WriteLine($\"Slept...\");\n    });\n}\n\nAnd to my surprise the code was executing around 5 seconds as expected, but it did not print to the console. It just dumped all 10 logs when it finished ForEach loop.\nAnd I am just curious why does it work that way? Is it related to ForEach/Linq or maybe to the Console object?\n",
"AnswerId": "76398085",
"AnswerBody": "Console.WriteLine() writes to whatever is the Standard Output which might not be a console in case of a test. Run the same code in a simple \"normal\" C# program and it will print as expected.\nConsider this program:\nnamespace MyProgram;\n\nclass Program\n{\n    static void Main(string[] args)\n    {\n        using var fileStream = File.OpenWrite(\"./consoleOutput.txt\");\n        using var streamWriter = new StreamWriter(fileStream);\n        // redirect standard output\n        Console.SetOut(streamWriter);\n        Enumerable.Range(0, 10).ToList().ForEach(_ =>\n        {\n            Thread.Sleep(500);\n            Console.WriteLine($\"Slept... {DateTime.UtcNow}\");\n        });\n        Console.WriteLine(\"Done\");\n    }\n}\n\nWhat this program does is, it redirects the standard output to write to a FileStream of a file called consoleOutput.txt. So when you run the program it creates the file and writes everything you would normally print to the console to the file. If you have a look at the file you can see that in fact it contains the whole output:\nconsoleOutput.txt\nSlept... 6/3/2023 9:34:42 PM\nSlept... 6/3/2023 9:34:42 PM\nSlept... 6/3/2023 9:34:43 PM\nSlept... 6/3/2023 9:34:43 PM\nSlept... 6/3/2023 9:34:44 PM\nSlept... 6/3/2023 9:34:44 PM\nSlept... 6/3/2023 9:34:45 PM\nSlept... 6/3/2023 9:34:45 PM\nSlept... 6/3/2023 9:34:46 PM\nSlept... 6/3/2023 9:34:46 PM\nDone\n\n"
},
{
"QuestionId": "76396924",
"QuestionTitle": "Nested for loop not looping on the first set, Python",
"QuestionBody": "I have written this code in python. In the end I would like to use this to get the indices to cut up a 100x100 matrix into squares that overlap by 10. However, at the bottom there is a nested loop and the y values print how I think they should but not the x-values, the x-values never change... Can anyone help? Thanks\nx_split = np.linspace(0, 100, 4 + 1, dtype=int)\nx_start = x_split[:-1] - 5\nx_start[0] = 0\nx_end = x_split[1:] + 5\nx_end[-1] = 100\n\ny_split = np.linspace(0, 100, 4 + 1, dtype=int)\ny_start = y_split[:-1] - 5\ny_start[0] = 0\ny_end = y_split[1:] + 5\ny_end[-1] = 100\n\nx_inds = zip(x_start, x_end)\ny_inds = zip(y_start, y_end)\n\ni = 0\nfor start_x, end_x in x_inds:\n    for start_y, end_y in y_inds:\n        i += 1\n        print(f\"i = {i}\")\n        print(f\"x = {start_x} {end_x}\")\n        print(f\"y = {start_y} {end_y}\")\n        print(\"\")\n\nCurrent output:\ni = 1\nx = 0 30\ny = 0 30\n\ni = 2\nx = 0 30\ny = 20 55\n\ni = 3\nx = 0 30\ny = 45 80\n\ni = 4\nx = 0 30\ny = 70 100\n\nAnd then stops. I want to to continue...\ni = 5\nx = 20 55\ny = 0 30\n\ni = 6\nx = 20 55\ny = 20 55\n\n...\n\n",
"AnswerId": "76396974",
"AnswerBody": "zip(y_start, y_end) returns an iterator.  After the first series of Xs, y_inds is exhausted and yields no more values for the subsequent values of X.\nMake it y_inds a list, so it can be reused on subsequence X rows:\n*y_inds, = zip(y_start, y_end)\n\nYou could also let numpy do the iterating for you to produce a matrix of square coordinates:\ncoords  = np.repeat(x_start,y_start.size)[:,None], \\\n          np.repeat(x_end,  y_start.size)[:,None], \\\n          np.tile(y_start,x_start.size)[:,None],   \\\n          np.tile(y_end,  x_start.size)[:,None]\nsquares = np.concatenate(coords,axis=1)\nprint(squares)\n[[  0  30   0  30]\n [  0  30  20  55]\n [  0  30  45  80]\n [  0  30  70 100]\n [ 20  55   0  30]\n [ 20  55  20  55]\n [ 20  55  45  80]\n [ 20  55  70 100]\n [ 45  80   0  30]\n [ 45  80  20  55]\n [ 45  80  45  80]\n [ 45  80  70 100]\n [ 70 100   0  30]\n [ 70 100  20  55]\n [ 70 100  45  80]\n [ 70 100  70 100]]\n\n"
},
{
"QuestionId": "76387478",
"QuestionTitle": "Flutter - in_app_purchase plugin - iOS - works in sim but not on device",
"QuestionBody": "Building an iOS app, _inAppPurchase.queryProductDetails(productIds); returns product details in a simulator (ipad, iphone) and everything works. But if I run on a physical iPhone productDetailResponse.productDetails.isEmpty is true and my product ids are in notFoundIDs. Same if I 'flutter build ipa' and try in TestFlight. Using synced StoreKit.storekit.. in_app_purchase: ^3.1.7. Why this may be?\n",
"AnswerId": "76395430",
"AnswerBody": "Getting all \"Agreements, Tax and Banking\" bits sorted and \"Active\" in App Store Connect has fixed it. Things started working the same on the device, simulator and TestFlight as soon as the forms got reviewed and approved.\n"
},
{
"QuestionId": "76398059",
"QuestionTitle": "Not explicitly saying `return` gives error: `match` arms have incompatible types",
"QuestionBody": "I am very new to Rust.\nThe following function:\nasync fn create(body: String) -> impl IntoResponse {\n    let j = match serde_json::from_str::<CreationJSON>(&body) {\n        Ok(j) => j,\n        Err (_) => (\n            StatusCode::UNPROCESSABLE_ENTITY,\n            \"body is invalid\".to_string(),\n        ),\n    };\n    println!(\"{:?}\", j.record_stringified);\n\n    (\n        StatusCode::CREATED,\n        \"created\".to_string(),\n    )\n}\n\ngives error:\nerror[E0308]: `match` arms have incompatible types\n   --> src/main.rs:128:20\n    |\n126 |       let j = match serde_json::from_str::<CreationJSON>(&body) {\n    |               ------------------------------------------------- `match` arms have incompatible types\n127 |           Ok(j) => j,\n    |                    - this is found to be of type `CreationJSON`\n128 |           Err (_) => (\n    |  ____________________^\n129 | |             StatusCode::UNPROCESSABLE_ENTITY,\n130 | |             \"body is invalid\".to_string(),\n131 | |         ),\n    | |_________^ expected `CreationJSON`, found `(StatusCode, String)`\n    |\n    = note: expected struct `CreationJSON`\n                found tuple `(axum::http::StatusCode, std::string::String)`\n\nHowever, if I add a \"return\" to the Err arm, then it works fine:\nasync fn create(body: String) -> impl IntoResponse {\n    let j = match serde_json::from_str::<CreationJSON>(&body) {\n        Ok(j) => j,\n        Err (_) => return (\n            StatusCode::UNPROCESSABLE_ENTITY,\n            \"body is invalid\".to_string(),\n        ),\n    };\n    println!(\"{:?}\", j.record_stringified);\n\n    (\n        StatusCode::CREATED,\n        \"created\".to_string(),\n    )\n}\n\nWhy do I need to add the return in the Err arm? I thought a function with no semi-colon was supposed to automatically return in Rust?\n",
"AnswerId": "76398086",
"AnswerBody": "return returns from the function. If you don't use the return keyword, then it'll \"return\" from the statement. In your first example, you're trying to assign the tuple to the variable j, while in the second you return from the function.\n"
},
{
"QuestionId": "76397592",
"QuestionTitle": "Why is the 'Growth Estimates' table not being detected by beautifulsoup on this website?",
"QuestionBody": "I tried to webscrape the data from the below url to get the data from the \"Growth Estimates\" table using beautiful soup & requests but it can't seem to pick the table up. However when using the inspection tool I can see there is a table there to pull data from and I couldn't see anything about it being pulled dynamically, but I could be wrong.\nurl = https://finance.yahoo.com/quote/AAPL/analysis?p=AAPL\nIs someone able to explain the issue and offer a solution?\nThank you!\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_growth_data(symbol):\n    url = \"https://finance.yahoo.com/quote/{symbol}/analysis?p={symbol}\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, \"html.parser\")\n\n    # Find the table containing the growth data\n    table = soup.find(\"table\", class_=\"W(100%) M(0) BdB Bdc($seperatorColor) Mb(25px)\")\n\n    if table is None:\n        print(\"Table not found.\")\n        return []\n\n    # Extract the growth values from the table\n    growth_values = []\n    rows = table.find_all(\"tr\")\n    for row in rows:\n        columns = row.find_all(\"td\")\n        if len(columns) >= 2:\n            growth_values.append(columns[1].text)\n\n    return growth_values\n\nsymbol = 'AAPL'\ngrowth_data = get_growth_data(symbol)\nprint(growth_data)\n\n\n",
"AnswerId": "76398115",
"AnswerBody": "To get correct response from the server set User-Agent HTTP header in your request:\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://finance.yahoo.com/quote/AAPL/analysis?p=AAPL'\nheaders = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/113.0'}\nsoup = BeautifulSoup(requests.get(url, headers=headers).content, 'html.parser')\n\ntable = soup.select_one('table:-soup-contains(\"Growth Estimates\")')\ndf = pd.read_html(str(table))[0]\n\nprint(df)\n\nPrints:\n           Growth Estimates    AAPL  Industry  Sector(s)  S&P 500\n0              Current Qtr.  -0.80%       NaN        NaN      NaN\n1                 Next Qtr.   5.40%       NaN        NaN      NaN\n2              Current Year  -2.30%       NaN        NaN      NaN\n3                 Next Year   9.90%       NaN        NaN      NaN\n4  Next 5 Years (per annum)   8.02%       NaN        NaN      NaN\n5  Past 5 Years (per annum)  23.64%       NaN        NaN      NaN\n\n"
},
{
"QuestionId": "76396938",
"QuestionTitle": "OptInt type function in Python",
"QuestionBody": "import pandas as pd\nimport json\n\n    mass=[]\n    fall=[]\n    year=[]\n\nreq = requests.get(\"https://data.nasa.gov/resource/y77d-th95.json\")\nresponse =req.json()\n\nfor i in range(0,len(response)):\n    mass.append(response[i]['mass']) \n    fall.append(response[i]['fall'])\n    year.append(response[i]['year'])\n\nI handle keyError with the help of Exception handling. If i got keyerror i added NAN value.\nAs java have function like OptString whenever we get keyerror it add default value.\nI just want to get all data in list but via using optString type method.\nCan you give any example ?\nThanks ,\n",
"AnswerId": "76397014",
"AnswerBody": "You can use dict.get to provide a default value as the second argument.\nFor example:\nfrom math import nan\n\nfor obj in response:\n    mass.append(obj.get('mass', nan))\n    fall.append(obj.get('fall', nan))\n    year.append(obj.get('year', nan))\n\n"
},
{
"QuestionId": "76396255",
"QuestionTitle": "Owner information not available from Google Cloud Storage blob",
"QuestionBody": "I am using get_blob using the python API. All kinds of information about the blob is available, but owner is set to None. My application needs to know who last updated the file in GCS.  Any help would be appreciated!\nI tried calling reload with projection set to full, as suggested elsewhere, but it didn’t help. I tried setting acl as well as uniform permissions on the bucket, but it was the same result.\nI would be willing to change the bucket permissions to anything (other than making it public) that would allow me to get the file updater/owner information.\n",
"AnswerId": "76397019",
"AnswerBody": "In Google Cloud Storage, buckets are owned by the project. Users (IAM principals) are not owners of a bucket. Permissions are granted to users to access a bucket and its objects. The logs record who created a bucket.\nFor updates, review Audit Logging. Google records changes to a resource's metadata.\nUsage logs & storage logs\n"
},
{
"QuestionId": "76395432",
"QuestionTitle": "Fix error RecyclerView: No adapter attached; skipping layout",
"QuestionBody": "Just implemented RecyclerView in my code, replacing ListView.\nEverything works fine. The data is displayed.\nBut error messages are being logged:\nRecyclerView: No adapter attached; skipping layout\nI have read other questions related to the same problem but none of them help.\n",
"AnswerId": "76395438",
"AnswerBody": "i have this problem , a few time problem is recycleView put in ScrollView object\nAfter checking implementation, the reason appears to be the following. If RecyclerView gets put into a ScrollView, then during measure step its height is unspecified (because ScrollView allows any height) and, as a result, gets equal to minimum height (as per implementation) which is apparently zero.\nYou have couple of options for fixing this:\nSet a certain height to RecyclerView\nSet ScrollView.fillViewport to true\nOr keep RecyclerView outside of ScrollView. In my opinion, this is the best option by far. If RecyclerView height is not limited - which is the case when it's put into ScrollView - then all Adapter's views have enough place vertically and get created all at once. There is no view recycling anymore which kinda breaks the purpose of RecyclerView .\n(Can be followed for android.support.v4.widget.NestedScrollView as well)\n"
},
{
"QuestionId": "76395305",
"QuestionTitle": "Pygame get_rect() is not running",
"QuestionBody": "get_rect() is not running\nI was trying to make a simple game for educational purposes using the pygame module. I encountered this error. I would be glad if you can help\nimport pygame \nimport random\nimport sys \nimport os \n\npygame.init()\nbalikci_konum = \"E:/E/Python/Python-eski/Oyuncalismalari/balik_avlama_oyunu/textures/balikci.png\"\ngenislik = 1000\nyukseklik = 600 \n\nekran = pygame.display.set_mode((genislik,yukseklik))\n\n# ...\n\nclass Balik(pygame.sprite.Sprite):\n    def __init__(self,x,y,resim,tip):\n        super().__init__()\n        self.image = resim \n        self.rect = self.image.get_rect()\n        self.rect.topleft = (x,y)\n        self.tip = tip \n        self.hiz = random.randint(0,13)\n        self.yonx= random.choice([1,-1])\n        self.yony= random.choice([1,-1])\n        \n    def update(self):\n        self.rect.x = self.hiz*self.yonx\n        self.rect.y = self.hiz*self.yony\n        \n        if self.rect.left <=0 or self.rect.right >= genislik : \n            self.yonx *=-1\n            \n        if self.rect.top <=0 or self.rect.bottom >= yukseklik : \n            self.yony *=-1\n     \n#Balık Grupları \nbalik1 = pygame.image.load(\"E:/E/Python/Python-eski/Oyuncalismalari/balik_avlama_oyunu/textures/balik1.png\")\nbalik2 = pygame.image.load(\"E:/E/Python/Python-eski/Oyuncalismalari/balik_avlama_oyunu/textures/balik2.png\")\n\nbalik_grup = pygame.sprite.Group()\nbalik = Balik(random.randint(0,genislik-32),random.randint(0,yukseklik-32),balik1,0)\nbalik_grup.add(balik)\n\nbalik = Balik(random.randint(0,genislik-32),random.randint(0,yukseklik-32),balik2,0)\nbalik_grup.add(balik)\n\n# ...\n\nthat is all of my code\ni tried relocating objects but still get_rect() function doesn't work\n",
"AnswerId": "76395440",
"AnswerBody": "To move the objects you have to change the position with += instead of setting the position with an assignment (=):\nself.rect.x = self.hiz*self.yonx\nself.rect.y = self.hiz*self.yony\nself.rect.x += self.hiz*self.yonx\nself.rect.y += self.hiz*self.yony\n\n"
},
{
"QuestionId": "76398116",
"QuestionTitle": "Javascript construct trap not working in class returning proxy",
"QuestionBody": "I am trying to create a little javascript two way form binder using proxies. I am stuck on how I can intercept 'new' calls. I use a 'construct' trap but it doesn't fire. Here is my code, I have removed the stuff that is not relivant for my specific problem\n    class BoundObject {\n\n        constructor(object, element) {\n\n            // distribute object properties into \"this\"\n            for (const prop in object) {\n                this[prop] = object[prop]\n            }\n\n            return new Proxy(this, {\n\n                construct:(target, args) => {\n                    console.log(`Creating a new ${target.name}`) // why is this not fired?\n                    return Reflect.construct(...args)\n                },\n                set: (target, prop, val, receiver) => {\n                    console.log(`attempting to set ${prop}=${val} type ${typeof val}`);\n\n                    return Reflect.set(target, prop, val) \n                }\n            })\n        }\n    }\n\n    // create an instance of our BoundObject class, passing in an object and an HTML element\n    const user = new BoundObject({name:'fred'},document.querySelector('#user-form'))    // why is the 'construct' call not intercepted?\n    user.name = 'mary' // set user name. The 'set' call is sucessfully intercepted\n\nThe set trap works, but the construct trap fails to fire.  I suspect this is to do with javascript deep magic around 'this' but cannot figure it out\nHow can I intercept the construction of the proxy object my class returns?\n",
"AnswerId": "76398122",
"AnswerBody": "The construct trap is only called when the [[Construct]] internal method is invoked on the proxy itself. This could be caused by using the new operator. However, in this case, the Proxy is returned as a result of calling new on the BoundObject constructor; new was not called on the proxy itself.\nHere is an example of where the construct trap could be called.\n\n\nfunction MyObj() {}\nconst proxy = new Proxy(MyObj, {\n  construct(target, args) {\n    console.log(args);\n    return new target(...args);\n  }\n});\nnew proxy('something');\n\n\n\n"
},
{
"QuestionId": "76396518",
"QuestionTitle": "How can I fix line breaks output by script(1) utility?",
"QuestionBody": "I have the following lftp script to copy files from a remote to local:\nenv TERM=dumb script -a $LOGSTDOUT -c \"$(cat <<- EOF\n    lftp $PROTOCOL://$URL -u ${USER},${PASS} << EOFF\n    set dns:fatal-timeout never\n    set sftp:auto-confirm yes\n    set mirror:use-pget-n 50\n    set mirror:parallel-transfer-count 2\n    set mirror:parallel-directories yes\n    set mirror:include-regex $REGEX\n    set log:enabled/xfer yes\n    set log:file/xfer $LOG\n    set xfer:use-temp-file yes\n    set xfer:temp-file-name *.lftp\n    mirror -c -v --loop --Remove-source-dirs \"$REMOTEDIR\" \"$LOCALDIR\"\n    quit\n    EOFF\nEOF\n)\"\n\nI am capturing terminal output with the script(1) utility. The env TERM=dumb is just a random piece of code I found to disable ANSI escape codes.\nMy problem is that the line breaks of the output log file get quiet mangled. It seems to be using CR and LF. I discovered more information here and it seems this is by design. Though I'm not sure how to fix it.\nThese line endings cause issues when viewing the logs in lnav:\n\nThe reason for this becomes quickly apparent upon inspecting the raw text:\n\nI have thought of some potential options, but not sure how to implement:\n\nFix the output of the script(1) utility so that single CR are converted to LF. Maybe this can be achieved with piping or some arguement?\nA hack for lnav to treat CR as LF when displaying in the GUI.\n\nAnyone know how I can fix these line breaks so it shows correctly in lnav?\n",
"AnswerId": "76397042",
"AnswerBody": "Try replacing\n... script -a $LOGSTDOUT ...\n\nwith\n... script -a >(tr -d '\\r' >\"$LOGSTDOUT\") ...\n\n\nSee the Process Substitution section on the Bash Reference Manual for an explanation of >(...).\nNote that ALL_UPPERCASE variable names (like LOGSTDOUT) are best avoided because there is a danger of clashes with the large number of special ALL_UPPERCASE variables that are used in shell programming.  See Correct Bash and shell script variable capitalization.\nThe quotes on $LOGSTDOUT are necessary in general.  Use Shellcheck to find common problems with shell code, including missing quotes.\n\n"
},
{
"QuestionId": "76397068",
"QuestionTitle": "PySpark and Postgres: JDBC connection error",
"QuestionBody": "Issues connecting PySpark & Postgres\nI've scoured the Apache docs, Stackoverflow and watched youtube tutorials but can't seem to find an issue to my exact issue. I have clearly pointed to the postgres executable jar file but it doesn't I can't seem to be able to read from the db. Below is an extract from my script. The properties parameter contains the user, password and driver (\"org.postgresql.Driver\") details in the form of a dictionary.\nAnybody know what I am missing? I get the error:\n\nIllegalArgumentException: requirement failed: the driver could not open a JDBC connection. Check the URL\n\nAdded context: I am using Postgres 15, Spark 3.4.0 and Python 3.10\nspark = SparkSession\\\n        .builder\\\n        .config('spark.jars','C:\\Program Files\\Spark\\spark-3.4.0-bin-hadoop3\\jars\\postgresql-42.6.0.jar')\\\n        .getOrCreate()\n\n    spark.read.jdbc(\n        url=f'jdbc:postgresql//localhost:5432/ag',\n        table='customers',\n        properties=props).load()\n\n",
"AnswerId": "76397087",
"AnswerBody": "Seems like your URL is missing a : character.\nYou've written\njdbc:postgresql//localhost...\n\ninstead of\njdbc:postgresql://localhost...\n\n"
},
{
"QuestionId": "76397037",
"QuestionTitle": "django full text search taggit",
"QuestionBody": "My application - the basics\nI have a simple django application which allows for storing information about certain items and I'm trying to implement a search view/functionality.\nI'm using django-taggit to tag the items by their functionality/features.\nWhat I want to implement\nI want to implement a full text search which allows to search across all the fields of the items, including their tags.\nThe problem(s)\n\nOn the results view, the tagged items are showing up multiple times (one occurence per tag)\nThe ranking is correct when I specify * only a single* tag in the search field, but when I specify multiple tag names, I will get unexpected ranking results.\n\nI suspect the SearchVector() does not resolve the tags relation as I expected it to do. The tags should be treated just like a list of words in this case.\nExample Code\nmodels.py\nfrom django.db import models\nfrom taggit.managers import TaggableManager\n\nclass Item(models.Model):\n    identifier = models.SlugField('ID', unique=True, editable=False)\n    short_text = models.CharField('Short Text', max_length=100, blank=True)\n    serial_number = models.CharField('Serial Number', max_length=30, blank=True)\n    revision = models.CharField('Revision/Version', max_length=30, blank=True)\n    part_number = models.CharField('Part Number', max_length=30, blank=True)\n    manufacturer = models.CharField('Manufacturer', max_length=30, blank=True)\n    description = models.TextField('Description', blank=True)\n    tags = TaggableManager('Tags', blank=True)\n    is_active = models.BooleanField('Active', default=True)\n\nforms.py\nfrom django import forms\n\nclass SearchForm(forms.Form):\n    search = forms.CharField(max_length=200, required=False)\n    active_only = forms.BooleanField(initial=True, label='Show active items only', required=False)\n\nviews.py\nfrom django.views.generic.list import ListView\nfrom django.contrib.postgres.search import SearchQuery, SearchVector, SearchRank\n\nfrom . import models\nfrom . import forms\n\nclass ItemListView(ListView):\n    form_class = forms.SearchForm\n    model = models.Item\n    fields = ['serial_number', 'part_number', 'manufacturer', 'tags', 'is_active']\n    template_name_suffix = '_list'\n\n    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['form'] = self.form_class(self.request.GET)\n        return context\n\n    def get_queryset(self):\n        queryset = super().get_queryset()\n        form = self.form_class(self.request.GET)\n        if form.is_valid():\n            if form.cleaned_data['active_only']:\n                queryset = queryset.filter(is_active=True)\n\n            if not form.cleaned_data['search']:\n                return super().get_queryset()\n\n            search_vector = SearchVector('identifier', 'short_text', 'serial_number', 'revision', 'part_number',\n                                         'manufacturer', 'description', 'tags')\n            search_query = SearchQuery(form.cleaned_data['search'], search_type='websearch')\n            return (\n                queryset.annotate(\n                    search=search_vector, rank=SearchRank(search_vector, search_query)\n                )\n                # .filter(search=search_query)\n                .order_by(\"-rank\").distinct()\n            ) #.filter(search__icontains=form.cleaned_data['search'],)\n        return super().get_queryset()\n\n",
"AnswerId": "76397104",
"AnswerBody": "Your problem is that you're adding the tags field directly to your SearchVector\nLets concatenate the tags with Django's StringAgg into a single string and then use that string in your SearchVector\nfirst we import StringAgg\nfrom django.contrib.postgres.aggregates import StringAgg\n\nthen this is how you have to change your get_queryset function\ndef get_queryset(self):\n    queryset = super().get_queryset()\n    form = self.form_class(self.request.GET)\n    if form.is_valid():\n        if form.cleaned_data['active_only']:\n            queryset = queryset.filter(is_active=True)\n\n        if not form.cleaned_data['search']:\n            return queryset\n\n        queryset = queryset.annotate(tags_str=StringAgg('tags__name', delimiter=' '))\n        search_vector = SearchVector('identifier', 'short_text', 'serial_number', 'revision', 'part_number',\n                                     'manufacturer', 'description', 'tags_str')\n        search_query = SearchQuery(form.cleaned_data['search'], search_type='websearch')\n        return (\n            queryset.annotate(\n                search=search_vector, rank=SearchRank(search_vector, search_query)\n            )\n            .order_by(\"-rank\").distinct()\n        )\n    return queryset\n\n"
},
{
"QuestionId": "76398027",
"QuestionTitle": "What constitutes a directive in C++, and how can I use them effectively?",
"QuestionBody": "How do you exactly define a directive in programming?\n#include is a directive, and using namespace std is a directive as well, assuming that I  am correct.\nWhat actually makes a sentence or word a directive?\nI tried reading from different sources, but all lead to no avail. I  am new to programming and I hope to grasp a good understanding of a directive.\n",
"AnswerId": "76398125",
"AnswerBody": "You mentioned two different programming constructs in your question: 1) the #include pre-processing directive and 2) the using namespace directive.\nEach of these constructs is literally referred to as a \"directive\" in the documentation, but they are completely different things. I can see how that could cause confusion.\nBoth the pre-processing directives and the using directive are not something that the user gets to define. They have a fixed meaning in the language. They can be used with different arguments to achieve different results.\nDirectives like #include can be used to direct what source code is used in the compilation. For example, #include <iostream> will cause the file iostream to be included. There are numerous other pre-processor directives, but for starting out, #include is by far the most important.\nA directive like using std::cout instructs the compiler to bring the std::cout symbol into the current namespace so it can be referenced as simply cout.\nI hope this helps clear up the confusion.\n"
},
{
"QuestionId": "76395200",
"QuestionTitle": "Grouping dictionary data from a list and storing in another dictionary",
"QuestionBody": "I am currently working on a big data set where the data is stored into list with dictionaries (format shown below)\nList = [{ID001: Report-1, ID002: Report-1, ID003: Report-1}, {ID001: Report-2, ID005: Report-5}…..]\n\nI am trying to group and print a list with one dictionary that contains all ID’s from all dictionaries in the above list with related values (in this case report-1, report-2…)\nresult_List = {ID001: [Report-1, Report-2, Report-5], ID002: [Report-3, Report-6, Report-23]}\n\nI thought of using for loop, but once the first dictionary is done looping through all the other dictionaries in list, it has to store unique ID’s in the result_List.\nThe code itself contains lot of loops, which I believe too complex for a list of 200 dictionaries with data.\nI am looking for something with Pandas or Numpy with relatively less complex. Can anyone suggest the best way to do this kind of data crunch?\n",
"AnswerId": "76395444",
"AnswerBody": "This way it can be done.\ndata =  [{ID001: Report-1, ID002: Report-1, ID003: Report-1}, {ID001: Report-2, ID005: Report-5}…..]\nd = pd.DataFrame.from_records(data)\nres = d.to_dict(\"list\")\nprint(res)\n\n"
},
{
"QuestionId": "76397033",
"QuestionTitle": "Retrieve issue number from string for comic",
"QuestionBody": "I'm not great with RegEx.  I need to retrieve the issue number from the long title of a comic book that includes its name and sometimes the artist's name.  Usually the issue number is the last number in the string, but not always.  Here are 6 examples that capture the range of variations I'm looking at:\nSTAR WARS: DOCTOR APHRA 32 CHRIS SPROUSE RETURN OF THE JEDI 40TH ANNIVERSARY VARIANT\nDEADPOOL 7\nX-23: DEADLY REGENESIS 3 GERALD PAREL VARIANT\nSPIDER-MAN 2099: DARK GENESIS 5\nTHE GODFORSAKEN 99 OF KRONOS 2 KEN GRAGGINS VARIANT\nTeenage Mutant Ninja Turtles: Saturday Morning Adventures (2023-) #1 Variant RI (10) (Dooney)\n\nI'm using VBA and this is my current function:\nFunction ExtractText(c As Range) As String\n    Dim rgx As RegExp\n    Dim match As match\n    Dim mc As MatchCollection\n    Dim sComicNo As String, sPattern As Variant\n    Dim lPos As Long, x As Long\n\n    sComicNo = \"\"\n    sPattern = Array(\" [0-9] \", \" #[0-9] \", \" [0-9][0-9] \", \" #[0-9][0-9] \", \" [0-9][0-9]\", \" #[0-9][0-9]\", \" [0-9]\", \" #[0-9]\")\n    lPos = 0\n    \n    Set rgx = New RegExp\n    \n    On Error GoTo ErrHandler\n    \n    Do While sComicNo = \"\"\n        \n        With rgx\n            .Pattern = sPattern(x)\n            .Global = True\n        \n            If .Test(c.Value) Then\n                Set mc = .Execute(c.Value)\n                \n                If mc.Count > 0 Then\n                    Set match = mc.Item(mc.Count - 1)\n                Else\n                    ExtractText = \"\"\n                End If\n                \n                lPos = match.FirstIndex\n                sComicNo = WorksheetFunction.Trim(match.Value) & \"|\" & lPos\n            Else\n                sComicNo = \"\"\n            End If\n            \n            x = x + 1\n            \n            If x > 8 Then\n                ExtractText = sComicNo\n                Exit Function\n            End If\n        \n        End With\n        \n    Loop\n    \n    ExtractText = sComicNo\n    \nErrHandler:\n\n    Exit Function\n    \nEnd Function\n\nThis pattern matches all my examples except the Spider-Man 2099, but there are other possible variations I'm overlooking.  It is also retrieving the position of the match for a separate purpose.  I'm trying to be as restrictive as possible by using patterns in a sequence that will retrieve very specific cases and gradually work up from there.\n",
"AnswerId": "76397135",
"AnswerBody": "I don't know VBA, but by trying to comprehend the code I think your regex can be simplified to this:\n\\s      # Match a whitespace,\n#?      # an optional '#', then\n\\d\\d?   # 1 or 2 digits, followed by\n\\b      # a word boundary (prevents numbers with 3+ digits from being matched).\n\nTry it on regex101.com.\nAlternatively, you can use a lookbehind to skip the trimming part:\n(?<=\\s)#?\\d\\d?\\b\n\n...in which (?<=\\s) means \"match something preceded by a whitespace\".\nTry it on regex101.com.\n"
},
{
"QuestionId": "76395338",
"QuestionTitle": "Why does Javascript add an extra backslash when I capture input values?",
"QuestionBody": "I have a standard HTML input form. The issue occurs when I enter something like \\n in the input. I'm aware it's a regex that means newline, but a user may for example have it in their password, and it should remain unchanged.\nThe behaviour I'm observing:\nconst value = $('#myInput').val()\nconsole.log(value)   // Console shows: hello\\n (which is indeed what the user typed in)\nconst outputData = { password: value }\nconsole.log(outputData)   // Console shows: { password: \"hello\\\\n\"}\n\nIt would be fine if it were just a display issue, but that data is being sent to the server with the double backslash, so there is a mismatch between what the user types in and what gets sent to the server (which of course breaks things).\nIt's also worth noting this doesn't happen (everything works as expected) when I send a request body via Postman\n\nWhy is this happening?\nHow can I avoid it?\n\n",
"AnswerId": "76395466",
"AnswerBody": "Re the code comments in the code you shared:\n\n\nconst value = $('#myInput').val()\nconsole.log(value)   // Console shows: hello\\n (which is indeed what the user typed in)\nconst outputData = { password: value }\nconsole.log(outputData)   // Console shows: { password: \"hello\\\\n\"}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<input type=\"text\" id=\"myInput\" value=\"hello\\n\">\n\n\n\nI assume you're referring to this style of console output:\n\nThat's just the difference between how the Chrome console (and some others) displays the output when you pass it a string vs. when you pass it an object. JavaScript is not adding anything to the string. When you pass a string to console.log, it just shows the characters of the string (which in your case are h, e, l, l, o, \\, and n). But when you pass it an object, it shows you something that looks like an object literal, and since the object literal contains a string literal for password, the backslash in the string literal has to be shown escaped. (Otherwise, it would be an escape character.) But there is only one backslash in the string, not two, exactly like this:\n\n\nconsole.log(\"hello\\\\n\"); // <== Notice the escaped backslash\n\n\n\nThe backslash is escaped in the string literal, because otherwise it wouldn't be a backslash, it would be an escape character changing the meaning of the next character (in this case, putting a newline in the string rather than \\ and n.) There is only one backslash in the string.\n\nIt would be fine if it were just a display issue, but that data is being sent to the server with the double backslash...\n\nTwo possibilities here:\n\nThe extra backslash is being added by code you haven't shown, either the code preparing the string to send to your server, or the code on the server writing it to the database. For instance, another answer posted to this question suggested doing JSON.stringify(value), but that would add an extra backslash to it for the same reason we put on in a string literal: you have to escape backslashes in JSON strings. The extra one would be removed if the server code parsed the JSON, but it wouldn't be if the server code used the string as-is. I'm not saying you're doing that, just that it's the kind of thing you could be doing to see what you're describing.\n\nOr — with apologies! :-) — it's possible that you're misinterpreting what you're seeing for what's in the database in the same way you misinterpeting the object literal in the console and there is actually only one backslash in the database.\n\n\nYour best bet for finding out what's causing the problem is to carefully audit the code processing the string, in particular:\n\nCheck the actual value of the string with a debugger just prior to sending it to the server.\nCheck how you're encoding what you're sending the server.\nCheck exactly what your code on the server is receiving.\nCheck what that code is doing to the string when adding the value to the database.\n\nSomewhere along the line, you'll either determine there isn't actually a problem (#2 above), or you'll find out what's mistakenly adding the backslash (#1 above).\n"
},
{
"QuestionId": "76396891",
"QuestionTitle": "How to make RTL to support right to left languages only in a column in XAML WPF VB.NET",
"QuestionBody": "If using FlowDirection=\"RightToLeft\" will change the whole datagrid right to left and solves the problem.\nBut my grid has both LTR and RTL contents. Some columns are LTR and some other column are RTL.\nSo please help me on this that how can I only set one column as RTL?\nThanks.\n",
"AnswerId": "76397169",
"AnswerBody": "At last I found the answer.\nHere it is:\n   <DataGridTextColumn ...>\n        <DataGridTextColumn.ElementStyle>\n            <Style TargetType=\"TextBlock\">\n                <Setter Property=\"FlowDirection\" Value=\"LeftToRight\" />\n            </Style>\n        </DataGridTextColumn.ElementStyle>\n        <DataGridTextColumn.EditingElementStyle>\n            <Style TargetType=\"TextBox\">\n                <Setter Property=\"FlowDirection\" Value=\"LeftToRight\" />\n            </Style>\n        </DataGridTextColumn.EditingElementStyle>\n    </DataGridTextColumn>\n\n"
},
{
"QuestionId": "76397866",
"QuestionTitle": "make two combo box related in javaFx",
"QuestionBody": "I Want to change the second comboBox items based on the user select of item in another comboBox.\nI do have courseCB comboBox that the user have to select first and then selct from mealCB comboBox;\nmealCB items should change based of courseCB select item.\n   @FXML\n    private ComboBox<String> courseCB;\n\n    @FXML\n    private ComboBox<String> mealCB;\n  @FXML\n    void initialize() {\n     //   courseCB.\n        ObservableList<String> courseList = FXCollections.observableArrayList(fileReader.getMealCourseArray());\n        courseCB.setItems(courseList);\n        courseCB.setValue(\"main meal\");\n        \n\n courseCB.getSelectionModel().selectedItemProperty().addListener(new ChangeListener<String>() {\n        @Override\n        public void changed(ObservableValue<? extends String> observableValue, String s, String t1) {\n            switch (t1){\n                case  \"first meal\": {\n                    ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"first meal\"));\n                    mealCB.setItems(mealByCourse);\n                }\n                case \"main meal\": {\n                    ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"main meal\"));\n                    mealCB.setItems(mealByCourse);\n                }\n                case \"drink\": {\n                    ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"drink\"));\n                    mealCB.setItems(mealByCourse);\n                }\n                break;\n            }\n        }\n    });\n}\n\n\nthe code of getMealBycourse:\n public static String[] getMealsByCourse(String mealCourse){\n        ArrayList<String> mealsList = new ArrayList<>();\n        Meal[] meals ;\n        fileReader filereader= new fileReader();\n        meals = filereader.getMealArray();\n        for (int i = 0; i < meals.length ; i++) {\n            if ((meals[i].getMealCourse()).compareTo(mealCourse)==0) {\n                mealsList.add(meals[i].getMealName());\n            }\n        }\n        String [] mealsByCourse = mealsList.toArray(new String[mealsList.size()]);\n        return mealsByCourse;\n    }\n\n\nfileReader.getMealCourseArray() will return an array of items of courseMeal and populate the courseCB (comboBox) with it.\nthe problem is that that mealCB is getting values of drinks only.\nthe method of get mealByCourse is working very well by testing it.\nso what is needed to change in the addListener to make it work.\n",
"AnswerId": "76398139",
"AnswerBody": "This is related to these answers so also study them:\n\nJavafx Cascading dropdown based on selection\ncombobox dependent on another combobox - JavaFX\n\nYou are using a similar approach to the first referenced answer, but have a logic error in your switch statement.\nYou don't break after every condition, instead you break only at the end of the switch. So the other conditions are \"working\" as in doing what they are asked to do, but the subsequent conditions run too and only the last one applies.\nYou can fix your logic error with the following code:\nswitch (t1) {\n    case \"first meal\": {\n        ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"first meal\"));\n        mealCB.setItems(mealByCourse);\n    }\n    break; \n    case \"main meal\": {\n        ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"main meal\"));\n        mealCB.setItems(mealByCourse);\n    }\n    break;\n    case \"drink\": {\n        ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"drink\"));\n        mealCB.setItems(mealByCourse);\n    }\n    break;\n}\n\nNote that I added break statements in between each case statement.\nThat way, only the block of a single case statement will be executed for each case.\nI advise you to go back and do some study on the Java language basics.  Study how switch statements work. That article is for Java 8. There are improved switches in later Java versions, but you aren't using the improved switch syntax, so the old article still applies for the old syntax that you use.\nIf you want to switch to using a more modern syntax (requires Java 14+), then you can write instead:\nswitch (t1) {\n    case \"first meal\" -> {\n        ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"first meal\"));\n        mealCB.setItems(mealByCourse);\n    }\n\n    case \"main meal\" -> {\n        ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"main meal\"));\n        mealCB.setItems(mealByCourse);\n    }\n\n    case \"drink\" -> {\n        ObservableList<String> mealByCourse = FXCollections.observableArrayList(fileReader.getMealsByCourse(\"drink\"));\n        mealCB.setItems(mealByCourse);\n    }\n}\n\nThis will do the same as the previous example, but is IMO, less error prone.  It uses the new -> syntax for cases in switches rather than the old : syntax.  The new syntax does not fall through cases and does not require explicit break statements.\nThe switch can be converted to an expression to allow a more functional style of programming, which I often prefer:\nString[] mealsByCourse = switch (t1) {\n    case \"first meal\" -> fileReader.getMealsByCourse(\"first meal\");\n    case \"main meal\" -> fileReader.getMealsByCourse(\"main meal\");\n    case \"drink\" -> fileReader.getMealsByCourse(\"drink\");\n    default -> new String[0];\n);\n\nmealCB.setItems(\n    FXCollections.observableArrayList(\n            mealsByCourse\n    )\n);\n\nBut then when you do that it becomes clear that you are just switching on a value and applying that value.\nSo you can instead just eliminate the switch statement and use the simple solution proposed by Anon in comments:\nObservableList<String> mealsByCourse = FXCollections.observableArrayList(\n        fileReader.getMealsByCourse(t1)\n);                     \n\nmealCB.setItems(mealsByCourse);\n\nThis final approach is the same as one of those proposed solutions in this answer to a related question:\n\ncombobox dependent on another combobox - JavaFX\n\n"
}
]